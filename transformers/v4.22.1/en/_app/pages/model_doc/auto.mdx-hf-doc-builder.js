import{S as Ima,i as Nma,s as qma,e as a,k as l,w as F,t as o,M as jma,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as v,y as M,q as E,o as C,B as w,v as Dma,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as Dvt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Gma($){let g,b,u,m,p,d,h,yo,rd,Mm,pt,td,ad,b9,Em,Ve,He,nd,Zn,F9,es,os,T9,sd,rs,M9,ld,Cm,Qa;return{c(){g=a("p"),b=o("If your "),u=a("code"),m=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),rd=a("code"),Mm=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),td=a("code"),ad=o('"new-model"'),b9=o(")."),Em=l(),Ve=a("p"),He=o("Likewise, if your "),nd=a("code"),Zn=o("NewModel"),F9=o(" is a subclass of "),es=a("a"),os=o("PreTrainedModel"),T9=o(`, make sure its
`),sd=a("code"),rs=o("config_class"),M9=o(` attribute is set to the same class you use when registering the model (here
`),ld=a("code"),Cm=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);b=r(Ae,"If your "),u=n(Ae,"CODE",{});var CB=s(u);m=r(CB,"NewModelConfig"),CB.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var id=s(d);h=r(id,"PretrainedConfig"),id.forEach(t),yo=r(Ae,`, make sure its
`),rd=n(Ae,"CODE",{});var wB=s(rd);Mm=r(wB,"model_type"),wB.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),td=n(Ae,"CODE",{});var AB=s(td);ad=r(AB,'"new-model"'),AB.forEach(t),b9=r(Ae,")."),Ae.forEach(t),Em=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),nd=n(xo,"CODE",{});var Wa=s(nd);Zn=r(Wa,"NewModel"),Wa.forEach(t),F9=r(xo," is a subclass of "),es=n(xo,"A",{href:!0});var LB=s(es);os=r(LB,"PreTrainedModel"),LB.forEach(t),T9=r(xo,`, make sure its
`),sd=n(xo,"CODE",{});var wm=s(sd);rs=r(wm,"config_class"),wm.forEach(t),M9=r(xo,` attribute is set to the same class you use when registering the model (here
`),ld=n(xo,"CODE",{});var yB=s(ld);Cm=r(yB,"NewModelConfig"),yB.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){c(es,"href","/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){v(Je,g,Ae),e(g,b),e(g,u),e(u,m),e(g,p),e(g,d),e(d,h),e(g,yo),e(g,rd),e(rd,Mm),e(g,pt),e(g,td),e(td,ad),e(g,b9),v(Je,Em,Ae),v(Je,Ve,Ae),e(Ve,He),e(Ve,nd),e(nd,Zn),e(Ve,F9),e(Ve,es),e(es,os),e(Ve,T9),e(Ve,sd),e(sd,rs),e(Ve,M9),e(Ve,ld),e(ld,Cm),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(Em),Je&&t(Ve)}}}function Oma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Vma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Xma($){let g,b,u,m,p;return{c(){g=a("p"),b=o("Passing "),u=a("code"),m=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);m=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){v(d,g,h),e(g,b),e(g,u),e(u,m),e(g,p)},d(d){d&&t(g)}}}function zma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Qma($){let g,b,u,m,p;return{c(){g=a("p"),b=o("Passing "),u=a("code"),m=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);m=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){v(d,g,h),e(g,b),e(g,u),e(u,m),e(g,p)},d(d){d&&t(g)}}}function Wma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Uma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Hma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Jma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Yma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Kma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Zma($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function ega($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function oga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function rga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function tga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function aga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function nga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function sga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function lga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function iga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function dga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function cga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function fga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function mga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function gga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function hga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function uga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function pga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function _ga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function vga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function bga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Fga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Tga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Mga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Ega($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Cga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function wga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Aga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Lga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function yga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function xga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $ga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function kga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Sga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Rga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Pga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Bga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Iga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Nga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function qga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function jga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Dga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Gga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Oga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Vga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Xga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function zga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Qga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Wga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Uga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Hga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Jga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Yga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Kga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Zga($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function eha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function oha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function rha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function tha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function aha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function nha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function sha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function lha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function iha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function dha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function cha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function fha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function mha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function gha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function hha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function uha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="3dc6de3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;3dc6de3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function pha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function _ha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function vha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function bha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Fha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Tha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Mha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Eha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Cha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function wha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Aha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Lha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function yha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function xha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function $ha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function kha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Sha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Rha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Pha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Bha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Iha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Nha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function qha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function jha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Dha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Gha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Oha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Vha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Xha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function zha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Qha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Wha($){let g,b,u,m,p;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),b=o("Examples:"),u=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);b=r(h,"Examples:"),h.forEach(t),u=i(d),T(m.$$.fragment,d)},m(d,h){v(d,g,h),e(g,b),v(d,u,h),M(m,d,h),p=!0},p:I,i(d){p||(E(m.$$.fragment,d),p=!0)},o(d){C(m.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(m,d)}}}function Uha($){let g,b,u,m,p,d,h,yo,rd,Mm,pt,td,ad,b9,Em,Ve,He,nd,Zn,F9,es,os,T9,sd,rs,M9,ld,Cm,Qa,Je,Ae,CB,id,wB,AB,xo,Wa,LB,wm,yB,iro,kYe,dd,Am,Hie,E9,dro,Jie,cro,SYe,ts,fro,Yie,mro,gro,Kie,hro,uro,RYe,C9,PYe,xB,pro,BYe,Lm,IYe,cd,ym,Zie,w9,_ro,ede,vro,NYe,$o,A9,bro,L9,Fro,$B,Tro,Mro,Ero,y9,Cro,ode,wro,Aro,Lro,Pr,x9,yro,rde,xro,$ro,fd,kro,tde,Sro,Rro,ade,Pro,Bro,Iro,A,xm,nde,Nro,qro,kB,jro,Dro,Gro,$m,sde,Oro,Vro,SB,Xro,zro,Qro,km,lde,Wro,Uro,RB,Hro,Jro,Yro,Sm,ide,Kro,Zro,PB,eto,oto,rto,Rm,dde,tto,ato,BB,nto,sto,lto,Pm,cde,ito,dto,IB,cto,fto,mto,Bm,fde,gto,hto,NB,uto,pto,_to,Im,mde,vto,bto,qB,Fto,Tto,Mto,Nm,gde,Eto,Cto,jB,wto,Ato,Lto,qm,hde,yto,xto,DB,$to,kto,Sto,jm,ude,Rto,Pto,GB,Bto,Ito,Nto,Dm,pde,qto,jto,OB,Dto,Gto,Oto,Gm,_de,Vto,Xto,VB,zto,Qto,Wto,Om,vde,Uto,Hto,XB,Jto,Yto,Kto,Vm,bde,Zto,eao,zB,oao,rao,tao,Xm,Fde,aao,nao,QB,sao,lao,iao,zm,Tde,dao,cao,WB,fao,mao,gao,Qm,Mde,hao,uao,UB,pao,_ao,vao,Wm,Ede,bao,Fao,HB,Tao,Mao,Eao,Um,Cde,Cao,wao,JB,Aao,Lao,yao,Hm,wde,xao,$ao,YB,kao,Sao,Rao,Jm,Ade,Pao,Bao,KB,Iao,Nao,qao,Ym,Lde,jao,Dao,ZB,Gao,Oao,Vao,Km,yde,Xao,zao,eI,Qao,Wao,Uao,Zm,xde,Hao,Jao,oI,Yao,Kao,Zao,eg,$de,eno,ono,rI,rno,tno,ano,og,kde,nno,sno,tI,lno,ino,dno,rg,Sde,cno,fno,aI,mno,gno,hno,tg,Rde,uno,pno,nI,_no,vno,bno,ag,Pde,Fno,Tno,sI,Mno,Eno,Cno,ng,Bde,wno,Ano,lI,Lno,yno,xno,sg,Ide,$no,kno,iI,Sno,Rno,Pno,lg,Nde,Bno,Ino,dI,Nno,qno,jno,ig,qde,Dno,Gno,cI,Ono,Vno,Xno,dg,jde,zno,Qno,fI,Wno,Uno,Hno,cg,Dde,Jno,Yno,mI,Kno,Zno,eso,fg,Gde,oso,rso,gI,tso,aso,nso,mg,Ode,sso,lso,hI,iso,dso,cso,gg,Vde,fso,mso,uI,gso,hso,uso,hg,Xde,pso,_so,pI,vso,bso,Fso,ug,zde,Tso,Mso,_I,Eso,Cso,wso,pg,Qde,Aso,Lso,vI,yso,xso,$so,_g,Wde,kso,Sso,bI,Rso,Pso,Bso,vg,Ude,Iso,Nso,FI,qso,jso,Dso,bg,Hde,Gso,Oso,TI,Vso,Xso,zso,Fg,Jde,Qso,Wso,MI,Uso,Hso,Jso,Tg,Yde,Yso,Kso,EI,Zso,elo,olo,Mg,Kde,rlo,tlo,CI,alo,nlo,slo,Eg,Zde,llo,ilo,wI,dlo,clo,flo,Cg,ece,mlo,glo,AI,hlo,ulo,plo,wg,oce,_lo,vlo,LI,blo,Flo,Tlo,Ag,rce,Mlo,Elo,yI,Clo,wlo,Alo,Lg,tce,Llo,ylo,xI,xlo,$lo,klo,yg,ace,Slo,Rlo,$I,Plo,Blo,Ilo,xg,nce,Nlo,qlo,kI,jlo,Dlo,Glo,$g,sce,Olo,Vlo,SI,Xlo,zlo,Qlo,kg,lce,Wlo,Ulo,RI,Hlo,Jlo,Ylo,Sg,ice,Klo,Zlo,PI,eio,oio,rio,Rg,dce,tio,aio,BI,nio,sio,lio,Pg,cce,iio,dio,II,cio,fio,mio,Bg,fce,gio,hio,NI,uio,pio,_io,Ig,mce,vio,bio,qI,Fio,Tio,Mio,Ng,gce,Eio,Cio,jI,wio,Aio,Lio,qg,hce,yio,xio,DI,$io,kio,Sio,jg,uce,Rio,Pio,GI,Bio,Iio,Nio,Dg,pce,qio,jio,OI,Dio,Gio,Oio,Gg,_ce,Vio,Xio,VI,zio,Qio,Wio,Og,vce,Uio,Hio,XI,Jio,Yio,Kio,Vg,bce,Zio,edo,zI,odo,rdo,tdo,Xg,Fce,ado,ndo,QI,sdo,ldo,ido,zg,Tce,ddo,cdo,WI,fdo,mdo,gdo,Qg,Mce,hdo,udo,UI,pdo,_do,vdo,Wg,Ece,bdo,Fdo,HI,Tdo,Mdo,Edo,Ug,Cce,Cdo,wdo,JI,Ado,Ldo,ydo,Hg,wce,xdo,$do,YI,kdo,Sdo,Rdo,Jg,Ace,Pdo,Bdo,KI,Ido,Ndo,qdo,Yg,Lce,jdo,Ddo,ZI,Gdo,Odo,Vdo,Kg,yce,Xdo,zdo,eN,Qdo,Wdo,Udo,Zg,xce,Hdo,Jdo,oN,Ydo,Kdo,Zdo,eh,$ce,eco,oco,rN,rco,tco,aco,oh,kce,nco,sco,tN,lco,ico,dco,rh,Sce,cco,fco,aN,mco,gco,hco,th,Rce,uco,pco,nN,_co,vco,bco,ah,Pce,Fco,Tco,sN,Mco,Eco,Cco,nh,Bce,wco,Aco,lN,Lco,yco,xco,sh,Ice,$co,kco,iN,Sco,Rco,Pco,lh,Nce,Bco,Ico,dN,Nco,qco,jco,ih,qce,Dco,Gco,cN,Oco,Vco,Xco,dh,jce,zco,Qco,fN,Wco,Uco,Hco,ch,Dce,Jco,Yco,mN,Kco,Zco,efo,fh,Gce,ofo,rfo,gN,tfo,afo,nfo,mh,Oce,sfo,lfo,hN,ifo,dfo,cfo,gh,Vce,ffo,mfo,uN,gfo,hfo,ufo,hh,Xce,pfo,_fo,pN,vfo,bfo,Ffo,uh,zce,Tfo,Mfo,_N,Efo,Cfo,wfo,ph,Qce,Afo,Lfo,vN,yfo,xfo,$fo,_h,Wce,kfo,Sfo,bN,Rfo,Pfo,Bfo,vh,Uce,Ifo,Nfo,FN,qfo,jfo,Dfo,bh,Hce,Gfo,Ofo,TN,Vfo,Xfo,zfo,Fh,Jce,Qfo,Wfo,MN,Ufo,Hfo,Jfo,Th,Yce,Yfo,Kfo,EN,Zfo,emo,omo,Mh,Kce,rmo,tmo,CN,amo,nmo,smo,Eh,Zce,lmo,imo,wN,dmo,cmo,fmo,Ch,efe,mmo,gmo,AN,hmo,umo,pmo,wh,ofe,_mo,vmo,LN,bmo,Fmo,Tmo,Ah,rfe,Mmo,Emo,yN,Cmo,wmo,Amo,Lh,tfe,Lmo,ymo,xN,xmo,$mo,kmo,yh,afe,Smo,Rmo,$N,Pmo,Bmo,Imo,xh,nfe,Nmo,qmo,kN,jmo,Dmo,Gmo,$h,sfe,Omo,Vmo,SN,Xmo,zmo,Qmo,kh,lfe,Wmo,Umo,RN,Hmo,Jmo,Ymo,Sh,ife,Kmo,Zmo,PN,ego,ogo,rgo,Rh,dfe,tgo,ago,BN,ngo,sgo,lgo,Ph,cfe,igo,dgo,IN,cgo,fgo,mgo,Bh,ffe,ggo,hgo,NN,ugo,pgo,_go,Ih,mfe,vgo,bgo,qN,Fgo,Tgo,Mgo,Nh,gfe,Ego,Cgo,jN,wgo,Ago,Lgo,qh,hfe,ygo,xgo,DN,$go,kgo,Sgo,jh,ufe,Rgo,Pgo,GN,Bgo,Igo,Ngo,Dh,pfe,qgo,jgo,ON,Dgo,Ggo,Ogo,Gh,_fe,Vgo,Xgo,VN,zgo,Qgo,Wgo,Oh,vfe,Ugo,Hgo,XN,Jgo,Ygo,Kgo,Vh,bfe,Zgo,eho,zN,oho,rho,tho,Xh,Ffe,aho,nho,QN,sho,lho,iho,zh,Tfe,dho,cho,WN,fho,mho,gho,Qh,hho,Wh,$9,uho,Mfe,pho,qYe,md,Uh,Efe,k9,_ho,Cfe,vho,jYe,ko,S9,bho,R9,Fho,UN,Tho,Mho,Eho,P9,Cho,wfe,who,Aho,Lho,Br,B9,yho,Afe,xho,$ho,Ua,kho,Lfe,Sho,Rho,yfe,Pho,Bho,xfe,Iho,Nho,qho,k,as,$fe,jho,Dho,HN,Gho,Oho,JN,Vho,Xho,zho,ns,kfe,Qho,Who,YN,Uho,Hho,KN,Jho,Yho,Kho,ss,Sfe,Zho,euo,ZN,ouo,ruo,eq,tuo,auo,nuo,Hh,Rfe,suo,luo,oq,iuo,duo,cuo,ls,Pfe,fuo,muo,rq,guo,huo,tq,uuo,puo,_uo,Jh,Bfe,vuo,buo,aq,Fuo,Tuo,Muo,Yh,Ife,Euo,Cuo,nq,wuo,Auo,Luo,Kh,Nfe,yuo,xuo,sq,$uo,kuo,Suo,is,qfe,Ruo,Puo,lq,Buo,Iuo,iq,Nuo,quo,juo,ds,jfe,Duo,Guo,dq,Ouo,Vuo,cq,Xuo,zuo,Quo,cs,Dfe,Wuo,Uuo,fq,Huo,Juo,mq,Yuo,Kuo,Zuo,Zh,Gfe,epo,opo,gq,rpo,tpo,apo,eu,Ofe,npo,spo,hq,lpo,ipo,dpo,ou,Vfe,cpo,fpo,uq,mpo,gpo,hpo,fs,Xfe,upo,ppo,pq,_po,vpo,_q,bpo,Fpo,Tpo,ru,zfe,Mpo,Epo,vq,Cpo,wpo,Apo,ms,Qfe,Lpo,ypo,bq,xpo,$po,Fq,kpo,Spo,Rpo,gs,Wfe,Ppo,Bpo,Tq,Ipo,Npo,Mq,qpo,jpo,Dpo,hs,Ufe,Gpo,Opo,Eq,Vpo,Xpo,Cq,zpo,Qpo,Wpo,us,Hfe,Upo,Hpo,wq,Jpo,Ypo,Aq,Kpo,Zpo,e_o,tu,Jfe,o_o,r_o,Lq,t_o,a_o,n_o,ps,Yfe,s_o,l_o,yq,i_o,d_o,xq,c_o,f_o,m_o,_s,Kfe,g_o,h_o,$q,u_o,p_o,kq,__o,v_o,b_o,vs,Zfe,F_o,T_o,Sq,M_o,E_o,Rq,C_o,w_o,A_o,bs,eme,L_o,y_o,Pq,x_o,$_o,Bq,k_o,S_o,R_o,Fs,ome,P_o,B_o,Iq,I_o,N_o,Nq,q_o,j_o,D_o,Ts,rme,G_o,O_o,qq,V_o,X_o,jq,z_o,Q_o,W_o,Ms,tme,U_o,H_o,Dq,J_o,Y_o,Gq,K_o,Z_o,e2o,au,ame,o2o,r2o,Oq,t2o,a2o,n2o,Es,nme,s2o,l2o,Vq,i2o,d2o,Xq,c2o,f2o,m2o,nu,sme,g2o,h2o,zq,u2o,p2o,_2o,Cs,lme,v2o,b2o,Qq,F2o,T2o,Wq,M2o,E2o,C2o,ws,ime,w2o,A2o,Uq,L2o,y2o,Hq,x2o,$2o,k2o,As,dme,S2o,R2o,Jq,P2o,B2o,Yq,I2o,N2o,q2o,su,cme,j2o,D2o,Kq,G2o,O2o,V2o,Ls,fme,X2o,z2o,Zq,Q2o,W2o,ej,U2o,H2o,J2o,ys,mme,Y2o,K2o,oj,Z2o,evo,rj,ovo,rvo,tvo,xs,gme,avo,nvo,tj,svo,lvo,aj,ivo,dvo,cvo,lu,hme,fvo,mvo,nj,gvo,hvo,uvo,$s,ume,pvo,_vo,sj,vvo,bvo,lj,Fvo,Tvo,Mvo,ks,pme,Evo,Cvo,ij,wvo,Avo,dj,Lvo,yvo,xvo,Ss,_me,$vo,kvo,cj,Svo,Rvo,fj,Pvo,Bvo,Ivo,Rs,vme,Nvo,qvo,mj,jvo,Dvo,gj,Gvo,Ovo,Vvo,Ps,bme,Xvo,zvo,hj,Qvo,Wvo,uj,Uvo,Hvo,Jvo,Bs,Fme,Yvo,Kvo,pj,Zvo,e1o,_j,o1o,r1o,t1o,Is,Tme,a1o,n1o,vj,s1o,l1o,bj,i1o,d1o,c1o,Ns,Mme,f1o,m1o,Fj,g1o,h1o,Tj,u1o,p1o,_1o,iu,Eme,v1o,b1o,Mj,F1o,T1o,M1o,qs,Cme,E1o,C1o,Ej,w1o,A1o,Cj,L1o,y1o,x1o,du,wme,$1o,k1o,wj,S1o,R1o,P1o,cu,Ame,B1o,I1o,Aj,N1o,q1o,j1o,js,Lme,D1o,G1o,Lj,O1o,V1o,yj,X1o,z1o,Q1o,Ds,yme,W1o,U1o,xj,H1o,J1o,$j,Y1o,K1o,Z1o,Gs,xme,e4o,o4o,kj,r4o,t4o,Sj,a4o,n4o,s4o,fu,$me,l4o,i4o,Rj,d4o,c4o,f4o,Os,kme,m4o,g4o,Pj,h4o,u4o,Bj,p4o,_4o,v4o,Vs,Sme,b4o,F4o,Ij,T4o,M4o,Nj,E4o,C4o,w4o,Xs,Rme,A4o,L4o,qj,y4o,x4o,jj,$4o,k4o,S4o,zs,Pme,R4o,P4o,Dj,B4o,I4o,Gj,N4o,q4o,j4o,Qs,Bme,D4o,G4o,Oj,O4o,V4o,Vj,X4o,z4o,Q4o,Ws,Ime,W4o,U4o,Xj,H4o,J4o,zj,Y4o,K4o,Z4o,Us,Nme,ebo,obo,Qj,rbo,tbo,Wj,abo,nbo,sbo,Hs,qme,lbo,ibo,Uj,dbo,cbo,Hj,fbo,mbo,gbo,mu,jme,hbo,ubo,Jj,pbo,_bo,vbo,Js,Dme,bbo,Fbo,Yj,Tbo,Mbo,Kj,Ebo,Cbo,wbo,Ys,Gme,Abo,Lbo,Zj,ybo,xbo,eD,$bo,kbo,Sbo,gu,Ome,Rbo,Pbo,oD,Bbo,Ibo,Nbo,hu,Vme,qbo,jbo,rD,Dbo,Gbo,Obo,uu,Xme,Vbo,Xbo,tD,zbo,Qbo,Wbo,pu,zme,Ubo,Hbo,aD,Jbo,Ybo,Kbo,Ks,Qme,Zbo,eFo,nD,oFo,rFo,sD,tFo,aFo,nFo,_u,Wme,sFo,lFo,lD,iFo,dFo,cFo,Zs,Ume,fFo,mFo,iD,gFo,hFo,dD,uFo,pFo,_Fo,el,Hme,vFo,bFo,cD,FFo,TFo,fD,MFo,EFo,CFo,ol,Jme,wFo,AFo,mD,LFo,yFo,gD,xFo,$Fo,kFo,rl,Yme,SFo,RFo,hD,PFo,BFo,uD,IFo,NFo,qFo,tl,Kme,jFo,DFo,pD,GFo,OFo,_D,VFo,XFo,zFo,al,Zme,QFo,WFo,vD,UFo,HFo,bD,JFo,YFo,KFo,vu,ege,ZFo,eTo,FD,oTo,rTo,tTo,bu,oge,aTo,nTo,TD,sTo,lTo,iTo,nl,rge,dTo,cTo,MD,fTo,mTo,ED,gTo,hTo,uTo,sl,tge,pTo,_To,CD,vTo,bTo,wD,FTo,TTo,MTo,ll,age,ETo,CTo,AD,wTo,ATo,LD,LTo,yTo,xTo,Fu,nge,$To,kTo,yD,STo,RTo,PTo,Tu,sge,BTo,ITo,xD,NTo,qTo,jTo,Mu,lge,DTo,GTo,$D,OTo,VTo,XTo,il,ige,zTo,QTo,kD,WTo,UTo,SD,HTo,JTo,YTo,dl,dge,KTo,ZTo,RD,eMo,oMo,PD,rMo,tMo,aMo,Eu,cge,nMo,sMo,BD,lMo,iMo,dMo,Cu,fge,cMo,fMo,ID,mMo,gMo,hMo,wu,mge,uMo,pMo,ND,_Mo,vMo,bMo,cl,gge,FMo,TMo,qD,MMo,EMo,jD,CMo,wMo,AMo,fl,hge,LMo,yMo,DD,xMo,$Mo,GD,kMo,SMo,RMo,Au,uge,PMo,BMo,OD,IMo,NMo,qMo,Lu,pge,jMo,DMo,VD,GMo,OMo,VMo,ml,_ge,XMo,zMo,XD,QMo,WMo,zD,UMo,HMo,JMo,gl,vge,YMo,KMo,QD,ZMo,eEo,WD,oEo,rEo,tEo,hl,bge,aEo,nEo,UD,sEo,lEo,HD,iEo,dEo,cEo,ul,Fge,fEo,mEo,JD,gEo,hEo,YD,uEo,pEo,_Eo,yu,vEo,xu,I9,bEo,Tge,FEo,DYe,gd,$u,Mge,N9,TEo,Ege,MEo,GYe,So,q9,EEo,j9,CEo,KD,wEo,AEo,LEo,D9,yEo,Cge,xEo,$Eo,kEo,Ye,G9,SEo,wge,REo,PEo,Ha,BEo,Age,IEo,NEo,Lge,qEo,jEo,yge,DEo,GEo,OEo,W,ku,xge,VEo,XEo,ZD,zEo,QEo,WEo,Su,$ge,UEo,HEo,eG,JEo,YEo,KEo,Ru,kge,ZEo,eCo,oG,oCo,rCo,tCo,Pu,Sge,aCo,nCo,rG,sCo,lCo,iCo,Bu,Rge,dCo,cCo,tG,fCo,mCo,gCo,Iu,Pge,hCo,uCo,aG,pCo,_Co,vCo,Nu,Bge,bCo,FCo,nG,TCo,MCo,ECo,qu,Ige,CCo,wCo,sG,ACo,LCo,yCo,ju,Nge,xCo,$Co,lG,kCo,SCo,RCo,Du,qge,PCo,BCo,iG,ICo,NCo,qCo,Gu,jge,jCo,DCo,dG,GCo,OCo,VCo,Ou,Dge,XCo,zCo,cG,QCo,WCo,UCo,Vu,Gge,HCo,JCo,fG,YCo,KCo,ZCo,Xu,Oge,e3o,o3o,mG,r3o,t3o,a3o,zu,Vge,n3o,s3o,gG,l3o,i3o,d3o,Qu,Xge,c3o,f3o,hG,m3o,g3o,h3o,Wu,zge,u3o,p3o,uG,_3o,v3o,b3o,Uu,Qge,F3o,T3o,pG,M3o,E3o,C3o,Hu,Wge,w3o,A3o,_G,L3o,y3o,x3o,Ju,Uge,$3o,k3o,vG,S3o,R3o,P3o,Yu,Hge,B3o,I3o,bG,N3o,q3o,j3o,Ku,Jge,D3o,G3o,FG,O3o,V3o,X3o,Zu,Yge,z3o,Q3o,TG,W3o,U3o,H3o,ep,Kge,J3o,Y3o,MG,K3o,Z3o,e5o,op,Zge,o5o,r5o,EG,t5o,a5o,n5o,rp,ehe,s5o,l5o,CG,i5o,d5o,c5o,tp,ohe,f5o,m5o,wG,g5o,h5o,u5o,ap,rhe,p5o,_5o,AG,v5o,b5o,F5o,np,the,T5o,M5o,LG,E5o,C5o,w5o,sp,ahe,A5o,L5o,yG,y5o,x5o,$5o,lp,nhe,k5o,S5o,xG,R5o,P5o,B5o,ip,she,I5o,N5o,$G,q5o,j5o,D5o,dp,lhe,G5o,O5o,kG,V5o,X5o,z5o,cp,ihe,Q5o,W5o,SG,U5o,H5o,J5o,fp,dhe,Y5o,K5o,RG,Z5o,e0o,o0o,mp,che,r0o,t0o,PG,a0o,n0o,s0o,gp,fhe,l0o,i0o,BG,d0o,c0o,f0o,hp,mhe,m0o,g0o,IG,h0o,u0o,p0o,up,ghe,_0o,v0o,NG,b0o,F0o,T0o,pp,M0o,_p,E0o,vp,O9,C0o,hhe,w0o,OYe,hd,bp,uhe,V9,A0o,phe,L0o,VYe,Ro,X9,y0o,z9,x0o,qG,$0o,k0o,S0o,Q9,R0o,_he,P0o,B0o,I0o,Ke,W9,N0o,vhe,q0o,j0o,ud,D0o,bhe,G0o,O0o,Fhe,V0o,X0o,z0o,ie,Fp,The,Q0o,W0o,jG,U0o,H0o,J0o,Tp,Mhe,Y0o,K0o,DG,Z0o,ewo,owo,Mp,Ehe,rwo,two,GG,awo,nwo,swo,Ep,Che,lwo,iwo,OG,dwo,cwo,fwo,Cp,whe,mwo,gwo,VG,hwo,uwo,pwo,wp,Ahe,_wo,vwo,XG,bwo,Fwo,Two,Ap,Lhe,Mwo,Ewo,zG,Cwo,wwo,Awo,Lp,yhe,Lwo,ywo,QG,xwo,$wo,kwo,yp,xhe,Swo,Rwo,WG,Pwo,Bwo,Iwo,xp,$he,Nwo,qwo,UG,jwo,Dwo,Gwo,$p,khe,Owo,Vwo,HG,Xwo,zwo,Qwo,kp,She,Wwo,Uwo,JG,Hwo,Jwo,Ywo,Sp,Rhe,Kwo,Zwo,YG,eAo,oAo,rAo,Rp,Phe,tAo,aAo,KG,nAo,sAo,lAo,Pp,Bhe,iAo,dAo,ZG,cAo,fAo,mAo,Bp,Ihe,gAo,hAo,eO,uAo,pAo,_Ao,Ip,Nhe,vAo,bAo,oO,FAo,TAo,MAo,Np,qhe,EAo,CAo,rO,wAo,AAo,LAo,qp,jhe,yAo,xAo,tO,$Ao,kAo,SAo,jp,Dhe,RAo,PAo,aO,BAo,IAo,NAo,Dp,Ghe,qAo,jAo,nO,DAo,GAo,OAo,Gp,VAo,Op,XAo,Vp,U9,zAo,Ohe,QAo,XYe,pd,Xp,Vhe,H9,WAo,Xhe,UAo,zYe,Po,J9,HAo,_d,JAo,sO,YAo,KAo,lO,ZAo,e6o,o6o,Y9,r6o,zhe,t6o,a6o,n6o,_t,K9,s6o,Qhe,l6o,i6o,vd,d6o,Whe,c6o,f6o,iO,m6o,g6o,h6o,zp,u6o,Ze,Z9,p6o,Uhe,_6o,v6o,Ja,b6o,Hhe,F6o,T6o,Jhe,M6o,E6o,Yhe,C6o,w6o,A6o,y,Qp,Khe,L6o,y6o,dO,x6o,$6o,k6o,Wp,Zhe,S6o,R6o,cO,P6o,B6o,I6o,Up,eue,N6o,q6o,fO,j6o,D6o,G6o,Hp,oue,O6o,V6o,mO,X6o,z6o,Q6o,Jp,rue,W6o,U6o,gO,H6o,J6o,Y6o,Yp,tue,K6o,Z6o,hO,e7o,o7o,r7o,Kp,aue,t7o,a7o,uO,n7o,s7o,l7o,Zp,nue,i7o,d7o,pO,c7o,f7o,m7o,e_,sue,g7o,h7o,_O,u7o,p7o,_7o,o_,lue,v7o,b7o,vO,F7o,T7o,M7o,r_,iue,E7o,C7o,bO,w7o,A7o,L7o,t_,due,y7o,x7o,FO,$7o,k7o,S7o,a_,cue,R7o,P7o,TO,B7o,I7o,N7o,n_,fue,q7o,j7o,MO,D7o,G7o,O7o,s_,mue,V7o,X7o,EO,z7o,Q7o,W7o,l_,gue,U7o,H7o,CO,J7o,Y7o,K7o,i_,hue,Z7o,eLo,wO,oLo,rLo,tLo,d_,uue,aLo,nLo,AO,sLo,lLo,iLo,c_,pue,dLo,cLo,LO,fLo,mLo,gLo,f_,_ue,hLo,uLo,yO,pLo,_Lo,vLo,m_,vue,bLo,FLo,xO,TLo,MLo,ELo,g_,bue,CLo,wLo,$O,ALo,LLo,yLo,h_,Fue,xLo,$Lo,kO,kLo,SLo,RLo,u_,Tue,PLo,BLo,SO,ILo,NLo,qLo,p_,Mue,jLo,DLo,RO,GLo,OLo,VLo,__,Eue,XLo,zLo,PO,QLo,WLo,ULo,v_,Cue,HLo,JLo,BO,YLo,KLo,ZLo,b_,wue,eyo,oyo,IO,ryo,tyo,ayo,F_,Aue,nyo,syo,NO,lyo,iyo,dyo,T_,Lue,cyo,fyo,qO,myo,gyo,hyo,M_,yue,uyo,pyo,jO,_yo,vyo,byo,E_,xue,Fyo,Tyo,DO,Myo,Eyo,Cyo,C_,$ue,wyo,Ayo,GO,Lyo,yyo,xyo,w_,kue,$yo,kyo,OO,Syo,Ryo,Pyo,A_,Sue,Byo,Iyo,VO,Nyo,qyo,jyo,L_,Rue,Dyo,Gyo,XO,Oyo,Vyo,Xyo,pl,Pue,zyo,Qyo,zO,Wyo,Uyo,QO,Hyo,Jyo,Yyo,y_,Bue,Kyo,Zyo,WO,e8o,o8o,r8o,x_,Iue,t8o,a8o,UO,n8o,s8o,l8o,$_,Nue,i8o,d8o,HO,c8o,f8o,m8o,k_,que,g8o,h8o,JO,u8o,p8o,_8o,S_,jue,v8o,b8o,YO,F8o,T8o,M8o,R_,Due,E8o,C8o,KO,w8o,A8o,L8o,P_,Gue,y8o,x8o,ZO,$8o,k8o,S8o,B_,Oue,R8o,P8o,eV,B8o,I8o,N8o,I_,Vue,q8o,j8o,oV,D8o,G8o,O8o,N_,Xue,V8o,X8o,rV,z8o,Q8o,W8o,q_,zue,U8o,H8o,tV,J8o,Y8o,K8o,j_,Que,Z8o,e9o,aV,o9o,r9o,t9o,D_,Wue,a9o,n9o,nV,s9o,l9o,i9o,G_,Uue,d9o,c9o,sV,f9o,m9o,g9o,O_,Hue,h9o,u9o,lV,p9o,_9o,v9o,V_,Jue,b9o,F9o,iV,T9o,M9o,E9o,X_,Yue,C9o,w9o,dV,A9o,L9o,y9o,z_,Kue,x9o,$9o,cV,k9o,S9o,R9o,Q_,Zue,P9o,B9o,fV,I9o,N9o,q9o,W_,epe,j9o,D9o,mV,G9o,O9o,V9o,U_,ope,X9o,z9o,gV,Q9o,W9o,U9o,H_,rpe,H9o,J9o,hV,Y9o,K9o,Z9o,J_,tpe,exo,oxo,uV,rxo,txo,axo,Y_,ape,nxo,sxo,pV,lxo,ixo,dxo,K_,npe,cxo,fxo,_V,mxo,gxo,hxo,Z_,spe,uxo,pxo,vV,_xo,vxo,bxo,e2,lpe,Fxo,Txo,bV,Mxo,Exo,Cxo,o2,ipe,wxo,Axo,FV,Lxo,yxo,xxo,r2,dpe,$xo,kxo,TV,Sxo,Rxo,Pxo,t2,cpe,Bxo,Ixo,MV,Nxo,qxo,jxo,a2,fpe,Dxo,Gxo,EV,Oxo,Vxo,Xxo,n2,mpe,zxo,Qxo,CV,Wxo,Uxo,Hxo,s2,gpe,Jxo,Yxo,wV,Kxo,Zxo,e$o,l2,hpe,o$o,r$o,AV,t$o,a$o,n$o,i2,upe,s$o,l$o,LV,i$o,d$o,c$o,d2,ppe,f$o,m$o,yV,g$o,h$o,u$o,c2,_pe,p$o,_$o,xV,v$o,b$o,F$o,f2,vpe,T$o,M$o,$V,E$o,C$o,w$o,m2,bpe,A$o,L$o,kV,y$o,x$o,$$o,g2,Fpe,k$o,S$o,SV,R$o,P$o,B$o,h2,Tpe,I$o,N$o,RV,q$o,j$o,D$o,u2,Mpe,G$o,O$o,PV,V$o,X$o,z$o,p2,Epe,Q$o,W$o,BV,U$o,H$o,J$o,_2,Cpe,Y$o,K$o,IV,Z$o,eko,oko,v2,wpe,rko,tko,NV,ako,nko,sko,b2,Ape,lko,iko,qV,dko,cko,fko,F2,Lpe,mko,gko,jV,hko,uko,pko,T2,ype,_ko,vko,DV,bko,Fko,Tko,M2,xpe,Mko,Eko,GV,Cko,wko,Ako,E2,$pe,Lko,yko,OV,xko,$ko,kko,C2,kpe,Sko,Rko,VV,Pko,Bko,Iko,w2,Spe,Nko,qko,XV,jko,Dko,Gko,A2,Rpe,Oko,Vko,zV,Xko,zko,Qko,L2,Ppe,Wko,Uko,QV,Hko,Jko,Yko,y2,Bpe,Kko,Zko,WV,eSo,oSo,rSo,x2,Ipe,tSo,aSo,UV,nSo,sSo,lSo,$2,Npe,iSo,dSo,HV,cSo,fSo,mSo,k2,qpe,gSo,hSo,JV,uSo,pSo,_So,S2,jpe,vSo,bSo,YV,FSo,TSo,MSo,R2,Dpe,ESo,CSo,KV,wSo,ASo,LSo,P2,Gpe,ySo,xSo,ZV,$So,kSo,SSo,B2,Ope,RSo,PSo,eX,BSo,ISo,NSo,I2,Vpe,qSo,jSo,oX,DSo,GSo,OSo,N2,Xpe,VSo,XSo,rX,zSo,QSo,WSo,q2,zpe,USo,HSo,tX,JSo,YSo,KSo,j2,Qpe,ZSo,eRo,aX,oRo,rRo,tRo,D2,Wpe,aRo,nRo,nX,sRo,lRo,iRo,G2,Upe,dRo,cRo,sX,fRo,mRo,gRo,O2,Hpe,hRo,uRo,lX,pRo,_Ro,vRo,V2,Jpe,bRo,FRo,iX,TRo,MRo,ERo,X2,Ype,CRo,wRo,dX,ARo,LRo,yRo,z2,Kpe,xRo,$Ro,cX,kRo,SRo,RRo,Q2,Zpe,PRo,BRo,fX,IRo,NRo,qRo,W2,e_e,jRo,DRo,mX,GRo,ORo,VRo,U2,o_e,XRo,zRo,gX,QRo,WRo,URo,H2,r_e,HRo,JRo,hX,YRo,KRo,ZRo,J2,t_e,ePo,oPo,uX,rPo,tPo,aPo,Y2,a_e,nPo,sPo,pX,lPo,iPo,dPo,K2,n_e,cPo,fPo,_X,mPo,gPo,hPo,Z2,s_e,uPo,pPo,vX,_Po,vPo,bPo,ev,l_e,FPo,TPo,bX,MPo,EPo,CPo,ov,i_e,wPo,APo,FX,LPo,yPo,xPo,rv,$Po,d_e,kPo,SPo,c_e,RPo,PPo,tv,QYe,bd,av,f_e,ex,BPo,m_e,IPo,WYe,Bo,ox,NPo,Fd,qPo,TX,jPo,DPo,MX,GPo,OPo,VPo,rx,XPo,g_e,zPo,QPo,WPo,vt,tx,UPo,h_e,HPo,JPo,Td,YPo,u_e,KPo,ZPo,EX,eBo,oBo,rBo,nv,tBo,eo,ax,aBo,p_e,nBo,sBo,Ya,lBo,__e,iBo,dBo,v_e,cBo,fBo,b_e,mBo,gBo,hBo,G,sv,F_e,uBo,pBo,CX,_Bo,vBo,bBo,lv,T_e,FBo,TBo,wX,MBo,EBo,CBo,iv,M_e,wBo,ABo,AX,LBo,yBo,xBo,dv,E_e,$Bo,kBo,LX,SBo,RBo,PBo,cv,C_e,BBo,IBo,yX,NBo,qBo,jBo,fv,w_e,DBo,GBo,xX,OBo,VBo,XBo,mv,A_e,zBo,QBo,$X,WBo,UBo,HBo,gv,L_e,JBo,YBo,kX,KBo,ZBo,eIo,hv,y_e,oIo,rIo,SX,tIo,aIo,nIo,uv,x_e,sIo,lIo,RX,iIo,dIo,cIo,pv,$_e,fIo,mIo,PX,gIo,hIo,uIo,_v,k_e,pIo,_Io,BX,vIo,bIo,FIo,vv,S_e,TIo,MIo,IX,EIo,CIo,wIo,bv,R_e,AIo,LIo,NX,yIo,xIo,$Io,Fv,P_e,kIo,SIo,qX,RIo,PIo,BIo,Tv,B_e,IIo,NIo,jX,qIo,jIo,DIo,Mv,I_e,GIo,OIo,DX,VIo,XIo,zIo,Ev,N_e,QIo,WIo,GX,UIo,HIo,JIo,Cv,q_e,YIo,KIo,OX,ZIo,eNo,oNo,wv,j_e,rNo,tNo,VX,aNo,nNo,sNo,Av,D_e,lNo,iNo,XX,dNo,cNo,fNo,Lv,G_e,mNo,gNo,zX,hNo,uNo,pNo,yv,O_e,_No,vNo,QX,bNo,FNo,TNo,xv,V_e,MNo,ENo,WX,CNo,wNo,ANo,$v,X_e,LNo,yNo,UX,xNo,$No,kNo,kv,z_e,SNo,RNo,HX,PNo,BNo,INo,Sv,Q_e,NNo,qNo,JX,jNo,DNo,GNo,Rv,W_e,ONo,VNo,YX,XNo,zNo,QNo,Pv,U_e,WNo,UNo,KX,HNo,JNo,YNo,Bv,H_e,KNo,ZNo,ZX,eqo,oqo,rqo,Iv,J_e,tqo,aqo,ez,nqo,sqo,lqo,Nv,Y_e,iqo,dqo,oz,cqo,fqo,mqo,qv,K_e,gqo,hqo,rz,uqo,pqo,_qo,jv,Z_e,vqo,bqo,tz,Fqo,Tqo,Mqo,Dv,e2e,Eqo,Cqo,az,wqo,Aqo,Lqo,Gv,o2e,yqo,xqo,nz,$qo,kqo,Sqo,Ov,r2e,Rqo,Pqo,sz,Bqo,Iqo,Nqo,Vv,t2e,qqo,jqo,lz,Dqo,Gqo,Oqo,Xv,a2e,Vqo,Xqo,iz,zqo,Qqo,Wqo,zv,n2e,Uqo,Hqo,dz,Jqo,Yqo,Kqo,Qv,s2e,Zqo,ejo,cz,ojo,rjo,tjo,Wv,l2e,ajo,njo,fz,sjo,ljo,ijo,Uv,i2e,djo,cjo,mz,fjo,mjo,gjo,Hv,d2e,hjo,ujo,gz,pjo,_jo,vjo,Jv,c2e,bjo,Fjo,hz,Tjo,Mjo,Ejo,Yv,f2e,Cjo,wjo,uz,Ajo,Ljo,yjo,Kv,m2e,xjo,$jo,pz,kjo,Sjo,Rjo,Zv,g2e,Pjo,Bjo,_z,Ijo,Njo,qjo,e1,jjo,h2e,Djo,Gjo,u2e,Ojo,Vjo,o1,UYe,Md,r1,p2e,nx,Xjo,_2e,zjo,HYe,Io,sx,Qjo,Ed,Wjo,vz,Ujo,Hjo,bz,Jjo,Yjo,Kjo,lx,Zjo,v2e,eDo,oDo,rDo,bt,ix,tDo,b2e,aDo,nDo,Cd,sDo,F2e,lDo,iDo,Fz,dDo,cDo,fDo,t1,mDo,oo,dx,gDo,T2e,hDo,uDo,Ka,pDo,M2e,_Do,vDo,E2e,bDo,FDo,C2e,TDo,MDo,EDo,z,a1,w2e,CDo,wDo,Tz,ADo,LDo,yDo,n1,A2e,xDo,$Do,Mz,kDo,SDo,RDo,s1,L2e,PDo,BDo,Ez,IDo,NDo,qDo,l1,y2e,jDo,DDo,Cz,GDo,ODo,VDo,i1,x2e,XDo,zDo,wz,QDo,WDo,UDo,d1,$2e,HDo,JDo,Az,YDo,KDo,ZDo,c1,k2e,eGo,oGo,Lz,rGo,tGo,aGo,f1,S2e,nGo,sGo,yz,lGo,iGo,dGo,m1,R2e,cGo,fGo,xz,mGo,gGo,hGo,g1,P2e,uGo,pGo,$z,_Go,vGo,bGo,h1,B2e,FGo,TGo,kz,MGo,EGo,CGo,u1,I2e,wGo,AGo,Sz,LGo,yGo,xGo,p1,N2e,$Go,kGo,Rz,SGo,RGo,PGo,_1,q2e,BGo,IGo,Pz,NGo,qGo,jGo,v1,j2e,DGo,GGo,Bz,OGo,VGo,XGo,b1,D2e,zGo,QGo,Iz,WGo,UGo,HGo,F1,G2e,JGo,YGo,Nz,KGo,ZGo,eOo,T1,O2e,oOo,rOo,qz,tOo,aOo,nOo,M1,V2e,sOo,lOo,jz,iOo,dOo,cOo,E1,X2e,fOo,mOo,Dz,gOo,hOo,uOo,C1,z2e,pOo,_Oo,Gz,vOo,bOo,FOo,w1,Q2e,TOo,MOo,Oz,EOo,COo,wOo,A1,W2e,AOo,LOo,Vz,yOo,xOo,$Oo,L1,U2e,kOo,SOo,Xz,ROo,POo,BOo,y1,H2e,IOo,NOo,zz,qOo,jOo,DOo,x1,J2e,GOo,OOo,Qz,VOo,XOo,zOo,$1,Y2e,QOo,WOo,Wz,UOo,HOo,JOo,k1,K2e,YOo,KOo,Uz,ZOo,eVo,oVo,S1,Z2e,rVo,tVo,Hz,aVo,nVo,sVo,R1,eve,lVo,iVo,Jz,dVo,cVo,fVo,P1,ove,mVo,gVo,Yz,hVo,uVo,pVo,B1,rve,_Vo,vVo,Kz,bVo,FVo,TVo,I1,tve,MVo,EVo,Zz,CVo,wVo,AVo,N1,ave,LVo,yVo,eQ,xVo,$Vo,kVo,q1,nve,SVo,RVo,oQ,PVo,BVo,IVo,j1,sve,NVo,qVo,rQ,jVo,DVo,GVo,D1,lve,OVo,VVo,tQ,XVo,zVo,QVo,G1,ive,WVo,UVo,aQ,HVo,JVo,YVo,O1,dve,KVo,ZVo,nQ,eXo,oXo,rXo,V1,cve,tXo,aXo,sQ,nXo,sXo,lXo,X1,fve,iXo,dXo,lQ,cXo,fXo,mXo,z1,gXo,mve,hXo,uXo,gve,pXo,_Xo,Q1,JYe,wd,W1,hve,cx,vXo,uve,bXo,YYe,No,fx,FXo,Ad,TXo,iQ,MXo,EXo,dQ,CXo,wXo,AXo,mx,LXo,pve,yXo,xXo,$Xo,Ft,gx,kXo,_ve,SXo,RXo,Ld,PXo,vve,BXo,IXo,cQ,NXo,qXo,jXo,U1,DXo,ro,hx,GXo,bve,OXo,VXo,Za,XXo,Fve,zXo,QXo,Tve,WXo,UXo,Mve,HXo,JXo,YXo,U,H1,Eve,KXo,ZXo,fQ,ezo,ozo,rzo,J1,Cve,tzo,azo,mQ,nzo,szo,lzo,Y1,wve,izo,dzo,gQ,czo,fzo,mzo,K1,Ave,gzo,hzo,hQ,uzo,pzo,_zo,Z1,Lve,vzo,bzo,uQ,Fzo,Tzo,Mzo,e4,yve,Ezo,Czo,pQ,wzo,Azo,Lzo,o4,xve,yzo,xzo,_Q,$zo,kzo,Szo,r4,$ve,Rzo,Pzo,vQ,Bzo,Izo,Nzo,t4,kve,qzo,jzo,bQ,Dzo,Gzo,Ozo,a4,Sve,Vzo,Xzo,FQ,zzo,Qzo,Wzo,n4,Rve,Uzo,Hzo,TQ,Jzo,Yzo,Kzo,s4,Pve,Zzo,eQo,MQ,oQo,rQo,tQo,l4,Bve,aQo,nQo,EQ,sQo,lQo,iQo,i4,Ive,dQo,cQo,CQ,fQo,mQo,gQo,d4,Nve,hQo,uQo,wQ,pQo,_Qo,vQo,c4,qve,bQo,FQo,AQ,TQo,MQo,EQo,f4,jve,CQo,wQo,LQ,AQo,LQo,yQo,m4,Dve,xQo,$Qo,yQ,kQo,SQo,RQo,g4,Gve,PQo,BQo,xQ,IQo,NQo,qQo,h4,Ove,jQo,DQo,$Q,GQo,OQo,VQo,u4,Vve,XQo,zQo,kQ,QQo,WQo,UQo,p4,Xve,HQo,JQo,SQ,YQo,KQo,ZQo,_4,zve,eWo,oWo,RQ,rWo,tWo,aWo,v4,Qve,nWo,sWo,PQ,lWo,iWo,dWo,b4,Wve,cWo,fWo,BQ,mWo,gWo,hWo,F4,Uve,uWo,pWo,IQ,_Wo,vWo,bWo,T4,Hve,FWo,TWo,NQ,MWo,EWo,CWo,M4,Jve,wWo,AWo,qQ,LWo,yWo,xWo,E4,Yve,$Wo,kWo,jQ,SWo,RWo,PWo,C4,Kve,BWo,IWo,DQ,NWo,qWo,jWo,w4,Zve,DWo,GWo,GQ,OWo,VWo,XWo,A4,e1e,zWo,QWo,OQ,WWo,UWo,HWo,L4,o1e,JWo,YWo,VQ,KWo,ZWo,eUo,y4,r1e,oUo,rUo,XQ,tUo,aUo,nUo,x4,t1e,sUo,lUo,a1e,iUo,dUo,cUo,$4,n1e,fUo,mUo,zQ,gUo,hUo,uUo,k4,s1e,pUo,_Uo,QQ,vUo,bUo,FUo,S4,l1e,TUo,MUo,WQ,EUo,CUo,wUo,R4,i1e,AUo,LUo,UQ,yUo,xUo,$Uo,P4,kUo,d1e,SUo,RUo,c1e,PUo,BUo,B4,KYe,yd,I4,f1e,ux,IUo,m1e,NUo,ZYe,qo,px,qUo,xd,jUo,HQ,DUo,GUo,JQ,OUo,VUo,XUo,_x,zUo,g1e,QUo,WUo,UUo,Tt,vx,HUo,h1e,JUo,YUo,$d,KUo,u1e,ZUo,eHo,YQ,oHo,rHo,tHo,N4,aHo,to,bx,nHo,p1e,sHo,lHo,en,iHo,_1e,dHo,cHo,v1e,fHo,mHo,b1e,gHo,hHo,uHo,fe,q4,F1e,pHo,_Ho,KQ,vHo,bHo,FHo,j4,T1e,THo,MHo,ZQ,EHo,CHo,wHo,D4,M1e,AHo,LHo,eW,yHo,xHo,$Ho,G4,E1e,kHo,SHo,oW,RHo,PHo,BHo,O4,C1e,IHo,NHo,rW,qHo,jHo,DHo,V4,w1e,GHo,OHo,tW,VHo,XHo,zHo,X4,A1e,QHo,WHo,aW,UHo,HHo,JHo,z4,L1e,YHo,KHo,nW,ZHo,eJo,oJo,Q4,y1e,rJo,tJo,sW,aJo,nJo,sJo,W4,x1e,lJo,iJo,lW,dJo,cJo,fJo,U4,$1e,mJo,gJo,iW,hJo,uJo,pJo,H4,k1e,_Jo,vJo,dW,bJo,FJo,TJo,J4,S1e,MJo,EJo,cW,CJo,wJo,AJo,Y4,R1e,LJo,yJo,fW,xJo,$Jo,kJo,K4,P1e,SJo,RJo,mW,PJo,BJo,IJo,Z4,B1e,NJo,qJo,gW,jJo,DJo,GJo,eb,I1e,OJo,VJo,hW,XJo,zJo,QJo,ob,N1e,WJo,UJo,uW,HJo,JJo,YJo,rb,q1e,KJo,ZJo,pW,eYo,oYo,rYo,tb,j1e,tYo,aYo,_W,nYo,sYo,lYo,ab,iYo,D1e,dYo,cYo,G1e,fYo,mYo,nb,eKe,kd,sb,O1e,Fx,gYo,V1e,hYo,oKe,jo,Tx,uYo,Sd,pYo,vW,_Yo,vYo,bW,bYo,FYo,TYo,Mx,MYo,X1e,EYo,CYo,wYo,Mt,Ex,AYo,z1e,LYo,yYo,Rd,xYo,Q1e,$Yo,kYo,FW,SYo,RYo,PYo,lb,BYo,ao,Cx,IYo,W1e,NYo,qYo,on,jYo,U1e,DYo,GYo,H1e,OYo,VYo,J1e,XYo,zYo,QYo,q,ib,Y1e,WYo,UYo,TW,HYo,JYo,YYo,db,K1e,KYo,ZYo,MW,eKo,oKo,rKo,cb,Z1e,tKo,aKo,EW,nKo,sKo,lKo,fb,e4e,iKo,dKo,CW,cKo,fKo,mKo,mb,o4e,gKo,hKo,wW,uKo,pKo,_Ko,gb,r4e,vKo,bKo,AW,FKo,TKo,MKo,hb,t4e,EKo,CKo,LW,wKo,AKo,LKo,ub,a4e,yKo,xKo,yW,$Ko,kKo,SKo,pb,n4e,RKo,PKo,xW,BKo,IKo,NKo,_b,s4e,qKo,jKo,$W,DKo,GKo,OKo,vb,l4e,VKo,XKo,kW,zKo,QKo,WKo,bb,i4e,UKo,HKo,SW,JKo,YKo,KKo,Fb,d4e,ZKo,eZo,RW,oZo,rZo,tZo,Tb,c4e,aZo,nZo,PW,sZo,lZo,iZo,Mb,f4e,dZo,cZo,BW,fZo,mZo,gZo,Eb,m4e,hZo,uZo,IW,pZo,_Zo,vZo,Cb,g4e,bZo,FZo,NW,TZo,MZo,EZo,wb,h4e,CZo,wZo,qW,AZo,LZo,yZo,Ab,u4e,xZo,$Zo,jW,kZo,SZo,RZo,Lb,p4e,PZo,BZo,DW,IZo,NZo,qZo,yb,_4e,jZo,DZo,GW,GZo,OZo,VZo,xb,v4e,XZo,zZo,OW,QZo,WZo,UZo,$b,b4e,HZo,JZo,VW,YZo,KZo,ZZo,kb,F4e,eer,oer,XW,rer,ter,aer,Sb,T4e,ner,ser,zW,ler,ier,der,Rb,M4e,cer,fer,QW,mer,ger,her,Pb,E4e,uer,per,WW,_er,ver,ber,Bb,C4e,Fer,Ter,UW,Mer,Eer,Cer,Ib,w4e,wer,Aer,HW,Ler,yer,xer,Nb,A4e,$er,ker,JW,Ser,Rer,Per,qb,L4e,Ber,Ier,YW,Ner,qer,jer,jb,y4e,Der,Ger,KW,Oer,Ver,Xer,Db,x4e,zer,Qer,ZW,Wer,Uer,Her,Gb,$4e,Jer,Yer,eU,Ker,Zer,eor,Ob,k4e,oor,ror,oU,tor,aor,nor,Vb,S4e,sor,lor,rU,ior,dor,cor,Xb,R4e,mor,gor,tU,hor,uor,por,zb,P4e,_or,vor,aU,bor,For,Tor,Qb,B4e,Mor,Eor,nU,Cor,wor,Aor,Wb,I4e,Lor,yor,sU,xor,$or,kor,Ub,N4e,Sor,Ror,lU,Por,Bor,Ior,Hb,q4e,Nor,qor,iU,jor,Dor,Gor,Jb,j4e,Oor,Vor,dU,Xor,zor,Qor,Yb,D4e,Wor,Uor,cU,Hor,Jor,Yor,Kb,G4e,Kor,Zor,fU,err,orr,rrr,Zb,O4e,trr,arr,mU,nrr,srr,lrr,eF,V4e,irr,drr,gU,crr,frr,mrr,oF,X4e,grr,hrr,hU,urr,prr,_rr,rF,z4e,vrr,brr,uU,Frr,Trr,Mrr,tF,Q4e,Err,Crr,pU,wrr,Arr,Lrr,aF,W4e,yrr,xrr,_U,$rr,krr,Srr,nF,U4e,Rrr,Prr,vU,Brr,Irr,Nrr,sF,H4e,qrr,jrr,bU,Drr,Grr,Orr,lF,Vrr,J4e,Xrr,zrr,Y4e,Qrr,Wrr,iF,rKe,Pd,dF,K4e,wx,Urr,Z4e,Hrr,tKe,Do,Ax,Jrr,Bd,Yrr,FU,Krr,Zrr,TU,etr,otr,rtr,Lx,ttr,ebe,atr,ntr,str,Et,yx,ltr,obe,itr,dtr,Id,ctr,rbe,ftr,mtr,MU,gtr,htr,utr,cF,ptr,no,xx,_tr,tbe,vtr,btr,rn,Ftr,abe,Ttr,Mtr,nbe,Etr,Ctr,sbe,wtr,Atr,Ltr,Z,fF,lbe,ytr,xtr,EU,$tr,ktr,Str,mF,ibe,Rtr,Ptr,CU,Btr,Itr,Ntr,gF,dbe,qtr,jtr,wU,Dtr,Gtr,Otr,hF,cbe,Vtr,Xtr,AU,ztr,Qtr,Wtr,uF,fbe,Utr,Htr,LU,Jtr,Ytr,Ktr,pF,mbe,Ztr,ear,yU,oar,rar,tar,_F,gbe,aar,nar,xU,sar,lar,iar,vF,hbe,dar,car,$U,far,mar,gar,bF,ube,har,uar,kU,par,_ar,bar,FF,pbe,Far,Tar,SU,Mar,Ear,Car,TF,_be,war,Aar,RU,Lar,yar,xar,MF,vbe,$ar,kar,PU,Sar,Rar,Par,EF,bbe,Bar,Iar,BU,Nar,qar,jar,CF,Fbe,Dar,Gar,IU,Oar,Var,Xar,wF,Tbe,zar,Qar,NU,War,Uar,Har,AF,Mbe,Jar,Yar,qU,Kar,Zar,enr,LF,Ebe,onr,rnr,jU,tnr,anr,nnr,yF,Cbe,snr,lnr,DU,inr,dnr,cnr,xF,wbe,fnr,mnr,GU,gnr,hnr,unr,$F,Abe,pnr,_nr,OU,vnr,bnr,Fnr,kF,Lbe,Tnr,Mnr,VU,Enr,Cnr,wnr,SF,ybe,Anr,Lnr,XU,ynr,xnr,$nr,RF,xbe,knr,Snr,zU,Rnr,Pnr,Bnr,PF,$be,Inr,Nnr,QU,qnr,jnr,Dnr,BF,kbe,Gnr,Onr,WU,Vnr,Xnr,znr,IF,Sbe,Qnr,Wnr,UU,Unr,Hnr,Jnr,NF,Rbe,Ynr,Knr,HU,Znr,esr,osr,qF,Pbe,rsr,tsr,JU,asr,nsr,ssr,jF,Bbe,lsr,isr,YU,dsr,csr,fsr,DF,Ibe,msr,gsr,KU,hsr,usr,psr,GF,Nbe,_sr,vsr,ZU,bsr,Fsr,Tsr,OF,qbe,Msr,Esr,eH,Csr,wsr,Asr,VF,Lsr,jbe,ysr,xsr,Dbe,$sr,ksr,XF,aKe,Nd,zF,Gbe,$x,Ssr,Obe,Rsr,nKe,Go,kx,Psr,qd,Bsr,oH,Isr,Nsr,rH,qsr,jsr,Dsr,Sx,Gsr,Vbe,Osr,Vsr,Xsr,Ct,Rx,zsr,Xbe,Qsr,Wsr,jd,Usr,zbe,Hsr,Jsr,tH,Ysr,Ksr,Zsr,QF,elr,so,Px,olr,Qbe,rlr,tlr,tn,alr,Wbe,nlr,slr,Ube,llr,ilr,Hbe,dlr,clr,flr,Ue,WF,Jbe,mlr,glr,aH,hlr,ulr,plr,UF,Ybe,_lr,vlr,nH,blr,Flr,Tlr,HF,Kbe,Mlr,Elr,sH,Clr,wlr,Alr,JF,Zbe,Llr,ylr,lH,xlr,$lr,klr,YF,eFe,Slr,Rlr,iH,Plr,Blr,Ilr,KF,oFe,Nlr,qlr,dH,jlr,Dlr,Glr,ZF,rFe,Olr,Vlr,cH,Xlr,zlr,Qlr,eT,Wlr,tFe,Ulr,Hlr,aFe,Jlr,Ylr,oT,sKe,Dd,rT,nFe,Bx,Klr,sFe,Zlr,lKe,Oo,Ix,eir,Gd,oir,fH,rir,tir,mH,air,nir,sir,Nx,lir,lFe,iir,dir,cir,wt,qx,fir,iFe,mir,gir,Od,hir,dFe,uir,pir,gH,_ir,vir,bir,tT,Fir,lo,jx,Tir,cFe,Mir,Eir,an,Cir,fFe,wir,Air,mFe,Lir,yir,gFe,xir,$ir,kir,H,aT,hFe,Sir,Rir,hH,Pir,Bir,Iir,nT,uFe,Nir,qir,uH,jir,Dir,Gir,sT,pFe,Oir,Vir,pH,Xir,zir,Qir,lT,_Fe,Wir,Uir,_H,Hir,Jir,Yir,iT,vFe,Kir,Zir,vH,edr,odr,rdr,dT,bFe,tdr,adr,bH,ndr,sdr,ldr,cT,FFe,idr,ddr,FH,cdr,fdr,mdr,fT,TFe,gdr,hdr,TH,udr,pdr,_dr,mT,MFe,vdr,bdr,MH,Fdr,Tdr,Mdr,gT,EFe,Edr,Cdr,EH,wdr,Adr,Ldr,hT,CFe,ydr,xdr,CH,$dr,kdr,Sdr,uT,wFe,Rdr,Pdr,wH,Bdr,Idr,Ndr,pT,AFe,qdr,jdr,AH,Ddr,Gdr,Odr,_T,LFe,Vdr,Xdr,LH,zdr,Qdr,Wdr,vT,yFe,Udr,Hdr,yH,Jdr,Ydr,Kdr,bT,xFe,Zdr,ecr,xH,ocr,rcr,tcr,FT,$Fe,acr,ncr,$H,scr,lcr,icr,TT,kFe,dcr,ccr,kH,fcr,mcr,gcr,MT,SFe,hcr,ucr,SH,pcr,_cr,vcr,ET,RFe,bcr,Fcr,RH,Tcr,Mcr,Ecr,CT,PFe,Ccr,wcr,PH,Acr,Lcr,ycr,wT,BFe,xcr,$cr,BH,kcr,Scr,Rcr,AT,IFe,Pcr,Bcr,IH,Icr,Ncr,qcr,LT,NFe,jcr,Dcr,NH,Gcr,Ocr,Vcr,yT,qFe,Xcr,zcr,qH,Qcr,Wcr,Ucr,xT,jFe,Hcr,Jcr,jH,Ycr,Kcr,Zcr,$T,DFe,efr,ofr,DH,rfr,tfr,afr,kT,GFe,nfr,sfr,GH,lfr,ifr,dfr,ST,OFe,cfr,ffr,OH,mfr,gfr,hfr,RT,VFe,ufr,pfr,VH,_fr,vfr,bfr,PT,XFe,Ffr,Tfr,XH,Mfr,Efr,Cfr,BT,zFe,wfr,Afr,zH,Lfr,yfr,xfr,IT,QFe,$fr,kfr,QH,Sfr,Rfr,Pfr,NT,WFe,Bfr,Ifr,WH,Nfr,qfr,jfr,qT,UFe,Dfr,Gfr,UH,Ofr,Vfr,Xfr,jT,HFe,zfr,Qfr,HH,Wfr,Ufr,Hfr,DT,JFe,Jfr,Yfr,JH,Kfr,Zfr,emr,GT,YFe,omr,rmr,YH,tmr,amr,nmr,OT,smr,KFe,lmr,imr,ZFe,dmr,cmr,VT,iKe,Vd,XT,eTe,Dx,fmr,oTe,mmr,dKe,Vo,Gx,gmr,Xd,hmr,KH,umr,pmr,ZH,_mr,vmr,bmr,Ox,Fmr,rTe,Tmr,Mmr,Emr,At,Vx,Cmr,tTe,wmr,Amr,zd,Lmr,aTe,ymr,xmr,eJ,$mr,kmr,Smr,zT,Rmr,io,Xx,Pmr,nTe,Bmr,Imr,nn,Nmr,sTe,qmr,jmr,lTe,Dmr,Gmr,iTe,Omr,Vmr,Xmr,V,QT,dTe,zmr,Qmr,oJ,Wmr,Umr,Hmr,WT,cTe,Jmr,Ymr,rJ,Kmr,Zmr,egr,UT,fTe,ogr,rgr,tJ,tgr,agr,ngr,HT,mTe,sgr,lgr,aJ,igr,dgr,cgr,JT,gTe,fgr,mgr,nJ,ggr,hgr,ugr,YT,hTe,pgr,_gr,sJ,vgr,bgr,Fgr,KT,uTe,Tgr,Mgr,lJ,Egr,Cgr,wgr,ZT,pTe,Agr,Lgr,iJ,ygr,xgr,$gr,eM,_Te,kgr,Sgr,dJ,Rgr,Pgr,Bgr,oM,vTe,Igr,Ngr,cJ,qgr,jgr,Dgr,rM,bTe,Ggr,Ogr,fJ,Vgr,Xgr,zgr,tM,FTe,Qgr,Wgr,mJ,Ugr,Hgr,Jgr,aM,TTe,Ygr,Kgr,gJ,Zgr,ehr,ohr,nM,MTe,rhr,thr,hJ,ahr,nhr,shr,sM,ETe,lhr,ihr,uJ,dhr,chr,fhr,lM,CTe,mhr,ghr,pJ,hhr,uhr,phr,iM,wTe,_hr,vhr,_J,bhr,Fhr,Thr,dM,ATe,Mhr,Ehr,vJ,Chr,whr,Ahr,cM,LTe,Lhr,yhr,bJ,xhr,$hr,khr,fM,yTe,Shr,Rhr,FJ,Phr,Bhr,Ihr,mM,xTe,Nhr,qhr,TJ,jhr,Dhr,Ghr,gM,$Te,Ohr,Vhr,MJ,Xhr,zhr,Qhr,hM,kTe,Whr,Uhr,EJ,Hhr,Jhr,Yhr,uM,STe,Khr,Zhr,CJ,eur,our,rur,pM,RTe,tur,aur,wJ,nur,sur,lur,_M,PTe,iur,dur,AJ,cur,fur,mur,vM,BTe,gur,hur,LJ,uur,pur,_ur,bM,ITe,vur,bur,yJ,Fur,Tur,Mur,FM,NTe,Eur,Cur,xJ,wur,Aur,Lur,TM,qTe,yur,xur,$J,$ur,kur,Sur,MM,jTe,Rur,Pur,kJ,Bur,Iur,Nur,EM,DTe,qur,jur,SJ,Dur,Gur,Our,CM,GTe,Vur,Xur,RJ,zur,Qur,Wur,wM,OTe,Uur,Hur,PJ,Jur,Yur,Kur,AM,VTe,Zur,epr,BJ,opr,rpr,tpr,LM,XTe,apr,npr,IJ,spr,lpr,ipr,yM,zTe,dpr,cpr,NJ,fpr,mpr,gpr,xM,QTe,hpr,upr,qJ,ppr,_pr,vpr,$M,WTe,bpr,Fpr,jJ,Tpr,Mpr,Epr,kM,UTe,Cpr,wpr,DJ,Apr,Lpr,ypr,SM,HTe,xpr,$pr,GJ,kpr,Spr,Rpr,RM,JTe,Ppr,Bpr,OJ,Ipr,Npr,qpr,PM,YTe,jpr,Dpr,VJ,Gpr,Opr,Vpr,BM,KTe,Xpr,zpr,XJ,Qpr,Wpr,Upr,IM,Hpr,ZTe,Jpr,Ypr,eMe,Kpr,Zpr,NM,cKe,Qd,qM,oMe,zx,e_r,rMe,o_r,fKe,Xo,Qx,r_r,Wd,t_r,zJ,a_r,n_r,QJ,s_r,l_r,i_r,Wx,d_r,tMe,c_r,f_r,m_r,Lt,Ux,g_r,aMe,h_r,u_r,Ud,p_r,nMe,__r,v_r,WJ,b_r,F_r,T_r,jM,M_r,co,Hx,E_r,sMe,C_r,w_r,sn,A_r,lMe,L_r,y_r,iMe,x_r,$_r,dMe,k_r,S_r,R_r,cMe,DM,fMe,P_r,B_r,UJ,I_r,N_r,q_r,GM,j_r,mMe,D_r,G_r,gMe,O_r,V_r,OM,mKe,Hd,VM,hMe,Jx,X_r,uMe,z_r,gKe,zo,Yx,Q_r,Jd,W_r,HJ,U_r,H_r,JJ,J_r,Y_r,K_r,Kx,Z_r,pMe,e2r,o2r,r2r,yt,Zx,t2r,_Me,a2r,n2r,Yd,s2r,vMe,l2r,i2r,YJ,d2r,c2r,f2r,XM,m2r,fo,e$,g2r,bMe,h2r,u2r,ln,p2r,FMe,_2r,v2r,TMe,b2r,F2r,MMe,T2r,M2r,E2r,Kd,zM,EMe,C2r,w2r,KJ,A2r,L2r,y2r,QM,CMe,x2r,$2r,ZJ,k2r,S2r,R2r,WM,wMe,P2r,B2r,eY,I2r,N2r,q2r,UM,j2r,AMe,D2r,G2r,LMe,O2r,V2r,HM,hKe,Zd,JM,yMe,o$,X2r,xMe,z2r,uKe,Qo,r$,Q2r,ec,W2r,oY,U2r,H2r,rY,J2r,Y2r,K2r,t$,Z2r,$Me,evr,ovr,rvr,xt,a$,tvr,kMe,avr,nvr,oc,svr,SMe,lvr,ivr,tY,dvr,cvr,fvr,YM,mvr,mo,n$,gvr,RMe,hvr,uvr,dn,pvr,PMe,_vr,vvr,BMe,bvr,Fvr,IMe,Tvr,Mvr,Evr,ve,KM,NMe,Cvr,wvr,aY,Avr,Lvr,yvr,ZM,qMe,xvr,$vr,nY,kvr,Svr,Rvr,eE,jMe,Pvr,Bvr,sY,Ivr,Nvr,qvr,oE,DMe,jvr,Dvr,lY,Gvr,Ovr,Vvr,_l,GMe,Xvr,zvr,iY,Qvr,Wvr,dY,Uvr,Hvr,Jvr,rE,OMe,Yvr,Kvr,cY,Zvr,e1r,o1r,vl,VMe,r1r,t1r,fY,a1r,n1r,mY,s1r,l1r,i1r,tE,XMe,d1r,c1r,gY,f1r,m1r,g1r,$t,zMe,h1r,u1r,hY,p1r,_1r,uY,v1r,b1r,pY,F1r,T1r,M1r,aE,QMe,E1r,C1r,_Y,w1r,A1r,L1r,nE,WMe,y1r,x1r,vY,$1r,k1r,S1r,sE,UMe,R1r,P1r,bY,B1r,I1r,N1r,lE,HMe,q1r,j1r,FY,D1r,G1r,O1r,iE,JMe,V1r,X1r,TY,z1r,Q1r,W1r,dE,YMe,U1r,H1r,MY,J1r,Y1r,K1r,cE,KMe,Z1r,e4r,EY,o4r,r4r,t4r,fE,ZMe,a4r,n4r,CY,s4r,l4r,i4r,mE,d4r,eEe,c4r,f4r,oEe,m4r,g4r,gE,pKe,rc,hE,rEe,s$,h4r,tEe,u4r,_Ke,Wo,l$,p4r,tc,_4r,wY,v4r,b4r,AY,F4r,T4r,M4r,i$,E4r,aEe,C4r,w4r,A4r,kt,d$,L4r,nEe,y4r,x4r,ac,$4r,sEe,k4r,S4r,LY,R4r,P4r,B4r,uE,I4r,go,c$,N4r,lEe,q4r,j4r,cn,D4r,iEe,G4r,O4r,dEe,V4r,X4r,cEe,z4r,Q4r,W4r,fEe,pE,mEe,U4r,H4r,yY,J4r,Y4r,K4r,_E,Z4r,gEe,ebr,obr,hEe,rbr,tbr,vE,vKe,nc,bE,uEe,f$,abr,pEe,nbr,bKe,Uo,m$,sbr,sc,lbr,xY,ibr,dbr,$Y,cbr,fbr,mbr,g$,gbr,_Ee,hbr,ubr,pbr,St,h$,_br,vEe,vbr,bbr,lc,Fbr,bEe,Tbr,Mbr,kY,Ebr,Cbr,wbr,FE,Abr,ho,u$,Lbr,FEe,ybr,xbr,fn,$br,TEe,kbr,Sbr,MEe,Rbr,Pbr,EEe,Bbr,Ibr,Nbr,CEe,TE,wEe,qbr,jbr,SY,Dbr,Gbr,Obr,ME,Vbr,AEe,Xbr,zbr,LEe,Qbr,Wbr,EE,FKe,ic,CE,yEe,p$,Ubr,xEe,Hbr,TKe,Ho,_$,Jbr,dc,Ybr,RY,Kbr,Zbr,PY,eFr,oFr,rFr,v$,tFr,$Ee,aFr,nFr,sFr,Rt,b$,lFr,kEe,iFr,dFr,cc,cFr,SEe,fFr,mFr,BY,gFr,hFr,uFr,wE,pFr,uo,F$,_Fr,REe,vFr,bFr,mn,FFr,PEe,TFr,MFr,BEe,EFr,CFr,IEe,wFr,AFr,LFr,NEe,AE,qEe,yFr,xFr,IY,$Fr,kFr,SFr,LE,RFr,jEe,PFr,BFr,DEe,IFr,NFr,yE,MKe,fc,xE,GEe,T$,qFr,OEe,jFr,EKe,Jo,M$,DFr,mc,GFr,NY,OFr,VFr,qY,XFr,zFr,QFr,E$,WFr,VEe,UFr,HFr,JFr,Pt,C$,YFr,XEe,KFr,ZFr,gc,eTr,zEe,oTr,rTr,jY,tTr,aTr,nTr,$E,sTr,po,w$,lTr,QEe,iTr,dTr,gn,cTr,WEe,fTr,mTr,UEe,gTr,hTr,HEe,uTr,pTr,_Tr,Pe,kE,JEe,vTr,bTr,DY,FTr,TTr,MTr,SE,YEe,ETr,CTr,GY,wTr,ATr,LTr,RE,KEe,yTr,xTr,OY,$Tr,kTr,STr,PE,ZEe,RTr,PTr,VY,BTr,ITr,NTr,BE,eCe,qTr,jTr,XY,DTr,GTr,OTr,IE,oCe,VTr,XTr,zY,zTr,QTr,WTr,NE,rCe,UTr,HTr,QY,JTr,YTr,KTr,qE,tCe,ZTr,eMr,WY,oMr,rMr,tMr,jE,aCe,aMr,nMr,UY,sMr,lMr,iMr,DE,dMr,nCe,cMr,fMr,sCe,mMr,gMr,GE,CKe,hc,OE,lCe,A$,hMr,iCe,uMr,wKe,Yo,L$,pMr,uc,_Mr,HY,vMr,bMr,JY,FMr,TMr,MMr,y$,EMr,dCe,CMr,wMr,AMr,Bt,x$,LMr,cCe,yMr,xMr,pc,$Mr,fCe,kMr,SMr,YY,RMr,PMr,BMr,VE,IMr,_o,$$,NMr,mCe,qMr,jMr,hn,DMr,gCe,GMr,OMr,hCe,VMr,XMr,uCe,zMr,QMr,WMr,ft,XE,pCe,UMr,HMr,KY,JMr,YMr,KMr,zE,_Ce,ZMr,eEr,ZY,oEr,rEr,tEr,QE,vCe,aEr,nEr,eK,sEr,lEr,iEr,WE,bCe,dEr,cEr,oK,fEr,mEr,gEr,UE,FCe,hEr,uEr,rK,pEr,_Er,vEr,HE,bEr,TCe,FEr,TEr,MCe,MEr,EEr,JE,AKe,_c,YE,ECe,k$,CEr,CCe,wEr,LKe,Ko,S$,AEr,vc,LEr,tK,yEr,xEr,aK,$Er,kEr,SEr,R$,REr,wCe,PEr,BEr,IEr,It,P$,NEr,ACe,qEr,jEr,bc,DEr,LCe,GEr,OEr,nK,VEr,XEr,zEr,KE,QEr,vo,B$,WEr,yCe,UEr,HEr,un,JEr,xCe,YEr,KEr,$Ce,ZEr,eCr,kCe,oCr,rCr,tCr,Le,ZE,SCe,aCr,nCr,sK,sCr,lCr,iCr,eC,RCe,dCr,cCr,lK,fCr,mCr,gCr,oC,PCe,hCr,uCr,iK,pCr,_Cr,vCr,rC,BCe,bCr,FCr,dK,TCr,MCr,ECr,tC,ICe,CCr,wCr,cK,ACr,LCr,yCr,aC,NCe,xCr,$Cr,fK,kCr,SCr,RCr,nC,qCe,PCr,BCr,mK,ICr,NCr,qCr,sC,jCe,jCr,DCr,gK,GCr,OCr,VCr,lC,DCe,XCr,zCr,hK,QCr,WCr,UCr,iC,GCe,HCr,JCr,uK,YCr,KCr,ZCr,dC,e3r,OCe,o3r,r3r,VCe,t3r,a3r,cC,yKe,Fc,fC,XCe,I$,n3r,zCe,s3r,xKe,Zo,N$,l3r,Tc,i3r,pK,d3r,c3r,_K,f3r,m3r,g3r,q$,h3r,QCe,u3r,p3r,_3r,Nt,j$,v3r,WCe,b3r,F3r,Mc,T3r,UCe,M3r,E3r,vK,C3r,w3r,A3r,mC,L3r,bo,D$,y3r,HCe,x3r,$3r,pn,k3r,JCe,S3r,R3r,YCe,P3r,B3r,KCe,I3r,N3r,q3r,G$,gC,ZCe,j3r,D3r,bK,G3r,O3r,V3r,hC,e3e,X3r,z3r,FK,Q3r,W3r,U3r,uC,H3r,o3e,J3r,Y3r,r3e,K3r,Z3r,pC,$Ke,Ec,_C,t3e,O$,e5r,a3e,o5r,kKe,er,V$,r5r,Cc,t5r,TK,a5r,n5r,MK,s5r,l5r,i5r,X$,d5r,n3e,c5r,f5r,m5r,qt,z$,g5r,s3e,h5r,u5r,wc,p5r,l3e,_5r,v5r,EK,b5r,F5r,T5r,vC,M5r,Fo,Q$,E5r,i3e,C5r,w5r,_n,A5r,d3e,L5r,y5r,c3e,x5r,$5r,f3e,k5r,S5r,R5r,mt,bC,m3e,P5r,B5r,CK,I5r,N5r,q5r,FC,g3e,j5r,D5r,wK,G5r,O5r,V5r,TC,h3e,X5r,z5r,AK,Q5r,W5r,U5r,MC,u3e,H5r,J5r,LK,Y5r,K5r,Z5r,EC,p3e,e0r,o0r,yK,r0r,t0r,a0r,CC,n0r,_3e,s0r,l0r,v3e,i0r,d0r,wC,SKe,Ac,AC,b3e,W$,c0r,F3e,f0r,RKe,or,U$,m0r,Lc,g0r,xK,h0r,u0r,$K,p0r,_0r,v0r,H$,b0r,T3e,F0r,T0r,M0r,jt,J$,E0r,M3e,C0r,w0r,yc,A0r,E3e,L0r,y0r,kK,x0r,$0r,k0r,LC,S0r,To,Y$,R0r,C3e,P0r,B0r,vn,I0r,w3e,N0r,q0r,A3e,j0r,D0r,L3e,G0r,O0r,V0r,bn,yC,y3e,X0r,z0r,SK,Q0r,W0r,U0r,xC,x3e,H0r,J0r,RK,Y0r,K0r,Z0r,$C,$3e,ewr,owr,PK,rwr,twr,awr,kC,k3e,nwr,swr,BK,lwr,iwr,dwr,SC,cwr,S3e,fwr,mwr,R3e,gwr,hwr,RC,PKe,xc,PC,P3e,K$,uwr,B3e,pwr,BKe,rr,Z$,_wr,$c,vwr,IK,bwr,Fwr,NK,Twr,Mwr,Ewr,ek,Cwr,I3e,wwr,Awr,Lwr,Dt,ok,ywr,N3e,xwr,$wr,kc,kwr,q3e,Swr,Rwr,qK,Pwr,Bwr,Iwr,BC,Nwr,Mo,rk,qwr,j3e,jwr,Dwr,Fn,Gwr,D3e,Owr,Vwr,G3e,Xwr,zwr,O3e,Qwr,Wwr,Uwr,tk,IC,V3e,Hwr,Jwr,jK,Ywr,Kwr,Zwr,NC,X3e,eAr,oAr,DK,rAr,tAr,aAr,qC,nAr,z3e,sAr,lAr,Q3e,iAr,dAr,jC,IKe,Sc,DC,W3e,ak,cAr,U3e,fAr,NKe,tr,nk,mAr,Rc,gAr,GK,hAr,uAr,OK,pAr,_Ar,vAr,sk,bAr,H3e,FAr,TAr,MAr,Gt,lk,EAr,J3e,CAr,wAr,Pc,AAr,Y3e,LAr,yAr,VK,xAr,$Ar,kAr,GC,SAr,Eo,ik,RAr,K3e,PAr,BAr,Tn,IAr,Z3e,NAr,qAr,e5e,jAr,DAr,o5e,GAr,OAr,VAr,r5e,OC,t5e,XAr,zAr,XK,QAr,WAr,UAr,VC,HAr,a5e,JAr,YAr,n5e,KAr,ZAr,XC,qKe,Bc,zC,s5e,dk,e6r,l5e,o6r,jKe,ar,ck,r6r,Ic,t6r,zK,a6r,n6r,QK,s6r,l6r,i6r,fk,d6r,i5e,c6r,f6r,m6r,Ot,mk,g6r,d5e,h6r,u6r,Nc,p6r,c5e,_6r,v6r,WK,b6r,F6r,T6r,QC,M6r,Co,gk,E6r,f5e,C6r,w6r,Mn,A6r,m5e,L6r,y6r,g5e,x6r,$6r,h5e,k6r,S6r,R6r,gt,WC,u5e,P6r,B6r,UK,I6r,N6r,q6r,UC,p5e,j6r,D6r,HK,G6r,O6r,V6r,HC,_5e,X6r,z6r,JK,Q6r,W6r,U6r,JC,v5e,H6r,J6r,YK,Y6r,K6r,Z6r,YC,b5e,e7r,o7r,KK,r7r,t7r,a7r,KC,n7r,F5e,s7r,l7r,T5e,i7r,d7r,ZC,DKe,qc,e3,M5e,hk,c7r,E5e,f7r,GKe,nr,uk,m7r,jc,g7r,ZK,h7r,u7r,eZ,p7r,_7r,v7r,pk,b7r,C5e,F7r,T7r,M7r,Vt,_k,E7r,w5e,C7r,w7r,Dc,A7r,A5e,L7r,y7r,oZ,x7r,$7r,k7r,o3,S7r,wo,vk,R7r,L5e,P7r,B7r,En,I7r,y5e,N7r,q7r,x5e,j7r,D7r,$5e,G7r,O7r,V7r,k5e,r3,S5e,X7r,z7r,rZ,Q7r,W7r,U7r,t3,H7r,R5e,J7r,Y7r,P5e,K7r,Z7r,a3,OKe,Gc,n3,B5e,bk,eLr,I5e,oLr,VKe,sr,Fk,rLr,Oc,tLr,tZ,aLr,nLr,aZ,sLr,lLr,iLr,Tk,dLr,N5e,cLr,fLr,mLr,Xt,Mk,gLr,q5e,hLr,uLr,Vc,pLr,j5e,_Lr,vLr,nZ,bLr,FLr,TLr,s3,MLr,Ir,Ek,ELr,D5e,CLr,wLr,Cn,ALr,G5e,LLr,yLr,O5e,xLr,$Lr,V5e,kLr,SLr,RLr,N,l3,X5e,PLr,BLr,sZ,ILr,NLr,qLr,i3,z5e,jLr,DLr,lZ,GLr,OLr,VLr,d3,Q5e,XLr,zLr,iZ,QLr,WLr,ULr,c3,W5e,HLr,JLr,dZ,YLr,KLr,ZLr,f3,U5e,eyr,oyr,cZ,ryr,tyr,ayr,m3,H5e,nyr,syr,fZ,lyr,iyr,dyr,g3,J5e,cyr,fyr,mZ,myr,gyr,hyr,h3,Y5e,uyr,pyr,gZ,_yr,vyr,byr,u3,K5e,Fyr,Tyr,hZ,Myr,Eyr,Cyr,p3,Z5e,wyr,Ayr,uZ,Lyr,yyr,xyr,_3,e0e,$yr,kyr,pZ,Syr,Ryr,Pyr,v3,o0e,Byr,Iyr,_Z,Nyr,qyr,jyr,b3,r0e,Dyr,Gyr,vZ,Oyr,Vyr,Xyr,F3,t0e,zyr,Qyr,bZ,Wyr,Uyr,Hyr,T3,a0e,Jyr,Yyr,FZ,Kyr,Zyr,e8r,M3,n0e,o8r,r8r,TZ,t8r,a8r,n8r,E3,s0e,s8r,l8r,MZ,i8r,d8r,c8r,C3,l0e,f8r,m8r,EZ,g8r,h8r,u8r,bl,i0e,p8r,_8r,CZ,v8r,b8r,wZ,F8r,T8r,M8r,w3,d0e,E8r,C8r,AZ,w8r,A8r,L8r,A3,c0e,y8r,x8r,LZ,$8r,k8r,S8r,L3,f0e,R8r,P8r,yZ,B8r,I8r,N8r,y3,m0e,q8r,j8r,xZ,D8r,G8r,O8r,x3,g0e,V8r,X8r,$Z,z8r,Q8r,W8r,$3,h0e,U8r,H8r,kZ,J8r,Y8r,K8r,k3,u0e,Z8r,e9r,SZ,o9r,r9r,t9r,S3,p0e,a9r,n9r,RZ,s9r,l9r,i9r,R3,_0e,d9r,c9r,PZ,f9r,m9r,g9r,P3,v0e,h9r,u9r,BZ,p9r,_9r,v9r,B3,b0e,b9r,F9r,IZ,T9r,M9r,E9r,I3,F0e,C9r,w9r,NZ,A9r,L9r,y9r,N3,T0e,x9r,$9r,qZ,k9r,S9r,R9r,q3,M0e,P9r,B9r,jZ,I9r,N9r,q9r,j3,E0e,j9r,D9r,DZ,G9r,O9r,V9r,D3,C0e,X9r,z9r,GZ,Q9r,W9r,U9r,G3,w0e,H9r,J9r,OZ,Y9r,K9r,Z9r,O3,A0e,exr,oxr,VZ,rxr,txr,axr,V3,L0e,nxr,sxr,XZ,lxr,ixr,dxr,X3,y0e,cxr,fxr,zZ,mxr,gxr,hxr,z3,x0e,uxr,pxr,QZ,_xr,vxr,bxr,Q3,$0e,Fxr,Txr,WZ,Mxr,Exr,Cxr,W3,k0e,wxr,Axr,UZ,Lxr,yxr,xxr,U3,S0e,$xr,kxr,HZ,Sxr,Rxr,Pxr,H3,R0e,Bxr,Ixr,JZ,Nxr,qxr,jxr,J3,P0e,Dxr,Gxr,YZ,Oxr,Vxr,Xxr,Y3,B0e,zxr,Qxr,KZ,Wxr,Uxr,Hxr,K3,I0e,Jxr,Yxr,ZZ,Kxr,Zxr,e$r,Z3,N0e,o$r,r$r,eee,t$r,a$r,n$r,e5,q0e,s$r,l$r,oee,i$r,d$r,c$r,o5,j0e,f$r,m$r,ree,g$r,h$r,u$r,r5,D0e,p$r,_$r,tee,v$r,b$r,F$r,t5,G0e,T$r,M$r,aee,E$r,C$r,w$r,a5,O0e,A$r,L$r,nee,y$r,x$r,$$r,n5,V0e,k$r,S$r,see,R$r,P$r,B$r,s5,XKe,Xc,l5,X0e,Ck,I$r,z0e,N$r,zKe,lr,wk,q$r,zc,j$r,lee,D$r,G$r,iee,O$r,V$r,X$r,Ak,z$r,Q0e,Q$r,W$r,U$r,zt,Lk,H$r,W0e,J$r,Y$r,Qc,K$r,U0e,Z$r,ekr,dee,okr,rkr,tkr,i5,akr,Nr,yk,nkr,H0e,skr,lkr,wn,ikr,J0e,dkr,ckr,Y0e,fkr,mkr,K0e,gkr,hkr,ukr,se,d5,Z0e,pkr,_kr,cee,vkr,bkr,Fkr,c5,ewe,Tkr,Mkr,fee,Ekr,Ckr,wkr,f5,owe,Akr,Lkr,mee,ykr,xkr,$kr,m5,rwe,kkr,Skr,gee,Rkr,Pkr,Bkr,g5,twe,Ikr,Nkr,hee,qkr,jkr,Dkr,h5,awe,Gkr,Okr,uee,Vkr,Xkr,zkr,u5,nwe,Qkr,Wkr,pee,Ukr,Hkr,Jkr,p5,swe,Ykr,Kkr,_ee,Zkr,eSr,oSr,_5,lwe,rSr,tSr,vee,aSr,nSr,sSr,v5,iwe,lSr,iSr,bee,dSr,cSr,fSr,b5,dwe,mSr,gSr,Fee,hSr,uSr,pSr,F5,cwe,_Sr,vSr,Tee,bSr,FSr,TSr,T5,fwe,MSr,ESr,Mee,CSr,wSr,ASr,M5,mwe,LSr,ySr,Eee,xSr,$Sr,kSr,E5,gwe,SSr,RSr,Cee,PSr,BSr,ISr,C5,hwe,NSr,qSr,wee,jSr,DSr,GSr,w5,uwe,OSr,VSr,Aee,XSr,zSr,QSr,A5,pwe,WSr,USr,Lee,HSr,JSr,YSr,L5,_we,KSr,ZSr,yee,eRr,oRr,rRr,y5,vwe,tRr,aRr,xee,nRr,sRr,lRr,x5,bwe,iRr,dRr,$ee,cRr,fRr,mRr,$5,Fwe,gRr,hRr,kee,uRr,pRr,_Rr,k5,Twe,vRr,bRr,See,FRr,TRr,MRr,S5,QKe,Wc,R5,Mwe,xk,ERr,Ewe,CRr,WKe,ir,$k,wRr,Uc,ARr,Ree,LRr,yRr,Pee,xRr,$Rr,kRr,kk,SRr,Cwe,RRr,PRr,BRr,Qt,Sk,IRr,wwe,NRr,qRr,Hc,jRr,Awe,DRr,GRr,Bee,ORr,VRr,XRr,P5,zRr,qr,Rk,QRr,Lwe,WRr,URr,An,HRr,ywe,JRr,YRr,xwe,KRr,ZRr,$we,ePr,oPr,rPr,Me,B5,kwe,tPr,aPr,Iee,nPr,sPr,lPr,I5,Swe,iPr,dPr,Nee,cPr,fPr,mPr,N5,Rwe,gPr,hPr,qee,uPr,pPr,_Pr,q5,Pwe,vPr,bPr,jee,FPr,TPr,MPr,j5,Bwe,EPr,CPr,Dee,wPr,APr,LPr,D5,Iwe,yPr,xPr,Gee,$Pr,kPr,SPr,G5,Nwe,RPr,PPr,Oee,BPr,IPr,NPr,O5,qwe,qPr,jPr,Vee,DPr,GPr,OPr,V5,jwe,VPr,XPr,Xee,zPr,QPr,WPr,X5,Dwe,UPr,HPr,zee,JPr,YPr,KPr,z5,Gwe,ZPr,eBr,Qee,oBr,rBr,tBr,Q5,Owe,aBr,nBr,Wee,sBr,lBr,iBr,W5,Vwe,dBr,cBr,Uee,fBr,mBr,gBr,U5,Xwe,hBr,uBr,Hee,pBr,_Br,vBr,H5,UKe,Jc,J5,zwe,Pk,bBr,Qwe,FBr,HKe,dr,Bk,TBr,Yc,MBr,Jee,EBr,CBr,Yee,wBr,ABr,LBr,Ik,yBr,Wwe,xBr,$Br,kBr,Wt,Nk,SBr,Uwe,RBr,PBr,Kc,BBr,Hwe,IBr,NBr,Kee,qBr,jBr,DBr,Y5,GBr,jr,qk,OBr,Jwe,VBr,XBr,Ln,zBr,Ywe,QBr,WBr,Kwe,UBr,HBr,Zwe,JBr,YBr,KBr,Be,K5,eAe,ZBr,eIr,Zee,oIr,rIr,tIr,Z5,oAe,aIr,nIr,eoe,sIr,lIr,iIr,Fl,rAe,dIr,cIr,ooe,fIr,mIr,roe,gIr,hIr,uIr,e0,tAe,pIr,_Ir,toe,vIr,bIr,FIr,o0,aAe,TIr,MIr,aoe,EIr,CIr,wIr,r0,nAe,AIr,LIr,noe,yIr,xIr,$Ir,t0,sAe,kIr,SIr,soe,RIr,PIr,BIr,a0,lAe,IIr,NIr,loe,qIr,jIr,DIr,n0,iAe,GIr,OIr,ioe,VIr,XIr,zIr,s0,JKe,Zc,l0,dAe,jk,QIr,cAe,WIr,YKe,cr,Dk,UIr,ef,HIr,doe,JIr,YIr,coe,KIr,ZIr,eNr,Gk,oNr,fAe,rNr,tNr,aNr,Ut,Ok,nNr,mAe,sNr,lNr,of,iNr,gAe,dNr,cNr,foe,fNr,mNr,gNr,i0,hNr,Dr,Vk,uNr,hAe,pNr,_Nr,yn,vNr,uAe,bNr,FNr,pAe,TNr,MNr,_Ae,ENr,CNr,wNr,rf,d0,vAe,ANr,LNr,moe,yNr,xNr,$Nr,c0,bAe,kNr,SNr,goe,RNr,PNr,BNr,f0,FAe,INr,NNr,hoe,qNr,jNr,DNr,m0,KKe,tf,g0,TAe,Xk,GNr,MAe,ONr,ZKe,fr,zk,VNr,af,XNr,uoe,zNr,QNr,poe,WNr,UNr,HNr,Qk,JNr,EAe,YNr,KNr,ZNr,Ht,Wk,eqr,CAe,oqr,rqr,nf,tqr,wAe,aqr,nqr,_oe,sqr,lqr,iqr,h0,dqr,Gr,Uk,cqr,AAe,fqr,mqr,xn,gqr,LAe,hqr,uqr,yAe,pqr,_qr,xAe,vqr,bqr,Fqr,me,u0,$Ae,Tqr,Mqr,voe,Eqr,Cqr,wqr,p0,kAe,Aqr,Lqr,boe,yqr,xqr,$qr,_0,SAe,kqr,Sqr,Foe,Rqr,Pqr,Bqr,v0,RAe,Iqr,Nqr,Toe,qqr,jqr,Dqr,b0,PAe,Gqr,Oqr,Moe,Vqr,Xqr,zqr,F0,BAe,Qqr,Wqr,Eoe,Uqr,Hqr,Jqr,T0,IAe,Yqr,Kqr,Coe,Zqr,ejr,ojr,M0,NAe,rjr,tjr,woe,ajr,njr,sjr,E0,qAe,ljr,ijr,Aoe,djr,cjr,fjr,C0,jAe,mjr,gjr,Loe,hjr,ujr,pjr,w0,DAe,_jr,vjr,yoe,bjr,Fjr,Tjr,A0,GAe,Mjr,Ejr,xoe,Cjr,wjr,Ajr,L0,OAe,Ljr,yjr,$oe,xjr,$jr,kjr,y0,VAe,Sjr,Rjr,koe,Pjr,Bjr,Ijr,x0,XAe,Njr,qjr,Soe,jjr,Djr,Gjr,$0,zAe,Ojr,Vjr,Roe,Xjr,zjr,Qjr,k0,QAe,Wjr,Ujr,Poe,Hjr,Jjr,Yjr,S0,WAe,Kjr,Zjr,Boe,eDr,oDr,rDr,R0,UAe,tDr,aDr,Ioe,nDr,sDr,lDr,P0,HAe,iDr,dDr,Noe,cDr,fDr,mDr,B0,eZe,sf,I0,JAe,Hk,gDr,YAe,hDr,oZe,mr,Jk,uDr,lf,pDr,qoe,_Dr,vDr,joe,bDr,FDr,TDr,Yk,MDr,KAe,EDr,CDr,wDr,Jt,Kk,ADr,ZAe,LDr,yDr,df,xDr,e6e,$Dr,kDr,Doe,SDr,RDr,PDr,N0,BDr,Or,Zk,IDr,o6e,NDr,qDr,$n,jDr,r6e,DDr,GDr,t6e,ODr,VDr,a6e,XDr,zDr,QDr,ye,q0,n6e,WDr,UDr,Goe,HDr,JDr,YDr,j0,s6e,KDr,ZDr,Ooe,eGr,oGr,rGr,D0,l6e,tGr,aGr,Voe,nGr,sGr,lGr,G0,i6e,iGr,dGr,Xoe,cGr,fGr,mGr,O0,d6e,gGr,hGr,zoe,uGr,pGr,_Gr,V0,c6e,vGr,bGr,Qoe,FGr,TGr,MGr,X0,f6e,EGr,CGr,Woe,wGr,AGr,LGr,z0,m6e,yGr,xGr,Uoe,$Gr,kGr,SGr,Q0,g6e,RGr,PGr,Hoe,BGr,IGr,NGr,W0,h6e,qGr,jGr,Joe,DGr,GGr,OGr,U0,rZe,cf,H0,u6e,eS,VGr,p6e,XGr,tZe,gr,oS,zGr,ff,QGr,Yoe,WGr,UGr,Koe,HGr,JGr,YGr,rS,KGr,_6e,ZGr,eOr,oOr,Yt,tS,rOr,v6e,tOr,aOr,mf,nOr,b6e,sOr,lOr,Zoe,iOr,dOr,cOr,J0,fOr,Vr,aS,mOr,F6e,gOr,hOr,kn,uOr,T6e,pOr,_Or,M6e,vOr,bOr,E6e,FOr,TOr,MOr,re,Y0,C6e,EOr,COr,ere,wOr,AOr,LOr,K0,w6e,yOr,xOr,ore,$Or,kOr,SOr,Z0,A6e,ROr,POr,rre,BOr,IOr,NOr,ew,L6e,qOr,jOr,tre,DOr,GOr,OOr,ow,y6e,VOr,XOr,are,zOr,QOr,WOr,rw,x6e,UOr,HOr,nre,JOr,YOr,KOr,tw,$6e,ZOr,eVr,sre,oVr,rVr,tVr,aw,k6e,aVr,nVr,lre,sVr,lVr,iVr,nw,S6e,dVr,cVr,ire,fVr,mVr,gVr,sw,R6e,hVr,uVr,dre,pVr,_Vr,vVr,lw,P6e,bVr,FVr,cre,TVr,MVr,EVr,iw,B6e,CVr,wVr,fre,AVr,LVr,yVr,dw,I6e,xVr,$Vr,mre,kVr,SVr,RVr,cw,N6e,PVr,BVr,gre,IVr,NVr,qVr,fw,q6e,jVr,DVr,hre,GVr,OVr,VVr,mw,j6e,XVr,zVr,ure,QVr,WVr,UVr,gw,D6e,HVr,JVr,pre,YVr,KVr,ZVr,hw,G6e,eXr,oXr,_re,rXr,tXr,aXr,uw,O6e,nXr,sXr,vre,lXr,iXr,dXr,pw,V6e,cXr,fXr,bre,mXr,gXr,hXr,_w,X6e,uXr,pXr,Fre,_Xr,vXr,bXr,vw,z6e,FXr,TXr,Tre,MXr,EXr,CXr,bw,Q6e,wXr,AXr,Mre,LXr,yXr,xXr,Fw,W6e,$Xr,kXr,Ere,SXr,RXr,PXr,Tw,U6e,BXr,IXr,Cre,NXr,qXr,jXr,Mw,H6e,DXr,GXr,wre,OXr,VXr,XXr,Ew,J6e,zXr,QXr,Are,WXr,UXr,HXr,Cw,aZe,gf,ww,Y6e,nS,JXr,K6e,YXr,nZe,hr,sS,KXr,hf,ZXr,Lre,ezr,ozr,yre,rzr,tzr,azr,lS,nzr,Z6e,szr,lzr,izr,Kt,iS,dzr,e7e,czr,fzr,uf,mzr,o7e,gzr,hzr,xre,uzr,pzr,_zr,Aw,vzr,Xr,dS,bzr,r7e,Fzr,Tzr,Sn,Mzr,t7e,Ezr,Czr,a7e,wzr,Azr,n7e,Lzr,yzr,xzr,be,Lw,s7e,$zr,kzr,$re,Szr,Rzr,Pzr,yw,l7e,Bzr,Izr,kre,Nzr,qzr,jzr,xw,i7e,Dzr,Gzr,Sre,Ozr,Vzr,Xzr,$w,d7e,zzr,Qzr,Rre,Wzr,Uzr,Hzr,kw,c7e,Jzr,Yzr,Pre,Kzr,Zzr,eQr,Sw,f7e,oQr,rQr,Bre,tQr,aQr,nQr,Rw,m7e,sQr,lQr,Ire,iQr,dQr,cQr,Pw,g7e,fQr,mQr,Nre,gQr,hQr,uQr,Bw,h7e,pQr,_Qr,qre,vQr,bQr,FQr,Iw,u7e,TQr,MQr,jre,EQr,CQr,wQr,Nw,p7e,AQr,LQr,Dre,yQr,xQr,$Qr,qw,_7e,kQr,SQr,Gre,RQr,PQr,BQr,jw,v7e,IQr,NQr,Ore,qQr,jQr,DQr,Dw,b7e,GQr,OQr,Vre,VQr,XQr,zQr,Gw,F7e,QQr,WQr,Xre,UQr,HQr,JQr,Ow,T7e,YQr,KQr,zre,ZQr,eWr,oWr,Vw,M7e,rWr,tWr,Qre,aWr,nWr,sWr,Xw,sZe,pf,zw,E7e,cS,lWr,C7e,iWr,lZe,ur,fS,dWr,_f,cWr,Wre,fWr,mWr,Ure,gWr,hWr,uWr,mS,pWr,w7e,_Wr,vWr,bWr,Zt,gS,FWr,A7e,TWr,MWr,vf,EWr,L7e,CWr,wWr,Hre,AWr,LWr,yWr,Qw,xWr,zr,hS,$Wr,y7e,kWr,SWr,Rn,RWr,x7e,PWr,BWr,$7e,IWr,NWr,k7e,qWr,jWr,DWr,uS,Ww,S7e,GWr,OWr,Jre,VWr,XWr,zWr,Uw,R7e,QWr,WWr,Yre,UWr,HWr,JWr,Hw,iZe,bf,Jw,P7e,pS,YWr,B7e,KWr,dZe,pr,_S,ZWr,Ff,eUr,Kre,oUr,rUr,Zre,tUr,aUr,nUr,vS,sUr,I7e,lUr,iUr,dUr,ea,bS,cUr,N7e,fUr,mUr,Tf,gUr,q7e,hUr,uUr,ete,pUr,_Ur,vUr,Yw,bUr,Qr,FS,FUr,j7e,TUr,MUr,Pn,EUr,D7e,CUr,wUr,G7e,AUr,LUr,O7e,yUr,xUr,$Ur,V7e,Kw,X7e,kUr,SUr,ote,RUr,PUr,BUr,Zw,cZe,Mf,eA,z7e,TS,IUr,Q7e,NUr,fZe,_r,MS,qUr,Ef,jUr,rte,DUr,GUr,tte,OUr,VUr,XUr,ES,zUr,W7e,QUr,WUr,UUr,oa,CS,HUr,U7e,JUr,YUr,Cf,KUr,H7e,ZUr,eHr,ate,oHr,rHr,tHr,oA,aHr,Wr,wS,nHr,J7e,sHr,lHr,Bn,iHr,Y7e,dHr,cHr,K7e,fHr,mHr,Z7e,gHr,hHr,uHr,eLe,rA,oLe,pHr,_Hr,nte,vHr,bHr,FHr,tA,mZe,wf,aA,rLe,AS,THr,tLe,MHr,gZe,vr,LS,EHr,Af,CHr,ste,wHr,AHr,lte,LHr,yHr,xHr,yS,$Hr,aLe,kHr,SHr,RHr,ra,xS,PHr,nLe,BHr,IHr,Lf,NHr,sLe,qHr,jHr,ite,DHr,GHr,OHr,nA,VHr,Ur,$S,XHr,lLe,zHr,QHr,In,WHr,iLe,UHr,HHr,dLe,JHr,YHr,cLe,KHr,ZHr,eJr,de,sA,fLe,oJr,rJr,dte,tJr,aJr,nJr,lA,mLe,sJr,lJr,cte,iJr,dJr,cJr,iA,gLe,fJr,mJr,fte,gJr,hJr,uJr,dA,hLe,pJr,_Jr,mte,vJr,bJr,FJr,cA,uLe,TJr,MJr,gte,EJr,CJr,wJr,fA,pLe,AJr,LJr,hte,yJr,xJr,$Jr,mA,_Le,kJr,SJr,ute,RJr,PJr,BJr,gA,vLe,IJr,NJr,pte,qJr,jJr,DJr,hA,bLe,GJr,OJr,_te,VJr,XJr,zJr,uA,FLe,QJr,WJr,vte,UJr,HJr,JJr,pA,TLe,YJr,KJr,bte,ZJr,eYr,oYr,_A,MLe,rYr,tYr,Fte,aYr,nYr,sYr,vA,ELe,lYr,iYr,Tte,dYr,cYr,fYr,bA,CLe,mYr,gYr,Mte,hYr,uYr,pYr,FA,wLe,_Yr,vYr,Ete,bYr,FYr,TYr,TA,ALe,MYr,EYr,Cte,CYr,wYr,AYr,MA,LLe,LYr,yYr,wte,xYr,$Yr,kYr,EA,yLe,SYr,RYr,Ate,PYr,BYr,IYr,CA,xLe,NYr,qYr,Lte,jYr,DYr,GYr,wA,$Le,OYr,VYr,yte,XYr,zYr,QYr,AA,kLe,WYr,UYr,xte,HYr,JYr,YYr,LA,hZe,yf,yA,SLe,kS,KYr,RLe,ZYr,uZe,br,SS,eKr,xf,oKr,$te,rKr,tKr,kte,aKr,nKr,sKr,RS,lKr,PLe,iKr,dKr,cKr,ta,PS,fKr,BLe,mKr,gKr,$f,hKr,ILe,uKr,pKr,Ste,_Kr,vKr,bKr,xA,FKr,Hr,BS,TKr,NLe,MKr,EKr,Nn,CKr,qLe,wKr,AKr,jLe,LKr,yKr,DLe,xKr,$Kr,kKr,ce,$A,GLe,SKr,RKr,Rte,PKr,BKr,IKr,kA,OLe,NKr,qKr,Pte,jKr,DKr,GKr,SA,VLe,OKr,VKr,Bte,XKr,zKr,QKr,RA,XLe,WKr,UKr,Ite,HKr,JKr,YKr,PA,zLe,KKr,ZKr,Nte,eZr,oZr,rZr,BA,QLe,tZr,aZr,qte,nZr,sZr,lZr,IA,WLe,iZr,dZr,jte,cZr,fZr,mZr,NA,ULe,gZr,hZr,Dte,uZr,pZr,_Zr,qA,HLe,vZr,bZr,Gte,FZr,TZr,MZr,jA,JLe,EZr,CZr,Ote,wZr,AZr,LZr,DA,YLe,yZr,xZr,Vte,$Zr,kZr,SZr,GA,KLe,RZr,PZr,Xte,BZr,IZr,NZr,OA,ZLe,qZr,jZr,zte,DZr,GZr,OZr,VA,eye,VZr,XZr,Qte,zZr,QZr,WZr,XA,oye,UZr,HZr,Wte,JZr,YZr,KZr,zA,rye,ZZr,eet,Ute,oet,ret,tet,QA,tye,aet,net,Hte,set,iet,det,WA,aye,cet,fet,Jte,met,get,het,UA,nye,uet,pet,Yte,_et,vet,bet,HA,sye,Fet,Tet,Kte,Met,Eet,Cet,JA,lye,wet,Aet,Zte,Let,yet,xet,YA,pZe,kf,KA,iye,IS,$et,dye,ket,_Ze,Fr,NS,Set,Sf,Ret,eae,Pet,Bet,oae,Iet,Net,qet,qS,jet,cye,Det,Get,Oet,aa,jS,Vet,fye,Xet,zet,Rf,Qet,mye,Wet,Uet,rae,Het,Jet,Yet,ZA,Ket,Jr,DS,Zet,gye,eot,oot,qn,rot,hye,tot,aot,uye,not,sot,pye,lot,iot,dot,_ye,e6,vye,cot,fot,tae,mot,got,hot,o6,vZe,Pf,r6,bye,GS,uot,Fye,pot,bZe,Tr,OS,_ot,Bf,vot,aae,bot,Fot,nae,Tot,Mot,Eot,VS,Cot,Tye,wot,Aot,Lot,na,XS,yot,Mye,xot,$ot,If,kot,Eye,Sot,Rot,sae,Pot,Bot,Iot,t6,Not,Yr,zS,qot,Cye,jot,Dot,jn,Got,wye,Oot,Vot,Aye,Xot,zot,Lye,Qot,Wot,Uot,yye,a6,xye,Hot,Jot,lae,Yot,Kot,Zot,n6,FZe,Nf,s6,$ye,QS,ert,kye,ort,TZe,Mr,WS,rrt,qf,trt,iae,art,nrt,dae,srt,lrt,irt,US,drt,Sye,crt,frt,mrt,sa,HS,grt,Rye,hrt,urt,jf,prt,Pye,_rt,vrt,cae,brt,Frt,Trt,l6,Mrt,Kr,JS,Ert,Bye,Crt,wrt,Dn,Art,Iye,Lrt,yrt,Nye,xrt,$rt,qye,krt,Srt,Rrt,te,i6,jye,Prt,Brt,fae,Irt,Nrt,qrt,d6,Dye,jrt,Drt,mae,Grt,Ort,Vrt,c6,Gye,Xrt,zrt,gae,Qrt,Wrt,Urt,f6,Oye,Hrt,Jrt,hae,Yrt,Krt,Zrt,m6,Vye,ett,ott,uae,rtt,ttt,att,g6,Xye,ntt,stt,pae,ltt,itt,dtt,h6,zye,ctt,ftt,_ae,mtt,gtt,htt,u6,Qye,utt,ptt,vae,_tt,vtt,btt,p6,Wye,Ftt,Ttt,bae,Mtt,Ett,Ctt,_6,Uye,wtt,Att,Fae,Ltt,ytt,xtt,v6,Hye,$tt,ktt,Tae,Stt,Rtt,Ptt,b6,Jye,Btt,Itt,Mae,Ntt,qtt,jtt,F6,Yye,Dtt,Gtt,Eae,Ott,Vtt,Xtt,T6,Kye,ztt,Qtt,Cae,Wtt,Utt,Htt,M6,Zye,Jtt,Ytt,wae,Ktt,Ztt,eat,E6,e8e,oat,rat,Aae,tat,aat,nat,C6,o8e,sat,lat,Lae,iat,dat,cat,w6,r8e,fat,mat,yae,gat,hat,uat,A6,t8e,pat,_at,xae,vat,bat,Fat,L6,a8e,Tat,Mat,$ae,Eat,Cat,wat,y6,n8e,Aat,Lat,kae,yat,xat,$at,x6,s8e,kat,Sat,Sae,Rat,Pat,Bat,$6,l8e,Iat,Nat,Rae,qat,jat,Dat,k6,i8e,Gat,Oat,Pae,Vat,Xat,zat,S6,d8e,Qat,Wat,Bae,Uat,Hat,Jat,R6,c8e,Yat,Kat,Iae,Zat,ent,ont,P6,f8e,rnt,tnt,Nae,ant,nnt,snt,B6,MZe,Df,I6,m8e,YS,lnt,g8e,int,EZe,Er,KS,dnt,Gf,cnt,qae,fnt,mnt,jae,gnt,hnt,unt,ZS,pnt,h8e,_nt,vnt,bnt,la,eR,Fnt,u8e,Tnt,Mnt,Of,Ent,p8e,Cnt,wnt,Dae,Ant,Lnt,ynt,N6,xnt,Zr,oR,$nt,_8e,knt,Snt,Gn,Rnt,v8e,Pnt,Bnt,b8e,Int,Nnt,F8e,qnt,jnt,Dnt,xe,q6,T8e,Gnt,Ont,Gae,Vnt,Xnt,znt,j6,M8e,Qnt,Wnt,Oae,Unt,Hnt,Jnt,D6,E8e,Ynt,Knt,Vae,Znt,est,ost,G6,C8e,rst,tst,Xae,ast,nst,sst,O6,w8e,lst,ist,zae,dst,cst,fst,V6,A8e,mst,gst,Qae,hst,ust,pst,X6,L8e,_st,vst,Wae,bst,Fst,Tst,z6,y8e,Mst,Est,Uae,Cst,wst,Ast,Q6,x8e,Lst,yst,Hae,xst,$st,kst,W6,$8e,Sst,Rst,Jae,Pst,Bst,Ist,U6,CZe,Vf,H6,k8e,rR,Nst,S8e,qst,wZe,Cr,tR,jst,Xf,Dst,Yae,Gst,Ost,Kae,Vst,Xst,zst,aR,Qst,R8e,Wst,Ust,Hst,ia,nR,Jst,P8e,Yst,Kst,zf,Zst,B8e,elt,olt,Zae,rlt,tlt,alt,J6,nlt,et,sR,slt,I8e,llt,ilt,On,dlt,N8e,clt,flt,q8e,mlt,glt,j8e,hlt,ult,plt,Ee,Y6,D8e,_lt,vlt,ene,blt,Flt,Tlt,K6,G8e,Mlt,Elt,one,Clt,wlt,Alt,Z6,O8e,Llt,ylt,rne,xlt,$lt,klt,e7,V8e,Slt,Rlt,tne,Plt,Blt,Ilt,o7,X8e,Nlt,qlt,ane,jlt,Dlt,Glt,r7,z8e,Olt,Vlt,nne,Xlt,zlt,Qlt,t7,Q8e,Wlt,Ult,sne,Hlt,Jlt,Ylt,a7,W8e,Klt,Zlt,lne,eit,oit,rit,n7,U8e,tit,ait,ine,nit,sit,lit,s7,H8e,iit,dit,dne,cit,fit,mit,l7,J8e,git,hit,cne,uit,pit,_it,i7,Y8e,vit,bit,fne,Fit,Tit,Mit,d7,K8e,Eit,Cit,mne,wit,Ait,Lit,c7,AZe,Qf,f7,Z8e,lR,yit,e9e,xit,LZe,wr,iR,$it,Wf,kit,gne,Sit,Rit,hne,Pit,Bit,Iit,dR,Nit,o9e,qit,jit,Dit,da,cR,Git,r9e,Oit,Vit,Uf,Xit,t9e,zit,Qit,une,Wit,Uit,Hit,m7,Jit,ot,fR,Yit,a9e,Kit,Zit,Vn,edt,n9e,odt,rdt,s9e,tdt,adt,l9e,ndt,sdt,ldt,$e,g7,i9e,idt,ddt,pne,cdt,fdt,mdt,h7,d9e,gdt,hdt,_ne,udt,pdt,_dt,u7,c9e,vdt,bdt,vne,Fdt,Tdt,Mdt,p7,f9e,Edt,Cdt,bne,wdt,Adt,Ldt,_7,m9e,ydt,xdt,Fne,$dt,kdt,Sdt,v7,g9e,Rdt,Pdt,Tne,Bdt,Idt,Ndt,b7,h9e,qdt,jdt,Mne,Ddt,Gdt,Odt,F7,u9e,Vdt,Xdt,Ene,zdt,Qdt,Wdt,T7,p9e,Udt,Hdt,Cne,Jdt,Ydt,Kdt,M7,_9e,Zdt,ect,wne,oct,rct,tct,E7,yZe,Hf,C7,v9e,mR,act,b9e,nct,xZe,Ar,gR,sct,Jf,lct,Ane,ict,dct,Lne,cct,fct,mct,hR,gct,F9e,hct,uct,pct,ca,uR,_ct,T9e,vct,bct,Yf,Fct,M9e,Tct,Mct,yne,Ect,Cct,wct,w7,Act,rt,pR,Lct,E9e,yct,xct,Xn,$ct,C9e,kct,Sct,w9e,Rct,Pct,A9e,Bct,Ict,Nct,ke,A7,L9e,qct,jct,xne,Dct,Gct,Oct,L7,y9e,Vct,Xct,$ne,zct,Qct,Wct,y7,x9e,Uct,Hct,kne,Jct,Yct,Kct,x7,$9e,Zct,eft,Sne,oft,rft,tft,$7,k9e,aft,nft,Rne,sft,lft,ift,k7,S9e,dft,cft,Pne,fft,mft,gft,S7,R9e,hft,uft,Bne,pft,_ft,vft,R7,P9e,bft,Fft,Ine,Tft,Mft,Eft,P7,B9e,Cft,wft,Nne,Aft,Lft,yft,B7,I9e,xft,$ft,qne,kft,Sft,Rft,I7,$Ze,Kf,N7,N9e,_R,Pft,q9e,Bft,kZe,Lr,vR,Ift,Zf,Nft,jne,qft,jft,Dne,Dft,Gft,Oft,bR,Vft,j9e,Xft,zft,Qft,fa,FR,Wft,D9e,Uft,Hft,em,Jft,G9e,Yft,Kft,Gne,Zft,emt,omt,q7,rmt,tt,TR,tmt,O9e,amt,nmt,zn,smt,V9e,lmt,imt,X9e,dmt,cmt,z9e,fmt,mmt,gmt,Se,j7,Q9e,hmt,umt,One,pmt,_mt,vmt,D7,W9e,bmt,Fmt,Vne,Tmt,Mmt,Emt,G7,U9e,Cmt,wmt,Xne,Amt,Lmt,ymt,O7,H9e,xmt,$mt,zne,kmt,Smt,Rmt,V7,J9e,Pmt,Bmt,Qne,Imt,Nmt,qmt,X7,Y9e,jmt,Dmt,Wne,Gmt,Omt,Vmt,z7,K9e,Xmt,zmt,Une,Qmt,Wmt,Umt,Q7,Z9e,Hmt,Jmt,Hne,Ymt,Kmt,Zmt,W7,exe,egt,ogt,Jne,rgt,tgt,agt,U7,oxe,ngt,sgt,Yne,lgt,igt,dgt,H7,SZe,om,J7,rxe,MR,cgt,txe,fgt,RZe,yr,ER,mgt,rm,ggt,Kne,hgt,ugt,Zne,pgt,_gt,vgt,CR,bgt,axe,Fgt,Tgt,Mgt,ma,wR,Egt,nxe,Cgt,wgt,tm,Agt,sxe,Lgt,ygt,ese,xgt,$gt,kgt,Y7,Sgt,at,AR,Rgt,lxe,Pgt,Bgt,Qn,Igt,ixe,Ngt,qgt,dxe,jgt,Dgt,cxe,Ggt,Ogt,Vgt,Re,K7,fxe,Xgt,zgt,ose,Qgt,Wgt,Ugt,Z7,mxe,Hgt,Jgt,rse,Ygt,Kgt,Zgt,eL,gxe,eht,oht,tse,rht,tht,aht,oL,hxe,nht,sht,ase,lht,iht,dht,rL,uxe,cht,fht,nse,mht,ght,hht,tL,pxe,uht,pht,sse,_ht,vht,bht,aL,_xe,Fht,Tht,lse,Mht,Eht,Cht,nL,vxe,wht,Aht,ise,Lht,yht,xht,sL,bxe,$ht,kht,dse,Sht,Rht,Pht,lL,Fxe,Bht,Iht,cse,Nht,qht,jht,iL,PZe,am,dL,Txe,LR,Dht,Mxe,Ght,BZe,xr,yR,Oht,nm,Vht,fse,Xht,zht,mse,Qht,Wht,Uht,xR,Hht,Exe,Jht,Yht,Kht,ga,$R,Zht,Cxe,eut,out,sm,rut,wxe,tut,aut,gse,nut,sut,lut,cL,iut,nt,kR,dut,Axe,cut,fut,Wn,mut,Lxe,gut,hut,yxe,uut,put,xxe,_ut,vut,but,Xe,fL,$xe,Fut,Tut,hse,Mut,Eut,Cut,mL,kxe,wut,Aut,use,Lut,yut,xut,gL,Sxe,$ut,kut,pse,Sut,Rut,Put,hL,Rxe,But,Iut,_se,Nut,qut,jut,uL,Pxe,Dut,Gut,vse,Out,Vut,Xut,pL,Bxe,zut,Qut,bse,Wut,Uut,Hut,_L,Ixe,Jut,Yut,Fse,Kut,Zut,ept,vL,Nxe,opt,rpt,Tse,tpt,apt,npt,bL,IZe,lm,FL,qxe,SR,spt,jxe,lpt,NZe,$r,RR,ipt,im,dpt,Mse,cpt,fpt,Ese,mpt,gpt,hpt,PR,upt,Dxe,ppt,_pt,vpt,ha,BR,bpt,Gxe,Fpt,Tpt,dm,Mpt,Oxe,Ept,Cpt,Cse,wpt,Apt,Lpt,TL,ypt,st,IR,xpt,Vxe,$pt,kpt,Un,Spt,Xxe,Rpt,Ppt,zxe,Bpt,Ipt,Qxe,Npt,qpt,jpt,ze,ML,Wxe,Dpt,Gpt,wse,Opt,Vpt,Xpt,EL,Uxe,zpt,Qpt,Ase,Wpt,Upt,Hpt,CL,Hxe,Jpt,Ypt,Lse,Kpt,Zpt,e_t,wL,Jxe,o_t,r_t,yse,t_t,a_t,n_t,AL,Yxe,s_t,l_t,xse,i_t,d_t,c_t,LL,Kxe,f_t,m_t,$se,g_t,h_t,u_t,yL,Zxe,p_t,__t,kse,v_t,b_t,F_t,xL,e$e,T_t,M_t,Sse,E_t,C_t,w_t,$L,qZe,cm,kL,o$e,NR,A_t,r$e,L_t,jZe,kr,qR,y_t,fm,x_t,Rse,$_t,k_t,Pse,S_t,R_t,P_t,jR,B_t,t$e,I_t,N_t,q_t,ua,DR,j_t,a$e,D_t,G_t,mm,O_t,n$e,V_t,X_t,Bse,z_t,Q_t,W_t,SL,U_t,lt,GR,H_t,s$e,J_t,Y_t,Hn,K_t,l$e,Z_t,e2t,i$e,o2t,r2t,d$e,t2t,a2t,n2t,c$e,RL,f$e,s2t,l2t,Ise,i2t,d2t,c2t,PL,DZe,gm,BL,m$e,OR,f2t,g$e,m2t,GZe,Sr,VR,g2t,hm,h2t,Nse,u2t,p2t,qse,_2t,v2t,b2t,XR,F2t,h$e,T2t,M2t,E2t,pa,zR,C2t,u$e,w2t,A2t,um,L2t,p$e,y2t,x2t,jse,$2t,k2t,S2t,IL,R2t,it,QR,P2t,_$e,B2t,I2t,Jn,N2t,v$e,q2t,j2t,b$e,D2t,G2t,F$e,O2t,V2t,X2t,WR,NL,T$e,z2t,Q2t,Dse,W2t,U2t,H2t,qL,M$e,J2t,Y2t,Gse,K2t,Z2t,evt,jL,OZe,pm,DL,E$e,UR,ovt,C$e,rvt,VZe,Rr,HR,tvt,_m,avt,Ose,nvt,svt,Vse,lvt,ivt,dvt,JR,cvt,w$e,fvt,mvt,gvt,_a,YR,hvt,A$e,uvt,pvt,vm,_vt,L$e,vvt,bvt,Xse,Fvt,Tvt,Mvt,GL,Evt,dt,KR,Cvt,y$e,wvt,Avt,Yn,Lvt,x$e,yvt,xvt,$$e,$vt,kvt,k$e,Svt,Rvt,Pvt,S$e,OL,R$e,Bvt,Ivt,zse,Nvt,qvt,jvt,VL,XZe;return d=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),E9=new oe({}),C9=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Lm=new Dvt({props:{warning:!0,$$slots:{default:[Gma]},$$scope:{ctx:$}}}),w9=new oe({}),A9=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/configuration_auto.py#L635"}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/configuration_auto.py#L658"}}),Qh=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Oma]},$$scope:{ctx:$}}}),$9=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/configuration_auto.py#L781"}}),k9=new oe({}),S9=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/tokenization_auto.py#L426"}}),B9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/v4.22.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/tokenization_auto.py#L440"}}),yu=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Vma]},$$scope:{ctx:$}}}),I9=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/tokenization_auto.py#L641"}}),N9=new oe({}),q9=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/feature_extraction_auto.py#L200"}}),G9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/v4.22.1/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/feature_extraction_auto.py#L214"}}),pp=new Dvt({props:{$$slots:{default:[Xma]},$$scope:{ctx:$}}}),_p=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[zma]},$$scope:{ctx:$}}}),O9=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/feature_extraction_auto.py#L341"}}),V9=new oe({}),X9=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/processing_auto.py#L92"}}),W9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/processing_auto.py#L106"}}),Gp=new Dvt({props:{$$slots:{default:[Qma]},$$scope:{ctx:$}}}),Op=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Wma]},$$scope:{ctx:$}}}),U9=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/processing_auto.py#L259"}}),H9=new oe({}),J9=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L833"}}),K9=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),zp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Uma]},$$scope:{ctx:$}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),tv=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Hma]},$$scope:{ctx:$}}}),ex=new oe({}),ox=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L840"}}),tx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),nv=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Jma]},$$scope:{ctx:$}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),o1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Yma]},$$scope:{ctx:$}}}),nx=new oe({}),sx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L855"}}),ix=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),t1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Kma]},$$scope:{ctx:$}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),Q1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Zma]},$$scope:{ctx:$}}}),cx=new oe({}),fx=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L862"}}),gx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),U1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[ega]},$$scope:{ctx:$}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),B4=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[oga]},$$scope:{ctx:$}}}),ux=new oe({}),px=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L869"}}),vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),N4=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[rga]},$$scope:{ctx:$}}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),nb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[tga]},$$scope:{ctx:$}}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L878"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),lb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[aga]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),iF=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[nga]},$$scope:{ctx:$}}}),wx=new oe({}),Ax=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L934"}}),yx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),cF=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[sga]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),XF=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[lga]},$$scope:{ctx:$}}}),$x=new oe({}),kx=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L941"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),QF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[iga]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),oT=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[dga]},$$scope:{ctx:$}}}),Bx=new oe({}),Ix=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L927"}}),qx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),tT=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[cga]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),VT=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[fga]},$$scope:{ctx:$}}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L887"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),zT=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[mga]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),NM=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[gga]},$$scope:{ctx:$}}}),zx=new oe({}),Qx=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L894"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),jM=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[hga]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),OM=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[uga]},$$scope:{ctx:$}}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L916"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),XM=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[pga]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),HM=new B({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_ga]},$$scope:{ctx:$}}}),o$=new oe({}),r$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L950"}}),a$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),YM=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[vga]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),gE=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[bga]},$$scope:{ctx:$}}}),s$=new oe({}),l$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L989"}}),d$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),uE=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Fga]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),vE=new B({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Tga]},$$scope:{ctx:$}}}),f$=new oe({}),m$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L996"}}),h$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),FE=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Mga]},$$scope:{ctx:$}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),EE=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Ega]},$$scope:{ctx:$}}}),p$=new oe({}),_$=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L905"}}),b$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),wE=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Cga]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),yE=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[wga]},$$scope:{ctx:$}}}),T$=new oe({}),M$=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L1003"}}),C$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),$E=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Aga]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),GE=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Lga]},$$scope:{ctx:$}}}),A$=new oe({}),L$=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L1026"}}),x$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),VE=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[yga]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),JE=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[xga]},$$scope:{ctx:$}}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L1010"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),KE=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[$ga]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),cC=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[kga]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L1017"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Sga]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),pC=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Rga]},$$scope:{ctx:$}}}),O$=new oe({}),V$=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L1035"}}),z$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),vC=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Pga]},$$scope:{ctx:$}}}),Q$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),wC=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Bga]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L1042"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Iga]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),RC=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Nga]},$$scope:{ctx:$}}}),K$=new oe({}),Z$=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L982"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[qga]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[jga]},$$scope:{ctx:$}}}),ak=new oe({}),nk=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L957"}}),lk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Dga]},$$scope:{ctx:$}}}),ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Gga]},$$scope:{ctx:$}}}),dk=new oe({}),ck=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L964"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Oga]},$$scope:{ctx:$}}}),gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),ZC=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Vga]},$$scope:{ctx:$}}}),hk=new oe({}),uk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_auto.py#L973"}}),_k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),o3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Xga]},$$scope:{ctx:$}}}),vk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[zga]},$$scope:{ctx:$}}}),bk=new oe({}),Fk=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),Mk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),s3=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Qga]},$$scope:{ctx:$}}}),Ek=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Wga]},$$scope:{ctx:$}}}),Ck=new oe({}),wk=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L440"}}),Lk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Uga]},$$scope:{ctx:$}}}),yk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),S5=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Hga]},$$scope:{ctx:$}}}),xk=new oe({}),$k=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),Sk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),P5=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Jga]},$$scope:{ctx:$}}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),H5=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Yga]},$$scope:{ctx:$}}}),Pk=new oe({}),Bk=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),Nk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/v4.22.1/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),Y5=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Kga]},$$scope:{ctx:$}}}),qk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),s0=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Zga]},$$scope:{ctx:$}}}),jk=new oe({}),Dk=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),Ok=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),i0=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[eha]},$$scope:{ctx:$}}}),Vk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),m0=new B({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[oha]},$$scope:{ctx:$}}}),Xk=new oe({}),zk=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),Wk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),h0=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[rha]},$$scope:{ctx:$}}}),Uk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),B0=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[tha]},$$scope:{ctx:$}}}),Hk=new oe({}),Jk=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L503"}}),Kk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),N0=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[aha]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),U0=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[nha]},$$scope:{ctx:$}}}),eS=new oe({}),oS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),tS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),J0=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[sha]},$$scope:{ctx:$}}}),aS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[lha]},$$scope:{ctx:$}}}),nS=new oe({}),sS=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L559"}}),iS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[iha]},$$scope:{ctx:$}}}),dS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),Xw=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[dha]},$$scope:{ctx:$}}}),cS=new oe({}),fS=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L566"}}),gS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),Qw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[cha]},$$scope:{ctx:$}}}),hS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),Hw=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[fha]},$$scope:{ctx:$}}}),pS=new oe({}),_S=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),bS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),Yw=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[mha]},$$scope:{ctx:$}}}),FS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),Zw=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[gha]},$$scope:{ctx:$}}}),TS=new oe({}),MS=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),CS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),oA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[hha]},$$scope:{ctx:$}}}),wS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),tA=new B({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[uha]},$$scope:{ctx:$}}}),AS=new oe({}),LS=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),xS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),nA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[pha]},$$scope:{ctx:$}}}),$S=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),LA=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[_ha]},$$scope:{ctx:$}}}),kS=new oe({}),SS=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),PS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),xA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[vha]},$$scope:{ctx:$}}}),BS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),YA=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[bha]},$$scope:{ctx:$}}}),IS=new oe({}),NS=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L489"}}),jS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),ZA=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Fha]},$$scope:{ctx:$}}}),DS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Tha]},$$scope:{ctx:$}}}),GS=new oe({}),OS=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_tf_auto.py#L575"}}),XS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Mha]},$$scope:{ctx:$}}}),zS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),n6=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Eha]},$$scope:{ctx:$}}}),QS=new oe({}),WS=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),HS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),l6=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Cha]},$$scope:{ctx:$}}}),JS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[wha]},$$scope:{ctx:$}}}),YS=new oe({}),KS=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),eR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Aha]},$$scope:{ctx:$}}}),oR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),U6=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Lha]},$$scope:{ctx:$}}}),rR=new oe({}),tR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),nR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),J6=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[yha]},$$scope:{ctx:$}}}),sR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),c7=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[xha]},$$scope:{ctx:$}}}),lR=new oe({}),iR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),cR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),m7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[$ha]},$$scope:{ctx:$}}}),fR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[kha]},$$scope:{ctx:$}}}),mR=new oe({}),gR=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),uR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Sha]},$$scope:{ctx:$}}}),pR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),I7=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Rha]},$$scope:{ctx:$}}}),_R=new oe({}),vR=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),FR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Pha]},$$scope:{ctx:$}}}),TR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),H7=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Bha]},$$scope:{ctx:$}}}),MR=new oe({}),ER=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),wR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),Y7=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Iha]},$$scope:{ctx:$}}}),AR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),iL=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Nha]},$$scope:{ctx:$}}}),LR=new oe({}),yR=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),$R=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),cL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[qha]},$$scope:{ctx:$}}}),kR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),bL=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[jha]},$$scope:{ctx:$}}}),SR=new oe({}),RR=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),BR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),TL=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Dha]},$$scope:{ctx:$}}}),IR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),$L=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Gha]},$$scope:{ctx:$}}}),NR=new oe({}),qR=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),DR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),SL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Oha]},$$scope:{ctx:$}}}),GR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),PL=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Vha]},$$scope:{ctx:$}}}),OR=new oe({}),VR=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),zR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),IL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Xha]},$$scope:{ctx:$}}}),QR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),jL=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[zha]},$$scope:{ctx:$}}}),UR=new oe({}),HR=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),YR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L389"}}),GL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Qha]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/v4.22.1/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.22.1/src/transformers/models/auto/auto_factory.py#L417"}}),VL=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Wha]},$$scope:{ctx:$}}}),{c(){g=a("meta"),b=l(),u=a("h1"),m=a("a"),p=a("span"),F(d.$$.fragment),h=l(),yo=a("span"),rd=o("Auto Classes"),Mm=l(),pt=a("p"),td=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=a("code"),b9=o("from_pretrained()"),Em=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),nd=o("Instantiating one of "),Zn=a("a"),F9=o("AutoConfig"),es=o(", "),os=a("a"),T9=o("AutoModel"),sd=o(`, and
`),rs=a("a"),M9=o("AutoTokenizer"),ld=o(" will directly create a class of the relevant architecture. For instance"),Cm=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),CB=o("will create a model that is an instance of "),id=a("a"),wB=o("BertModel"),AB=o("."),xo=l(),Wa=a("p"),LB=o("There is one class of "),wm=a("code"),yB=o("AutoModel"),iro=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),kYe=l(),dd=a("h2"),Am=a("a"),Hie=a("span"),F(E9.$$.fragment),dro=l(),Jie=a("span"),cro=o("Extending the Auto Classes"),SYe=l(),ts=a("p"),fro=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yie=a("code"),mro=o("NewModel"),gro=o(", make sure you have a "),Kie=a("code"),hro=o("NewModelConfig"),uro=o(` then you can add those to the auto
classes like this:`),RYe=l(),F(C9.$$.fragment),PYe=l(),xB=a("p"),pro=o("You will then be able to use the auto classes like you would usually do!"),BYe=l(),F(Lm.$$.fragment),IYe=l(),cd=a("h2"),ym=a("a"),Zie=a("span"),F(w9.$$.fragment),_ro=l(),ede=a("span"),vro=o("AutoConfig"),NYe=l(),$o=a("div"),F(A9.$$.fragment),bro=l(),L9=a("p"),Fro=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),$B=a("a"),Tro=o("from_pretrained()"),Mro=o(" class method."),Ero=l(),y9=a("p"),Cro=o("This class cannot be instantiated directly using "),ode=a("code"),wro=o("__init__()"),Aro=o(" (throws an error)."),Lro=l(),Pr=a("div"),F(x9.$$.fragment),yro=l(),rde=a("p"),xro=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),$ro=l(),fd=a("p"),kro=o("The configuration class to instantiate is selected based on the "),tde=a("code"),Sro=o("model_type"),Rro=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ade=a("code"),Pro=o("pretrained_model_name_or_path"),Bro=o(":"),Iro=l(),A=a("ul"),xm=a("li"),nde=a("strong"),Nro=o("albert"),qro=o(" \u2014 "),kB=a("a"),jro=o("AlbertConfig"),Dro=o(" (ALBERT model)"),Gro=l(),$m=a("li"),sde=a("strong"),Oro=o("bart"),Vro=o(" \u2014 "),SB=a("a"),Xro=o("BartConfig"),zro=o(" (BART model)"),Qro=l(),km=a("li"),lde=a("strong"),Wro=o("beit"),Uro=o(" \u2014 "),RB=a("a"),Hro=o("BeitConfig"),Jro=o(" (BEiT model)"),Yro=l(),Sm=a("li"),ide=a("strong"),Kro=o("bert"),Zro=o(" \u2014 "),PB=a("a"),eto=o("BertConfig"),oto=o(" (BERT model)"),rto=l(),Rm=a("li"),dde=a("strong"),tto=o("bert-generation"),ato=o(" \u2014 "),BB=a("a"),nto=o("BertGenerationConfig"),sto=o(" (Bert Generation model)"),lto=l(),Pm=a("li"),cde=a("strong"),ito=o("big_bird"),dto=o(" \u2014 "),IB=a("a"),cto=o("BigBirdConfig"),fto=o(" (BigBird model)"),mto=l(),Bm=a("li"),fde=a("strong"),gto=o("bigbird_pegasus"),hto=o(" \u2014 "),NB=a("a"),uto=o("BigBirdPegasusConfig"),pto=o(" (BigBird-Pegasus model)"),_to=l(),Im=a("li"),mde=a("strong"),vto=o("blenderbot"),bto=o(" \u2014 "),qB=a("a"),Fto=o("BlenderbotConfig"),Tto=o(" (Blenderbot model)"),Mto=l(),Nm=a("li"),gde=a("strong"),Eto=o("blenderbot-small"),Cto=o(" \u2014 "),jB=a("a"),wto=o("BlenderbotSmallConfig"),Ato=o(" (BlenderbotSmall model)"),Lto=l(),qm=a("li"),hde=a("strong"),yto=o("bloom"),xto=o(" \u2014 "),DB=a("a"),$to=o("BloomConfig"),kto=o(" (BLOOM model)"),Sto=l(),jm=a("li"),ude=a("strong"),Rto=o("camembert"),Pto=o(" \u2014 "),GB=a("a"),Bto=o("CamembertConfig"),Ito=o(" (CamemBERT model)"),Nto=l(),Dm=a("li"),pde=a("strong"),qto=o("canine"),jto=o(" \u2014 "),OB=a("a"),Dto=o("CanineConfig"),Gto=o(" (CANINE model)"),Oto=l(),Gm=a("li"),_de=a("strong"),Vto=o("clip"),Xto=o(" \u2014 "),VB=a("a"),zto=o("CLIPConfig"),Qto=o(" (CLIP model)"),Wto=l(),Om=a("li"),vde=a("strong"),Uto=o("codegen"),Hto=o(" \u2014 "),XB=a("a"),Jto=o("CodeGenConfig"),Yto=o(" (CodeGen model)"),Kto=l(),Vm=a("li"),bde=a("strong"),Zto=o("convbert"),eao=o(" \u2014 "),zB=a("a"),oao=o("ConvBertConfig"),rao=o(" (ConvBERT model)"),tao=l(),Xm=a("li"),Fde=a("strong"),aao=o("convnext"),nao=o(" \u2014 "),QB=a("a"),sao=o("ConvNextConfig"),lao=o(" (ConvNeXT model)"),iao=l(),zm=a("li"),Tde=a("strong"),dao=o("ctrl"),cao=o(" \u2014 "),WB=a("a"),fao=o("CTRLConfig"),mao=o(" (CTRL model)"),gao=l(),Qm=a("li"),Mde=a("strong"),hao=o("cvt"),uao=o(" \u2014 "),UB=a("a"),pao=o("CvtConfig"),_ao=o(" (CvT model)"),vao=l(),Wm=a("li"),Ede=a("strong"),bao=o("data2vec-audio"),Fao=o(" \u2014 "),HB=a("a"),Tao=o("Data2VecAudioConfig"),Mao=o(" (Data2VecAudio model)"),Eao=l(),Um=a("li"),Cde=a("strong"),Cao=o("data2vec-text"),wao=o(" \u2014 "),JB=a("a"),Aao=o("Data2VecTextConfig"),Lao=o(" (Data2VecText model)"),yao=l(),Hm=a("li"),wde=a("strong"),xao=o("data2vec-vision"),$ao=o(" \u2014 "),YB=a("a"),kao=o("Data2VecVisionConfig"),Sao=o(" (Data2VecVision model)"),Rao=l(),Jm=a("li"),Ade=a("strong"),Pao=o("deberta"),Bao=o(" \u2014 "),KB=a("a"),Iao=o("DebertaConfig"),Nao=o(" (DeBERTa model)"),qao=l(),Ym=a("li"),Lde=a("strong"),jao=o("deberta-v2"),Dao=o(" \u2014 "),ZB=a("a"),Gao=o("DebertaV2Config"),Oao=o(" (DeBERTa-v2 model)"),Vao=l(),Km=a("li"),yde=a("strong"),Xao=o("decision_transformer"),zao=o(" \u2014 "),eI=a("a"),Qao=o("DecisionTransformerConfig"),Wao=o(" (Decision Transformer model)"),Uao=l(),Zm=a("li"),xde=a("strong"),Hao=o("deit"),Jao=o(" \u2014 "),oI=a("a"),Yao=o("DeiTConfig"),Kao=o(" (DeiT model)"),Zao=l(),eg=a("li"),$de=a("strong"),eno=o("detr"),ono=o(" \u2014 "),rI=a("a"),rno=o("DetrConfig"),tno=o(" (DETR model)"),ano=l(),og=a("li"),kde=a("strong"),nno=o("distilbert"),sno=o(" \u2014 "),tI=a("a"),lno=o("DistilBertConfig"),ino=o(" (DistilBERT model)"),dno=l(),rg=a("li"),Sde=a("strong"),cno=o("donut-swin"),fno=o(" \u2014 "),aI=a("a"),mno=o("DonutSwinConfig"),gno=o(" (DonutSwin model)"),hno=l(),tg=a("li"),Rde=a("strong"),uno=o("dpr"),pno=o(" \u2014 "),nI=a("a"),_no=o("DPRConfig"),vno=o(" (DPR model)"),bno=l(),ag=a("li"),Pde=a("strong"),Fno=o("dpt"),Tno=o(" \u2014 "),sI=a("a"),Mno=o("DPTConfig"),Eno=o(" (DPT model)"),Cno=l(),ng=a("li"),Bde=a("strong"),wno=o("electra"),Ano=o(" \u2014 "),lI=a("a"),Lno=o("ElectraConfig"),yno=o(" (ELECTRA model)"),xno=l(),sg=a("li"),Ide=a("strong"),$no=o("encoder-decoder"),kno=o(" \u2014 "),iI=a("a"),Sno=o("EncoderDecoderConfig"),Rno=o(" (Encoder decoder model)"),Pno=l(),lg=a("li"),Nde=a("strong"),Bno=o("ernie"),Ino=o(" \u2014 "),dI=a("a"),Nno=o("ErnieConfig"),qno=o(" (ERNIE model)"),jno=l(),ig=a("li"),qde=a("strong"),Dno=o("flaubert"),Gno=o(" \u2014 "),cI=a("a"),Ono=o("FlaubertConfig"),Vno=o(" (FlauBERT model)"),Xno=l(),dg=a("li"),jde=a("strong"),zno=o("flava"),Qno=o(" \u2014 "),fI=a("a"),Wno=o("FlavaConfig"),Uno=o(" (FLAVA model)"),Hno=l(),cg=a("li"),Dde=a("strong"),Jno=o("fnet"),Yno=o(" \u2014 "),mI=a("a"),Kno=o("FNetConfig"),Zno=o(" (FNet model)"),eso=l(),fg=a("li"),Gde=a("strong"),oso=o("fsmt"),rso=o(" \u2014 "),gI=a("a"),tso=o("FSMTConfig"),aso=o(" (FairSeq Machine-Translation model)"),nso=l(),mg=a("li"),Ode=a("strong"),sso=o("funnel"),lso=o(" \u2014 "),hI=a("a"),iso=o("FunnelConfig"),dso=o(" (Funnel Transformer model)"),cso=l(),gg=a("li"),Vde=a("strong"),fso=o("glpn"),mso=o(" \u2014 "),uI=a("a"),gso=o("GLPNConfig"),hso=o(" (GLPN model)"),uso=l(),hg=a("li"),Xde=a("strong"),pso=o("gpt2"),_so=o(" \u2014 "),pI=a("a"),vso=o("GPT2Config"),bso=o(" (OpenAI GPT-2 model)"),Fso=l(),ug=a("li"),zde=a("strong"),Tso=o("gpt_neo"),Mso=o(" \u2014 "),_I=a("a"),Eso=o("GPTNeoConfig"),Cso=o(" (GPT Neo model)"),wso=l(),pg=a("li"),Qde=a("strong"),Aso=o("gpt_neox"),Lso=o(" \u2014 "),vI=a("a"),yso=o("GPTNeoXConfig"),xso=o(" (GPT NeoX model)"),$so=l(),_g=a("li"),Wde=a("strong"),kso=o("gptj"),Sso=o(" \u2014 "),bI=a("a"),Rso=o("GPTJConfig"),Pso=o(" (GPT-J model)"),Bso=l(),vg=a("li"),Ude=a("strong"),Iso=o("groupvit"),Nso=o(" \u2014 "),FI=a("a"),qso=o("GroupViTConfig"),jso=o(" (GroupViT model)"),Dso=l(),bg=a("li"),Hde=a("strong"),Gso=o("hubert"),Oso=o(" \u2014 "),TI=a("a"),Vso=o("HubertConfig"),Xso=o(" (Hubert model)"),zso=l(),Fg=a("li"),Jde=a("strong"),Qso=o("ibert"),Wso=o(" \u2014 "),MI=a("a"),Uso=o("IBertConfig"),Hso=o(" (I-BERT model)"),Jso=l(),Tg=a("li"),Yde=a("strong"),Yso=o("imagegpt"),Kso=o(" \u2014 "),EI=a("a"),Zso=o("ImageGPTConfig"),elo=o(" (ImageGPT model)"),olo=l(),Mg=a("li"),Kde=a("strong"),rlo=o("layoutlm"),tlo=o(" \u2014 "),CI=a("a"),alo=o("LayoutLMConfig"),nlo=o(" (LayoutLM model)"),slo=l(),Eg=a("li"),Zde=a("strong"),llo=o("layoutlmv2"),ilo=o(" \u2014 "),wI=a("a"),dlo=o("LayoutLMv2Config"),clo=o(" (LayoutLMv2 model)"),flo=l(),Cg=a("li"),ece=a("strong"),mlo=o("layoutlmv3"),glo=o(" \u2014 "),AI=a("a"),hlo=o("LayoutLMv3Config"),ulo=o(" (LayoutLMv3 model)"),plo=l(),wg=a("li"),oce=a("strong"),_lo=o("led"),vlo=o(" \u2014 "),LI=a("a"),blo=o("LEDConfig"),Flo=o(" (LED model)"),Tlo=l(),Ag=a("li"),rce=a("strong"),Mlo=o("levit"),Elo=o(" \u2014 "),yI=a("a"),Clo=o("LevitConfig"),wlo=o(" (LeViT model)"),Alo=l(),Lg=a("li"),tce=a("strong"),Llo=o("longformer"),ylo=o(" \u2014 "),xI=a("a"),xlo=o("LongformerConfig"),$lo=o(" (Longformer model)"),klo=l(),yg=a("li"),ace=a("strong"),Slo=o("longt5"),Rlo=o(" \u2014 "),$I=a("a"),Plo=o("LongT5Config"),Blo=o(" (LongT5 model)"),Ilo=l(),xg=a("li"),nce=a("strong"),Nlo=o("luke"),qlo=o(" \u2014 "),kI=a("a"),jlo=o("LukeConfig"),Dlo=o(" (LUKE model)"),Glo=l(),$g=a("li"),sce=a("strong"),Olo=o("lxmert"),Vlo=o(" \u2014 "),SI=a("a"),Xlo=o("LxmertConfig"),zlo=o(" (LXMERT model)"),Qlo=l(),kg=a("li"),lce=a("strong"),Wlo=o("m2m_100"),Ulo=o(" \u2014 "),RI=a("a"),Hlo=o("M2M100Config"),Jlo=o(" (M2M100 model)"),Ylo=l(),Sg=a("li"),ice=a("strong"),Klo=o("marian"),Zlo=o(" \u2014 "),PI=a("a"),eio=o("MarianConfig"),oio=o(" (Marian model)"),rio=l(),Rg=a("li"),dce=a("strong"),tio=o("maskformer"),aio=o(" \u2014 "),BI=a("a"),nio=o("MaskFormerConfig"),sio=o(" (MaskFormer model)"),lio=l(),Pg=a("li"),cce=a("strong"),iio=o("mbart"),dio=o(" \u2014 "),II=a("a"),cio=o("MBartConfig"),fio=o(" (mBART model)"),mio=l(),Bg=a("li"),fce=a("strong"),gio=o("mctct"),hio=o(" \u2014 "),NI=a("a"),uio=o("MCTCTConfig"),pio=o(" (M-CTC-T model)"),_io=l(),Ig=a("li"),mce=a("strong"),vio=o("megatron-bert"),bio=o(" \u2014 "),qI=a("a"),Fio=o("MegatronBertConfig"),Tio=o(" (Megatron-BERT model)"),Mio=l(),Ng=a("li"),gce=a("strong"),Eio=o("mobilebert"),Cio=o(" \u2014 "),jI=a("a"),wio=o("MobileBertConfig"),Aio=o(" (MobileBERT model)"),Lio=l(),qg=a("li"),hce=a("strong"),yio=o("mobilevit"),xio=o(" \u2014 "),DI=a("a"),$io=o("MobileViTConfig"),kio=o(" (MobileViT model)"),Sio=l(),jg=a("li"),uce=a("strong"),Rio=o("mpnet"),Pio=o(" \u2014 "),GI=a("a"),Bio=o("MPNetConfig"),Iio=o(" (MPNet model)"),Nio=l(),Dg=a("li"),pce=a("strong"),qio=o("mt5"),jio=o(" \u2014 "),OI=a("a"),Dio=o("MT5Config"),Gio=o(" (MT5 model)"),Oio=l(),Gg=a("li"),_ce=a("strong"),Vio=o("mvp"),Xio=o(" \u2014 "),VI=a("a"),zio=o("MvpConfig"),Qio=o(" (MVP model)"),Wio=l(),Og=a("li"),vce=a("strong"),Uio=o("nezha"),Hio=o(" \u2014 "),XI=a("a"),Jio=o("NezhaConfig"),Yio=o(" (Nezha model)"),Kio=l(),Vg=a("li"),bce=a("strong"),Zio=o("nystromformer"),edo=o(" \u2014 "),zI=a("a"),odo=o("NystromformerConfig"),rdo=o(" (Nystr\xF6mformer model)"),tdo=l(),Xg=a("li"),Fce=a("strong"),ado=o("openai-gpt"),ndo=o(" \u2014 "),QI=a("a"),sdo=o("OpenAIGPTConfig"),ldo=o(" (OpenAI GPT model)"),ido=l(),zg=a("li"),Tce=a("strong"),ddo=o("opt"),cdo=o(" \u2014 "),WI=a("a"),fdo=o("OPTConfig"),mdo=o(" (OPT model)"),gdo=l(),Qg=a("li"),Mce=a("strong"),hdo=o("owlvit"),udo=o(" \u2014 "),UI=a("a"),pdo=o("OwlViTConfig"),_do=o(" (OWL-ViT model)"),vdo=l(),Wg=a("li"),Ece=a("strong"),bdo=o("pegasus"),Fdo=o(" \u2014 "),HI=a("a"),Tdo=o("PegasusConfig"),Mdo=o(" (Pegasus model)"),Edo=l(),Ug=a("li"),Cce=a("strong"),Cdo=o("pegasus_x"),wdo=o(" \u2014 "),JI=a("a"),Ado=o("PegasusXConfig"),Ldo=o(" (PEGASUS-X model)"),ydo=l(),Hg=a("li"),wce=a("strong"),xdo=o("perceiver"),$do=o(" \u2014 "),YI=a("a"),kdo=o("PerceiverConfig"),Sdo=o(" (Perceiver model)"),Rdo=l(),Jg=a("li"),Ace=a("strong"),Pdo=o("plbart"),Bdo=o(" \u2014 "),KI=a("a"),Ido=o("PLBartConfig"),Ndo=o(" (PLBart model)"),qdo=l(),Yg=a("li"),Lce=a("strong"),jdo=o("poolformer"),Ddo=o(" \u2014 "),ZI=a("a"),Gdo=o("PoolFormerConfig"),Odo=o(" (PoolFormer model)"),Vdo=l(),Kg=a("li"),yce=a("strong"),Xdo=o("prophetnet"),zdo=o(" \u2014 "),eN=a("a"),Qdo=o("ProphetNetConfig"),Wdo=o(" (ProphetNet model)"),Udo=l(),Zg=a("li"),xce=a("strong"),Hdo=o("qdqbert"),Jdo=o(" \u2014 "),oN=a("a"),Ydo=o("QDQBertConfig"),Kdo=o(" (QDQBert model)"),Zdo=l(),eh=a("li"),$ce=a("strong"),eco=o("rag"),oco=o(" \u2014 "),rN=a("a"),rco=o("RagConfig"),tco=o(" (RAG model)"),aco=l(),oh=a("li"),kce=a("strong"),nco=o("realm"),sco=o(" \u2014 "),tN=a("a"),lco=o("RealmConfig"),ico=o(" (REALM model)"),dco=l(),rh=a("li"),Sce=a("strong"),cco=o("reformer"),fco=o(" \u2014 "),aN=a("a"),mco=o("ReformerConfig"),gco=o(" (Reformer model)"),hco=l(),th=a("li"),Rce=a("strong"),uco=o("regnet"),pco=o(" \u2014 "),nN=a("a"),_co=o("RegNetConfig"),vco=o(" (RegNet model)"),bco=l(),ah=a("li"),Pce=a("strong"),Fco=o("rembert"),Tco=o(" \u2014 "),sN=a("a"),Mco=o("RemBertConfig"),Eco=o(" (RemBERT model)"),Cco=l(),nh=a("li"),Bce=a("strong"),wco=o("resnet"),Aco=o(" \u2014 "),lN=a("a"),Lco=o("ResNetConfig"),yco=o(" (ResNet model)"),xco=l(),sh=a("li"),Ice=a("strong"),$co=o("retribert"),kco=o(" \u2014 "),iN=a("a"),Sco=o("RetriBertConfig"),Rco=o(" (RetriBERT model)"),Pco=l(),lh=a("li"),Nce=a("strong"),Bco=o("roberta"),Ico=o(" \u2014 "),dN=a("a"),Nco=o("RobertaConfig"),qco=o(" (RoBERTa model)"),jco=l(),ih=a("li"),qce=a("strong"),Dco=o("roformer"),Gco=o(" \u2014 "),cN=a("a"),Oco=o("RoFormerConfig"),Vco=o(" (RoFormer model)"),Xco=l(),dh=a("li"),jce=a("strong"),zco=o("segformer"),Qco=o(" \u2014 "),fN=a("a"),Wco=o("SegformerConfig"),Uco=o(" (SegFormer model)"),Hco=l(),ch=a("li"),Dce=a("strong"),Jco=o("sew"),Yco=o(" \u2014 "),mN=a("a"),Kco=o("SEWConfig"),Zco=o(" (SEW model)"),efo=l(),fh=a("li"),Gce=a("strong"),ofo=o("sew-d"),rfo=o(" \u2014 "),gN=a("a"),tfo=o("SEWDConfig"),afo=o(" (SEW-D model)"),nfo=l(),mh=a("li"),Oce=a("strong"),sfo=o("speech-encoder-decoder"),lfo=o(" \u2014 "),hN=a("a"),ifo=o("SpeechEncoderDecoderConfig"),dfo=o(" (Speech Encoder decoder model)"),cfo=l(),gh=a("li"),Vce=a("strong"),ffo=o("speech_to_text"),mfo=o(" \u2014 "),uN=a("a"),gfo=o("Speech2TextConfig"),hfo=o(" (Speech2Text model)"),ufo=l(),hh=a("li"),Xce=a("strong"),pfo=o("speech_to_text_2"),_fo=o(" \u2014 "),pN=a("a"),vfo=o("Speech2Text2Config"),bfo=o(" (Speech2Text2 model)"),Ffo=l(),uh=a("li"),zce=a("strong"),Tfo=o("splinter"),Mfo=o(" \u2014 "),_N=a("a"),Efo=o("SplinterConfig"),Cfo=o(" (Splinter model)"),wfo=l(),ph=a("li"),Qce=a("strong"),Afo=o("squeezebert"),Lfo=o(" \u2014 "),vN=a("a"),yfo=o("SqueezeBertConfig"),xfo=o(" (SqueezeBERT model)"),$fo=l(),_h=a("li"),Wce=a("strong"),kfo=o("swin"),Sfo=o(" \u2014 "),bN=a("a"),Rfo=o("SwinConfig"),Pfo=o(" (Swin Transformer model)"),Bfo=l(),vh=a("li"),Uce=a("strong"),Ifo=o("swinv2"),Nfo=o(" \u2014 "),FN=a("a"),qfo=o("Swinv2Config"),jfo=o(" (Swin Transformer V2 model)"),Dfo=l(),bh=a("li"),Hce=a("strong"),Gfo=o("t5"),Ofo=o(" \u2014 "),TN=a("a"),Vfo=o("T5Config"),Xfo=o(" (T5 model)"),zfo=l(),Fh=a("li"),Jce=a("strong"),Qfo=o("tapas"),Wfo=o(" \u2014 "),MN=a("a"),Ufo=o("TapasConfig"),Hfo=o(" (TAPAS model)"),Jfo=l(),Th=a("li"),Yce=a("strong"),Yfo=o("trajectory_transformer"),Kfo=o(" \u2014 "),EN=a("a"),Zfo=o("TrajectoryTransformerConfig"),emo=o(" (Trajectory Transformer model)"),omo=l(),Mh=a("li"),Kce=a("strong"),rmo=o("transfo-xl"),tmo=o(" \u2014 "),CN=a("a"),amo=o("TransfoXLConfig"),nmo=o(" (Transformer-XL model)"),smo=l(),Eh=a("li"),Zce=a("strong"),lmo=o("trocr"),imo=o(" \u2014 "),wN=a("a"),dmo=o("TrOCRConfig"),cmo=o(" (TrOCR model)"),fmo=l(),Ch=a("li"),efe=a("strong"),mmo=o("unispeech"),gmo=o(" \u2014 "),AN=a("a"),hmo=o("UniSpeechConfig"),umo=o(" (UniSpeech model)"),pmo=l(),wh=a("li"),ofe=a("strong"),_mo=o("unispeech-sat"),vmo=o(" \u2014 "),LN=a("a"),bmo=o("UniSpeechSatConfig"),Fmo=o(" (UniSpeechSat model)"),Tmo=l(),Ah=a("li"),rfe=a("strong"),Mmo=o("van"),Emo=o(" \u2014 "),yN=a("a"),Cmo=o("VanConfig"),wmo=o(" (VAN model)"),Amo=l(),Lh=a("li"),tfe=a("strong"),Lmo=o("videomae"),ymo=o(" \u2014 "),xN=a("a"),xmo=o("VideoMAEConfig"),$mo=o(" (VideoMAE model)"),kmo=l(),yh=a("li"),afe=a("strong"),Smo=o("vilt"),Rmo=o(" \u2014 "),$N=a("a"),Pmo=o("ViltConfig"),Bmo=o(" (ViLT model)"),Imo=l(),xh=a("li"),nfe=a("strong"),Nmo=o("vision-encoder-decoder"),qmo=o(" \u2014 "),kN=a("a"),jmo=o("VisionEncoderDecoderConfig"),Dmo=o(" (Vision Encoder decoder model)"),Gmo=l(),$h=a("li"),sfe=a("strong"),Omo=o("vision-text-dual-encoder"),Vmo=o(" \u2014 "),SN=a("a"),Xmo=o("VisionTextDualEncoderConfig"),zmo=o(" (VisionTextDualEncoder model)"),Qmo=l(),kh=a("li"),lfe=a("strong"),Wmo=o("visual_bert"),Umo=o(" \u2014 "),RN=a("a"),Hmo=o("VisualBertConfig"),Jmo=o(" (VisualBERT model)"),Ymo=l(),Sh=a("li"),ife=a("strong"),Kmo=o("vit"),Zmo=o(" \u2014 "),PN=a("a"),ego=o("ViTConfig"),ogo=o(" (ViT model)"),rgo=l(),Rh=a("li"),dfe=a("strong"),tgo=o("vit_mae"),ago=o(" \u2014 "),BN=a("a"),ngo=o("ViTMAEConfig"),sgo=o(" (ViTMAE model)"),lgo=l(),Ph=a("li"),cfe=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),IN=a("a"),cgo=o("Wav2Vec2Config"),fgo=o(" (Wav2Vec2 model)"),mgo=l(),Bh=a("li"),ffe=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),NN=a("a"),ugo=o("Wav2Vec2ConformerConfig"),pgo=o(" (Wav2Vec2-Conformer model)"),_go=l(),Ih=a("li"),mfe=a("strong"),vgo=o("wavlm"),bgo=o(" \u2014 "),qN=a("a"),Fgo=o("WavLMConfig"),Tgo=o(" (WavLM model)"),Mgo=l(),Nh=a("li"),gfe=a("strong"),Ego=o("xclip"),Cgo=o(" \u2014 "),jN=a("a"),wgo=o("XCLIPConfig"),Ago=o(" (X-CLIP model)"),Lgo=l(),qh=a("li"),hfe=a("strong"),ygo=o("xglm"),xgo=o(" \u2014 "),DN=a("a"),$go=o("XGLMConfig"),kgo=o(" (XGLM model)"),Sgo=l(),jh=a("li"),ufe=a("strong"),Rgo=o("xlm"),Pgo=o(" \u2014 "),GN=a("a"),Bgo=o("XLMConfig"),Igo=o(" (XLM model)"),Ngo=l(),Dh=a("li"),pfe=a("strong"),qgo=o("xlm-prophetnet"),jgo=o(" \u2014 "),ON=a("a"),Dgo=o("XLMProphetNetConfig"),Ggo=o(" (XLM-ProphetNet model)"),Ogo=l(),Gh=a("li"),_fe=a("strong"),Vgo=o("xlm-roberta"),Xgo=o(" \u2014 "),VN=a("a"),zgo=o("XLMRobertaConfig"),Qgo=o(" (XLM-RoBERTa model)"),Wgo=l(),Oh=a("li"),vfe=a("strong"),Ugo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),XN=a("a"),Jgo=o("XLMRobertaXLConfig"),Ygo=o(" (XLM-RoBERTa-XL model)"),Kgo=l(),Vh=a("li"),bfe=a("strong"),Zgo=o("xlnet"),eho=o(" \u2014 "),zN=a("a"),oho=o("XLNetConfig"),rho=o(" (XLNet model)"),tho=l(),Xh=a("li"),Ffe=a("strong"),aho=o("yolos"),nho=o(" \u2014 "),QN=a("a"),sho=o("YolosConfig"),lho=o(" (YOLOS model)"),iho=l(),zh=a("li"),Tfe=a("strong"),dho=o("yoso"),cho=o(" \u2014 "),WN=a("a"),fho=o("YosoConfig"),mho=o(" (YOSO model)"),gho=l(),F(Qh.$$.fragment),hho=l(),Wh=a("div"),F($9.$$.fragment),uho=l(),Mfe=a("p"),pho=o("Register a new configuration for this class."),qYe=l(),md=a("h2"),Uh=a("a"),Efe=a("span"),F(k9.$$.fragment),_ho=l(),Cfe=a("span"),vho=o("AutoTokenizer"),jYe=l(),ko=a("div"),F(S9.$$.fragment),bho=l(),R9=a("p"),Fho=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UN=a("a"),Tho=o("AutoTokenizer.from_pretrained()"),Mho=o(" class method."),Eho=l(),P9=a("p"),Cho=o("This class cannot be instantiated directly using "),wfe=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),Br=a("div"),F(B9.$$.fragment),yho=l(),Afe=a("p"),xho=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),$ho=l(),Ua=a("p"),kho=o("The tokenizer class to instantiate is selected based on the "),Lfe=a("code"),Sho=o("model_type"),Rho=o(` property of the config object (either
passed as an argument or loaded from `),yfe=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xfe=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),k=a("ul"),as=a("li"),$fe=a("strong"),jho=o("albert"),Dho=o(" \u2014 "),HN=a("a"),Gho=o("AlbertTokenizer"),Oho=o(" or "),JN=a("a"),Vho=o("AlbertTokenizerFast"),Xho=o(" (ALBERT model)"),zho=l(),ns=a("li"),kfe=a("strong"),Qho=o("bart"),Who=o(" \u2014 "),YN=a("a"),Uho=o("BartTokenizer"),Hho=o(" or "),KN=a("a"),Jho=o("BartTokenizerFast"),Yho=o(" (BART model)"),Kho=l(),ss=a("li"),Sfe=a("strong"),Zho=o("barthez"),euo=o(" \u2014 "),ZN=a("a"),ouo=o("BarthezTokenizer"),ruo=o(" or "),eq=a("a"),tuo=o("BarthezTokenizerFast"),auo=o(" (BARThez model)"),nuo=l(),Hh=a("li"),Rfe=a("strong"),suo=o("bartpho"),luo=o(" \u2014 "),oq=a("a"),iuo=o("BartphoTokenizer"),duo=o(" (BARTpho model)"),cuo=l(),ls=a("li"),Pfe=a("strong"),fuo=o("bert"),muo=o(" \u2014 "),rq=a("a"),guo=o("BertTokenizer"),huo=o(" or "),tq=a("a"),uuo=o("BertTokenizerFast"),puo=o(" (BERT model)"),_uo=l(),Jh=a("li"),Bfe=a("strong"),vuo=o("bert-generation"),buo=o(" \u2014 "),aq=a("a"),Fuo=o("BertGenerationTokenizer"),Tuo=o(" (Bert Generation model)"),Muo=l(),Yh=a("li"),Ife=a("strong"),Euo=o("bert-japanese"),Cuo=o(" \u2014 "),nq=a("a"),wuo=o("BertJapaneseTokenizer"),Auo=o(" (BertJapanese model)"),Luo=l(),Kh=a("li"),Nfe=a("strong"),yuo=o("bertweet"),xuo=o(" \u2014 "),sq=a("a"),$uo=o("BertweetTokenizer"),kuo=o(" (BERTweet model)"),Suo=l(),is=a("li"),qfe=a("strong"),Ruo=o("big_bird"),Puo=o(" \u2014 "),lq=a("a"),Buo=o("BigBirdTokenizer"),Iuo=o(" or "),iq=a("a"),Nuo=o("BigBirdTokenizerFast"),quo=o(" (BigBird model)"),juo=l(),ds=a("li"),jfe=a("strong"),Duo=o("bigbird_pegasus"),Guo=o(" \u2014 "),dq=a("a"),Ouo=o("PegasusTokenizer"),Vuo=o(" or "),cq=a("a"),Xuo=o("PegasusTokenizerFast"),zuo=o(" (BigBird-Pegasus model)"),Quo=l(),cs=a("li"),Dfe=a("strong"),Wuo=o("blenderbot"),Uuo=o(" \u2014 "),fq=a("a"),Huo=o("BlenderbotTokenizer"),Juo=o(" or "),mq=a("a"),Yuo=o("BlenderbotTokenizerFast"),Kuo=o(" (Blenderbot model)"),Zuo=l(),Zh=a("li"),Gfe=a("strong"),epo=o("blenderbot-small"),opo=o(" \u2014 "),gq=a("a"),rpo=o("BlenderbotSmallTokenizer"),tpo=o(" (BlenderbotSmall model)"),apo=l(),eu=a("li"),Ofe=a("strong"),npo=o("bloom"),spo=o(" \u2014 "),hq=a("a"),lpo=o("BloomTokenizerFast"),ipo=o(" (BLOOM model)"),dpo=l(),ou=a("li"),Vfe=a("strong"),cpo=o("byt5"),fpo=o(" \u2014 "),uq=a("a"),mpo=o("ByT5Tokenizer"),gpo=o(" (ByT5 model)"),hpo=l(),fs=a("li"),Xfe=a("strong"),upo=o("camembert"),ppo=o(" \u2014 "),pq=a("a"),_po=o("CamembertTokenizer"),vpo=o(" or "),_q=a("a"),bpo=o("CamembertTokenizerFast"),Fpo=o(" (CamemBERT model)"),Tpo=l(),ru=a("li"),zfe=a("strong"),Mpo=o("canine"),Epo=o(" \u2014 "),vq=a("a"),Cpo=o("CanineTokenizer"),wpo=o(" (CANINE model)"),Apo=l(),ms=a("li"),Qfe=a("strong"),Lpo=o("clip"),ypo=o(" \u2014 "),bq=a("a"),xpo=o("CLIPTokenizer"),$po=o(" or "),Fq=a("a"),kpo=o("CLIPTokenizerFast"),Spo=o(" (CLIP model)"),Rpo=l(),gs=a("li"),Wfe=a("strong"),Ppo=o("codegen"),Bpo=o(" \u2014 "),Tq=a("a"),Ipo=o("CodeGenTokenizer"),Npo=o(" or "),Mq=a("a"),qpo=o("CodeGenTokenizerFast"),jpo=o(" (CodeGen model)"),Dpo=l(),hs=a("li"),Ufe=a("strong"),Gpo=o("convbert"),Opo=o(" \u2014 "),Eq=a("a"),Vpo=o("ConvBertTokenizer"),Xpo=o(" or "),Cq=a("a"),zpo=o("ConvBertTokenizerFast"),Qpo=o(" (ConvBERT model)"),Wpo=l(),us=a("li"),Hfe=a("strong"),Upo=o("cpm"),Hpo=o(" \u2014 "),wq=a("a"),Jpo=o("CpmTokenizer"),Ypo=o(" or "),Aq=a("a"),Kpo=o("CpmTokenizerFast"),Zpo=o(" (CPM model)"),e_o=l(),tu=a("li"),Jfe=a("strong"),o_o=o("ctrl"),r_o=o(" \u2014 "),Lq=a("a"),t_o=o("CTRLTokenizer"),a_o=o(" (CTRL model)"),n_o=l(),ps=a("li"),Yfe=a("strong"),s_o=o("data2vec-text"),l_o=o(" \u2014 "),yq=a("a"),i_o=o("RobertaTokenizer"),d_o=o(" or "),xq=a("a"),c_o=o("RobertaTokenizerFast"),f_o=o(" (Data2VecText model)"),m_o=l(),_s=a("li"),Kfe=a("strong"),g_o=o("deberta"),h_o=o(" \u2014 "),$q=a("a"),u_o=o("DebertaTokenizer"),p_o=o(" or "),kq=a("a"),__o=o("DebertaTokenizerFast"),v_o=o(" (DeBERTa model)"),b_o=l(),vs=a("li"),Zfe=a("strong"),F_o=o("deberta-v2"),T_o=o(" \u2014 "),Sq=a("a"),M_o=o("DebertaV2Tokenizer"),E_o=o(" or "),Rq=a("a"),C_o=o("DebertaV2TokenizerFast"),w_o=o(" (DeBERTa-v2 model)"),A_o=l(),bs=a("li"),eme=a("strong"),L_o=o("distilbert"),y_o=o(" \u2014 "),Pq=a("a"),x_o=o("DistilBertTokenizer"),$_o=o(" or "),Bq=a("a"),k_o=o("DistilBertTokenizerFast"),S_o=o(" (DistilBERT model)"),R_o=l(),Fs=a("li"),ome=a("strong"),P_o=o("dpr"),B_o=o(" \u2014 "),Iq=a("a"),I_o=o("DPRQuestionEncoderTokenizer"),N_o=o(" or "),Nq=a("a"),q_o=o("DPRQuestionEncoderTokenizerFast"),j_o=o(" (DPR model)"),D_o=l(),Ts=a("li"),rme=a("strong"),G_o=o("electra"),O_o=o(" \u2014 "),qq=a("a"),V_o=o("ElectraTokenizer"),X_o=o(" or "),jq=a("a"),z_o=o("ElectraTokenizerFast"),Q_o=o(" (ELECTRA model)"),W_o=l(),Ms=a("li"),tme=a("strong"),U_o=o("ernie"),H_o=o(" \u2014 "),Dq=a("a"),J_o=o("BertTokenizer"),Y_o=o(" or "),Gq=a("a"),K_o=o("BertTokenizerFast"),Z_o=o(" (ERNIE model)"),e2o=l(),au=a("li"),ame=a("strong"),o2o=o("flaubert"),r2o=o(" \u2014 "),Oq=a("a"),t2o=o("FlaubertTokenizer"),a2o=o(" (FlauBERT model)"),n2o=l(),Es=a("li"),nme=a("strong"),s2o=o("fnet"),l2o=o(" \u2014 "),Vq=a("a"),i2o=o("FNetTokenizer"),d2o=o(" or "),Xq=a("a"),c2o=o("FNetTokenizerFast"),f2o=o(" (FNet model)"),m2o=l(),nu=a("li"),sme=a("strong"),g2o=o("fsmt"),h2o=o(" \u2014 "),zq=a("a"),u2o=o("FSMTTokenizer"),p2o=o(" (FairSeq Machine-Translation model)"),_2o=l(),Cs=a("li"),lme=a("strong"),v2o=o("funnel"),b2o=o(" \u2014 "),Qq=a("a"),F2o=o("FunnelTokenizer"),T2o=o(" or "),Wq=a("a"),M2o=o("FunnelTokenizerFast"),E2o=o(" (Funnel Transformer model)"),C2o=l(),ws=a("li"),ime=a("strong"),w2o=o("gpt2"),A2o=o(" \u2014 "),Uq=a("a"),L2o=o("GPT2Tokenizer"),y2o=o(" or "),Hq=a("a"),x2o=o("GPT2TokenizerFast"),$2o=o(" (OpenAI GPT-2 model)"),k2o=l(),As=a("li"),dme=a("strong"),S2o=o("gpt_neo"),R2o=o(" \u2014 "),Jq=a("a"),P2o=o("GPT2Tokenizer"),B2o=o(" or "),Yq=a("a"),I2o=o("GPT2TokenizerFast"),N2o=o(" (GPT Neo model)"),q2o=l(),su=a("li"),cme=a("strong"),j2o=o("gpt_neox"),D2o=o(" \u2014 "),Kq=a("a"),G2o=o("GPTNeoXTokenizerFast"),O2o=o(" (GPT NeoX model)"),V2o=l(),Ls=a("li"),fme=a("strong"),X2o=o("gptj"),z2o=o(" \u2014 "),Zq=a("a"),Q2o=o("GPT2Tokenizer"),W2o=o(" or "),ej=a("a"),U2o=o("GPT2TokenizerFast"),H2o=o(" (GPT-J model)"),J2o=l(),ys=a("li"),mme=a("strong"),Y2o=o("groupvit"),K2o=o(" \u2014 "),oj=a("a"),Z2o=o("CLIPTokenizer"),evo=o(" or "),rj=a("a"),ovo=o("CLIPTokenizerFast"),rvo=o(" (GroupViT model)"),tvo=l(),xs=a("li"),gme=a("strong"),avo=o("herbert"),nvo=o(" \u2014 "),tj=a("a"),svo=o("HerbertTokenizer"),lvo=o(" or "),aj=a("a"),ivo=o("HerbertTokenizerFast"),dvo=o(" (HerBERT model)"),cvo=l(),lu=a("li"),hme=a("strong"),fvo=o("hubert"),mvo=o(" \u2014 "),nj=a("a"),gvo=o("Wav2Vec2CTCTokenizer"),hvo=o(" (Hubert model)"),uvo=l(),$s=a("li"),ume=a("strong"),pvo=o("ibert"),_vo=o(" \u2014 "),sj=a("a"),vvo=o("RobertaTokenizer"),bvo=o(" or "),lj=a("a"),Fvo=o("RobertaTokenizerFast"),Tvo=o(" (I-BERT model)"),Mvo=l(),ks=a("li"),pme=a("strong"),Evo=o("layoutlm"),Cvo=o(" \u2014 "),ij=a("a"),wvo=o("LayoutLMTokenizer"),Avo=o(" or "),dj=a("a"),Lvo=o("LayoutLMTokenizerFast"),yvo=o(" (LayoutLM model)"),xvo=l(),Ss=a("li"),_me=a("strong"),$vo=o("layoutlmv2"),kvo=o(" \u2014 "),cj=a("a"),Svo=o("LayoutLMv2Tokenizer"),Rvo=o(" or "),fj=a("a"),Pvo=o("LayoutLMv2TokenizerFast"),Bvo=o(" (LayoutLMv2 model)"),Ivo=l(),Rs=a("li"),vme=a("strong"),Nvo=o("layoutlmv3"),qvo=o(" \u2014 "),mj=a("a"),jvo=o("LayoutLMv3Tokenizer"),Dvo=o(" or "),gj=a("a"),Gvo=o("LayoutLMv3TokenizerFast"),Ovo=o(" (LayoutLMv3 model)"),Vvo=l(),Ps=a("li"),bme=a("strong"),Xvo=o("layoutxlm"),zvo=o(" \u2014 "),hj=a("a"),Qvo=o("LayoutXLMTokenizer"),Wvo=o(" or "),uj=a("a"),Uvo=o("LayoutXLMTokenizerFast"),Hvo=o(" (LayoutXLM model)"),Jvo=l(),Bs=a("li"),Fme=a("strong"),Yvo=o("led"),Kvo=o(" \u2014 "),pj=a("a"),Zvo=o("LEDTokenizer"),e1o=o(" or "),_j=a("a"),o1o=o("LEDTokenizerFast"),r1o=o(" (LED model)"),t1o=l(),Is=a("li"),Tme=a("strong"),a1o=o("longformer"),n1o=o(" \u2014 "),vj=a("a"),s1o=o("LongformerTokenizer"),l1o=o(" or "),bj=a("a"),i1o=o("LongformerTokenizerFast"),d1o=o(" (Longformer model)"),c1o=l(),Ns=a("li"),Mme=a("strong"),f1o=o("longt5"),m1o=o(" \u2014 "),Fj=a("a"),g1o=o("T5Tokenizer"),h1o=o(" or "),Tj=a("a"),u1o=o("T5TokenizerFast"),p1o=o(" (LongT5 model)"),_1o=l(),iu=a("li"),Eme=a("strong"),v1o=o("luke"),b1o=o(" \u2014 "),Mj=a("a"),F1o=o("LukeTokenizer"),T1o=o(" (LUKE model)"),M1o=l(),qs=a("li"),Cme=a("strong"),E1o=o("lxmert"),C1o=o(" \u2014 "),Ej=a("a"),w1o=o("LxmertTokenizer"),A1o=o(" or "),Cj=a("a"),L1o=o("LxmertTokenizerFast"),y1o=o(" (LXMERT model)"),x1o=l(),du=a("li"),wme=a("strong"),$1o=o("m2m_100"),k1o=o(" \u2014 "),wj=a("a"),S1o=o("M2M100Tokenizer"),R1o=o(" (M2M100 model)"),P1o=l(),cu=a("li"),Ame=a("strong"),B1o=o("marian"),I1o=o(" \u2014 "),Aj=a("a"),N1o=o("MarianTokenizer"),q1o=o(" (Marian model)"),j1o=l(),js=a("li"),Lme=a("strong"),D1o=o("mbart"),G1o=o(" \u2014 "),Lj=a("a"),O1o=o("MBartTokenizer"),V1o=o(" or "),yj=a("a"),X1o=o("MBartTokenizerFast"),z1o=o(" (mBART model)"),Q1o=l(),Ds=a("li"),yme=a("strong"),W1o=o("mbart50"),U1o=o(" \u2014 "),xj=a("a"),H1o=o("MBart50Tokenizer"),J1o=o(" or "),$j=a("a"),Y1o=o("MBart50TokenizerFast"),K1o=o(" (mBART-50 model)"),Z1o=l(),Gs=a("li"),xme=a("strong"),e4o=o("megatron-bert"),o4o=o(" \u2014 "),kj=a("a"),r4o=o("BertTokenizer"),t4o=o(" or "),Sj=a("a"),a4o=o("BertTokenizerFast"),n4o=o(" (Megatron-BERT model)"),s4o=l(),fu=a("li"),$me=a("strong"),l4o=o("mluke"),i4o=o(" \u2014 "),Rj=a("a"),d4o=o("MLukeTokenizer"),c4o=o(" (mLUKE model)"),f4o=l(),Os=a("li"),kme=a("strong"),m4o=o("mobilebert"),g4o=o(" \u2014 "),Pj=a("a"),h4o=o("MobileBertTokenizer"),u4o=o(" or "),Bj=a("a"),p4o=o("MobileBertTokenizerFast"),_4o=o(" (MobileBERT model)"),v4o=l(),Vs=a("li"),Sme=a("strong"),b4o=o("mpnet"),F4o=o(" \u2014 "),Ij=a("a"),T4o=o("MPNetTokenizer"),M4o=o(" or "),Nj=a("a"),E4o=o("MPNetTokenizerFast"),C4o=o(" (MPNet model)"),w4o=l(),Xs=a("li"),Rme=a("strong"),A4o=o("mt5"),L4o=o(" \u2014 "),qj=a("a"),y4o=o("MT5Tokenizer"),x4o=o(" or "),jj=a("a"),$4o=o("MT5TokenizerFast"),k4o=o(" (MT5 model)"),S4o=l(),zs=a("li"),Pme=a("strong"),R4o=o("mvp"),P4o=o(" \u2014 "),Dj=a("a"),B4o=o("MvpTokenizer"),I4o=o(" or "),Gj=a("a"),N4o=o("MvpTokenizerFast"),q4o=o(" (MVP model)"),j4o=l(),Qs=a("li"),Bme=a("strong"),D4o=o("nezha"),G4o=o(" \u2014 "),Oj=a("a"),O4o=o("BertTokenizer"),V4o=o(" or "),Vj=a("a"),X4o=o("BertTokenizerFast"),z4o=o(" (Nezha model)"),Q4o=l(),Ws=a("li"),Ime=a("strong"),W4o=o("nllb"),U4o=o(" \u2014 "),Xj=a("a"),H4o=o("NllbTokenizer"),J4o=o(" or "),zj=a("a"),Y4o=o("NllbTokenizerFast"),K4o=o(" (NLLB model)"),Z4o=l(),Us=a("li"),Nme=a("strong"),ebo=o("nystromformer"),obo=o(" \u2014 "),Qj=a("a"),rbo=o("AlbertTokenizer"),tbo=o(" or "),Wj=a("a"),abo=o("AlbertTokenizerFast"),nbo=o(" (Nystr\xF6mformer model)"),sbo=l(),Hs=a("li"),qme=a("strong"),lbo=o("openai-gpt"),ibo=o(" \u2014 "),Uj=a("a"),dbo=o("OpenAIGPTTokenizer"),cbo=o(" or "),Hj=a("a"),fbo=o("OpenAIGPTTokenizerFast"),mbo=o(" (OpenAI GPT model)"),gbo=l(),mu=a("li"),jme=a("strong"),hbo=o("opt"),ubo=o(" \u2014 "),Jj=a("a"),pbo=o("GPT2Tokenizer"),_bo=o(" (OPT model)"),vbo=l(),Js=a("li"),Dme=a("strong"),bbo=o("owlvit"),Fbo=o(" \u2014 "),Yj=a("a"),Tbo=o("CLIPTokenizer"),Mbo=o(" or "),Kj=a("a"),Ebo=o("CLIPTokenizerFast"),Cbo=o(" (OWL-ViT model)"),wbo=l(),Ys=a("li"),Gme=a("strong"),Abo=o("pegasus"),Lbo=o(" \u2014 "),Zj=a("a"),ybo=o("PegasusTokenizer"),xbo=o(" or "),eD=a("a"),$bo=o("PegasusTokenizerFast"),kbo=o(" (Pegasus model)"),Sbo=l(),gu=a("li"),Ome=a("strong"),Rbo=o("perceiver"),Pbo=o(" \u2014 "),oD=a("a"),Bbo=o("PerceiverTokenizer"),Ibo=o(" (Perceiver model)"),Nbo=l(),hu=a("li"),Vme=a("strong"),qbo=o("phobert"),jbo=o(" \u2014 "),rD=a("a"),Dbo=o("PhobertTokenizer"),Gbo=o(" (PhoBERT model)"),Obo=l(),uu=a("li"),Xme=a("strong"),Vbo=o("plbart"),Xbo=o(" \u2014 "),tD=a("a"),zbo=o("PLBartTokenizer"),Qbo=o(" (PLBart model)"),Wbo=l(),pu=a("li"),zme=a("strong"),Ubo=o("prophetnet"),Hbo=o(" \u2014 "),aD=a("a"),Jbo=o("ProphetNetTokenizer"),Ybo=o(" (ProphetNet model)"),Kbo=l(),Ks=a("li"),Qme=a("strong"),Zbo=o("qdqbert"),eFo=o(" \u2014 "),nD=a("a"),oFo=o("BertTokenizer"),rFo=o(" or "),sD=a("a"),tFo=o("BertTokenizerFast"),aFo=o(" (QDQBert model)"),nFo=l(),_u=a("li"),Wme=a("strong"),sFo=o("rag"),lFo=o(" \u2014 "),lD=a("a"),iFo=o("RagTokenizer"),dFo=o(" (RAG model)"),cFo=l(),Zs=a("li"),Ume=a("strong"),fFo=o("realm"),mFo=o(" \u2014 "),iD=a("a"),gFo=o("RealmTokenizer"),hFo=o(" or "),dD=a("a"),uFo=o("RealmTokenizerFast"),pFo=o(" (REALM model)"),_Fo=l(),el=a("li"),Hme=a("strong"),vFo=o("reformer"),bFo=o(" \u2014 "),cD=a("a"),FFo=o("ReformerTokenizer"),TFo=o(" or "),fD=a("a"),MFo=o("ReformerTokenizerFast"),EFo=o(" (Reformer model)"),CFo=l(),ol=a("li"),Jme=a("strong"),wFo=o("rembert"),AFo=o(" \u2014 "),mD=a("a"),LFo=o("RemBertTokenizer"),yFo=o(" or "),gD=a("a"),xFo=o("RemBertTokenizerFast"),$Fo=o(" (RemBERT model)"),kFo=l(),rl=a("li"),Yme=a("strong"),SFo=o("retribert"),RFo=o(" \u2014 "),hD=a("a"),PFo=o("RetriBertTokenizer"),BFo=o(" or "),uD=a("a"),IFo=o("RetriBertTokenizerFast"),NFo=o(" (RetriBERT model)"),qFo=l(),tl=a("li"),Kme=a("strong"),jFo=o("roberta"),DFo=o(" \u2014 "),pD=a("a"),GFo=o("RobertaTokenizer"),OFo=o(" or "),_D=a("a"),VFo=o("RobertaTokenizerFast"),XFo=o(" (RoBERTa model)"),zFo=l(),al=a("li"),Zme=a("strong"),QFo=o("roformer"),WFo=o(" \u2014 "),vD=a("a"),UFo=o("RoFormerTokenizer"),HFo=o(" or "),bD=a("a"),JFo=o("RoFormerTokenizerFast"),YFo=o(" (RoFormer model)"),KFo=l(),vu=a("li"),ege=a("strong"),ZFo=o("speech_to_text"),eTo=o(" \u2014 "),FD=a("a"),oTo=o("Speech2TextTokenizer"),rTo=o(" (Speech2Text model)"),tTo=l(),bu=a("li"),oge=a("strong"),aTo=o("speech_to_text_2"),nTo=o(" \u2014 "),TD=a("a"),sTo=o("Speech2Text2Tokenizer"),lTo=o(" (Speech2Text2 model)"),iTo=l(),nl=a("li"),rge=a("strong"),dTo=o("splinter"),cTo=o(" \u2014 "),MD=a("a"),fTo=o("SplinterTokenizer"),mTo=o(" or "),ED=a("a"),gTo=o("SplinterTokenizerFast"),hTo=o(" (Splinter model)"),uTo=l(),sl=a("li"),tge=a("strong"),pTo=o("squeezebert"),_To=o(" \u2014 "),CD=a("a"),vTo=o("SqueezeBertTokenizer"),bTo=o(" or "),wD=a("a"),FTo=o("SqueezeBertTokenizerFast"),TTo=o(" (SqueezeBERT model)"),MTo=l(),ll=a("li"),age=a("strong"),ETo=o("t5"),CTo=o(" \u2014 "),AD=a("a"),wTo=o("T5Tokenizer"),ATo=o(" or "),LD=a("a"),LTo=o("T5TokenizerFast"),yTo=o(" (T5 model)"),xTo=l(),Fu=a("li"),nge=a("strong"),$To=o("tapas"),kTo=o(" \u2014 "),yD=a("a"),STo=o("TapasTokenizer"),RTo=o(" (TAPAS model)"),PTo=l(),Tu=a("li"),sge=a("strong"),BTo=o("tapex"),ITo=o(" \u2014 "),xD=a("a"),NTo=o("TapexTokenizer"),qTo=o(" (TAPEX model)"),jTo=l(),Mu=a("li"),lge=a("strong"),DTo=o("transfo-xl"),GTo=o(" \u2014 "),$D=a("a"),OTo=o("TransfoXLTokenizer"),VTo=o(" (Transformer-XL model)"),XTo=l(),il=a("li"),ige=a("strong"),zTo=o("vilt"),QTo=o(" \u2014 "),kD=a("a"),WTo=o("BertTokenizer"),UTo=o(" or "),SD=a("a"),HTo=o("BertTokenizerFast"),JTo=o(" (ViLT model)"),YTo=l(),dl=a("li"),dge=a("strong"),KTo=o("visual_bert"),ZTo=o(" \u2014 "),RD=a("a"),eMo=o("BertTokenizer"),oMo=o(" or "),PD=a("a"),rMo=o("BertTokenizerFast"),tMo=o(" (VisualBERT model)"),aMo=l(),Eu=a("li"),cge=a("strong"),nMo=o("wav2vec2"),sMo=o(" \u2014 "),BD=a("a"),lMo=o("Wav2Vec2CTCTokenizer"),iMo=o(" (Wav2Vec2 model)"),dMo=l(),Cu=a("li"),fge=a("strong"),cMo=o("wav2vec2-conformer"),fMo=o(" \u2014 "),ID=a("a"),mMo=o("Wav2Vec2CTCTokenizer"),gMo=o(" (Wav2Vec2-Conformer model)"),hMo=l(),wu=a("li"),mge=a("strong"),uMo=o("wav2vec2_phoneme"),pMo=o(" \u2014 "),ND=a("a"),_Mo=o("Wav2Vec2PhonemeCTCTokenizer"),vMo=o(" (Wav2Vec2Phoneme model)"),bMo=l(),cl=a("li"),gge=a("strong"),FMo=o("xclip"),TMo=o(" \u2014 "),qD=a("a"),MMo=o("CLIPTokenizer"),EMo=o(" or "),jD=a("a"),CMo=o("CLIPTokenizerFast"),wMo=o(" (X-CLIP model)"),AMo=l(),fl=a("li"),hge=a("strong"),LMo=o("xglm"),yMo=o(" \u2014 "),DD=a("a"),xMo=o("XGLMTokenizer"),$Mo=o(" or "),GD=a("a"),kMo=o("XGLMTokenizerFast"),SMo=o(" (XGLM model)"),RMo=l(),Au=a("li"),uge=a("strong"),PMo=o("xlm"),BMo=o(" \u2014 "),OD=a("a"),IMo=o("XLMTokenizer"),NMo=o(" (XLM model)"),qMo=l(),Lu=a("li"),pge=a("strong"),jMo=o("xlm-prophetnet"),DMo=o(" \u2014 "),VD=a("a"),GMo=o("XLMProphetNetTokenizer"),OMo=o(" (XLM-ProphetNet model)"),VMo=l(),ml=a("li"),_ge=a("strong"),XMo=o("xlm-roberta"),zMo=o(" \u2014 "),XD=a("a"),QMo=o("XLMRobertaTokenizer"),WMo=o(" or "),zD=a("a"),UMo=o("XLMRobertaTokenizerFast"),HMo=o(" (XLM-RoBERTa model)"),JMo=l(),gl=a("li"),vge=a("strong"),YMo=o("xlm-roberta-xl"),KMo=o(" \u2014 "),QD=a("a"),ZMo=o("XLMRobertaTokenizer"),eEo=o(" or "),WD=a("a"),oEo=o("XLMRobertaTokenizerFast"),rEo=o(" (XLM-RoBERTa-XL model)"),tEo=l(),hl=a("li"),bge=a("strong"),aEo=o("xlnet"),nEo=o(" \u2014 "),UD=a("a"),sEo=o("XLNetTokenizer"),lEo=o(" or "),HD=a("a"),iEo=o("XLNetTokenizerFast"),dEo=o(" (XLNet model)"),cEo=l(),ul=a("li"),Fge=a("strong"),fEo=o("yoso"),mEo=o(" \u2014 "),JD=a("a"),gEo=o("AlbertTokenizer"),hEo=o(" or "),YD=a("a"),uEo=o("AlbertTokenizerFast"),pEo=o(" (YOSO model)"),_Eo=l(),F(yu.$$.fragment),vEo=l(),xu=a("div"),F(I9.$$.fragment),bEo=l(),Tge=a("p"),FEo=o("Register a new tokenizer in this mapping."),DYe=l(),gd=a("h2"),$u=a("a"),Mge=a("span"),F(N9.$$.fragment),TEo=l(),Ege=a("span"),MEo=o("AutoFeatureExtractor"),GYe=l(),So=a("div"),F(q9.$$.fragment),EEo=l(),j9=a("p"),CEo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KD=a("a"),wEo=o("AutoFeatureExtractor.from_pretrained()"),AEo=o(" class method."),LEo=l(),D9=a("p"),yEo=o("This class cannot be instantiated directly using "),Cge=a("code"),xEo=o("__init__()"),$Eo=o(" (throws an error)."),kEo=l(),Ye=a("div"),F(G9.$$.fragment),SEo=l(),wge=a("p"),REo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),PEo=l(),Ha=a("p"),BEo=o("The feature extractor class to instantiate is selected based on the "),Age=a("code"),IEo=o("model_type"),NEo=o(` property of the config object
(either passed as an argument or loaded from `),Lge=a("code"),qEo=o("pretrained_model_name_or_path"),jEo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),yge=a("code"),DEo=o("pretrained_model_name_or_path"),GEo=o(":"),OEo=l(),W=a("ul"),ku=a("li"),xge=a("strong"),VEo=o("beit"),XEo=o(" \u2014 "),ZD=a("a"),zEo=o("BeitFeatureExtractor"),QEo=o(" (BEiT model)"),WEo=l(),Su=a("li"),$ge=a("strong"),UEo=o("clip"),HEo=o(" \u2014 "),eG=a("a"),JEo=o("CLIPFeatureExtractor"),YEo=o(" (CLIP model)"),KEo=l(),Ru=a("li"),kge=a("strong"),ZEo=o("convnext"),eCo=o(" \u2014 "),oG=a("a"),oCo=o("ConvNextFeatureExtractor"),rCo=o(" (ConvNeXT model)"),tCo=l(),Pu=a("li"),Sge=a("strong"),aCo=o("cvt"),nCo=o(" \u2014 "),rG=a("a"),sCo=o("ConvNextFeatureExtractor"),lCo=o(" (CvT model)"),iCo=l(),Bu=a("li"),Rge=a("strong"),dCo=o("data2vec-audio"),cCo=o(" \u2014 "),tG=a("a"),fCo=o("Wav2Vec2FeatureExtractor"),mCo=o(" (Data2VecAudio model)"),gCo=l(),Iu=a("li"),Pge=a("strong"),hCo=o("data2vec-vision"),uCo=o(" \u2014 "),aG=a("a"),pCo=o("BeitFeatureExtractor"),_Co=o(" (Data2VecVision model)"),vCo=l(),Nu=a("li"),Bge=a("strong"),bCo=o("deit"),FCo=o(" \u2014 "),nG=a("a"),TCo=o("DeiTFeatureExtractor"),MCo=o(" (DeiT model)"),ECo=l(),qu=a("li"),Ige=a("strong"),CCo=o("detr"),wCo=o(" \u2014 "),sG=a("a"),ACo=o("DetrFeatureExtractor"),LCo=o(" (DETR model)"),yCo=l(),ju=a("li"),Nge=a("strong"),xCo=o("donut"),$Co=o(" \u2014 "),lG=a("a"),kCo=o("DonutFeatureExtractor"),SCo=o(" (Donut model)"),RCo=l(),Du=a("li"),qge=a("strong"),PCo=o("dpt"),BCo=o(" \u2014 "),iG=a("a"),ICo=o("DPTFeatureExtractor"),NCo=o(" (DPT model)"),qCo=l(),Gu=a("li"),jge=a("strong"),jCo=o("flava"),DCo=o(" \u2014 "),dG=a("a"),GCo=o("FlavaFeatureExtractor"),OCo=o(" (FLAVA model)"),VCo=l(),Ou=a("li"),Dge=a("strong"),XCo=o("glpn"),zCo=o(" \u2014 "),cG=a("a"),QCo=o("GLPNFeatureExtractor"),WCo=o(" (GLPN model)"),UCo=l(),Vu=a("li"),Gge=a("strong"),HCo=o("groupvit"),JCo=o(" \u2014 "),fG=a("a"),YCo=o("CLIPFeatureExtractor"),KCo=o(" (GroupViT model)"),ZCo=l(),Xu=a("li"),Oge=a("strong"),e3o=o("hubert"),o3o=o(" \u2014 "),mG=a("a"),r3o=o("Wav2Vec2FeatureExtractor"),t3o=o(" (Hubert model)"),a3o=l(),zu=a("li"),Vge=a("strong"),n3o=o("imagegpt"),s3o=o(" \u2014 "),gG=a("a"),l3o=o("ImageGPTFeatureExtractor"),i3o=o(" (ImageGPT model)"),d3o=l(),Qu=a("li"),Xge=a("strong"),c3o=o("layoutlmv2"),f3o=o(" \u2014 "),hG=a("a"),m3o=o("LayoutLMv2FeatureExtractor"),g3o=o(" (LayoutLMv2 model)"),h3o=l(),Wu=a("li"),zge=a("strong"),u3o=o("layoutlmv3"),p3o=o(" \u2014 "),uG=a("a"),_3o=o("LayoutLMv3FeatureExtractor"),v3o=o(" (LayoutLMv3 model)"),b3o=l(),Uu=a("li"),Qge=a("strong"),F3o=o("levit"),T3o=o(" \u2014 "),pG=a("a"),M3o=o("LevitFeatureExtractor"),E3o=o(" (LeViT model)"),C3o=l(),Hu=a("li"),Wge=a("strong"),w3o=o("maskformer"),A3o=o(" \u2014 "),_G=a("a"),L3o=o("MaskFormerFeatureExtractor"),y3o=o(" (MaskFormer model)"),x3o=l(),Ju=a("li"),Uge=a("strong"),$3o=o("mctct"),k3o=o(" \u2014 "),vG=a("a"),S3o=o("MCTCTFeatureExtractor"),R3o=o(" (M-CTC-T model)"),P3o=l(),Yu=a("li"),Hge=a("strong"),B3o=o("mobilevit"),I3o=o(" \u2014 "),bG=a("a"),N3o=o("MobileViTFeatureExtractor"),q3o=o(" (MobileViT model)"),j3o=l(),Ku=a("li"),Jge=a("strong"),D3o=o("owlvit"),G3o=o(" \u2014 "),FG=a("a"),O3o=o("OwlViTFeatureExtractor"),V3o=o(" (OWL-ViT model)"),X3o=l(),Zu=a("li"),Yge=a("strong"),z3o=o("perceiver"),Q3o=o(" \u2014 "),TG=a("a"),W3o=o("PerceiverFeatureExtractor"),U3o=o(" (Perceiver model)"),H3o=l(),ep=a("li"),Kge=a("strong"),J3o=o("poolformer"),Y3o=o(" \u2014 "),MG=a("a"),K3o=o("PoolFormerFeatureExtractor"),Z3o=o(" (PoolFormer model)"),e5o=l(),op=a("li"),Zge=a("strong"),o5o=o("regnet"),r5o=o(" \u2014 "),EG=a("a"),t5o=o("ConvNextFeatureExtractor"),a5o=o(" (RegNet model)"),n5o=l(),rp=a("li"),ehe=a("strong"),s5o=o("resnet"),l5o=o(" \u2014 "),CG=a("a"),i5o=o("ConvNextFeatureExtractor"),d5o=o(" (ResNet model)"),c5o=l(),tp=a("li"),ohe=a("strong"),f5o=o("segformer"),m5o=o(" \u2014 "),wG=a("a"),g5o=o("SegformerFeatureExtractor"),h5o=o(" (SegFormer model)"),u5o=l(),ap=a("li"),rhe=a("strong"),p5o=o("speech_to_text"),_5o=o(" \u2014 "),AG=a("a"),v5o=o("Speech2TextFeatureExtractor"),b5o=o(" (Speech2Text model)"),F5o=l(),np=a("li"),the=a("strong"),T5o=o("swin"),M5o=o(" \u2014 "),LG=a("a"),E5o=o("ViTFeatureExtractor"),C5o=o(" (Swin Transformer model)"),w5o=l(),sp=a("li"),ahe=a("strong"),A5o=o("swinv2"),L5o=o(" \u2014 "),yG=a("a"),y5o=o("ViTFeatureExtractor"),x5o=o(" (Swin Transformer V2 model)"),$5o=l(),lp=a("li"),nhe=a("strong"),k5o=o("van"),S5o=o(" \u2014 "),xG=a("a"),R5o=o("ConvNextFeatureExtractor"),P5o=o(" (VAN model)"),B5o=l(),ip=a("li"),she=a("strong"),I5o=o("videomae"),N5o=o(" \u2014 "),$G=a("a"),q5o=o("VideoMAEFeatureExtractor"),j5o=o(" (VideoMAE model)"),D5o=l(),dp=a("li"),lhe=a("strong"),G5o=o("vilt"),O5o=o(" \u2014 "),kG=a("a"),V5o=o("ViltFeatureExtractor"),X5o=o(" (ViLT model)"),z5o=l(),cp=a("li"),ihe=a("strong"),Q5o=o("vit"),W5o=o(" \u2014 "),SG=a("a"),U5o=o("ViTFeatureExtractor"),H5o=o(" (ViT model)"),J5o=l(),fp=a("li"),dhe=a("strong"),Y5o=o("vit_mae"),K5o=o(" \u2014 "),RG=a("a"),Z5o=o("ViTFeatureExtractor"),e0o=o(" (ViTMAE model)"),o0o=l(),mp=a("li"),che=a("strong"),r0o=o("wav2vec2"),t0o=o(" \u2014 "),PG=a("a"),a0o=o("Wav2Vec2FeatureExtractor"),n0o=o(" (Wav2Vec2 model)"),s0o=l(),gp=a("li"),fhe=a("strong"),l0o=o("wav2vec2-conformer"),i0o=o(" \u2014 "),BG=a("a"),d0o=o("Wav2Vec2FeatureExtractor"),c0o=o(" (Wav2Vec2-Conformer model)"),f0o=l(),hp=a("li"),mhe=a("strong"),m0o=o("xclip"),g0o=o(" \u2014 "),IG=a("a"),h0o=o("CLIPFeatureExtractor"),u0o=o(" (X-CLIP model)"),p0o=l(),up=a("li"),ghe=a("strong"),_0o=o("yolos"),v0o=o(" \u2014 "),NG=a("a"),b0o=o("YolosFeatureExtractor"),F0o=o(" (YOLOS model)"),T0o=l(),F(pp.$$.fragment),M0o=l(),F(_p.$$.fragment),E0o=l(),vp=a("div"),F(O9.$$.fragment),C0o=l(),hhe=a("p"),w0o=o("Register a new feature extractor for this class."),OYe=l(),hd=a("h2"),bp=a("a"),uhe=a("span"),F(V9.$$.fragment),A0o=l(),phe=a("span"),L0o=o("AutoProcessor"),VYe=l(),Ro=a("div"),F(X9.$$.fragment),y0o=l(),z9=a("p"),x0o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qG=a("a"),$0o=o("AutoProcessor.from_pretrained()"),k0o=o(" class method."),S0o=l(),Q9=a("p"),R0o=o("This class cannot be instantiated directly using "),_he=a("code"),P0o=o("__init__()"),B0o=o(" (throws an error)."),I0o=l(),Ke=a("div"),F(W9.$$.fragment),N0o=l(),vhe=a("p"),q0o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),j0o=l(),ud=a("p"),D0o=o("The processor class to instantiate is selected based on the "),bhe=a("code"),G0o=o("model_type"),O0o=o(` property of the config object (either
passed as an argument or loaded from `),Fhe=a("code"),V0o=o("pretrained_model_name_or_path"),X0o=o(" if possible):"),z0o=l(),ie=a("ul"),Fp=a("li"),The=a("strong"),Q0o=o("clip"),W0o=o(" \u2014 "),jG=a("a"),U0o=o("CLIPProcessor"),H0o=o(" (CLIP model)"),J0o=l(),Tp=a("li"),Mhe=a("strong"),Y0o=o("donut"),K0o=o(" \u2014 "),DG=a("a"),Z0o=o("DonutProcessor"),ewo=o(" (Donut model)"),owo=l(),Mp=a("li"),Ehe=a("strong"),rwo=o("flava"),two=o(" \u2014 "),GG=a("a"),awo=o("FlavaProcessor"),nwo=o(" (FLAVA model)"),swo=l(),Ep=a("li"),Che=a("strong"),lwo=o("groupvit"),iwo=o(" \u2014 "),OG=a("a"),dwo=o("CLIPProcessor"),cwo=o(" (GroupViT model)"),fwo=l(),Cp=a("li"),whe=a("strong"),mwo=o("layoutlmv2"),gwo=o(" \u2014 "),VG=a("a"),hwo=o("LayoutLMv2Processor"),uwo=o(" (LayoutLMv2 model)"),pwo=l(),wp=a("li"),Ahe=a("strong"),_wo=o("layoutlmv3"),vwo=o(" \u2014 "),XG=a("a"),bwo=o("LayoutLMv3Processor"),Fwo=o(" (LayoutLMv3 model)"),Two=l(),Ap=a("li"),Lhe=a("strong"),Mwo=o("layoutxlm"),Ewo=o(" \u2014 "),zG=a("a"),Cwo=o("LayoutXLMProcessor"),wwo=o(" (LayoutXLM model)"),Awo=l(),Lp=a("li"),yhe=a("strong"),Lwo=o("owlvit"),ywo=o(" \u2014 "),QG=a("a"),xwo=o("OwlViTProcessor"),$wo=o(" (OWL-ViT model)"),kwo=l(),yp=a("li"),xhe=a("strong"),Swo=o("sew"),Rwo=o(" \u2014 "),WG=a("a"),Pwo=o("Wav2Vec2Processor"),Bwo=o(" (SEW model)"),Iwo=l(),xp=a("li"),$he=a("strong"),Nwo=o("sew-d"),qwo=o(" \u2014 "),UG=a("a"),jwo=o("Wav2Vec2Processor"),Dwo=o(" (SEW-D model)"),Gwo=l(),$p=a("li"),khe=a("strong"),Owo=o("speech_to_text"),Vwo=o(" \u2014 "),HG=a("a"),Xwo=o("Speech2TextProcessor"),zwo=o(" (Speech2Text model)"),Qwo=l(),kp=a("li"),She=a("strong"),Wwo=o("speech_to_text_2"),Uwo=o(" \u2014 "),JG=a("a"),Hwo=o("Speech2Text2Processor"),Jwo=o(" (Speech2Text2 model)"),Ywo=l(),Sp=a("li"),Rhe=a("strong"),Kwo=o("trocr"),Zwo=o(" \u2014 "),YG=a("a"),eAo=o("TrOCRProcessor"),oAo=o(" (TrOCR model)"),rAo=l(),Rp=a("li"),Phe=a("strong"),tAo=o("unispeech"),aAo=o(" \u2014 "),KG=a("a"),nAo=o("Wav2Vec2Processor"),sAo=o(" (UniSpeech model)"),lAo=l(),Pp=a("li"),Bhe=a("strong"),iAo=o("unispeech-sat"),dAo=o(" \u2014 "),ZG=a("a"),cAo=o("Wav2Vec2Processor"),fAo=o(" (UniSpeechSat model)"),mAo=l(),Bp=a("li"),Ihe=a("strong"),gAo=o("vilt"),hAo=o(" \u2014 "),eO=a("a"),uAo=o("ViltProcessor"),pAo=o(" (ViLT model)"),_Ao=l(),Ip=a("li"),Nhe=a("strong"),vAo=o("vision-text-dual-encoder"),bAo=o(" \u2014 "),oO=a("a"),FAo=o("VisionTextDualEncoderProcessor"),TAo=o(" (VisionTextDualEncoder model)"),MAo=l(),Np=a("li"),qhe=a("strong"),EAo=o("wav2vec2"),CAo=o(" \u2014 "),rO=a("a"),wAo=o("Wav2Vec2Processor"),AAo=o(" (Wav2Vec2 model)"),LAo=l(),qp=a("li"),jhe=a("strong"),yAo=o("wav2vec2-conformer"),xAo=o(" \u2014 "),tO=a("a"),$Ao=o("Wav2Vec2Processor"),kAo=o(" (Wav2Vec2-Conformer model)"),SAo=l(),jp=a("li"),Dhe=a("strong"),RAo=o("wavlm"),PAo=o(" \u2014 "),aO=a("a"),BAo=o("Wav2Vec2Processor"),IAo=o(" (WavLM model)"),NAo=l(),Dp=a("li"),Ghe=a("strong"),qAo=o("xclip"),jAo=o(" \u2014 "),nO=a("a"),DAo=o("CLIPProcessor"),GAo=o(" (X-CLIP model)"),OAo=l(),F(Gp.$$.fragment),VAo=l(),F(Op.$$.fragment),XAo=l(),Vp=a("div"),F(U9.$$.fragment),zAo=l(),Ohe=a("p"),QAo=o("Register a new processor for this class."),XYe=l(),pd=a("h2"),Xp=a("a"),Vhe=a("span"),F(H9.$$.fragment),WAo=l(),Xhe=a("span"),UAo=o("AutoModel"),zYe=l(),Po=a("div"),F(J9.$$.fragment),HAo=l(),_d=a("p"),JAo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sO=a("a"),YAo=o("from_pretrained()"),KAo=o(" class method or the "),lO=a("a"),ZAo=o("from_config()"),e6o=o(` class
method.`),o6o=l(),Y9=a("p"),r6o=o("This class cannot be instantiated directly using "),zhe=a("code"),t6o=o("__init__()"),a6o=o(" (throws an error)."),n6o=l(),_t=a("div"),F(K9.$$.fragment),s6o=l(),Qhe=a("p"),l6o=o("Instantiates one of the base model classes of the library from a configuration."),i6o=l(),vd=a("p"),d6o=o(`Note:
Loading a model from its configuration file does `),Whe=a("strong"),c6o=o("not"),f6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=a("a"),m6o=o("from_pretrained()"),g6o=o(" to load the model weights."),h6o=l(),F(zp.$$.fragment),u6o=l(),Ze=a("div"),F(Z9.$$.fragment),p6o=l(),Uhe=a("p"),_6o=o("Instantiate one of the base model classes of the library from a pretrained model."),v6o=l(),Ja=a("p"),b6o=o("The model class to instantiate is selected based on the "),Hhe=a("code"),F6o=o("model_type"),T6o=o(` property of the config object (either
passed as an argument or loaded from `),Jhe=a("code"),M6o=o("pretrained_model_name_or_path"),E6o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=a("code"),C6o=o("pretrained_model_name_or_path"),w6o=o(":"),A6o=l(),y=a("ul"),Qp=a("li"),Khe=a("strong"),L6o=o("albert"),y6o=o(" \u2014 "),dO=a("a"),x6o=o("AlbertModel"),$6o=o(" (ALBERT model)"),k6o=l(),Wp=a("li"),Zhe=a("strong"),S6o=o("bart"),R6o=o(" \u2014 "),cO=a("a"),P6o=o("BartModel"),B6o=o(" (BART model)"),I6o=l(),Up=a("li"),eue=a("strong"),N6o=o("beit"),q6o=o(" \u2014 "),fO=a("a"),j6o=o("BeitModel"),D6o=o(" (BEiT model)"),G6o=l(),Hp=a("li"),oue=a("strong"),O6o=o("bert"),V6o=o(" \u2014 "),mO=a("a"),X6o=o("BertModel"),z6o=o(" (BERT model)"),Q6o=l(),Jp=a("li"),rue=a("strong"),W6o=o("bert-generation"),U6o=o(" \u2014 "),gO=a("a"),H6o=o("BertGenerationEncoder"),J6o=o(" (Bert Generation model)"),Y6o=l(),Yp=a("li"),tue=a("strong"),K6o=o("big_bird"),Z6o=o(" \u2014 "),hO=a("a"),e7o=o("BigBirdModel"),o7o=o(" (BigBird model)"),r7o=l(),Kp=a("li"),aue=a("strong"),t7o=o("bigbird_pegasus"),a7o=o(" \u2014 "),uO=a("a"),n7o=o("BigBirdPegasusModel"),s7o=o(" (BigBird-Pegasus model)"),l7o=l(),Zp=a("li"),nue=a("strong"),i7o=o("blenderbot"),d7o=o(" \u2014 "),pO=a("a"),c7o=o("BlenderbotModel"),f7o=o(" (Blenderbot model)"),m7o=l(),e_=a("li"),sue=a("strong"),g7o=o("blenderbot-small"),h7o=o(" \u2014 "),_O=a("a"),u7o=o("BlenderbotSmallModel"),p7o=o(" (BlenderbotSmall model)"),_7o=l(),o_=a("li"),lue=a("strong"),v7o=o("bloom"),b7o=o(" \u2014 "),vO=a("a"),F7o=o("BloomModel"),T7o=o(" (BLOOM model)"),M7o=l(),r_=a("li"),iue=a("strong"),E7o=o("camembert"),C7o=o(" \u2014 "),bO=a("a"),w7o=o("CamembertModel"),A7o=o(" (CamemBERT model)"),L7o=l(),t_=a("li"),due=a("strong"),y7o=o("canine"),x7o=o(" \u2014 "),FO=a("a"),$7o=o("CanineModel"),k7o=o(" (CANINE model)"),S7o=l(),a_=a("li"),cue=a("strong"),R7o=o("clip"),P7o=o(" \u2014 "),TO=a("a"),B7o=o("CLIPModel"),I7o=o(" (CLIP model)"),N7o=l(),n_=a("li"),fue=a("strong"),q7o=o("codegen"),j7o=o(" \u2014 "),MO=a("a"),D7o=o("CodeGenModel"),G7o=o(" (CodeGen model)"),O7o=l(),s_=a("li"),mue=a("strong"),V7o=o("convbert"),X7o=o(" \u2014 "),EO=a("a"),z7o=o("ConvBertModel"),Q7o=o(" (ConvBERT model)"),W7o=l(),l_=a("li"),gue=a("strong"),U7o=o("convnext"),H7o=o(" \u2014 "),CO=a("a"),J7o=o("ConvNextModel"),Y7o=o(" (ConvNeXT model)"),K7o=l(),i_=a("li"),hue=a("strong"),Z7o=o("ctrl"),eLo=o(" \u2014 "),wO=a("a"),oLo=o("CTRLModel"),rLo=o(" (CTRL model)"),tLo=l(),d_=a("li"),uue=a("strong"),aLo=o("cvt"),nLo=o(" \u2014 "),AO=a("a"),sLo=o("CvtModel"),lLo=o(" (CvT model)"),iLo=l(),c_=a("li"),pue=a("strong"),dLo=o("data2vec-audio"),cLo=o(" \u2014 "),LO=a("a"),fLo=o("Data2VecAudioModel"),mLo=o(" (Data2VecAudio model)"),gLo=l(),f_=a("li"),_ue=a("strong"),hLo=o("data2vec-text"),uLo=o(" \u2014 "),yO=a("a"),pLo=o("Data2VecTextModel"),_Lo=o(" (Data2VecText model)"),vLo=l(),m_=a("li"),vue=a("strong"),bLo=o("data2vec-vision"),FLo=o(" \u2014 "),xO=a("a"),TLo=o("Data2VecVisionModel"),MLo=o(" (Data2VecVision model)"),ELo=l(),g_=a("li"),bue=a("strong"),CLo=o("deberta"),wLo=o(" \u2014 "),$O=a("a"),ALo=o("DebertaModel"),LLo=o(" (DeBERTa model)"),yLo=l(),h_=a("li"),Fue=a("strong"),xLo=o("deberta-v2"),$Lo=o(" \u2014 "),kO=a("a"),kLo=o("DebertaV2Model"),SLo=o(" (DeBERTa-v2 model)"),RLo=l(),u_=a("li"),Tue=a("strong"),PLo=o("decision_transformer"),BLo=o(" \u2014 "),SO=a("a"),ILo=o("DecisionTransformerModel"),NLo=o(" (Decision Transformer model)"),qLo=l(),p_=a("li"),Mue=a("strong"),jLo=o("deit"),DLo=o(" \u2014 "),RO=a("a"),GLo=o("DeiTModel"),OLo=o(" (DeiT model)"),VLo=l(),__=a("li"),Eue=a("strong"),XLo=o("detr"),zLo=o(" \u2014 "),PO=a("a"),QLo=o("DetrModel"),WLo=o(" (DETR model)"),ULo=l(),v_=a("li"),Cue=a("strong"),HLo=o("distilbert"),JLo=o(" \u2014 "),BO=a("a"),YLo=o("DistilBertModel"),KLo=o(" (DistilBERT model)"),ZLo=l(),b_=a("li"),wue=a("strong"),eyo=o("donut-swin"),oyo=o(" \u2014 "),IO=a("a"),ryo=o("DonutSwinModel"),tyo=o(" (DonutSwin model)"),ayo=l(),F_=a("li"),Aue=a("strong"),nyo=o("dpr"),syo=o(" \u2014 "),NO=a("a"),lyo=o("DPRQuestionEncoder"),iyo=o(" (DPR model)"),dyo=l(),T_=a("li"),Lue=a("strong"),cyo=o("dpt"),fyo=o(" \u2014 "),qO=a("a"),myo=o("DPTModel"),gyo=o(" (DPT model)"),hyo=l(),M_=a("li"),yue=a("strong"),uyo=o("electra"),pyo=o(" \u2014 "),jO=a("a"),_yo=o("ElectraModel"),vyo=o(" (ELECTRA model)"),byo=l(),E_=a("li"),xue=a("strong"),Fyo=o("ernie"),Tyo=o(" \u2014 "),DO=a("a"),Myo=o("ErnieModel"),Eyo=o(" (ERNIE model)"),Cyo=l(),C_=a("li"),$ue=a("strong"),wyo=o("flaubert"),Ayo=o(" \u2014 "),GO=a("a"),Lyo=o("FlaubertModel"),yyo=o(" (FlauBERT model)"),xyo=l(),w_=a("li"),kue=a("strong"),$yo=o("flava"),kyo=o(" \u2014 "),OO=a("a"),Syo=o("FlavaModel"),Ryo=o(" (FLAVA model)"),Pyo=l(),A_=a("li"),Sue=a("strong"),Byo=o("fnet"),Iyo=o(" \u2014 "),VO=a("a"),Nyo=o("FNetModel"),qyo=o(" (FNet model)"),jyo=l(),L_=a("li"),Rue=a("strong"),Dyo=o("fsmt"),Gyo=o(" \u2014 "),XO=a("a"),Oyo=o("FSMTModel"),Vyo=o(" (FairSeq Machine-Translation model)"),Xyo=l(),pl=a("li"),Pue=a("strong"),zyo=o("funnel"),Qyo=o(" \u2014 "),zO=a("a"),Wyo=o("FunnelModel"),Uyo=o(" or "),QO=a("a"),Hyo=o("FunnelBaseModel"),Jyo=o(" (Funnel Transformer model)"),Yyo=l(),y_=a("li"),Bue=a("strong"),Kyo=o("glpn"),Zyo=o(" \u2014 "),WO=a("a"),e8o=o("GLPNModel"),o8o=o(" (GLPN model)"),r8o=l(),x_=a("li"),Iue=a("strong"),t8o=o("gpt2"),a8o=o(" \u2014 "),UO=a("a"),n8o=o("GPT2Model"),s8o=o(" (OpenAI GPT-2 model)"),l8o=l(),$_=a("li"),Nue=a("strong"),i8o=o("gpt_neo"),d8o=o(" \u2014 "),HO=a("a"),c8o=o("GPTNeoModel"),f8o=o(" (GPT Neo model)"),m8o=l(),k_=a("li"),que=a("strong"),g8o=o("gpt_neox"),h8o=o(" \u2014 "),JO=a("a"),u8o=o("GPTNeoXModel"),p8o=o(" (GPT NeoX model)"),_8o=l(),S_=a("li"),jue=a("strong"),v8o=o("gptj"),b8o=o(" \u2014 "),YO=a("a"),F8o=o("GPTJModel"),T8o=o(" (GPT-J model)"),M8o=l(),R_=a("li"),Due=a("strong"),E8o=o("groupvit"),C8o=o(" \u2014 "),KO=a("a"),w8o=o("GroupViTModel"),A8o=o(" (GroupViT model)"),L8o=l(),P_=a("li"),Gue=a("strong"),y8o=o("hubert"),x8o=o(" \u2014 "),ZO=a("a"),$8o=o("HubertModel"),k8o=o(" (Hubert model)"),S8o=l(),B_=a("li"),Oue=a("strong"),R8o=o("ibert"),P8o=o(" \u2014 "),eV=a("a"),B8o=o("IBertModel"),I8o=o(" (I-BERT model)"),N8o=l(),I_=a("li"),Vue=a("strong"),q8o=o("imagegpt"),j8o=o(" \u2014 "),oV=a("a"),D8o=o("ImageGPTModel"),G8o=o(" (ImageGPT model)"),O8o=l(),N_=a("li"),Xue=a("strong"),V8o=o("layoutlm"),X8o=o(" \u2014 "),rV=a("a"),z8o=o("LayoutLMModel"),Q8o=o(" (LayoutLM model)"),W8o=l(),q_=a("li"),zue=a("strong"),U8o=o("layoutlmv2"),H8o=o(" \u2014 "),tV=a("a"),J8o=o("LayoutLMv2Model"),Y8o=o(" (LayoutLMv2 model)"),K8o=l(),j_=a("li"),Que=a("strong"),Z8o=o("layoutlmv3"),e9o=o(" \u2014 "),aV=a("a"),o9o=o("LayoutLMv3Model"),r9o=o(" (LayoutLMv3 model)"),t9o=l(),D_=a("li"),Wue=a("strong"),a9o=o("led"),n9o=o(" \u2014 "),nV=a("a"),s9o=o("LEDModel"),l9o=o(" (LED model)"),i9o=l(),G_=a("li"),Uue=a("strong"),d9o=o("levit"),c9o=o(" \u2014 "),sV=a("a"),f9o=o("LevitModel"),m9o=o(" (LeViT model)"),g9o=l(),O_=a("li"),Hue=a("strong"),h9o=o("longformer"),u9o=o(" \u2014 "),lV=a("a"),p9o=o("LongformerModel"),_9o=o(" (Longformer model)"),v9o=l(),V_=a("li"),Jue=a("strong"),b9o=o("longt5"),F9o=o(" \u2014 "),iV=a("a"),T9o=o("LongT5Model"),M9o=o(" (LongT5 model)"),E9o=l(),X_=a("li"),Yue=a("strong"),C9o=o("luke"),w9o=o(" \u2014 "),dV=a("a"),A9o=o("LukeModel"),L9o=o(" (LUKE model)"),y9o=l(),z_=a("li"),Kue=a("strong"),x9o=o("lxmert"),$9o=o(" \u2014 "),cV=a("a"),k9o=o("LxmertModel"),S9o=o(" (LXMERT model)"),R9o=l(),Q_=a("li"),Zue=a("strong"),P9o=o("m2m_100"),B9o=o(" \u2014 "),fV=a("a"),I9o=o("M2M100Model"),N9o=o(" (M2M100 model)"),q9o=l(),W_=a("li"),epe=a("strong"),j9o=o("marian"),D9o=o(" \u2014 "),mV=a("a"),G9o=o("MarianModel"),O9o=o(" (Marian model)"),V9o=l(),U_=a("li"),ope=a("strong"),X9o=o("maskformer"),z9o=o(" \u2014 "),gV=a("a"),Q9o=o("MaskFormerModel"),W9o=o(" (MaskFormer model)"),U9o=l(),H_=a("li"),rpe=a("strong"),H9o=o("mbart"),J9o=o(" \u2014 "),hV=a("a"),Y9o=o("MBartModel"),K9o=o(" (mBART model)"),Z9o=l(),J_=a("li"),tpe=a("strong"),exo=o("mctct"),oxo=o(" \u2014 "),uV=a("a"),rxo=o("MCTCTModel"),txo=o(" (M-CTC-T model)"),axo=l(),Y_=a("li"),ape=a("strong"),nxo=o("megatron-bert"),sxo=o(" \u2014 "),pV=a("a"),lxo=o("MegatronBertModel"),ixo=o(" (Megatron-BERT model)"),dxo=l(),K_=a("li"),npe=a("strong"),cxo=o("mobilebert"),fxo=o(" \u2014 "),_V=a("a"),mxo=o("MobileBertModel"),gxo=o(" (MobileBERT model)"),hxo=l(),Z_=a("li"),spe=a("strong"),uxo=o("mobilevit"),pxo=o(" \u2014 "),vV=a("a"),_xo=o("MobileViTModel"),vxo=o(" (MobileViT model)"),bxo=l(),e2=a("li"),lpe=a("strong"),Fxo=o("mpnet"),Txo=o(" \u2014 "),bV=a("a"),Mxo=o("MPNetModel"),Exo=o(" (MPNet model)"),Cxo=l(),o2=a("li"),ipe=a("strong"),wxo=o("mt5"),Axo=o(" \u2014 "),FV=a("a"),Lxo=o("MT5Model"),yxo=o(" (MT5 model)"),xxo=l(),r2=a("li"),dpe=a("strong"),$xo=o("mvp"),kxo=o(" \u2014 "),TV=a("a"),Sxo=o("MvpModel"),Rxo=o(" (MVP model)"),Pxo=l(),t2=a("li"),cpe=a("strong"),Bxo=o("nezha"),Ixo=o(" \u2014 "),MV=a("a"),Nxo=o("NezhaModel"),qxo=o(" (Nezha model)"),jxo=l(),a2=a("li"),fpe=a("strong"),Dxo=o("nllb"),Gxo=o(" \u2014 "),EV=a("a"),Oxo=o("M2M100Model"),Vxo=o(" (NLLB model)"),Xxo=l(),n2=a("li"),mpe=a("strong"),zxo=o("nystromformer"),Qxo=o(" \u2014 "),CV=a("a"),Wxo=o("NystromformerModel"),Uxo=o(" (Nystr\xF6mformer model)"),Hxo=l(),s2=a("li"),gpe=a("strong"),Jxo=o("openai-gpt"),Yxo=o(" \u2014 "),wV=a("a"),Kxo=o("OpenAIGPTModel"),Zxo=o(" (OpenAI GPT model)"),e$o=l(),l2=a("li"),hpe=a("strong"),o$o=o("opt"),r$o=o(" \u2014 "),AV=a("a"),t$o=o("OPTModel"),a$o=o(" (OPT model)"),n$o=l(),i2=a("li"),upe=a("strong"),s$o=o("owlvit"),l$o=o(" \u2014 "),LV=a("a"),i$o=o("OwlViTModel"),d$o=o(" (OWL-ViT model)"),c$o=l(),d2=a("li"),ppe=a("strong"),f$o=o("pegasus"),m$o=o(" \u2014 "),yV=a("a"),g$o=o("PegasusModel"),h$o=o(" (Pegasus model)"),u$o=l(),c2=a("li"),_pe=a("strong"),p$o=o("pegasus_x"),_$o=o(" \u2014 "),xV=a("a"),v$o=o("PegasusXModel"),b$o=o(" (PEGASUS-X model)"),F$o=l(),f2=a("li"),vpe=a("strong"),T$o=o("perceiver"),M$o=o(" \u2014 "),$V=a("a"),E$o=o("PerceiverModel"),C$o=o(" (Perceiver model)"),w$o=l(),m2=a("li"),bpe=a("strong"),A$o=o("plbart"),L$o=o(" \u2014 "),kV=a("a"),y$o=o("PLBartModel"),x$o=o(" (PLBart model)"),$$o=l(),g2=a("li"),Fpe=a("strong"),k$o=o("poolformer"),S$o=o(" \u2014 "),SV=a("a"),R$o=o("PoolFormerModel"),P$o=o(" (PoolFormer model)"),B$o=l(),h2=a("li"),Tpe=a("strong"),I$o=o("prophetnet"),N$o=o(" \u2014 "),RV=a("a"),q$o=o("ProphetNetModel"),j$o=o(" (ProphetNet model)"),D$o=l(),u2=a("li"),Mpe=a("strong"),G$o=o("qdqbert"),O$o=o(" \u2014 "),PV=a("a"),V$o=o("QDQBertModel"),X$o=o(" (QDQBert model)"),z$o=l(),p2=a("li"),Epe=a("strong"),Q$o=o("reformer"),W$o=o(" \u2014 "),BV=a("a"),U$o=o("ReformerModel"),H$o=o(" (Reformer model)"),J$o=l(),_2=a("li"),Cpe=a("strong"),Y$o=o("regnet"),K$o=o(" \u2014 "),IV=a("a"),Z$o=o("RegNetModel"),eko=o(" (RegNet model)"),oko=l(),v2=a("li"),wpe=a("strong"),rko=o("rembert"),tko=o(" \u2014 "),NV=a("a"),ako=o("RemBertModel"),nko=o(" (RemBERT model)"),sko=l(),b2=a("li"),Ape=a("strong"),lko=o("resnet"),iko=o(" \u2014 "),qV=a("a"),dko=o("ResNetModel"),cko=o(" (ResNet model)"),fko=l(),F2=a("li"),Lpe=a("strong"),mko=o("retribert"),gko=o(" \u2014 "),jV=a("a"),hko=o("RetriBertModel"),uko=o(" (RetriBERT model)"),pko=l(),T2=a("li"),ype=a("strong"),_ko=o("roberta"),vko=o(" \u2014 "),DV=a("a"),bko=o("RobertaModel"),Fko=o(" (RoBERTa model)"),Tko=l(),M2=a("li"),xpe=a("strong"),Mko=o("roformer"),Eko=o(" \u2014 "),GV=a("a"),Cko=o("RoFormerModel"),wko=o(" (RoFormer model)"),Ako=l(),E2=a("li"),$pe=a("strong"),Lko=o("segformer"),yko=o(" \u2014 "),OV=a("a"),xko=o("SegformerModel"),$ko=o(" (SegFormer model)"),kko=l(),C2=a("li"),kpe=a("strong"),Sko=o("sew"),Rko=o(" \u2014 "),VV=a("a"),Pko=o("SEWModel"),Bko=o(" (SEW model)"),Iko=l(),w2=a("li"),Spe=a("strong"),Nko=o("sew-d"),qko=o(" \u2014 "),XV=a("a"),jko=o("SEWDModel"),Dko=o(" (SEW-D model)"),Gko=l(),A2=a("li"),Rpe=a("strong"),Oko=o("speech_to_text"),Vko=o(" \u2014 "),zV=a("a"),Xko=o("Speech2TextModel"),zko=o(" (Speech2Text model)"),Qko=l(),L2=a("li"),Ppe=a("strong"),Wko=o("splinter"),Uko=o(" \u2014 "),QV=a("a"),Hko=o("SplinterModel"),Jko=o(" (Splinter model)"),Yko=l(),y2=a("li"),Bpe=a("strong"),Kko=o("squeezebert"),Zko=o(" \u2014 "),WV=a("a"),eSo=o("SqueezeBertModel"),oSo=o(" (SqueezeBERT model)"),rSo=l(),x2=a("li"),Ipe=a("strong"),tSo=o("swin"),aSo=o(" \u2014 "),UV=a("a"),nSo=o("SwinModel"),sSo=o(" (Swin Transformer model)"),lSo=l(),$2=a("li"),Npe=a("strong"),iSo=o("swinv2"),dSo=o(" \u2014 "),HV=a("a"),cSo=o("Swinv2Model"),fSo=o(" (Swin Transformer V2 model)"),mSo=l(),k2=a("li"),qpe=a("strong"),gSo=o("t5"),hSo=o(" \u2014 "),JV=a("a"),uSo=o("T5Model"),pSo=o(" (T5 model)"),_So=l(),S2=a("li"),jpe=a("strong"),vSo=o("tapas"),bSo=o(" \u2014 "),YV=a("a"),FSo=o("TapasModel"),TSo=o(" (TAPAS model)"),MSo=l(),R2=a("li"),Dpe=a("strong"),ESo=o("trajectory_transformer"),CSo=o(" \u2014 "),KV=a("a"),wSo=o("TrajectoryTransformerModel"),ASo=o(" (Trajectory Transformer model)"),LSo=l(),P2=a("li"),Gpe=a("strong"),ySo=o("transfo-xl"),xSo=o(" \u2014 "),ZV=a("a"),$So=o("TransfoXLModel"),kSo=o(" (Transformer-XL model)"),SSo=l(),B2=a("li"),Ope=a("strong"),RSo=o("unispeech"),PSo=o(" \u2014 "),eX=a("a"),BSo=o("UniSpeechModel"),ISo=o(" (UniSpeech model)"),NSo=l(),I2=a("li"),Vpe=a("strong"),qSo=o("unispeech-sat"),jSo=o(" \u2014 "),oX=a("a"),DSo=o("UniSpeechSatModel"),GSo=o(" (UniSpeechSat model)"),OSo=l(),N2=a("li"),Xpe=a("strong"),VSo=o("van"),XSo=o(" \u2014 "),rX=a("a"),zSo=o("VanModel"),QSo=o(" (VAN model)"),WSo=l(),q2=a("li"),zpe=a("strong"),USo=o("videomae"),HSo=o(" \u2014 "),tX=a("a"),JSo=o("VideoMAEModel"),YSo=o(" (VideoMAE model)"),KSo=l(),j2=a("li"),Qpe=a("strong"),ZSo=o("vilt"),eRo=o(" \u2014 "),aX=a("a"),oRo=o("ViltModel"),rRo=o(" (ViLT model)"),tRo=l(),D2=a("li"),Wpe=a("strong"),aRo=o("vision-text-dual-encoder"),nRo=o(" \u2014 "),nX=a("a"),sRo=o("VisionTextDualEncoderModel"),lRo=o(" (VisionTextDualEncoder model)"),iRo=l(),G2=a("li"),Upe=a("strong"),dRo=o("visual_bert"),cRo=o(" \u2014 "),sX=a("a"),fRo=o("VisualBertModel"),mRo=o(" (VisualBERT model)"),gRo=l(),O2=a("li"),Hpe=a("strong"),hRo=o("vit"),uRo=o(" \u2014 "),lX=a("a"),pRo=o("ViTModel"),_Ro=o(" (ViT model)"),vRo=l(),V2=a("li"),Jpe=a("strong"),bRo=o("vit_mae"),FRo=o(" \u2014 "),iX=a("a"),TRo=o("ViTMAEModel"),MRo=o(" (ViTMAE model)"),ERo=l(),X2=a("li"),Ype=a("strong"),CRo=o("wav2vec2"),wRo=o(" \u2014 "),dX=a("a"),ARo=o("Wav2Vec2Model"),LRo=o(" (Wav2Vec2 model)"),yRo=l(),z2=a("li"),Kpe=a("strong"),xRo=o("wav2vec2-conformer"),$Ro=o(" \u2014 "),cX=a("a"),kRo=o("Wav2Vec2ConformerModel"),SRo=o(" (Wav2Vec2-Conformer model)"),RRo=l(),Q2=a("li"),Zpe=a("strong"),PRo=o("wavlm"),BRo=o(" \u2014 "),fX=a("a"),IRo=o("WavLMModel"),NRo=o(" (WavLM model)"),qRo=l(),W2=a("li"),e_e=a("strong"),jRo=o("xclip"),DRo=o(" \u2014 "),mX=a("a"),GRo=o("XCLIPModel"),ORo=o(" (X-CLIP model)"),VRo=l(),U2=a("li"),o_e=a("strong"),XRo=o("xglm"),zRo=o(" \u2014 "),gX=a("a"),QRo=o("XGLMModel"),WRo=o(" (XGLM model)"),URo=l(),H2=a("li"),r_e=a("strong"),HRo=o("xlm"),JRo=o(" \u2014 "),hX=a("a"),YRo=o("XLMModel"),KRo=o(" (XLM model)"),ZRo=l(),J2=a("li"),t_e=a("strong"),ePo=o("xlm-prophetnet"),oPo=o(" \u2014 "),uX=a("a"),rPo=o("XLMProphetNetModel"),tPo=o(" (XLM-ProphetNet model)"),aPo=l(),Y2=a("li"),a_e=a("strong"),nPo=o("xlm-roberta"),sPo=o(" \u2014 "),pX=a("a"),lPo=o("XLMRobertaModel"),iPo=o(" (XLM-RoBERTa model)"),dPo=l(),K2=a("li"),n_e=a("strong"),cPo=o("xlm-roberta-xl"),fPo=o(" \u2014 "),_X=a("a"),mPo=o("XLMRobertaXLModel"),gPo=o(" (XLM-RoBERTa-XL model)"),hPo=l(),Z2=a("li"),s_e=a("strong"),uPo=o("xlnet"),pPo=o(" \u2014 "),vX=a("a"),_Po=o("XLNetModel"),vPo=o(" (XLNet model)"),bPo=l(),ev=a("li"),l_e=a("strong"),FPo=o("yolos"),TPo=o(" \u2014 "),bX=a("a"),MPo=o("YolosModel"),EPo=o(" (YOLOS model)"),CPo=l(),ov=a("li"),i_e=a("strong"),wPo=o("yoso"),APo=o(" \u2014 "),FX=a("a"),LPo=o("YosoModel"),yPo=o(" (YOSO model)"),xPo=l(),rv=a("p"),$Po=o("The model is set in evaluation mode by default using "),d_e=a("code"),kPo=o("model.eval()"),SPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=a("code"),RPo=o("model.train()"),PPo=l(),F(tv.$$.fragment),QYe=l(),bd=a("h2"),av=a("a"),f_e=a("span"),F(ex.$$.fragment),BPo=l(),m_e=a("span"),IPo=o("AutoModelForPreTraining"),WYe=l(),Bo=a("div"),F(ox.$$.fragment),NPo=l(),Fd=a("p"),qPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TX=a("a"),jPo=o("from_pretrained()"),DPo=o(" class method or the "),MX=a("a"),GPo=o("from_config()"),OPo=o(` class
method.`),VPo=l(),rx=a("p"),XPo=o("This class cannot be instantiated directly using "),g_e=a("code"),zPo=o("__init__()"),QPo=o(" (throws an error)."),WPo=l(),vt=a("div"),F(tx.$$.fragment),UPo=l(),h_e=a("p"),HPo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),JPo=l(),Td=a("p"),YPo=o(`Note:
Loading a model from its configuration file does `),u_e=a("strong"),KPo=o("not"),ZPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=a("a"),eBo=o("from_pretrained()"),oBo=o(" to load the model weights."),rBo=l(),F(nv.$$.fragment),tBo=l(),eo=a("div"),F(ax.$$.fragment),aBo=l(),p_e=a("p"),nBo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),sBo=l(),Ya=a("p"),lBo=o("The model class to instantiate is selected based on the "),__e=a("code"),iBo=o("model_type"),dBo=o(` property of the config object (either
passed as an argument or loaded from `),v_e=a("code"),cBo=o("pretrained_model_name_or_path"),fBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=a("code"),mBo=o("pretrained_model_name_or_path"),gBo=o(":"),hBo=l(),G=a("ul"),sv=a("li"),F_e=a("strong"),uBo=o("albert"),pBo=o(" \u2014 "),CX=a("a"),_Bo=o("AlbertForPreTraining"),vBo=o(" (ALBERT model)"),bBo=l(),lv=a("li"),T_e=a("strong"),FBo=o("bart"),TBo=o(" \u2014 "),wX=a("a"),MBo=o("BartForConditionalGeneration"),EBo=o(" (BART model)"),CBo=l(),iv=a("li"),M_e=a("strong"),wBo=o("bert"),ABo=o(" \u2014 "),AX=a("a"),LBo=o("BertForPreTraining"),yBo=o(" (BERT model)"),xBo=l(),dv=a("li"),E_e=a("strong"),$Bo=o("big_bird"),kBo=o(" \u2014 "),LX=a("a"),SBo=o("BigBirdForPreTraining"),RBo=o(" (BigBird model)"),PBo=l(),cv=a("li"),C_e=a("strong"),BBo=o("bloom"),IBo=o(" \u2014 "),yX=a("a"),NBo=o("BloomForCausalLM"),qBo=o(" (BLOOM model)"),jBo=l(),fv=a("li"),w_e=a("strong"),DBo=o("camembert"),GBo=o(" \u2014 "),xX=a("a"),OBo=o("CamembertForMaskedLM"),VBo=o(" (CamemBERT model)"),XBo=l(),mv=a("li"),A_e=a("strong"),zBo=o("ctrl"),QBo=o(" \u2014 "),$X=a("a"),WBo=o("CTRLLMHeadModel"),UBo=o(" (CTRL model)"),HBo=l(),gv=a("li"),L_e=a("strong"),JBo=o("data2vec-text"),YBo=o(" \u2014 "),kX=a("a"),KBo=o("Data2VecTextForMaskedLM"),ZBo=o(" (Data2VecText model)"),eIo=l(),hv=a("li"),y_e=a("strong"),oIo=o("deberta"),rIo=o(" \u2014 "),SX=a("a"),tIo=o("DebertaForMaskedLM"),aIo=o(" (DeBERTa model)"),nIo=l(),uv=a("li"),x_e=a("strong"),sIo=o("deberta-v2"),lIo=o(" \u2014 "),RX=a("a"),iIo=o("DebertaV2ForMaskedLM"),dIo=o(" (DeBERTa-v2 model)"),cIo=l(),pv=a("li"),$_e=a("strong"),fIo=o("distilbert"),mIo=o(" \u2014 "),PX=a("a"),gIo=o("DistilBertForMaskedLM"),hIo=o(" (DistilBERT model)"),uIo=l(),_v=a("li"),k_e=a("strong"),pIo=o("electra"),_Io=o(" \u2014 "),BX=a("a"),vIo=o("ElectraForPreTraining"),bIo=o(" (ELECTRA model)"),FIo=l(),vv=a("li"),S_e=a("strong"),TIo=o("ernie"),MIo=o(" \u2014 "),IX=a("a"),EIo=o("ErnieForPreTraining"),CIo=o(" (ERNIE model)"),wIo=l(),bv=a("li"),R_e=a("strong"),AIo=o("flaubert"),LIo=o(" \u2014 "),NX=a("a"),yIo=o("FlaubertWithLMHeadModel"),xIo=o(" (FlauBERT model)"),$Io=l(),Fv=a("li"),P_e=a("strong"),kIo=o("flava"),SIo=o(" \u2014 "),qX=a("a"),RIo=o("FlavaForPreTraining"),PIo=o(" (FLAVA model)"),BIo=l(),Tv=a("li"),B_e=a("strong"),IIo=o("fnet"),NIo=o(" \u2014 "),jX=a("a"),qIo=o("FNetForPreTraining"),jIo=o(" (FNet model)"),DIo=l(),Mv=a("li"),I_e=a("strong"),GIo=o("fsmt"),OIo=o(" \u2014 "),DX=a("a"),VIo=o("FSMTForConditionalGeneration"),XIo=o(" (FairSeq Machine-Translation model)"),zIo=l(),Ev=a("li"),N_e=a("strong"),QIo=o("funnel"),WIo=o(" \u2014 "),GX=a("a"),UIo=o("FunnelForPreTraining"),HIo=o(" (Funnel Transformer model)"),JIo=l(),Cv=a("li"),q_e=a("strong"),YIo=o("gpt2"),KIo=o(" \u2014 "),OX=a("a"),ZIo=o("GPT2LMHeadModel"),eNo=o(" (OpenAI GPT-2 model)"),oNo=l(),wv=a("li"),j_e=a("strong"),rNo=o("ibert"),tNo=o(" \u2014 "),VX=a("a"),aNo=o("IBertForMaskedLM"),nNo=o(" (I-BERT model)"),sNo=l(),Av=a("li"),D_e=a("strong"),lNo=o("layoutlm"),iNo=o(" \u2014 "),XX=a("a"),dNo=o("LayoutLMForMaskedLM"),cNo=o(" (LayoutLM model)"),fNo=l(),Lv=a("li"),G_e=a("strong"),mNo=o("longformer"),gNo=o(" \u2014 "),zX=a("a"),hNo=o("LongformerForMaskedLM"),uNo=o(" (Longformer model)"),pNo=l(),yv=a("li"),O_e=a("strong"),_No=o("luke"),vNo=o(" \u2014 "),QX=a("a"),bNo=o("LukeForMaskedLM"),FNo=o(" (LUKE model)"),TNo=l(),xv=a("li"),V_e=a("strong"),MNo=o("lxmert"),ENo=o(" \u2014 "),WX=a("a"),CNo=o("LxmertForPreTraining"),wNo=o(" (LXMERT model)"),ANo=l(),$v=a("li"),X_e=a("strong"),LNo=o("megatron-bert"),yNo=o(" \u2014 "),UX=a("a"),xNo=o("MegatronBertForPreTraining"),$No=o(" (Megatron-BERT model)"),kNo=l(),kv=a("li"),z_e=a("strong"),SNo=o("mobilebert"),RNo=o(" \u2014 "),HX=a("a"),PNo=o("MobileBertForPreTraining"),BNo=o(" (MobileBERT model)"),INo=l(),Sv=a("li"),Q_e=a("strong"),NNo=o("mpnet"),qNo=o(" \u2014 "),JX=a("a"),jNo=o("MPNetForMaskedLM"),DNo=o(" (MPNet model)"),GNo=l(),Rv=a("li"),W_e=a("strong"),ONo=o("mvp"),VNo=o(" \u2014 "),YX=a("a"),XNo=o("MvpForConditionalGeneration"),zNo=o(" (MVP model)"),QNo=l(),Pv=a("li"),U_e=a("strong"),WNo=o("nezha"),UNo=o(" \u2014 "),KX=a("a"),HNo=o("NezhaForPreTraining"),JNo=o(" (Nezha model)"),YNo=l(),Bv=a("li"),H_e=a("strong"),KNo=o("openai-gpt"),ZNo=o(" \u2014 "),ZX=a("a"),eqo=o("OpenAIGPTLMHeadModel"),oqo=o(" (OpenAI GPT model)"),rqo=l(),Iv=a("li"),J_e=a("strong"),tqo=o("retribert"),aqo=o(" \u2014 "),ez=a("a"),nqo=o("RetriBertModel"),sqo=o(" (RetriBERT model)"),lqo=l(),Nv=a("li"),Y_e=a("strong"),iqo=o("roberta"),dqo=o(" \u2014 "),oz=a("a"),cqo=o("RobertaForMaskedLM"),fqo=o(" (RoBERTa model)"),mqo=l(),qv=a("li"),K_e=a("strong"),gqo=o("splinter"),hqo=o(" \u2014 "),rz=a("a"),uqo=o("SplinterForPreTraining"),pqo=o(" (Splinter model)"),_qo=l(),jv=a("li"),Z_e=a("strong"),vqo=o("squeezebert"),bqo=o(" \u2014 "),tz=a("a"),Fqo=o("SqueezeBertForMaskedLM"),Tqo=o(" (SqueezeBERT model)"),Mqo=l(),Dv=a("li"),e2e=a("strong"),Eqo=o("t5"),Cqo=o(" \u2014 "),az=a("a"),wqo=o("T5ForConditionalGeneration"),Aqo=o(" (T5 model)"),Lqo=l(),Gv=a("li"),o2e=a("strong"),yqo=o("tapas"),xqo=o(" \u2014 "),nz=a("a"),$qo=o("TapasForMaskedLM"),kqo=o(" (TAPAS model)"),Sqo=l(),Ov=a("li"),r2e=a("strong"),Rqo=o("transfo-xl"),Pqo=o(" \u2014 "),sz=a("a"),Bqo=o("TransfoXLLMHeadModel"),Iqo=o(" (Transformer-XL model)"),Nqo=l(),Vv=a("li"),t2e=a("strong"),qqo=o("unispeech"),jqo=o(" \u2014 "),lz=a("a"),Dqo=o("UniSpeechForPreTraining"),Gqo=o(" (UniSpeech model)"),Oqo=l(),Xv=a("li"),a2e=a("strong"),Vqo=o("unispeech-sat"),Xqo=o(" \u2014 "),iz=a("a"),zqo=o("UniSpeechSatForPreTraining"),Qqo=o(" (UniSpeechSat model)"),Wqo=l(),zv=a("li"),n2e=a("strong"),Uqo=o("videomae"),Hqo=o(" \u2014 "),dz=a("a"),Jqo=o("VideoMAEForPreTraining"),Yqo=o(" (VideoMAE model)"),Kqo=l(),Qv=a("li"),s2e=a("strong"),Zqo=o("visual_bert"),ejo=o(" \u2014 "),cz=a("a"),ojo=o("VisualBertForPreTraining"),rjo=o(" (VisualBERT model)"),tjo=l(),Wv=a("li"),l2e=a("strong"),ajo=o("vit_mae"),njo=o(" \u2014 "),fz=a("a"),sjo=o("ViTMAEForPreTraining"),ljo=o(" (ViTMAE model)"),ijo=l(),Uv=a("li"),i2e=a("strong"),djo=o("wav2vec2"),cjo=o(" \u2014 "),mz=a("a"),fjo=o("Wav2Vec2ForPreTraining"),mjo=o(" (Wav2Vec2 model)"),gjo=l(),Hv=a("li"),d2e=a("strong"),hjo=o("wav2vec2-conformer"),ujo=o(" \u2014 "),gz=a("a"),pjo=o("Wav2Vec2ConformerForPreTraining"),_jo=o(" (Wav2Vec2-Conformer model)"),vjo=l(),Jv=a("li"),c2e=a("strong"),bjo=o("xlm"),Fjo=o(" \u2014 "),hz=a("a"),Tjo=o("XLMWithLMHeadModel"),Mjo=o(" (XLM model)"),Ejo=l(),Yv=a("li"),f2e=a("strong"),Cjo=o("xlm-roberta"),wjo=o(" \u2014 "),uz=a("a"),Ajo=o("XLMRobertaForMaskedLM"),Ljo=o(" (XLM-RoBERTa model)"),yjo=l(),Kv=a("li"),m2e=a("strong"),xjo=o("xlm-roberta-xl"),$jo=o(" \u2014 "),pz=a("a"),kjo=o("XLMRobertaXLForMaskedLM"),Sjo=o(" (XLM-RoBERTa-XL model)"),Rjo=l(),Zv=a("li"),g2e=a("strong"),Pjo=o("xlnet"),Bjo=o(" \u2014 "),_z=a("a"),Ijo=o("XLNetLMHeadModel"),Njo=o(" (XLNet model)"),qjo=l(),e1=a("p"),jjo=o("The model is set in evaluation mode by default using "),h2e=a("code"),Djo=o("model.eval()"),Gjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=a("code"),Ojo=o("model.train()"),Vjo=l(),F(o1.$$.fragment),UYe=l(),Md=a("h2"),r1=a("a"),p2e=a("span"),F(nx.$$.fragment),Xjo=l(),_2e=a("span"),zjo=o("AutoModelForCausalLM"),HYe=l(),Io=a("div"),F(sx.$$.fragment),Qjo=l(),Ed=a("p"),Wjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vz=a("a"),Ujo=o("from_pretrained()"),Hjo=o(" class method or the "),bz=a("a"),Jjo=o("from_config()"),Yjo=o(` class
method.`),Kjo=l(),lx=a("p"),Zjo=o("This class cannot be instantiated directly using "),v2e=a("code"),eDo=o("__init__()"),oDo=o(" (throws an error)."),rDo=l(),bt=a("div"),F(ix.$$.fragment),tDo=l(),b2e=a("p"),aDo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),nDo=l(),Cd=a("p"),sDo=o(`Note:
Loading a model from its configuration file does `),F2e=a("strong"),lDo=o("not"),iDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),dDo=o("from_pretrained()"),cDo=o(" to load the model weights."),fDo=l(),F(t1.$$.fragment),mDo=l(),oo=a("div"),F(dx.$$.fragment),gDo=l(),T2e=a("p"),hDo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uDo=l(),Ka=a("p"),pDo=o("The model class to instantiate is selected based on the "),M2e=a("code"),_Do=o("model_type"),vDo=o(` property of the config object (either
passed as an argument or loaded from `),E2e=a("code"),bDo=o("pretrained_model_name_or_path"),FDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C2e=a("code"),TDo=o("pretrained_model_name_or_path"),MDo=o(":"),EDo=l(),z=a("ul"),a1=a("li"),w2e=a("strong"),CDo=o("bart"),wDo=o(" \u2014 "),Tz=a("a"),ADo=o("BartForCausalLM"),LDo=o(" (BART model)"),yDo=l(),n1=a("li"),A2e=a("strong"),xDo=o("bert"),$Do=o(" \u2014 "),Mz=a("a"),kDo=o("BertLMHeadModel"),SDo=o(" (BERT model)"),RDo=l(),s1=a("li"),L2e=a("strong"),PDo=o("bert-generation"),BDo=o(" \u2014 "),Ez=a("a"),IDo=o("BertGenerationDecoder"),NDo=o(" (Bert Generation model)"),qDo=l(),l1=a("li"),y2e=a("strong"),jDo=o("big_bird"),DDo=o(" \u2014 "),Cz=a("a"),GDo=o("BigBirdForCausalLM"),ODo=o(" (BigBird model)"),VDo=l(),i1=a("li"),x2e=a("strong"),XDo=o("bigbird_pegasus"),zDo=o(" \u2014 "),wz=a("a"),QDo=o("BigBirdPegasusForCausalLM"),WDo=o(" (BigBird-Pegasus model)"),UDo=l(),d1=a("li"),$2e=a("strong"),HDo=o("blenderbot"),JDo=o(" \u2014 "),Az=a("a"),YDo=o("BlenderbotForCausalLM"),KDo=o(" (Blenderbot model)"),ZDo=l(),c1=a("li"),k2e=a("strong"),eGo=o("blenderbot-small"),oGo=o(" \u2014 "),Lz=a("a"),rGo=o("BlenderbotSmallForCausalLM"),tGo=o(" (BlenderbotSmall model)"),aGo=l(),f1=a("li"),S2e=a("strong"),nGo=o("bloom"),sGo=o(" \u2014 "),yz=a("a"),lGo=o("BloomForCausalLM"),iGo=o(" (BLOOM model)"),dGo=l(),m1=a("li"),R2e=a("strong"),cGo=o("camembert"),fGo=o(" \u2014 "),xz=a("a"),mGo=o("CamembertForCausalLM"),gGo=o(" (CamemBERT model)"),hGo=l(),g1=a("li"),P2e=a("strong"),uGo=o("codegen"),pGo=o(" \u2014 "),$z=a("a"),_Go=o("CodeGenForCausalLM"),vGo=o(" (CodeGen model)"),bGo=l(),h1=a("li"),B2e=a("strong"),FGo=o("ctrl"),TGo=o(" \u2014 "),kz=a("a"),MGo=o("CTRLLMHeadModel"),EGo=o(" (CTRL model)"),CGo=l(),u1=a("li"),I2e=a("strong"),wGo=o("data2vec-text"),AGo=o(" \u2014 "),Sz=a("a"),LGo=o("Data2VecTextForCausalLM"),yGo=o(" (Data2VecText model)"),xGo=l(),p1=a("li"),N2e=a("strong"),$Go=o("electra"),kGo=o(" \u2014 "),Rz=a("a"),SGo=o("ElectraForCausalLM"),RGo=o(" (ELECTRA model)"),PGo=l(),_1=a("li"),q2e=a("strong"),BGo=o("ernie"),IGo=o(" \u2014 "),Pz=a("a"),NGo=o("ErnieForCausalLM"),qGo=o(" (ERNIE model)"),jGo=l(),v1=a("li"),j2e=a("strong"),DGo=o("gpt2"),GGo=o(" \u2014 "),Bz=a("a"),OGo=o("GPT2LMHeadModel"),VGo=o(" (OpenAI GPT-2 model)"),XGo=l(),b1=a("li"),D2e=a("strong"),zGo=o("gpt_neo"),QGo=o(" \u2014 "),Iz=a("a"),WGo=o("GPTNeoForCausalLM"),UGo=o(" (GPT Neo model)"),HGo=l(),F1=a("li"),G2e=a("strong"),JGo=o("gpt_neox"),YGo=o(" \u2014 "),Nz=a("a"),KGo=o("GPTNeoXForCausalLM"),ZGo=o(" (GPT NeoX model)"),eOo=l(),T1=a("li"),O2e=a("strong"),oOo=o("gptj"),rOo=o(" \u2014 "),qz=a("a"),tOo=o("GPTJForCausalLM"),aOo=o(" (GPT-J model)"),nOo=l(),M1=a("li"),V2e=a("strong"),sOo=o("marian"),lOo=o(" \u2014 "),jz=a("a"),iOo=o("MarianForCausalLM"),dOo=o(" (Marian model)"),cOo=l(),E1=a("li"),X2e=a("strong"),fOo=o("mbart"),mOo=o(" \u2014 "),Dz=a("a"),gOo=o("MBartForCausalLM"),hOo=o(" (mBART model)"),uOo=l(),C1=a("li"),z2e=a("strong"),pOo=o("megatron-bert"),_Oo=o(" \u2014 "),Gz=a("a"),vOo=o("MegatronBertForCausalLM"),bOo=o(" (Megatron-BERT model)"),FOo=l(),w1=a("li"),Q2e=a("strong"),TOo=o("mvp"),MOo=o(" \u2014 "),Oz=a("a"),EOo=o("MvpForCausalLM"),COo=o(" (MVP model)"),wOo=l(),A1=a("li"),W2e=a("strong"),AOo=o("openai-gpt"),LOo=o(" \u2014 "),Vz=a("a"),yOo=o("OpenAIGPTLMHeadModel"),xOo=o(" (OpenAI GPT model)"),$Oo=l(),L1=a("li"),U2e=a("strong"),kOo=o("opt"),SOo=o(" \u2014 "),Xz=a("a"),ROo=o("OPTForCausalLM"),POo=o(" (OPT model)"),BOo=l(),y1=a("li"),H2e=a("strong"),IOo=o("pegasus"),NOo=o(" \u2014 "),zz=a("a"),qOo=o("PegasusForCausalLM"),jOo=o(" (Pegasus model)"),DOo=l(),x1=a("li"),J2e=a("strong"),GOo=o("plbart"),OOo=o(" \u2014 "),Qz=a("a"),VOo=o("PLBartForCausalLM"),XOo=o(" (PLBart model)"),zOo=l(),$1=a("li"),Y2e=a("strong"),QOo=o("prophetnet"),WOo=o(" \u2014 "),Wz=a("a"),UOo=o("ProphetNetForCausalLM"),HOo=o(" (ProphetNet model)"),JOo=l(),k1=a("li"),K2e=a("strong"),YOo=o("qdqbert"),KOo=o(" \u2014 "),Uz=a("a"),ZOo=o("QDQBertLMHeadModel"),eVo=o(" (QDQBert model)"),oVo=l(),S1=a("li"),Z2e=a("strong"),rVo=o("reformer"),tVo=o(" \u2014 "),Hz=a("a"),aVo=o("ReformerModelWithLMHead"),nVo=o(" (Reformer model)"),sVo=l(),R1=a("li"),eve=a("strong"),lVo=o("rembert"),iVo=o(" \u2014 "),Jz=a("a"),dVo=o("RemBertForCausalLM"),cVo=o(" (RemBERT model)"),fVo=l(),P1=a("li"),ove=a("strong"),mVo=o("roberta"),gVo=o(" \u2014 "),Yz=a("a"),hVo=o("RobertaForCausalLM"),uVo=o(" (RoBERTa model)"),pVo=l(),B1=a("li"),rve=a("strong"),_Vo=o("roformer"),vVo=o(" \u2014 "),Kz=a("a"),bVo=o("RoFormerForCausalLM"),FVo=o(" (RoFormer model)"),TVo=l(),I1=a("li"),tve=a("strong"),MVo=o("speech_to_text_2"),EVo=o(" \u2014 "),Zz=a("a"),CVo=o("Speech2Text2ForCausalLM"),wVo=o(" (Speech2Text2 model)"),AVo=l(),N1=a("li"),ave=a("strong"),LVo=o("transfo-xl"),yVo=o(" \u2014 "),eQ=a("a"),xVo=o("TransfoXLLMHeadModel"),$Vo=o(" (Transformer-XL model)"),kVo=l(),q1=a("li"),nve=a("strong"),SVo=o("trocr"),RVo=o(" \u2014 "),oQ=a("a"),PVo=o("TrOCRForCausalLM"),BVo=o(" (TrOCR model)"),IVo=l(),j1=a("li"),sve=a("strong"),NVo=o("xglm"),qVo=o(" \u2014 "),rQ=a("a"),jVo=o("XGLMForCausalLM"),DVo=o(" (XGLM model)"),GVo=l(),D1=a("li"),lve=a("strong"),OVo=o("xlm"),VVo=o(" \u2014 "),tQ=a("a"),XVo=o("XLMWithLMHeadModel"),zVo=o(" (XLM model)"),QVo=l(),G1=a("li"),ive=a("strong"),WVo=o("xlm-prophetnet"),UVo=o(" \u2014 "),aQ=a("a"),HVo=o("XLMProphetNetForCausalLM"),JVo=o(" (XLM-ProphetNet model)"),YVo=l(),O1=a("li"),dve=a("strong"),KVo=o("xlm-roberta"),ZVo=o(" \u2014 "),nQ=a("a"),eXo=o("XLMRobertaForCausalLM"),oXo=o(" (XLM-RoBERTa model)"),rXo=l(),V1=a("li"),cve=a("strong"),tXo=o("xlm-roberta-xl"),aXo=o(" \u2014 "),sQ=a("a"),nXo=o("XLMRobertaXLForCausalLM"),sXo=o(" (XLM-RoBERTa-XL model)"),lXo=l(),X1=a("li"),fve=a("strong"),iXo=o("xlnet"),dXo=o(" \u2014 "),lQ=a("a"),cXo=o("XLNetLMHeadModel"),fXo=o(" (XLNet model)"),mXo=l(),z1=a("p"),gXo=o("The model is set in evaluation mode by default using "),mve=a("code"),hXo=o("model.eval()"),uXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gve=a("code"),pXo=o("model.train()"),_Xo=l(),F(Q1.$$.fragment),JYe=l(),wd=a("h2"),W1=a("a"),hve=a("span"),F(cx.$$.fragment),vXo=l(),uve=a("span"),bXo=o("AutoModelForMaskedLM"),YYe=l(),No=a("div"),F(fx.$$.fragment),FXo=l(),Ad=a("p"),TXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),iQ=a("a"),MXo=o("from_pretrained()"),EXo=o(" class method or the "),dQ=a("a"),CXo=o("from_config()"),wXo=o(` class
method.`),AXo=l(),mx=a("p"),LXo=o("This class cannot be instantiated directly using "),pve=a("code"),yXo=o("__init__()"),xXo=o(" (throws an error)."),$Xo=l(),Ft=a("div"),F(gx.$$.fragment),kXo=l(),_ve=a("p"),SXo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),RXo=l(),Ld=a("p"),PXo=o(`Note:
Loading a model from its configuration file does `),vve=a("strong"),BXo=o("not"),IXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),NXo=o("from_pretrained()"),qXo=o(" to load the model weights."),jXo=l(),F(U1.$$.fragment),DXo=l(),ro=a("div"),F(hx.$$.fragment),GXo=l(),bve=a("p"),OXo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),VXo=l(),Za=a("p"),XXo=o("The model class to instantiate is selected based on the "),Fve=a("code"),zXo=o("model_type"),QXo=o(` property of the config object (either
passed as an argument or loaded from `),Tve=a("code"),WXo=o("pretrained_model_name_or_path"),UXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mve=a("code"),HXo=o("pretrained_model_name_or_path"),JXo=o(":"),YXo=l(),U=a("ul"),H1=a("li"),Eve=a("strong"),KXo=o("albert"),ZXo=o(" \u2014 "),fQ=a("a"),ezo=o("AlbertForMaskedLM"),ozo=o(" (ALBERT model)"),rzo=l(),J1=a("li"),Cve=a("strong"),tzo=o("bart"),azo=o(" \u2014 "),mQ=a("a"),nzo=o("BartForConditionalGeneration"),szo=o(" (BART model)"),lzo=l(),Y1=a("li"),wve=a("strong"),izo=o("bert"),dzo=o(" \u2014 "),gQ=a("a"),czo=o("BertForMaskedLM"),fzo=o(" (BERT model)"),mzo=l(),K1=a("li"),Ave=a("strong"),gzo=o("big_bird"),hzo=o(" \u2014 "),hQ=a("a"),uzo=o("BigBirdForMaskedLM"),pzo=o(" (BigBird model)"),_zo=l(),Z1=a("li"),Lve=a("strong"),vzo=o("camembert"),bzo=o(" \u2014 "),uQ=a("a"),Fzo=o("CamembertForMaskedLM"),Tzo=o(" (CamemBERT model)"),Mzo=l(),e4=a("li"),yve=a("strong"),Ezo=o("convbert"),Czo=o(" \u2014 "),pQ=a("a"),wzo=o("ConvBertForMaskedLM"),Azo=o(" (ConvBERT model)"),Lzo=l(),o4=a("li"),xve=a("strong"),yzo=o("data2vec-text"),xzo=o(" \u2014 "),_Q=a("a"),$zo=o("Data2VecTextForMaskedLM"),kzo=o(" (Data2VecText model)"),Szo=l(),r4=a("li"),$ve=a("strong"),Rzo=o("deberta"),Pzo=o(" \u2014 "),vQ=a("a"),Bzo=o("DebertaForMaskedLM"),Izo=o(" (DeBERTa model)"),Nzo=l(),t4=a("li"),kve=a("strong"),qzo=o("deberta-v2"),jzo=o(" \u2014 "),bQ=a("a"),Dzo=o("DebertaV2ForMaskedLM"),Gzo=o(" (DeBERTa-v2 model)"),Ozo=l(),a4=a("li"),Sve=a("strong"),Vzo=o("distilbert"),Xzo=o(" \u2014 "),FQ=a("a"),zzo=o("DistilBertForMaskedLM"),Qzo=o(" (DistilBERT model)"),Wzo=l(),n4=a("li"),Rve=a("strong"),Uzo=o("electra"),Hzo=o(" \u2014 "),TQ=a("a"),Jzo=o("ElectraForMaskedLM"),Yzo=o(" (ELECTRA model)"),Kzo=l(),s4=a("li"),Pve=a("strong"),Zzo=o("ernie"),eQo=o(" \u2014 "),MQ=a("a"),oQo=o("ErnieForMaskedLM"),rQo=o(" (ERNIE model)"),tQo=l(),l4=a("li"),Bve=a("strong"),aQo=o("flaubert"),nQo=o(" \u2014 "),EQ=a("a"),sQo=o("FlaubertWithLMHeadModel"),lQo=o(" (FlauBERT model)"),iQo=l(),i4=a("li"),Ive=a("strong"),dQo=o("fnet"),cQo=o(" \u2014 "),CQ=a("a"),fQo=o("FNetForMaskedLM"),mQo=o(" (FNet model)"),gQo=l(),d4=a("li"),Nve=a("strong"),hQo=o("funnel"),uQo=o(" \u2014 "),wQ=a("a"),pQo=o("FunnelForMaskedLM"),_Qo=o(" (Funnel Transformer model)"),vQo=l(),c4=a("li"),qve=a("strong"),bQo=o("ibert"),FQo=o(" \u2014 "),AQ=a("a"),TQo=o("IBertForMaskedLM"),MQo=o(" (I-BERT model)"),EQo=l(),f4=a("li"),jve=a("strong"),CQo=o("layoutlm"),wQo=o(" \u2014 "),LQ=a("a"),AQo=o("LayoutLMForMaskedLM"),LQo=o(" (LayoutLM model)"),yQo=l(),m4=a("li"),Dve=a("strong"),xQo=o("longformer"),$Qo=o(" \u2014 "),yQ=a("a"),kQo=o("LongformerForMaskedLM"),SQo=o(" (Longformer model)"),RQo=l(),g4=a("li"),Gve=a("strong"),PQo=o("luke"),BQo=o(" \u2014 "),xQ=a("a"),IQo=o("LukeForMaskedLM"),NQo=o(" (LUKE model)"),qQo=l(),h4=a("li"),Ove=a("strong"),jQo=o("mbart"),DQo=o(" \u2014 "),$Q=a("a"),GQo=o("MBartForConditionalGeneration"),OQo=o(" (mBART model)"),VQo=l(),u4=a("li"),Vve=a("strong"),XQo=o("megatron-bert"),zQo=o(" \u2014 "),kQ=a("a"),QQo=o("MegatronBertForMaskedLM"),WQo=o(" (Megatron-BERT model)"),UQo=l(),p4=a("li"),Xve=a("strong"),HQo=o("mobilebert"),JQo=o(" \u2014 "),SQ=a("a"),YQo=o("MobileBertForMaskedLM"),KQo=o(" (MobileBERT model)"),ZQo=l(),_4=a("li"),zve=a("strong"),eWo=o("mpnet"),oWo=o(" \u2014 "),RQ=a("a"),rWo=o("MPNetForMaskedLM"),tWo=o(" (MPNet model)"),aWo=l(),v4=a("li"),Qve=a("strong"),nWo=o("mvp"),sWo=o(" \u2014 "),PQ=a("a"),lWo=o("MvpForConditionalGeneration"),iWo=o(" (MVP model)"),dWo=l(),b4=a("li"),Wve=a("strong"),cWo=o("nezha"),fWo=o(" \u2014 "),BQ=a("a"),mWo=o("NezhaForMaskedLM"),gWo=o(" (Nezha model)"),hWo=l(),F4=a("li"),Uve=a("strong"),uWo=o("nystromformer"),pWo=o(" \u2014 "),IQ=a("a"),_Wo=o("NystromformerForMaskedLM"),vWo=o(" (Nystr\xF6mformer model)"),bWo=l(),T4=a("li"),Hve=a("strong"),FWo=o("perceiver"),TWo=o(" \u2014 "),NQ=a("a"),MWo=o("PerceiverForMaskedLM"),EWo=o(" (Perceiver model)"),CWo=l(),M4=a("li"),Jve=a("strong"),wWo=o("qdqbert"),AWo=o(" \u2014 "),qQ=a("a"),LWo=o("QDQBertForMaskedLM"),yWo=o(" (QDQBert model)"),xWo=l(),E4=a("li"),Yve=a("strong"),$Wo=o("reformer"),kWo=o(" \u2014 "),jQ=a("a"),SWo=o("ReformerForMaskedLM"),RWo=o(" (Reformer model)"),PWo=l(),C4=a("li"),Kve=a("strong"),BWo=o("rembert"),IWo=o(" \u2014 "),DQ=a("a"),NWo=o("RemBertForMaskedLM"),qWo=o(" (RemBERT model)"),jWo=l(),w4=a("li"),Zve=a("strong"),DWo=o("roberta"),GWo=o(" \u2014 "),GQ=a("a"),OWo=o("RobertaForMaskedLM"),VWo=o(" (RoBERTa model)"),XWo=l(),A4=a("li"),e1e=a("strong"),zWo=o("roformer"),QWo=o(" \u2014 "),OQ=a("a"),WWo=o("RoFormerForMaskedLM"),UWo=o(" (RoFormer model)"),HWo=l(),L4=a("li"),o1e=a("strong"),JWo=o("squeezebert"),YWo=o(" \u2014 "),VQ=a("a"),KWo=o("SqueezeBertForMaskedLM"),ZWo=o(" (SqueezeBERT model)"),eUo=l(),y4=a("li"),r1e=a("strong"),oUo=o("tapas"),rUo=o(" \u2014 "),XQ=a("a"),tUo=o("TapasForMaskedLM"),aUo=o(" (TAPAS model)"),nUo=l(),x4=a("li"),t1e=a("strong"),sUo=o("wav2vec2"),lUo=o(" \u2014 "),a1e=a("code"),iUo=o("Wav2Vec2ForMaskedLM"),dUo=o(" (Wav2Vec2 model)"),cUo=l(),$4=a("li"),n1e=a("strong"),fUo=o("xlm"),mUo=o(" \u2014 "),zQ=a("a"),gUo=o("XLMWithLMHeadModel"),hUo=o(" (XLM model)"),uUo=l(),k4=a("li"),s1e=a("strong"),pUo=o("xlm-roberta"),_Uo=o(" \u2014 "),QQ=a("a"),vUo=o("XLMRobertaForMaskedLM"),bUo=o(" (XLM-RoBERTa model)"),FUo=l(),S4=a("li"),l1e=a("strong"),TUo=o("xlm-roberta-xl"),MUo=o(" \u2014 "),WQ=a("a"),EUo=o("XLMRobertaXLForMaskedLM"),CUo=o(" (XLM-RoBERTa-XL model)"),wUo=l(),R4=a("li"),i1e=a("strong"),AUo=o("yoso"),LUo=o(" \u2014 "),UQ=a("a"),yUo=o("YosoForMaskedLM"),xUo=o(" (YOSO model)"),$Uo=l(),P4=a("p"),kUo=o("The model is set in evaluation mode by default using "),d1e=a("code"),SUo=o("model.eval()"),RUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c1e=a("code"),PUo=o("model.train()"),BUo=l(),F(B4.$$.fragment),KYe=l(),yd=a("h2"),I4=a("a"),f1e=a("span"),F(ux.$$.fragment),IUo=l(),m1e=a("span"),NUo=o("AutoModelForSeq2SeqLM"),ZYe=l(),qo=a("div"),F(px.$$.fragment),qUo=l(),xd=a("p"),jUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HQ=a("a"),DUo=o("from_pretrained()"),GUo=o(" class method or the "),JQ=a("a"),OUo=o("from_config()"),VUo=o(` class
method.`),XUo=l(),_x=a("p"),zUo=o("This class cannot be instantiated directly using "),g1e=a("code"),QUo=o("__init__()"),WUo=o(" (throws an error)."),UUo=l(),Tt=a("div"),F(vx.$$.fragment),HUo=l(),h1e=a("p"),JUo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YUo=l(),$d=a("p"),KUo=o(`Note:
Loading a model from its configuration file does `),u1e=a("strong"),ZUo=o("not"),eHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=a("a"),oHo=o("from_pretrained()"),rHo=o(" to load the model weights."),tHo=l(),F(N4.$$.fragment),aHo=l(),to=a("div"),F(bx.$$.fragment),nHo=l(),p1e=a("p"),sHo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),lHo=l(),en=a("p"),iHo=o("The model class to instantiate is selected based on the "),_1e=a("code"),dHo=o("model_type"),cHo=o(` property of the config object (either
passed as an argument or loaded from `),v1e=a("code"),fHo=o("pretrained_model_name_or_path"),mHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b1e=a("code"),gHo=o("pretrained_model_name_or_path"),hHo=o(":"),uHo=l(),fe=a("ul"),q4=a("li"),F1e=a("strong"),pHo=o("bart"),_Ho=o(" \u2014 "),KQ=a("a"),vHo=o("BartForConditionalGeneration"),bHo=o(" (BART model)"),FHo=l(),j4=a("li"),T1e=a("strong"),THo=o("bigbird_pegasus"),MHo=o(" \u2014 "),ZQ=a("a"),EHo=o("BigBirdPegasusForConditionalGeneration"),CHo=o(" (BigBird-Pegasus model)"),wHo=l(),D4=a("li"),M1e=a("strong"),AHo=o("blenderbot"),LHo=o(" \u2014 "),eW=a("a"),yHo=o("BlenderbotForConditionalGeneration"),xHo=o(" (Blenderbot model)"),$Ho=l(),G4=a("li"),E1e=a("strong"),kHo=o("blenderbot-small"),SHo=o(" \u2014 "),oW=a("a"),RHo=o("BlenderbotSmallForConditionalGeneration"),PHo=o(" (BlenderbotSmall model)"),BHo=l(),O4=a("li"),C1e=a("strong"),IHo=o("encoder-decoder"),NHo=o(" \u2014 "),rW=a("a"),qHo=o("EncoderDecoderModel"),jHo=o(" (Encoder decoder model)"),DHo=l(),V4=a("li"),w1e=a("strong"),GHo=o("fsmt"),OHo=o(" \u2014 "),tW=a("a"),VHo=o("FSMTForConditionalGeneration"),XHo=o(" (FairSeq Machine-Translation model)"),zHo=l(),X4=a("li"),A1e=a("strong"),QHo=o("led"),WHo=o(" \u2014 "),aW=a("a"),UHo=o("LEDForConditionalGeneration"),HHo=o(" (LED model)"),JHo=l(),z4=a("li"),L1e=a("strong"),YHo=o("longt5"),KHo=o(" \u2014 "),nW=a("a"),ZHo=o("LongT5ForConditionalGeneration"),eJo=o(" (LongT5 model)"),oJo=l(),Q4=a("li"),y1e=a("strong"),rJo=o("m2m_100"),tJo=o(" \u2014 "),sW=a("a"),aJo=o("M2M100ForConditionalGeneration"),nJo=o(" (M2M100 model)"),sJo=l(),W4=a("li"),x1e=a("strong"),lJo=o("marian"),iJo=o(" \u2014 "),lW=a("a"),dJo=o("MarianMTModel"),cJo=o(" (Marian model)"),fJo=l(),U4=a("li"),$1e=a("strong"),mJo=o("mbart"),gJo=o(" \u2014 "),iW=a("a"),hJo=o("MBartForConditionalGeneration"),uJo=o(" (mBART model)"),pJo=l(),H4=a("li"),k1e=a("strong"),_Jo=o("mt5"),vJo=o(" \u2014 "),dW=a("a"),bJo=o("MT5ForConditionalGeneration"),FJo=o(" (MT5 model)"),TJo=l(),J4=a("li"),S1e=a("strong"),MJo=o("mvp"),EJo=o(" \u2014 "),cW=a("a"),CJo=o("MvpForConditionalGeneration"),wJo=o(" (MVP model)"),AJo=l(),Y4=a("li"),R1e=a("strong"),LJo=o("nllb"),yJo=o(" \u2014 "),fW=a("a"),xJo=o("M2M100ForConditionalGeneration"),$Jo=o(" (NLLB model)"),kJo=l(),K4=a("li"),P1e=a("strong"),SJo=o("pegasus"),RJo=o(" \u2014 "),mW=a("a"),PJo=o("PegasusForConditionalGeneration"),BJo=o(" (Pegasus model)"),IJo=l(),Z4=a("li"),B1e=a("strong"),NJo=o("pegasus_x"),qJo=o(" \u2014 "),gW=a("a"),jJo=o("PegasusXForConditionalGeneration"),DJo=o(" (PEGASUS-X model)"),GJo=l(),eb=a("li"),I1e=a("strong"),OJo=o("plbart"),VJo=o(" \u2014 "),hW=a("a"),XJo=o("PLBartForConditionalGeneration"),zJo=o(" (PLBart model)"),QJo=l(),ob=a("li"),N1e=a("strong"),WJo=o("prophetnet"),UJo=o(" \u2014 "),uW=a("a"),HJo=o("ProphetNetForConditionalGeneration"),JJo=o(" (ProphetNet model)"),YJo=l(),rb=a("li"),q1e=a("strong"),KJo=o("t5"),ZJo=o(" \u2014 "),pW=a("a"),eYo=o("T5ForConditionalGeneration"),oYo=o(" (T5 model)"),rYo=l(),tb=a("li"),j1e=a("strong"),tYo=o("xlm-prophetnet"),aYo=o(" \u2014 "),_W=a("a"),nYo=o("XLMProphetNetForConditionalGeneration"),sYo=o(" (XLM-ProphetNet model)"),lYo=l(),ab=a("p"),iYo=o("The model is set in evaluation mode by default using "),D1e=a("code"),dYo=o("model.eval()"),cYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G1e=a("code"),fYo=o("model.train()"),mYo=l(),F(nb.$$.fragment),eKe=l(),kd=a("h2"),sb=a("a"),O1e=a("span"),F(Fx.$$.fragment),gYo=l(),V1e=a("span"),hYo=o("AutoModelForSequenceClassification"),oKe=l(),jo=a("div"),F(Tx.$$.fragment),uYo=l(),Sd=a("p"),pYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),vW=a("a"),_Yo=o("from_pretrained()"),vYo=o(" class method or the "),bW=a("a"),bYo=o("from_config()"),FYo=o(` class
method.`),TYo=l(),Mx=a("p"),MYo=o("This class cannot be instantiated directly using "),X1e=a("code"),EYo=o("__init__()"),CYo=o(" (throws an error)."),wYo=l(),Mt=a("div"),F(Ex.$$.fragment),AYo=l(),z1e=a("p"),LYo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yYo=l(),Rd=a("p"),xYo=o(`Note:
Loading a model from its configuration file does `),Q1e=a("strong"),$Yo=o("not"),kYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FW=a("a"),SYo=o("from_pretrained()"),RYo=o(" to load the model weights."),PYo=l(),F(lb.$$.fragment),BYo=l(),ao=a("div"),F(Cx.$$.fragment),IYo=l(),W1e=a("p"),NYo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qYo=l(),on=a("p"),jYo=o("The model class to instantiate is selected based on the "),U1e=a("code"),DYo=o("model_type"),GYo=o(` property of the config object (either
passed as an argument or loaded from `),H1e=a("code"),OYo=o("pretrained_model_name_or_path"),VYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J1e=a("code"),XYo=o("pretrained_model_name_or_path"),zYo=o(":"),QYo=l(),q=a("ul"),ib=a("li"),Y1e=a("strong"),WYo=o("albert"),UYo=o(" \u2014 "),TW=a("a"),HYo=o("AlbertForSequenceClassification"),JYo=o(" (ALBERT model)"),YYo=l(),db=a("li"),K1e=a("strong"),KYo=o("bart"),ZYo=o(" \u2014 "),MW=a("a"),eKo=o("BartForSequenceClassification"),oKo=o(" (BART model)"),rKo=l(),cb=a("li"),Z1e=a("strong"),tKo=o("bert"),aKo=o(" \u2014 "),EW=a("a"),nKo=o("BertForSequenceClassification"),sKo=o(" (BERT model)"),lKo=l(),fb=a("li"),e4e=a("strong"),iKo=o("big_bird"),dKo=o(" \u2014 "),CW=a("a"),cKo=o("BigBirdForSequenceClassification"),fKo=o(" (BigBird model)"),mKo=l(),mb=a("li"),o4e=a("strong"),gKo=o("bigbird_pegasus"),hKo=o(" \u2014 "),wW=a("a"),uKo=o("BigBirdPegasusForSequenceClassification"),pKo=o(" (BigBird-Pegasus model)"),_Ko=l(),gb=a("li"),r4e=a("strong"),vKo=o("bloom"),bKo=o(" \u2014 "),AW=a("a"),FKo=o("BloomForSequenceClassification"),TKo=o(" (BLOOM model)"),MKo=l(),hb=a("li"),t4e=a("strong"),EKo=o("camembert"),CKo=o(" \u2014 "),LW=a("a"),wKo=o("CamembertForSequenceClassification"),AKo=o(" (CamemBERT model)"),LKo=l(),ub=a("li"),a4e=a("strong"),yKo=o("canine"),xKo=o(" \u2014 "),yW=a("a"),$Ko=o("CanineForSequenceClassification"),kKo=o(" (CANINE model)"),SKo=l(),pb=a("li"),n4e=a("strong"),RKo=o("convbert"),PKo=o(" \u2014 "),xW=a("a"),BKo=o("ConvBertForSequenceClassification"),IKo=o(" (ConvBERT model)"),NKo=l(),_b=a("li"),s4e=a("strong"),qKo=o("ctrl"),jKo=o(" \u2014 "),$W=a("a"),DKo=o("CTRLForSequenceClassification"),GKo=o(" (CTRL model)"),OKo=l(),vb=a("li"),l4e=a("strong"),VKo=o("data2vec-text"),XKo=o(" \u2014 "),kW=a("a"),zKo=o("Data2VecTextForSequenceClassification"),QKo=o(" (Data2VecText model)"),WKo=l(),bb=a("li"),i4e=a("strong"),UKo=o("deberta"),HKo=o(" \u2014 "),SW=a("a"),JKo=o("DebertaForSequenceClassification"),YKo=o(" (DeBERTa model)"),KKo=l(),Fb=a("li"),d4e=a("strong"),ZKo=o("deberta-v2"),eZo=o(" \u2014 "),RW=a("a"),oZo=o("DebertaV2ForSequenceClassification"),rZo=o(" (DeBERTa-v2 model)"),tZo=l(),Tb=a("li"),c4e=a("strong"),aZo=o("distilbert"),nZo=o(" \u2014 "),PW=a("a"),sZo=o("DistilBertForSequenceClassification"),lZo=o(" (DistilBERT model)"),iZo=l(),Mb=a("li"),f4e=a("strong"),dZo=o("electra"),cZo=o(" \u2014 "),BW=a("a"),fZo=o("ElectraForSequenceClassification"),mZo=o(" (ELECTRA model)"),gZo=l(),Eb=a("li"),m4e=a("strong"),hZo=o("ernie"),uZo=o(" \u2014 "),IW=a("a"),pZo=o("ErnieForSequenceClassification"),_Zo=o(" (ERNIE model)"),vZo=l(),Cb=a("li"),g4e=a("strong"),bZo=o("flaubert"),FZo=o(" \u2014 "),NW=a("a"),TZo=o("FlaubertForSequenceClassification"),MZo=o(" (FlauBERT model)"),EZo=l(),wb=a("li"),h4e=a("strong"),CZo=o("fnet"),wZo=o(" \u2014 "),qW=a("a"),AZo=o("FNetForSequenceClassification"),LZo=o(" (FNet model)"),yZo=l(),Ab=a("li"),u4e=a("strong"),xZo=o("funnel"),$Zo=o(" \u2014 "),jW=a("a"),kZo=o("FunnelForSequenceClassification"),SZo=o(" (Funnel Transformer model)"),RZo=l(),Lb=a("li"),p4e=a("strong"),PZo=o("gpt2"),BZo=o(" \u2014 "),DW=a("a"),IZo=o("GPT2ForSequenceClassification"),NZo=o(" (OpenAI GPT-2 model)"),qZo=l(),yb=a("li"),_4e=a("strong"),jZo=o("gpt_neo"),DZo=o(" \u2014 "),GW=a("a"),GZo=o("GPTNeoForSequenceClassification"),OZo=o(" (GPT Neo model)"),VZo=l(),xb=a("li"),v4e=a("strong"),XZo=o("gptj"),zZo=o(" \u2014 "),OW=a("a"),QZo=o("GPTJForSequenceClassification"),WZo=o(" (GPT-J model)"),UZo=l(),$b=a("li"),b4e=a("strong"),HZo=o("ibert"),JZo=o(" \u2014 "),VW=a("a"),YZo=o("IBertForSequenceClassification"),KZo=o(" (I-BERT model)"),ZZo=l(),kb=a("li"),F4e=a("strong"),eer=o("layoutlm"),oer=o(" \u2014 "),XW=a("a"),rer=o("LayoutLMForSequenceClassification"),ter=o(" (LayoutLM model)"),aer=l(),Sb=a("li"),T4e=a("strong"),ner=o("layoutlmv2"),ser=o(" \u2014 "),zW=a("a"),ler=o("LayoutLMv2ForSequenceClassification"),ier=o(" (LayoutLMv2 model)"),der=l(),Rb=a("li"),M4e=a("strong"),cer=o("layoutlmv3"),fer=o(" \u2014 "),QW=a("a"),mer=o("LayoutLMv3ForSequenceClassification"),ger=o(" (LayoutLMv3 model)"),her=l(),Pb=a("li"),E4e=a("strong"),uer=o("led"),per=o(" \u2014 "),WW=a("a"),_er=o("LEDForSequenceClassification"),ver=o(" (LED model)"),ber=l(),Bb=a("li"),C4e=a("strong"),Fer=o("longformer"),Ter=o(" \u2014 "),UW=a("a"),Mer=o("LongformerForSequenceClassification"),Eer=o(" (Longformer model)"),Cer=l(),Ib=a("li"),w4e=a("strong"),wer=o("luke"),Aer=o(" \u2014 "),HW=a("a"),Ler=o("LukeForSequenceClassification"),yer=o(" (LUKE model)"),xer=l(),Nb=a("li"),A4e=a("strong"),$er=o("mbart"),ker=o(" \u2014 "),JW=a("a"),Ser=o("MBartForSequenceClassification"),Rer=o(" (mBART model)"),Per=l(),qb=a("li"),L4e=a("strong"),Ber=o("megatron-bert"),Ier=o(" \u2014 "),YW=a("a"),Ner=o("MegatronBertForSequenceClassification"),qer=o(" (Megatron-BERT model)"),jer=l(),jb=a("li"),y4e=a("strong"),Der=o("mobilebert"),Ger=o(" \u2014 "),KW=a("a"),Oer=o("MobileBertForSequenceClassification"),Ver=o(" (MobileBERT model)"),Xer=l(),Db=a("li"),x4e=a("strong"),zer=o("mpnet"),Qer=o(" \u2014 "),ZW=a("a"),Wer=o("MPNetForSequenceClassification"),Uer=o(" (MPNet model)"),Her=l(),Gb=a("li"),$4e=a("strong"),Jer=o("mvp"),Yer=o(" \u2014 "),eU=a("a"),Ker=o("MvpForSequenceClassification"),Zer=o(" (MVP model)"),eor=l(),Ob=a("li"),k4e=a("strong"),oor=o("nezha"),ror=o(" \u2014 "),oU=a("a"),tor=o("NezhaForSequenceClassification"),aor=o(" (Nezha model)"),nor=l(),Vb=a("li"),S4e=a("strong"),sor=o("nystromformer"),lor=o(" \u2014 "),rU=a("a"),ior=o("NystromformerForSequenceClassification"),dor=o(" (Nystr\xF6mformer model)"),cor=l(),Xb=a("li"),R4e=a("strong"),mor=o("openai-gpt"),gor=o(" \u2014 "),tU=a("a"),hor=o("OpenAIGPTForSequenceClassification"),uor=o(" (OpenAI GPT model)"),por=l(),zb=a("li"),P4e=a("strong"),_or=o("opt"),vor=o(" \u2014 "),aU=a("a"),bor=o("OPTForSequenceClassification"),For=o(" (OPT model)"),Tor=l(),Qb=a("li"),B4e=a("strong"),Mor=o("perceiver"),Eor=o(" \u2014 "),nU=a("a"),Cor=o("PerceiverForSequenceClassification"),wor=o(" (Perceiver model)"),Aor=l(),Wb=a("li"),I4e=a("strong"),Lor=o("plbart"),yor=o(" \u2014 "),sU=a("a"),xor=o("PLBartForSequenceClassification"),$or=o(" (PLBart model)"),kor=l(),Ub=a("li"),N4e=a("strong"),Sor=o("qdqbert"),Ror=o(" \u2014 "),lU=a("a"),Por=o("QDQBertForSequenceClassification"),Bor=o(" (QDQBert model)"),Ior=l(),Hb=a("li"),q4e=a("strong"),Nor=o("reformer"),qor=o(" \u2014 "),iU=a("a"),jor=o("ReformerForSequenceClassification"),Dor=o(" (Reformer model)"),Gor=l(),Jb=a("li"),j4e=a("strong"),Oor=o("rembert"),Vor=o(" \u2014 "),dU=a("a"),Xor=o("RemBertForSequenceClassification"),zor=o(" (RemBERT model)"),Qor=l(),Yb=a("li"),D4e=a("strong"),Wor=o("roberta"),Uor=o(" \u2014 "),cU=a("a"),Hor=o("RobertaForSequenceClassification"),Jor=o(" (RoBERTa model)"),Yor=l(),Kb=a("li"),G4e=a("strong"),Kor=o("roformer"),Zor=o(" \u2014 "),fU=a("a"),err=o("RoFormerForSequenceClassification"),orr=o(" (RoFormer model)"),rrr=l(),Zb=a("li"),O4e=a("strong"),trr=o("squeezebert"),arr=o(" \u2014 "),mU=a("a"),nrr=o("SqueezeBertForSequenceClassification"),srr=o(" (SqueezeBERT model)"),lrr=l(),eF=a("li"),V4e=a("strong"),irr=o("tapas"),drr=o(" \u2014 "),gU=a("a"),crr=o("TapasForSequenceClassification"),frr=o(" (TAPAS model)"),mrr=l(),oF=a("li"),X4e=a("strong"),grr=o("transfo-xl"),hrr=o(" \u2014 "),hU=a("a"),urr=o("TransfoXLForSequenceClassification"),prr=o(" (Transformer-XL model)"),_rr=l(),rF=a("li"),z4e=a("strong"),vrr=o("xlm"),brr=o(" \u2014 "),uU=a("a"),Frr=o("XLMForSequenceClassification"),Trr=o(" (XLM model)"),Mrr=l(),tF=a("li"),Q4e=a("strong"),Err=o("xlm-roberta"),Crr=o(" \u2014 "),pU=a("a"),wrr=o("XLMRobertaForSequenceClassification"),Arr=o(" (XLM-RoBERTa model)"),Lrr=l(),aF=a("li"),W4e=a("strong"),yrr=o("xlm-roberta-xl"),xrr=o(" \u2014 "),_U=a("a"),$rr=o("XLMRobertaXLForSequenceClassification"),krr=o(" (XLM-RoBERTa-XL model)"),Srr=l(),nF=a("li"),U4e=a("strong"),Rrr=o("xlnet"),Prr=o(" \u2014 "),vU=a("a"),Brr=o("XLNetForSequenceClassification"),Irr=o(" (XLNet model)"),Nrr=l(),sF=a("li"),H4e=a("strong"),qrr=o("yoso"),jrr=o(" \u2014 "),bU=a("a"),Drr=o("YosoForSequenceClassification"),Grr=o(" (YOSO model)"),Orr=l(),lF=a("p"),Vrr=o("The model is set in evaluation mode by default using "),J4e=a("code"),Xrr=o("model.eval()"),zrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y4e=a("code"),Qrr=o("model.train()"),Wrr=l(),F(iF.$$.fragment),rKe=l(),Pd=a("h2"),dF=a("a"),K4e=a("span"),F(wx.$$.fragment),Urr=l(),Z4e=a("span"),Hrr=o("AutoModelForMultipleChoice"),tKe=l(),Do=a("div"),F(Ax.$$.fragment),Jrr=l(),Bd=a("p"),Yrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FU=a("a"),Krr=o("from_pretrained()"),Zrr=o(" class method or the "),TU=a("a"),etr=o("from_config()"),otr=o(` class
method.`),rtr=l(),Lx=a("p"),ttr=o("This class cannot be instantiated directly using "),ebe=a("code"),atr=o("__init__()"),ntr=o(" (throws an error)."),str=l(),Et=a("div"),F(yx.$$.fragment),ltr=l(),obe=a("p"),itr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),dtr=l(),Id=a("p"),ctr=o(`Note:
Loading a model from its configuration file does `),rbe=a("strong"),ftr=o("not"),mtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=a("a"),gtr=o("from_pretrained()"),htr=o(" to load the model weights."),utr=l(),F(cF.$$.fragment),ptr=l(),no=a("div"),F(xx.$$.fragment),_tr=l(),tbe=a("p"),vtr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),btr=l(),rn=a("p"),Ftr=o("The model class to instantiate is selected based on the "),abe=a("code"),Ttr=o("model_type"),Mtr=o(` property of the config object (either
passed as an argument or loaded from `),nbe=a("code"),Etr=o("pretrained_model_name_or_path"),Ctr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sbe=a("code"),wtr=o("pretrained_model_name_or_path"),Atr=o(":"),Ltr=l(),Z=a("ul"),fF=a("li"),lbe=a("strong"),ytr=o("albert"),xtr=o(" \u2014 "),EU=a("a"),$tr=o("AlbertForMultipleChoice"),ktr=o(" (ALBERT model)"),Str=l(),mF=a("li"),ibe=a("strong"),Rtr=o("bert"),Ptr=o(" \u2014 "),CU=a("a"),Btr=o("BertForMultipleChoice"),Itr=o(" (BERT model)"),Ntr=l(),gF=a("li"),dbe=a("strong"),qtr=o("big_bird"),jtr=o(" \u2014 "),wU=a("a"),Dtr=o("BigBirdForMultipleChoice"),Gtr=o(" (BigBird model)"),Otr=l(),hF=a("li"),cbe=a("strong"),Vtr=o("camembert"),Xtr=o(" \u2014 "),AU=a("a"),ztr=o("CamembertForMultipleChoice"),Qtr=o(" (CamemBERT model)"),Wtr=l(),uF=a("li"),fbe=a("strong"),Utr=o("canine"),Htr=o(" \u2014 "),LU=a("a"),Jtr=o("CanineForMultipleChoice"),Ytr=o(" (CANINE model)"),Ktr=l(),pF=a("li"),mbe=a("strong"),Ztr=o("convbert"),ear=o(" \u2014 "),yU=a("a"),oar=o("ConvBertForMultipleChoice"),rar=o(" (ConvBERT model)"),tar=l(),_F=a("li"),gbe=a("strong"),aar=o("data2vec-text"),nar=o(" \u2014 "),xU=a("a"),sar=o("Data2VecTextForMultipleChoice"),lar=o(" (Data2VecText model)"),iar=l(),vF=a("li"),hbe=a("strong"),dar=o("deberta-v2"),car=o(" \u2014 "),$U=a("a"),far=o("DebertaV2ForMultipleChoice"),mar=o(" (DeBERTa-v2 model)"),gar=l(),bF=a("li"),ube=a("strong"),har=o("distilbert"),uar=o(" \u2014 "),kU=a("a"),par=o("DistilBertForMultipleChoice"),_ar=o(" (DistilBERT model)"),bar=l(),FF=a("li"),pbe=a("strong"),Far=o("electra"),Tar=o(" \u2014 "),SU=a("a"),Mar=o("ElectraForMultipleChoice"),Ear=o(" (ELECTRA model)"),Car=l(),TF=a("li"),_be=a("strong"),war=o("ernie"),Aar=o(" \u2014 "),RU=a("a"),Lar=o("ErnieForMultipleChoice"),yar=o(" (ERNIE model)"),xar=l(),MF=a("li"),vbe=a("strong"),$ar=o("flaubert"),kar=o(" \u2014 "),PU=a("a"),Sar=o("FlaubertForMultipleChoice"),Rar=o(" (FlauBERT model)"),Par=l(),EF=a("li"),bbe=a("strong"),Bar=o("fnet"),Iar=o(" \u2014 "),BU=a("a"),Nar=o("FNetForMultipleChoice"),qar=o(" (FNet model)"),jar=l(),CF=a("li"),Fbe=a("strong"),Dar=o("funnel"),Gar=o(" \u2014 "),IU=a("a"),Oar=o("FunnelForMultipleChoice"),Var=o(" (Funnel Transformer model)"),Xar=l(),wF=a("li"),Tbe=a("strong"),zar=o("ibert"),Qar=o(" \u2014 "),NU=a("a"),War=o("IBertForMultipleChoice"),Uar=o(" (I-BERT model)"),Har=l(),AF=a("li"),Mbe=a("strong"),Jar=o("longformer"),Yar=o(" \u2014 "),qU=a("a"),Kar=o("LongformerForMultipleChoice"),Zar=o(" (Longformer model)"),enr=l(),LF=a("li"),Ebe=a("strong"),onr=o("luke"),rnr=o(" \u2014 "),jU=a("a"),tnr=o("LukeForMultipleChoice"),anr=o(" (LUKE model)"),nnr=l(),yF=a("li"),Cbe=a("strong"),snr=o("megatron-bert"),lnr=o(" \u2014 "),DU=a("a"),inr=o("MegatronBertForMultipleChoice"),dnr=o(" (Megatron-BERT model)"),cnr=l(),xF=a("li"),wbe=a("strong"),fnr=o("mobilebert"),mnr=o(" \u2014 "),GU=a("a"),gnr=o("MobileBertForMultipleChoice"),hnr=o(" (MobileBERT model)"),unr=l(),$F=a("li"),Abe=a("strong"),pnr=o("mpnet"),_nr=o(" \u2014 "),OU=a("a"),vnr=o("MPNetForMultipleChoice"),bnr=o(" (MPNet model)"),Fnr=l(),kF=a("li"),Lbe=a("strong"),Tnr=o("nezha"),Mnr=o(" \u2014 "),VU=a("a"),Enr=o("NezhaForMultipleChoice"),Cnr=o(" (Nezha model)"),wnr=l(),SF=a("li"),ybe=a("strong"),Anr=o("nystromformer"),Lnr=o(" \u2014 "),XU=a("a"),ynr=o("NystromformerForMultipleChoice"),xnr=o(" (Nystr\xF6mformer model)"),$nr=l(),RF=a("li"),xbe=a("strong"),knr=o("qdqbert"),Snr=o(" \u2014 "),zU=a("a"),Rnr=o("QDQBertForMultipleChoice"),Pnr=o(" (QDQBert model)"),Bnr=l(),PF=a("li"),$be=a("strong"),Inr=o("rembert"),Nnr=o(" \u2014 "),QU=a("a"),qnr=o("RemBertForMultipleChoice"),jnr=o(" (RemBERT model)"),Dnr=l(),BF=a("li"),kbe=a("strong"),Gnr=o("roberta"),Onr=o(" \u2014 "),WU=a("a"),Vnr=o("RobertaForMultipleChoice"),Xnr=o(" (RoBERTa model)"),znr=l(),IF=a("li"),Sbe=a("strong"),Qnr=o("roformer"),Wnr=o(" \u2014 "),UU=a("a"),Unr=o("RoFormerForMultipleChoice"),Hnr=o(" (RoFormer model)"),Jnr=l(),NF=a("li"),Rbe=a("strong"),Ynr=o("squeezebert"),Knr=o(" \u2014 "),HU=a("a"),Znr=o("SqueezeBertForMultipleChoice"),esr=o(" (SqueezeBERT model)"),osr=l(),qF=a("li"),Pbe=a("strong"),rsr=o("xlm"),tsr=o(" \u2014 "),JU=a("a"),asr=o("XLMForMultipleChoice"),nsr=o(" (XLM model)"),ssr=l(),jF=a("li"),Bbe=a("strong"),lsr=o("xlm-roberta"),isr=o(" \u2014 "),YU=a("a"),dsr=o("XLMRobertaForMultipleChoice"),csr=o(" (XLM-RoBERTa model)"),fsr=l(),DF=a("li"),Ibe=a("strong"),msr=o("xlm-roberta-xl"),gsr=o(" \u2014 "),KU=a("a"),hsr=o("XLMRobertaXLForMultipleChoice"),usr=o(" (XLM-RoBERTa-XL model)"),psr=l(),GF=a("li"),Nbe=a("strong"),_sr=o("xlnet"),vsr=o(" \u2014 "),ZU=a("a"),bsr=o("XLNetForMultipleChoice"),Fsr=o(" (XLNet model)"),Tsr=l(),OF=a("li"),qbe=a("strong"),Msr=o("yoso"),Esr=o(" \u2014 "),eH=a("a"),Csr=o("YosoForMultipleChoice"),wsr=o(" (YOSO model)"),Asr=l(),VF=a("p"),Lsr=o("The model is set in evaluation mode by default using "),jbe=a("code"),ysr=o("model.eval()"),xsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dbe=a("code"),$sr=o("model.train()"),ksr=l(),F(XF.$$.fragment),aKe=l(),Nd=a("h2"),zF=a("a"),Gbe=a("span"),F($x.$$.fragment),Ssr=l(),Obe=a("span"),Rsr=o("AutoModelForNextSentencePrediction"),nKe=l(),Go=a("div"),F(kx.$$.fragment),Psr=l(),qd=a("p"),Bsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oH=a("a"),Isr=o("from_pretrained()"),Nsr=o(" class method or the "),rH=a("a"),qsr=o("from_config()"),jsr=o(` class
method.`),Dsr=l(),Sx=a("p"),Gsr=o("This class cannot be instantiated directly using "),Vbe=a("code"),Osr=o("__init__()"),Vsr=o(" (throws an error)."),Xsr=l(),Ct=a("div"),F(Rx.$$.fragment),zsr=l(),Xbe=a("p"),Qsr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wsr=l(),jd=a("p"),Usr=o(`Note:
Loading a model from its configuration file does `),zbe=a("strong"),Hsr=o("not"),Jsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=a("a"),Ysr=o("from_pretrained()"),Ksr=o(" to load the model weights."),Zsr=l(),F(QF.$$.fragment),elr=l(),so=a("div"),F(Px.$$.fragment),olr=l(),Qbe=a("p"),rlr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),tlr=l(),tn=a("p"),alr=o("The model class to instantiate is selected based on the "),Wbe=a("code"),nlr=o("model_type"),slr=o(` property of the config object (either
passed as an argument or loaded from `),Ube=a("code"),llr=o("pretrained_model_name_or_path"),ilr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hbe=a("code"),dlr=o("pretrained_model_name_or_path"),clr=o(":"),flr=l(),Ue=a("ul"),WF=a("li"),Jbe=a("strong"),mlr=o("bert"),glr=o(" \u2014 "),aH=a("a"),hlr=o("BertForNextSentencePrediction"),ulr=o(" (BERT model)"),plr=l(),UF=a("li"),Ybe=a("strong"),_lr=o("ernie"),vlr=o(" \u2014 "),nH=a("a"),blr=o("ErnieForNextSentencePrediction"),Flr=o(" (ERNIE model)"),Tlr=l(),HF=a("li"),Kbe=a("strong"),Mlr=o("fnet"),Elr=o(" \u2014 "),sH=a("a"),Clr=o("FNetForNextSentencePrediction"),wlr=o(" (FNet model)"),Alr=l(),JF=a("li"),Zbe=a("strong"),Llr=o("megatron-bert"),ylr=o(" \u2014 "),lH=a("a"),xlr=o("MegatronBertForNextSentencePrediction"),$lr=o(" (Megatron-BERT model)"),klr=l(),YF=a("li"),eFe=a("strong"),Slr=o("mobilebert"),Rlr=o(" \u2014 "),iH=a("a"),Plr=o("MobileBertForNextSentencePrediction"),Blr=o(" (MobileBERT model)"),Ilr=l(),KF=a("li"),oFe=a("strong"),Nlr=o("nezha"),qlr=o(" \u2014 "),dH=a("a"),jlr=o("NezhaForNextSentencePrediction"),Dlr=o(" (Nezha model)"),Glr=l(),ZF=a("li"),rFe=a("strong"),Olr=o("qdqbert"),Vlr=o(" \u2014 "),cH=a("a"),Xlr=o("QDQBertForNextSentencePrediction"),zlr=o(" (QDQBert model)"),Qlr=l(),eT=a("p"),Wlr=o("The model is set in evaluation mode by default using "),tFe=a("code"),Ulr=o("model.eval()"),Hlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aFe=a("code"),Jlr=o("model.train()"),Ylr=l(),F(oT.$$.fragment),sKe=l(),Dd=a("h2"),rT=a("a"),nFe=a("span"),F(Bx.$$.fragment),Klr=l(),sFe=a("span"),Zlr=o("AutoModelForTokenClassification"),lKe=l(),Oo=a("div"),F(Ix.$$.fragment),eir=l(),Gd=a("p"),oir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fH=a("a"),rir=o("from_pretrained()"),tir=o(" class method or the "),mH=a("a"),air=o("from_config()"),nir=o(` class
method.`),sir=l(),Nx=a("p"),lir=o("This class cannot be instantiated directly using "),lFe=a("code"),iir=o("__init__()"),dir=o(" (throws an error)."),cir=l(),wt=a("div"),F(qx.$$.fragment),fir=l(),iFe=a("p"),mir=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gir=l(),Od=a("p"),hir=o(`Note:
Loading a model from its configuration file does `),dFe=a("strong"),uir=o("not"),pir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=a("a"),_ir=o("from_pretrained()"),vir=o(" to load the model weights."),bir=l(),F(tT.$$.fragment),Fir=l(),lo=a("div"),F(jx.$$.fragment),Tir=l(),cFe=a("p"),Mir=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Eir=l(),an=a("p"),Cir=o("The model class to instantiate is selected based on the "),fFe=a("code"),wir=o("model_type"),Air=o(` property of the config object (either
passed as an argument or loaded from `),mFe=a("code"),Lir=o("pretrained_model_name_or_path"),yir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gFe=a("code"),xir=o("pretrained_model_name_or_path"),$ir=o(":"),kir=l(),H=a("ul"),aT=a("li"),hFe=a("strong"),Sir=o("albert"),Rir=o(" \u2014 "),hH=a("a"),Pir=o("AlbertForTokenClassification"),Bir=o(" (ALBERT model)"),Iir=l(),nT=a("li"),uFe=a("strong"),Nir=o("bert"),qir=o(" \u2014 "),uH=a("a"),jir=o("BertForTokenClassification"),Dir=o(" (BERT model)"),Gir=l(),sT=a("li"),pFe=a("strong"),Oir=o("big_bird"),Vir=o(" \u2014 "),pH=a("a"),Xir=o("BigBirdForTokenClassification"),zir=o(" (BigBird model)"),Qir=l(),lT=a("li"),_Fe=a("strong"),Wir=o("bloom"),Uir=o(" \u2014 "),_H=a("a"),Hir=o("BloomForTokenClassification"),Jir=o(" (BLOOM model)"),Yir=l(),iT=a("li"),vFe=a("strong"),Kir=o("camembert"),Zir=o(" \u2014 "),vH=a("a"),edr=o("CamembertForTokenClassification"),odr=o(" (CamemBERT model)"),rdr=l(),dT=a("li"),bFe=a("strong"),tdr=o("canine"),adr=o(" \u2014 "),bH=a("a"),ndr=o("CanineForTokenClassification"),sdr=o(" (CANINE model)"),ldr=l(),cT=a("li"),FFe=a("strong"),idr=o("convbert"),ddr=o(" \u2014 "),FH=a("a"),cdr=o("ConvBertForTokenClassification"),fdr=o(" (ConvBERT model)"),mdr=l(),fT=a("li"),TFe=a("strong"),gdr=o("data2vec-text"),hdr=o(" \u2014 "),TH=a("a"),udr=o("Data2VecTextForTokenClassification"),pdr=o(" (Data2VecText model)"),_dr=l(),mT=a("li"),MFe=a("strong"),vdr=o("deberta"),bdr=o(" \u2014 "),MH=a("a"),Fdr=o("DebertaForTokenClassification"),Tdr=o(" (DeBERTa model)"),Mdr=l(),gT=a("li"),EFe=a("strong"),Edr=o("deberta-v2"),Cdr=o(" \u2014 "),EH=a("a"),wdr=o("DebertaV2ForTokenClassification"),Adr=o(" (DeBERTa-v2 model)"),Ldr=l(),hT=a("li"),CFe=a("strong"),ydr=o("distilbert"),xdr=o(" \u2014 "),CH=a("a"),$dr=o("DistilBertForTokenClassification"),kdr=o(" (DistilBERT model)"),Sdr=l(),uT=a("li"),wFe=a("strong"),Rdr=o("electra"),Pdr=o(" \u2014 "),wH=a("a"),Bdr=o("ElectraForTokenClassification"),Idr=o(" (ELECTRA model)"),Ndr=l(),pT=a("li"),AFe=a("strong"),qdr=o("ernie"),jdr=o(" \u2014 "),AH=a("a"),Ddr=o("ErnieForTokenClassification"),Gdr=o(" (ERNIE model)"),Odr=l(),_T=a("li"),LFe=a("strong"),Vdr=o("flaubert"),Xdr=o(" \u2014 "),LH=a("a"),zdr=o("FlaubertForTokenClassification"),Qdr=o(" (FlauBERT model)"),Wdr=l(),vT=a("li"),yFe=a("strong"),Udr=o("fnet"),Hdr=o(" \u2014 "),yH=a("a"),Jdr=o("FNetForTokenClassification"),Ydr=o(" (FNet model)"),Kdr=l(),bT=a("li"),xFe=a("strong"),Zdr=o("funnel"),ecr=o(" \u2014 "),xH=a("a"),ocr=o("FunnelForTokenClassification"),rcr=o(" (Funnel Transformer model)"),tcr=l(),FT=a("li"),$Fe=a("strong"),acr=o("gpt2"),ncr=o(" \u2014 "),$H=a("a"),scr=o("GPT2ForTokenClassification"),lcr=o(" (OpenAI GPT-2 model)"),icr=l(),TT=a("li"),kFe=a("strong"),dcr=o("ibert"),ccr=o(" \u2014 "),kH=a("a"),fcr=o("IBertForTokenClassification"),mcr=o(" (I-BERT model)"),gcr=l(),MT=a("li"),SFe=a("strong"),hcr=o("layoutlm"),ucr=o(" \u2014 "),SH=a("a"),pcr=o("LayoutLMForTokenClassification"),_cr=o(" (LayoutLM model)"),vcr=l(),ET=a("li"),RFe=a("strong"),bcr=o("layoutlmv2"),Fcr=o(" \u2014 "),RH=a("a"),Tcr=o("LayoutLMv2ForTokenClassification"),Mcr=o(" (LayoutLMv2 model)"),Ecr=l(),CT=a("li"),PFe=a("strong"),Ccr=o("layoutlmv3"),wcr=o(" \u2014 "),PH=a("a"),Acr=o("LayoutLMv3ForTokenClassification"),Lcr=o(" (LayoutLMv3 model)"),ycr=l(),wT=a("li"),BFe=a("strong"),xcr=o("longformer"),$cr=o(" \u2014 "),BH=a("a"),kcr=o("LongformerForTokenClassification"),Scr=o(" (Longformer model)"),Rcr=l(),AT=a("li"),IFe=a("strong"),Pcr=o("luke"),Bcr=o(" \u2014 "),IH=a("a"),Icr=o("LukeForTokenClassification"),Ncr=o(" (LUKE model)"),qcr=l(),LT=a("li"),NFe=a("strong"),jcr=o("megatron-bert"),Dcr=o(" \u2014 "),NH=a("a"),Gcr=o("MegatronBertForTokenClassification"),Ocr=o(" (Megatron-BERT model)"),Vcr=l(),yT=a("li"),qFe=a("strong"),Xcr=o("mobilebert"),zcr=o(" \u2014 "),qH=a("a"),Qcr=o("MobileBertForTokenClassification"),Wcr=o(" (MobileBERT model)"),Ucr=l(),xT=a("li"),jFe=a("strong"),Hcr=o("mpnet"),Jcr=o(" \u2014 "),jH=a("a"),Ycr=o("MPNetForTokenClassification"),Kcr=o(" (MPNet model)"),Zcr=l(),$T=a("li"),DFe=a("strong"),efr=o("nezha"),ofr=o(" \u2014 "),DH=a("a"),rfr=o("NezhaForTokenClassification"),tfr=o(" (Nezha model)"),afr=l(),kT=a("li"),GFe=a("strong"),nfr=o("nystromformer"),sfr=o(" \u2014 "),GH=a("a"),lfr=o("NystromformerForTokenClassification"),ifr=o(" (Nystr\xF6mformer model)"),dfr=l(),ST=a("li"),OFe=a("strong"),cfr=o("qdqbert"),ffr=o(" \u2014 "),OH=a("a"),mfr=o("QDQBertForTokenClassification"),gfr=o(" (QDQBert model)"),hfr=l(),RT=a("li"),VFe=a("strong"),ufr=o("rembert"),pfr=o(" \u2014 "),VH=a("a"),_fr=o("RemBertForTokenClassification"),vfr=o(" (RemBERT model)"),bfr=l(),PT=a("li"),XFe=a("strong"),Ffr=o("roberta"),Tfr=o(" \u2014 "),XH=a("a"),Mfr=o("RobertaForTokenClassification"),Efr=o(" (RoBERTa model)"),Cfr=l(),BT=a("li"),zFe=a("strong"),wfr=o("roformer"),Afr=o(" \u2014 "),zH=a("a"),Lfr=o("RoFormerForTokenClassification"),yfr=o(" (RoFormer model)"),xfr=l(),IT=a("li"),QFe=a("strong"),$fr=o("squeezebert"),kfr=o(" \u2014 "),QH=a("a"),Sfr=o("SqueezeBertForTokenClassification"),Rfr=o(" (SqueezeBERT model)"),Pfr=l(),NT=a("li"),WFe=a("strong"),Bfr=o("xlm"),Ifr=o(" \u2014 "),WH=a("a"),Nfr=o("XLMForTokenClassification"),qfr=o(" (XLM model)"),jfr=l(),qT=a("li"),UFe=a("strong"),Dfr=o("xlm-roberta"),Gfr=o(" \u2014 "),UH=a("a"),Ofr=o("XLMRobertaForTokenClassification"),Vfr=o(" (XLM-RoBERTa model)"),Xfr=l(),jT=a("li"),HFe=a("strong"),zfr=o("xlm-roberta-xl"),Qfr=o(" \u2014 "),HH=a("a"),Wfr=o("XLMRobertaXLForTokenClassification"),Ufr=o(" (XLM-RoBERTa-XL model)"),Hfr=l(),DT=a("li"),JFe=a("strong"),Jfr=o("xlnet"),Yfr=o(" \u2014 "),JH=a("a"),Kfr=o("XLNetForTokenClassification"),Zfr=o(" (XLNet model)"),emr=l(),GT=a("li"),YFe=a("strong"),omr=o("yoso"),rmr=o(" \u2014 "),YH=a("a"),tmr=o("YosoForTokenClassification"),amr=o(" (YOSO model)"),nmr=l(),OT=a("p"),smr=o("The model is set in evaluation mode by default using "),KFe=a("code"),lmr=o("model.eval()"),imr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZFe=a("code"),dmr=o("model.train()"),cmr=l(),F(VT.$$.fragment),iKe=l(),Vd=a("h2"),XT=a("a"),eTe=a("span"),F(Dx.$$.fragment),fmr=l(),oTe=a("span"),mmr=o("AutoModelForQuestionAnswering"),dKe=l(),Vo=a("div"),F(Gx.$$.fragment),gmr=l(),Xd=a("p"),hmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KH=a("a"),umr=o("from_pretrained()"),pmr=o(" class method or the "),ZH=a("a"),_mr=o("from_config()"),vmr=o(` class
method.`),bmr=l(),Ox=a("p"),Fmr=o("This class cannot be instantiated directly using "),rTe=a("code"),Tmr=o("__init__()"),Mmr=o(" (throws an error)."),Emr=l(),At=a("div"),F(Vx.$$.fragment),Cmr=l(),tTe=a("p"),wmr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Amr=l(),zd=a("p"),Lmr=o(`Note:
Loading a model from its configuration file does `),aTe=a("strong"),ymr=o("not"),xmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),$mr=o("from_pretrained()"),kmr=o(" to load the model weights."),Smr=l(),F(zT.$$.fragment),Rmr=l(),io=a("div"),F(Xx.$$.fragment),Pmr=l(),nTe=a("p"),Bmr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Imr=l(),nn=a("p"),Nmr=o("The model class to instantiate is selected based on the "),sTe=a("code"),qmr=o("model_type"),jmr=o(` property of the config object (either
passed as an argument or loaded from `),lTe=a("code"),Dmr=o("pretrained_model_name_or_path"),Gmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=a("code"),Omr=o("pretrained_model_name_or_path"),Vmr=o(":"),Xmr=l(),V=a("ul"),QT=a("li"),dTe=a("strong"),zmr=o("albert"),Qmr=o(" \u2014 "),oJ=a("a"),Wmr=o("AlbertForQuestionAnswering"),Umr=o(" (ALBERT model)"),Hmr=l(),WT=a("li"),cTe=a("strong"),Jmr=o("bart"),Ymr=o(" \u2014 "),rJ=a("a"),Kmr=o("BartForQuestionAnswering"),Zmr=o(" (BART model)"),egr=l(),UT=a("li"),fTe=a("strong"),ogr=o("bert"),rgr=o(" \u2014 "),tJ=a("a"),tgr=o("BertForQuestionAnswering"),agr=o(" (BERT model)"),ngr=l(),HT=a("li"),mTe=a("strong"),sgr=o("big_bird"),lgr=o(" \u2014 "),aJ=a("a"),igr=o("BigBirdForQuestionAnswering"),dgr=o(" (BigBird model)"),cgr=l(),JT=a("li"),gTe=a("strong"),fgr=o("bigbird_pegasus"),mgr=o(" \u2014 "),nJ=a("a"),ggr=o("BigBirdPegasusForQuestionAnswering"),hgr=o(" (BigBird-Pegasus model)"),ugr=l(),YT=a("li"),hTe=a("strong"),pgr=o("camembert"),_gr=o(" \u2014 "),sJ=a("a"),vgr=o("CamembertForQuestionAnswering"),bgr=o(" (CamemBERT model)"),Fgr=l(),KT=a("li"),uTe=a("strong"),Tgr=o("canine"),Mgr=o(" \u2014 "),lJ=a("a"),Egr=o("CanineForQuestionAnswering"),Cgr=o(" (CANINE model)"),wgr=l(),ZT=a("li"),pTe=a("strong"),Agr=o("convbert"),Lgr=o(" \u2014 "),iJ=a("a"),ygr=o("ConvBertForQuestionAnswering"),xgr=o(" (ConvBERT model)"),$gr=l(),eM=a("li"),_Te=a("strong"),kgr=o("data2vec-text"),Sgr=o(" \u2014 "),dJ=a("a"),Rgr=o("Data2VecTextForQuestionAnswering"),Pgr=o(" (Data2VecText model)"),Bgr=l(),oM=a("li"),vTe=a("strong"),Igr=o("deberta"),Ngr=o(" \u2014 "),cJ=a("a"),qgr=o("DebertaForQuestionAnswering"),jgr=o(" (DeBERTa model)"),Dgr=l(),rM=a("li"),bTe=a("strong"),Ggr=o("deberta-v2"),Ogr=o(" \u2014 "),fJ=a("a"),Vgr=o("DebertaV2ForQuestionAnswering"),Xgr=o(" (DeBERTa-v2 model)"),zgr=l(),tM=a("li"),FTe=a("strong"),Qgr=o("distilbert"),Wgr=o(" \u2014 "),mJ=a("a"),Ugr=o("DistilBertForQuestionAnswering"),Hgr=o(" (DistilBERT model)"),Jgr=l(),aM=a("li"),TTe=a("strong"),Ygr=o("electra"),Kgr=o(" \u2014 "),gJ=a("a"),Zgr=o("ElectraForQuestionAnswering"),ehr=o(" (ELECTRA model)"),ohr=l(),nM=a("li"),MTe=a("strong"),rhr=o("ernie"),thr=o(" \u2014 "),hJ=a("a"),ahr=o("ErnieForQuestionAnswering"),nhr=o(" (ERNIE model)"),shr=l(),sM=a("li"),ETe=a("strong"),lhr=o("flaubert"),ihr=o(" \u2014 "),uJ=a("a"),dhr=o("FlaubertForQuestionAnsweringSimple"),chr=o(" (FlauBERT model)"),fhr=l(),lM=a("li"),CTe=a("strong"),mhr=o("fnet"),ghr=o(" \u2014 "),pJ=a("a"),hhr=o("FNetForQuestionAnswering"),uhr=o(" (FNet model)"),phr=l(),iM=a("li"),wTe=a("strong"),_hr=o("funnel"),vhr=o(" \u2014 "),_J=a("a"),bhr=o("FunnelForQuestionAnswering"),Fhr=o(" (Funnel Transformer model)"),Thr=l(),dM=a("li"),ATe=a("strong"),Mhr=o("gptj"),Ehr=o(" \u2014 "),vJ=a("a"),Chr=o("GPTJForQuestionAnswering"),whr=o(" (GPT-J model)"),Ahr=l(),cM=a("li"),LTe=a("strong"),Lhr=o("ibert"),yhr=o(" \u2014 "),bJ=a("a"),xhr=o("IBertForQuestionAnswering"),$hr=o(" (I-BERT model)"),khr=l(),fM=a("li"),yTe=a("strong"),Shr=o("layoutlmv2"),Rhr=o(" \u2014 "),FJ=a("a"),Phr=o("LayoutLMv2ForQuestionAnswering"),Bhr=o(" (LayoutLMv2 model)"),Ihr=l(),mM=a("li"),xTe=a("strong"),Nhr=o("layoutlmv3"),qhr=o(" \u2014 "),TJ=a("a"),jhr=o("LayoutLMv3ForQuestionAnswering"),Dhr=o(" (LayoutLMv3 model)"),Ghr=l(),gM=a("li"),$Te=a("strong"),Ohr=o("led"),Vhr=o(" \u2014 "),MJ=a("a"),Xhr=o("LEDForQuestionAnswering"),zhr=o(" (LED model)"),Qhr=l(),hM=a("li"),kTe=a("strong"),Whr=o("longformer"),Uhr=o(" \u2014 "),EJ=a("a"),Hhr=o("LongformerForQuestionAnswering"),Jhr=o(" (Longformer model)"),Yhr=l(),uM=a("li"),STe=a("strong"),Khr=o("luke"),Zhr=o(" \u2014 "),CJ=a("a"),eur=o("LukeForQuestionAnswering"),our=o(" (LUKE model)"),rur=l(),pM=a("li"),RTe=a("strong"),tur=o("lxmert"),aur=o(" \u2014 "),wJ=a("a"),nur=o("LxmertForQuestionAnswering"),sur=o(" (LXMERT model)"),lur=l(),_M=a("li"),PTe=a("strong"),iur=o("mbart"),dur=o(" \u2014 "),AJ=a("a"),cur=o("MBartForQuestionAnswering"),fur=o(" (mBART model)"),mur=l(),vM=a("li"),BTe=a("strong"),gur=o("megatron-bert"),hur=o(" \u2014 "),LJ=a("a"),uur=o("MegatronBertForQuestionAnswering"),pur=o(" (Megatron-BERT model)"),_ur=l(),bM=a("li"),ITe=a("strong"),vur=o("mobilebert"),bur=o(" \u2014 "),yJ=a("a"),Fur=o("MobileBertForQuestionAnswering"),Tur=o(" (MobileBERT model)"),Mur=l(),FM=a("li"),NTe=a("strong"),Eur=o("mpnet"),Cur=o(" \u2014 "),xJ=a("a"),wur=o("MPNetForQuestionAnswering"),Aur=o(" (MPNet model)"),Lur=l(),TM=a("li"),qTe=a("strong"),yur=o("mvp"),xur=o(" \u2014 "),$J=a("a"),$ur=o("MvpForQuestionAnswering"),kur=o(" (MVP model)"),Sur=l(),MM=a("li"),jTe=a("strong"),Rur=o("nezha"),Pur=o(" \u2014 "),kJ=a("a"),Bur=o("NezhaForQuestionAnswering"),Iur=o(" (Nezha model)"),Nur=l(),EM=a("li"),DTe=a("strong"),qur=o("nystromformer"),jur=o(" \u2014 "),SJ=a("a"),Dur=o("NystromformerForQuestionAnswering"),Gur=o(" (Nystr\xF6mformer model)"),Our=l(),CM=a("li"),GTe=a("strong"),Vur=o("qdqbert"),Xur=o(" \u2014 "),RJ=a("a"),zur=o("QDQBertForQuestionAnswering"),Qur=o(" (QDQBert model)"),Wur=l(),wM=a("li"),OTe=a("strong"),Uur=o("reformer"),Hur=o(" \u2014 "),PJ=a("a"),Jur=o("ReformerForQuestionAnswering"),Yur=o(" (Reformer model)"),Kur=l(),AM=a("li"),VTe=a("strong"),Zur=o("rembert"),epr=o(" \u2014 "),BJ=a("a"),opr=o("RemBertForQuestionAnswering"),rpr=o(" (RemBERT model)"),tpr=l(),LM=a("li"),XTe=a("strong"),apr=o("roberta"),npr=o(" \u2014 "),IJ=a("a"),spr=o("RobertaForQuestionAnswering"),lpr=o(" (RoBERTa model)"),ipr=l(),yM=a("li"),zTe=a("strong"),dpr=o("roformer"),cpr=o(" \u2014 "),NJ=a("a"),fpr=o("RoFormerForQuestionAnswering"),mpr=o(" (RoFormer model)"),gpr=l(),xM=a("li"),QTe=a("strong"),hpr=o("splinter"),upr=o(" \u2014 "),qJ=a("a"),ppr=o("SplinterForQuestionAnswering"),_pr=o(" (Splinter model)"),vpr=l(),$M=a("li"),WTe=a("strong"),bpr=o("squeezebert"),Fpr=o(" \u2014 "),jJ=a("a"),Tpr=o("SqueezeBertForQuestionAnswering"),Mpr=o(" (SqueezeBERT model)"),Epr=l(),kM=a("li"),UTe=a("strong"),Cpr=o("xlm"),wpr=o(" \u2014 "),DJ=a("a"),Apr=o("XLMForQuestionAnsweringSimple"),Lpr=o(" (XLM model)"),ypr=l(),SM=a("li"),HTe=a("strong"),xpr=o("xlm-roberta"),$pr=o(" \u2014 "),GJ=a("a"),kpr=o("XLMRobertaForQuestionAnswering"),Spr=o(" (XLM-RoBERTa model)"),Rpr=l(),RM=a("li"),JTe=a("strong"),Ppr=o("xlm-roberta-xl"),Bpr=o(" \u2014 "),OJ=a("a"),Ipr=o("XLMRobertaXLForQuestionAnswering"),Npr=o(" (XLM-RoBERTa-XL model)"),qpr=l(),PM=a("li"),YTe=a("strong"),jpr=o("xlnet"),Dpr=o(" \u2014 "),VJ=a("a"),Gpr=o("XLNetForQuestionAnsweringSimple"),Opr=o(" (XLNet model)"),Vpr=l(),BM=a("li"),KTe=a("strong"),Xpr=o("yoso"),zpr=o(" \u2014 "),XJ=a("a"),Qpr=o("YosoForQuestionAnswering"),Wpr=o(" (YOSO model)"),Upr=l(),IM=a("p"),Hpr=o("The model is set in evaluation mode by default using "),ZTe=a("code"),Jpr=o("model.eval()"),Ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eMe=a("code"),Kpr=o("model.train()"),Zpr=l(),F(NM.$$.fragment),cKe=l(),Qd=a("h2"),qM=a("a"),oMe=a("span"),F(zx.$$.fragment),e_r=l(),rMe=a("span"),o_r=o("AutoModelForTableQuestionAnswering"),fKe=l(),Xo=a("div"),F(Qx.$$.fragment),r_r=l(),Wd=a("p"),t_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zJ=a("a"),a_r=o("from_pretrained()"),n_r=o(" class method or the "),QJ=a("a"),s_r=o("from_config()"),l_r=o(` class
method.`),i_r=l(),Wx=a("p"),d_r=o("This class cannot be instantiated directly using "),tMe=a("code"),c_r=o("__init__()"),f_r=o(" (throws an error)."),m_r=l(),Lt=a("div"),F(Ux.$$.fragment),g_r=l(),aMe=a("p"),h_r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),u_r=l(),Ud=a("p"),p_r=o(`Note:
Loading a model from its configuration file does `),nMe=a("strong"),__r=o("not"),v_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=a("a"),b_r=o("from_pretrained()"),F_r=o(" to load the model weights."),T_r=l(),F(jM.$$.fragment),M_r=l(),co=a("div"),F(Hx.$$.fragment),E_r=l(),sMe=a("p"),C_r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),w_r=l(),sn=a("p"),A_r=o("The model class to instantiate is selected based on the "),lMe=a("code"),L_r=o("model_type"),y_r=o(` property of the config object (either
passed as an argument or loaded from `),iMe=a("code"),x_r=o("pretrained_model_name_or_path"),$_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=a("code"),k_r=o("pretrained_model_name_or_path"),S_r=o(":"),R_r=l(),cMe=a("ul"),DM=a("li"),fMe=a("strong"),P_r=o("tapas"),B_r=o(" \u2014 "),UJ=a("a"),I_r=o("TapasForQuestionAnswering"),N_r=o(" (TAPAS model)"),q_r=l(),GM=a("p"),j_r=o("The model is set in evaluation mode by default using "),mMe=a("code"),D_r=o("model.eval()"),G_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gMe=a("code"),O_r=o("model.train()"),V_r=l(),F(OM.$$.fragment),mKe=l(),Hd=a("h2"),VM=a("a"),hMe=a("span"),F(Jx.$$.fragment),X_r=l(),uMe=a("span"),z_r=o("AutoModelForDocumentQuestionAnswering"),gKe=l(),zo=a("div"),F(Yx.$$.fragment),Q_r=l(),Jd=a("p"),W_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),HJ=a("a"),U_r=o("from_pretrained()"),H_r=o(" class method or the "),JJ=a("a"),J_r=o("from_config()"),Y_r=o(` class
method.`),K_r=l(),Kx=a("p"),Z_r=o("This class cannot be instantiated directly using "),pMe=a("code"),e2r=o("__init__()"),o2r=o(" (throws an error)."),r2r=l(),yt=a("div"),F(Zx.$$.fragment),t2r=l(),_Me=a("p"),a2r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),n2r=l(),Yd=a("p"),s2r=o(`Note:
Loading a model from its configuration file does `),vMe=a("strong"),l2r=o("not"),i2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),d2r=o("from_pretrained()"),c2r=o(" to load the model weights."),f2r=l(),F(XM.$$.fragment),m2r=l(),fo=a("div"),F(e$.$$.fragment),g2r=l(),bMe=a("p"),h2r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),u2r=l(),ln=a("p"),p2r=o("The model class to instantiate is selected based on the "),FMe=a("code"),_2r=o("model_type"),v2r=o(` property of the config object (either
passed as an argument or loaded from `),TMe=a("code"),b2r=o("pretrained_model_name_or_path"),F2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MMe=a("code"),T2r=o("pretrained_model_name_or_path"),M2r=o(":"),E2r=l(),Kd=a("ul"),zM=a("li"),EMe=a("strong"),C2r=o("layoutlm"),w2r=o(" \u2014 "),KJ=a("a"),A2r=o("LayoutLMForQuestionAnswering"),L2r=o(" (LayoutLM model)"),y2r=l(),QM=a("li"),CMe=a("strong"),x2r=o("layoutlmv2"),$2r=o(" \u2014 "),ZJ=a("a"),k2r=o("LayoutLMv2ForQuestionAnswering"),S2r=o(" (LayoutLMv2 model)"),R2r=l(),WM=a("li"),wMe=a("strong"),P2r=o("layoutlmv3"),B2r=o(" \u2014 "),eY=a("a"),I2r=o("LayoutLMv3ForQuestionAnswering"),N2r=o(" (LayoutLMv3 model)"),q2r=l(),UM=a("p"),j2r=o("The model is set in evaluation mode by default using "),AMe=a("code"),D2r=o("model.eval()"),G2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LMe=a("code"),O2r=o("model.train()"),V2r=l(),F(HM.$$.fragment),hKe=l(),Zd=a("h2"),JM=a("a"),yMe=a("span"),F(o$.$$.fragment),X2r=l(),xMe=a("span"),z2r=o("AutoModelForImageClassification"),uKe=l(),Qo=a("div"),F(r$.$$.fragment),Q2r=l(),ec=a("p"),W2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),oY=a("a"),U2r=o("from_pretrained()"),H2r=o(" class method or the "),rY=a("a"),J2r=o("from_config()"),Y2r=o(` class
method.`),K2r=l(),t$=a("p"),Z2r=o("This class cannot be instantiated directly using "),$Me=a("code"),evr=o("__init__()"),ovr=o(" (throws an error)."),rvr=l(),xt=a("div"),F(a$.$$.fragment),tvr=l(),kMe=a("p"),avr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),nvr=l(),oc=a("p"),svr=o(`Note:
Loading a model from its configuration file does `),SMe=a("strong"),lvr=o("not"),ivr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=a("a"),dvr=o("from_pretrained()"),cvr=o(" to load the model weights."),fvr=l(),F(YM.$$.fragment),mvr=l(),mo=a("div"),F(n$.$$.fragment),gvr=l(),RMe=a("p"),hvr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),uvr=l(),dn=a("p"),pvr=o("The model class to instantiate is selected based on the "),PMe=a("code"),_vr=o("model_type"),vvr=o(` property of the config object (either
passed as an argument or loaded from `),BMe=a("code"),bvr=o("pretrained_model_name_or_path"),Fvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IMe=a("code"),Tvr=o("pretrained_model_name_or_path"),Mvr=o(":"),Evr=l(),ve=a("ul"),KM=a("li"),NMe=a("strong"),Cvr=o("beit"),wvr=o(" \u2014 "),aY=a("a"),Avr=o("BeitForImageClassification"),Lvr=o(" (BEiT model)"),yvr=l(),ZM=a("li"),qMe=a("strong"),xvr=o("convnext"),$vr=o(" \u2014 "),nY=a("a"),kvr=o("ConvNextForImageClassification"),Svr=o(" (ConvNeXT model)"),Rvr=l(),eE=a("li"),jMe=a("strong"),Pvr=o("cvt"),Bvr=o(" \u2014 "),sY=a("a"),Ivr=o("CvtForImageClassification"),Nvr=o(" (CvT model)"),qvr=l(),oE=a("li"),DMe=a("strong"),jvr=o("data2vec-vision"),Dvr=o(" \u2014 "),lY=a("a"),Gvr=o("Data2VecVisionForImageClassification"),Ovr=o(" (Data2VecVision model)"),Vvr=l(),_l=a("li"),GMe=a("strong"),Xvr=o("deit"),zvr=o(" \u2014 "),iY=a("a"),Qvr=o("DeiTForImageClassification"),Wvr=o(" or "),dY=a("a"),Uvr=o("DeiTForImageClassificationWithTeacher"),Hvr=o(" (DeiT model)"),Jvr=l(),rE=a("li"),OMe=a("strong"),Yvr=o("imagegpt"),Kvr=o(" \u2014 "),cY=a("a"),Zvr=o("ImageGPTForImageClassification"),e1r=o(" (ImageGPT model)"),o1r=l(),vl=a("li"),VMe=a("strong"),r1r=o("levit"),t1r=o(" \u2014 "),fY=a("a"),a1r=o("LevitForImageClassification"),n1r=o(" or "),mY=a("a"),s1r=o("LevitForImageClassificationWithTeacher"),l1r=o(" (LeViT model)"),i1r=l(),tE=a("li"),XMe=a("strong"),d1r=o("mobilevit"),c1r=o(" \u2014 "),gY=a("a"),f1r=o("MobileViTForImageClassification"),m1r=o(" (MobileViT model)"),g1r=l(),$t=a("li"),zMe=a("strong"),h1r=o("perceiver"),u1r=o(" \u2014 "),hY=a("a"),p1r=o("PerceiverForImageClassificationLearned"),_1r=o(" or "),uY=a("a"),v1r=o("PerceiverForImageClassificationFourier"),b1r=o(" or "),pY=a("a"),F1r=o("PerceiverForImageClassificationConvProcessing"),T1r=o(" (Perceiver model)"),M1r=l(),aE=a("li"),QMe=a("strong"),E1r=o("poolformer"),C1r=o(" \u2014 "),_Y=a("a"),w1r=o("PoolFormerForImageClassification"),A1r=o(" (PoolFormer model)"),L1r=l(),nE=a("li"),WMe=a("strong"),y1r=o("regnet"),x1r=o(" \u2014 "),vY=a("a"),$1r=o("RegNetForImageClassification"),k1r=o(" (RegNet model)"),S1r=l(),sE=a("li"),UMe=a("strong"),R1r=o("resnet"),P1r=o(" \u2014 "),bY=a("a"),B1r=o("ResNetForImageClassification"),I1r=o(" (ResNet model)"),N1r=l(),lE=a("li"),HMe=a("strong"),q1r=o("segformer"),j1r=o(" \u2014 "),FY=a("a"),D1r=o("SegformerForImageClassification"),G1r=o(" (SegFormer model)"),O1r=l(),iE=a("li"),JMe=a("strong"),V1r=o("swin"),X1r=o(" \u2014 "),TY=a("a"),z1r=o("SwinForImageClassification"),Q1r=o(" (Swin Transformer model)"),W1r=l(),dE=a("li"),YMe=a("strong"),U1r=o("swinv2"),H1r=o(" \u2014 "),MY=a("a"),J1r=o("Swinv2ForImageClassification"),Y1r=o(" (Swin Transformer V2 model)"),K1r=l(),cE=a("li"),KMe=a("strong"),Z1r=o("van"),e4r=o(" \u2014 "),EY=a("a"),o4r=o("VanForImageClassification"),r4r=o(" (VAN model)"),t4r=l(),fE=a("li"),ZMe=a("strong"),a4r=o("vit"),n4r=o(" \u2014 "),CY=a("a"),s4r=o("ViTForImageClassification"),l4r=o(" (ViT model)"),i4r=l(),mE=a("p"),d4r=o("The model is set in evaluation mode by default using "),eEe=a("code"),c4r=o("model.eval()"),f4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oEe=a("code"),m4r=o("model.train()"),g4r=l(),F(gE.$$.fragment),pKe=l(),rc=a("h2"),hE=a("a"),rEe=a("span"),F(s$.$$.fragment),h4r=l(),tEe=a("span"),u4r=o("AutoModelForVideoClassification"),_Ke=l(),Wo=a("div"),F(l$.$$.fragment),p4r=l(),tc=a("p"),_4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),wY=a("a"),v4r=o("from_pretrained()"),b4r=o(" class method or the "),AY=a("a"),F4r=o("from_config()"),T4r=o(` class
method.`),M4r=l(),i$=a("p"),E4r=o("This class cannot be instantiated directly using "),aEe=a("code"),C4r=o("__init__()"),w4r=o(" (throws an error)."),A4r=l(),kt=a("div"),F(d$.$$.fragment),L4r=l(),nEe=a("p"),y4r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),x4r=l(),ac=a("p"),$4r=o(`Note:
Loading a model from its configuration file does `),sEe=a("strong"),k4r=o("not"),S4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),R4r=o("from_pretrained()"),P4r=o(" to load the model weights."),B4r=l(),F(uE.$$.fragment),I4r=l(),go=a("div"),F(c$.$$.fragment),N4r=l(),lEe=a("p"),q4r=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),j4r=l(),cn=a("p"),D4r=o("The model class to instantiate is selected based on the "),iEe=a("code"),G4r=o("model_type"),O4r=o(` property of the config object (either
passed as an argument or loaded from `),dEe=a("code"),V4r=o("pretrained_model_name_or_path"),X4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cEe=a("code"),z4r=o("pretrained_model_name_or_path"),Q4r=o(":"),W4r=l(),fEe=a("ul"),pE=a("li"),mEe=a("strong"),U4r=o("videomae"),H4r=o(" \u2014 "),yY=a("a"),J4r=o("VideoMAEForVideoClassification"),Y4r=o(" (VideoMAE model)"),K4r=l(),_E=a("p"),Z4r=o("The model is set in evaluation mode by default using "),gEe=a("code"),ebr=o("model.eval()"),obr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hEe=a("code"),rbr=o("model.train()"),tbr=l(),F(vE.$$.fragment),vKe=l(),nc=a("h2"),bE=a("a"),uEe=a("span"),F(f$.$$.fragment),abr=l(),pEe=a("span"),nbr=o("AutoModelForVision2Seq"),bKe=l(),Uo=a("div"),F(m$.$$.fragment),sbr=l(),sc=a("p"),lbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xY=a("a"),ibr=o("from_pretrained()"),dbr=o(" class method or the "),$Y=a("a"),cbr=o("from_config()"),fbr=o(` class
method.`),mbr=l(),g$=a("p"),gbr=o("This class cannot be instantiated directly using "),_Ee=a("code"),hbr=o("__init__()"),ubr=o(" (throws an error)."),pbr=l(),St=a("div"),F(h$.$$.fragment),_br=l(),vEe=a("p"),vbr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),bbr=l(),lc=a("p"),Fbr=o(`Note:
Loading a model from its configuration file does `),bEe=a("strong"),Tbr=o("not"),Mbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=a("a"),Ebr=o("from_pretrained()"),Cbr=o(" to load the model weights."),wbr=l(),F(FE.$$.fragment),Abr=l(),ho=a("div"),F(u$.$$.fragment),Lbr=l(),FEe=a("p"),ybr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xbr=l(),fn=a("p"),$br=o("The model class to instantiate is selected based on the "),TEe=a("code"),kbr=o("model_type"),Sbr=o(` property of the config object (either
passed as an argument or loaded from `),MEe=a("code"),Rbr=o("pretrained_model_name_or_path"),Pbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EEe=a("code"),Bbr=o("pretrained_model_name_or_path"),Ibr=o(":"),Nbr=l(),CEe=a("ul"),TE=a("li"),wEe=a("strong"),qbr=o("vision-encoder-decoder"),jbr=o(" \u2014 "),SY=a("a"),Dbr=o("VisionEncoderDecoderModel"),Gbr=o(" (Vision Encoder decoder model)"),Obr=l(),ME=a("p"),Vbr=o("The model is set in evaluation mode by default using "),AEe=a("code"),Xbr=o("model.eval()"),zbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=a("code"),Qbr=o("model.train()"),Wbr=l(),F(EE.$$.fragment),FKe=l(),ic=a("h2"),CE=a("a"),yEe=a("span"),F(p$.$$.fragment),Ubr=l(),xEe=a("span"),Hbr=o("AutoModelForVisualQuestionAnswering"),TKe=l(),Ho=a("div"),F(_$.$$.fragment),Jbr=l(),dc=a("p"),Ybr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),RY=a("a"),Kbr=o("from_pretrained()"),Zbr=o(" class method or the "),PY=a("a"),eFr=o("from_config()"),oFr=o(` class
method.`),rFr=l(),v$=a("p"),tFr=o("This class cannot be instantiated directly using "),$Ee=a("code"),aFr=o("__init__()"),nFr=o(" (throws an error)."),sFr=l(),Rt=a("div"),F(b$.$$.fragment),lFr=l(),kEe=a("p"),iFr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),dFr=l(),cc=a("p"),cFr=o(`Note:
Loading a model from its configuration file does `),SEe=a("strong"),fFr=o("not"),mFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=a("a"),gFr=o("from_pretrained()"),hFr=o(" to load the model weights."),uFr=l(),F(wE.$$.fragment),pFr=l(),uo=a("div"),F(F$.$$.fragment),_Fr=l(),REe=a("p"),vFr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),bFr=l(),mn=a("p"),FFr=o("The model class to instantiate is selected based on the "),PEe=a("code"),TFr=o("model_type"),MFr=o(` property of the config object (either
passed as an argument or loaded from `),BEe=a("code"),EFr=o("pretrained_model_name_or_path"),CFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=a("code"),wFr=o("pretrained_model_name_or_path"),AFr=o(":"),LFr=l(),NEe=a("ul"),AE=a("li"),qEe=a("strong"),yFr=o("vilt"),xFr=o(" \u2014 "),IY=a("a"),$Fr=o("ViltForQuestionAnswering"),kFr=o(" (ViLT model)"),SFr=l(),LE=a("p"),RFr=o("The model is set in evaluation mode by default using "),jEe=a("code"),PFr=o("model.eval()"),BFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DEe=a("code"),IFr=o("model.train()"),NFr=l(),F(yE.$$.fragment),MKe=l(),fc=a("h2"),xE=a("a"),GEe=a("span"),F(T$.$$.fragment),qFr=l(),OEe=a("span"),jFr=o("AutoModelForAudioClassification"),EKe=l(),Jo=a("div"),F(M$.$$.fragment),DFr=l(),mc=a("p"),GFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),NY=a("a"),OFr=o("from_pretrained()"),VFr=o(" class method or the "),qY=a("a"),XFr=o("from_config()"),zFr=o(` class
method.`),QFr=l(),E$=a("p"),WFr=o("This class cannot be instantiated directly using "),VEe=a("code"),UFr=o("__init__()"),HFr=o(" (throws an error)."),JFr=l(),Pt=a("div"),F(C$.$$.fragment),YFr=l(),XEe=a("p"),KFr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),ZFr=l(),gc=a("p"),eTr=o(`Note:
Loading a model from its configuration file does `),zEe=a("strong"),oTr=o("not"),rTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=a("a"),tTr=o("from_pretrained()"),aTr=o(" to load the model weights."),nTr=l(),F($E.$$.fragment),sTr=l(),po=a("div"),F(w$.$$.fragment),lTr=l(),QEe=a("p"),iTr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),dTr=l(),gn=a("p"),cTr=o("The model class to instantiate is selected based on the "),WEe=a("code"),fTr=o("model_type"),mTr=o(` property of the config object (either
passed as an argument or loaded from `),UEe=a("code"),gTr=o("pretrained_model_name_or_path"),hTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HEe=a("code"),uTr=o("pretrained_model_name_or_path"),pTr=o(":"),_Tr=l(),Pe=a("ul"),kE=a("li"),JEe=a("strong"),vTr=o("data2vec-audio"),bTr=o(" \u2014 "),DY=a("a"),FTr=o("Data2VecAudioForSequenceClassification"),TTr=o(" (Data2VecAudio model)"),MTr=l(),SE=a("li"),YEe=a("strong"),ETr=o("hubert"),CTr=o(" \u2014 "),GY=a("a"),wTr=o("HubertForSequenceClassification"),ATr=o(" (Hubert model)"),LTr=l(),RE=a("li"),KEe=a("strong"),yTr=o("sew"),xTr=o(" \u2014 "),OY=a("a"),$Tr=o("SEWForSequenceClassification"),kTr=o(" (SEW model)"),STr=l(),PE=a("li"),ZEe=a("strong"),RTr=o("sew-d"),PTr=o(" \u2014 "),VY=a("a"),BTr=o("SEWDForSequenceClassification"),ITr=o(" (SEW-D model)"),NTr=l(),BE=a("li"),eCe=a("strong"),qTr=o("unispeech"),jTr=o(" \u2014 "),XY=a("a"),DTr=o("UniSpeechForSequenceClassification"),GTr=o(" (UniSpeech model)"),OTr=l(),IE=a("li"),oCe=a("strong"),VTr=o("unispeech-sat"),XTr=o(" \u2014 "),zY=a("a"),zTr=o("UniSpeechSatForSequenceClassification"),QTr=o(" (UniSpeechSat model)"),WTr=l(),NE=a("li"),rCe=a("strong"),UTr=o("wav2vec2"),HTr=o(" \u2014 "),QY=a("a"),JTr=o("Wav2Vec2ForSequenceClassification"),YTr=o(" (Wav2Vec2 model)"),KTr=l(),qE=a("li"),tCe=a("strong"),ZTr=o("wav2vec2-conformer"),eMr=o(" \u2014 "),WY=a("a"),oMr=o("Wav2Vec2ConformerForSequenceClassification"),rMr=o(" (Wav2Vec2-Conformer model)"),tMr=l(),jE=a("li"),aCe=a("strong"),aMr=o("wavlm"),nMr=o(" \u2014 "),UY=a("a"),sMr=o("WavLMForSequenceClassification"),lMr=o(" (WavLM model)"),iMr=l(),DE=a("p"),dMr=o("The model is set in evaluation mode by default using "),nCe=a("code"),cMr=o("model.eval()"),fMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sCe=a("code"),mMr=o("model.train()"),gMr=l(),F(GE.$$.fragment),CKe=l(),hc=a("h2"),OE=a("a"),lCe=a("span"),F(A$.$$.fragment),hMr=l(),iCe=a("span"),uMr=o("AutoModelForAudioFrameClassification"),wKe=l(),Yo=a("div"),F(L$.$$.fragment),pMr=l(),uc=a("p"),_Mr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),HY=a("a"),vMr=o("from_pretrained()"),bMr=o(" class method or the "),JY=a("a"),FMr=o("from_config()"),TMr=o(` class
method.`),MMr=l(),y$=a("p"),EMr=o("This class cannot be instantiated directly using "),dCe=a("code"),CMr=o("__init__()"),wMr=o(" (throws an error)."),AMr=l(),Bt=a("div"),F(x$.$$.fragment),LMr=l(),cCe=a("p"),yMr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xMr=l(),pc=a("p"),$Mr=o(`Note:
Loading a model from its configuration file does `),fCe=a("strong"),kMr=o("not"),SMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=a("a"),RMr=o("from_pretrained()"),PMr=o(" to load the model weights."),BMr=l(),F(VE.$$.fragment),IMr=l(),_o=a("div"),F($$.$$.fragment),NMr=l(),mCe=a("p"),qMr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jMr=l(),hn=a("p"),DMr=o("The model class to instantiate is selected based on the "),gCe=a("code"),GMr=o("model_type"),OMr=o(` property of the config object (either
passed as an argument or loaded from `),hCe=a("code"),VMr=o("pretrained_model_name_or_path"),XMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=a("code"),zMr=o("pretrained_model_name_or_path"),QMr=o(":"),WMr=l(),ft=a("ul"),XE=a("li"),pCe=a("strong"),UMr=o("data2vec-audio"),HMr=o(" \u2014 "),KY=a("a"),JMr=o("Data2VecAudioForAudioFrameClassification"),YMr=o(" (Data2VecAudio model)"),KMr=l(),zE=a("li"),_Ce=a("strong"),ZMr=o("unispeech-sat"),eEr=o(" \u2014 "),ZY=a("a"),oEr=o("UniSpeechSatForAudioFrameClassification"),rEr=o(" (UniSpeechSat model)"),tEr=l(),QE=a("li"),vCe=a("strong"),aEr=o("wav2vec2"),nEr=o(" \u2014 "),eK=a("a"),sEr=o("Wav2Vec2ForAudioFrameClassification"),lEr=o(" (Wav2Vec2 model)"),iEr=l(),WE=a("li"),bCe=a("strong"),dEr=o("wav2vec2-conformer"),cEr=o(" \u2014 "),oK=a("a"),fEr=o("Wav2Vec2ConformerForAudioFrameClassification"),mEr=o(" (Wav2Vec2-Conformer model)"),gEr=l(),UE=a("li"),FCe=a("strong"),hEr=o("wavlm"),uEr=o(" \u2014 "),rK=a("a"),pEr=o("WavLMForAudioFrameClassification"),_Er=o(" (WavLM model)"),vEr=l(),HE=a("p"),bEr=o("The model is set in evaluation mode by default using "),TCe=a("code"),FEr=o("model.eval()"),TEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MCe=a("code"),MEr=o("model.train()"),EEr=l(),F(JE.$$.fragment),AKe=l(),_c=a("h2"),YE=a("a"),ECe=a("span"),F(k$.$$.fragment),CEr=l(),CCe=a("span"),wEr=o("AutoModelForCTC"),LKe=l(),Ko=a("div"),F(S$.$$.fragment),AEr=l(),vc=a("p"),LEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),tK=a("a"),yEr=o("from_pretrained()"),xEr=o(" class method or the "),aK=a("a"),$Er=o("from_config()"),kEr=o(` class
method.`),SEr=l(),R$=a("p"),REr=o("This class cannot be instantiated directly using "),wCe=a("code"),PEr=o("__init__()"),BEr=o(" (throws an error)."),IEr=l(),It=a("div"),F(P$.$$.fragment),NEr=l(),ACe=a("p"),qEr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),jEr=l(),bc=a("p"),DEr=o(`Note:
Loading a model from its configuration file does `),LCe=a("strong"),GEr=o("not"),OEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),VEr=o("from_pretrained()"),XEr=o(" to load the model weights."),zEr=l(),F(KE.$$.fragment),QEr=l(),vo=a("div"),F(B$.$$.fragment),WEr=l(),yCe=a("p"),UEr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),HEr=l(),un=a("p"),JEr=o("The model class to instantiate is selected based on the "),xCe=a("code"),YEr=o("model_type"),KEr=o(` property of the config object (either
passed as an argument or loaded from `),$Ce=a("code"),ZEr=o("pretrained_model_name_or_path"),eCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kCe=a("code"),oCr=o("pretrained_model_name_or_path"),rCr=o(":"),tCr=l(),Le=a("ul"),ZE=a("li"),SCe=a("strong"),aCr=o("data2vec-audio"),nCr=o(" \u2014 "),sK=a("a"),sCr=o("Data2VecAudioForCTC"),lCr=o(" (Data2VecAudio model)"),iCr=l(),eC=a("li"),RCe=a("strong"),dCr=o("hubert"),cCr=o(" \u2014 "),lK=a("a"),fCr=o("HubertForCTC"),mCr=o(" (Hubert model)"),gCr=l(),oC=a("li"),PCe=a("strong"),hCr=o("mctct"),uCr=o(" \u2014 "),iK=a("a"),pCr=o("MCTCTForCTC"),_Cr=o(" (M-CTC-T model)"),vCr=l(),rC=a("li"),BCe=a("strong"),bCr=o("sew"),FCr=o(" \u2014 "),dK=a("a"),TCr=o("SEWForCTC"),MCr=o(" (SEW model)"),ECr=l(),tC=a("li"),ICe=a("strong"),CCr=o("sew-d"),wCr=o(" \u2014 "),cK=a("a"),ACr=o("SEWDForCTC"),LCr=o(" (SEW-D model)"),yCr=l(),aC=a("li"),NCe=a("strong"),xCr=o("unispeech"),$Cr=o(" \u2014 "),fK=a("a"),kCr=o("UniSpeechForCTC"),SCr=o(" (UniSpeech model)"),RCr=l(),nC=a("li"),qCe=a("strong"),PCr=o("unispeech-sat"),BCr=o(" \u2014 "),mK=a("a"),ICr=o("UniSpeechSatForCTC"),NCr=o(" (UniSpeechSat model)"),qCr=l(),sC=a("li"),jCe=a("strong"),jCr=o("wav2vec2"),DCr=o(" \u2014 "),gK=a("a"),GCr=o("Wav2Vec2ForCTC"),OCr=o(" (Wav2Vec2 model)"),VCr=l(),lC=a("li"),DCe=a("strong"),XCr=o("wav2vec2-conformer"),zCr=o(" \u2014 "),hK=a("a"),QCr=o("Wav2Vec2ConformerForCTC"),WCr=o(" (Wav2Vec2-Conformer model)"),UCr=l(),iC=a("li"),GCe=a("strong"),HCr=o("wavlm"),JCr=o(" \u2014 "),uK=a("a"),YCr=o("WavLMForCTC"),KCr=o(" (WavLM model)"),ZCr=l(),dC=a("p"),e3r=o("The model is set in evaluation mode by default using "),OCe=a("code"),o3r=o("model.eval()"),r3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VCe=a("code"),t3r=o("model.train()"),a3r=l(),F(cC.$$.fragment),yKe=l(),Fc=a("h2"),fC=a("a"),XCe=a("span"),F(I$.$$.fragment),n3r=l(),zCe=a("span"),s3r=o("AutoModelForSpeechSeq2Seq"),xKe=l(),Zo=a("div"),F(N$.$$.fragment),l3r=l(),Tc=a("p"),i3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pK=a("a"),d3r=o("from_pretrained()"),c3r=o(" class method or the "),_K=a("a"),f3r=o("from_config()"),m3r=o(` class
method.`),g3r=l(),q$=a("p"),h3r=o("This class cannot be instantiated directly using "),QCe=a("code"),u3r=o("__init__()"),p3r=o(" (throws an error)."),_3r=l(),Nt=a("div"),F(j$.$$.fragment),v3r=l(),WCe=a("p"),b3r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),F3r=l(),Mc=a("p"),T3r=o(`Note:
Loading a model from its configuration file does `),UCe=a("strong"),M3r=o("not"),E3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=a("a"),C3r=o("from_pretrained()"),w3r=o(" to load the model weights."),A3r=l(),F(mC.$$.fragment),L3r=l(),bo=a("div"),F(D$.$$.fragment),y3r=l(),HCe=a("p"),x3r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$3r=l(),pn=a("p"),k3r=o("The model class to instantiate is selected based on the "),JCe=a("code"),S3r=o("model_type"),R3r=o(` property of the config object (either
passed as an argument or loaded from `),YCe=a("code"),P3r=o("pretrained_model_name_or_path"),B3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=a("code"),I3r=o("pretrained_model_name_or_path"),N3r=o(":"),q3r=l(),G$=a("ul"),gC=a("li"),ZCe=a("strong"),j3r=o("speech-encoder-decoder"),D3r=o(" \u2014 "),bK=a("a"),G3r=o("SpeechEncoderDecoderModel"),O3r=o(" (Speech Encoder decoder model)"),V3r=l(),hC=a("li"),e3e=a("strong"),X3r=o("speech_to_text"),z3r=o(" \u2014 "),FK=a("a"),Q3r=o("Speech2TextForConditionalGeneration"),W3r=o(" (Speech2Text model)"),U3r=l(),uC=a("p"),H3r=o("The model is set in evaluation mode by default using "),o3e=a("code"),J3r=o("model.eval()"),Y3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r3e=a("code"),K3r=o("model.train()"),Z3r=l(),F(pC.$$.fragment),$Ke=l(),Ec=a("h2"),_C=a("a"),t3e=a("span"),F(O$.$$.fragment),e5r=l(),a3e=a("span"),o5r=o("AutoModelForAudioXVector"),kKe=l(),er=a("div"),F(V$.$$.fragment),r5r=l(),Cc=a("p"),t5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),TK=a("a"),a5r=o("from_pretrained()"),n5r=o(" class method or the "),MK=a("a"),s5r=o("from_config()"),l5r=o(` class
method.`),i5r=l(),X$=a("p"),d5r=o("This class cannot be instantiated directly using "),n3e=a("code"),c5r=o("__init__()"),f5r=o(" (throws an error)."),m5r=l(),qt=a("div"),F(z$.$$.fragment),g5r=l(),s3e=a("p"),h5r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),u5r=l(),wc=a("p"),p5r=o(`Note:
Loading a model from its configuration file does `),l3e=a("strong"),_5r=o("not"),v5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=a("a"),b5r=o("from_pretrained()"),F5r=o(" to load the model weights."),T5r=l(),F(vC.$$.fragment),M5r=l(),Fo=a("div"),F(Q$.$$.fragment),E5r=l(),i3e=a("p"),C5r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),w5r=l(),_n=a("p"),A5r=o("The model class to instantiate is selected based on the "),d3e=a("code"),L5r=o("model_type"),y5r=o(` property of the config object (either
passed as an argument or loaded from `),c3e=a("code"),x5r=o("pretrained_model_name_or_path"),$5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f3e=a("code"),k5r=o("pretrained_model_name_or_path"),S5r=o(":"),R5r=l(),mt=a("ul"),bC=a("li"),m3e=a("strong"),P5r=o("data2vec-audio"),B5r=o(" \u2014 "),CK=a("a"),I5r=o("Data2VecAudioForXVector"),N5r=o(" (Data2VecAudio model)"),q5r=l(),FC=a("li"),g3e=a("strong"),j5r=o("unispeech-sat"),D5r=o(" \u2014 "),wK=a("a"),G5r=o("UniSpeechSatForXVector"),O5r=o(" (UniSpeechSat model)"),V5r=l(),TC=a("li"),h3e=a("strong"),X5r=o("wav2vec2"),z5r=o(" \u2014 "),AK=a("a"),Q5r=o("Wav2Vec2ForXVector"),W5r=o(" (Wav2Vec2 model)"),U5r=l(),MC=a("li"),u3e=a("strong"),H5r=o("wav2vec2-conformer"),J5r=o(" \u2014 "),LK=a("a"),Y5r=o("Wav2Vec2ConformerForXVector"),K5r=o(" (Wav2Vec2-Conformer model)"),Z5r=l(),EC=a("li"),p3e=a("strong"),e0r=o("wavlm"),o0r=o(" \u2014 "),yK=a("a"),r0r=o("WavLMForXVector"),t0r=o(" (WavLM model)"),a0r=l(),CC=a("p"),n0r=o("The model is set in evaluation mode by default using "),_3e=a("code"),s0r=o("model.eval()"),l0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v3e=a("code"),i0r=o("model.train()"),d0r=l(),F(wC.$$.fragment),SKe=l(),Ac=a("h2"),AC=a("a"),b3e=a("span"),F(W$.$$.fragment),c0r=l(),F3e=a("span"),f0r=o("AutoModelForMaskedImageModeling"),RKe=l(),or=a("div"),F(U$.$$.fragment),m0r=l(),Lc=a("p"),g0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xK=a("a"),h0r=o("from_pretrained()"),u0r=o(" class method or the "),$K=a("a"),p0r=o("from_config()"),_0r=o(` class
method.`),v0r=l(),H$=a("p"),b0r=o("This class cannot be instantiated directly using "),T3e=a("code"),F0r=o("__init__()"),T0r=o(" (throws an error)."),M0r=l(),jt=a("div"),F(J$.$$.fragment),E0r=l(),M3e=a("p"),C0r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),w0r=l(),yc=a("p"),A0r=o(`Note:
Loading a model from its configuration file does `),E3e=a("strong"),L0r=o("not"),y0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),x0r=o("from_pretrained()"),$0r=o(" to load the model weights."),k0r=l(),F(LC.$$.fragment),S0r=l(),To=a("div"),F(Y$.$$.fragment),R0r=l(),C3e=a("p"),P0r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B0r=l(),vn=a("p"),I0r=o("The model class to instantiate is selected based on the "),w3e=a("code"),N0r=o("model_type"),q0r=o(` property of the config object (either
passed as an argument or loaded from `),A3e=a("code"),j0r=o("pretrained_model_name_or_path"),D0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L3e=a("code"),G0r=o("pretrained_model_name_or_path"),O0r=o(":"),V0r=l(),bn=a("ul"),yC=a("li"),y3e=a("strong"),X0r=o("deit"),z0r=o(" \u2014 "),SK=a("a"),Q0r=o("DeiTForMaskedImageModeling"),W0r=o(" (DeiT model)"),U0r=l(),xC=a("li"),x3e=a("strong"),H0r=o("swin"),J0r=o(" \u2014 "),RK=a("a"),Y0r=o("SwinForMaskedImageModeling"),K0r=o(" (Swin Transformer model)"),Z0r=l(),$C=a("li"),$3e=a("strong"),ewr=o("swinv2"),owr=o(" \u2014 "),PK=a("a"),rwr=o("Swinv2ForMaskedImageModeling"),twr=o(" (Swin Transformer V2 model)"),awr=l(),kC=a("li"),k3e=a("strong"),nwr=o("vit"),swr=o(" \u2014 "),BK=a("a"),lwr=o("ViTForMaskedImageModeling"),iwr=o(" (ViT model)"),dwr=l(),SC=a("p"),cwr=o("The model is set in evaluation mode by default using "),S3e=a("code"),fwr=o("model.eval()"),mwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R3e=a("code"),gwr=o("model.train()"),hwr=l(),F(RC.$$.fragment),PKe=l(),xc=a("h2"),PC=a("a"),P3e=a("span"),F(K$.$$.fragment),uwr=l(),B3e=a("span"),pwr=o("AutoModelForObjectDetection"),BKe=l(),rr=a("div"),F(Z$.$$.fragment),_wr=l(),$c=a("p"),vwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IK=a("a"),bwr=o("from_pretrained()"),Fwr=o(" class method or the "),NK=a("a"),Twr=o("from_config()"),Mwr=o(` class
method.`),Ewr=l(),ek=a("p"),Cwr=o("This class cannot be instantiated directly using "),I3e=a("code"),wwr=o("__init__()"),Awr=o(" (throws an error)."),Lwr=l(),Dt=a("div"),F(ok.$$.fragment),ywr=l(),N3e=a("p"),xwr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),$wr=l(),kc=a("p"),kwr=o(`Note:
Loading a model from its configuration file does `),q3e=a("strong"),Swr=o("not"),Rwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=a("a"),Pwr=o("from_pretrained()"),Bwr=o(" to load the model weights."),Iwr=l(),F(BC.$$.fragment),Nwr=l(),Mo=a("div"),F(rk.$$.fragment),qwr=l(),j3e=a("p"),jwr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Dwr=l(),Fn=a("p"),Gwr=o("The model class to instantiate is selected based on the "),D3e=a("code"),Owr=o("model_type"),Vwr=o(` property of the config object (either
passed as an argument or loaded from `),G3e=a("code"),Xwr=o("pretrained_model_name_or_path"),zwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O3e=a("code"),Qwr=o("pretrained_model_name_or_path"),Wwr=o(":"),Uwr=l(),tk=a("ul"),IC=a("li"),V3e=a("strong"),Hwr=o("detr"),Jwr=o(" \u2014 "),jK=a("a"),Ywr=o("DetrForObjectDetection"),Kwr=o(" (DETR model)"),Zwr=l(),NC=a("li"),X3e=a("strong"),eAr=o("yolos"),oAr=o(" \u2014 "),DK=a("a"),rAr=o("YolosForObjectDetection"),tAr=o(" (YOLOS model)"),aAr=l(),qC=a("p"),nAr=o("The model is set in evaluation mode by default using "),z3e=a("code"),sAr=o("model.eval()"),lAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q3e=a("code"),iAr=o("model.train()"),dAr=l(),F(jC.$$.fragment),IKe=l(),Sc=a("h2"),DC=a("a"),W3e=a("span"),F(ak.$$.fragment),cAr=l(),U3e=a("span"),fAr=o("AutoModelForImageSegmentation"),NKe=l(),tr=a("div"),F(nk.$$.fragment),mAr=l(),Rc=a("p"),gAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GK=a("a"),hAr=o("from_pretrained()"),uAr=o(" class method or the "),OK=a("a"),pAr=o("from_config()"),_Ar=o(` class
method.`),vAr=l(),sk=a("p"),bAr=o("This class cannot be instantiated directly using "),H3e=a("code"),FAr=o("__init__()"),TAr=o(" (throws an error)."),MAr=l(),Gt=a("div"),F(lk.$$.fragment),EAr=l(),J3e=a("p"),CAr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),wAr=l(),Pc=a("p"),AAr=o(`Note:
Loading a model from its configuration file does `),Y3e=a("strong"),LAr=o("not"),yAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=a("a"),xAr=o("from_pretrained()"),$Ar=o(" to load the model weights."),kAr=l(),F(GC.$$.fragment),SAr=l(),Eo=a("div"),F(ik.$$.fragment),RAr=l(),K3e=a("p"),PAr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),BAr=l(),Tn=a("p"),IAr=o("The model class to instantiate is selected based on the "),Z3e=a("code"),NAr=o("model_type"),qAr=o(` property of the config object (either
passed as an argument or loaded from `),e5e=a("code"),jAr=o("pretrained_model_name_or_path"),DAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o5e=a("code"),GAr=o("pretrained_model_name_or_path"),OAr=o(":"),VAr=l(),r5e=a("ul"),OC=a("li"),t5e=a("strong"),XAr=o("detr"),zAr=o(" \u2014 "),XK=a("a"),QAr=o("DetrForSegmentation"),WAr=o(" (DETR model)"),UAr=l(),VC=a("p"),HAr=o("The model is set in evaluation mode by default using "),a5e=a("code"),JAr=o("model.eval()"),YAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n5e=a("code"),KAr=o("model.train()"),ZAr=l(),F(XC.$$.fragment),qKe=l(),Bc=a("h2"),zC=a("a"),s5e=a("span"),F(dk.$$.fragment),e6r=l(),l5e=a("span"),o6r=o("AutoModelForSemanticSegmentation"),jKe=l(),ar=a("div"),F(ck.$$.fragment),r6r=l(),Ic=a("p"),t6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zK=a("a"),a6r=o("from_pretrained()"),n6r=o(" class method or the "),QK=a("a"),s6r=o("from_config()"),l6r=o(` class
method.`),i6r=l(),fk=a("p"),d6r=o("This class cannot be instantiated directly using "),i5e=a("code"),c6r=o("__init__()"),f6r=o(" (throws an error)."),m6r=l(),Ot=a("div"),F(mk.$$.fragment),g6r=l(),d5e=a("p"),h6r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),u6r=l(),Nc=a("p"),p6r=o(`Note:
Loading a model from its configuration file does `),c5e=a("strong"),_6r=o("not"),v6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WK=a("a"),b6r=o("from_pretrained()"),F6r=o(" to load the model weights."),T6r=l(),F(QC.$$.fragment),M6r=l(),Co=a("div"),F(gk.$$.fragment),E6r=l(),f5e=a("p"),C6r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),w6r=l(),Mn=a("p"),A6r=o("The model class to instantiate is selected based on the "),m5e=a("code"),L6r=o("model_type"),y6r=o(` property of the config object (either
passed as an argument or loaded from `),g5e=a("code"),x6r=o("pretrained_model_name_or_path"),$6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h5e=a("code"),k6r=o("pretrained_model_name_or_path"),S6r=o(":"),R6r=l(),gt=a("ul"),WC=a("li"),u5e=a("strong"),P6r=o("beit"),B6r=o(" \u2014 "),UK=a("a"),I6r=o("BeitForSemanticSegmentation"),N6r=o(" (BEiT model)"),q6r=l(),UC=a("li"),p5e=a("strong"),j6r=o("data2vec-vision"),D6r=o(" \u2014 "),HK=a("a"),G6r=o("Data2VecVisionForSemanticSegmentation"),O6r=o(" (Data2VecVision model)"),V6r=l(),HC=a("li"),_5e=a("strong"),X6r=o("dpt"),z6r=o(" \u2014 "),JK=a("a"),Q6r=o("DPTForSemanticSegmentation"),W6r=o(" (DPT model)"),U6r=l(),JC=a("li"),v5e=a("strong"),H6r=o("mobilevit"),J6r=o(" \u2014 "),YK=a("a"),Y6r=o("MobileViTForSemanticSegmentation"),K6r=o(" (MobileViT model)"),Z6r=l(),YC=a("li"),b5e=a("strong"),e7r=o("segformer"),o7r=o(" \u2014 "),KK=a("a"),r7r=o("SegformerForSemanticSegmentation"),t7r=o(" (SegFormer model)"),a7r=l(),KC=a("p"),n7r=o("The model is set in evaluation mode by default using "),F5e=a("code"),s7r=o("model.eval()"),l7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T5e=a("code"),i7r=o("model.train()"),d7r=l(),F(ZC.$$.fragment),DKe=l(),qc=a("h2"),e3=a("a"),M5e=a("span"),F(hk.$$.fragment),c7r=l(),E5e=a("span"),f7r=o("AutoModelForInstanceSegmentation"),GKe=l(),nr=a("div"),F(uk.$$.fragment),m7r=l(),jc=a("p"),g7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),ZK=a("a"),h7r=o("from_pretrained()"),u7r=o(" class method or the "),eZ=a("a"),p7r=o("from_config()"),_7r=o(` class
method.`),v7r=l(),pk=a("p"),b7r=o("This class cannot be instantiated directly using "),C5e=a("code"),F7r=o("__init__()"),T7r=o(" (throws an error)."),M7r=l(),Vt=a("div"),F(_k.$$.fragment),E7r=l(),w5e=a("p"),C7r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),w7r=l(),Dc=a("p"),A7r=o(`Note:
Loading a model from its configuration file does `),A5e=a("strong"),L7r=o("not"),y7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),x7r=o("from_pretrained()"),$7r=o(" to load the model weights."),k7r=l(),F(o3.$$.fragment),S7r=l(),wo=a("div"),F(vk.$$.fragment),R7r=l(),L5e=a("p"),P7r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),B7r=l(),En=a("p"),I7r=o("The model class to instantiate is selected based on the "),y5e=a("code"),N7r=o("model_type"),q7r=o(` property of the config object (either
passed as an argument or loaded from `),x5e=a("code"),j7r=o("pretrained_model_name_or_path"),D7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$5e=a("code"),G7r=o("pretrained_model_name_or_path"),O7r=o(":"),V7r=l(),k5e=a("ul"),r3=a("li"),S5e=a("strong"),X7r=o("maskformer"),z7r=o(" \u2014 "),rZ=a("a"),Q7r=o("MaskFormerForInstanceSegmentation"),W7r=o(" (MaskFormer model)"),U7r=l(),t3=a("p"),H7r=o("The model is set in evaluation mode by default using "),R5e=a("code"),J7r=o("model.eval()"),Y7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=a("code"),K7r=o("model.train()"),Z7r=l(),F(a3.$$.fragment),OKe=l(),Gc=a("h2"),n3=a("a"),B5e=a("span"),F(bk.$$.fragment),eLr=l(),I5e=a("span"),oLr=o("TFAutoModel"),VKe=l(),sr=a("div"),F(Fk.$$.fragment),rLr=l(),Oc=a("p"),tLr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tZ=a("a"),aLr=o("from_pretrained()"),nLr=o(" class method or the "),aZ=a("a"),sLr=o("from_config()"),lLr=o(` class
method.`),iLr=l(),Tk=a("p"),dLr=o("This class cannot be instantiated directly using "),N5e=a("code"),cLr=o("__init__()"),fLr=o(" (throws an error)."),mLr=l(),Xt=a("div"),F(Mk.$$.fragment),gLr=l(),q5e=a("p"),hLr=o("Instantiates one of the base model classes of the library from a configuration."),uLr=l(),Vc=a("p"),pLr=o(`Note:
Loading a model from its configuration file does `),j5e=a("strong"),_Lr=o("not"),vLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=a("a"),bLr=o("from_pretrained()"),FLr=o(" to load the model weights."),TLr=l(),F(s3.$$.fragment),MLr=l(),Ir=a("div"),F(Ek.$$.fragment),ELr=l(),D5e=a("p"),CLr=o("Instantiate one of the base model classes of the library from a pretrained model."),wLr=l(),Cn=a("p"),ALr=o("The model class to instantiate is selected based on the "),G5e=a("code"),LLr=o("model_type"),yLr=o(` property of the config object (either
passed as an argument or loaded from `),O5e=a("code"),xLr=o("pretrained_model_name_or_path"),$Lr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=a("code"),kLr=o("pretrained_model_name_or_path"),SLr=o(":"),RLr=l(),N=a("ul"),l3=a("li"),X5e=a("strong"),PLr=o("albert"),BLr=o(" \u2014 "),sZ=a("a"),ILr=o("TFAlbertModel"),NLr=o(" (ALBERT model)"),qLr=l(),i3=a("li"),z5e=a("strong"),jLr=o("bart"),DLr=o(" \u2014 "),lZ=a("a"),GLr=o("TFBartModel"),OLr=o(" (BART model)"),VLr=l(),d3=a("li"),Q5e=a("strong"),XLr=o("bert"),zLr=o(" \u2014 "),iZ=a("a"),QLr=o("TFBertModel"),WLr=o(" (BERT model)"),ULr=l(),c3=a("li"),W5e=a("strong"),HLr=o("blenderbot"),JLr=o(" \u2014 "),dZ=a("a"),YLr=o("TFBlenderbotModel"),KLr=o(" (Blenderbot model)"),ZLr=l(),f3=a("li"),U5e=a("strong"),eyr=o("blenderbot-small"),oyr=o(" \u2014 "),cZ=a("a"),ryr=o("TFBlenderbotSmallModel"),tyr=o(" (BlenderbotSmall model)"),ayr=l(),m3=a("li"),H5e=a("strong"),nyr=o("camembert"),syr=o(" \u2014 "),fZ=a("a"),lyr=o("TFCamembertModel"),iyr=o(" (CamemBERT model)"),dyr=l(),g3=a("li"),J5e=a("strong"),cyr=o("clip"),fyr=o(" \u2014 "),mZ=a("a"),myr=o("TFCLIPModel"),gyr=o(" (CLIP model)"),hyr=l(),h3=a("li"),Y5e=a("strong"),uyr=o("convbert"),pyr=o(" \u2014 "),gZ=a("a"),_yr=o("TFConvBertModel"),vyr=o(" (ConvBERT model)"),byr=l(),u3=a("li"),K5e=a("strong"),Fyr=o("convnext"),Tyr=o(" \u2014 "),hZ=a("a"),Myr=o("TFConvNextModel"),Eyr=o(" (ConvNeXT model)"),Cyr=l(),p3=a("li"),Z5e=a("strong"),wyr=o("ctrl"),Ayr=o(" \u2014 "),uZ=a("a"),Lyr=o("TFCTRLModel"),yyr=o(" (CTRL model)"),xyr=l(),_3=a("li"),e0e=a("strong"),$yr=o("data2vec-vision"),kyr=o(" \u2014 "),pZ=a("a"),Syr=o("TFData2VecVisionModel"),Ryr=o(" (Data2VecVision model)"),Pyr=l(),v3=a("li"),o0e=a("strong"),Byr=o("deberta"),Iyr=o(" \u2014 "),_Z=a("a"),Nyr=o("TFDebertaModel"),qyr=o(" (DeBERTa model)"),jyr=l(),b3=a("li"),r0e=a("strong"),Dyr=o("deberta-v2"),Gyr=o(" \u2014 "),vZ=a("a"),Oyr=o("TFDebertaV2Model"),Vyr=o(" (DeBERTa-v2 model)"),Xyr=l(),F3=a("li"),t0e=a("strong"),zyr=o("deit"),Qyr=o(" \u2014 "),bZ=a("a"),Wyr=o("TFDeiTModel"),Uyr=o(" (DeiT model)"),Hyr=l(),T3=a("li"),a0e=a("strong"),Jyr=o("distilbert"),Yyr=o(" \u2014 "),FZ=a("a"),Kyr=o("TFDistilBertModel"),Zyr=o(" (DistilBERT model)"),e8r=l(),M3=a("li"),n0e=a("strong"),o8r=o("dpr"),r8r=o(" \u2014 "),TZ=a("a"),t8r=o("TFDPRQuestionEncoder"),a8r=o(" (DPR model)"),n8r=l(),E3=a("li"),s0e=a("strong"),s8r=o("electra"),l8r=o(" \u2014 "),MZ=a("a"),i8r=o("TFElectraModel"),d8r=o(" (ELECTRA model)"),c8r=l(),C3=a("li"),l0e=a("strong"),f8r=o("flaubert"),m8r=o(" \u2014 "),EZ=a("a"),g8r=o("TFFlaubertModel"),h8r=o(" (FlauBERT model)"),u8r=l(),bl=a("li"),i0e=a("strong"),p8r=o("funnel"),_8r=o(" \u2014 "),CZ=a("a"),v8r=o("TFFunnelModel"),b8r=o(" or "),wZ=a("a"),F8r=o("TFFunnelBaseModel"),T8r=o(" (Funnel Transformer model)"),M8r=l(),w3=a("li"),d0e=a("strong"),E8r=o("gpt2"),C8r=o(" \u2014 "),AZ=a("a"),w8r=o("TFGPT2Model"),A8r=o(" (OpenAI GPT-2 model)"),L8r=l(),A3=a("li"),c0e=a("strong"),y8r=o("gptj"),x8r=o(" \u2014 "),LZ=a("a"),$8r=o("TFGPTJModel"),k8r=o(" (GPT-J model)"),S8r=l(),L3=a("li"),f0e=a("strong"),R8r=o("hubert"),P8r=o(" \u2014 "),yZ=a("a"),B8r=o("TFHubertModel"),I8r=o(" (Hubert model)"),N8r=l(),y3=a("li"),m0e=a("strong"),q8r=o("layoutlm"),j8r=o(" \u2014 "),xZ=a("a"),D8r=o("TFLayoutLMModel"),G8r=o(" (LayoutLM model)"),O8r=l(),x3=a("li"),g0e=a("strong"),V8r=o("layoutlmv3"),X8r=o(" \u2014 "),$Z=a("a"),z8r=o("TFLayoutLMv3Model"),Q8r=o(" (LayoutLMv3 model)"),W8r=l(),$3=a("li"),h0e=a("strong"),U8r=o("led"),H8r=o(" \u2014 "),kZ=a("a"),J8r=o("TFLEDModel"),Y8r=o(" (LED model)"),K8r=l(),k3=a("li"),u0e=a("strong"),Z8r=o("longformer"),e9r=o(" \u2014 "),SZ=a("a"),o9r=o("TFLongformerModel"),r9r=o(" (Longformer model)"),t9r=l(),S3=a("li"),p0e=a("strong"),a9r=o("lxmert"),n9r=o(" \u2014 "),RZ=a("a"),s9r=o("TFLxmertModel"),l9r=o(" (LXMERT model)"),i9r=l(),R3=a("li"),_0e=a("strong"),d9r=o("marian"),c9r=o(" \u2014 "),PZ=a("a"),f9r=o("TFMarianModel"),m9r=o(" (Marian model)"),g9r=l(),P3=a("li"),v0e=a("strong"),h9r=o("mbart"),u9r=o(" \u2014 "),BZ=a("a"),p9r=o("TFMBartModel"),_9r=o(" (mBART model)"),v9r=l(),B3=a("li"),b0e=a("strong"),b9r=o("mobilebert"),F9r=o(" \u2014 "),IZ=a("a"),T9r=o("TFMobileBertModel"),M9r=o(" (MobileBERT model)"),E9r=l(),I3=a("li"),F0e=a("strong"),C9r=o("mobilevit"),w9r=o(" \u2014 "),NZ=a("a"),A9r=o("TFMobileViTModel"),L9r=o(" (MobileViT model)"),y9r=l(),N3=a("li"),T0e=a("strong"),x9r=o("mpnet"),$9r=o(" \u2014 "),qZ=a("a"),k9r=o("TFMPNetModel"),S9r=o(" (MPNet model)"),R9r=l(),q3=a("li"),M0e=a("strong"),P9r=o("mt5"),B9r=o(" \u2014 "),jZ=a("a"),I9r=o("TFMT5Model"),N9r=o(" (MT5 model)"),q9r=l(),j3=a("li"),E0e=a("strong"),j9r=o("openai-gpt"),D9r=o(" \u2014 "),DZ=a("a"),G9r=o("TFOpenAIGPTModel"),O9r=o(" (OpenAI GPT model)"),V9r=l(),D3=a("li"),C0e=a("strong"),X9r=o("opt"),z9r=o(" \u2014 "),GZ=a("a"),Q9r=o("TFOPTModel"),W9r=o(" (OPT model)"),U9r=l(),G3=a("li"),w0e=a("strong"),H9r=o("pegasus"),J9r=o(" \u2014 "),OZ=a("a"),Y9r=o("TFPegasusModel"),K9r=o(" (Pegasus model)"),Z9r=l(),O3=a("li"),A0e=a("strong"),exr=o("regnet"),oxr=o(" \u2014 "),VZ=a("a"),rxr=o("TFRegNetModel"),txr=o(" (RegNet model)"),axr=l(),V3=a("li"),L0e=a("strong"),nxr=o("rembert"),sxr=o(" \u2014 "),XZ=a("a"),lxr=o("TFRemBertModel"),ixr=o(" (RemBERT model)"),dxr=l(),X3=a("li"),y0e=a("strong"),cxr=o("resnet"),fxr=o(" \u2014 "),zZ=a("a"),mxr=o("TFResNetModel"),gxr=o(" (ResNet model)"),hxr=l(),z3=a("li"),x0e=a("strong"),uxr=o("roberta"),pxr=o(" \u2014 "),QZ=a("a"),_xr=o("TFRobertaModel"),vxr=o(" (RoBERTa model)"),bxr=l(),Q3=a("li"),$0e=a("strong"),Fxr=o("roformer"),Txr=o(" \u2014 "),WZ=a("a"),Mxr=o("TFRoFormerModel"),Exr=o(" (RoFormer model)"),Cxr=l(),W3=a("li"),k0e=a("strong"),wxr=o("segformer"),Axr=o(" \u2014 "),UZ=a("a"),Lxr=o("TFSegformerModel"),yxr=o(" (SegFormer model)"),xxr=l(),U3=a("li"),S0e=a("strong"),$xr=o("speech_to_text"),kxr=o(" \u2014 "),HZ=a("a"),Sxr=o("TFSpeech2TextModel"),Rxr=o(" (Speech2Text model)"),Pxr=l(),H3=a("li"),R0e=a("strong"),Bxr=o("swin"),Ixr=o(" \u2014 "),JZ=a("a"),Nxr=o("TFSwinModel"),qxr=o(" (Swin Transformer model)"),jxr=l(),J3=a("li"),P0e=a("strong"),Dxr=o("t5"),Gxr=o(" \u2014 "),YZ=a("a"),Oxr=o("TFT5Model"),Vxr=o(" (T5 model)"),Xxr=l(),Y3=a("li"),B0e=a("strong"),zxr=o("tapas"),Qxr=o(" \u2014 "),KZ=a("a"),Wxr=o("TFTapasModel"),Uxr=o(" (TAPAS model)"),Hxr=l(),K3=a("li"),I0e=a("strong"),Jxr=o("transfo-xl"),Yxr=o(" \u2014 "),ZZ=a("a"),Kxr=o("TFTransfoXLModel"),Zxr=o(" (Transformer-XL model)"),e$r=l(),Z3=a("li"),N0e=a("strong"),o$r=o("vit"),r$r=o(" \u2014 "),eee=a("a"),t$r=o("TFViTModel"),a$r=o(" (ViT model)"),n$r=l(),e5=a("li"),q0e=a("strong"),s$r=o("vit_mae"),l$r=o(" \u2014 "),oee=a("a"),i$r=o("TFViTMAEModel"),d$r=o(" (ViTMAE model)"),c$r=l(),o5=a("li"),j0e=a("strong"),f$r=o("wav2vec2"),m$r=o(" \u2014 "),ree=a("a"),g$r=o("TFWav2Vec2Model"),h$r=o(" (Wav2Vec2 model)"),u$r=l(),r5=a("li"),D0e=a("strong"),p$r=o("xglm"),_$r=o(" \u2014 "),tee=a("a"),v$r=o("TFXGLMModel"),b$r=o(" (XGLM model)"),F$r=l(),t5=a("li"),G0e=a("strong"),T$r=o("xlm"),M$r=o(" \u2014 "),aee=a("a"),E$r=o("TFXLMModel"),C$r=o(" (XLM model)"),w$r=l(),a5=a("li"),O0e=a("strong"),A$r=o("xlm-roberta"),L$r=o(" \u2014 "),nee=a("a"),y$r=o("TFXLMRobertaModel"),x$r=o(" (XLM-RoBERTa model)"),$$r=l(),n5=a("li"),V0e=a("strong"),k$r=o("xlnet"),S$r=o(" \u2014 "),see=a("a"),R$r=o("TFXLNetModel"),P$r=o(" (XLNet model)"),B$r=l(),F(s5.$$.fragment),XKe=l(),Xc=a("h2"),l5=a("a"),X0e=a("span"),F(Ck.$$.fragment),I$r=l(),z0e=a("span"),N$r=o("TFAutoModelForPreTraining"),zKe=l(),lr=a("div"),F(wk.$$.fragment),q$r=l(),zc=a("p"),j$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lee=a("a"),D$r=o("from_pretrained()"),G$r=o(" class method or the "),iee=a("a"),O$r=o("from_config()"),V$r=o(` class
method.`),X$r=l(),Ak=a("p"),z$r=o("This class cannot be instantiated directly using "),Q0e=a("code"),Q$r=o("__init__()"),W$r=o(" (throws an error)."),U$r=l(),zt=a("div"),F(Lk.$$.fragment),H$r=l(),W0e=a("p"),J$r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Y$r=l(),Qc=a("p"),K$r=o(`Note:
Loading a model from its configuration file does `),U0e=a("strong"),Z$r=o("not"),ekr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=a("a"),okr=o("from_pretrained()"),rkr=o(" to load the model weights."),tkr=l(),F(i5.$$.fragment),akr=l(),Nr=a("div"),F(yk.$$.fragment),nkr=l(),H0e=a("p"),skr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lkr=l(),wn=a("p"),ikr=o("The model class to instantiate is selected based on the "),J0e=a("code"),dkr=o("model_type"),ckr=o(` property of the config object (either
passed as an argument or loaded from `),Y0e=a("code"),fkr=o("pretrained_model_name_or_path"),mkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K0e=a("code"),gkr=o("pretrained_model_name_or_path"),hkr=o(":"),ukr=l(),se=a("ul"),d5=a("li"),Z0e=a("strong"),pkr=o("albert"),_kr=o(" \u2014 "),cee=a("a"),vkr=o("TFAlbertForPreTraining"),bkr=o(" (ALBERT model)"),Fkr=l(),c5=a("li"),ewe=a("strong"),Tkr=o("bart"),Mkr=o(" \u2014 "),fee=a("a"),Ekr=o("TFBartForConditionalGeneration"),Ckr=o(" (BART model)"),wkr=l(),f5=a("li"),owe=a("strong"),Akr=o("bert"),Lkr=o(" \u2014 "),mee=a("a"),ykr=o("TFBertForPreTraining"),xkr=o(" (BERT model)"),$kr=l(),m5=a("li"),rwe=a("strong"),kkr=o("camembert"),Skr=o(" \u2014 "),gee=a("a"),Rkr=o("TFCamembertForMaskedLM"),Pkr=o(" (CamemBERT model)"),Bkr=l(),g5=a("li"),twe=a("strong"),Ikr=o("ctrl"),Nkr=o(" \u2014 "),hee=a("a"),qkr=o("TFCTRLLMHeadModel"),jkr=o(" (CTRL model)"),Dkr=l(),h5=a("li"),awe=a("strong"),Gkr=o("distilbert"),Okr=o(" \u2014 "),uee=a("a"),Vkr=o("TFDistilBertForMaskedLM"),Xkr=o(" (DistilBERT model)"),zkr=l(),u5=a("li"),nwe=a("strong"),Qkr=o("electra"),Wkr=o(" \u2014 "),pee=a("a"),Ukr=o("TFElectraForPreTraining"),Hkr=o(" (ELECTRA model)"),Jkr=l(),p5=a("li"),swe=a("strong"),Ykr=o("flaubert"),Kkr=o(" \u2014 "),_ee=a("a"),Zkr=o("TFFlaubertWithLMHeadModel"),eSr=o(" (FlauBERT model)"),oSr=l(),_5=a("li"),lwe=a("strong"),rSr=o("funnel"),tSr=o(" \u2014 "),vee=a("a"),aSr=o("TFFunnelForPreTraining"),nSr=o(" (Funnel Transformer model)"),sSr=l(),v5=a("li"),iwe=a("strong"),lSr=o("gpt2"),iSr=o(" \u2014 "),bee=a("a"),dSr=o("TFGPT2LMHeadModel"),cSr=o(" (OpenAI GPT-2 model)"),fSr=l(),b5=a("li"),dwe=a("strong"),mSr=o("layoutlm"),gSr=o(" \u2014 "),Fee=a("a"),hSr=o("TFLayoutLMForMaskedLM"),uSr=o(" (LayoutLM model)"),pSr=l(),F5=a("li"),cwe=a("strong"),_Sr=o("lxmert"),vSr=o(" \u2014 "),Tee=a("a"),bSr=o("TFLxmertForPreTraining"),FSr=o(" (LXMERT model)"),TSr=l(),T5=a("li"),fwe=a("strong"),MSr=o("mobilebert"),ESr=o(" \u2014 "),Mee=a("a"),CSr=o("TFMobileBertForPreTraining"),wSr=o(" (MobileBERT model)"),ASr=l(),M5=a("li"),mwe=a("strong"),LSr=o("mpnet"),ySr=o(" \u2014 "),Eee=a("a"),xSr=o("TFMPNetForMaskedLM"),$Sr=o(" (MPNet model)"),kSr=l(),E5=a("li"),gwe=a("strong"),SSr=o("openai-gpt"),RSr=o(" \u2014 "),Cee=a("a"),PSr=o("TFOpenAIGPTLMHeadModel"),BSr=o(" (OpenAI GPT model)"),ISr=l(),C5=a("li"),hwe=a("strong"),NSr=o("roberta"),qSr=o(" \u2014 "),wee=a("a"),jSr=o("TFRobertaForMaskedLM"),DSr=o(" (RoBERTa model)"),GSr=l(),w5=a("li"),uwe=a("strong"),OSr=o("t5"),VSr=o(" \u2014 "),Aee=a("a"),XSr=o("TFT5ForConditionalGeneration"),zSr=o(" (T5 model)"),QSr=l(),A5=a("li"),pwe=a("strong"),WSr=o("tapas"),USr=o(" \u2014 "),Lee=a("a"),HSr=o("TFTapasForMaskedLM"),JSr=o(" (TAPAS model)"),YSr=l(),L5=a("li"),_we=a("strong"),KSr=o("transfo-xl"),ZSr=o(" \u2014 "),yee=a("a"),eRr=o("TFTransfoXLLMHeadModel"),oRr=o(" (Transformer-XL model)"),rRr=l(),y5=a("li"),vwe=a("strong"),tRr=o("vit_mae"),aRr=o(" \u2014 "),xee=a("a"),nRr=o("TFViTMAEForPreTraining"),sRr=o(" (ViTMAE model)"),lRr=l(),x5=a("li"),bwe=a("strong"),iRr=o("xlm"),dRr=o(" \u2014 "),$ee=a("a"),cRr=o("TFXLMWithLMHeadModel"),fRr=o(" (XLM model)"),mRr=l(),$5=a("li"),Fwe=a("strong"),gRr=o("xlm-roberta"),hRr=o(" \u2014 "),kee=a("a"),uRr=o("TFXLMRobertaForMaskedLM"),pRr=o(" (XLM-RoBERTa model)"),_Rr=l(),k5=a("li"),Twe=a("strong"),vRr=o("xlnet"),bRr=o(" \u2014 "),See=a("a"),FRr=o("TFXLNetLMHeadModel"),TRr=o(" (XLNet model)"),MRr=l(),F(S5.$$.fragment),QKe=l(),Wc=a("h2"),R5=a("a"),Mwe=a("span"),F(xk.$$.fragment),ERr=l(),Ewe=a("span"),CRr=o("TFAutoModelForCausalLM"),WKe=l(),ir=a("div"),F($k.$$.fragment),wRr=l(),Uc=a("p"),ARr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Ree=a("a"),LRr=o("from_pretrained()"),yRr=o(" class method or the "),Pee=a("a"),xRr=o("from_config()"),$Rr=o(` class
method.`),kRr=l(),kk=a("p"),SRr=o("This class cannot be instantiated directly using "),Cwe=a("code"),RRr=o("__init__()"),PRr=o(" (throws an error)."),BRr=l(),Qt=a("div"),F(Sk.$$.fragment),IRr=l(),wwe=a("p"),NRr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qRr=l(),Hc=a("p"),jRr=o(`Note:
Loading a model from its configuration file does `),Awe=a("strong"),DRr=o("not"),GRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=a("a"),ORr=o("from_pretrained()"),VRr=o(" to load the model weights."),XRr=l(),F(P5.$$.fragment),zRr=l(),qr=a("div"),F(Rk.$$.fragment),QRr=l(),Lwe=a("p"),WRr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),URr=l(),An=a("p"),HRr=o("The model class to instantiate is selected based on the "),ywe=a("code"),JRr=o("model_type"),YRr=o(` property of the config object (either
passed as an argument or loaded from `),xwe=a("code"),KRr=o("pretrained_model_name_or_path"),ZRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=a("code"),ePr=o("pretrained_model_name_or_path"),oPr=o(":"),rPr=l(),Me=a("ul"),B5=a("li"),kwe=a("strong"),tPr=o("bert"),aPr=o(" \u2014 "),Iee=a("a"),nPr=o("TFBertLMHeadModel"),sPr=o(" (BERT model)"),lPr=l(),I5=a("li"),Swe=a("strong"),iPr=o("camembert"),dPr=o(" \u2014 "),Nee=a("a"),cPr=o("TFCamembertForCausalLM"),fPr=o(" (CamemBERT model)"),mPr=l(),N5=a("li"),Rwe=a("strong"),gPr=o("ctrl"),hPr=o(" \u2014 "),qee=a("a"),uPr=o("TFCTRLLMHeadModel"),pPr=o(" (CTRL model)"),_Pr=l(),q5=a("li"),Pwe=a("strong"),vPr=o("gpt2"),bPr=o(" \u2014 "),jee=a("a"),FPr=o("TFGPT2LMHeadModel"),TPr=o(" (OpenAI GPT-2 model)"),MPr=l(),j5=a("li"),Bwe=a("strong"),EPr=o("gptj"),CPr=o(" \u2014 "),Dee=a("a"),wPr=o("TFGPTJForCausalLM"),APr=o(" (GPT-J model)"),LPr=l(),D5=a("li"),Iwe=a("strong"),yPr=o("openai-gpt"),xPr=o(" \u2014 "),Gee=a("a"),$Pr=o("TFOpenAIGPTLMHeadModel"),kPr=o(" (OpenAI GPT model)"),SPr=l(),G5=a("li"),Nwe=a("strong"),RPr=o("opt"),PPr=o(" \u2014 "),Oee=a("a"),BPr=o("TFOPTForCausalLM"),IPr=o(" (OPT model)"),NPr=l(),O5=a("li"),qwe=a("strong"),qPr=o("rembert"),jPr=o(" \u2014 "),Vee=a("a"),DPr=o("TFRemBertForCausalLM"),GPr=o(" (RemBERT model)"),OPr=l(),V5=a("li"),jwe=a("strong"),VPr=o("roberta"),XPr=o(" \u2014 "),Xee=a("a"),zPr=o("TFRobertaForCausalLM"),QPr=o(" (RoBERTa model)"),WPr=l(),X5=a("li"),Dwe=a("strong"),UPr=o("roformer"),HPr=o(" \u2014 "),zee=a("a"),JPr=o("TFRoFormerForCausalLM"),YPr=o(" (RoFormer model)"),KPr=l(),z5=a("li"),Gwe=a("strong"),ZPr=o("transfo-xl"),eBr=o(" \u2014 "),Qee=a("a"),oBr=o("TFTransfoXLLMHeadModel"),rBr=o(" (Transformer-XL model)"),tBr=l(),Q5=a("li"),Owe=a("strong"),aBr=o("xglm"),nBr=o(" \u2014 "),Wee=a("a"),sBr=o("TFXGLMForCausalLM"),lBr=o(" (XGLM model)"),iBr=l(),W5=a("li"),Vwe=a("strong"),dBr=o("xlm"),cBr=o(" \u2014 "),Uee=a("a"),fBr=o("TFXLMWithLMHeadModel"),mBr=o(" (XLM model)"),gBr=l(),U5=a("li"),Xwe=a("strong"),hBr=o("xlnet"),uBr=o(" \u2014 "),Hee=a("a"),pBr=o("TFXLNetLMHeadModel"),_Br=o(" (XLNet model)"),vBr=l(),F(H5.$$.fragment),UKe=l(),Jc=a("h2"),J5=a("a"),zwe=a("span"),F(Pk.$$.fragment),bBr=l(),Qwe=a("span"),FBr=o("TFAutoModelForImageClassification"),HKe=l(),dr=a("div"),F(Bk.$$.fragment),TBr=l(),Yc=a("p"),MBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jee=a("a"),EBr=o("from_pretrained()"),CBr=o(" class method or the "),Yee=a("a"),wBr=o("from_config()"),ABr=o(` class
method.`),LBr=l(),Ik=a("p"),yBr=o("This class cannot be instantiated directly using "),Wwe=a("code"),xBr=o("__init__()"),$Br=o(" (throws an error)."),kBr=l(),Wt=a("div"),F(Nk.$$.fragment),SBr=l(),Uwe=a("p"),RBr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),PBr=l(),Kc=a("p"),BBr=o(`Note:
Loading a model from its configuration file does `),Hwe=a("strong"),IBr=o("not"),NBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=a("a"),qBr=o("from_pretrained()"),jBr=o(" to load the model weights."),DBr=l(),F(Y5.$$.fragment),GBr=l(),jr=a("div"),F(qk.$$.fragment),OBr=l(),Jwe=a("p"),VBr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XBr=l(),Ln=a("p"),zBr=o("The model class to instantiate is selected based on the "),Ywe=a("code"),QBr=o("model_type"),WBr=o(` property of the config object (either
passed as an argument or loaded from `),Kwe=a("code"),UBr=o("pretrained_model_name_or_path"),HBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=a("code"),JBr=o("pretrained_model_name_or_path"),YBr=o(":"),KBr=l(),Be=a("ul"),K5=a("li"),eAe=a("strong"),ZBr=o("convnext"),eIr=o(" \u2014 "),Zee=a("a"),oIr=o("TFConvNextForImageClassification"),rIr=o(" (ConvNeXT model)"),tIr=l(),Z5=a("li"),oAe=a("strong"),aIr=o("data2vec-vision"),nIr=o(" \u2014 "),eoe=a("a"),sIr=o("TFData2VecVisionForImageClassification"),lIr=o(" (Data2VecVision model)"),iIr=l(),Fl=a("li"),rAe=a("strong"),dIr=o("deit"),cIr=o(" \u2014 "),ooe=a("a"),fIr=o("TFDeiTForImageClassification"),mIr=o(" or "),roe=a("a"),gIr=o("TFDeiTForImageClassificationWithTeacher"),hIr=o(" (DeiT model)"),uIr=l(),e0=a("li"),tAe=a("strong"),pIr=o("mobilevit"),_Ir=o(" \u2014 "),toe=a("a"),vIr=o("TFMobileViTForImageClassification"),bIr=o(" (MobileViT model)"),FIr=l(),o0=a("li"),aAe=a("strong"),TIr=o("regnet"),MIr=o(" \u2014 "),aoe=a("a"),EIr=o("TFRegNetForImageClassification"),CIr=o(" (RegNet model)"),wIr=l(),r0=a("li"),nAe=a("strong"),AIr=o("resnet"),LIr=o(" \u2014 "),noe=a("a"),yIr=o("TFResNetForImageClassification"),xIr=o(" (ResNet model)"),$Ir=l(),t0=a("li"),sAe=a("strong"),kIr=o("segformer"),SIr=o(" \u2014 "),soe=a("a"),RIr=o("TFSegformerForImageClassification"),PIr=o(" (SegFormer model)"),BIr=l(),a0=a("li"),lAe=a("strong"),IIr=o("swin"),NIr=o(" \u2014 "),loe=a("a"),qIr=o("TFSwinForImageClassification"),jIr=o(" (Swin Transformer model)"),DIr=l(),n0=a("li"),iAe=a("strong"),GIr=o("vit"),OIr=o(" \u2014 "),ioe=a("a"),VIr=o("TFViTForImageClassification"),XIr=o(" (ViT model)"),zIr=l(),F(s0.$$.fragment),JKe=l(),Zc=a("h2"),l0=a("a"),dAe=a("span"),F(jk.$$.fragment),QIr=l(),cAe=a("span"),WIr=o("TFAutoModelForSemanticSegmentation"),YKe=l(),cr=a("div"),F(Dk.$$.fragment),UIr=l(),ef=a("p"),HIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),doe=a("a"),JIr=o("from_pretrained()"),YIr=o(" class method or the "),coe=a("a"),KIr=o("from_config()"),ZIr=o(` class
method.`),eNr=l(),Gk=a("p"),oNr=o("This class cannot be instantiated directly using "),fAe=a("code"),rNr=o("__init__()"),tNr=o(" (throws an error)."),aNr=l(),Ut=a("div"),F(Ok.$$.fragment),nNr=l(),mAe=a("p"),sNr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),lNr=l(),of=a("p"),iNr=o(`Note:
Loading a model from its configuration file does `),gAe=a("strong"),dNr=o("not"),cNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),fNr=o("from_pretrained()"),mNr=o(" to load the model weights."),gNr=l(),F(i0.$$.fragment),hNr=l(),Dr=a("div"),F(Vk.$$.fragment),uNr=l(),hAe=a("p"),pNr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),_Nr=l(),yn=a("p"),vNr=o("The model class to instantiate is selected based on the "),uAe=a("code"),bNr=o("model_type"),FNr=o(` property of the config object (either
passed as an argument or loaded from `),pAe=a("code"),TNr=o("pretrained_model_name_or_path"),MNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=a("code"),ENr=o("pretrained_model_name_or_path"),CNr=o(":"),wNr=l(),rf=a("ul"),d0=a("li"),vAe=a("strong"),ANr=o("data2vec-vision"),LNr=o(" \u2014 "),moe=a("a"),yNr=o("TFData2VecVisionForSemanticSegmentation"),xNr=o(" (Data2VecVision model)"),$Nr=l(),c0=a("li"),bAe=a("strong"),kNr=o("mobilevit"),SNr=o(" \u2014 "),goe=a("a"),RNr=o("TFMobileViTForSemanticSegmentation"),PNr=o(" (MobileViT model)"),BNr=l(),f0=a("li"),FAe=a("strong"),INr=o("segformer"),NNr=o(" \u2014 "),hoe=a("a"),qNr=o("TFSegformerForSemanticSegmentation"),jNr=o(" (SegFormer model)"),DNr=l(),F(m0.$$.fragment),KKe=l(),tf=a("h2"),g0=a("a"),TAe=a("span"),F(Xk.$$.fragment),GNr=l(),MAe=a("span"),ONr=o("TFAutoModelForMaskedLM"),ZKe=l(),fr=a("div"),F(zk.$$.fragment),VNr=l(),af=a("p"),XNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uoe=a("a"),zNr=o("from_pretrained()"),QNr=o(" class method or the "),poe=a("a"),WNr=o("from_config()"),UNr=o(` class
method.`),HNr=l(),Qk=a("p"),JNr=o("This class cannot be instantiated directly using "),EAe=a("code"),YNr=o("__init__()"),KNr=o(" (throws an error)."),ZNr=l(),Ht=a("div"),F(Wk.$$.fragment),eqr=l(),CAe=a("p"),oqr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rqr=l(),nf=a("p"),tqr=o(`Note:
Loading a model from its configuration file does `),wAe=a("strong"),aqr=o("not"),nqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),sqr=o("from_pretrained()"),lqr=o(" to load the model weights."),iqr=l(),F(h0.$$.fragment),dqr=l(),Gr=a("div"),F(Uk.$$.fragment),cqr=l(),AAe=a("p"),fqr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),mqr=l(),xn=a("p"),gqr=o("The model class to instantiate is selected based on the "),LAe=a("code"),hqr=o("model_type"),uqr=o(` property of the config object (either
passed as an argument or loaded from `),yAe=a("code"),pqr=o("pretrained_model_name_or_path"),_qr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=a("code"),vqr=o("pretrained_model_name_or_path"),bqr=o(":"),Fqr=l(),me=a("ul"),u0=a("li"),$Ae=a("strong"),Tqr=o("albert"),Mqr=o(" \u2014 "),voe=a("a"),Eqr=o("TFAlbertForMaskedLM"),Cqr=o(" (ALBERT model)"),wqr=l(),p0=a("li"),kAe=a("strong"),Aqr=o("bert"),Lqr=o(" \u2014 "),boe=a("a"),yqr=o("TFBertForMaskedLM"),xqr=o(" (BERT model)"),$qr=l(),_0=a("li"),SAe=a("strong"),kqr=o("camembert"),Sqr=o(" \u2014 "),Foe=a("a"),Rqr=o("TFCamembertForMaskedLM"),Pqr=o(" (CamemBERT model)"),Bqr=l(),v0=a("li"),RAe=a("strong"),Iqr=o("convbert"),Nqr=o(" \u2014 "),Toe=a("a"),qqr=o("TFConvBertForMaskedLM"),jqr=o(" (ConvBERT model)"),Dqr=l(),b0=a("li"),PAe=a("strong"),Gqr=o("deberta"),Oqr=o(" \u2014 "),Moe=a("a"),Vqr=o("TFDebertaForMaskedLM"),Xqr=o(" (DeBERTa model)"),zqr=l(),F0=a("li"),BAe=a("strong"),Qqr=o("deberta-v2"),Wqr=o(" \u2014 "),Eoe=a("a"),Uqr=o("TFDebertaV2ForMaskedLM"),Hqr=o(" (DeBERTa-v2 model)"),Jqr=l(),T0=a("li"),IAe=a("strong"),Yqr=o("distilbert"),Kqr=o(" \u2014 "),Coe=a("a"),Zqr=o("TFDistilBertForMaskedLM"),ejr=o(" (DistilBERT model)"),ojr=l(),M0=a("li"),NAe=a("strong"),rjr=o("electra"),tjr=o(" \u2014 "),woe=a("a"),ajr=o("TFElectraForMaskedLM"),njr=o(" (ELECTRA model)"),sjr=l(),E0=a("li"),qAe=a("strong"),ljr=o("flaubert"),ijr=o(" \u2014 "),Aoe=a("a"),djr=o("TFFlaubertWithLMHeadModel"),cjr=o(" (FlauBERT model)"),fjr=l(),C0=a("li"),jAe=a("strong"),mjr=o("funnel"),gjr=o(" \u2014 "),Loe=a("a"),hjr=o("TFFunnelForMaskedLM"),ujr=o(" (Funnel Transformer model)"),pjr=l(),w0=a("li"),DAe=a("strong"),_jr=o("layoutlm"),vjr=o(" \u2014 "),yoe=a("a"),bjr=o("TFLayoutLMForMaskedLM"),Fjr=o(" (LayoutLM model)"),Tjr=l(),A0=a("li"),GAe=a("strong"),Mjr=o("longformer"),Ejr=o(" \u2014 "),xoe=a("a"),Cjr=o("TFLongformerForMaskedLM"),wjr=o(" (Longformer model)"),Ajr=l(),L0=a("li"),OAe=a("strong"),Ljr=o("mobilebert"),yjr=o(" \u2014 "),$oe=a("a"),xjr=o("TFMobileBertForMaskedLM"),$jr=o(" (MobileBERT model)"),kjr=l(),y0=a("li"),VAe=a("strong"),Sjr=o("mpnet"),Rjr=o(" \u2014 "),koe=a("a"),Pjr=o("TFMPNetForMaskedLM"),Bjr=o(" (MPNet model)"),Ijr=l(),x0=a("li"),XAe=a("strong"),Njr=o("rembert"),qjr=o(" \u2014 "),Soe=a("a"),jjr=o("TFRemBertForMaskedLM"),Djr=o(" (RemBERT model)"),Gjr=l(),$0=a("li"),zAe=a("strong"),Ojr=o("roberta"),Vjr=o(" \u2014 "),Roe=a("a"),Xjr=o("TFRobertaForMaskedLM"),zjr=o(" (RoBERTa model)"),Qjr=l(),k0=a("li"),QAe=a("strong"),Wjr=o("roformer"),Ujr=o(" \u2014 "),Poe=a("a"),Hjr=o("TFRoFormerForMaskedLM"),Jjr=o(" (RoFormer model)"),Yjr=l(),S0=a("li"),WAe=a("strong"),Kjr=o("tapas"),Zjr=o(" \u2014 "),Boe=a("a"),eDr=o("TFTapasForMaskedLM"),oDr=o(" (TAPAS model)"),rDr=l(),R0=a("li"),UAe=a("strong"),tDr=o("xlm"),aDr=o(" \u2014 "),Ioe=a("a"),nDr=o("TFXLMWithLMHeadModel"),sDr=o(" (XLM model)"),lDr=l(),P0=a("li"),HAe=a("strong"),iDr=o("xlm-roberta"),dDr=o(" \u2014 "),Noe=a("a"),cDr=o("TFXLMRobertaForMaskedLM"),fDr=o(" (XLM-RoBERTa model)"),mDr=l(),F(B0.$$.fragment),eZe=l(),sf=a("h2"),I0=a("a"),JAe=a("span"),F(Hk.$$.fragment),gDr=l(),YAe=a("span"),hDr=o("TFAutoModelForSeq2SeqLM"),oZe=l(),mr=a("div"),F(Jk.$$.fragment),uDr=l(),lf=a("p"),pDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qoe=a("a"),_Dr=o("from_pretrained()"),vDr=o(" class method or the "),joe=a("a"),bDr=o("from_config()"),FDr=o(` class
method.`),TDr=l(),Yk=a("p"),MDr=o("This class cannot be instantiated directly using "),KAe=a("code"),EDr=o("__init__()"),CDr=o(" (throws an error)."),wDr=l(),Jt=a("div"),F(Kk.$$.fragment),ADr=l(),ZAe=a("p"),LDr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yDr=l(),df=a("p"),xDr=o(`Note:
Loading a model from its configuration file does `),e6e=a("strong"),$Dr=o("not"),kDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=a("a"),SDr=o("from_pretrained()"),RDr=o(" to load the model weights."),PDr=l(),F(N0.$$.fragment),BDr=l(),Or=a("div"),F(Zk.$$.fragment),IDr=l(),o6e=a("p"),NDr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qDr=l(),$n=a("p"),jDr=o("The model class to instantiate is selected based on the "),r6e=a("code"),DDr=o("model_type"),GDr=o(` property of the config object (either
passed as an argument or loaded from `),t6e=a("code"),ODr=o("pretrained_model_name_or_path"),VDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=a("code"),XDr=o("pretrained_model_name_or_path"),zDr=o(":"),QDr=l(),ye=a("ul"),q0=a("li"),n6e=a("strong"),WDr=o("bart"),UDr=o(" \u2014 "),Goe=a("a"),HDr=o("TFBartForConditionalGeneration"),JDr=o(" (BART model)"),YDr=l(),j0=a("li"),s6e=a("strong"),KDr=o("blenderbot"),ZDr=o(" \u2014 "),Ooe=a("a"),eGr=o("TFBlenderbotForConditionalGeneration"),oGr=o(" (Blenderbot model)"),rGr=l(),D0=a("li"),l6e=a("strong"),tGr=o("blenderbot-small"),aGr=o(" \u2014 "),Voe=a("a"),nGr=o("TFBlenderbotSmallForConditionalGeneration"),sGr=o(" (BlenderbotSmall model)"),lGr=l(),G0=a("li"),i6e=a("strong"),iGr=o("encoder-decoder"),dGr=o(" \u2014 "),Xoe=a("a"),cGr=o("TFEncoderDecoderModel"),fGr=o(" (Encoder decoder model)"),mGr=l(),O0=a("li"),d6e=a("strong"),gGr=o("led"),hGr=o(" \u2014 "),zoe=a("a"),uGr=o("TFLEDForConditionalGeneration"),pGr=o(" (LED model)"),_Gr=l(),V0=a("li"),c6e=a("strong"),vGr=o("marian"),bGr=o(" \u2014 "),Qoe=a("a"),FGr=o("TFMarianMTModel"),TGr=o(" (Marian model)"),MGr=l(),X0=a("li"),f6e=a("strong"),EGr=o("mbart"),CGr=o(" \u2014 "),Woe=a("a"),wGr=o("TFMBartForConditionalGeneration"),AGr=o(" (mBART model)"),LGr=l(),z0=a("li"),m6e=a("strong"),yGr=o("mt5"),xGr=o(" \u2014 "),Uoe=a("a"),$Gr=o("TFMT5ForConditionalGeneration"),kGr=o(" (MT5 model)"),SGr=l(),Q0=a("li"),g6e=a("strong"),RGr=o("pegasus"),PGr=o(" \u2014 "),Hoe=a("a"),BGr=o("TFPegasusForConditionalGeneration"),IGr=o(" (Pegasus model)"),NGr=l(),W0=a("li"),h6e=a("strong"),qGr=o("t5"),jGr=o(" \u2014 "),Joe=a("a"),DGr=o("TFT5ForConditionalGeneration"),GGr=o(" (T5 model)"),OGr=l(),F(U0.$$.fragment),rZe=l(),cf=a("h2"),H0=a("a"),u6e=a("span"),F(eS.$$.fragment),VGr=l(),p6e=a("span"),XGr=o("TFAutoModelForSequenceClassification"),tZe=l(),gr=a("div"),F(oS.$$.fragment),zGr=l(),ff=a("p"),QGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yoe=a("a"),WGr=o("from_pretrained()"),UGr=o(" class method or the "),Koe=a("a"),HGr=o("from_config()"),JGr=o(` class
method.`),YGr=l(),rS=a("p"),KGr=o("This class cannot be instantiated directly using "),_6e=a("code"),ZGr=o("__init__()"),eOr=o(" (throws an error)."),oOr=l(),Yt=a("div"),F(tS.$$.fragment),rOr=l(),v6e=a("p"),tOr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aOr=l(),mf=a("p"),nOr=o(`Note:
Loading a model from its configuration file does `),b6e=a("strong"),sOr=o("not"),lOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=a("a"),iOr=o("from_pretrained()"),dOr=o(" to load the model weights."),cOr=l(),F(J0.$$.fragment),fOr=l(),Vr=a("div"),F(aS.$$.fragment),mOr=l(),F6e=a("p"),gOr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),hOr=l(),kn=a("p"),uOr=o("The model class to instantiate is selected based on the "),T6e=a("code"),pOr=o("model_type"),_Or=o(` property of the config object (either
passed as an argument or loaded from `),M6e=a("code"),vOr=o("pretrained_model_name_or_path"),bOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=a("code"),FOr=o("pretrained_model_name_or_path"),TOr=o(":"),MOr=l(),re=a("ul"),Y0=a("li"),C6e=a("strong"),EOr=o("albert"),COr=o(" \u2014 "),ere=a("a"),wOr=o("TFAlbertForSequenceClassification"),AOr=o(" (ALBERT model)"),LOr=l(),K0=a("li"),w6e=a("strong"),yOr=o("bert"),xOr=o(" \u2014 "),ore=a("a"),$Or=o("TFBertForSequenceClassification"),kOr=o(" (BERT model)"),SOr=l(),Z0=a("li"),A6e=a("strong"),ROr=o("camembert"),POr=o(" \u2014 "),rre=a("a"),BOr=o("TFCamembertForSequenceClassification"),IOr=o(" (CamemBERT model)"),NOr=l(),ew=a("li"),L6e=a("strong"),qOr=o("convbert"),jOr=o(" \u2014 "),tre=a("a"),DOr=o("TFConvBertForSequenceClassification"),GOr=o(" (ConvBERT model)"),OOr=l(),ow=a("li"),y6e=a("strong"),VOr=o("ctrl"),XOr=o(" \u2014 "),are=a("a"),zOr=o("TFCTRLForSequenceClassification"),QOr=o(" (CTRL model)"),WOr=l(),rw=a("li"),x6e=a("strong"),UOr=o("deberta"),HOr=o(" \u2014 "),nre=a("a"),JOr=o("TFDebertaForSequenceClassification"),YOr=o(" (DeBERTa model)"),KOr=l(),tw=a("li"),$6e=a("strong"),ZOr=o("deberta-v2"),eVr=o(" \u2014 "),sre=a("a"),oVr=o("TFDebertaV2ForSequenceClassification"),rVr=o(" (DeBERTa-v2 model)"),tVr=l(),aw=a("li"),k6e=a("strong"),aVr=o("distilbert"),nVr=o(" \u2014 "),lre=a("a"),sVr=o("TFDistilBertForSequenceClassification"),lVr=o(" (DistilBERT model)"),iVr=l(),nw=a("li"),S6e=a("strong"),dVr=o("electra"),cVr=o(" \u2014 "),ire=a("a"),fVr=o("TFElectraForSequenceClassification"),mVr=o(" (ELECTRA model)"),gVr=l(),sw=a("li"),R6e=a("strong"),hVr=o("flaubert"),uVr=o(" \u2014 "),dre=a("a"),pVr=o("TFFlaubertForSequenceClassification"),_Vr=o(" (FlauBERT model)"),vVr=l(),lw=a("li"),P6e=a("strong"),bVr=o("funnel"),FVr=o(" \u2014 "),cre=a("a"),TVr=o("TFFunnelForSequenceClassification"),MVr=o(" (Funnel Transformer model)"),EVr=l(),iw=a("li"),B6e=a("strong"),CVr=o("gpt2"),wVr=o(" \u2014 "),fre=a("a"),AVr=o("TFGPT2ForSequenceClassification"),LVr=o(" (OpenAI GPT-2 model)"),yVr=l(),dw=a("li"),I6e=a("strong"),xVr=o("gptj"),$Vr=o(" \u2014 "),mre=a("a"),kVr=o("TFGPTJForSequenceClassification"),SVr=o(" (GPT-J model)"),RVr=l(),cw=a("li"),N6e=a("strong"),PVr=o("layoutlm"),BVr=o(" \u2014 "),gre=a("a"),IVr=o("TFLayoutLMForSequenceClassification"),NVr=o(" (LayoutLM model)"),qVr=l(),fw=a("li"),q6e=a("strong"),jVr=o("layoutlmv3"),DVr=o(" \u2014 "),hre=a("a"),GVr=o("TFLayoutLMv3ForSequenceClassification"),OVr=o(" (LayoutLMv3 model)"),VVr=l(),mw=a("li"),j6e=a("strong"),XVr=o("longformer"),zVr=o(" \u2014 "),ure=a("a"),QVr=o("TFLongformerForSequenceClassification"),WVr=o(" (Longformer model)"),UVr=l(),gw=a("li"),D6e=a("strong"),HVr=o("mobilebert"),JVr=o(" \u2014 "),pre=a("a"),YVr=o("TFMobileBertForSequenceClassification"),KVr=o(" (MobileBERT model)"),ZVr=l(),hw=a("li"),G6e=a("strong"),eXr=o("mpnet"),oXr=o(" \u2014 "),_re=a("a"),rXr=o("TFMPNetForSequenceClassification"),tXr=o(" (MPNet model)"),aXr=l(),uw=a("li"),O6e=a("strong"),nXr=o("openai-gpt"),sXr=o(" \u2014 "),vre=a("a"),lXr=o("TFOpenAIGPTForSequenceClassification"),iXr=o(" (OpenAI GPT model)"),dXr=l(),pw=a("li"),V6e=a("strong"),cXr=o("rembert"),fXr=o(" \u2014 "),bre=a("a"),mXr=o("TFRemBertForSequenceClassification"),gXr=o(" (RemBERT model)"),hXr=l(),_w=a("li"),X6e=a("strong"),uXr=o("roberta"),pXr=o(" \u2014 "),Fre=a("a"),_Xr=o("TFRobertaForSequenceClassification"),vXr=o(" (RoBERTa model)"),bXr=l(),vw=a("li"),z6e=a("strong"),FXr=o("roformer"),TXr=o(" \u2014 "),Tre=a("a"),MXr=o("TFRoFormerForSequenceClassification"),EXr=o(" (RoFormer model)"),CXr=l(),bw=a("li"),Q6e=a("strong"),wXr=o("tapas"),AXr=o(" \u2014 "),Mre=a("a"),LXr=o("TFTapasForSequenceClassification"),yXr=o(" (TAPAS model)"),xXr=l(),Fw=a("li"),W6e=a("strong"),$Xr=o("transfo-xl"),kXr=o(" \u2014 "),Ere=a("a"),SXr=o("TFTransfoXLForSequenceClassification"),RXr=o(" (Transformer-XL model)"),PXr=l(),Tw=a("li"),U6e=a("strong"),BXr=o("xlm"),IXr=o(" \u2014 "),Cre=a("a"),NXr=o("TFXLMForSequenceClassification"),qXr=o(" (XLM model)"),jXr=l(),Mw=a("li"),H6e=a("strong"),DXr=o("xlm-roberta"),GXr=o(" \u2014 "),wre=a("a"),OXr=o("TFXLMRobertaForSequenceClassification"),VXr=o(" (XLM-RoBERTa model)"),XXr=l(),Ew=a("li"),J6e=a("strong"),zXr=o("xlnet"),QXr=o(" \u2014 "),Are=a("a"),WXr=o("TFXLNetForSequenceClassification"),UXr=o(" (XLNet model)"),HXr=l(),F(Cw.$$.fragment),aZe=l(),gf=a("h2"),ww=a("a"),Y6e=a("span"),F(nS.$$.fragment),JXr=l(),K6e=a("span"),YXr=o("TFAutoModelForMultipleChoice"),nZe=l(),hr=a("div"),F(sS.$$.fragment),KXr=l(),hf=a("p"),ZXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lre=a("a"),ezr=o("from_pretrained()"),ozr=o(" class method or the "),yre=a("a"),rzr=o("from_config()"),tzr=o(` class
method.`),azr=l(),lS=a("p"),nzr=o("This class cannot be instantiated directly using "),Z6e=a("code"),szr=o("__init__()"),lzr=o(" (throws an error)."),izr=l(),Kt=a("div"),F(iS.$$.fragment),dzr=l(),e7e=a("p"),czr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fzr=l(),uf=a("p"),mzr=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),gzr=o("not"),hzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=a("a"),uzr=o("from_pretrained()"),pzr=o(" to load the model weights."),_zr=l(),F(Aw.$$.fragment),vzr=l(),Xr=a("div"),F(dS.$$.fragment),bzr=l(),r7e=a("p"),Fzr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tzr=l(),Sn=a("p"),Mzr=o("The model class to instantiate is selected based on the "),t7e=a("code"),Ezr=o("model_type"),Czr=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),wzr=o("pretrained_model_name_or_path"),Azr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),Lzr=o("pretrained_model_name_or_path"),yzr=o(":"),xzr=l(),be=a("ul"),Lw=a("li"),s7e=a("strong"),$zr=o("albert"),kzr=o(" \u2014 "),$re=a("a"),Szr=o("TFAlbertForMultipleChoice"),Rzr=o(" (ALBERT model)"),Pzr=l(),yw=a("li"),l7e=a("strong"),Bzr=o("bert"),Izr=o(" \u2014 "),kre=a("a"),Nzr=o("TFBertForMultipleChoice"),qzr=o(" (BERT model)"),jzr=l(),xw=a("li"),i7e=a("strong"),Dzr=o("camembert"),Gzr=o(" \u2014 "),Sre=a("a"),Ozr=o("TFCamembertForMultipleChoice"),Vzr=o(" (CamemBERT model)"),Xzr=l(),$w=a("li"),d7e=a("strong"),zzr=o("convbert"),Qzr=o(" \u2014 "),Rre=a("a"),Wzr=o("TFConvBertForMultipleChoice"),Uzr=o(" (ConvBERT model)"),Hzr=l(),kw=a("li"),c7e=a("strong"),Jzr=o("distilbert"),Yzr=o(" \u2014 "),Pre=a("a"),Kzr=o("TFDistilBertForMultipleChoice"),Zzr=o(" (DistilBERT model)"),eQr=l(),Sw=a("li"),f7e=a("strong"),oQr=o("electra"),rQr=o(" \u2014 "),Bre=a("a"),tQr=o("TFElectraForMultipleChoice"),aQr=o(" (ELECTRA model)"),nQr=l(),Rw=a("li"),m7e=a("strong"),sQr=o("flaubert"),lQr=o(" \u2014 "),Ire=a("a"),iQr=o("TFFlaubertForMultipleChoice"),dQr=o(" (FlauBERT model)"),cQr=l(),Pw=a("li"),g7e=a("strong"),fQr=o("funnel"),mQr=o(" \u2014 "),Nre=a("a"),gQr=o("TFFunnelForMultipleChoice"),hQr=o(" (Funnel Transformer model)"),uQr=l(),Bw=a("li"),h7e=a("strong"),pQr=o("longformer"),_Qr=o(" \u2014 "),qre=a("a"),vQr=o("TFLongformerForMultipleChoice"),bQr=o(" (Longformer model)"),FQr=l(),Iw=a("li"),u7e=a("strong"),TQr=o("mobilebert"),MQr=o(" \u2014 "),jre=a("a"),EQr=o("TFMobileBertForMultipleChoice"),CQr=o(" (MobileBERT model)"),wQr=l(),Nw=a("li"),p7e=a("strong"),AQr=o("mpnet"),LQr=o(" \u2014 "),Dre=a("a"),yQr=o("TFMPNetForMultipleChoice"),xQr=o(" (MPNet model)"),$Qr=l(),qw=a("li"),_7e=a("strong"),kQr=o("rembert"),SQr=o(" \u2014 "),Gre=a("a"),RQr=o("TFRemBertForMultipleChoice"),PQr=o(" (RemBERT model)"),BQr=l(),jw=a("li"),v7e=a("strong"),IQr=o("roberta"),NQr=o(" \u2014 "),Ore=a("a"),qQr=o("TFRobertaForMultipleChoice"),jQr=o(" (RoBERTa model)"),DQr=l(),Dw=a("li"),b7e=a("strong"),GQr=o("roformer"),OQr=o(" \u2014 "),Vre=a("a"),VQr=o("TFRoFormerForMultipleChoice"),XQr=o(" (RoFormer model)"),zQr=l(),Gw=a("li"),F7e=a("strong"),QQr=o("xlm"),WQr=o(" \u2014 "),Xre=a("a"),UQr=o("TFXLMForMultipleChoice"),HQr=o(" (XLM model)"),JQr=l(),Ow=a("li"),T7e=a("strong"),YQr=o("xlm-roberta"),KQr=o(" \u2014 "),zre=a("a"),ZQr=o("TFXLMRobertaForMultipleChoice"),eWr=o(" (XLM-RoBERTa model)"),oWr=l(),Vw=a("li"),M7e=a("strong"),rWr=o("xlnet"),tWr=o(" \u2014 "),Qre=a("a"),aWr=o("TFXLNetForMultipleChoice"),nWr=o(" (XLNet model)"),sWr=l(),F(Xw.$$.fragment),sZe=l(),pf=a("h2"),zw=a("a"),E7e=a("span"),F(cS.$$.fragment),lWr=l(),C7e=a("span"),iWr=o("TFAutoModelForNextSentencePrediction"),lZe=l(),ur=a("div"),F(fS.$$.fragment),dWr=l(),_f=a("p"),cWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wre=a("a"),fWr=o("from_pretrained()"),mWr=o(" class method or the "),Ure=a("a"),gWr=o("from_config()"),hWr=o(` class
method.`),uWr=l(),mS=a("p"),pWr=o("This class cannot be instantiated directly using "),w7e=a("code"),_Wr=o("__init__()"),vWr=o(" (throws an error)."),bWr=l(),Zt=a("div"),F(gS.$$.fragment),FWr=l(),A7e=a("p"),TWr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),MWr=l(),vf=a("p"),EWr=o(`Note:
Loading a model from its configuration file does `),L7e=a("strong"),CWr=o("not"),wWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hre=a("a"),AWr=o("from_pretrained()"),LWr=o(" to load the model weights."),yWr=l(),F(Qw.$$.fragment),xWr=l(),zr=a("div"),F(hS.$$.fragment),$Wr=l(),y7e=a("p"),kWr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SWr=l(),Rn=a("p"),RWr=o("The model class to instantiate is selected based on the "),x7e=a("code"),PWr=o("model_type"),BWr=o(` property of the config object (either
passed as an argument or loaded from `),$7e=a("code"),IWr=o("pretrained_model_name_or_path"),NWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=a("code"),qWr=o("pretrained_model_name_or_path"),jWr=o(":"),DWr=l(),uS=a("ul"),Ww=a("li"),S7e=a("strong"),GWr=o("bert"),OWr=o(" \u2014 "),Jre=a("a"),VWr=o("TFBertForNextSentencePrediction"),XWr=o(" (BERT model)"),zWr=l(),Uw=a("li"),R7e=a("strong"),QWr=o("mobilebert"),WWr=o(" \u2014 "),Yre=a("a"),UWr=o("TFMobileBertForNextSentencePrediction"),HWr=o(" (MobileBERT model)"),JWr=l(),F(Hw.$$.fragment),iZe=l(),bf=a("h2"),Jw=a("a"),P7e=a("span"),F(pS.$$.fragment),YWr=l(),B7e=a("span"),KWr=o("TFAutoModelForTableQuestionAnswering"),dZe=l(),pr=a("div"),F(_S.$$.fragment),ZWr=l(),Ff=a("p"),eUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kre=a("a"),oUr=o("from_pretrained()"),rUr=o(" class method or the "),Zre=a("a"),tUr=o("from_config()"),aUr=o(` class
method.`),nUr=l(),vS=a("p"),sUr=o("This class cannot be instantiated directly using "),I7e=a("code"),lUr=o("__init__()"),iUr=o(" (throws an error)."),dUr=l(),ea=a("div"),F(bS.$$.fragment),cUr=l(),N7e=a("p"),fUr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),mUr=l(),Tf=a("p"),gUr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),hUr=o("not"),uUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=a("a"),pUr=o("from_pretrained()"),_Ur=o(" to load the model weights."),vUr=l(),F(Yw.$$.fragment),bUr=l(),Qr=a("div"),F(FS.$$.fragment),FUr=l(),j7e=a("p"),TUr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),MUr=l(),Pn=a("p"),EUr=o("The model class to instantiate is selected based on the "),D7e=a("code"),CUr=o("model_type"),wUr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),AUr=o("pretrained_model_name_or_path"),LUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),yUr=o("pretrained_model_name_or_path"),xUr=o(":"),$Ur=l(),V7e=a("ul"),Kw=a("li"),X7e=a("strong"),kUr=o("tapas"),SUr=o(" \u2014 "),ote=a("a"),RUr=o("TFTapasForQuestionAnswering"),PUr=o(" (TAPAS model)"),BUr=l(),F(Zw.$$.fragment),cZe=l(),Mf=a("h2"),eA=a("a"),z7e=a("span"),F(TS.$$.fragment),IUr=l(),Q7e=a("span"),NUr=o("TFAutoModelForDocumentQuestionAnswering"),fZe=l(),_r=a("div"),F(MS.$$.fragment),qUr=l(),Ef=a("p"),jUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rte=a("a"),DUr=o("from_pretrained()"),GUr=o(" class method or the "),tte=a("a"),OUr=o("from_config()"),VUr=o(` class
method.`),XUr=l(),ES=a("p"),zUr=o("This class cannot be instantiated directly using "),W7e=a("code"),QUr=o("__init__()"),WUr=o(" (throws an error)."),UUr=l(),oa=a("div"),F(CS.$$.fragment),HUr=l(),U7e=a("p"),JUr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),YUr=l(),Cf=a("p"),KUr=o(`Note:
Loading a model from its configuration file does `),H7e=a("strong"),ZUr=o("not"),eHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=a("a"),oHr=o("from_pretrained()"),rHr=o(" to load the model weights."),tHr=l(),F(oA.$$.fragment),aHr=l(),Wr=a("div"),F(wS.$$.fragment),nHr=l(),J7e=a("p"),sHr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),lHr=l(),Bn=a("p"),iHr=o("The model class to instantiate is selected based on the "),Y7e=a("code"),dHr=o("model_type"),cHr=o(` property of the config object (either
passed as an argument or loaded from `),K7e=a("code"),fHr=o("pretrained_model_name_or_path"),mHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z7e=a("code"),gHr=o("pretrained_model_name_or_path"),hHr=o(":"),uHr=l(),eLe=a("ul"),rA=a("li"),oLe=a("strong"),pHr=o("layoutlm"),_Hr=o(" \u2014 "),nte=a("a"),vHr=o("TFLayoutLMForQuestionAnswering"),bHr=o(" (LayoutLM model)"),FHr=l(),F(tA.$$.fragment),mZe=l(),wf=a("h2"),aA=a("a"),rLe=a("span"),F(AS.$$.fragment),THr=l(),tLe=a("span"),MHr=o("TFAutoModelForTokenClassification"),gZe=l(),vr=a("div"),F(LS.$$.fragment),EHr=l(),Af=a("p"),CHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ste=a("a"),wHr=o("from_pretrained()"),AHr=o(" class method or the "),lte=a("a"),LHr=o("from_config()"),yHr=o(` class
method.`),xHr=l(),yS=a("p"),$Hr=o("This class cannot be instantiated directly using "),aLe=a("code"),kHr=o("__init__()"),SHr=o(" (throws an error)."),RHr=l(),ra=a("div"),F(xS.$$.fragment),PHr=l(),nLe=a("p"),BHr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),IHr=l(),Lf=a("p"),NHr=o(`Note:
Loading a model from its configuration file does `),sLe=a("strong"),qHr=o("not"),jHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=a("a"),DHr=o("from_pretrained()"),GHr=o(" to load the model weights."),OHr=l(),F(nA.$$.fragment),VHr=l(),Ur=a("div"),F($S.$$.fragment),XHr=l(),lLe=a("p"),zHr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),QHr=l(),In=a("p"),WHr=o("The model class to instantiate is selected based on the "),iLe=a("code"),UHr=o("model_type"),HHr=o(` property of the config object (either
passed as an argument or loaded from `),dLe=a("code"),JHr=o("pretrained_model_name_or_path"),YHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cLe=a("code"),KHr=o("pretrained_model_name_or_path"),ZHr=o(":"),eJr=l(),de=a("ul"),sA=a("li"),fLe=a("strong"),oJr=o("albert"),rJr=o(" \u2014 "),dte=a("a"),tJr=o("TFAlbertForTokenClassification"),aJr=o(" (ALBERT model)"),nJr=l(),lA=a("li"),mLe=a("strong"),sJr=o("bert"),lJr=o(" \u2014 "),cte=a("a"),iJr=o("TFBertForTokenClassification"),dJr=o(" (BERT model)"),cJr=l(),iA=a("li"),gLe=a("strong"),fJr=o("camembert"),mJr=o(" \u2014 "),fte=a("a"),gJr=o("TFCamembertForTokenClassification"),hJr=o(" (CamemBERT model)"),uJr=l(),dA=a("li"),hLe=a("strong"),pJr=o("convbert"),_Jr=o(" \u2014 "),mte=a("a"),vJr=o("TFConvBertForTokenClassification"),bJr=o(" (ConvBERT model)"),FJr=l(),cA=a("li"),uLe=a("strong"),TJr=o("deberta"),MJr=o(" \u2014 "),gte=a("a"),EJr=o("TFDebertaForTokenClassification"),CJr=o(" (DeBERTa model)"),wJr=l(),fA=a("li"),pLe=a("strong"),AJr=o("deberta-v2"),LJr=o(" \u2014 "),hte=a("a"),yJr=o("TFDebertaV2ForTokenClassification"),xJr=o(" (DeBERTa-v2 model)"),$Jr=l(),mA=a("li"),_Le=a("strong"),kJr=o("distilbert"),SJr=o(" \u2014 "),ute=a("a"),RJr=o("TFDistilBertForTokenClassification"),PJr=o(" (DistilBERT model)"),BJr=l(),gA=a("li"),vLe=a("strong"),IJr=o("electra"),NJr=o(" \u2014 "),pte=a("a"),qJr=o("TFElectraForTokenClassification"),jJr=o(" (ELECTRA model)"),DJr=l(),hA=a("li"),bLe=a("strong"),GJr=o("flaubert"),OJr=o(" \u2014 "),_te=a("a"),VJr=o("TFFlaubertForTokenClassification"),XJr=o(" (FlauBERT model)"),zJr=l(),uA=a("li"),FLe=a("strong"),QJr=o("funnel"),WJr=o(" \u2014 "),vte=a("a"),UJr=o("TFFunnelForTokenClassification"),HJr=o(" (Funnel Transformer model)"),JJr=l(),pA=a("li"),TLe=a("strong"),YJr=o("layoutlm"),KJr=o(" \u2014 "),bte=a("a"),ZJr=o("TFLayoutLMForTokenClassification"),eYr=o(" (LayoutLM model)"),oYr=l(),_A=a("li"),MLe=a("strong"),rYr=o("layoutlmv3"),tYr=o(" \u2014 "),Fte=a("a"),aYr=o("TFLayoutLMv3ForTokenClassification"),nYr=o(" (LayoutLMv3 model)"),sYr=l(),vA=a("li"),ELe=a("strong"),lYr=o("longformer"),iYr=o(" \u2014 "),Tte=a("a"),dYr=o("TFLongformerForTokenClassification"),cYr=o(" (Longformer model)"),fYr=l(),bA=a("li"),CLe=a("strong"),mYr=o("mobilebert"),gYr=o(" \u2014 "),Mte=a("a"),hYr=o("TFMobileBertForTokenClassification"),uYr=o(" (MobileBERT model)"),pYr=l(),FA=a("li"),wLe=a("strong"),_Yr=o("mpnet"),vYr=o(" \u2014 "),Ete=a("a"),bYr=o("TFMPNetForTokenClassification"),FYr=o(" (MPNet model)"),TYr=l(),TA=a("li"),ALe=a("strong"),MYr=o("rembert"),EYr=o(" \u2014 "),Cte=a("a"),CYr=o("TFRemBertForTokenClassification"),wYr=o(" (RemBERT model)"),AYr=l(),MA=a("li"),LLe=a("strong"),LYr=o("roberta"),yYr=o(" \u2014 "),wte=a("a"),xYr=o("TFRobertaForTokenClassification"),$Yr=o(" (RoBERTa model)"),kYr=l(),EA=a("li"),yLe=a("strong"),SYr=o("roformer"),RYr=o(" \u2014 "),Ate=a("a"),PYr=o("TFRoFormerForTokenClassification"),BYr=o(" (RoFormer model)"),IYr=l(),CA=a("li"),xLe=a("strong"),NYr=o("xlm"),qYr=o(" \u2014 "),Lte=a("a"),jYr=o("TFXLMForTokenClassification"),DYr=o(" (XLM model)"),GYr=l(),wA=a("li"),$Le=a("strong"),OYr=o("xlm-roberta"),VYr=o(" \u2014 "),yte=a("a"),XYr=o("TFXLMRobertaForTokenClassification"),zYr=o(" (XLM-RoBERTa model)"),QYr=l(),AA=a("li"),kLe=a("strong"),WYr=o("xlnet"),UYr=o(" \u2014 "),xte=a("a"),HYr=o("TFXLNetForTokenClassification"),JYr=o(" (XLNet model)"),YYr=l(),F(LA.$$.fragment),hZe=l(),yf=a("h2"),yA=a("a"),SLe=a("span"),F(kS.$$.fragment),KYr=l(),RLe=a("span"),ZYr=o("TFAutoModelForQuestionAnswering"),uZe=l(),br=a("div"),F(SS.$$.fragment),eKr=l(),xf=a("p"),oKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$te=a("a"),rKr=o("from_pretrained()"),tKr=o(" class method or the "),kte=a("a"),aKr=o("from_config()"),nKr=o(` class
method.`),sKr=l(),RS=a("p"),lKr=o("This class cannot be instantiated directly using "),PLe=a("code"),iKr=o("__init__()"),dKr=o(" (throws an error)."),cKr=l(),ta=a("div"),F(PS.$$.fragment),fKr=l(),BLe=a("p"),mKr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gKr=l(),$f=a("p"),hKr=o(`Note:
Loading a model from its configuration file does `),ILe=a("strong"),uKr=o("not"),pKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ste=a("a"),_Kr=o("from_pretrained()"),vKr=o(" to load the model weights."),bKr=l(),F(xA.$$.fragment),FKr=l(),Hr=a("div"),F(BS.$$.fragment),TKr=l(),NLe=a("p"),MKr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),EKr=l(),Nn=a("p"),CKr=o("The model class to instantiate is selected based on the "),qLe=a("code"),wKr=o("model_type"),AKr=o(` property of the config object (either
passed as an argument or loaded from `),jLe=a("code"),LKr=o("pretrained_model_name_or_path"),yKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DLe=a("code"),xKr=o("pretrained_model_name_or_path"),$Kr=o(":"),kKr=l(),ce=a("ul"),$A=a("li"),GLe=a("strong"),SKr=o("albert"),RKr=o(" \u2014 "),Rte=a("a"),PKr=o("TFAlbertForQuestionAnswering"),BKr=o(" (ALBERT model)"),IKr=l(),kA=a("li"),OLe=a("strong"),NKr=o("bert"),qKr=o(" \u2014 "),Pte=a("a"),jKr=o("TFBertForQuestionAnswering"),DKr=o(" (BERT model)"),GKr=l(),SA=a("li"),VLe=a("strong"),OKr=o("camembert"),VKr=o(" \u2014 "),Bte=a("a"),XKr=o("TFCamembertForQuestionAnswering"),zKr=o(" (CamemBERT model)"),QKr=l(),RA=a("li"),XLe=a("strong"),WKr=o("convbert"),UKr=o(" \u2014 "),Ite=a("a"),HKr=o("TFConvBertForQuestionAnswering"),JKr=o(" (ConvBERT model)"),YKr=l(),PA=a("li"),zLe=a("strong"),KKr=o("deberta"),ZKr=o(" \u2014 "),Nte=a("a"),eZr=o("TFDebertaForQuestionAnswering"),oZr=o(" (DeBERTa model)"),rZr=l(),BA=a("li"),QLe=a("strong"),tZr=o("deberta-v2"),aZr=o(" \u2014 "),qte=a("a"),nZr=o("TFDebertaV2ForQuestionAnswering"),sZr=o(" (DeBERTa-v2 model)"),lZr=l(),IA=a("li"),WLe=a("strong"),iZr=o("distilbert"),dZr=o(" \u2014 "),jte=a("a"),cZr=o("TFDistilBertForQuestionAnswering"),fZr=o(" (DistilBERT model)"),mZr=l(),NA=a("li"),ULe=a("strong"),gZr=o("electra"),hZr=o(" \u2014 "),Dte=a("a"),uZr=o("TFElectraForQuestionAnswering"),pZr=o(" (ELECTRA model)"),_Zr=l(),qA=a("li"),HLe=a("strong"),vZr=o("flaubert"),bZr=o(" \u2014 "),Gte=a("a"),FZr=o("TFFlaubertForQuestionAnsweringSimple"),TZr=o(" (FlauBERT model)"),MZr=l(),jA=a("li"),JLe=a("strong"),EZr=o("funnel"),CZr=o(" \u2014 "),Ote=a("a"),wZr=o("TFFunnelForQuestionAnswering"),AZr=o(" (Funnel Transformer model)"),LZr=l(),DA=a("li"),YLe=a("strong"),yZr=o("gptj"),xZr=o(" \u2014 "),Vte=a("a"),$Zr=o("TFGPTJForQuestionAnswering"),kZr=o(" (GPT-J model)"),SZr=l(),GA=a("li"),KLe=a("strong"),RZr=o("layoutlmv3"),PZr=o(" \u2014 "),Xte=a("a"),BZr=o("TFLayoutLMv3ForQuestionAnswering"),IZr=o(" (LayoutLMv3 model)"),NZr=l(),OA=a("li"),ZLe=a("strong"),qZr=o("longformer"),jZr=o(" \u2014 "),zte=a("a"),DZr=o("TFLongformerForQuestionAnswering"),GZr=o(" (Longformer model)"),OZr=l(),VA=a("li"),eye=a("strong"),VZr=o("mobilebert"),XZr=o(" \u2014 "),Qte=a("a"),zZr=o("TFMobileBertForQuestionAnswering"),QZr=o(" (MobileBERT model)"),WZr=l(),XA=a("li"),oye=a("strong"),UZr=o("mpnet"),HZr=o(" \u2014 "),Wte=a("a"),JZr=o("TFMPNetForQuestionAnswering"),YZr=o(" (MPNet model)"),KZr=l(),zA=a("li"),rye=a("strong"),ZZr=o("rembert"),eet=o(" \u2014 "),Ute=a("a"),oet=o("TFRemBertForQuestionAnswering"),ret=o(" (RemBERT model)"),tet=l(),QA=a("li"),tye=a("strong"),aet=o("roberta"),net=o(" \u2014 "),Hte=a("a"),set=o("TFRobertaForQuestionAnswering"),iet=o(" (RoBERTa model)"),det=l(),WA=a("li"),aye=a("strong"),cet=o("roformer"),fet=o(" \u2014 "),Jte=a("a"),met=o("TFRoFormerForQuestionAnswering"),get=o(" (RoFormer model)"),het=l(),UA=a("li"),nye=a("strong"),uet=o("xlm"),pet=o(" \u2014 "),Yte=a("a"),_et=o("TFXLMForQuestionAnsweringSimple"),vet=o(" (XLM model)"),bet=l(),HA=a("li"),sye=a("strong"),Fet=o("xlm-roberta"),Tet=o(" \u2014 "),Kte=a("a"),Met=o("TFXLMRobertaForQuestionAnswering"),Eet=o(" (XLM-RoBERTa model)"),Cet=l(),JA=a("li"),lye=a("strong"),wet=o("xlnet"),Aet=o(" \u2014 "),Zte=a("a"),Let=o("TFXLNetForQuestionAnsweringSimple"),yet=o(" (XLNet model)"),xet=l(),F(YA.$$.fragment),pZe=l(),kf=a("h2"),KA=a("a"),iye=a("span"),F(IS.$$.fragment),$et=l(),dye=a("span"),ket=o("TFAutoModelForVision2Seq"),_Ze=l(),Fr=a("div"),F(NS.$$.fragment),Set=l(),Sf=a("p"),Ret=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=a("a"),Pet=o("from_pretrained()"),Bet=o(" class method or the "),oae=a("a"),Iet=o("from_config()"),Net=o(` class
method.`),qet=l(),qS=a("p"),jet=o("This class cannot be instantiated directly using "),cye=a("code"),Det=o("__init__()"),Get=o(" (throws an error)."),Oet=l(),aa=a("div"),F(jS.$$.fragment),Vet=l(),fye=a("p"),Xet=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zet=l(),Rf=a("p"),Qet=o(`Note:
Loading a model from its configuration file does `),mye=a("strong"),Wet=o("not"),Uet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=a("a"),Het=o("from_pretrained()"),Jet=o(" to load the model weights."),Yet=l(),F(ZA.$$.fragment),Ket=l(),Jr=a("div"),F(DS.$$.fragment),Zet=l(),gye=a("p"),eot=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oot=l(),qn=a("p"),rot=o("The model class to instantiate is selected based on the "),hye=a("code"),tot=o("model_type"),aot=o(` property of the config object (either
passed as an argument or loaded from `),uye=a("code"),not=o("pretrained_model_name_or_path"),sot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pye=a("code"),lot=o("pretrained_model_name_or_path"),iot=o(":"),dot=l(),_ye=a("ul"),e6=a("li"),vye=a("strong"),cot=o("vision-encoder-decoder"),fot=o(" \u2014 "),tae=a("a"),mot=o("TFVisionEncoderDecoderModel"),got=o(" (Vision Encoder decoder model)"),hot=l(),F(o6.$$.fragment),vZe=l(),Pf=a("h2"),r6=a("a"),bye=a("span"),F(GS.$$.fragment),uot=l(),Fye=a("span"),pot=o("TFAutoModelForSpeechSeq2Seq"),bZe=l(),Tr=a("div"),F(OS.$$.fragment),_ot=l(),Bf=a("p"),vot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),aae=a("a"),bot=o("from_pretrained()"),Fot=o(" class method or the "),nae=a("a"),Tot=o("from_config()"),Mot=o(` class
method.`),Eot=l(),VS=a("p"),Cot=o("This class cannot be instantiated directly using "),Tye=a("code"),wot=o("__init__()"),Aot=o(" (throws an error)."),Lot=l(),na=a("div"),F(XS.$$.fragment),yot=l(),Mye=a("p"),xot=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$ot=l(),If=a("p"),kot=o(`Note:
Loading a model from its configuration file does `),Eye=a("strong"),Sot=o("not"),Rot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=a("a"),Pot=o("from_pretrained()"),Bot=o(" to load the model weights."),Iot=l(),F(t6.$$.fragment),Not=l(),Yr=a("div"),F(zS.$$.fragment),qot=l(),Cye=a("p"),jot=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dot=l(),jn=a("p"),Got=o("The model class to instantiate is selected based on the "),wye=a("code"),Oot=o("model_type"),Vot=o(` property of the config object (either
passed as an argument or loaded from `),Aye=a("code"),Xot=o("pretrained_model_name_or_path"),zot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lye=a("code"),Qot=o("pretrained_model_name_or_path"),Wot=o(":"),Uot=l(),yye=a("ul"),a6=a("li"),xye=a("strong"),Hot=o("speech_to_text"),Jot=o(" \u2014 "),lae=a("a"),Yot=o("TFSpeech2TextForConditionalGeneration"),Kot=o(" (Speech2Text model)"),Zot=l(),F(n6.$$.fragment),FZe=l(),Nf=a("h2"),s6=a("a"),$ye=a("span"),F(QS.$$.fragment),ert=l(),kye=a("span"),ort=o("FlaxAutoModel"),TZe=l(),Mr=a("div"),F(WS.$$.fragment),rrt=l(),qf=a("p"),trt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),iae=a("a"),art=o("from_pretrained()"),nrt=o(" class method or the "),dae=a("a"),srt=o("from_config()"),lrt=o(` class
method.`),irt=l(),US=a("p"),drt=o("This class cannot be instantiated directly using "),Sye=a("code"),crt=o("__init__()"),frt=o(" (throws an error)."),mrt=l(),sa=a("div"),F(HS.$$.fragment),grt=l(),Rye=a("p"),hrt=o("Instantiates one of the base model classes of the library from a configuration."),urt=l(),jf=a("p"),prt=o(`Note:
Loading a model from its configuration file does `),Pye=a("strong"),_rt=o("not"),vrt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=a("a"),brt=o("from_pretrained()"),Frt=o(" to load the model weights."),Trt=l(),F(l6.$$.fragment),Mrt=l(),Kr=a("div"),F(JS.$$.fragment),Ert=l(),Bye=a("p"),Crt=o("Instantiate one of the base model classes of the library from a pretrained model."),wrt=l(),Dn=a("p"),Art=o("The model class to instantiate is selected based on the "),Iye=a("code"),Lrt=o("model_type"),yrt=o(` property of the config object (either
passed as an argument or loaded from `),Nye=a("code"),xrt=o("pretrained_model_name_or_path"),$rt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=a("code"),krt=o("pretrained_model_name_or_path"),Srt=o(":"),Rrt=l(),te=a("ul"),i6=a("li"),jye=a("strong"),Prt=o("albert"),Brt=o(" \u2014 "),fae=a("a"),Irt=o("FlaxAlbertModel"),Nrt=o(" (ALBERT model)"),qrt=l(),d6=a("li"),Dye=a("strong"),jrt=o("bart"),Drt=o(" \u2014 "),mae=a("a"),Grt=o("FlaxBartModel"),Ort=o(" (BART model)"),Vrt=l(),c6=a("li"),Gye=a("strong"),Xrt=o("beit"),zrt=o(" \u2014 "),gae=a("a"),Qrt=o("FlaxBeitModel"),Wrt=o(" (BEiT model)"),Urt=l(),f6=a("li"),Oye=a("strong"),Hrt=o("bert"),Jrt=o(" \u2014 "),hae=a("a"),Yrt=o("FlaxBertModel"),Krt=o(" (BERT model)"),Zrt=l(),m6=a("li"),Vye=a("strong"),ett=o("big_bird"),ott=o(" \u2014 "),uae=a("a"),rtt=o("FlaxBigBirdModel"),ttt=o(" (BigBird model)"),att=l(),g6=a("li"),Xye=a("strong"),ntt=o("blenderbot"),stt=o(" \u2014 "),pae=a("a"),ltt=o("FlaxBlenderbotModel"),itt=o(" (Blenderbot model)"),dtt=l(),h6=a("li"),zye=a("strong"),ctt=o("blenderbot-small"),ftt=o(" \u2014 "),_ae=a("a"),mtt=o("FlaxBlenderbotSmallModel"),gtt=o(" (BlenderbotSmall model)"),htt=l(),u6=a("li"),Qye=a("strong"),utt=o("clip"),ptt=o(" \u2014 "),vae=a("a"),_tt=o("FlaxCLIPModel"),vtt=o(" (CLIP model)"),btt=l(),p6=a("li"),Wye=a("strong"),Ftt=o("distilbert"),Ttt=o(" \u2014 "),bae=a("a"),Mtt=o("FlaxDistilBertModel"),Ett=o(" (DistilBERT model)"),Ctt=l(),_6=a("li"),Uye=a("strong"),wtt=o("electra"),Att=o(" \u2014 "),Fae=a("a"),Ltt=o("FlaxElectraModel"),ytt=o(" (ELECTRA model)"),xtt=l(),v6=a("li"),Hye=a("strong"),$tt=o("gpt2"),ktt=o(" \u2014 "),Tae=a("a"),Stt=o("FlaxGPT2Model"),Rtt=o(" (OpenAI GPT-2 model)"),Ptt=l(),b6=a("li"),Jye=a("strong"),Btt=o("gpt_neo"),Itt=o(" \u2014 "),Mae=a("a"),Ntt=o("FlaxGPTNeoModel"),qtt=o(" (GPT Neo model)"),jtt=l(),F6=a("li"),Yye=a("strong"),Dtt=o("gptj"),Gtt=o(" \u2014 "),Eae=a("a"),Ott=o("FlaxGPTJModel"),Vtt=o(" (GPT-J model)"),Xtt=l(),T6=a("li"),Kye=a("strong"),ztt=o("longt5"),Qtt=o(" \u2014 "),Cae=a("a"),Wtt=o("FlaxLongT5Model"),Utt=o(" (LongT5 model)"),Htt=l(),M6=a("li"),Zye=a("strong"),Jtt=o("marian"),Ytt=o(" \u2014 "),wae=a("a"),Ktt=o("FlaxMarianModel"),Ztt=o(" (Marian model)"),eat=l(),E6=a("li"),e8e=a("strong"),oat=o("mbart"),rat=o(" \u2014 "),Aae=a("a"),tat=o("FlaxMBartModel"),aat=o(" (mBART model)"),nat=l(),C6=a("li"),o8e=a("strong"),sat=o("mt5"),lat=o(" \u2014 "),Lae=a("a"),iat=o("FlaxMT5Model"),dat=o(" (MT5 model)"),cat=l(),w6=a("li"),r8e=a("strong"),fat=o("opt"),mat=o(" \u2014 "),yae=a("a"),gat=o("FlaxOPTModel"),hat=o(" (OPT model)"),uat=l(),A6=a("li"),t8e=a("strong"),pat=o("pegasus"),_at=o(" \u2014 "),xae=a("a"),vat=o("FlaxPegasusModel"),bat=o(" (Pegasus model)"),Fat=l(),L6=a("li"),a8e=a("strong"),Tat=o("roberta"),Mat=o(" \u2014 "),$ae=a("a"),Eat=o("FlaxRobertaModel"),Cat=o(" (RoBERTa model)"),wat=l(),y6=a("li"),n8e=a("strong"),Aat=o("roformer"),Lat=o(" \u2014 "),kae=a("a"),yat=o("FlaxRoFormerModel"),xat=o(" (RoFormer model)"),$at=l(),x6=a("li"),s8e=a("strong"),kat=o("t5"),Sat=o(" \u2014 "),Sae=a("a"),Rat=o("FlaxT5Model"),Pat=o(" (T5 model)"),Bat=l(),$6=a("li"),l8e=a("strong"),Iat=o("vision-text-dual-encoder"),Nat=o(" \u2014 "),Rae=a("a"),qat=o("FlaxVisionTextDualEncoderModel"),jat=o(" (VisionTextDualEncoder model)"),Dat=l(),k6=a("li"),i8e=a("strong"),Gat=o("vit"),Oat=o(" \u2014 "),Pae=a("a"),Vat=o("FlaxViTModel"),Xat=o(" (ViT model)"),zat=l(),S6=a("li"),d8e=a("strong"),Qat=o("wav2vec2"),Wat=o(" \u2014 "),Bae=a("a"),Uat=o("FlaxWav2Vec2Model"),Hat=o(" (Wav2Vec2 model)"),Jat=l(),R6=a("li"),c8e=a("strong"),Yat=o("xglm"),Kat=o(" \u2014 "),Iae=a("a"),Zat=o("FlaxXGLMModel"),ent=o(" (XGLM model)"),ont=l(),P6=a("li"),f8e=a("strong"),rnt=o("xlm-roberta"),tnt=o(" \u2014 "),Nae=a("a"),ant=o("FlaxXLMRobertaModel"),nnt=o(" (XLM-RoBERTa model)"),snt=l(),F(B6.$$.fragment),MZe=l(),Df=a("h2"),I6=a("a"),m8e=a("span"),F(YS.$$.fragment),lnt=l(),g8e=a("span"),int=o("FlaxAutoModelForCausalLM"),EZe=l(),Er=a("div"),F(KS.$$.fragment),dnt=l(),Gf=a("p"),cnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qae=a("a"),fnt=o("from_pretrained()"),mnt=o(" class method or the "),jae=a("a"),gnt=o("from_config()"),hnt=o(` class
method.`),unt=l(),ZS=a("p"),pnt=o("This class cannot be instantiated directly using "),h8e=a("code"),_nt=o("__init__()"),vnt=o(" (throws an error)."),bnt=l(),la=a("div"),F(eR.$$.fragment),Fnt=l(),u8e=a("p"),Tnt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Mnt=l(),Of=a("p"),Ent=o(`Note:
Loading a model from its configuration file does `),p8e=a("strong"),Cnt=o("not"),wnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=a("a"),Ant=o("from_pretrained()"),Lnt=o(" to load the model weights."),ynt=l(),F(N6.$$.fragment),xnt=l(),Zr=a("div"),F(oR.$$.fragment),$nt=l(),_8e=a("p"),knt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Snt=l(),Gn=a("p"),Rnt=o("The model class to instantiate is selected based on the "),v8e=a("code"),Pnt=o("model_type"),Bnt=o(` property of the config object (either
passed as an argument or loaded from `),b8e=a("code"),Int=o("pretrained_model_name_or_path"),Nnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=a("code"),qnt=o("pretrained_model_name_or_path"),jnt=o(":"),Dnt=l(),xe=a("ul"),q6=a("li"),T8e=a("strong"),Gnt=o("bart"),Ont=o(" \u2014 "),Gae=a("a"),Vnt=o("FlaxBartForCausalLM"),Xnt=o(" (BART model)"),znt=l(),j6=a("li"),M8e=a("strong"),Qnt=o("bert"),Wnt=o(" \u2014 "),Oae=a("a"),Unt=o("FlaxBertForCausalLM"),Hnt=o(" (BERT model)"),Jnt=l(),D6=a("li"),E8e=a("strong"),Ynt=o("big_bird"),Knt=o(" \u2014 "),Vae=a("a"),Znt=o("FlaxBigBirdForCausalLM"),est=o(" (BigBird model)"),ost=l(),G6=a("li"),C8e=a("strong"),rst=o("electra"),tst=o(" \u2014 "),Xae=a("a"),ast=o("FlaxElectraForCausalLM"),nst=o(" (ELECTRA model)"),sst=l(),O6=a("li"),w8e=a("strong"),lst=o("gpt2"),ist=o(" \u2014 "),zae=a("a"),dst=o("FlaxGPT2LMHeadModel"),cst=o(" (OpenAI GPT-2 model)"),fst=l(),V6=a("li"),A8e=a("strong"),mst=o("gpt_neo"),gst=o(" \u2014 "),Qae=a("a"),hst=o("FlaxGPTNeoForCausalLM"),ust=o(" (GPT Neo model)"),pst=l(),X6=a("li"),L8e=a("strong"),_st=o("gptj"),vst=o(" \u2014 "),Wae=a("a"),bst=o("FlaxGPTJForCausalLM"),Fst=o(" (GPT-J model)"),Tst=l(),z6=a("li"),y8e=a("strong"),Mst=o("opt"),Est=o(" \u2014 "),Uae=a("a"),Cst=o("FlaxOPTForCausalLM"),wst=o(" (OPT model)"),Ast=l(),Q6=a("li"),x8e=a("strong"),Lst=o("roberta"),yst=o(" \u2014 "),Hae=a("a"),xst=o("FlaxRobertaForCausalLM"),$st=o(" (RoBERTa model)"),kst=l(),W6=a("li"),$8e=a("strong"),Sst=o("xglm"),Rst=o(" \u2014 "),Jae=a("a"),Pst=o("FlaxXGLMForCausalLM"),Bst=o(" (XGLM model)"),Ist=l(),F(U6.$$.fragment),CZe=l(),Vf=a("h2"),H6=a("a"),k8e=a("span"),F(rR.$$.fragment),Nst=l(),S8e=a("span"),qst=o("FlaxAutoModelForPreTraining"),wZe=l(),Cr=a("div"),F(tR.$$.fragment),jst=l(),Xf=a("p"),Dst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yae=a("a"),Gst=o("from_pretrained()"),Ost=o(" class method or the "),Kae=a("a"),Vst=o("from_config()"),Xst=o(` class
method.`),zst=l(),aR=a("p"),Qst=o("This class cannot be instantiated directly using "),R8e=a("code"),Wst=o("__init__()"),Ust=o(" (throws an error)."),Hst=l(),ia=a("div"),F(nR.$$.fragment),Jst=l(),P8e=a("p"),Yst=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Kst=l(),zf=a("p"),Zst=o(`Note:
Loading a model from its configuration file does `),B8e=a("strong"),elt=o("not"),olt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=a("a"),rlt=o("from_pretrained()"),tlt=o(" to load the model weights."),alt=l(),F(J6.$$.fragment),nlt=l(),et=a("div"),F(sR.$$.fragment),slt=l(),I8e=a("p"),llt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ilt=l(),On=a("p"),dlt=o("The model class to instantiate is selected based on the "),N8e=a("code"),clt=o("model_type"),flt=o(` property of the config object (either
passed as an argument or loaded from `),q8e=a("code"),mlt=o("pretrained_model_name_or_path"),glt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=a("code"),hlt=o("pretrained_model_name_or_path"),ult=o(":"),plt=l(),Ee=a("ul"),Y6=a("li"),D8e=a("strong"),_lt=o("albert"),vlt=o(" \u2014 "),ene=a("a"),blt=o("FlaxAlbertForPreTraining"),Flt=o(" (ALBERT model)"),Tlt=l(),K6=a("li"),G8e=a("strong"),Mlt=o("bart"),Elt=o(" \u2014 "),one=a("a"),Clt=o("FlaxBartForConditionalGeneration"),wlt=o(" (BART model)"),Alt=l(),Z6=a("li"),O8e=a("strong"),Llt=o("bert"),ylt=o(" \u2014 "),rne=a("a"),xlt=o("FlaxBertForPreTraining"),$lt=o(" (BERT model)"),klt=l(),e7=a("li"),V8e=a("strong"),Slt=o("big_bird"),Rlt=o(" \u2014 "),tne=a("a"),Plt=o("FlaxBigBirdForPreTraining"),Blt=o(" (BigBird model)"),Ilt=l(),o7=a("li"),X8e=a("strong"),Nlt=o("electra"),qlt=o(" \u2014 "),ane=a("a"),jlt=o("FlaxElectraForPreTraining"),Dlt=o(" (ELECTRA model)"),Glt=l(),r7=a("li"),z8e=a("strong"),Olt=o("longt5"),Vlt=o(" \u2014 "),nne=a("a"),Xlt=o("FlaxLongT5ForConditionalGeneration"),zlt=o(" (LongT5 model)"),Qlt=l(),t7=a("li"),Q8e=a("strong"),Wlt=o("mbart"),Ult=o(" \u2014 "),sne=a("a"),Hlt=o("FlaxMBartForConditionalGeneration"),Jlt=o(" (mBART model)"),Ylt=l(),a7=a("li"),W8e=a("strong"),Klt=o("mt5"),Zlt=o(" \u2014 "),lne=a("a"),eit=o("FlaxMT5ForConditionalGeneration"),oit=o(" (MT5 model)"),rit=l(),n7=a("li"),U8e=a("strong"),tit=o("roberta"),ait=o(" \u2014 "),ine=a("a"),nit=o("FlaxRobertaForMaskedLM"),sit=o(" (RoBERTa model)"),lit=l(),s7=a("li"),H8e=a("strong"),iit=o("roformer"),dit=o(" \u2014 "),dne=a("a"),cit=o("FlaxRoFormerForMaskedLM"),fit=o(" (RoFormer model)"),mit=l(),l7=a("li"),J8e=a("strong"),git=o("t5"),hit=o(" \u2014 "),cne=a("a"),uit=o("FlaxT5ForConditionalGeneration"),pit=o(" (T5 model)"),_it=l(),i7=a("li"),Y8e=a("strong"),vit=o("wav2vec2"),bit=o(" \u2014 "),fne=a("a"),Fit=o("FlaxWav2Vec2ForPreTraining"),Tit=o(" (Wav2Vec2 model)"),Mit=l(),d7=a("li"),K8e=a("strong"),Eit=o("xlm-roberta"),Cit=o(" \u2014 "),mne=a("a"),wit=o("FlaxXLMRobertaForMaskedLM"),Ait=o(" (XLM-RoBERTa model)"),Lit=l(),F(c7.$$.fragment),AZe=l(),Qf=a("h2"),f7=a("a"),Z8e=a("span"),F(lR.$$.fragment),yit=l(),e9e=a("span"),xit=o("FlaxAutoModelForMaskedLM"),LZe=l(),wr=a("div"),F(iR.$$.fragment),$it=l(),Wf=a("p"),kit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gne=a("a"),Sit=o("from_pretrained()"),Rit=o(" class method or the "),hne=a("a"),Pit=o("from_config()"),Bit=o(` class
method.`),Iit=l(),dR=a("p"),Nit=o("This class cannot be instantiated directly using "),o9e=a("code"),qit=o("__init__()"),jit=o(" (throws an error)."),Dit=l(),da=a("div"),F(cR.$$.fragment),Git=l(),r9e=a("p"),Oit=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Vit=l(),Uf=a("p"),Xit=o(`Note:
Loading a model from its configuration file does `),t9e=a("strong"),zit=o("not"),Qit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),une=a("a"),Wit=o("from_pretrained()"),Uit=o(" to load the model weights."),Hit=l(),F(m7.$$.fragment),Jit=l(),ot=a("div"),F(fR.$$.fragment),Yit=l(),a9e=a("p"),Kit=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Zit=l(),Vn=a("p"),edt=o("The model class to instantiate is selected based on the "),n9e=a("code"),odt=o("model_type"),rdt=o(` property of the config object (either
passed as an argument or loaded from `),s9e=a("code"),tdt=o("pretrained_model_name_or_path"),adt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=a("code"),ndt=o("pretrained_model_name_or_path"),sdt=o(":"),ldt=l(),$e=a("ul"),g7=a("li"),i9e=a("strong"),idt=o("albert"),ddt=o(" \u2014 "),pne=a("a"),cdt=o("FlaxAlbertForMaskedLM"),fdt=o(" (ALBERT model)"),mdt=l(),h7=a("li"),d9e=a("strong"),gdt=o("bart"),hdt=o(" \u2014 "),_ne=a("a"),udt=o("FlaxBartForConditionalGeneration"),pdt=o(" (BART model)"),_dt=l(),u7=a("li"),c9e=a("strong"),vdt=o("bert"),bdt=o(" \u2014 "),vne=a("a"),Fdt=o("FlaxBertForMaskedLM"),Tdt=o(" (BERT model)"),Mdt=l(),p7=a("li"),f9e=a("strong"),Edt=o("big_bird"),Cdt=o(" \u2014 "),bne=a("a"),wdt=o("FlaxBigBirdForMaskedLM"),Adt=o(" (BigBird model)"),Ldt=l(),_7=a("li"),m9e=a("strong"),ydt=o("distilbert"),xdt=o(" \u2014 "),Fne=a("a"),$dt=o("FlaxDistilBertForMaskedLM"),kdt=o(" (DistilBERT model)"),Sdt=l(),v7=a("li"),g9e=a("strong"),Rdt=o("electra"),Pdt=o(" \u2014 "),Tne=a("a"),Bdt=o("FlaxElectraForMaskedLM"),Idt=o(" (ELECTRA model)"),Ndt=l(),b7=a("li"),h9e=a("strong"),qdt=o("mbart"),jdt=o(" \u2014 "),Mne=a("a"),Ddt=o("FlaxMBartForConditionalGeneration"),Gdt=o(" (mBART model)"),Odt=l(),F7=a("li"),u9e=a("strong"),Vdt=o("roberta"),Xdt=o(" \u2014 "),Ene=a("a"),zdt=o("FlaxRobertaForMaskedLM"),Qdt=o(" (RoBERTa model)"),Wdt=l(),T7=a("li"),p9e=a("strong"),Udt=o("roformer"),Hdt=o(" \u2014 "),Cne=a("a"),Jdt=o("FlaxRoFormerForMaskedLM"),Ydt=o(" (RoFormer model)"),Kdt=l(),M7=a("li"),_9e=a("strong"),Zdt=o("xlm-roberta"),ect=o(" \u2014 "),wne=a("a"),oct=o("FlaxXLMRobertaForMaskedLM"),rct=o(" (XLM-RoBERTa model)"),tct=l(),F(E7.$$.fragment),yZe=l(),Hf=a("h2"),C7=a("a"),v9e=a("span"),F(mR.$$.fragment),act=l(),b9e=a("span"),nct=o("FlaxAutoModelForSeq2SeqLM"),xZe=l(),Ar=a("div"),F(gR.$$.fragment),sct=l(),Jf=a("p"),lct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ane=a("a"),ict=o("from_pretrained()"),dct=o(" class method or the "),Lne=a("a"),cct=o("from_config()"),fct=o(` class
method.`),mct=l(),hR=a("p"),gct=o("This class cannot be instantiated directly using "),F9e=a("code"),hct=o("__init__()"),uct=o(" (throws an error)."),pct=l(),ca=a("div"),F(uR.$$.fragment),_ct=l(),T9e=a("p"),vct=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bct=l(),Yf=a("p"),Fct=o(`Note:
Loading a model from its configuration file does `),M9e=a("strong"),Tct=o("not"),Mct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=a("a"),Ect=o("from_pretrained()"),Cct=o(" to load the model weights."),wct=l(),F(w7.$$.fragment),Act=l(),rt=a("div"),F(pR.$$.fragment),Lct=l(),E9e=a("p"),yct=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xct=l(),Xn=a("p"),$ct=o("The model class to instantiate is selected based on the "),C9e=a("code"),kct=o("model_type"),Sct=o(` property of the config object (either
passed as an argument or loaded from `),w9e=a("code"),Rct=o("pretrained_model_name_or_path"),Pct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A9e=a("code"),Bct=o("pretrained_model_name_or_path"),Ict=o(":"),Nct=l(),ke=a("ul"),A7=a("li"),L9e=a("strong"),qct=o("bart"),jct=o(" \u2014 "),xne=a("a"),Dct=o("FlaxBartForConditionalGeneration"),Gct=o(" (BART model)"),Oct=l(),L7=a("li"),y9e=a("strong"),Vct=o("blenderbot"),Xct=o(" \u2014 "),$ne=a("a"),zct=o("FlaxBlenderbotForConditionalGeneration"),Qct=o(" (Blenderbot model)"),Wct=l(),y7=a("li"),x9e=a("strong"),Uct=o("blenderbot-small"),Hct=o(" \u2014 "),kne=a("a"),Jct=o("FlaxBlenderbotSmallForConditionalGeneration"),Yct=o(" (BlenderbotSmall model)"),Kct=l(),x7=a("li"),$9e=a("strong"),Zct=o("encoder-decoder"),eft=o(" \u2014 "),Sne=a("a"),oft=o("FlaxEncoderDecoderModel"),rft=o(" (Encoder decoder model)"),tft=l(),$7=a("li"),k9e=a("strong"),aft=o("longt5"),nft=o(" \u2014 "),Rne=a("a"),sft=o("FlaxLongT5ForConditionalGeneration"),lft=o(" (LongT5 model)"),ift=l(),k7=a("li"),S9e=a("strong"),dft=o("marian"),cft=o(" \u2014 "),Pne=a("a"),fft=o("FlaxMarianMTModel"),mft=o(" (Marian model)"),gft=l(),S7=a("li"),R9e=a("strong"),hft=o("mbart"),uft=o(" \u2014 "),Bne=a("a"),pft=o("FlaxMBartForConditionalGeneration"),_ft=o(" (mBART model)"),vft=l(),R7=a("li"),P9e=a("strong"),bft=o("mt5"),Fft=o(" \u2014 "),Ine=a("a"),Tft=o("FlaxMT5ForConditionalGeneration"),Mft=o(" (MT5 model)"),Eft=l(),P7=a("li"),B9e=a("strong"),Cft=o("pegasus"),wft=o(" \u2014 "),Nne=a("a"),Aft=o("FlaxPegasusForConditionalGeneration"),Lft=o(" (Pegasus model)"),yft=l(),B7=a("li"),I9e=a("strong"),xft=o("t5"),$ft=o(" \u2014 "),qne=a("a"),kft=o("FlaxT5ForConditionalGeneration"),Sft=o(" (T5 model)"),Rft=l(),F(I7.$$.fragment),$Ze=l(),Kf=a("h2"),N7=a("a"),N9e=a("span"),F(_R.$$.fragment),Pft=l(),q9e=a("span"),Bft=o("FlaxAutoModelForSequenceClassification"),kZe=l(),Lr=a("div"),F(vR.$$.fragment),Ift=l(),Zf=a("p"),Nft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),jne=a("a"),qft=o("from_pretrained()"),jft=o(" class method or the "),Dne=a("a"),Dft=o("from_config()"),Gft=o(` class
method.`),Oft=l(),bR=a("p"),Vft=o("This class cannot be instantiated directly using "),j9e=a("code"),Xft=o("__init__()"),zft=o(" (throws an error)."),Qft=l(),fa=a("div"),F(FR.$$.fragment),Wft=l(),D9e=a("p"),Uft=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hft=l(),em=a("p"),Jft=o(`Note:
Loading a model from its configuration file does `),G9e=a("strong"),Yft=o("not"),Kft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=a("a"),Zft=o("from_pretrained()"),emt=o(" to load the model weights."),omt=l(),F(q7.$$.fragment),rmt=l(),tt=a("div"),F(TR.$$.fragment),tmt=l(),O9e=a("p"),amt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nmt=l(),zn=a("p"),smt=o("The model class to instantiate is selected based on the "),V9e=a("code"),lmt=o("model_type"),imt=o(` property of the config object (either
passed as an argument or loaded from `),X9e=a("code"),dmt=o("pretrained_model_name_or_path"),cmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=a("code"),fmt=o("pretrained_model_name_or_path"),mmt=o(":"),gmt=l(),Se=a("ul"),j7=a("li"),Q9e=a("strong"),hmt=o("albert"),umt=o(" \u2014 "),One=a("a"),pmt=o("FlaxAlbertForSequenceClassification"),_mt=o(" (ALBERT model)"),vmt=l(),D7=a("li"),W9e=a("strong"),bmt=o("bart"),Fmt=o(" \u2014 "),Vne=a("a"),Tmt=o("FlaxBartForSequenceClassification"),Mmt=o(" (BART model)"),Emt=l(),G7=a("li"),U9e=a("strong"),Cmt=o("bert"),wmt=o(" \u2014 "),Xne=a("a"),Amt=o("FlaxBertForSequenceClassification"),Lmt=o(" (BERT model)"),ymt=l(),O7=a("li"),H9e=a("strong"),xmt=o("big_bird"),$mt=o(" \u2014 "),zne=a("a"),kmt=o("FlaxBigBirdForSequenceClassification"),Smt=o(" (BigBird model)"),Rmt=l(),V7=a("li"),J9e=a("strong"),Pmt=o("distilbert"),Bmt=o(" \u2014 "),Qne=a("a"),Imt=o("FlaxDistilBertForSequenceClassification"),Nmt=o(" (DistilBERT model)"),qmt=l(),X7=a("li"),Y9e=a("strong"),jmt=o("electra"),Dmt=o(" \u2014 "),Wne=a("a"),Gmt=o("FlaxElectraForSequenceClassification"),Omt=o(" (ELECTRA model)"),Vmt=l(),z7=a("li"),K9e=a("strong"),Xmt=o("mbart"),zmt=o(" \u2014 "),Une=a("a"),Qmt=o("FlaxMBartForSequenceClassification"),Wmt=o(" (mBART model)"),Umt=l(),Q7=a("li"),Z9e=a("strong"),Hmt=o("roberta"),Jmt=o(" \u2014 "),Hne=a("a"),Ymt=o("FlaxRobertaForSequenceClassification"),Kmt=o(" (RoBERTa model)"),Zmt=l(),W7=a("li"),exe=a("strong"),egt=o("roformer"),ogt=o(" \u2014 "),Jne=a("a"),rgt=o("FlaxRoFormerForSequenceClassification"),tgt=o(" (RoFormer model)"),agt=l(),U7=a("li"),oxe=a("strong"),ngt=o("xlm-roberta"),sgt=o(" \u2014 "),Yne=a("a"),lgt=o("FlaxXLMRobertaForSequenceClassification"),igt=o(" (XLM-RoBERTa model)"),dgt=l(),F(H7.$$.fragment),SZe=l(),om=a("h2"),J7=a("a"),rxe=a("span"),F(MR.$$.fragment),cgt=l(),txe=a("span"),fgt=o("FlaxAutoModelForQuestionAnswering"),RZe=l(),yr=a("div"),F(ER.$$.fragment),mgt=l(),rm=a("p"),ggt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kne=a("a"),hgt=o("from_pretrained()"),ugt=o(" class method or the "),Zne=a("a"),pgt=o("from_config()"),_gt=o(` class
method.`),vgt=l(),CR=a("p"),bgt=o("This class cannot be instantiated directly using "),axe=a("code"),Fgt=o("__init__()"),Tgt=o(" (throws an error)."),Mgt=l(),ma=a("div"),F(wR.$$.fragment),Egt=l(),nxe=a("p"),Cgt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),wgt=l(),tm=a("p"),Agt=o(`Note:
Loading a model from its configuration file does `),sxe=a("strong"),Lgt=o("not"),ygt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ese=a("a"),xgt=o("from_pretrained()"),$gt=o(" to load the model weights."),kgt=l(),F(Y7.$$.fragment),Sgt=l(),at=a("div"),F(AR.$$.fragment),Rgt=l(),lxe=a("p"),Pgt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Bgt=l(),Qn=a("p"),Igt=o("The model class to instantiate is selected based on the "),ixe=a("code"),Ngt=o("model_type"),qgt=o(` property of the config object (either
passed as an argument or loaded from `),dxe=a("code"),jgt=o("pretrained_model_name_or_path"),Dgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cxe=a("code"),Ggt=o("pretrained_model_name_or_path"),Ogt=o(":"),Vgt=l(),Re=a("ul"),K7=a("li"),fxe=a("strong"),Xgt=o("albert"),zgt=o(" \u2014 "),ose=a("a"),Qgt=o("FlaxAlbertForQuestionAnswering"),Wgt=o(" (ALBERT model)"),Ugt=l(),Z7=a("li"),mxe=a("strong"),Hgt=o("bart"),Jgt=o(" \u2014 "),rse=a("a"),Ygt=o("FlaxBartForQuestionAnswering"),Kgt=o(" (BART model)"),Zgt=l(),eL=a("li"),gxe=a("strong"),eht=o("bert"),oht=o(" \u2014 "),tse=a("a"),rht=o("FlaxBertForQuestionAnswering"),tht=o(" (BERT model)"),aht=l(),oL=a("li"),hxe=a("strong"),nht=o("big_bird"),sht=o(" \u2014 "),ase=a("a"),lht=o("FlaxBigBirdForQuestionAnswering"),iht=o(" (BigBird model)"),dht=l(),rL=a("li"),uxe=a("strong"),cht=o("distilbert"),fht=o(" \u2014 "),nse=a("a"),mht=o("FlaxDistilBertForQuestionAnswering"),ght=o(" (DistilBERT model)"),hht=l(),tL=a("li"),pxe=a("strong"),uht=o("electra"),pht=o(" \u2014 "),sse=a("a"),_ht=o("FlaxElectraForQuestionAnswering"),vht=o(" (ELECTRA model)"),bht=l(),aL=a("li"),_xe=a("strong"),Fht=o("mbart"),Tht=o(" \u2014 "),lse=a("a"),Mht=o("FlaxMBartForQuestionAnswering"),Eht=o(" (mBART model)"),Cht=l(),nL=a("li"),vxe=a("strong"),wht=o("roberta"),Aht=o(" \u2014 "),ise=a("a"),Lht=o("FlaxRobertaForQuestionAnswering"),yht=o(" (RoBERTa model)"),xht=l(),sL=a("li"),bxe=a("strong"),$ht=o("roformer"),kht=o(" \u2014 "),dse=a("a"),Sht=o("FlaxRoFormerForQuestionAnswering"),Rht=o(" (RoFormer model)"),Pht=l(),lL=a("li"),Fxe=a("strong"),Bht=o("xlm-roberta"),Iht=o(" \u2014 "),cse=a("a"),Nht=o("FlaxXLMRobertaForQuestionAnswering"),qht=o(" (XLM-RoBERTa model)"),jht=l(),F(iL.$$.fragment),PZe=l(),am=a("h2"),dL=a("a"),Txe=a("span"),F(LR.$$.fragment),Dht=l(),Mxe=a("span"),Ght=o("FlaxAutoModelForTokenClassification"),BZe=l(),xr=a("div"),F(yR.$$.fragment),Oht=l(),nm=a("p"),Vht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fse=a("a"),Xht=o("from_pretrained()"),zht=o(" class method or the "),mse=a("a"),Qht=o("from_config()"),Wht=o(` class
method.`),Uht=l(),xR=a("p"),Hht=o("This class cannot be instantiated directly using "),Exe=a("code"),Jht=o("__init__()"),Yht=o(" (throws an error)."),Kht=l(),ga=a("div"),F($R.$$.fragment),Zht=l(),Cxe=a("p"),eut=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),out=l(),sm=a("p"),rut=o(`Note:
Loading a model from its configuration file does `),wxe=a("strong"),tut=o("not"),aut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=a("a"),nut=o("from_pretrained()"),sut=o(" to load the model weights."),lut=l(),F(cL.$$.fragment),iut=l(),nt=a("div"),F(kR.$$.fragment),dut=l(),Axe=a("p"),cut=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),fut=l(),Wn=a("p"),mut=o("The model class to instantiate is selected based on the "),Lxe=a("code"),gut=o("model_type"),hut=o(` property of the config object (either
passed as an argument or loaded from `),yxe=a("code"),uut=o("pretrained_model_name_or_path"),put=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xxe=a("code"),_ut=o("pretrained_model_name_or_path"),vut=o(":"),but=l(),Xe=a("ul"),fL=a("li"),$xe=a("strong"),Fut=o("albert"),Tut=o(" \u2014 "),hse=a("a"),Mut=o("FlaxAlbertForTokenClassification"),Eut=o(" (ALBERT model)"),Cut=l(),mL=a("li"),kxe=a("strong"),wut=o("bert"),Aut=o(" \u2014 "),use=a("a"),Lut=o("FlaxBertForTokenClassification"),yut=o(" (BERT model)"),xut=l(),gL=a("li"),Sxe=a("strong"),$ut=o("big_bird"),kut=o(" \u2014 "),pse=a("a"),Sut=o("FlaxBigBirdForTokenClassification"),Rut=o(" (BigBird model)"),Put=l(),hL=a("li"),Rxe=a("strong"),But=o("distilbert"),Iut=o(" \u2014 "),_se=a("a"),Nut=o("FlaxDistilBertForTokenClassification"),qut=o(" (DistilBERT model)"),jut=l(),uL=a("li"),Pxe=a("strong"),Dut=o("electra"),Gut=o(" \u2014 "),vse=a("a"),Out=o("FlaxElectraForTokenClassification"),Vut=o(" (ELECTRA model)"),Xut=l(),pL=a("li"),Bxe=a("strong"),zut=o("roberta"),Qut=o(" \u2014 "),bse=a("a"),Wut=o("FlaxRobertaForTokenClassification"),Uut=o(" (RoBERTa model)"),Hut=l(),_L=a("li"),Ixe=a("strong"),Jut=o("roformer"),Yut=o(" \u2014 "),Fse=a("a"),Kut=o("FlaxRoFormerForTokenClassification"),Zut=o(" (RoFormer model)"),ept=l(),vL=a("li"),Nxe=a("strong"),opt=o("xlm-roberta"),rpt=o(" \u2014 "),Tse=a("a"),tpt=o("FlaxXLMRobertaForTokenClassification"),apt=o(" (XLM-RoBERTa model)"),npt=l(),F(bL.$$.fragment),IZe=l(),lm=a("h2"),FL=a("a"),qxe=a("span"),F(SR.$$.fragment),spt=l(),jxe=a("span"),lpt=o("FlaxAutoModelForMultipleChoice"),NZe=l(),$r=a("div"),F(RR.$$.fragment),ipt=l(),im=a("p"),dpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Mse=a("a"),cpt=o("from_pretrained()"),fpt=o(" class method or the "),Ese=a("a"),mpt=o("from_config()"),gpt=o(` class
method.`),hpt=l(),PR=a("p"),upt=o("This class cannot be instantiated directly using "),Dxe=a("code"),ppt=o("__init__()"),_pt=o(" (throws an error)."),vpt=l(),ha=a("div"),F(BR.$$.fragment),bpt=l(),Gxe=a("p"),Fpt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tpt=l(),dm=a("p"),Mpt=o(`Note:
Loading a model from its configuration file does `),Oxe=a("strong"),Ept=o("not"),Cpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=a("a"),wpt=o("from_pretrained()"),Apt=o(" to load the model weights."),Lpt=l(),F(TL.$$.fragment),ypt=l(),st=a("div"),F(IR.$$.fragment),xpt=l(),Vxe=a("p"),$pt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kpt=l(),Un=a("p"),Spt=o("The model class to instantiate is selected based on the "),Xxe=a("code"),Rpt=o("model_type"),Ppt=o(` property of the config object (either
passed as an argument or loaded from `),zxe=a("code"),Bpt=o("pretrained_model_name_or_path"),Ipt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qxe=a("code"),Npt=o("pretrained_model_name_or_path"),qpt=o(":"),jpt=l(),ze=a("ul"),ML=a("li"),Wxe=a("strong"),Dpt=o("albert"),Gpt=o(" \u2014 "),wse=a("a"),Opt=o("FlaxAlbertForMultipleChoice"),Vpt=o(" (ALBERT model)"),Xpt=l(),EL=a("li"),Uxe=a("strong"),zpt=o("bert"),Qpt=o(" \u2014 "),Ase=a("a"),Wpt=o("FlaxBertForMultipleChoice"),Upt=o(" (BERT model)"),Hpt=l(),CL=a("li"),Hxe=a("strong"),Jpt=o("big_bird"),Ypt=o(" \u2014 "),Lse=a("a"),Kpt=o("FlaxBigBirdForMultipleChoice"),Zpt=o(" (BigBird model)"),e_t=l(),wL=a("li"),Jxe=a("strong"),o_t=o("distilbert"),r_t=o(" \u2014 "),yse=a("a"),t_t=o("FlaxDistilBertForMultipleChoice"),a_t=o(" (DistilBERT model)"),n_t=l(),AL=a("li"),Yxe=a("strong"),s_t=o("electra"),l_t=o(" \u2014 "),xse=a("a"),i_t=o("FlaxElectraForMultipleChoice"),d_t=o(" (ELECTRA model)"),c_t=l(),LL=a("li"),Kxe=a("strong"),f_t=o("roberta"),m_t=o(" \u2014 "),$se=a("a"),g_t=o("FlaxRobertaForMultipleChoice"),h_t=o(" (RoBERTa model)"),u_t=l(),yL=a("li"),Zxe=a("strong"),p_t=o("roformer"),__t=o(" \u2014 "),kse=a("a"),v_t=o("FlaxRoFormerForMultipleChoice"),b_t=o(" (RoFormer model)"),F_t=l(),xL=a("li"),e$e=a("strong"),T_t=o("xlm-roberta"),M_t=o(" \u2014 "),Sse=a("a"),E_t=o("FlaxXLMRobertaForMultipleChoice"),C_t=o(" (XLM-RoBERTa model)"),w_t=l(),F($L.$$.fragment),qZe=l(),cm=a("h2"),kL=a("a"),o$e=a("span"),F(NR.$$.fragment),A_t=l(),r$e=a("span"),L_t=o("FlaxAutoModelForNextSentencePrediction"),jZe=l(),kr=a("div"),F(qR.$$.fragment),y_t=l(),fm=a("p"),x_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Rse=a("a"),$_t=o("from_pretrained()"),k_t=o(" class method or the "),Pse=a("a"),S_t=o("from_config()"),R_t=o(` class
method.`),P_t=l(),jR=a("p"),B_t=o("This class cannot be instantiated directly using "),t$e=a("code"),I_t=o("__init__()"),N_t=o(" (throws an error)."),q_t=l(),ua=a("div"),F(DR.$$.fragment),j_t=l(),a$e=a("p"),D_t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),G_t=l(),mm=a("p"),O_t=o(`Note:
Loading a model from its configuration file does `),n$e=a("strong"),V_t=o("not"),X_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bse=a("a"),z_t=o("from_pretrained()"),Q_t=o(" to load the model weights."),W_t=l(),F(SL.$$.fragment),U_t=l(),lt=a("div"),F(GR.$$.fragment),H_t=l(),s$e=a("p"),J_t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Y_t=l(),Hn=a("p"),K_t=o("The model class to instantiate is selected based on the "),l$e=a("code"),Z_t=o("model_type"),e2t=o(` property of the config object (either
passed as an argument or loaded from `),i$e=a("code"),o2t=o("pretrained_model_name_or_path"),r2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=a("code"),t2t=o("pretrained_model_name_or_path"),a2t=o(":"),n2t=l(),c$e=a("ul"),RL=a("li"),f$e=a("strong"),s2t=o("bert"),l2t=o(" \u2014 "),Ise=a("a"),i2t=o("FlaxBertForNextSentencePrediction"),d2t=o(" (BERT model)"),c2t=l(),F(PL.$$.fragment),DZe=l(),gm=a("h2"),BL=a("a"),m$e=a("span"),F(OR.$$.fragment),f2t=l(),g$e=a("span"),m2t=o("FlaxAutoModelForImageClassification"),GZe=l(),Sr=a("div"),F(VR.$$.fragment),g2t=l(),hm=a("p"),h2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nse=a("a"),u2t=o("from_pretrained()"),p2t=o(" class method or the "),qse=a("a"),_2t=o("from_config()"),v2t=o(` class
method.`),b2t=l(),XR=a("p"),F2t=o("This class cannot be instantiated directly using "),h$e=a("code"),T2t=o("__init__()"),M2t=o(" (throws an error)."),E2t=l(),pa=a("div"),F(zR.$$.fragment),C2t=l(),u$e=a("p"),w2t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),A2t=l(),um=a("p"),L2t=o(`Note:
Loading a model from its configuration file does `),p$e=a("strong"),y2t=o("not"),x2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=a("a"),$2t=o("from_pretrained()"),k2t=o(" to load the model weights."),S2t=l(),F(IL.$$.fragment),R2t=l(),it=a("div"),F(QR.$$.fragment),P2t=l(),_$e=a("p"),B2t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),I2t=l(),Jn=a("p"),N2t=o("The model class to instantiate is selected based on the "),v$e=a("code"),q2t=o("model_type"),j2t=o(` property of the config object (either
passed as an argument or loaded from `),b$e=a("code"),D2t=o("pretrained_model_name_or_path"),G2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=a("code"),O2t=o("pretrained_model_name_or_path"),V2t=o(":"),X2t=l(),WR=a("ul"),NL=a("li"),T$e=a("strong"),z2t=o("beit"),Q2t=o(" \u2014 "),Dse=a("a"),W2t=o("FlaxBeitForImageClassification"),U2t=o(" (BEiT model)"),H2t=l(),qL=a("li"),M$e=a("strong"),J2t=o("vit"),Y2t=o(" \u2014 "),Gse=a("a"),K2t=o("FlaxViTForImageClassification"),Z2t=o(" (ViT model)"),evt=l(),F(jL.$$.fragment),OZe=l(),pm=a("h2"),DL=a("a"),E$e=a("span"),F(UR.$$.fragment),ovt=l(),C$e=a("span"),rvt=o("FlaxAutoModelForVision2Seq"),VZe=l(),Rr=a("div"),F(HR.$$.fragment),tvt=l(),_m=a("p"),avt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ose=a("a"),nvt=o("from_pretrained()"),svt=o(" class method or the "),Vse=a("a"),lvt=o("from_config()"),ivt=o(` class
method.`),dvt=l(),JR=a("p"),cvt=o("This class cannot be instantiated directly using "),w$e=a("code"),fvt=o("__init__()"),mvt=o(" (throws an error)."),gvt=l(),_a=a("div"),F(YR.$$.fragment),hvt=l(),A$e=a("p"),uvt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),pvt=l(),vm=a("p"),_vt=o(`Note:
Loading a model from its configuration file does `),L$e=a("strong"),vvt=o("not"),bvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=a("a"),Fvt=o("from_pretrained()"),Tvt=o(" to load the model weights."),Mvt=l(),F(GL.$$.fragment),Evt=l(),dt=a("div"),F(KR.$$.fragment),Cvt=l(),y$e=a("p"),wvt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Avt=l(),Yn=a("p"),Lvt=o("The model class to instantiate is selected based on the "),x$e=a("code"),yvt=o("model_type"),xvt=o(` property of the config object (either
passed as an argument or loaded from `),$$e=a("code"),$vt=o("pretrained_model_name_or_path"),kvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=a("code"),Svt=o("pretrained_model_name_or_path"),Rvt=o(":"),Pvt=l(),S$e=a("ul"),OL=a("li"),R$e=a("strong"),Bvt=o("vision-encoder-decoder"),Ivt=o(" \u2014 "),zse=a("a"),Nvt=o("FlaxVisionEncoderDecoderModel"),qvt=o(" (Vision Encoder decoder model)"),jvt=l(),F(VL.$$.fragment),this.h()},l(f){const _=jma('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),b=i(f),u=n(f,"H1",{class:!0});var ZR=s(u);m=n(ZR,"A",{id:!0,class:!0,href:!0});var P$e=s(m);p=n(P$e,"SPAN",{});var B$e=s(p);T(d.$$.fragment,B$e),B$e.forEach(t),P$e.forEach(t),h=i(ZR),yo=n(ZR,"SPAN",{});var I$e=s(yo);rd=r(I$e,"Auto Classes"),I$e.forEach(t),ZR.forEach(t),Mm=i(f),pt=n(f,"P",{});var eP=s(pt);td=r(eP,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ad=n(eP,"CODE",{});var N$e=s(ad);b9=r(N$e,"from_pretrained()"),N$e.forEach(t),Em=r(eP,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),eP.forEach(t),Ve=i(f),He=n(f,"P",{});var Kn=s(He);nd=r(Kn,"Instantiating one of "),Zn=n(Kn,"A",{href:!0});var q$e=s(Zn);F9=r(q$e,"AutoConfig"),q$e.forEach(t),es=r(Kn,", "),os=n(Kn,"A",{href:!0});var j$e=s(os);T9=r(j$e,"AutoModel"),j$e.forEach(t),sd=r(Kn,`, and
`),rs=n(Kn,"A",{href:!0});var D$e=s(rs);M9=r(D$e,"AutoTokenizer"),D$e.forEach(t),ld=r(Kn," will directly create a class of the relevant architecture. For instance"),Kn.forEach(t),Cm=i(f),T(Qa.$$.fragment,f),Je=i(f),Ae=n(f,"P",{});var oP=s(Ae);CB=r(oP,"will create a model that is an instance of "),id=n(oP,"A",{href:!0});var G$e=s(id);wB=r(G$e,"BertModel"),G$e.forEach(t),AB=r(oP,"."),oP.forEach(t),xo=i(f),Wa=n(f,"P",{});var rP=s(Wa);LB=r(rP,"There is one class of "),wm=n(rP,"CODE",{});var O$e=s(wm);yB=r(O$e,"AutoModel"),O$e.forEach(t),iro=r(rP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),rP.forEach(t),kYe=i(f),dd=n(f,"H2",{class:!0});var tP=s(dd);Am=n(tP,"A",{id:!0,class:!0,href:!0});var V$e=s(Am);Hie=n(V$e,"SPAN",{});var X$e=s(Hie);T(E9.$$.fragment,X$e),X$e.forEach(t),V$e.forEach(t),dro=i(tP),Jie=n(tP,"SPAN",{});var z$e=s(Jie);cro=r(z$e,"Extending the Auto Classes"),z$e.forEach(t),tP.forEach(t),SYe=i(f),ts=n(f,"P",{});var bm=s(ts);fro=r(bm,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Yie=n(bm,"CODE",{});var Q$e=s(Yie);mro=r(Q$e,"NewModel"),Q$e.forEach(t),gro=r(bm,", make sure you have a "),Kie=n(bm,"CODE",{});var W$e=s(Kie);hro=r(W$e,"NewModelConfig"),W$e.forEach(t),uro=r(bm,` then you can add those to the auto
classes like this:`),bm.forEach(t),RYe=i(f),T(C9.$$.fragment,f),PYe=i(f),xB=n(f,"P",{});var U$e=s(xB);pro=r(U$e,"You will then be able to use the auto classes like you would usually do!"),U$e.forEach(t),BYe=i(f),T(Lm.$$.fragment,f),IYe=i(f),cd=n(f,"H2",{class:!0});var aP=s(cd);ym=n(aP,"A",{id:!0,class:!0,href:!0});var H$e=s(ym);Zie=n(H$e,"SPAN",{});var J$e=s(Zie);T(w9.$$.fragment,J$e),J$e.forEach(t),H$e.forEach(t),_ro=i(aP),ede=n(aP,"SPAN",{});var Y$e=s(ede);vro=r(Y$e,"AutoConfig"),Y$e.forEach(t),aP.forEach(t),NYe=i(f),$o=n(f,"DIV",{class:!0});var ht=s($o);T(A9.$$.fragment,ht),bro=i(ht),L9=n(ht,"P",{});var nP=s(L9);Fro=r(nP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),$B=n(nP,"A",{href:!0});var K$e=s($B);Tro=r(K$e,"from_pretrained()"),K$e.forEach(t),Mro=r(nP," class method."),nP.forEach(t),Ero=i(ht),y9=n(ht,"P",{});var sP=s(y9);Cro=r(sP,"This class cannot be instantiated directly using "),ode=n(sP,"CODE",{});var Z$e=s(ode);wro=r(Z$e,"__init__()"),Z$e.forEach(t),Aro=r(sP," (throws an error)."),sP.forEach(t),Lro=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(x9.$$.fragment,ut),yro=i(ut),rde=n(ut,"P",{});var eke=s(rde);xro=r(eke,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),eke.forEach(t),$ro=i(ut),fd=n(ut,"P",{});var Fm=s(fd);kro=r(Fm,"The configuration class to instantiate is selected based on the "),tde=n(Fm,"CODE",{});var oke=s(tde);Sro=r(oke,"model_type"),oke.forEach(t),Rro=r(Fm,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ade=n(Fm,"CODE",{});var rke=s(ade);Pro=r(rke,"pretrained_model_name_or_path"),rke.forEach(t),Bro=r(Fm,":"),Fm.forEach(t),Iro=i(ut),A=n(ut,"UL",{});var L=s(A);xm=n(L,"LI",{});var XL=s(xm);nde=n(XL,"STRONG",{});var tke=s(nde);Nro=r(tke,"albert"),tke.forEach(t),qro=r(XL," \u2014 "),kB=n(XL,"A",{href:!0});var ake=s(kB);jro=r(ake,"AlbertConfig"),ake.forEach(t),Dro=r(XL," (ALBERT model)"),XL.forEach(t),Gro=i(L),$m=n(L,"LI",{});var zL=s($m);sde=n(zL,"STRONG",{});var nke=s(sde);Oro=r(nke,"bart"),nke.forEach(t),Vro=r(zL," \u2014 "),SB=n(zL,"A",{href:!0});var ske=s(SB);Xro=r(ske,"BartConfig"),ske.forEach(t),zro=r(zL," (BART model)"),zL.forEach(t),Qro=i(L),km=n(L,"LI",{});var QL=s(km);lde=n(QL,"STRONG",{});var lke=s(lde);Wro=r(lke,"beit"),lke.forEach(t),Uro=r(QL," \u2014 "),RB=n(QL,"A",{href:!0});var ike=s(RB);Hro=r(ike,"BeitConfig"),ike.forEach(t),Jro=r(QL," (BEiT model)"),QL.forEach(t),Yro=i(L),Sm=n(L,"LI",{});var WL=s(Sm);ide=n(WL,"STRONG",{});var dke=s(ide);Kro=r(dke,"bert"),dke.forEach(t),Zro=r(WL," \u2014 "),PB=n(WL,"A",{href:!0});var cke=s(PB);eto=r(cke,"BertConfig"),cke.forEach(t),oto=r(WL," (BERT model)"),WL.forEach(t),rto=i(L),Rm=n(L,"LI",{});var UL=s(Rm);dde=n(UL,"STRONG",{});var fke=s(dde);tto=r(fke,"bert-generation"),fke.forEach(t),ato=r(UL," \u2014 "),BB=n(UL,"A",{href:!0});var mke=s(BB);nto=r(mke,"BertGenerationConfig"),mke.forEach(t),sto=r(UL," (Bert Generation model)"),UL.forEach(t),lto=i(L),Pm=n(L,"LI",{});var HL=s(Pm);cde=n(HL,"STRONG",{});var gke=s(cde);ito=r(gke,"big_bird"),gke.forEach(t),dto=r(HL," \u2014 "),IB=n(HL,"A",{href:!0});var hke=s(IB);cto=r(hke,"BigBirdConfig"),hke.forEach(t),fto=r(HL," (BigBird model)"),HL.forEach(t),mto=i(L),Bm=n(L,"LI",{});var JL=s(Bm);fde=n(JL,"STRONG",{});var uke=s(fde);gto=r(uke,"bigbird_pegasus"),uke.forEach(t),hto=r(JL," \u2014 "),NB=n(JL,"A",{href:!0});var pke=s(NB);uto=r(pke,"BigBirdPegasusConfig"),pke.forEach(t),pto=r(JL," (BigBird-Pegasus model)"),JL.forEach(t),_to=i(L),Im=n(L,"LI",{});var YL=s(Im);mde=n(YL,"STRONG",{});var _ke=s(mde);vto=r(_ke,"blenderbot"),_ke.forEach(t),bto=r(YL," \u2014 "),qB=n(YL,"A",{href:!0});var vke=s(qB);Fto=r(vke,"BlenderbotConfig"),vke.forEach(t),Tto=r(YL," (Blenderbot model)"),YL.forEach(t),Mto=i(L),Nm=n(L,"LI",{});var KL=s(Nm);gde=n(KL,"STRONG",{});var bke=s(gde);Eto=r(bke,"blenderbot-small"),bke.forEach(t),Cto=r(KL," \u2014 "),jB=n(KL,"A",{href:!0});var Fke=s(jB);wto=r(Fke,"BlenderbotSmallConfig"),Fke.forEach(t),Ato=r(KL," (BlenderbotSmall model)"),KL.forEach(t),Lto=i(L),qm=n(L,"LI",{});var ZL=s(qm);hde=n(ZL,"STRONG",{});var Tke=s(hde);yto=r(Tke,"bloom"),Tke.forEach(t),xto=r(ZL," \u2014 "),DB=n(ZL,"A",{href:!0});var Mke=s(DB);$to=r(Mke,"BloomConfig"),Mke.forEach(t),kto=r(ZL," (BLOOM model)"),ZL.forEach(t),Sto=i(L),jm=n(L,"LI",{});var ey=s(jm);ude=n(ey,"STRONG",{});var Eke=s(ude);Rto=r(Eke,"camembert"),Eke.forEach(t),Pto=r(ey," \u2014 "),GB=n(ey,"A",{href:!0});var Cke=s(GB);Bto=r(Cke,"CamembertConfig"),Cke.forEach(t),Ito=r(ey," (CamemBERT model)"),ey.forEach(t),Nto=i(L),Dm=n(L,"LI",{});var oy=s(Dm);pde=n(oy,"STRONG",{});var wke=s(pde);qto=r(wke,"canine"),wke.forEach(t),jto=r(oy," \u2014 "),OB=n(oy,"A",{href:!0});var Ake=s(OB);Dto=r(Ake,"CanineConfig"),Ake.forEach(t),Gto=r(oy," (CANINE model)"),oy.forEach(t),Oto=i(L),Gm=n(L,"LI",{});var ry=s(Gm);_de=n(ry,"STRONG",{});var Lke=s(_de);Vto=r(Lke,"clip"),Lke.forEach(t),Xto=r(ry," \u2014 "),VB=n(ry,"A",{href:!0});var yke=s(VB);zto=r(yke,"CLIPConfig"),yke.forEach(t),Qto=r(ry," (CLIP model)"),ry.forEach(t),Wto=i(L),Om=n(L,"LI",{});var ty=s(Om);vde=n(ty,"STRONG",{});var xke=s(vde);Uto=r(xke,"codegen"),xke.forEach(t),Hto=r(ty," \u2014 "),XB=n(ty,"A",{href:!0});var $ke=s(XB);Jto=r($ke,"CodeGenConfig"),$ke.forEach(t),Yto=r(ty," (CodeGen model)"),ty.forEach(t),Kto=i(L),Vm=n(L,"LI",{});var ay=s(Vm);bde=n(ay,"STRONG",{});var kke=s(bde);Zto=r(kke,"convbert"),kke.forEach(t),eao=r(ay," \u2014 "),zB=n(ay,"A",{href:!0});var Ske=s(zB);oao=r(Ske,"ConvBertConfig"),Ske.forEach(t),rao=r(ay," (ConvBERT model)"),ay.forEach(t),tao=i(L),Xm=n(L,"LI",{});var ny=s(Xm);Fde=n(ny,"STRONG",{});var Rke=s(Fde);aao=r(Rke,"convnext"),Rke.forEach(t),nao=r(ny," \u2014 "),QB=n(ny,"A",{href:!0});var Pke=s(QB);sao=r(Pke,"ConvNextConfig"),Pke.forEach(t),lao=r(ny," (ConvNeXT model)"),ny.forEach(t),iao=i(L),zm=n(L,"LI",{});var sy=s(zm);Tde=n(sy,"STRONG",{});var Bke=s(Tde);dao=r(Bke,"ctrl"),Bke.forEach(t),cao=r(sy," \u2014 "),WB=n(sy,"A",{href:!0});var Ike=s(WB);fao=r(Ike,"CTRLConfig"),Ike.forEach(t),mao=r(sy," (CTRL model)"),sy.forEach(t),gao=i(L),Qm=n(L,"LI",{});var ly=s(Qm);Mde=n(ly,"STRONG",{});var Nke=s(Mde);hao=r(Nke,"cvt"),Nke.forEach(t),uao=r(ly," \u2014 "),UB=n(ly,"A",{href:!0});var qke=s(UB);pao=r(qke,"CvtConfig"),qke.forEach(t),_ao=r(ly," (CvT model)"),ly.forEach(t),vao=i(L),Wm=n(L,"LI",{});var iy=s(Wm);Ede=n(iy,"STRONG",{});var jke=s(Ede);bao=r(jke,"data2vec-audio"),jke.forEach(t),Fao=r(iy," \u2014 "),HB=n(iy,"A",{href:!0});var Dke=s(HB);Tao=r(Dke,"Data2VecAudioConfig"),Dke.forEach(t),Mao=r(iy," (Data2VecAudio model)"),iy.forEach(t),Eao=i(L),Um=n(L,"LI",{});var dy=s(Um);Cde=n(dy,"STRONG",{});var Gke=s(Cde);Cao=r(Gke,"data2vec-text"),Gke.forEach(t),wao=r(dy," \u2014 "),JB=n(dy,"A",{href:!0});var Oke=s(JB);Aao=r(Oke,"Data2VecTextConfig"),Oke.forEach(t),Lao=r(dy," (Data2VecText model)"),dy.forEach(t),yao=i(L),Hm=n(L,"LI",{});var cy=s(Hm);wde=n(cy,"STRONG",{});var Vke=s(wde);xao=r(Vke,"data2vec-vision"),Vke.forEach(t),$ao=r(cy," \u2014 "),YB=n(cy,"A",{href:!0});var Xke=s(YB);kao=r(Xke,"Data2VecVisionConfig"),Xke.forEach(t),Sao=r(cy," (Data2VecVision model)"),cy.forEach(t),Rao=i(L),Jm=n(L,"LI",{});var fy=s(Jm);Ade=n(fy,"STRONG",{});var zke=s(Ade);Pao=r(zke,"deberta"),zke.forEach(t),Bao=r(fy," \u2014 "),KB=n(fy,"A",{href:!0});var Qke=s(KB);Iao=r(Qke,"DebertaConfig"),Qke.forEach(t),Nao=r(fy," (DeBERTa model)"),fy.forEach(t),qao=i(L),Ym=n(L,"LI",{});var my=s(Ym);Lde=n(my,"STRONG",{});var Wke=s(Lde);jao=r(Wke,"deberta-v2"),Wke.forEach(t),Dao=r(my," \u2014 "),ZB=n(my,"A",{href:!0});var Uke=s(ZB);Gao=r(Uke,"DebertaV2Config"),Uke.forEach(t),Oao=r(my," (DeBERTa-v2 model)"),my.forEach(t),Vao=i(L),Km=n(L,"LI",{});var gy=s(Km);yde=n(gy,"STRONG",{});var Hke=s(yde);Xao=r(Hke,"decision_transformer"),Hke.forEach(t),zao=r(gy," \u2014 "),eI=n(gy,"A",{href:!0});var Jke=s(eI);Qao=r(Jke,"DecisionTransformerConfig"),Jke.forEach(t),Wao=r(gy," (Decision Transformer model)"),gy.forEach(t),Uao=i(L),Zm=n(L,"LI",{});var hy=s(Zm);xde=n(hy,"STRONG",{});var Yke=s(xde);Hao=r(Yke,"deit"),Yke.forEach(t),Jao=r(hy," \u2014 "),oI=n(hy,"A",{href:!0});var Kke=s(oI);Yao=r(Kke,"DeiTConfig"),Kke.forEach(t),Kao=r(hy," (DeiT model)"),hy.forEach(t),Zao=i(L),eg=n(L,"LI",{});var uy=s(eg);$de=n(uy,"STRONG",{});var Zke=s($de);eno=r(Zke,"detr"),Zke.forEach(t),ono=r(uy," \u2014 "),rI=n(uy,"A",{href:!0});var eSe=s(rI);rno=r(eSe,"DetrConfig"),eSe.forEach(t),tno=r(uy," (DETR model)"),uy.forEach(t),ano=i(L),og=n(L,"LI",{});var oSe=s(og);kde=n(oSe,"STRONG",{});var Gvt=s(kde);nno=r(Gvt,"distilbert"),Gvt.forEach(t),sno=r(oSe," \u2014 "),tI=n(oSe,"A",{href:!0});var Ovt=s(tI);lno=r(Ovt,"DistilBertConfig"),Ovt.forEach(t),ino=r(oSe," (DistilBERT model)"),oSe.forEach(t),dno=i(L),rg=n(L,"LI",{});var rSe=s(rg);Sde=n(rSe,"STRONG",{});var Vvt=s(Sde);cno=r(Vvt,"donut-swin"),Vvt.forEach(t),fno=r(rSe," \u2014 "),aI=n(rSe,"A",{href:!0});var Xvt=s(aI);mno=r(Xvt,"DonutSwinConfig"),Xvt.forEach(t),gno=r(rSe," (DonutSwin model)"),rSe.forEach(t),hno=i(L),tg=n(L,"LI",{});var tSe=s(tg);Rde=n(tSe,"STRONG",{});var zvt=s(Rde);uno=r(zvt,"dpr"),zvt.forEach(t),pno=r(tSe," \u2014 "),nI=n(tSe,"A",{href:!0});var Qvt=s(nI);_no=r(Qvt,"DPRConfig"),Qvt.forEach(t),vno=r(tSe," (DPR model)"),tSe.forEach(t),bno=i(L),ag=n(L,"LI",{});var aSe=s(ag);Pde=n(aSe,"STRONG",{});var Wvt=s(Pde);Fno=r(Wvt,"dpt"),Wvt.forEach(t),Tno=r(aSe," \u2014 "),sI=n(aSe,"A",{href:!0});var Uvt=s(sI);Mno=r(Uvt,"DPTConfig"),Uvt.forEach(t),Eno=r(aSe," (DPT model)"),aSe.forEach(t),Cno=i(L),ng=n(L,"LI",{});var nSe=s(ng);Bde=n(nSe,"STRONG",{});var Hvt=s(Bde);wno=r(Hvt,"electra"),Hvt.forEach(t),Ano=r(nSe," \u2014 "),lI=n(nSe,"A",{href:!0});var Jvt=s(lI);Lno=r(Jvt,"ElectraConfig"),Jvt.forEach(t),yno=r(nSe," (ELECTRA model)"),nSe.forEach(t),xno=i(L),sg=n(L,"LI",{});var sSe=s(sg);Ide=n(sSe,"STRONG",{});var Yvt=s(Ide);$no=r(Yvt,"encoder-decoder"),Yvt.forEach(t),kno=r(sSe," \u2014 "),iI=n(sSe,"A",{href:!0});var Kvt=s(iI);Sno=r(Kvt,"EncoderDecoderConfig"),Kvt.forEach(t),Rno=r(sSe," (Encoder decoder model)"),sSe.forEach(t),Pno=i(L),lg=n(L,"LI",{});var lSe=s(lg);Nde=n(lSe,"STRONG",{});var Zvt=s(Nde);Bno=r(Zvt,"ernie"),Zvt.forEach(t),Ino=r(lSe," \u2014 "),dI=n(lSe,"A",{href:!0});var e1t=s(dI);Nno=r(e1t,"ErnieConfig"),e1t.forEach(t),qno=r(lSe," (ERNIE model)"),lSe.forEach(t),jno=i(L),ig=n(L,"LI",{});var iSe=s(ig);qde=n(iSe,"STRONG",{});var o1t=s(qde);Dno=r(o1t,"flaubert"),o1t.forEach(t),Gno=r(iSe," \u2014 "),cI=n(iSe,"A",{href:!0});var r1t=s(cI);Ono=r(r1t,"FlaubertConfig"),r1t.forEach(t),Vno=r(iSe," (FlauBERT model)"),iSe.forEach(t),Xno=i(L),dg=n(L,"LI",{});var dSe=s(dg);jde=n(dSe,"STRONG",{});var t1t=s(jde);zno=r(t1t,"flava"),t1t.forEach(t),Qno=r(dSe," \u2014 "),fI=n(dSe,"A",{href:!0});var a1t=s(fI);Wno=r(a1t,"FlavaConfig"),a1t.forEach(t),Uno=r(dSe," (FLAVA model)"),dSe.forEach(t),Hno=i(L),cg=n(L,"LI",{});var cSe=s(cg);Dde=n(cSe,"STRONG",{});var n1t=s(Dde);Jno=r(n1t,"fnet"),n1t.forEach(t),Yno=r(cSe," \u2014 "),mI=n(cSe,"A",{href:!0});var s1t=s(mI);Kno=r(s1t,"FNetConfig"),s1t.forEach(t),Zno=r(cSe," (FNet model)"),cSe.forEach(t),eso=i(L),fg=n(L,"LI",{});var fSe=s(fg);Gde=n(fSe,"STRONG",{});var l1t=s(Gde);oso=r(l1t,"fsmt"),l1t.forEach(t),rso=r(fSe," \u2014 "),gI=n(fSe,"A",{href:!0});var i1t=s(gI);tso=r(i1t,"FSMTConfig"),i1t.forEach(t),aso=r(fSe," (FairSeq Machine-Translation model)"),fSe.forEach(t),nso=i(L),mg=n(L,"LI",{});var mSe=s(mg);Ode=n(mSe,"STRONG",{});var d1t=s(Ode);sso=r(d1t,"funnel"),d1t.forEach(t),lso=r(mSe," \u2014 "),hI=n(mSe,"A",{href:!0});var c1t=s(hI);iso=r(c1t,"FunnelConfig"),c1t.forEach(t),dso=r(mSe," (Funnel Transformer model)"),mSe.forEach(t),cso=i(L),gg=n(L,"LI",{});var gSe=s(gg);Vde=n(gSe,"STRONG",{});var f1t=s(Vde);fso=r(f1t,"glpn"),f1t.forEach(t),mso=r(gSe," \u2014 "),uI=n(gSe,"A",{href:!0});var m1t=s(uI);gso=r(m1t,"GLPNConfig"),m1t.forEach(t),hso=r(gSe," (GLPN model)"),gSe.forEach(t),uso=i(L),hg=n(L,"LI",{});var hSe=s(hg);Xde=n(hSe,"STRONG",{});var g1t=s(Xde);pso=r(g1t,"gpt2"),g1t.forEach(t),_so=r(hSe," \u2014 "),pI=n(hSe,"A",{href:!0});var h1t=s(pI);vso=r(h1t,"GPT2Config"),h1t.forEach(t),bso=r(hSe," (OpenAI GPT-2 model)"),hSe.forEach(t),Fso=i(L),ug=n(L,"LI",{});var uSe=s(ug);zde=n(uSe,"STRONG",{});var u1t=s(zde);Tso=r(u1t,"gpt_neo"),u1t.forEach(t),Mso=r(uSe," \u2014 "),_I=n(uSe,"A",{href:!0});var p1t=s(_I);Eso=r(p1t,"GPTNeoConfig"),p1t.forEach(t),Cso=r(uSe," (GPT Neo model)"),uSe.forEach(t),wso=i(L),pg=n(L,"LI",{});var pSe=s(pg);Qde=n(pSe,"STRONG",{});var _1t=s(Qde);Aso=r(_1t,"gpt_neox"),_1t.forEach(t),Lso=r(pSe," \u2014 "),vI=n(pSe,"A",{href:!0});var v1t=s(vI);yso=r(v1t,"GPTNeoXConfig"),v1t.forEach(t),xso=r(pSe," (GPT NeoX model)"),pSe.forEach(t),$so=i(L),_g=n(L,"LI",{});var _Se=s(_g);Wde=n(_Se,"STRONG",{});var b1t=s(Wde);kso=r(b1t,"gptj"),b1t.forEach(t),Sso=r(_Se," \u2014 "),bI=n(_Se,"A",{href:!0});var F1t=s(bI);Rso=r(F1t,"GPTJConfig"),F1t.forEach(t),Pso=r(_Se," (GPT-J model)"),_Se.forEach(t),Bso=i(L),vg=n(L,"LI",{});var vSe=s(vg);Ude=n(vSe,"STRONG",{});var T1t=s(Ude);Iso=r(T1t,"groupvit"),T1t.forEach(t),Nso=r(vSe," \u2014 "),FI=n(vSe,"A",{href:!0});var M1t=s(FI);qso=r(M1t,"GroupViTConfig"),M1t.forEach(t),jso=r(vSe," (GroupViT model)"),vSe.forEach(t),Dso=i(L),bg=n(L,"LI",{});var bSe=s(bg);Hde=n(bSe,"STRONG",{});var E1t=s(Hde);Gso=r(E1t,"hubert"),E1t.forEach(t),Oso=r(bSe," \u2014 "),TI=n(bSe,"A",{href:!0});var C1t=s(TI);Vso=r(C1t,"HubertConfig"),C1t.forEach(t),Xso=r(bSe," (Hubert model)"),bSe.forEach(t),zso=i(L),Fg=n(L,"LI",{});var FSe=s(Fg);Jde=n(FSe,"STRONG",{});var w1t=s(Jde);Qso=r(w1t,"ibert"),w1t.forEach(t),Wso=r(FSe," \u2014 "),MI=n(FSe,"A",{href:!0});var A1t=s(MI);Uso=r(A1t,"IBertConfig"),A1t.forEach(t),Hso=r(FSe," (I-BERT model)"),FSe.forEach(t),Jso=i(L),Tg=n(L,"LI",{});var TSe=s(Tg);Yde=n(TSe,"STRONG",{});var L1t=s(Yde);Yso=r(L1t,"imagegpt"),L1t.forEach(t),Kso=r(TSe," \u2014 "),EI=n(TSe,"A",{href:!0});var y1t=s(EI);Zso=r(y1t,"ImageGPTConfig"),y1t.forEach(t),elo=r(TSe," (ImageGPT model)"),TSe.forEach(t),olo=i(L),Mg=n(L,"LI",{});var MSe=s(Mg);Kde=n(MSe,"STRONG",{});var x1t=s(Kde);rlo=r(x1t,"layoutlm"),x1t.forEach(t),tlo=r(MSe," \u2014 "),CI=n(MSe,"A",{href:!0});var $1t=s(CI);alo=r($1t,"LayoutLMConfig"),$1t.forEach(t),nlo=r(MSe," (LayoutLM model)"),MSe.forEach(t),slo=i(L),Eg=n(L,"LI",{});var ESe=s(Eg);Zde=n(ESe,"STRONG",{});var k1t=s(Zde);llo=r(k1t,"layoutlmv2"),k1t.forEach(t),ilo=r(ESe," \u2014 "),wI=n(ESe,"A",{href:!0});var S1t=s(wI);dlo=r(S1t,"LayoutLMv2Config"),S1t.forEach(t),clo=r(ESe," (LayoutLMv2 model)"),ESe.forEach(t),flo=i(L),Cg=n(L,"LI",{});var CSe=s(Cg);ece=n(CSe,"STRONG",{});var R1t=s(ece);mlo=r(R1t,"layoutlmv3"),R1t.forEach(t),glo=r(CSe," \u2014 "),AI=n(CSe,"A",{href:!0});var P1t=s(AI);hlo=r(P1t,"LayoutLMv3Config"),P1t.forEach(t),ulo=r(CSe," (LayoutLMv3 model)"),CSe.forEach(t),plo=i(L),wg=n(L,"LI",{});var wSe=s(wg);oce=n(wSe,"STRONG",{});var B1t=s(oce);_lo=r(B1t,"led"),B1t.forEach(t),vlo=r(wSe," \u2014 "),LI=n(wSe,"A",{href:!0});var I1t=s(LI);blo=r(I1t,"LEDConfig"),I1t.forEach(t),Flo=r(wSe," (LED model)"),wSe.forEach(t),Tlo=i(L),Ag=n(L,"LI",{});var ASe=s(Ag);rce=n(ASe,"STRONG",{});var N1t=s(rce);Mlo=r(N1t,"levit"),N1t.forEach(t),Elo=r(ASe," \u2014 "),yI=n(ASe,"A",{href:!0});var q1t=s(yI);Clo=r(q1t,"LevitConfig"),q1t.forEach(t),wlo=r(ASe," (LeViT model)"),ASe.forEach(t),Alo=i(L),Lg=n(L,"LI",{});var LSe=s(Lg);tce=n(LSe,"STRONG",{});var j1t=s(tce);Llo=r(j1t,"longformer"),j1t.forEach(t),ylo=r(LSe," \u2014 "),xI=n(LSe,"A",{href:!0});var D1t=s(xI);xlo=r(D1t,"LongformerConfig"),D1t.forEach(t),$lo=r(LSe," (Longformer model)"),LSe.forEach(t),klo=i(L),yg=n(L,"LI",{});var ySe=s(yg);ace=n(ySe,"STRONG",{});var G1t=s(ace);Slo=r(G1t,"longt5"),G1t.forEach(t),Rlo=r(ySe," \u2014 "),$I=n(ySe,"A",{href:!0});var O1t=s($I);Plo=r(O1t,"LongT5Config"),O1t.forEach(t),Blo=r(ySe," (LongT5 model)"),ySe.forEach(t),Ilo=i(L),xg=n(L,"LI",{});var xSe=s(xg);nce=n(xSe,"STRONG",{});var V1t=s(nce);Nlo=r(V1t,"luke"),V1t.forEach(t),qlo=r(xSe," \u2014 "),kI=n(xSe,"A",{href:!0});var X1t=s(kI);jlo=r(X1t,"LukeConfig"),X1t.forEach(t),Dlo=r(xSe," (LUKE model)"),xSe.forEach(t),Glo=i(L),$g=n(L,"LI",{});var $Se=s($g);sce=n($Se,"STRONG",{});var z1t=s(sce);Olo=r(z1t,"lxmert"),z1t.forEach(t),Vlo=r($Se," \u2014 "),SI=n($Se,"A",{href:!0});var Q1t=s(SI);Xlo=r(Q1t,"LxmertConfig"),Q1t.forEach(t),zlo=r($Se," (LXMERT model)"),$Se.forEach(t),Qlo=i(L),kg=n(L,"LI",{});var kSe=s(kg);lce=n(kSe,"STRONG",{});var W1t=s(lce);Wlo=r(W1t,"m2m_100"),W1t.forEach(t),Ulo=r(kSe," \u2014 "),RI=n(kSe,"A",{href:!0});var U1t=s(RI);Hlo=r(U1t,"M2M100Config"),U1t.forEach(t),Jlo=r(kSe," (M2M100 model)"),kSe.forEach(t),Ylo=i(L),Sg=n(L,"LI",{});var SSe=s(Sg);ice=n(SSe,"STRONG",{});var H1t=s(ice);Klo=r(H1t,"marian"),H1t.forEach(t),Zlo=r(SSe," \u2014 "),PI=n(SSe,"A",{href:!0});var J1t=s(PI);eio=r(J1t,"MarianConfig"),J1t.forEach(t),oio=r(SSe," (Marian model)"),SSe.forEach(t),rio=i(L),Rg=n(L,"LI",{});var RSe=s(Rg);dce=n(RSe,"STRONG",{});var Y1t=s(dce);tio=r(Y1t,"maskformer"),Y1t.forEach(t),aio=r(RSe," \u2014 "),BI=n(RSe,"A",{href:!0});var K1t=s(BI);nio=r(K1t,"MaskFormerConfig"),K1t.forEach(t),sio=r(RSe," (MaskFormer model)"),RSe.forEach(t),lio=i(L),Pg=n(L,"LI",{});var PSe=s(Pg);cce=n(PSe,"STRONG",{});var Z1t=s(cce);iio=r(Z1t,"mbart"),Z1t.forEach(t),dio=r(PSe," \u2014 "),II=n(PSe,"A",{href:!0});var e4t=s(II);cio=r(e4t,"MBartConfig"),e4t.forEach(t),fio=r(PSe," (mBART model)"),PSe.forEach(t),mio=i(L),Bg=n(L,"LI",{});var BSe=s(Bg);fce=n(BSe,"STRONG",{});var o4t=s(fce);gio=r(o4t,"mctct"),o4t.forEach(t),hio=r(BSe," \u2014 "),NI=n(BSe,"A",{href:!0});var r4t=s(NI);uio=r(r4t,"MCTCTConfig"),r4t.forEach(t),pio=r(BSe," (M-CTC-T model)"),BSe.forEach(t),_io=i(L),Ig=n(L,"LI",{});var ISe=s(Ig);mce=n(ISe,"STRONG",{});var t4t=s(mce);vio=r(t4t,"megatron-bert"),t4t.forEach(t),bio=r(ISe," \u2014 "),qI=n(ISe,"A",{href:!0});var a4t=s(qI);Fio=r(a4t,"MegatronBertConfig"),a4t.forEach(t),Tio=r(ISe," (Megatron-BERT model)"),ISe.forEach(t),Mio=i(L),Ng=n(L,"LI",{});var NSe=s(Ng);gce=n(NSe,"STRONG",{});var n4t=s(gce);Eio=r(n4t,"mobilebert"),n4t.forEach(t),Cio=r(NSe," \u2014 "),jI=n(NSe,"A",{href:!0});var s4t=s(jI);wio=r(s4t,"MobileBertConfig"),s4t.forEach(t),Aio=r(NSe," (MobileBERT model)"),NSe.forEach(t),Lio=i(L),qg=n(L,"LI",{});var qSe=s(qg);hce=n(qSe,"STRONG",{});var l4t=s(hce);yio=r(l4t,"mobilevit"),l4t.forEach(t),xio=r(qSe," \u2014 "),DI=n(qSe,"A",{href:!0});var i4t=s(DI);$io=r(i4t,"MobileViTConfig"),i4t.forEach(t),kio=r(qSe," (MobileViT model)"),qSe.forEach(t),Sio=i(L),jg=n(L,"LI",{});var jSe=s(jg);uce=n(jSe,"STRONG",{});var d4t=s(uce);Rio=r(d4t,"mpnet"),d4t.forEach(t),Pio=r(jSe," \u2014 "),GI=n(jSe,"A",{href:!0});var c4t=s(GI);Bio=r(c4t,"MPNetConfig"),c4t.forEach(t),Iio=r(jSe," (MPNet model)"),jSe.forEach(t),Nio=i(L),Dg=n(L,"LI",{});var DSe=s(Dg);pce=n(DSe,"STRONG",{});var f4t=s(pce);qio=r(f4t,"mt5"),f4t.forEach(t),jio=r(DSe," \u2014 "),OI=n(DSe,"A",{href:!0});var m4t=s(OI);Dio=r(m4t,"MT5Config"),m4t.forEach(t),Gio=r(DSe," (MT5 model)"),DSe.forEach(t),Oio=i(L),Gg=n(L,"LI",{});var GSe=s(Gg);_ce=n(GSe,"STRONG",{});var g4t=s(_ce);Vio=r(g4t,"mvp"),g4t.forEach(t),Xio=r(GSe," \u2014 "),VI=n(GSe,"A",{href:!0});var h4t=s(VI);zio=r(h4t,"MvpConfig"),h4t.forEach(t),Qio=r(GSe," (MVP model)"),GSe.forEach(t),Wio=i(L),Og=n(L,"LI",{});var OSe=s(Og);vce=n(OSe,"STRONG",{});var u4t=s(vce);Uio=r(u4t,"nezha"),u4t.forEach(t),Hio=r(OSe," \u2014 "),XI=n(OSe,"A",{href:!0});var p4t=s(XI);Jio=r(p4t,"NezhaConfig"),p4t.forEach(t),Yio=r(OSe," (Nezha model)"),OSe.forEach(t),Kio=i(L),Vg=n(L,"LI",{});var VSe=s(Vg);bce=n(VSe,"STRONG",{});var _4t=s(bce);Zio=r(_4t,"nystromformer"),_4t.forEach(t),edo=r(VSe," \u2014 "),zI=n(VSe,"A",{href:!0});var v4t=s(zI);odo=r(v4t,"NystromformerConfig"),v4t.forEach(t),rdo=r(VSe," (Nystr\xF6mformer model)"),VSe.forEach(t),tdo=i(L),Xg=n(L,"LI",{});var XSe=s(Xg);Fce=n(XSe,"STRONG",{});var b4t=s(Fce);ado=r(b4t,"openai-gpt"),b4t.forEach(t),ndo=r(XSe," \u2014 "),QI=n(XSe,"A",{href:!0});var F4t=s(QI);sdo=r(F4t,"OpenAIGPTConfig"),F4t.forEach(t),ldo=r(XSe," (OpenAI GPT model)"),XSe.forEach(t),ido=i(L),zg=n(L,"LI",{});var zSe=s(zg);Tce=n(zSe,"STRONG",{});var T4t=s(Tce);ddo=r(T4t,"opt"),T4t.forEach(t),cdo=r(zSe," \u2014 "),WI=n(zSe,"A",{href:!0});var M4t=s(WI);fdo=r(M4t,"OPTConfig"),M4t.forEach(t),mdo=r(zSe," (OPT model)"),zSe.forEach(t),gdo=i(L),Qg=n(L,"LI",{});var QSe=s(Qg);Mce=n(QSe,"STRONG",{});var E4t=s(Mce);hdo=r(E4t,"owlvit"),E4t.forEach(t),udo=r(QSe," \u2014 "),UI=n(QSe,"A",{href:!0});var C4t=s(UI);pdo=r(C4t,"OwlViTConfig"),C4t.forEach(t),_do=r(QSe," (OWL-ViT model)"),QSe.forEach(t),vdo=i(L),Wg=n(L,"LI",{});var WSe=s(Wg);Ece=n(WSe,"STRONG",{});var w4t=s(Ece);bdo=r(w4t,"pegasus"),w4t.forEach(t),Fdo=r(WSe," \u2014 "),HI=n(WSe,"A",{href:!0});var A4t=s(HI);Tdo=r(A4t,"PegasusConfig"),A4t.forEach(t),Mdo=r(WSe," (Pegasus model)"),WSe.forEach(t),Edo=i(L),Ug=n(L,"LI",{});var USe=s(Ug);Cce=n(USe,"STRONG",{});var L4t=s(Cce);Cdo=r(L4t,"pegasus_x"),L4t.forEach(t),wdo=r(USe," \u2014 "),JI=n(USe,"A",{href:!0});var y4t=s(JI);Ado=r(y4t,"PegasusXConfig"),y4t.forEach(t),Ldo=r(USe," (PEGASUS-X model)"),USe.forEach(t),ydo=i(L),Hg=n(L,"LI",{});var HSe=s(Hg);wce=n(HSe,"STRONG",{});var x4t=s(wce);xdo=r(x4t,"perceiver"),x4t.forEach(t),$do=r(HSe," \u2014 "),YI=n(HSe,"A",{href:!0});var $4t=s(YI);kdo=r($4t,"PerceiverConfig"),$4t.forEach(t),Sdo=r(HSe," (Perceiver model)"),HSe.forEach(t),Rdo=i(L),Jg=n(L,"LI",{});var JSe=s(Jg);Ace=n(JSe,"STRONG",{});var k4t=s(Ace);Pdo=r(k4t,"plbart"),k4t.forEach(t),Bdo=r(JSe," \u2014 "),KI=n(JSe,"A",{href:!0});var S4t=s(KI);Ido=r(S4t,"PLBartConfig"),S4t.forEach(t),Ndo=r(JSe," (PLBart model)"),JSe.forEach(t),qdo=i(L),Yg=n(L,"LI",{});var YSe=s(Yg);Lce=n(YSe,"STRONG",{});var R4t=s(Lce);jdo=r(R4t,"poolformer"),R4t.forEach(t),Ddo=r(YSe," \u2014 "),ZI=n(YSe,"A",{href:!0});var P4t=s(ZI);Gdo=r(P4t,"PoolFormerConfig"),P4t.forEach(t),Odo=r(YSe," (PoolFormer model)"),YSe.forEach(t),Vdo=i(L),Kg=n(L,"LI",{});var KSe=s(Kg);yce=n(KSe,"STRONG",{});var B4t=s(yce);Xdo=r(B4t,"prophetnet"),B4t.forEach(t),zdo=r(KSe," \u2014 "),eN=n(KSe,"A",{href:!0});var I4t=s(eN);Qdo=r(I4t,"ProphetNetConfig"),I4t.forEach(t),Wdo=r(KSe," (ProphetNet model)"),KSe.forEach(t),Udo=i(L),Zg=n(L,"LI",{});var ZSe=s(Zg);xce=n(ZSe,"STRONG",{});var N4t=s(xce);Hdo=r(N4t,"qdqbert"),N4t.forEach(t),Jdo=r(ZSe," \u2014 "),oN=n(ZSe,"A",{href:!0});var q4t=s(oN);Ydo=r(q4t,"QDQBertConfig"),q4t.forEach(t),Kdo=r(ZSe," (QDQBert model)"),ZSe.forEach(t),Zdo=i(L),eh=n(L,"LI",{});var eRe=s(eh);$ce=n(eRe,"STRONG",{});var j4t=s($ce);eco=r(j4t,"rag"),j4t.forEach(t),oco=r(eRe," \u2014 "),rN=n(eRe,"A",{href:!0});var D4t=s(rN);rco=r(D4t,"RagConfig"),D4t.forEach(t),tco=r(eRe," (RAG model)"),eRe.forEach(t),aco=i(L),oh=n(L,"LI",{});var oRe=s(oh);kce=n(oRe,"STRONG",{});var G4t=s(kce);nco=r(G4t,"realm"),G4t.forEach(t),sco=r(oRe," \u2014 "),tN=n(oRe,"A",{href:!0});var O4t=s(tN);lco=r(O4t,"RealmConfig"),O4t.forEach(t),ico=r(oRe," (REALM model)"),oRe.forEach(t),dco=i(L),rh=n(L,"LI",{});var rRe=s(rh);Sce=n(rRe,"STRONG",{});var V4t=s(Sce);cco=r(V4t,"reformer"),V4t.forEach(t),fco=r(rRe," \u2014 "),aN=n(rRe,"A",{href:!0});var X4t=s(aN);mco=r(X4t,"ReformerConfig"),X4t.forEach(t),gco=r(rRe," (Reformer model)"),rRe.forEach(t),hco=i(L),th=n(L,"LI",{});var tRe=s(th);Rce=n(tRe,"STRONG",{});var z4t=s(Rce);uco=r(z4t,"regnet"),z4t.forEach(t),pco=r(tRe," \u2014 "),nN=n(tRe,"A",{href:!0});var Q4t=s(nN);_co=r(Q4t,"RegNetConfig"),Q4t.forEach(t),vco=r(tRe," (RegNet model)"),tRe.forEach(t),bco=i(L),ah=n(L,"LI",{});var aRe=s(ah);Pce=n(aRe,"STRONG",{});var W4t=s(Pce);Fco=r(W4t,"rembert"),W4t.forEach(t),Tco=r(aRe," \u2014 "),sN=n(aRe,"A",{href:!0});var U4t=s(sN);Mco=r(U4t,"RemBertConfig"),U4t.forEach(t),Eco=r(aRe," (RemBERT model)"),aRe.forEach(t),Cco=i(L),nh=n(L,"LI",{});var nRe=s(nh);Bce=n(nRe,"STRONG",{});var H4t=s(Bce);wco=r(H4t,"resnet"),H4t.forEach(t),Aco=r(nRe," \u2014 "),lN=n(nRe,"A",{href:!0});var J4t=s(lN);Lco=r(J4t,"ResNetConfig"),J4t.forEach(t),yco=r(nRe," (ResNet model)"),nRe.forEach(t),xco=i(L),sh=n(L,"LI",{});var sRe=s(sh);Ice=n(sRe,"STRONG",{});var Y4t=s(Ice);$co=r(Y4t,"retribert"),Y4t.forEach(t),kco=r(sRe," \u2014 "),iN=n(sRe,"A",{href:!0});var K4t=s(iN);Sco=r(K4t,"RetriBertConfig"),K4t.forEach(t),Rco=r(sRe," (RetriBERT model)"),sRe.forEach(t),Pco=i(L),lh=n(L,"LI",{});var lRe=s(lh);Nce=n(lRe,"STRONG",{});var Z4t=s(Nce);Bco=r(Z4t,"roberta"),Z4t.forEach(t),Ico=r(lRe," \u2014 "),dN=n(lRe,"A",{href:!0});var ebt=s(dN);Nco=r(ebt,"RobertaConfig"),ebt.forEach(t),qco=r(lRe," (RoBERTa model)"),lRe.forEach(t),jco=i(L),ih=n(L,"LI",{});var iRe=s(ih);qce=n(iRe,"STRONG",{});var obt=s(qce);Dco=r(obt,"roformer"),obt.forEach(t),Gco=r(iRe," \u2014 "),cN=n(iRe,"A",{href:!0});var rbt=s(cN);Oco=r(rbt,"RoFormerConfig"),rbt.forEach(t),Vco=r(iRe," (RoFormer model)"),iRe.forEach(t),Xco=i(L),dh=n(L,"LI",{});var dRe=s(dh);jce=n(dRe,"STRONG",{});var tbt=s(jce);zco=r(tbt,"segformer"),tbt.forEach(t),Qco=r(dRe," \u2014 "),fN=n(dRe,"A",{href:!0});var abt=s(fN);Wco=r(abt,"SegformerConfig"),abt.forEach(t),Uco=r(dRe," (SegFormer model)"),dRe.forEach(t),Hco=i(L),ch=n(L,"LI",{});var cRe=s(ch);Dce=n(cRe,"STRONG",{});var nbt=s(Dce);Jco=r(nbt,"sew"),nbt.forEach(t),Yco=r(cRe," \u2014 "),mN=n(cRe,"A",{href:!0});var sbt=s(mN);Kco=r(sbt,"SEWConfig"),sbt.forEach(t),Zco=r(cRe," (SEW model)"),cRe.forEach(t),efo=i(L),fh=n(L,"LI",{});var fRe=s(fh);Gce=n(fRe,"STRONG",{});var lbt=s(Gce);ofo=r(lbt,"sew-d"),lbt.forEach(t),rfo=r(fRe," \u2014 "),gN=n(fRe,"A",{href:!0});var ibt=s(gN);tfo=r(ibt,"SEWDConfig"),ibt.forEach(t),afo=r(fRe," (SEW-D model)"),fRe.forEach(t),nfo=i(L),mh=n(L,"LI",{});var mRe=s(mh);Oce=n(mRe,"STRONG",{});var dbt=s(Oce);sfo=r(dbt,"speech-encoder-decoder"),dbt.forEach(t),lfo=r(mRe," \u2014 "),hN=n(mRe,"A",{href:!0});var cbt=s(hN);ifo=r(cbt,"SpeechEncoderDecoderConfig"),cbt.forEach(t),dfo=r(mRe," (Speech Encoder decoder model)"),mRe.forEach(t),cfo=i(L),gh=n(L,"LI",{});var gRe=s(gh);Vce=n(gRe,"STRONG",{});var fbt=s(Vce);ffo=r(fbt,"speech_to_text"),fbt.forEach(t),mfo=r(gRe," \u2014 "),uN=n(gRe,"A",{href:!0});var mbt=s(uN);gfo=r(mbt,"Speech2TextConfig"),mbt.forEach(t),hfo=r(gRe," (Speech2Text model)"),gRe.forEach(t),ufo=i(L),hh=n(L,"LI",{});var hRe=s(hh);Xce=n(hRe,"STRONG",{});var gbt=s(Xce);pfo=r(gbt,"speech_to_text_2"),gbt.forEach(t),_fo=r(hRe," \u2014 "),pN=n(hRe,"A",{href:!0});var hbt=s(pN);vfo=r(hbt,"Speech2Text2Config"),hbt.forEach(t),bfo=r(hRe," (Speech2Text2 model)"),hRe.forEach(t),Ffo=i(L),uh=n(L,"LI",{});var uRe=s(uh);zce=n(uRe,"STRONG",{});var ubt=s(zce);Tfo=r(ubt,"splinter"),ubt.forEach(t),Mfo=r(uRe," \u2014 "),_N=n(uRe,"A",{href:!0});var pbt=s(_N);Efo=r(pbt,"SplinterConfig"),pbt.forEach(t),Cfo=r(uRe," (Splinter model)"),uRe.forEach(t),wfo=i(L),ph=n(L,"LI",{});var pRe=s(ph);Qce=n(pRe,"STRONG",{});var _bt=s(Qce);Afo=r(_bt,"squeezebert"),_bt.forEach(t),Lfo=r(pRe," \u2014 "),vN=n(pRe,"A",{href:!0});var vbt=s(vN);yfo=r(vbt,"SqueezeBertConfig"),vbt.forEach(t),xfo=r(pRe," (SqueezeBERT model)"),pRe.forEach(t),$fo=i(L),_h=n(L,"LI",{});var _Re=s(_h);Wce=n(_Re,"STRONG",{});var bbt=s(Wce);kfo=r(bbt,"swin"),bbt.forEach(t),Sfo=r(_Re," \u2014 "),bN=n(_Re,"A",{href:!0});var Fbt=s(bN);Rfo=r(Fbt,"SwinConfig"),Fbt.forEach(t),Pfo=r(_Re," (Swin Transformer model)"),_Re.forEach(t),Bfo=i(L),vh=n(L,"LI",{});var vRe=s(vh);Uce=n(vRe,"STRONG",{});var Tbt=s(Uce);Ifo=r(Tbt,"swinv2"),Tbt.forEach(t),Nfo=r(vRe," \u2014 "),FN=n(vRe,"A",{href:!0});var Mbt=s(FN);qfo=r(Mbt,"Swinv2Config"),Mbt.forEach(t),jfo=r(vRe," (Swin Transformer V2 model)"),vRe.forEach(t),Dfo=i(L),bh=n(L,"LI",{});var bRe=s(bh);Hce=n(bRe,"STRONG",{});var Ebt=s(Hce);Gfo=r(Ebt,"t5"),Ebt.forEach(t),Ofo=r(bRe," \u2014 "),TN=n(bRe,"A",{href:!0});var Cbt=s(TN);Vfo=r(Cbt,"T5Config"),Cbt.forEach(t),Xfo=r(bRe," (T5 model)"),bRe.forEach(t),zfo=i(L),Fh=n(L,"LI",{});var FRe=s(Fh);Jce=n(FRe,"STRONG",{});var wbt=s(Jce);Qfo=r(wbt,"tapas"),wbt.forEach(t),Wfo=r(FRe," \u2014 "),MN=n(FRe,"A",{href:!0});var Abt=s(MN);Ufo=r(Abt,"TapasConfig"),Abt.forEach(t),Hfo=r(FRe," (TAPAS model)"),FRe.forEach(t),Jfo=i(L),Th=n(L,"LI",{});var TRe=s(Th);Yce=n(TRe,"STRONG",{});var Lbt=s(Yce);Yfo=r(Lbt,"trajectory_transformer"),Lbt.forEach(t),Kfo=r(TRe," \u2014 "),EN=n(TRe,"A",{href:!0});var ybt=s(EN);Zfo=r(ybt,"TrajectoryTransformerConfig"),ybt.forEach(t),emo=r(TRe," (Trajectory Transformer model)"),TRe.forEach(t),omo=i(L),Mh=n(L,"LI",{});var MRe=s(Mh);Kce=n(MRe,"STRONG",{});var xbt=s(Kce);rmo=r(xbt,"transfo-xl"),xbt.forEach(t),tmo=r(MRe," \u2014 "),CN=n(MRe,"A",{href:!0});var $bt=s(CN);amo=r($bt,"TransfoXLConfig"),$bt.forEach(t),nmo=r(MRe," (Transformer-XL model)"),MRe.forEach(t),smo=i(L),Eh=n(L,"LI",{});var ERe=s(Eh);Zce=n(ERe,"STRONG",{});var kbt=s(Zce);lmo=r(kbt,"trocr"),kbt.forEach(t),imo=r(ERe," \u2014 "),wN=n(ERe,"A",{href:!0});var Sbt=s(wN);dmo=r(Sbt,"TrOCRConfig"),Sbt.forEach(t),cmo=r(ERe," (TrOCR model)"),ERe.forEach(t),fmo=i(L),Ch=n(L,"LI",{});var CRe=s(Ch);efe=n(CRe,"STRONG",{});var Rbt=s(efe);mmo=r(Rbt,"unispeech"),Rbt.forEach(t),gmo=r(CRe," \u2014 "),AN=n(CRe,"A",{href:!0});var Pbt=s(AN);hmo=r(Pbt,"UniSpeechConfig"),Pbt.forEach(t),umo=r(CRe," (UniSpeech model)"),CRe.forEach(t),pmo=i(L),wh=n(L,"LI",{});var wRe=s(wh);ofe=n(wRe,"STRONG",{});var Bbt=s(ofe);_mo=r(Bbt,"unispeech-sat"),Bbt.forEach(t),vmo=r(wRe," \u2014 "),LN=n(wRe,"A",{href:!0});var Ibt=s(LN);bmo=r(Ibt,"UniSpeechSatConfig"),Ibt.forEach(t),Fmo=r(wRe," (UniSpeechSat model)"),wRe.forEach(t),Tmo=i(L),Ah=n(L,"LI",{});var ARe=s(Ah);rfe=n(ARe,"STRONG",{});var Nbt=s(rfe);Mmo=r(Nbt,"van"),Nbt.forEach(t),Emo=r(ARe," \u2014 "),yN=n(ARe,"A",{href:!0});var qbt=s(yN);Cmo=r(qbt,"VanConfig"),qbt.forEach(t),wmo=r(ARe," (VAN model)"),ARe.forEach(t),Amo=i(L),Lh=n(L,"LI",{});var LRe=s(Lh);tfe=n(LRe,"STRONG",{});var jbt=s(tfe);Lmo=r(jbt,"videomae"),jbt.forEach(t),ymo=r(LRe," \u2014 "),xN=n(LRe,"A",{href:!0});var Dbt=s(xN);xmo=r(Dbt,"VideoMAEConfig"),Dbt.forEach(t),$mo=r(LRe," (VideoMAE model)"),LRe.forEach(t),kmo=i(L),yh=n(L,"LI",{});var yRe=s(yh);afe=n(yRe,"STRONG",{});var Gbt=s(afe);Smo=r(Gbt,"vilt"),Gbt.forEach(t),Rmo=r(yRe," \u2014 "),$N=n(yRe,"A",{href:!0});var Obt=s($N);Pmo=r(Obt,"ViltConfig"),Obt.forEach(t),Bmo=r(yRe," (ViLT model)"),yRe.forEach(t),Imo=i(L),xh=n(L,"LI",{});var xRe=s(xh);nfe=n(xRe,"STRONG",{});var Vbt=s(nfe);Nmo=r(Vbt,"vision-encoder-decoder"),Vbt.forEach(t),qmo=r(xRe," \u2014 "),kN=n(xRe,"A",{href:!0});var Xbt=s(kN);jmo=r(Xbt,"VisionEncoderDecoderConfig"),Xbt.forEach(t),Dmo=r(xRe," (Vision Encoder decoder model)"),xRe.forEach(t),Gmo=i(L),$h=n(L,"LI",{});var $Re=s($h);sfe=n($Re,"STRONG",{});var zbt=s(sfe);Omo=r(zbt,"vision-text-dual-encoder"),zbt.forEach(t),Vmo=r($Re," \u2014 "),SN=n($Re,"A",{href:!0});var Qbt=s(SN);Xmo=r(Qbt,"VisionTextDualEncoderConfig"),Qbt.forEach(t),zmo=r($Re," (VisionTextDualEncoder model)"),$Re.forEach(t),Qmo=i(L),kh=n(L,"LI",{});var kRe=s(kh);lfe=n(kRe,"STRONG",{});var Wbt=s(lfe);Wmo=r(Wbt,"visual_bert"),Wbt.forEach(t),Umo=r(kRe," \u2014 "),RN=n(kRe,"A",{href:!0});var Ubt=s(RN);Hmo=r(Ubt,"VisualBertConfig"),Ubt.forEach(t),Jmo=r(kRe," (VisualBERT model)"),kRe.forEach(t),Ymo=i(L),Sh=n(L,"LI",{});var SRe=s(Sh);ife=n(SRe,"STRONG",{});var Hbt=s(ife);Kmo=r(Hbt,"vit"),Hbt.forEach(t),Zmo=r(SRe," \u2014 "),PN=n(SRe,"A",{href:!0});var Jbt=s(PN);ego=r(Jbt,"ViTConfig"),Jbt.forEach(t),ogo=r(SRe," (ViT model)"),SRe.forEach(t),rgo=i(L),Rh=n(L,"LI",{});var RRe=s(Rh);dfe=n(RRe,"STRONG",{});var Ybt=s(dfe);tgo=r(Ybt,"vit_mae"),Ybt.forEach(t),ago=r(RRe," \u2014 "),BN=n(RRe,"A",{href:!0});var Kbt=s(BN);ngo=r(Kbt,"ViTMAEConfig"),Kbt.forEach(t),sgo=r(RRe," (ViTMAE model)"),RRe.forEach(t),lgo=i(L),Ph=n(L,"LI",{});var PRe=s(Ph);cfe=n(PRe,"STRONG",{});var Zbt=s(cfe);igo=r(Zbt,"wav2vec2"),Zbt.forEach(t),dgo=r(PRe," \u2014 "),IN=n(PRe,"A",{href:!0});var eFt=s(IN);cgo=r(eFt,"Wav2Vec2Config"),eFt.forEach(t),fgo=r(PRe," (Wav2Vec2 model)"),PRe.forEach(t),mgo=i(L),Bh=n(L,"LI",{});var BRe=s(Bh);ffe=n(BRe,"STRONG",{});var oFt=s(ffe);ggo=r(oFt,"wav2vec2-conformer"),oFt.forEach(t),hgo=r(BRe," \u2014 "),NN=n(BRe,"A",{href:!0});var rFt=s(NN);ugo=r(rFt,"Wav2Vec2ConformerConfig"),rFt.forEach(t),pgo=r(BRe," (Wav2Vec2-Conformer model)"),BRe.forEach(t),_go=i(L),Ih=n(L,"LI",{});var IRe=s(Ih);mfe=n(IRe,"STRONG",{});var tFt=s(mfe);vgo=r(tFt,"wavlm"),tFt.forEach(t),bgo=r(IRe," \u2014 "),qN=n(IRe,"A",{href:!0});var aFt=s(qN);Fgo=r(aFt,"WavLMConfig"),aFt.forEach(t),Tgo=r(IRe," (WavLM model)"),IRe.forEach(t),Mgo=i(L),Nh=n(L,"LI",{});var NRe=s(Nh);gfe=n(NRe,"STRONG",{});var nFt=s(gfe);Ego=r(nFt,"xclip"),nFt.forEach(t),Cgo=r(NRe," \u2014 "),jN=n(NRe,"A",{href:!0});var sFt=s(jN);wgo=r(sFt,"XCLIPConfig"),sFt.forEach(t),Ago=r(NRe," (X-CLIP model)"),NRe.forEach(t),Lgo=i(L),qh=n(L,"LI",{});var qRe=s(qh);hfe=n(qRe,"STRONG",{});var lFt=s(hfe);ygo=r(lFt,"xglm"),lFt.forEach(t),xgo=r(qRe," \u2014 "),DN=n(qRe,"A",{href:!0});var iFt=s(DN);$go=r(iFt,"XGLMConfig"),iFt.forEach(t),kgo=r(qRe," (XGLM model)"),qRe.forEach(t),Sgo=i(L),jh=n(L,"LI",{});var jRe=s(jh);ufe=n(jRe,"STRONG",{});var dFt=s(ufe);Rgo=r(dFt,"xlm"),dFt.forEach(t),Pgo=r(jRe," \u2014 "),GN=n(jRe,"A",{href:!0});var cFt=s(GN);Bgo=r(cFt,"XLMConfig"),cFt.forEach(t),Igo=r(jRe," (XLM model)"),jRe.forEach(t),Ngo=i(L),Dh=n(L,"LI",{});var DRe=s(Dh);pfe=n(DRe,"STRONG",{});var fFt=s(pfe);qgo=r(fFt,"xlm-prophetnet"),fFt.forEach(t),jgo=r(DRe," \u2014 "),ON=n(DRe,"A",{href:!0});var mFt=s(ON);Dgo=r(mFt,"XLMProphetNetConfig"),mFt.forEach(t),Ggo=r(DRe," (XLM-ProphetNet model)"),DRe.forEach(t),Ogo=i(L),Gh=n(L,"LI",{});var GRe=s(Gh);_fe=n(GRe,"STRONG",{});var gFt=s(_fe);Vgo=r(gFt,"xlm-roberta"),gFt.forEach(t),Xgo=r(GRe," \u2014 "),VN=n(GRe,"A",{href:!0});var hFt=s(VN);zgo=r(hFt,"XLMRobertaConfig"),hFt.forEach(t),Qgo=r(GRe," (XLM-RoBERTa model)"),GRe.forEach(t),Wgo=i(L),Oh=n(L,"LI",{});var ORe=s(Oh);vfe=n(ORe,"STRONG",{});var uFt=s(vfe);Ugo=r(uFt,"xlm-roberta-xl"),uFt.forEach(t),Hgo=r(ORe," \u2014 "),XN=n(ORe,"A",{href:!0});var pFt=s(XN);Jgo=r(pFt,"XLMRobertaXLConfig"),pFt.forEach(t),Ygo=r(ORe," (XLM-RoBERTa-XL model)"),ORe.forEach(t),Kgo=i(L),Vh=n(L,"LI",{});var VRe=s(Vh);bfe=n(VRe,"STRONG",{});var _Ft=s(bfe);Zgo=r(_Ft,"xlnet"),_Ft.forEach(t),eho=r(VRe," \u2014 "),zN=n(VRe,"A",{href:!0});var vFt=s(zN);oho=r(vFt,"XLNetConfig"),vFt.forEach(t),rho=r(VRe," (XLNet model)"),VRe.forEach(t),tho=i(L),Xh=n(L,"LI",{});var XRe=s(Xh);Ffe=n(XRe,"STRONG",{});var bFt=s(Ffe);aho=r(bFt,"yolos"),bFt.forEach(t),nho=r(XRe," \u2014 "),QN=n(XRe,"A",{href:!0});var FFt=s(QN);sho=r(FFt,"YolosConfig"),FFt.forEach(t),lho=r(XRe," (YOLOS model)"),XRe.forEach(t),iho=i(L),zh=n(L,"LI",{});var zRe=s(zh);Tfe=n(zRe,"STRONG",{});var TFt=s(Tfe);dho=r(TFt,"yoso"),TFt.forEach(t),cho=r(zRe," \u2014 "),WN=n(zRe,"A",{href:!0});var MFt=s(WN);fho=r(MFt,"YosoConfig"),MFt.forEach(t),mho=r(zRe," (YOSO model)"),zRe.forEach(t),L.forEach(t),gho=i(ut),T(Qh.$$.fragment,ut),ut.forEach(t),hho=i(ht),Wh=n(ht,"DIV",{class:!0});var zZe=s(Wh);T($9.$$.fragment,zZe),uho=i(zZe),Mfe=n(zZe,"P",{});var EFt=s(Mfe);pho=r(EFt,"Register a new configuration for this class."),EFt.forEach(t),zZe.forEach(t),ht.forEach(t),qYe=i(f),md=n(f,"H2",{class:!0});var QZe=s(md);Uh=n(QZe,"A",{id:!0,class:!0,href:!0});var CFt=s(Uh);Efe=n(CFt,"SPAN",{});var wFt=s(Efe);T(k9.$$.fragment,wFt),wFt.forEach(t),CFt.forEach(t),_ho=i(QZe),Cfe=n(QZe,"SPAN",{});var AFt=s(Cfe);vho=r(AFt,"AutoTokenizer"),AFt.forEach(t),QZe.forEach(t),jYe=i(f),ko=n(f,"DIV",{class:!0});var Tl=s(ko);T(S9.$$.fragment,Tl),bho=i(Tl),R9=n(Tl,"P",{});var WZe=s(R9);Fho=r(WZe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UN=n(WZe,"A",{href:!0});var LFt=s(UN);Tho=r(LFt,"AutoTokenizer.from_pretrained()"),LFt.forEach(t),Mho=r(WZe," class method."),WZe.forEach(t),Eho=i(Tl),P9=n(Tl,"P",{});var UZe=s(P9);Cho=r(UZe,"This class cannot be instantiated directly using "),wfe=n(UZe,"CODE",{});var yFt=s(wfe);who=r(yFt,"__init__()"),yFt.forEach(t),Aho=r(UZe," (throws an error)."),UZe.forEach(t),Lho=i(Tl),Br=n(Tl,"DIV",{class:!0});var Ml=s(Br);T(B9.$$.fragment,Ml),yho=i(Ml),Afe=n(Ml,"P",{});var xFt=s(Afe);xho=r(xFt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),xFt.forEach(t),$ho=i(Ml),Ua=n(Ml,"P",{});var py=s(Ua);kho=r(py,"The tokenizer class to instantiate is selected based on the "),Lfe=n(py,"CODE",{});var $Ft=s(Lfe);Sho=r($Ft,"model_type"),$Ft.forEach(t),Rho=r(py,` property of the config object (either
passed as an argument or loaded from `),yfe=n(py,"CODE",{});var kFt=s(yfe);Pho=r(kFt,"pretrained_model_name_or_path"),kFt.forEach(t),Bho=r(py,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xfe=n(py,"CODE",{});var SFt=s(xfe);Iho=r(SFt,"pretrained_model_name_or_path"),SFt.forEach(t),Nho=r(py,":"),py.forEach(t),qho=i(Ml),k=n(Ml,"UL",{});var S=s(k);as=n(S,"LI",{});var lP=s(as);$fe=n(lP,"STRONG",{});var RFt=s($fe);jho=r(RFt,"albert"),RFt.forEach(t),Dho=r(lP," \u2014 "),HN=n(lP,"A",{href:!0});var PFt=s(HN);Gho=r(PFt,"AlbertTokenizer"),PFt.forEach(t),Oho=r(lP," or "),JN=n(lP,"A",{href:!0});var BFt=s(JN);Vho=r(BFt,"AlbertTokenizerFast"),BFt.forEach(t),Xho=r(lP," (ALBERT model)"),lP.forEach(t),zho=i(S),ns=n(S,"LI",{});var iP=s(ns);kfe=n(iP,"STRONG",{});var IFt=s(kfe);Qho=r(IFt,"bart"),IFt.forEach(t),Who=r(iP," \u2014 "),YN=n(iP,"A",{href:!0});var NFt=s(YN);Uho=r(NFt,"BartTokenizer"),NFt.forEach(t),Hho=r(iP," or "),KN=n(iP,"A",{href:!0});var qFt=s(KN);Jho=r(qFt,"BartTokenizerFast"),qFt.forEach(t),Yho=r(iP," (BART model)"),iP.forEach(t),Kho=i(S),ss=n(S,"LI",{});var dP=s(ss);Sfe=n(dP,"STRONG",{});var jFt=s(Sfe);Zho=r(jFt,"barthez"),jFt.forEach(t),euo=r(dP," \u2014 "),ZN=n(dP,"A",{href:!0});var DFt=s(ZN);ouo=r(DFt,"BarthezTokenizer"),DFt.forEach(t),ruo=r(dP," or "),eq=n(dP,"A",{href:!0});var GFt=s(eq);tuo=r(GFt,"BarthezTokenizerFast"),GFt.forEach(t),auo=r(dP," (BARThez model)"),dP.forEach(t),nuo=i(S),Hh=n(S,"LI",{});var QRe=s(Hh);Rfe=n(QRe,"STRONG",{});var OFt=s(Rfe);suo=r(OFt,"bartpho"),OFt.forEach(t),luo=r(QRe," \u2014 "),oq=n(QRe,"A",{href:!0});var VFt=s(oq);iuo=r(VFt,"BartphoTokenizer"),VFt.forEach(t),duo=r(QRe," (BARTpho model)"),QRe.forEach(t),cuo=i(S),ls=n(S,"LI",{});var cP=s(ls);Pfe=n(cP,"STRONG",{});var XFt=s(Pfe);fuo=r(XFt,"bert"),XFt.forEach(t),muo=r(cP," \u2014 "),rq=n(cP,"A",{href:!0});var zFt=s(rq);guo=r(zFt,"BertTokenizer"),zFt.forEach(t),huo=r(cP," or "),tq=n(cP,"A",{href:!0});var QFt=s(tq);uuo=r(QFt,"BertTokenizerFast"),QFt.forEach(t),puo=r(cP," (BERT model)"),cP.forEach(t),_uo=i(S),Jh=n(S,"LI",{});var WRe=s(Jh);Bfe=n(WRe,"STRONG",{});var WFt=s(Bfe);vuo=r(WFt,"bert-generation"),WFt.forEach(t),buo=r(WRe," \u2014 "),aq=n(WRe,"A",{href:!0});var UFt=s(aq);Fuo=r(UFt,"BertGenerationTokenizer"),UFt.forEach(t),Tuo=r(WRe," (Bert Generation model)"),WRe.forEach(t),Muo=i(S),Yh=n(S,"LI",{});var URe=s(Yh);Ife=n(URe,"STRONG",{});var HFt=s(Ife);Euo=r(HFt,"bert-japanese"),HFt.forEach(t),Cuo=r(URe," \u2014 "),nq=n(URe,"A",{href:!0});var JFt=s(nq);wuo=r(JFt,"BertJapaneseTokenizer"),JFt.forEach(t),Auo=r(URe," (BertJapanese model)"),URe.forEach(t),Luo=i(S),Kh=n(S,"LI",{});var HRe=s(Kh);Nfe=n(HRe,"STRONG",{});var YFt=s(Nfe);yuo=r(YFt,"bertweet"),YFt.forEach(t),xuo=r(HRe," \u2014 "),sq=n(HRe,"A",{href:!0});var KFt=s(sq);$uo=r(KFt,"BertweetTokenizer"),KFt.forEach(t),kuo=r(HRe," (BERTweet model)"),HRe.forEach(t),Suo=i(S),is=n(S,"LI",{});var fP=s(is);qfe=n(fP,"STRONG",{});var ZFt=s(qfe);Ruo=r(ZFt,"big_bird"),ZFt.forEach(t),Puo=r(fP," \u2014 "),lq=n(fP,"A",{href:!0});var eTt=s(lq);Buo=r(eTt,"BigBirdTokenizer"),eTt.forEach(t),Iuo=r(fP," or "),iq=n(fP,"A",{href:!0});var oTt=s(iq);Nuo=r(oTt,"BigBirdTokenizerFast"),oTt.forEach(t),quo=r(fP," (BigBird model)"),fP.forEach(t),juo=i(S),ds=n(S,"LI",{});var mP=s(ds);jfe=n(mP,"STRONG",{});var rTt=s(jfe);Duo=r(rTt,"bigbird_pegasus"),rTt.forEach(t),Guo=r(mP," \u2014 "),dq=n(mP,"A",{href:!0});var tTt=s(dq);Ouo=r(tTt,"PegasusTokenizer"),tTt.forEach(t),Vuo=r(mP," or "),cq=n(mP,"A",{href:!0});var aTt=s(cq);Xuo=r(aTt,"PegasusTokenizerFast"),aTt.forEach(t),zuo=r(mP," (BigBird-Pegasus model)"),mP.forEach(t),Quo=i(S),cs=n(S,"LI",{});var gP=s(cs);Dfe=n(gP,"STRONG",{});var nTt=s(Dfe);Wuo=r(nTt,"blenderbot"),nTt.forEach(t),Uuo=r(gP," \u2014 "),fq=n(gP,"A",{href:!0});var sTt=s(fq);Huo=r(sTt,"BlenderbotTokenizer"),sTt.forEach(t),Juo=r(gP," or "),mq=n(gP,"A",{href:!0});var lTt=s(mq);Yuo=r(lTt,"BlenderbotTokenizerFast"),lTt.forEach(t),Kuo=r(gP," (Blenderbot model)"),gP.forEach(t),Zuo=i(S),Zh=n(S,"LI",{});var JRe=s(Zh);Gfe=n(JRe,"STRONG",{});var iTt=s(Gfe);epo=r(iTt,"blenderbot-small"),iTt.forEach(t),opo=r(JRe," \u2014 "),gq=n(JRe,"A",{href:!0});var dTt=s(gq);rpo=r(dTt,"BlenderbotSmallTokenizer"),dTt.forEach(t),tpo=r(JRe," (BlenderbotSmall model)"),JRe.forEach(t),apo=i(S),eu=n(S,"LI",{});var YRe=s(eu);Ofe=n(YRe,"STRONG",{});var cTt=s(Ofe);npo=r(cTt,"bloom"),cTt.forEach(t),spo=r(YRe," \u2014 "),hq=n(YRe,"A",{href:!0});var fTt=s(hq);lpo=r(fTt,"BloomTokenizerFast"),fTt.forEach(t),ipo=r(YRe," (BLOOM model)"),YRe.forEach(t),dpo=i(S),ou=n(S,"LI",{});var KRe=s(ou);Vfe=n(KRe,"STRONG",{});var mTt=s(Vfe);cpo=r(mTt,"byt5"),mTt.forEach(t),fpo=r(KRe," \u2014 "),uq=n(KRe,"A",{href:!0});var gTt=s(uq);mpo=r(gTt,"ByT5Tokenizer"),gTt.forEach(t),gpo=r(KRe," (ByT5 model)"),KRe.forEach(t),hpo=i(S),fs=n(S,"LI",{});var hP=s(fs);Xfe=n(hP,"STRONG",{});var hTt=s(Xfe);upo=r(hTt,"camembert"),hTt.forEach(t),ppo=r(hP," \u2014 "),pq=n(hP,"A",{href:!0});var uTt=s(pq);_po=r(uTt,"CamembertTokenizer"),uTt.forEach(t),vpo=r(hP," or "),_q=n(hP,"A",{href:!0});var pTt=s(_q);bpo=r(pTt,"CamembertTokenizerFast"),pTt.forEach(t),Fpo=r(hP," (CamemBERT model)"),hP.forEach(t),Tpo=i(S),ru=n(S,"LI",{});var ZRe=s(ru);zfe=n(ZRe,"STRONG",{});var _Tt=s(zfe);Mpo=r(_Tt,"canine"),_Tt.forEach(t),Epo=r(ZRe," \u2014 "),vq=n(ZRe,"A",{href:!0});var vTt=s(vq);Cpo=r(vTt,"CanineTokenizer"),vTt.forEach(t),wpo=r(ZRe," (CANINE model)"),ZRe.forEach(t),Apo=i(S),ms=n(S,"LI",{});var uP=s(ms);Qfe=n(uP,"STRONG",{});var bTt=s(Qfe);Lpo=r(bTt,"clip"),bTt.forEach(t),ypo=r(uP," \u2014 "),bq=n(uP,"A",{href:!0});var FTt=s(bq);xpo=r(FTt,"CLIPTokenizer"),FTt.forEach(t),$po=r(uP," or "),Fq=n(uP,"A",{href:!0});var TTt=s(Fq);kpo=r(TTt,"CLIPTokenizerFast"),TTt.forEach(t),Spo=r(uP," (CLIP model)"),uP.forEach(t),Rpo=i(S),gs=n(S,"LI",{});var pP=s(gs);Wfe=n(pP,"STRONG",{});var MTt=s(Wfe);Ppo=r(MTt,"codegen"),MTt.forEach(t),Bpo=r(pP," \u2014 "),Tq=n(pP,"A",{href:!0});var ETt=s(Tq);Ipo=r(ETt,"CodeGenTokenizer"),ETt.forEach(t),Npo=r(pP," or "),Mq=n(pP,"A",{href:!0});var CTt=s(Mq);qpo=r(CTt,"CodeGenTokenizerFast"),CTt.forEach(t),jpo=r(pP," (CodeGen model)"),pP.forEach(t),Dpo=i(S),hs=n(S,"LI",{});var _P=s(hs);Ufe=n(_P,"STRONG",{});var wTt=s(Ufe);Gpo=r(wTt,"convbert"),wTt.forEach(t),Opo=r(_P," \u2014 "),Eq=n(_P,"A",{href:!0});var ATt=s(Eq);Vpo=r(ATt,"ConvBertTokenizer"),ATt.forEach(t),Xpo=r(_P," or "),Cq=n(_P,"A",{href:!0});var LTt=s(Cq);zpo=r(LTt,"ConvBertTokenizerFast"),LTt.forEach(t),Qpo=r(_P," (ConvBERT model)"),_P.forEach(t),Wpo=i(S),us=n(S,"LI",{});var vP=s(us);Hfe=n(vP,"STRONG",{});var yTt=s(Hfe);Upo=r(yTt,"cpm"),yTt.forEach(t),Hpo=r(vP," \u2014 "),wq=n(vP,"A",{href:!0});var xTt=s(wq);Jpo=r(xTt,"CpmTokenizer"),xTt.forEach(t),Ypo=r(vP," or "),Aq=n(vP,"A",{href:!0});var $Tt=s(Aq);Kpo=r($Tt,"CpmTokenizerFast"),$Tt.forEach(t),Zpo=r(vP," (CPM model)"),vP.forEach(t),e_o=i(S),tu=n(S,"LI",{});var ePe=s(tu);Jfe=n(ePe,"STRONG",{});var kTt=s(Jfe);o_o=r(kTt,"ctrl"),kTt.forEach(t),r_o=r(ePe," \u2014 "),Lq=n(ePe,"A",{href:!0});var STt=s(Lq);t_o=r(STt,"CTRLTokenizer"),STt.forEach(t),a_o=r(ePe," (CTRL model)"),ePe.forEach(t),n_o=i(S),ps=n(S,"LI",{});var bP=s(ps);Yfe=n(bP,"STRONG",{});var RTt=s(Yfe);s_o=r(RTt,"data2vec-text"),RTt.forEach(t),l_o=r(bP," \u2014 "),yq=n(bP,"A",{href:!0});var PTt=s(yq);i_o=r(PTt,"RobertaTokenizer"),PTt.forEach(t),d_o=r(bP," or "),xq=n(bP,"A",{href:!0});var BTt=s(xq);c_o=r(BTt,"RobertaTokenizerFast"),BTt.forEach(t),f_o=r(bP," (Data2VecText model)"),bP.forEach(t),m_o=i(S),_s=n(S,"LI",{});var FP=s(_s);Kfe=n(FP,"STRONG",{});var ITt=s(Kfe);g_o=r(ITt,"deberta"),ITt.forEach(t),h_o=r(FP," \u2014 "),$q=n(FP,"A",{href:!0});var NTt=s($q);u_o=r(NTt,"DebertaTokenizer"),NTt.forEach(t),p_o=r(FP," or "),kq=n(FP,"A",{href:!0});var qTt=s(kq);__o=r(qTt,"DebertaTokenizerFast"),qTt.forEach(t),v_o=r(FP," (DeBERTa model)"),FP.forEach(t),b_o=i(S),vs=n(S,"LI",{});var TP=s(vs);Zfe=n(TP,"STRONG",{});var jTt=s(Zfe);F_o=r(jTt,"deberta-v2"),jTt.forEach(t),T_o=r(TP," \u2014 "),Sq=n(TP,"A",{href:!0});var DTt=s(Sq);M_o=r(DTt,"DebertaV2Tokenizer"),DTt.forEach(t),E_o=r(TP," or "),Rq=n(TP,"A",{href:!0});var GTt=s(Rq);C_o=r(GTt,"DebertaV2TokenizerFast"),GTt.forEach(t),w_o=r(TP," (DeBERTa-v2 model)"),TP.forEach(t),A_o=i(S),bs=n(S,"LI",{});var MP=s(bs);eme=n(MP,"STRONG",{});var OTt=s(eme);L_o=r(OTt,"distilbert"),OTt.forEach(t),y_o=r(MP," \u2014 "),Pq=n(MP,"A",{href:!0});var VTt=s(Pq);x_o=r(VTt,"DistilBertTokenizer"),VTt.forEach(t),$_o=r(MP," or "),Bq=n(MP,"A",{href:!0});var XTt=s(Bq);k_o=r(XTt,"DistilBertTokenizerFast"),XTt.forEach(t),S_o=r(MP," (DistilBERT model)"),MP.forEach(t),R_o=i(S),Fs=n(S,"LI",{});var EP=s(Fs);ome=n(EP,"STRONG",{});var zTt=s(ome);P_o=r(zTt,"dpr"),zTt.forEach(t),B_o=r(EP," \u2014 "),Iq=n(EP,"A",{href:!0});var QTt=s(Iq);I_o=r(QTt,"DPRQuestionEncoderTokenizer"),QTt.forEach(t),N_o=r(EP," or "),Nq=n(EP,"A",{href:!0});var WTt=s(Nq);q_o=r(WTt,"DPRQuestionEncoderTokenizerFast"),WTt.forEach(t),j_o=r(EP," (DPR model)"),EP.forEach(t),D_o=i(S),Ts=n(S,"LI",{});var CP=s(Ts);rme=n(CP,"STRONG",{});var UTt=s(rme);G_o=r(UTt,"electra"),UTt.forEach(t),O_o=r(CP," \u2014 "),qq=n(CP,"A",{href:!0});var HTt=s(qq);V_o=r(HTt,"ElectraTokenizer"),HTt.forEach(t),X_o=r(CP," or "),jq=n(CP,"A",{href:!0});var JTt=s(jq);z_o=r(JTt,"ElectraTokenizerFast"),JTt.forEach(t),Q_o=r(CP," (ELECTRA model)"),CP.forEach(t),W_o=i(S),Ms=n(S,"LI",{});var wP=s(Ms);tme=n(wP,"STRONG",{});var YTt=s(tme);U_o=r(YTt,"ernie"),YTt.forEach(t),H_o=r(wP," \u2014 "),Dq=n(wP,"A",{href:!0});var KTt=s(Dq);J_o=r(KTt,"BertTokenizer"),KTt.forEach(t),Y_o=r(wP," or "),Gq=n(wP,"A",{href:!0});var ZTt=s(Gq);K_o=r(ZTt,"BertTokenizerFast"),ZTt.forEach(t),Z_o=r(wP," (ERNIE model)"),wP.forEach(t),e2o=i(S),au=n(S,"LI",{});var oPe=s(au);ame=n(oPe,"STRONG",{});var eMt=s(ame);o2o=r(eMt,"flaubert"),eMt.forEach(t),r2o=r(oPe," \u2014 "),Oq=n(oPe,"A",{href:!0});var oMt=s(Oq);t2o=r(oMt,"FlaubertTokenizer"),oMt.forEach(t),a2o=r(oPe," (FlauBERT model)"),oPe.forEach(t),n2o=i(S),Es=n(S,"LI",{});var AP=s(Es);nme=n(AP,"STRONG",{});var rMt=s(nme);s2o=r(rMt,"fnet"),rMt.forEach(t),l2o=r(AP," \u2014 "),Vq=n(AP,"A",{href:!0});var tMt=s(Vq);i2o=r(tMt,"FNetTokenizer"),tMt.forEach(t),d2o=r(AP," or "),Xq=n(AP,"A",{href:!0});var aMt=s(Xq);c2o=r(aMt,"FNetTokenizerFast"),aMt.forEach(t),f2o=r(AP," (FNet model)"),AP.forEach(t),m2o=i(S),nu=n(S,"LI",{});var rPe=s(nu);sme=n(rPe,"STRONG",{});var nMt=s(sme);g2o=r(nMt,"fsmt"),nMt.forEach(t),h2o=r(rPe," \u2014 "),zq=n(rPe,"A",{href:!0});var sMt=s(zq);u2o=r(sMt,"FSMTTokenizer"),sMt.forEach(t),p2o=r(rPe," (FairSeq Machine-Translation model)"),rPe.forEach(t),_2o=i(S),Cs=n(S,"LI",{});var LP=s(Cs);lme=n(LP,"STRONG",{});var lMt=s(lme);v2o=r(lMt,"funnel"),lMt.forEach(t),b2o=r(LP," \u2014 "),Qq=n(LP,"A",{href:!0});var iMt=s(Qq);F2o=r(iMt,"FunnelTokenizer"),iMt.forEach(t),T2o=r(LP," or "),Wq=n(LP,"A",{href:!0});var dMt=s(Wq);M2o=r(dMt,"FunnelTokenizerFast"),dMt.forEach(t),E2o=r(LP," (Funnel Transformer model)"),LP.forEach(t),C2o=i(S),ws=n(S,"LI",{});var yP=s(ws);ime=n(yP,"STRONG",{});var cMt=s(ime);w2o=r(cMt,"gpt2"),cMt.forEach(t),A2o=r(yP," \u2014 "),Uq=n(yP,"A",{href:!0});var fMt=s(Uq);L2o=r(fMt,"GPT2Tokenizer"),fMt.forEach(t),y2o=r(yP," or "),Hq=n(yP,"A",{href:!0});var mMt=s(Hq);x2o=r(mMt,"GPT2TokenizerFast"),mMt.forEach(t),$2o=r(yP," (OpenAI GPT-2 model)"),yP.forEach(t),k2o=i(S),As=n(S,"LI",{});var xP=s(As);dme=n(xP,"STRONG",{});var gMt=s(dme);S2o=r(gMt,"gpt_neo"),gMt.forEach(t),R2o=r(xP," \u2014 "),Jq=n(xP,"A",{href:!0});var hMt=s(Jq);P2o=r(hMt,"GPT2Tokenizer"),hMt.forEach(t),B2o=r(xP," or "),Yq=n(xP,"A",{href:!0});var uMt=s(Yq);I2o=r(uMt,"GPT2TokenizerFast"),uMt.forEach(t),N2o=r(xP," (GPT Neo model)"),xP.forEach(t),q2o=i(S),su=n(S,"LI",{});var tPe=s(su);cme=n(tPe,"STRONG",{});var pMt=s(cme);j2o=r(pMt,"gpt_neox"),pMt.forEach(t),D2o=r(tPe," \u2014 "),Kq=n(tPe,"A",{href:!0});var _Mt=s(Kq);G2o=r(_Mt,"GPTNeoXTokenizerFast"),_Mt.forEach(t),O2o=r(tPe," (GPT NeoX model)"),tPe.forEach(t),V2o=i(S),Ls=n(S,"LI",{});var $P=s(Ls);fme=n($P,"STRONG",{});var vMt=s(fme);X2o=r(vMt,"gptj"),vMt.forEach(t),z2o=r($P," \u2014 "),Zq=n($P,"A",{href:!0});var bMt=s(Zq);Q2o=r(bMt,"GPT2Tokenizer"),bMt.forEach(t),W2o=r($P," or "),ej=n($P,"A",{href:!0});var FMt=s(ej);U2o=r(FMt,"GPT2TokenizerFast"),FMt.forEach(t),H2o=r($P," (GPT-J model)"),$P.forEach(t),J2o=i(S),ys=n(S,"LI",{});var kP=s(ys);mme=n(kP,"STRONG",{});var TMt=s(mme);Y2o=r(TMt,"groupvit"),TMt.forEach(t),K2o=r(kP," \u2014 "),oj=n(kP,"A",{href:!0});var MMt=s(oj);Z2o=r(MMt,"CLIPTokenizer"),MMt.forEach(t),evo=r(kP," or "),rj=n(kP,"A",{href:!0});var EMt=s(rj);ovo=r(EMt,"CLIPTokenizerFast"),EMt.forEach(t),rvo=r(kP," (GroupViT model)"),kP.forEach(t),tvo=i(S),xs=n(S,"LI",{});var SP=s(xs);gme=n(SP,"STRONG",{});var CMt=s(gme);avo=r(CMt,"herbert"),CMt.forEach(t),nvo=r(SP," \u2014 "),tj=n(SP,"A",{href:!0});var wMt=s(tj);svo=r(wMt,"HerbertTokenizer"),wMt.forEach(t),lvo=r(SP," or "),aj=n(SP,"A",{href:!0});var AMt=s(aj);ivo=r(AMt,"HerbertTokenizerFast"),AMt.forEach(t),dvo=r(SP," (HerBERT model)"),SP.forEach(t),cvo=i(S),lu=n(S,"LI",{});var aPe=s(lu);hme=n(aPe,"STRONG",{});var LMt=s(hme);fvo=r(LMt,"hubert"),LMt.forEach(t),mvo=r(aPe," \u2014 "),nj=n(aPe,"A",{href:!0});var yMt=s(nj);gvo=r(yMt,"Wav2Vec2CTCTokenizer"),yMt.forEach(t),hvo=r(aPe," (Hubert model)"),aPe.forEach(t),uvo=i(S),$s=n(S,"LI",{});var RP=s($s);ume=n(RP,"STRONG",{});var xMt=s(ume);pvo=r(xMt,"ibert"),xMt.forEach(t),_vo=r(RP," \u2014 "),sj=n(RP,"A",{href:!0});var $Mt=s(sj);vvo=r($Mt,"RobertaTokenizer"),$Mt.forEach(t),bvo=r(RP," or "),lj=n(RP,"A",{href:!0});var kMt=s(lj);Fvo=r(kMt,"RobertaTokenizerFast"),kMt.forEach(t),Tvo=r(RP," (I-BERT model)"),RP.forEach(t),Mvo=i(S),ks=n(S,"LI",{});var PP=s(ks);pme=n(PP,"STRONG",{});var SMt=s(pme);Evo=r(SMt,"layoutlm"),SMt.forEach(t),Cvo=r(PP," \u2014 "),ij=n(PP,"A",{href:!0});var RMt=s(ij);wvo=r(RMt,"LayoutLMTokenizer"),RMt.forEach(t),Avo=r(PP," or "),dj=n(PP,"A",{href:!0});var PMt=s(dj);Lvo=r(PMt,"LayoutLMTokenizerFast"),PMt.forEach(t),yvo=r(PP," (LayoutLM model)"),PP.forEach(t),xvo=i(S),Ss=n(S,"LI",{});var BP=s(Ss);_me=n(BP,"STRONG",{});var BMt=s(_me);$vo=r(BMt,"layoutlmv2"),BMt.forEach(t),kvo=r(BP," \u2014 "),cj=n(BP,"A",{href:!0});var IMt=s(cj);Svo=r(IMt,"LayoutLMv2Tokenizer"),IMt.forEach(t),Rvo=r(BP," or "),fj=n(BP,"A",{href:!0});var NMt=s(fj);Pvo=r(NMt,"LayoutLMv2TokenizerFast"),NMt.forEach(t),Bvo=r(BP," (LayoutLMv2 model)"),BP.forEach(t),Ivo=i(S),Rs=n(S,"LI",{});var IP=s(Rs);vme=n(IP,"STRONG",{});var qMt=s(vme);Nvo=r(qMt,"layoutlmv3"),qMt.forEach(t),qvo=r(IP," \u2014 "),mj=n(IP,"A",{href:!0});var jMt=s(mj);jvo=r(jMt,"LayoutLMv3Tokenizer"),jMt.forEach(t),Dvo=r(IP," or "),gj=n(IP,"A",{href:!0});var DMt=s(gj);Gvo=r(DMt,"LayoutLMv3TokenizerFast"),DMt.forEach(t),Ovo=r(IP," (LayoutLMv3 model)"),IP.forEach(t),Vvo=i(S),Ps=n(S,"LI",{});var NP=s(Ps);bme=n(NP,"STRONG",{});var GMt=s(bme);Xvo=r(GMt,"layoutxlm"),GMt.forEach(t),zvo=r(NP," \u2014 "),hj=n(NP,"A",{href:!0});var OMt=s(hj);Qvo=r(OMt,"LayoutXLMTokenizer"),OMt.forEach(t),Wvo=r(NP," or "),uj=n(NP,"A",{href:!0});var VMt=s(uj);Uvo=r(VMt,"LayoutXLMTokenizerFast"),VMt.forEach(t),Hvo=r(NP," (LayoutXLM model)"),NP.forEach(t),Jvo=i(S),Bs=n(S,"LI",{});var qP=s(Bs);Fme=n(qP,"STRONG",{});var XMt=s(Fme);Yvo=r(XMt,"led"),XMt.forEach(t),Kvo=r(qP," \u2014 "),pj=n(qP,"A",{href:!0});var zMt=s(pj);Zvo=r(zMt,"LEDTokenizer"),zMt.forEach(t),e1o=r(qP," or "),_j=n(qP,"A",{href:!0});var QMt=s(_j);o1o=r(QMt,"LEDTokenizerFast"),QMt.forEach(t),r1o=r(qP," (LED model)"),qP.forEach(t),t1o=i(S),Is=n(S,"LI",{});var jP=s(Is);Tme=n(jP,"STRONG",{});var WMt=s(Tme);a1o=r(WMt,"longformer"),WMt.forEach(t),n1o=r(jP," \u2014 "),vj=n(jP,"A",{href:!0});var UMt=s(vj);s1o=r(UMt,"LongformerTokenizer"),UMt.forEach(t),l1o=r(jP," or "),bj=n(jP,"A",{href:!0});var HMt=s(bj);i1o=r(HMt,"LongformerTokenizerFast"),HMt.forEach(t),d1o=r(jP," (Longformer model)"),jP.forEach(t),c1o=i(S),Ns=n(S,"LI",{});var DP=s(Ns);Mme=n(DP,"STRONG",{});var JMt=s(Mme);f1o=r(JMt,"longt5"),JMt.forEach(t),m1o=r(DP," \u2014 "),Fj=n(DP,"A",{href:!0});var YMt=s(Fj);g1o=r(YMt,"T5Tokenizer"),YMt.forEach(t),h1o=r(DP," or "),Tj=n(DP,"A",{href:!0});var KMt=s(Tj);u1o=r(KMt,"T5TokenizerFast"),KMt.forEach(t),p1o=r(DP," (LongT5 model)"),DP.forEach(t),_1o=i(S),iu=n(S,"LI",{});var nPe=s(iu);Eme=n(nPe,"STRONG",{});var ZMt=s(Eme);v1o=r(ZMt,"luke"),ZMt.forEach(t),b1o=r(nPe," \u2014 "),Mj=n(nPe,"A",{href:!0});var eEt=s(Mj);F1o=r(eEt,"LukeTokenizer"),eEt.forEach(t),T1o=r(nPe," (LUKE model)"),nPe.forEach(t),M1o=i(S),qs=n(S,"LI",{});var GP=s(qs);Cme=n(GP,"STRONG",{});var oEt=s(Cme);E1o=r(oEt,"lxmert"),oEt.forEach(t),C1o=r(GP," \u2014 "),Ej=n(GP,"A",{href:!0});var rEt=s(Ej);w1o=r(rEt,"LxmertTokenizer"),rEt.forEach(t),A1o=r(GP," or "),Cj=n(GP,"A",{href:!0});var tEt=s(Cj);L1o=r(tEt,"LxmertTokenizerFast"),tEt.forEach(t),y1o=r(GP," (LXMERT model)"),GP.forEach(t),x1o=i(S),du=n(S,"LI",{});var sPe=s(du);wme=n(sPe,"STRONG",{});var aEt=s(wme);$1o=r(aEt,"m2m_100"),aEt.forEach(t),k1o=r(sPe," \u2014 "),wj=n(sPe,"A",{href:!0});var nEt=s(wj);S1o=r(nEt,"M2M100Tokenizer"),nEt.forEach(t),R1o=r(sPe," (M2M100 model)"),sPe.forEach(t),P1o=i(S),cu=n(S,"LI",{});var lPe=s(cu);Ame=n(lPe,"STRONG",{});var sEt=s(Ame);B1o=r(sEt,"marian"),sEt.forEach(t),I1o=r(lPe," \u2014 "),Aj=n(lPe,"A",{href:!0});var lEt=s(Aj);N1o=r(lEt,"MarianTokenizer"),lEt.forEach(t),q1o=r(lPe," (Marian model)"),lPe.forEach(t),j1o=i(S),js=n(S,"LI",{});var OP=s(js);Lme=n(OP,"STRONG",{});var iEt=s(Lme);D1o=r(iEt,"mbart"),iEt.forEach(t),G1o=r(OP," \u2014 "),Lj=n(OP,"A",{href:!0});var dEt=s(Lj);O1o=r(dEt,"MBartTokenizer"),dEt.forEach(t),V1o=r(OP," or "),yj=n(OP,"A",{href:!0});var cEt=s(yj);X1o=r(cEt,"MBartTokenizerFast"),cEt.forEach(t),z1o=r(OP," (mBART model)"),OP.forEach(t),Q1o=i(S),Ds=n(S,"LI",{});var VP=s(Ds);yme=n(VP,"STRONG",{});var fEt=s(yme);W1o=r(fEt,"mbart50"),fEt.forEach(t),U1o=r(VP," \u2014 "),xj=n(VP,"A",{href:!0});var mEt=s(xj);H1o=r(mEt,"MBart50Tokenizer"),mEt.forEach(t),J1o=r(VP," or "),$j=n(VP,"A",{href:!0});var gEt=s($j);Y1o=r(gEt,"MBart50TokenizerFast"),gEt.forEach(t),K1o=r(VP," (mBART-50 model)"),VP.forEach(t),Z1o=i(S),Gs=n(S,"LI",{});var XP=s(Gs);xme=n(XP,"STRONG",{});var hEt=s(xme);e4o=r(hEt,"megatron-bert"),hEt.forEach(t),o4o=r(XP," \u2014 "),kj=n(XP,"A",{href:!0});var uEt=s(kj);r4o=r(uEt,"BertTokenizer"),uEt.forEach(t),t4o=r(XP," or "),Sj=n(XP,"A",{href:!0});var pEt=s(Sj);a4o=r(pEt,"BertTokenizerFast"),pEt.forEach(t),n4o=r(XP," (Megatron-BERT model)"),XP.forEach(t),s4o=i(S),fu=n(S,"LI",{});var iPe=s(fu);$me=n(iPe,"STRONG",{});var _Et=s($me);l4o=r(_Et,"mluke"),_Et.forEach(t),i4o=r(iPe," \u2014 "),Rj=n(iPe,"A",{href:!0});var vEt=s(Rj);d4o=r(vEt,"MLukeTokenizer"),vEt.forEach(t),c4o=r(iPe," (mLUKE model)"),iPe.forEach(t),f4o=i(S),Os=n(S,"LI",{});var zP=s(Os);kme=n(zP,"STRONG",{});var bEt=s(kme);m4o=r(bEt,"mobilebert"),bEt.forEach(t),g4o=r(zP," \u2014 "),Pj=n(zP,"A",{href:!0});var FEt=s(Pj);h4o=r(FEt,"MobileBertTokenizer"),FEt.forEach(t),u4o=r(zP," or "),Bj=n(zP,"A",{href:!0});var TEt=s(Bj);p4o=r(TEt,"MobileBertTokenizerFast"),TEt.forEach(t),_4o=r(zP," (MobileBERT model)"),zP.forEach(t),v4o=i(S),Vs=n(S,"LI",{});var QP=s(Vs);Sme=n(QP,"STRONG",{});var MEt=s(Sme);b4o=r(MEt,"mpnet"),MEt.forEach(t),F4o=r(QP," \u2014 "),Ij=n(QP,"A",{href:!0});var EEt=s(Ij);T4o=r(EEt,"MPNetTokenizer"),EEt.forEach(t),M4o=r(QP," or "),Nj=n(QP,"A",{href:!0});var CEt=s(Nj);E4o=r(CEt,"MPNetTokenizerFast"),CEt.forEach(t),C4o=r(QP," (MPNet model)"),QP.forEach(t),w4o=i(S),Xs=n(S,"LI",{});var WP=s(Xs);Rme=n(WP,"STRONG",{});var wEt=s(Rme);A4o=r(wEt,"mt5"),wEt.forEach(t),L4o=r(WP," \u2014 "),qj=n(WP,"A",{href:!0});var AEt=s(qj);y4o=r(AEt,"MT5Tokenizer"),AEt.forEach(t),x4o=r(WP," or "),jj=n(WP,"A",{href:!0});var LEt=s(jj);$4o=r(LEt,"MT5TokenizerFast"),LEt.forEach(t),k4o=r(WP," (MT5 model)"),WP.forEach(t),S4o=i(S),zs=n(S,"LI",{});var UP=s(zs);Pme=n(UP,"STRONG",{});var yEt=s(Pme);R4o=r(yEt,"mvp"),yEt.forEach(t),P4o=r(UP," \u2014 "),Dj=n(UP,"A",{href:!0});var xEt=s(Dj);B4o=r(xEt,"MvpTokenizer"),xEt.forEach(t),I4o=r(UP," or "),Gj=n(UP,"A",{href:!0});var $Et=s(Gj);N4o=r($Et,"MvpTokenizerFast"),$Et.forEach(t),q4o=r(UP," (MVP model)"),UP.forEach(t),j4o=i(S),Qs=n(S,"LI",{});var HP=s(Qs);Bme=n(HP,"STRONG",{});var kEt=s(Bme);D4o=r(kEt,"nezha"),kEt.forEach(t),G4o=r(HP," \u2014 "),Oj=n(HP,"A",{href:!0});var SEt=s(Oj);O4o=r(SEt,"BertTokenizer"),SEt.forEach(t),V4o=r(HP," or "),Vj=n(HP,"A",{href:!0});var REt=s(Vj);X4o=r(REt,"BertTokenizerFast"),REt.forEach(t),z4o=r(HP," (Nezha model)"),HP.forEach(t),Q4o=i(S),Ws=n(S,"LI",{});var JP=s(Ws);Ime=n(JP,"STRONG",{});var PEt=s(Ime);W4o=r(PEt,"nllb"),PEt.forEach(t),U4o=r(JP," \u2014 "),Xj=n(JP,"A",{href:!0});var BEt=s(Xj);H4o=r(BEt,"NllbTokenizer"),BEt.forEach(t),J4o=r(JP," or "),zj=n(JP,"A",{href:!0});var IEt=s(zj);Y4o=r(IEt,"NllbTokenizerFast"),IEt.forEach(t),K4o=r(JP," (NLLB model)"),JP.forEach(t),Z4o=i(S),Us=n(S,"LI",{});var YP=s(Us);Nme=n(YP,"STRONG",{});var NEt=s(Nme);ebo=r(NEt,"nystromformer"),NEt.forEach(t),obo=r(YP," \u2014 "),Qj=n(YP,"A",{href:!0});var qEt=s(Qj);rbo=r(qEt,"AlbertTokenizer"),qEt.forEach(t),tbo=r(YP," or "),Wj=n(YP,"A",{href:!0});var jEt=s(Wj);abo=r(jEt,"AlbertTokenizerFast"),jEt.forEach(t),nbo=r(YP," (Nystr\xF6mformer model)"),YP.forEach(t),sbo=i(S),Hs=n(S,"LI",{});var KP=s(Hs);qme=n(KP,"STRONG",{});var DEt=s(qme);lbo=r(DEt,"openai-gpt"),DEt.forEach(t),ibo=r(KP," \u2014 "),Uj=n(KP,"A",{href:!0});var GEt=s(Uj);dbo=r(GEt,"OpenAIGPTTokenizer"),GEt.forEach(t),cbo=r(KP," or "),Hj=n(KP,"A",{href:!0});var OEt=s(Hj);fbo=r(OEt,"OpenAIGPTTokenizerFast"),OEt.forEach(t),mbo=r(KP," (OpenAI GPT model)"),KP.forEach(t),gbo=i(S),mu=n(S,"LI",{});var dPe=s(mu);jme=n(dPe,"STRONG",{});var VEt=s(jme);hbo=r(VEt,"opt"),VEt.forEach(t),ubo=r(dPe," \u2014 "),Jj=n(dPe,"A",{href:!0});var XEt=s(Jj);pbo=r(XEt,"GPT2Tokenizer"),XEt.forEach(t),_bo=r(dPe," (OPT model)"),dPe.forEach(t),vbo=i(S),Js=n(S,"LI",{});var ZP=s(Js);Dme=n(ZP,"STRONG",{});var zEt=s(Dme);bbo=r(zEt,"owlvit"),zEt.forEach(t),Fbo=r(ZP," \u2014 "),Yj=n(ZP,"A",{href:!0});var QEt=s(Yj);Tbo=r(QEt,"CLIPTokenizer"),QEt.forEach(t),Mbo=r(ZP," or "),Kj=n(ZP,"A",{href:!0});var WEt=s(Kj);Ebo=r(WEt,"CLIPTokenizerFast"),WEt.forEach(t),Cbo=r(ZP," (OWL-ViT model)"),ZP.forEach(t),wbo=i(S),Ys=n(S,"LI",{});var eB=s(Ys);Gme=n(eB,"STRONG",{});var UEt=s(Gme);Abo=r(UEt,"pegasus"),UEt.forEach(t),Lbo=r(eB," \u2014 "),Zj=n(eB,"A",{href:!0});var HEt=s(Zj);ybo=r(HEt,"PegasusTokenizer"),HEt.forEach(t),xbo=r(eB," or "),eD=n(eB,"A",{href:!0});var JEt=s(eD);$bo=r(JEt,"PegasusTokenizerFast"),JEt.forEach(t),kbo=r(eB," (Pegasus model)"),eB.forEach(t),Sbo=i(S),gu=n(S,"LI",{});var cPe=s(gu);Ome=n(cPe,"STRONG",{});var YEt=s(Ome);Rbo=r(YEt,"perceiver"),YEt.forEach(t),Pbo=r(cPe," \u2014 "),oD=n(cPe,"A",{href:!0});var KEt=s(oD);Bbo=r(KEt,"PerceiverTokenizer"),KEt.forEach(t),Ibo=r(cPe," (Perceiver model)"),cPe.forEach(t),Nbo=i(S),hu=n(S,"LI",{});var fPe=s(hu);Vme=n(fPe,"STRONG",{});var ZEt=s(Vme);qbo=r(ZEt,"phobert"),ZEt.forEach(t),jbo=r(fPe," \u2014 "),rD=n(fPe,"A",{href:!0});var eCt=s(rD);Dbo=r(eCt,"PhobertTokenizer"),eCt.forEach(t),Gbo=r(fPe," (PhoBERT model)"),fPe.forEach(t),Obo=i(S),uu=n(S,"LI",{});var mPe=s(uu);Xme=n(mPe,"STRONG",{});var oCt=s(Xme);Vbo=r(oCt,"plbart"),oCt.forEach(t),Xbo=r(mPe," \u2014 "),tD=n(mPe,"A",{href:!0});var rCt=s(tD);zbo=r(rCt,"PLBartTokenizer"),rCt.forEach(t),Qbo=r(mPe," (PLBart model)"),mPe.forEach(t),Wbo=i(S),pu=n(S,"LI",{});var gPe=s(pu);zme=n(gPe,"STRONG",{});var tCt=s(zme);Ubo=r(tCt,"prophetnet"),tCt.forEach(t),Hbo=r(gPe," \u2014 "),aD=n(gPe,"A",{href:!0});var aCt=s(aD);Jbo=r(aCt,"ProphetNetTokenizer"),aCt.forEach(t),Ybo=r(gPe," (ProphetNet model)"),gPe.forEach(t),Kbo=i(S),Ks=n(S,"LI",{});var oB=s(Ks);Qme=n(oB,"STRONG",{});var nCt=s(Qme);Zbo=r(nCt,"qdqbert"),nCt.forEach(t),eFo=r(oB," \u2014 "),nD=n(oB,"A",{href:!0});var sCt=s(nD);oFo=r(sCt,"BertTokenizer"),sCt.forEach(t),rFo=r(oB," or "),sD=n(oB,"A",{href:!0});var lCt=s(sD);tFo=r(lCt,"BertTokenizerFast"),lCt.forEach(t),aFo=r(oB," (QDQBert model)"),oB.forEach(t),nFo=i(S),_u=n(S,"LI",{});var hPe=s(_u);Wme=n(hPe,"STRONG",{});var iCt=s(Wme);sFo=r(iCt,"rag"),iCt.forEach(t),lFo=r(hPe," \u2014 "),lD=n(hPe,"A",{href:!0});var dCt=s(lD);iFo=r(dCt,"RagTokenizer"),dCt.forEach(t),dFo=r(hPe," (RAG model)"),hPe.forEach(t),cFo=i(S),Zs=n(S,"LI",{});var rB=s(Zs);Ume=n(rB,"STRONG",{});var cCt=s(Ume);fFo=r(cCt,"realm"),cCt.forEach(t),mFo=r(rB," \u2014 "),iD=n(rB,"A",{href:!0});var fCt=s(iD);gFo=r(fCt,"RealmTokenizer"),fCt.forEach(t),hFo=r(rB," or "),dD=n(rB,"A",{href:!0});var mCt=s(dD);uFo=r(mCt,"RealmTokenizerFast"),mCt.forEach(t),pFo=r(rB," (REALM model)"),rB.forEach(t),_Fo=i(S),el=n(S,"LI",{});var tB=s(el);Hme=n(tB,"STRONG",{});var gCt=s(Hme);vFo=r(gCt,"reformer"),gCt.forEach(t),bFo=r(tB," \u2014 "),cD=n(tB,"A",{href:!0});var hCt=s(cD);FFo=r(hCt,"ReformerTokenizer"),hCt.forEach(t),TFo=r(tB," or "),fD=n(tB,"A",{href:!0});var uCt=s(fD);MFo=r(uCt,"ReformerTokenizerFast"),uCt.forEach(t),EFo=r(tB," (Reformer model)"),tB.forEach(t),CFo=i(S),ol=n(S,"LI",{});var aB=s(ol);Jme=n(aB,"STRONG",{});var pCt=s(Jme);wFo=r(pCt,"rembert"),pCt.forEach(t),AFo=r(aB," \u2014 "),mD=n(aB,"A",{href:!0});var _Ct=s(mD);LFo=r(_Ct,"RemBertTokenizer"),_Ct.forEach(t),yFo=r(aB," or "),gD=n(aB,"A",{href:!0});var vCt=s(gD);xFo=r(vCt,"RemBertTokenizerFast"),vCt.forEach(t),$Fo=r(aB," (RemBERT model)"),aB.forEach(t),kFo=i(S),rl=n(S,"LI",{});var nB=s(rl);Yme=n(nB,"STRONG",{});var bCt=s(Yme);SFo=r(bCt,"retribert"),bCt.forEach(t),RFo=r(nB," \u2014 "),hD=n(nB,"A",{href:!0});var FCt=s(hD);PFo=r(FCt,"RetriBertTokenizer"),FCt.forEach(t),BFo=r(nB," or "),uD=n(nB,"A",{href:!0});var TCt=s(uD);IFo=r(TCt,"RetriBertTokenizerFast"),TCt.forEach(t),NFo=r(nB," (RetriBERT model)"),nB.forEach(t),qFo=i(S),tl=n(S,"LI",{});var sB=s(tl);Kme=n(sB,"STRONG",{});var MCt=s(Kme);jFo=r(MCt,"roberta"),MCt.forEach(t),DFo=r(sB," \u2014 "),pD=n(sB,"A",{href:!0});var ECt=s(pD);GFo=r(ECt,"RobertaTokenizer"),ECt.forEach(t),OFo=r(sB," or "),_D=n(sB,"A",{href:!0});var CCt=s(_D);VFo=r(CCt,"RobertaTokenizerFast"),CCt.forEach(t),XFo=r(sB," (RoBERTa model)"),sB.forEach(t),zFo=i(S),al=n(S,"LI",{});var lB=s(al);Zme=n(lB,"STRONG",{});var wCt=s(Zme);QFo=r(wCt,"roformer"),wCt.forEach(t),WFo=r(lB," \u2014 "),vD=n(lB,"A",{href:!0});var ACt=s(vD);UFo=r(ACt,"RoFormerTokenizer"),ACt.forEach(t),HFo=r(lB," or "),bD=n(lB,"A",{href:!0});var LCt=s(bD);JFo=r(LCt,"RoFormerTokenizerFast"),LCt.forEach(t),YFo=r(lB," (RoFormer model)"),lB.forEach(t),KFo=i(S),vu=n(S,"LI",{});var uPe=s(vu);ege=n(uPe,"STRONG",{});var yCt=s(ege);ZFo=r(yCt,"speech_to_text"),yCt.forEach(t),eTo=r(uPe," \u2014 "),FD=n(uPe,"A",{href:!0});var xCt=s(FD);oTo=r(xCt,"Speech2TextTokenizer"),xCt.forEach(t),rTo=r(uPe," (Speech2Text model)"),uPe.forEach(t),tTo=i(S),bu=n(S,"LI",{});var pPe=s(bu);oge=n(pPe,"STRONG",{});var $Ct=s(oge);aTo=r($Ct,"speech_to_text_2"),$Ct.forEach(t),nTo=r(pPe," \u2014 "),TD=n(pPe,"A",{href:!0});var kCt=s(TD);sTo=r(kCt,"Speech2Text2Tokenizer"),kCt.forEach(t),lTo=r(pPe," (Speech2Text2 model)"),pPe.forEach(t),iTo=i(S),nl=n(S,"LI",{});var iB=s(nl);rge=n(iB,"STRONG",{});var SCt=s(rge);dTo=r(SCt,"splinter"),SCt.forEach(t),cTo=r(iB," \u2014 "),MD=n(iB,"A",{href:!0});var RCt=s(MD);fTo=r(RCt,"SplinterTokenizer"),RCt.forEach(t),mTo=r(iB," or "),ED=n(iB,"A",{href:!0});var PCt=s(ED);gTo=r(PCt,"SplinterTokenizerFast"),PCt.forEach(t),hTo=r(iB," (Splinter model)"),iB.forEach(t),uTo=i(S),sl=n(S,"LI",{});var dB=s(sl);tge=n(dB,"STRONG",{});var BCt=s(tge);pTo=r(BCt,"squeezebert"),BCt.forEach(t),_To=r(dB," \u2014 "),CD=n(dB,"A",{href:!0});var ICt=s(CD);vTo=r(ICt,"SqueezeBertTokenizer"),ICt.forEach(t),bTo=r(dB," or "),wD=n(dB,"A",{href:!0});var NCt=s(wD);FTo=r(NCt,"SqueezeBertTokenizerFast"),NCt.forEach(t),TTo=r(dB," (SqueezeBERT model)"),dB.forEach(t),MTo=i(S),ll=n(S,"LI",{});var cB=s(ll);age=n(cB,"STRONG",{});var qCt=s(age);ETo=r(qCt,"t5"),qCt.forEach(t),CTo=r(cB," \u2014 "),AD=n(cB,"A",{href:!0});var jCt=s(AD);wTo=r(jCt,"T5Tokenizer"),jCt.forEach(t),ATo=r(cB," or "),LD=n(cB,"A",{href:!0});var DCt=s(LD);LTo=r(DCt,"T5TokenizerFast"),DCt.forEach(t),yTo=r(cB," (T5 model)"),cB.forEach(t),xTo=i(S),Fu=n(S,"LI",{});var _Pe=s(Fu);nge=n(_Pe,"STRONG",{});var GCt=s(nge);$To=r(GCt,"tapas"),GCt.forEach(t),kTo=r(_Pe," \u2014 "),yD=n(_Pe,"A",{href:!0});var OCt=s(yD);STo=r(OCt,"TapasTokenizer"),OCt.forEach(t),RTo=r(_Pe," (TAPAS model)"),_Pe.forEach(t),PTo=i(S),Tu=n(S,"LI",{});var vPe=s(Tu);sge=n(vPe,"STRONG",{});var VCt=s(sge);BTo=r(VCt,"tapex"),VCt.forEach(t),ITo=r(vPe," \u2014 "),xD=n(vPe,"A",{href:!0});var XCt=s(xD);NTo=r(XCt,"TapexTokenizer"),XCt.forEach(t),qTo=r(vPe," (TAPEX model)"),vPe.forEach(t),jTo=i(S),Mu=n(S,"LI",{});var bPe=s(Mu);lge=n(bPe,"STRONG",{});var zCt=s(lge);DTo=r(zCt,"transfo-xl"),zCt.forEach(t),GTo=r(bPe," \u2014 "),$D=n(bPe,"A",{href:!0});var QCt=s($D);OTo=r(QCt,"TransfoXLTokenizer"),QCt.forEach(t),VTo=r(bPe," (Transformer-XL model)"),bPe.forEach(t),XTo=i(S),il=n(S,"LI",{});var fB=s(il);ige=n(fB,"STRONG",{});var WCt=s(ige);zTo=r(WCt,"vilt"),WCt.forEach(t),QTo=r(fB," \u2014 "),kD=n(fB,"A",{href:!0});var UCt=s(kD);WTo=r(UCt,"BertTokenizer"),UCt.forEach(t),UTo=r(fB," or "),SD=n(fB,"A",{href:!0});var HCt=s(SD);HTo=r(HCt,"BertTokenizerFast"),HCt.forEach(t),JTo=r(fB," (ViLT model)"),fB.forEach(t),YTo=i(S),dl=n(S,"LI",{});var mB=s(dl);dge=n(mB,"STRONG",{});var JCt=s(dge);KTo=r(JCt,"visual_bert"),JCt.forEach(t),ZTo=r(mB," \u2014 "),RD=n(mB,"A",{href:!0});var YCt=s(RD);eMo=r(YCt,"BertTokenizer"),YCt.forEach(t),oMo=r(mB," or "),PD=n(mB,"A",{href:!0});var KCt=s(PD);rMo=r(KCt,"BertTokenizerFast"),KCt.forEach(t),tMo=r(mB," (VisualBERT model)"),mB.forEach(t),aMo=i(S),Eu=n(S,"LI",{});var FPe=s(Eu);cge=n(FPe,"STRONG",{});var ZCt=s(cge);nMo=r(ZCt,"wav2vec2"),ZCt.forEach(t),sMo=r(FPe," \u2014 "),BD=n(FPe,"A",{href:!0});var e3t=s(BD);lMo=r(e3t,"Wav2Vec2CTCTokenizer"),e3t.forEach(t),iMo=r(FPe," (Wav2Vec2 model)"),FPe.forEach(t),dMo=i(S),Cu=n(S,"LI",{});var TPe=s(Cu);fge=n(TPe,"STRONG",{});var o3t=s(fge);cMo=r(o3t,"wav2vec2-conformer"),o3t.forEach(t),fMo=r(TPe," \u2014 "),ID=n(TPe,"A",{href:!0});var r3t=s(ID);mMo=r(r3t,"Wav2Vec2CTCTokenizer"),r3t.forEach(t),gMo=r(TPe," (Wav2Vec2-Conformer model)"),TPe.forEach(t),hMo=i(S),wu=n(S,"LI",{});var MPe=s(wu);mge=n(MPe,"STRONG",{});var t3t=s(mge);uMo=r(t3t,"wav2vec2_phoneme"),t3t.forEach(t),pMo=r(MPe," \u2014 "),ND=n(MPe,"A",{href:!0});var a3t=s(ND);_Mo=r(a3t,"Wav2Vec2PhonemeCTCTokenizer"),a3t.forEach(t),vMo=r(MPe," (Wav2Vec2Phoneme model)"),MPe.forEach(t),bMo=i(S),cl=n(S,"LI",{});var gB=s(cl);gge=n(gB,"STRONG",{});var n3t=s(gge);FMo=r(n3t,"xclip"),n3t.forEach(t),TMo=r(gB," \u2014 "),qD=n(gB,"A",{href:!0});var s3t=s(qD);MMo=r(s3t,"CLIPTokenizer"),s3t.forEach(t),EMo=r(gB," or "),jD=n(gB,"A",{href:!0});var l3t=s(jD);CMo=r(l3t,"CLIPTokenizerFast"),l3t.forEach(t),wMo=r(gB," (X-CLIP model)"),gB.forEach(t),AMo=i(S),fl=n(S,"LI",{});var hB=s(fl);hge=n(hB,"STRONG",{});var i3t=s(hge);LMo=r(i3t,"xglm"),i3t.forEach(t),yMo=r(hB," \u2014 "),DD=n(hB,"A",{href:!0});var d3t=s(DD);xMo=r(d3t,"XGLMTokenizer"),d3t.forEach(t),$Mo=r(hB," or "),GD=n(hB,"A",{href:!0});var c3t=s(GD);kMo=r(c3t,"XGLMTokenizerFast"),c3t.forEach(t),SMo=r(hB," (XGLM model)"),hB.forEach(t),RMo=i(S),Au=n(S,"LI",{});var EPe=s(Au);uge=n(EPe,"STRONG",{});var f3t=s(uge);PMo=r(f3t,"xlm"),f3t.forEach(t),BMo=r(EPe," \u2014 "),OD=n(EPe,"A",{href:!0});var m3t=s(OD);IMo=r(m3t,"XLMTokenizer"),m3t.forEach(t),NMo=r(EPe," (XLM model)"),EPe.forEach(t),qMo=i(S),Lu=n(S,"LI",{});var CPe=s(Lu);pge=n(CPe,"STRONG",{});var g3t=s(pge);jMo=r(g3t,"xlm-prophetnet"),g3t.forEach(t),DMo=r(CPe," \u2014 "),VD=n(CPe,"A",{href:!0});var h3t=s(VD);GMo=r(h3t,"XLMProphetNetTokenizer"),h3t.forEach(t),OMo=r(CPe," (XLM-ProphetNet model)"),CPe.forEach(t),VMo=i(S),ml=n(S,"LI",{});var uB=s(ml);_ge=n(uB,"STRONG",{});var u3t=s(_ge);XMo=r(u3t,"xlm-roberta"),u3t.forEach(t),zMo=r(uB," \u2014 "),XD=n(uB,"A",{href:!0});var p3t=s(XD);QMo=r(p3t,"XLMRobertaTokenizer"),p3t.forEach(t),WMo=r(uB," or "),zD=n(uB,"A",{href:!0});var _3t=s(zD);UMo=r(_3t,"XLMRobertaTokenizerFast"),_3t.forEach(t),HMo=r(uB," (XLM-RoBERTa model)"),uB.forEach(t),JMo=i(S),gl=n(S,"LI",{});var pB=s(gl);vge=n(pB,"STRONG",{});var v3t=s(vge);YMo=r(v3t,"xlm-roberta-xl"),v3t.forEach(t),KMo=r(pB," \u2014 "),QD=n(pB,"A",{href:!0});var b3t=s(QD);ZMo=r(b3t,"XLMRobertaTokenizer"),b3t.forEach(t),eEo=r(pB," or "),WD=n(pB,"A",{href:!0});var F3t=s(WD);oEo=r(F3t,"XLMRobertaTokenizerFast"),F3t.forEach(t),rEo=r(pB," (XLM-RoBERTa-XL model)"),pB.forEach(t),tEo=i(S),hl=n(S,"LI",{});var _B=s(hl);bge=n(_B,"STRONG",{});var T3t=s(bge);aEo=r(T3t,"xlnet"),T3t.forEach(t),nEo=r(_B," \u2014 "),UD=n(_B,"A",{href:!0});var M3t=s(UD);sEo=r(M3t,"XLNetTokenizer"),M3t.forEach(t),lEo=r(_B," or "),HD=n(_B,"A",{href:!0});var E3t=s(HD);iEo=r(E3t,"XLNetTokenizerFast"),E3t.forEach(t),dEo=r(_B," (XLNet model)"),_B.forEach(t),cEo=i(S),ul=n(S,"LI",{});var vB=s(ul);Fge=n(vB,"STRONG",{});var C3t=s(Fge);fEo=r(C3t,"yoso"),C3t.forEach(t),mEo=r(vB," \u2014 "),JD=n(vB,"A",{href:!0});var w3t=s(JD);gEo=r(w3t,"AlbertTokenizer"),w3t.forEach(t),hEo=r(vB," or "),YD=n(vB,"A",{href:!0});var A3t=s(YD);uEo=r(A3t,"AlbertTokenizerFast"),A3t.forEach(t),pEo=r(vB," (YOSO model)"),vB.forEach(t),S.forEach(t),_Eo=i(Ml),T(yu.$$.fragment,Ml),Ml.forEach(t),vEo=i(Tl),xu=n(Tl,"DIV",{class:!0});var HZe=s(xu);T(I9.$$.fragment,HZe),bEo=i(HZe),Tge=n(HZe,"P",{});var L3t=s(Tge);FEo=r(L3t,"Register a new tokenizer in this mapping."),L3t.forEach(t),HZe.forEach(t),Tl.forEach(t),DYe=i(f),gd=n(f,"H2",{class:!0});var JZe=s(gd);$u=n(JZe,"A",{id:!0,class:!0,href:!0});var y3t=s($u);Mge=n(y3t,"SPAN",{});var x3t=s(Mge);T(N9.$$.fragment,x3t),x3t.forEach(t),y3t.forEach(t),TEo=i(JZe),Ege=n(JZe,"SPAN",{});var $3t=s(Ege);MEo=r($3t,"AutoFeatureExtractor"),$3t.forEach(t),JZe.forEach(t),GYe=i(f),So=n(f,"DIV",{class:!0});var El=s(So);T(q9.$$.fragment,El),EEo=i(El),j9=n(El,"P",{});var YZe=s(j9);CEo=r(YZe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KD=n(YZe,"A",{href:!0});var k3t=s(KD);wEo=r(k3t,"AutoFeatureExtractor.from_pretrained()"),k3t.forEach(t),AEo=r(YZe," class method."),YZe.forEach(t),LEo=i(El),D9=n(El,"P",{});var KZe=s(D9);yEo=r(KZe,"This class cannot be instantiated directly using "),Cge=n(KZe,"CODE",{});var S3t=s(Cge);xEo=r(S3t,"__init__()"),S3t.forEach(t),$Eo=r(KZe," (throws an error)."),KZe.forEach(t),kEo=i(El),Ye=n(El,"DIV",{class:!0});var va=s(Ye);T(G9.$$.fragment,va),SEo=i(va),wge=n(va,"P",{});var R3t=s(wge);REo=r(R3t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),R3t.forEach(t),PEo=i(va),Ha=n(va,"P",{});var _y=s(Ha);BEo=r(_y,"The feature extractor class to instantiate is selected based on the "),Age=n(_y,"CODE",{});var P3t=s(Age);IEo=r(P3t,"model_type"),P3t.forEach(t),NEo=r(_y,` property of the config object
(either passed as an argument or loaded from `),Lge=n(_y,"CODE",{});var B3t=s(Lge);qEo=r(B3t,"pretrained_model_name_or_path"),B3t.forEach(t),jEo=r(_y,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),yge=n(_y,"CODE",{});var I3t=s(yge);DEo=r(I3t,"pretrained_model_name_or_path"),I3t.forEach(t),GEo=r(_y,":"),_y.forEach(t),OEo=i(va),W=n(va,"UL",{});var J=s(W);ku=n(J,"LI",{});var wPe=s(ku);xge=n(wPe,"STRONG",{});var N3t=s(xge);VEo=r(N3t,"beit"),N3t.forEach(t),XEo=r(wPe," \u2014 "),ZD=n(wPe,"A",{href:!0});var q3t=s(ZD);zEo=r(q3t,"BeitFeatureExtractor"),q3t.forEach(t),QEo=r(wPe," (BEiT model)"),wPe.forEach(t),WEo=i(J),Su=n(J,"LI",{});var APe=s(Su);$ge=n(APe,"STRONG",{});var j3t=s($ge);UEo=r(j3t,"clip"),j3t.forEach(t),HEo=r(APe," \u2014 "),eG=n(APe,"A",{href:!0});var D3t=s(eG);JEo=r(D3t,"CLIPFeatureExtractor"),D3t.forEach(t),YEo=r(APe," (CLIP model)"),APe.forEach(t),KEo=i(J),Ru=n(J,"LI",{});var LPe=s(Ru);kge=n(LPe,"STRONG",{});var G3t=s(kge);ZEo=r(G3t,"convnext"),G3t.forEach(t),eCo=r(LPe," \u2014 "),oG=n(LPe,"A",{href:!0});var O3t=s(oG);oCo=r(O3t,"ConvNextFeatureExtractor"),O3t.forEach(t),rCo=r(LPe," (ConvNeXT model)"),LPe.forEach(t),tCo=i(J),Pu=n(J,"LI",{});var yPe=s(Pu);Sge=n(yPe,"STRONG",{});var V3t=s(Sge);aCo=r(V3t,"cvt"),V3t.forEach(t),nCo=r(yPe," \u2014 "),rG=n(yPe,"A",{href:!0});var X3t=s(rG);sCo=r(X3t,"ConvNextFeatureExtractor"),X3t.forEach(t),lCo=r(yPe," (CvT model)"),yPe.forEach(t),iCo=i(J),Bu=n(J,"LI",{});var xPe=s(Bu);Rge=n(xPe,"STRONG",{});var z3t=s(Rge);dCo=r(z3t,"data2vec-audio"),z3t.forEach(t),cCo=r(xPe," \u2014 "),tG=n(xPe,"A",{href:!0});var Q3t=s(tG);fCo=r(Q3t,"Wav2Vec2FeatureExtractor"),Q3t.forEach(t),mCo=r(xPe," (Data2VecAudio model)"),xPe.forEach(t),gCo=i(J),Iu=n(J,"LI",{});var $Pe=s(Iu);Pge=n($Pe,"STRONG",{});var W3t=s(Pge);hCo=r(W3t,"data2vec-vision"),W3t.forEach(t),uCo=r($Pe," \u2014 "),aG=n($Pe,"A",{href:!0});var U3t=s(aG);pCo=r(U3t,"BeitFeatureExtractor"),U3t.forEach(t),_Co=r($Pe," (Data2VecVision model)"),$Pe.forEach(t),vCo=i(J),Nu=n(J,"LI",{});var kPe=s(Nu);Bge=n(kPe,"STRONG",{});var H3t=s(Bge);bCo=r(H3t,"deit"),H3t.forEach(t),FCo=r(kPe," \u2014 "),nG=n(kPe,"A",{href:!0});var J3t=s(nG);TCo=r(J3t,"DeiTFeatureExtractor"),J3t.forEach(t),MCo=r(kPe," (DeiT model)"),kPe.forEach(t),ECo=i(J),qu=n(J,"LI",{});var SPe=s(qu);Ige=n(SPe,"STRONG",{});var Y3t=s(Ige);CCo=r(Y3t,"detr"),Y3t.forEach(t),wCo=r(SPe," \u2014 "),sG=n(SPe,"A",{href:!0});var K3t=s(sG);ACo=r(K3t,"DetrFeatureExtractor"),K3t.forEach(t),LCo=r(SPe," (DETR model)"),SPe.forEach(t),yCo=i(J),ju=n(J,"LI",{});var RPe=s(ju);Nge=n(RPe,"STRONG",{});var Z3t=s(Nge);xCo=r(Z3t,"donut"),Z3t.forEach(t),$Co=r(RPe," \u2014 "),lG=n(RPe,"A",{href:!0});var e5t=s(lG);kCo=r(e5t,"DonutFeatureExtractor"),e5t.forEach(t),SCo=r(RPe," (Donut model)"),RPe.forEach(t),RCo=i(J),Du=n(J,"LI",{});var PPe=s(Du);qge=n(PPe,"STRONG",{});var o5t=s(qge);PCo=r(o5t,"dpt"),o5t.forEach(t),BCo=r(PPe," \u2014 "),iG=n(PPe,"A",{href:!0});var r5t=s(iG);ICo=r(r5t,"DPTFeatureExtractor"),r5t.forEach(t),NCo=r(PPe," (DPT model)"),PPe.forEach(t),qCo=i(J),Gu=n(J,"LI",{});var BPe=s(Gu);jge=n(BPe,"STRONG",{});var t5t=s(jge);jCo=r(t5t,"flava"),t5t.forEach(t),DCo=r(BPe," \u2014 "),dG=n(BPe,"A",{href:!0});var a5t=s(dG);GCo=r(a5t,"FlavaFeatureExtractor"),a5t.forEach(t),OCo=r(BPe," (FLAVA model)"),BPe.forEach(t),VCo=i(J),Ou=n(J,"LI",{});var IPe=s(Ou);Dge=n(IPe,"STRONG",{});var n5t=s(Dge);XCo=r(n5t,"glpn"),n5t.forEach(t),zCo=r(IPe," \u2014 "),cG=n(IPe,"A",{href:!0});var s5t=s(cG);QCo=r(s5t,"GLPNFeatureExtractor"),s5t.forEach(t),WCo=r(IPe," (GLPN model)"),IPe.forEach(t),UCo=i(J),Vu=n(J,"LI",{});var NPe=s(Vu);Gge=n(NPe,"STRONG",{});var l5t=s(Gge);HCo=r(l5t,"groupvit"),l5t.forEach(t),JCo=r(NPe," \u2014 "),fG=n(NPe,"A",{href:!0});var i5t=s(fG);YCo=r(i5t,"CLIPFeatureExtractor"),i5t.forEach(t),KCo=r(NPe," (GroupViT model)"),NPe.forEach(t),ZCo=i(J),Xu=n(J,"LI",{});var qPe=s(Xu);Oge=n(qPe,"STRONG",{});var d5t=s(Oge);e3o=r(d5t,"hubert"),d5t.forEach(t),o3o=r(qPe," \u2014 "),mG=n(qPe,"A",{href:!0});var c5t=s(mG);r3o=r(c5t,"Wav2Vec2FeatureExtractor"),c5t.forEach(t),t3o=r(qPe," (Hubert model)"),qPe.forEach(t),a3o=i(J),zu=n(J,"LI",{});var jPe=s(zu);Vge=n(jPe,"STRONG",{});var f5t=s(Vge);n3o=r(f5t,"imagegpt"),f5t.forEach(t),s3o=r(jPe," \u2014 "),gG=n(jPe,"A",{href:!0});var m5t=s(gG);l3o=r(m5t,"ImageGPTFeatureExtractor"),m5t.forEach(t),i3o=r(jPe," (ImageGPT model)"),jPe.forEach(t),d3o=i(J),Qu=n(J,"LI",{});var DPe=s(Qu);Xge=n(DPe,"STRONG",{});var g5t=s(Xge);c3o=r(g5t,"layoutlmv2"),g5t.forEach(t),f3o=r(DPe," \u2014 "),hG=n(DPe,"A",{href:!0});var h5t=s(hG);m3o=r(h5t,"LayoutLMv2FeatureExtractor"),h5t.forEach(t),g3o=r(DPe," (LayoutLMv2 model)"),DPe.forEach(t),h3o=i(J),Wu=n(J,"LI",{});var GPe=s(Wu);zge=n(GPe,"STRONG",{});var u5t=s(zge);u3o=r(u5t,"layoutlmv3"),u5t.forEach(t),p3o=r(GPe," \u2014 "),uG=n(GPe,"A",{href:!0});var p5t=s(uG);_3o=r(p5t,"LayoutLMv3FeatureExtractor"),p5t.forEach(t),v3o=r(GPe," (LayoutLMv3 model)"),GPe.forEach(t),b3o=i(J),Uu=n(J,"LI",{});var OPe=s(Uu);Qge=n(OPe,"STRONG",{});var _5t=s(Qge);F3o=r(_5t,"levit"),_5t.forEach(t),T3o=r(OPe," \u2014 "),pG=n(OPe,"A",{href:!0});var v5t=s(pG);M3o=r(v5t,"LevitFeatureExtractor"),v5t.forEach(t),E3o=r(OPe," (LeViT model)"),OPe.forEach(t),C3o=i(J),Hu=n(J,"LI",{});var VPe=s(Hu);Wge=n(VPe,"STRONG",{});var b5t=s(Wge);w3o=r(b5t,"maskformer"),b5t.forEach(t),A3o=r(VPe," \u2014 "),_G=n(VPe,"A",{href:!0});var F5t=s(_G);L3o=r(F5t,"MaskFormerFeatureExtractor"),F5t.forEach(t),y3o=r(VPe," (MaskFormer model)"),VPe.forEach(t),x3o=i(J),Ju=n(J,"LI",{});var XPe=s(Ju);Uge=n(XPe,"STRONG",{});var T5t=s(Uge);$3o=r(T5t,"mctct"),T5t.forEach(t),k3o=r(XPe," \u2014 "),vG=n(XPe,"A",{href:!0});var M5t=s(vG);S3o=r(M5t,"MCTCTFeatureExtractor"),M5t.forEach(t),R3o=r(XPe," (M-CTC-T model)"),XPe.forEach(t),P3o=i(J),Yu=n(J,"LI",{});var zPe=s(Yu);Hge=n(zPe,"STRONG",{});var E5t=s(Hge);B3o=r(E5t,"mobilevit"),E5t.forEach(t),I3o=r(zPe," \u2014 "),bG=n(zPe,"A",{href:!0});var C5t=s(bG);N3o=r(C5t,"MobileViTFeatureExtractor"),C5t.forEach(t),q3o=r(zPe," (MobileViT model)"),zPe.forEach(t),j3o=i(J),Ku=n(J,"LI",{});var QPe=s(Ku);Jge=n(QPe,"STRONG",{});var w5t=s(Jge);D3o=r(w5t,"owlvit"),w5t.forEach(t),G3o=r(QPe," \u2014 "),FG=n(QPe,"A",{href:!0});var A5t=s(FG);O3o=r(A5t,"OwlViTFeatureExtractor"),A5t.forEach(t),V3o=r(QPe," (OWL-ViT model)"),QPe.forEach(t),X3o=i(J),Zu=n(J,"LI",{});var WPe=s(Zu);Yge=n(WPe,"STRONG",{});var L5t=s(Yge);z3o=r(L5t,"perceiver"),L5t.forEach(t),Q3o=r(WPe," \u2014 "),TG=n(WPe,"A",{href:!0});var y5t=s(TG);W3o=r(y5t,"PerceiverFeatureExtractor"),y5t.forEach(t),U3o=r(WPe," (Perceiver model)"),WPe.forEach(t),H3o=i(J),ep=n(J,"LI",{});var UPe=s(ep);Kge=n(UPe,"STRONG",{});var x5t=s(Kge);J3o=r(x5t,"poolformer"),x5t.forEach(t),Y3o=r(UPe," \u2014 "),MG=n(UPe,"A",{href:!0});var $5t=s(MG);K3o=r($5t,"PoolFormerFeatureExtractor"),$5t.forEach(t),Z3o=r(UPe," (PoolFormer model)"),UPe.forEach(t),e5o=i(J),op=n(J,"LI",{});var HPe=s(op);Zge=n(HPe,"STRONG",{});var k5t=s(Zge);o5o=r(k5t,"regnet"),k5t.forEach(t),r5o=r(HPe," \u2014 "),EG=n(HPe,"A",{href:!0});var S5t=s(EG);t5o=r(S5t,"ConvNextFeatureExtractor"),S5t.forEach(t),a5o=r(HPe," (RegNet model)"),HPe.forEach(t),n5o=i(J),rp=n(J,"LI",{});var JPe=s(rp);ehe=n(JPe,"STRONG",{});var R5t=s(ehe);s5o=r(R5t,"resnet"),R5t.forEach(t),l5o=r(JPe," \u2014 "),CG=n(JPe,"A",{href:!0});var P5t=s(CG);i5o=r(P5t,"ConvNextFeatureExtractor"),P5t.forEach(t),d5o=r(JPe," (ResNet model)"),JPe.forEach(t),c5o=i(J),tp=n(J,"LI",{});var YPe=s(tp);ohe=n(YPe,"STRONG",{});var B5t=s(ohe);f5o=r(B5t,"segformer"),B5t.forEach(t),m5o=r(YPe," \u2014 "),wG=n(YPe,"A",{href:!0});var I5t=s(wG);g5o=r(I5t,"SegformerFeatureExtractor"),I5t.forEach(t),h5o=r(YPe," (SegFormer model)"),YPe.forEach(t),u5o=i(J),ap=n(J,"LI",{});var KPe=s(ap);rhe=n(KPe,"STRONG",{});var N5t=s(rhe);p5o=r(N5t,"speech_to_text"),N5t.forEach(t),_5o=r(KPe," \u2014 "),AG=n(KPe,"A",{href:!0});var q5t=s(AG);v5o=r(q5t,"Speech2TextFeatureExtractor"),q5t.forEach(t),b5o=r(KPe," (Speech2Text model)"),KPe.forEach(t),F5o=i(J),np=n(J,"LI",{});var ZPe=s(np);the=n(ZPe,"STRONG",{});var j5t=s(the);T5o=r(j5t,"swin"),j5t.forEach(t),M5o=r(ZPe," \u2014 "),LG=n(ZPe,"A",{href:!0});var D5t=s(LG);E5o=r(D5t,"ViTFeatureExtractor"),D5t.forEach(t),C5o=r(ZPe," (Swin Transformer model)"),ZPe.forEach(t),w5o=i(J),sp=n(J,"LI",{});var eBe=s(sp);ahe=n(eBe,"STRONG",{});var G5t=s(ahe);A5o=r(G5t,"swinv2"),G5t.forEach(t),L5o=r(eBe," \u2014 "),yG=n(eBe,"A",{href:!0});var O5t=s(yG);y5o=r(O5t,"ViTFeatureExtractor"),O5t.forEach(t),x5o=r(eBe," (Swin Transformer V2 model)"),eBe.forEach(t),$5o=i(J),lp=n(J,"LI",{});var oBe=s(lp);nhe=n(oBe,"STRONG",{});var V5t=s(nhe);k5o=r(V5t,"van"),V5t.forEach(t),S5o=r(oBe," \u2014 "),xG=n(oBe,"A",{href:!0});var X5t=s(xG);R5o=r(X5t,"ConvNextFeatureExtractor"),X5t.forEach(t),P5o=r(oBe," (VAN model)"),oBe.forEach(t),B5o=i(J),ip=n(J,"LI",{});var rBe=s(ip);she=n(rBe,"STRONG",{});var z5t=s(she);I5o=r(z5t,"videomae"),z5t.forEach(t),N5o=r(rBe," \u2014 "),$G=n(rBe,"A",{href:!0});var Q5t=s($G);q5o=r(Q5t,"VideoMAEFeatureExtractor"),Q5t.forEach(t),j5o=r(rBe," (VideoMAE model)"),rBe.forEach(t),D5o=i(J),dp=n(J,"LI",{});var tBe=s(dp);lhe=n(tBe,"STRONG",{});var W5t=s(lhe);G5o=r(W5t,"vilt"),W5t.forEach(t),O5o=r(tBe," \u2014 "),kG=n(tBe,"A",{href:!0});var U5t=s(kG);V5o=r(U5t,"ViltFeatureExtractor"),U5t.forEach(t),X5o=r(tBe," (ViLT model)"),tBe.forEach(t),z5o=i(J),cp=n(J,"LI",{});var aBe=s(cp);ihe=n(aBe,"STRONG",{});var H5t=s(ihe);Q5o=r(H5t,"vit"),H5t.forEach(t),W5o=r(aBe," \u2014 "),SG=n(aBe,"A",{href:!0});var J5t=s(SG);U5o=r(J5t,"ViTFeatureExtractor"),J5t.forEach(t),H5o=r(aBe," (ViT model)"),aBe.forEach(t),J5o=i(J),fp=n(J,"LI",{});var nBe=s(fp);dhe=n(nBe,"STRONG",{});var Y5t=s(dhe);Y5o=r(Y5t,"vit_mae"),Y5t.forEach(t),K5o=r(nBe," \u2014 "),RG=n(nBe,"A",{href:!0});var K5t=s(RG);Z5o=r(K5t,"ViTFeatureExtractor"),K5t.forEach(t),e0o=r(nBe," (ViTMAE model)"),nBe.forEach(t),o0o=i(J),mp=n(J,"LI",{});var sBe=s(mp);che=n(sBe,"STRONG",{});var Z5t=s(che);r0o=r(Z5t,"wav2vec2"),Z5t.forEach(t),t0o=r(sBe," \u2014 "),PG=n(sBe,"A",{href:!0});var e0t=s(PG);a0o=r(e0t,"Wav2Vec2FeatureExtractor"),e0t.forEach(t),n0o=r(sBe," (Wav2Vec2 model)"),sBe.forEach(t),s0o=i(J),gp=n(J,"LI",{});var lBe=s(gp);fhe=n(lBe,"STRONG",{});var o0t=s(fhe);l0o=r(o0t,"wav2vec2-conformer"),o0t.forEach(t),i0o=r(lBe," \u2014 "),BG=n(lBe,"A",{href:!0});var r0t=s(BG);d0o=r(r0t,"Wav2Vec2FeatureExtractor"),r0t.forEach(t),c0o=r(lBe," (Wav2Vec2-Conformer model)"),lBe.forEach(t),f0o=i(J),hp=n(J,"LI",{});var iBe=s(hp);mhe=n(iBe,"STRONG",{});var t0t=s(mhe);m0o=r(t0t,"xclip"),t0t.forEach(t),g0o=r(iBe," \u2014 "),IG=n(iBe,"A",{href:!0});var a0t=s(IG);h0o=r(a0t,"CLIPFeatureExtractor"),a0t.forEach(t),u0o=r(iBe," (X-CLIP model)"),iBe.forEach(t),p0o=i(J),up=n(J,"LI",{});var dBe=s(up);ghe=n(dBe,"STRONG",{});var n0t=s(ghe);_0o=r(n0t,"yolos"),n0t.forEach(t),v0o=r(dBe," \u2014 "),NG=n(dBe,"A",{href:!0});var s0t=s(NG);b0o=r(s0t,"YolosFeatureExtractor"),s0t.forEach(t),F0o=r(dBe," (YOLOS model)"),dBe.forEach(t),J.forEach(t),T0o=i(va),T(pp.$$.fragment,va),M0o=i(va),T(_p.$$.fragment,va),va.forEach(t),E0o=i(El),vp=n(El,"DIV",{class:!0});var ZZe=s(vp);T(O9.$$.fragment,ZZe),C0o=i(ZZe),hhe=n(ZZe,"P",{});var l0t=s(hhe);w0o=r(l0t,"Register a new feature extractor for this class."),l0t.forEach(t),ZZe.forEach(t),El.forEach(t),OYe=i(f),hd=n(f,"H2",{class:!0});var eeo=s(hd);bp=n(eeo,"A",{id:!0,class:!0,href:!0});var i0t=s(bp);uhe=n(i0t,"SPAN",{});var d0t=s(uhe);T(V9.$$.fragment,d0t),d0t.forEach(t),i0t.forEach(t),A0o=i(eeo),phe=n(eeo,"SPAN",{});var c0t=s(phe);L0o=r(c0t,"AutoProcessor"),c0t.forEach(t),eeo.forEach(t),VYe=i(f),Ro=n(f,"DIV",{class:!0});var Cl=s(Ro);T(X9.$$.fragment,Cl),y0o=i(Cl),z9=n(Cl,"P",{});var oeo=s(z9);x0o=r(oeo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qG=n(oeo,"A",{href:!0});var f0t=s(qG);$0o=r(f0t,"AutoProcessor.from_pretrained()"),f0t.forEach(t),k0o=r(oeo," class method."),oeo.forEach(t),S0o=i(Cl),Q9=n(Cl,"P",{});var reo=s(Q9);R0o=r(reo,"This class cannot be instantiated directly using "),_he=n(reo,"CODE",{});var m0t=s(_he);P0o=r(m0t,"__init__()"),m0t.forEach(t),B0o=r(reo," (throws an error)."),reo.forEach(t),I0o=i(Cl),Ke=n(Cl,"DIV",{class:!0});var ba=s(Ke);T(W9.$$.fragment,ba),N0o=i(ba),vhe=n(ba,"P",{});var g0t=s(vhe);q0o=r(g0t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),g0t.forEach(t),j0o=i(ba),ud=n(ba,"P",{});var Qse=s(ud);D0o=r(Qse,"The processor class to instantiate is selected based on the "),bhe=n(Qse,"CODE",{});var h0t=s(bhe);G0o=r(h0t,"model_type"),h0t.forEach(t),O0o=r(Qse,` property of the config object (either
passed as an argument or loaded from `),Fhe=n(Qse,"CODE",{});var u0t=s(Fhe);V0o=r(u0t,"pretrained_model_name_or_path"),u0t.forEach(t),X0o=r(Qse," if possible):"),Qse.forEach(t),z0o=i(ba),ie=n(ba,"UL",{});var ge=s(ie);Fp=n(ge,"LI",{});var cBe=s(Fp);The=n(cBe,"STRONG",{});var p0t=s(The);Q0o=r(p0t,"clip"),p0t.forEach(t),W0o=r(cBe," \u2014 "),jG=n(cBe,"A",{href:!0});var _0t=s(jG);U0o=r(_0t,"CLIPProcessor"),_0t.forEach(t),H0o=r(cBe," (CLIP model)"),cBe.forEach(t),J0o=i(ge),Tp=n(ge,"LI",{});var fBe=s(Tp);Mhe=n(fBe,"STRONG",{});var v0t=s(Mhe);Y0o=r(v0t,"donut"),v0t.forEach(t),K0o=r(fBe," \u2014 "),DG=n(fBe,"A",{href:!0});var b0t=s(DG);Z0o=r(b0t,"DonutProcessor"),b0t.forEach(t),ewo=r(fBe," (Donut model)"),fBe.forEach(t),owo=i(ge),Mp=n(ge,"LI",{});var mBe=s(Mp);Ehe=n(mBe,"STRONG",{});var F0t=s(Ehe);rwo=r(F0t,"flava"),F0t.forEach(t),two=r(mBe," \u2014 "),GG=n(mBe,"A",{href:!0});var T0t=s(GG);awo=r(T0t,"FlavaProcessor"),T0t.forEach(t),nwo=r(mBe," (FLAVA model)"),mBe.forEach(t),swo=i(ge),Ep=n(ge,"LI",{});var gBe=s(Ep);Che=n(gBe,"STRONG",{});var M0t=s(Che);lwo=r(M0t,"groupvit"),M0t.forEach(t),iwo=r(gBe," \u2014 "),OG=n(gBe,"A",{href:!0});var E0t=s(OG);dwo=r(E0t,"CLIPProcessor"),E0t.forEach(t),cwo=r(gBe," (GroupViT model)"),gBe.forEach(t),fwo=i(ge),Cp=n(ge,"LI",{});var hBe=s(Cp);whe=n(hBe,"STRONG",{});var C0t=s(whe);mwo=r(C0t,"layoutlmv2"),C0t.forEach(t),gwo=r(hBe," \u2014 "),VG=n(hBe,"A",{href:!0});var w0t=s(VG);hwo=r(w0t,"LayoutLMv2Processor"),w0t.forEach(t),uwo=r(hBe," (LayoutLMv2 model)"),hBe.forEach(t),pwo=i(ge),wp=n(ge,"LI",{});var uBe=s(wp);Ahe=n(uBe,"STRONG",{});var A0t=s(Ahe);_wo=r(A0t,"layoutlmv3"),A0t.forEach(t),vwo=r(uBe," \u2014 "),XG=n(uBe,"A",{href:!0});var L0t=s(XG);bwo=r(L0t,"LayoutLMv3Processor"),L0t.forEach(t),Fwo=r(uBe," (LayoutLMv3 model)"),uBe.forEach(t),Two=i(ge),Ap=n(ge,"LI",{});var pBe=s(Ap);Lhe=n(pBe,"STRONG",{});var y0t=s(Lhe);Mwo=r(y0t,"layoutxlm"),y0t.forEach(t),Ewo=r(pBe," \u2014 "),zG=n(pBe,"A",{href:!0});var x0t=s(zG);Cwo=r(x0t,"LayoutXLMProcessor"),x0t.forEach(t),wwo=r(pBe," (LayoutXLM model)"),pBe.forEach(t),Awo=i(ge),Lp=n(ge,"LI",{});var _Be=s(Lp);yhe=n(_Be,"STRONG",{});var $0t=s(yhe);Lwo=r($0t,"owlvit"),$0t.forEach(t),ywo=r(_Be," \u2014 "),QG=n(_Be,"A",{href:!0});var k0t=s(QG);xwo=r(k0t,"OwlViTProcessor"),k0t.forEach(t),$wo=r(_Be," (OWL-ViT model)"),_Be.forEach(t),kwo=i(ge),yp=n(ge,"LI",{});var vBe=s(yp);xhe=n(vBe,"STRONG",{});var S0t=s(xhe);Swo=r(S0t,"sew"),S0t.forEach(t),Rwo=r(vBe," \u2014 "),WG=n(vBe,"A",{href:!0});var R0t=s(WG);Pwo=r(R0t,"Wav2Vec2Processor"),R0t.forEach(t),Bwo=r(vBe," (SEW model)"),vBe.forEach(t),Iwo=i(ge),xp=n(ge,"LI",{});var bBe=s(xp);$he=n(bBe,"STRONG",{});var P0t=s($he);Nwo=r(P0t,"sew-d"),P0t.forEach(t),qwo=r(bBe," \u2014 "),UG=n(bBe,"A",{href:!0});var B0t=s(UG);jwo=r(B0t,"Wav2Vec2Processor"),B0t.forEach(t),Dwo=r(bBe," (SEW-D model)"),bBe.forEach(t),Gwo=i(ge),$p=n(ge,"LI",{});var FBe=s($p);khe=n(FBe,"STRONG",{});var I0t=s(khe);Owo=r(I0t,"speech_to_text"),I0t.forEach(t),Vwo=r(FBe," \u2014 "),HG=n(FBe,"A",{href:!0});var N0t=s(HG);Xwo=r(N0t,"Speech2TextProcessor"),N0t.forEach(t),zwo=r(FBe," (Speech2Text model)"),FBe.forEach(t),Qwo=i(ge),kp=n(ge,"LI",{});var TBe=s(kp);She=n(TBe,"STRONG",{});var q0t=s(She);Wwo=r(q0t,"speech_to_text_2"),q0t.forEach(t),Uwo=r(TBe," \u2014 "),JG=n(TBe,"A",{href:!0});var j0t=s(JG);Hwo=r(j0t,"Speech2Text2Processor"),j0t.forEach(t),Jwo=r(TBe," (Speech2Text2 model)"),TBe.forEach(t),Ywo=i(ge),Sp=n(ge,"LI",{});var MBe=s(Sp);Rhe=n(MBe,"STRONG",{});var D0t=s(Rhe);Kwo=r(D0t,"trocr"),D0t.forEach(t),Zwo=r(MBe," \u2014 "),YG=n(MBe,"A",{href:!0});var G0t=s(YG);eAo=r(G0t,"TrOCRProcessor"),G0t.forEach(t),oAo=r(MBe," (TrOCR model)"),MBe.forEach(t),rAo=i(ge),Rp=n(ge,"LI",{});var EBe=s(Rp);Phe=n(EBe,"STRONG",{});var O0t=s(Phe);tAo=r(O0t,"unispeech"),O0t.forEach(t),aAo=r(EBe," \u2014 "),KG=n(EBe,"A",{href:!0});var V0t=s(KG);nAo=r(V0t,"Wav2Vec2Processor"),V0t.forEach(t),sAo=r(EBe," (UniSpeech model)"),EBe.forEach(t),lAo=i(ge),Pp=n(ge,"LI",{});var CBe=s(Pp);Bhe=n(CBe,"STRONG",{});var X0t=s(Bhe);iAo=r(X0t,"unispeech-sat"),X0t.forEach(t),dAo=r(CBe," \u2014 "),ZG=n(CBe,"A",{href:!0});var z0t=s(ZG);cAo=r(z0t,"Wav2Vec2Processor"),z0t.forEach(t),fAo=r(CBe," (UniSpeechSat model)"),CBe.forEach(t),mAo=i(ge),Bp=n(ge,"LI",{});var wBe=s(Bp);Ihe=n(wBe,"STRONG",{});var Q0t=s(Ihe);gAo=r(Q0t,"vilt"),Q0t.forEach(t),hAo=r(wBe," \u2014 "),eO=n(wBe,"A",{href:!0});var W0t=s(eO);uAo=r(W0t,"ViltProcessor"),W0t.forEach(t),pAo=r(wBe," (ViLT model)"),wBe.forEach(t),_Ao=i(ge),Ip=n(ge,"LI",{});var ABe=s(Ip);Nhe=n(ABe,"STRONG",{});var U0t=s(Nhe);vAo=r(U0t,"vision-text-dual-encoder"),U0t.forEach(t),bAo=r(ABe," \u2014 "),oO=n(ABe,"A",{href:!0});var H0t=s(oO);FAo=r(H0t,"VisionTextDualEncoderProcessor"),H0t.forEach(t),TAo=r(ABe," (VisionTextDualEncoder model)"),ABe.forEach(t),MAo=i(ge),Np=n(ge,"LI",{});var LBe=s(Np);qhe=n(LBe,"STRONG",{});var J0t=s(qhe);EAo=r(J0t,"wav2vec2"),J0t.forEach(t),CAo=r(LBe," \u2014 "),rO=n(LBe,"A",{href:!0});var Y0t=s(rO);wAo=r(Y0t,"Wav2Vec2Processor"),Y0t.forEach(t),AAo=r(LBe," (Wav2Vec2 model)"),LBe.forEach(t),LAo=i(ge),qp=n(ge,"LI",{});var yBe=s(qp);jhe=n(yBe,"STRONG",{});var K0t=s(jhe);yAo=r(K0t,"wav2vec2-conformer"),K0t.forEach(t),xAo=r(yBe," \u2014 "),tO=n(yBe,"A",{href:!0});var Z0t=s(tO);$Ao=r(Z0t,"Wav2Vec2Processor"),Z0t.forEach(t),kAo=r(yBe," (Wav2Vec2-Conformer model)"),yBe.forEach(t),SAo=i(ge),jp=n(ge,"LI",{});var xBe=s(jp);Dhe=n(xBe,"STRONG",{});var ewt=s(Dhe);RAo=r(ewt,"wavlm"),ewt.forEach(t),PAo=r(xBe," \u2014 "),aO=n(xBe,"A",{href:!0});var owt=s(aO);BAo=r(owt,"Wav2Vec2Processor"),owt.forEach(t),IAo=r(xBe," (WavLM model)"),xBe.forEach(t),NAo=i(ge),Dp=n(ge,"LI",{});var $Be=s(Dp);Ghe=n($Be,"STRONG",{});var rwt=s(Ghe);qAo=r(rwt,"xclip"),rwt.forEach(t),jAo=r($Be," \u2014 "),nO=n($Be,"A",{href:!0});var twt=s(nO);DAo=r(twt,"CLIPProcessor"),twt.forEach(t),GAo=r($Be," (X-CLIP model)"),$Be.forEach(t),ge.forEach(t),OAo=i(ba),T(Gp.$$.fragment,ba),VAo=i(ba),T(Op.$$.fragment,ba),ba.forEach(t),XAo=i(Cl),Vp=n(Cl,"DIV",{class:!0});var teo=s(Vp);T(U9.$$.fragment,teo),zAo=i(teo),Ohe=n(teo,"P",{});var awt=s(Ohe);QAo=r(awt,"Register a new processor for this class."),awt.forEach(t),teo.forEach(t),Cl.forEach(t),XYe=i(f),pd=n(f,"H2",{class:!0});var aeo=s(pd);Xp=n(aeo,"A",{id:!0,class:!0,href:!0});var nwt=s(Xp);Vhe=n(nwt,"SPAN",{});var swt=s(Vhe);T(H9.$$.fragment,swt),swt.forEach(t),nwt.forEach(t),WAo=i(aeo),Xhe=n(aeo,"SPAN",{});var lwt=s(Xhe);UAo=r(lwt,"AutoModel"),lwt.forEach(t),aeo.forEach(t),zYe=i(f),Po=n(f,"DIV",{class:!0});var wl=s(Po);T(J9.$$.fragment,wl),HAo=i(wl),_d=n(wl,"P",{});var Wse=s(_d);JAo=r(Wse,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sO=n(Wse,"A",{href:!0});var iwt=s(sO);YAo=r(iwt,"from_pretrained()"),iwt.forEach(t),KAo=r(Wse," class method or the "),lO=n(Wse,"A",{href:!0});var dwt=s(lO);ZAo=r(dwt,"from_config()"),dwt.forEach(t),e6o=r(Wse,` class
method.`),Wse.forEach(t),o6o=i(wl),Y9=n(wl,"P",{});var neo=s(Y9);r6o=r(neo,"This class cannot be instantiated directly using "),zhe=n(neo,"CODE",{});var cwt=s(zhe);t6o=r(cwt,"__init__()"),cwt.forEach(t),a6o=r(neo," (throws an error)."),neo.forEach(t),n6o=i(wl),_t=n(wl,"DIV",{class:!0});var vy=s(_t);T(K9.$$.fragment,vy),s6o=i(vy),Qhe=n(vy,"P",{});var fwt=s(Qhe);l6o=r(fwt,"Instantiates one of the base model classes of the library from a configuration."),fwt.forEach(t),i6o=i(vy),vd=n(vy,"P",{});var Use=s(vd);d6o=r(Use,`Note:
Loading a model from its configuration file does `),Whe=n(Use,"STRONG",{});var mwt=s(Whe);c6o=r(mwt,"not"),mwt.forEach(t),f6o=r(Use,` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=n(Use,"A",{href:!0});var gwt=s(iO);m6o=r(gwt,"from_pretrained()"),gwt.forEach(t),g6o=r(Use," to load the model weights."),Use.forEach(t),h6o=i(vy),T(zp.$$.fragment,vy),vy.forEach(t),u6o=i(wl),Ze=n(wl,"DIV",{class:!0});var Fa=s(Ze);T(Z9.$$.fragment,Fa),p6o=i(Fa),Uhe=n(Fa,"P",{});var hwt=s(Uhe);_6o=r(hwt,"Instantiate one of the base model classes of the library from a pretrained model."),hwt.forEach(t),v6o=i(Fa),Ja=n(Fa,"P",{});var by=s(Ja);b6o=r(by,"The model class to instantiate is selected based on the "),Hhe=n(by,"CODE",{});var uwt=s(Hhe);F6o=r(uwt,"model_type"),uwt.forEach(t),T6o=r(by,` property of the config object (either
passed as an argument or loaded from `),Jhe=n(by,"CODE",{});var pwt=s(Jhe);M6o=r(pwt,"pretrained_model_name_or_path"),pwt.forEach(t),E6o=r(by,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yhe=n(by,"CODE",{});var _wt=s(Yhe);C6o=r(_wt,"pretrained_model_name_or_path"),_wt.forEach(t),w6o=r(by,":"),by.forEach(t),A6o=i(Fa),y=n(Fa,"UL",{});var x=s(y);Qp=n(x,"LI",{});var kBe=s(Qp);Khe=n(kBe,"STRONG",{});var vwt=s(Khe);L6o=r(vwt,"albert"),vwt.forEach(t),y6o=r(kBe," \u2014 "),dO=n(kBe,"A",{href:!0});var bwt=s(dO);x6o=r(bwt,"AlbertModel"),bwt.forEach(t),$6o=r(kBe," (ALBERT model)"),kBe.forEach(t),k6o=i(x),Wp=n(x,"LI",{});var SBe=s(Wp);Zhe=n(SBe,"STRONG",{});var Fwt=s(Zhe);S6o=r(Fwt,"bart"),Fwt.forEach(t),R6o=r(SBe," \u2014 "),cO=n(SBe,"A",{href:!0});var Twt=s(cO);P6o=r(Twt,"BartModel"),Twt.forEach(t),B6o=r(SBe," (BART model)"),SBe.forEach(t),I6o=i(x),Up=n(x,"LI",{});var RBe=s(Up);eue=n(RBe,"STRONG",{});var Mwt=s(eue);N6o=r(Mwt,"beit"),Mwt.forEach(t),q6o=r(RBe," \u2014 "),fO=n(RBe,"A",{href:!0});var Ewt=s(fO);j6o=r(Ewt,"BeitModel"),Ewt.forEach(t),D6o=r(RBe," (BEiT model)"),RBe.forEach(t),G6o=i(x),Hp=n(x,"LI",{});var PBe=s(Hp);oue=n(PBe,"STRONG",{});var Cwt=s(oue);O6o=r(Cwt,"bert"),Cwt.forEach(t),V6o=r(PBe," \u2014 "),mO=n(PBe,"A",{href:!0});var wwt=s(mO);X6o=r(wwt,"BertModel"),wwt.forEach(t),z6o=r(PBe," (BERT model)"),PBe.forEach(t),Q6o=i(x),Jp=n(x,"LI",{});var BBe=s(Jp);rue=n(BBe,"STRONG",{});var Awt=s(rue);W6o=r(Awt,"bert-generation"),Awt.forEach(t),U6o=r(BBe," \u2014 "),gO=n(BBe,"A",{href:!0});var Lwt=s(gO);H6o=r(Lwt,"BertGenerationEncoder"),Lwt.forEach(t),J6o=r(BBe," (Bert Generation model)"),BBe.forEach(t),Y6o=i(x),Yp=n(x,"LI",{});var IBe=s(Yp);tue=n(IBe,"STRONG",{});var ywt=s(tue);K6o=r(ywt,"big_bird"),ywt.forEach(t),Z6o=r(IBe," \u2014 "),hO=n(IBe,"A",{href:!0});var xwt=s(hO);e7o=r(xwt,"BigBirdModel"),xwt.forEach(t),o7o=r(IBe," (BigBird model)"),IBe.forEach(t),r7o=i(x),Kp=n(x,"LI",{});var NBe=s(Kp);aue=n(NBe,"STRONG",{});var $wt=s(aue);t7o=r($wt,"bigbird_pegasus"),$wt.forEach(t),a7o=r(NBe," \u2014 "),uO=n(NBe,"A",{href:!0});var kwt=s(uO);n7o=r(kwt,"BigBirdPegasusModel"),kwt.forEach(t),s7o=r(NBe," (BigBird-Pegasus model)"),NBe.forEach(t),l7o=i(x),Zp=n(x,"LI",{});var qBe=s(Zp);nue=n(qBe,"STRONG",{});var Swt=s(nue);i7o=r(Swt,"blenderbot"),Swt.forEach(t),d7o=r(qBe," \u2014 "),pO=n(qBe,"A",{href:!0});var Rwt=s(pO);c7o=r(Rwt,"BlenderbotModel"),Rwt.forEach(t),f7o=r(qBe," (Blenderbot model)"),qBe.forEach(t),m7o=i(x),e_=n(x,"LI",{});var jBe=s(e_);sue=n(jBe,"STRONG",{});var Pwt=s(sue);g7o=r(Pwt,"blenderbot-small"),Pwt.forEach(t),h7o=r(jBe," \u2014 "),_O=n(jBe,"A",{href:!0});var Bwt=s(_O);u7o=r(Bwt,"BlenderbotSmallModel"),Bwt.forEach(t),p7o=r(jBe," (BlenderbotSmall model)"),jBe.forEach(t),_7o=i(x),o_=n(x,"LI",{});var DBe=s(o_);lue=n(DBe,"STRONG",{});var Iwt=s(lue);v7o=r(Iwt,"bloom"),Iwt.forEach(t),b7o=r(DBe," \u2014 "),vO=n(DBe,"A",{href:!0});var Nwt=s(vO);F7o=r(Nwt,"BloomModel"),Nwt.forEach(t),T7o=r(DBe," (BLOOM model)"),DBe.forEach(t),M7o=i(x),r_=n(x,"LI",{});var GBe=s(r_);iue=n(GBe,"STRONG",{});var qwt=s(iue);E7o=r(qwt,"camembert"),qwt.forEach(t),C7o=r(GBe," \u2014 "),bO=n(GBe,"A",{href:!0});var jwt=s(bO);w7o=r(jwt,"CamembertModel"),jwt.forEach(t),A7o=r(GBe," (CamemBERT model)"),GBe.forEach(t),L7o=i(x),t_=n(x,"LI",{});var OBe=s(t_);due=n(OBe,"STRONG",{});var Dwt=s(due);y7o=r(Dwt,"canine"),Dwt.forEach(t),x7o=r(OBe," \u2014 "),FO=n(OBe,"A",{href:!0});var Gwt=s(FO);$7o=r(Gwt,"CanineModel"),Gwt.forEach(t),k7o=r(OBe," (CANINE model)"),OBe.forEach(t),S7o=i(x),a_=n(x,"LI",{});var VBe=s(a_);cue=n(VBe,"STRONG",{});var Owt=s(cue);R7o=r(Owt,"clip"),Owt.forEach(t),P7o=r(VBe," \u2014 "),TO=n(VBe,"A",{href:!0});var Vwt=s(TO);B7o=r(Vwt,"CLIPModel"),Vwt.forEach(t),I7o=r(VBe," (CLIP model)"),VBe.forEach(t),N7o=i(x),n_=n(x,"LI",{});var XBe=s(n_);fue=n(XBe,"STRONG",{});var Xwt=s(fue);q7o=r(Xwt,"codegen"),Xwt.forEach(t),j7o=r(XBe," \u2014 "),MO=n(XBe,"A",{href:!0});var zwt=s(MO);D7o=r(zwt,"CodeGenModel"),zwt.forEach(t),G7o=r(XBe," (CodeGen model)"),XBe.forEach(t),O7o=i(x),s_=n(x,"LI",{});var zBe=s(s_);mue=n(zBe,"STRONG",{});var Qwt=s(mue);V7o=r(Qwt,"convbert"),Qwt.forEach(t),X7o=r(zBe," \u2014 "),EO=n(zBe,"A",{href:!0});var Wwt=s(EO);z7o=r(Wwt,"ConvBertModel"),Wwt.forEach(t),Q7o=r(zBe," (ConvBERT model)"),zBe.forEach(t),W7o=i(x),l_=n(x,"LI",{});var QBe=s(l_);gue=n(QBe,"STRONG",{});var Uwt=s(gue);U7o=r(Uwt,"convnext"),Uwt.forEach(t),H7o=r(QBe," \u2014 "),CO=n(QBe,"A",{href:!0});var Hwt=s(CO);J7o=r(Hwt,"ConvNextModel"),Hwt.forEach(t),Y7o=r(QBe," (ConvNeXT model)"),QBe.forEach(t),K7o=i(x),i_=n(x,"LI",{});var WBe=s(i_);hue=n(WBe,"STRONG",{});var Jwt=s(hue);Z7o=r(Jwt,"ctrl"),Jwt.forEach(t),eLo=r(WBe," \u2014 "),wO=n(WBe,"A",{href:!0});var Ywt=s(wO);oLo=r(Ywt,"CTRLModel"),Ywt.forEach(t),rLo=r(WBe," (CTRL model)"),WBe.forEach(t),tLo=i(x),d_=n(x,"LI",{});var UBe=s(d_);uue=n(UBe,"STRONG",{});var Kwt=s(uue);aLo=r(Kwt,"cvt"),Kwt.forEach(t),nLo=r(UBe," \u2014 "),AO=n(UBe,"A",{href:!0});var Zwt=s(AO);sLo=r(Zwt,"CvtModel"),Zwt.forEach(t),lLo=r(UBe," (CvT model)"),UBe.forEach(t),iLo=i(x),c_=n(x,"LI",{});var HBe=s(c_);pue=n(HBe,"STRONG",{});var eAt=s(pue);dLo=r(eAt,"data2vec-audio"),eAt.forEach(t),cLo=r(HBe," \u2014 "),LO=n(HBe,"A",{href:!0});var oAt=s(LO);fLo=r(oAt,"Data2VecAudioModel"),oAt.forEach(t),mLo=r(HBe," (Data2VecAudio model)"),HBe.forEach(t),gLo=i(x),f_=n(x,"LI",{});var JBe=s(f_);_ue=n(JBe,"STRONG",{});var rAt=s(_ue);hLo=r(rAt,"data2vec-text"),rAt.forEach(t),uLo=r(JBe," \u2014 "),yO=n(JBe,"A",{href:!0});var tAt=s(yO);pLo=r(tAt,"Data2VecTextModel"),tAt.forEach(t),_Lo=r(JBe," (Data2VecText model)"),JBe.forEach(t),vLo=i(x),m_=n(x,"LI",{});var YBe=s(m_);vue=n(YBe,"STRONG",{});var aAt=s(vue);bLo=r(aAt,"data2vec-vision"),aAt.forEach(t),FLo=r(YBe," \u2014 "),xO=n(YBe,"A",{href:!0});var nAt=s(xO);TLo=r(nAt,"Data2VecVisionModel"),nAt.forEach(t),MLo=r(YBe," (Data2VecVision model)"),YBe.forEach(t),ELo=i(x),g_=n(x,"LI",{});var KBe=s(g_);bue=n(KBe,"STRONG",{});var sAt=s(bue);CLo=r(sAt,"deberta"),sAt.forEach(t),wLo=r(KBe," \u2014 "),$O=n(KBe,"A",{href:!0});var lAt=s($O);ALo=r(lAt,"DebertaModel"),lAt.forEach(t),LLo=r(KBe," (DeBERTa model)"),KBe.forEach(t),yLo=i(x),h_=n(x,"LI",{});var ZBe=s(h_);Fue=n(ZBe,"STRONG",{});var iAt=s(Fue);xLo=r(iAt,"deberta-v2"),iAt.forEach(t),$Lo=r(ZBe," \u2014 "),kO=n(ZBe,"A",{href:!0});var dAt=s(kO);kLo=r(dAt,"DebertaV2Model"),dAt.forEach(t),SLo=r(ZBe," (DeBERTa-v2 model)"),ZBe.forEach(t),RLo=i(x),u_=n(x,"LI",{});var eIe=s(u_);Tue=n(eIe,"STRONG",{});var cAt=s(Tue);PLo=r(cAt,"decision_transformer"),cAt.forEach(t),BLo=r(eIe," \u2014 "),SO=n(eIe,"A",{href:!0});var fAt=s(SO);ILo=r(fAt,"DecisionTransformerModel"),fAt.forEach(t),NLo=r(eIe," (Decision Transformer model)"),eIe.forEach(t),qLo=i(x),p_=n(x,"LI",{});var oIe=s(p_);Mue=n(oIe,"STRONG",{});var mAt=s(Mue);jLo=r(mAt,"deit"),mAt.forEach(t),DLo=r(oIe," \u2014 "),RO=n(oIe,"A",{href:!0});var gAt=s(RO);GLo=r(gAt,"DeiTModel"),gAt.forEach(t),OLo=r(oIe," (DeiT model)"),oIe.forEach(t),VLo=i(x),__=n(x,"LI",{});var rIe=s(__);Eue=n(rIe,"STRONG",{});var hAt=s(Eue);XLo=r(hAt,"detr"),hAt.forEach(t),zLo=r(rIe," \u2014 "),PO=n(rIe,"A",{href:!0});var uAt=s(PO);QLo=r(uAt,"DetrModel"),uAt.forEach(t),WLo=r(rIe," (DETR model)"),rIe.forEach(t),ULo=i(x),v_=n(x,"LI",{});var tIe=s(v_);Cue=n(tIe,"STRONG",{});var pAt=s(Cue);HLo=r(pAt,"distilbert"),pAt.forEach(t),JLo=r(tIe," \u2014 "),BO=n(tIe,"A",{href:!0});var _At=s(BO);YLo=r(_At,"DistilBertModel"),_At.forEach(t),KLo=r(tIe," (DistilBERT model)"),tIe.forEach(t),ZLo=i(x),b_=n(x,"LI",{});var aIe=s(b_);wue=n(aIe,"STRONG",{});var vAt=s(wue);eyo=r(vAt,"donut-swin"),vAt.forEach(t),oyo=r(aIe," \u2014 "),IO=n(aIe,"A",{href:!0});var bAt=s(IO);ryo=r(bAt,"DonutSwinModel"),bAt.forEach(t),tyo=r(aIe," (DonutSwin model)"),aIe.forEach(t),ayo=i(x),F_=n(x,"LI",{});var nIe=s(F_);Aue=n(nIe,"STRONG",{});var FAt=s(Aue);nyo=r(FAt,"dpr"),FAt.forEach(t),syo=r(nIe," \u2014 "),NO=n(nIe,"A",{href:!0});var TAt=s(NO);lyo=r(TAt,"DPRQuestionEncoder"),TAt.forEach(t),iyo=r(nIe," (DPR model)"),nIe.forEach(t),dyo=i(x),T_=n(x,"LI",{});var sIe=s(T_);Lue=n(sIe,"STRONG",{});var MAt=s(Lue);cyo=r(MAt,"dpt"),MAt.forEach(t),fyo=r(sIe," \u2014 "),qO=n(sIe,"A",{href:!0});var EAt=s(qO);myo=r(EAt,"DPTModel"),EAt.forEach(t),gyo=r(sIe," (DPT model)"),sIe.forEach(t),hyo=i(x),M_=n(x,"LI",{});var lIe=s(M_);yue=n(lIe,"STRONG",{});var CAt=s(yue);uyo=r(CAt,"electra"),CAt.forEach(t),pyo=r(lIe," \u2014 "),jO=n(lIe,"A",{href:!0});var wAt=s(jO);_yo=r(wAt,"ElectraModel"),wAt.forEach(t),vyo=r(lIe," (ELECTRA model)"),lIe.forEach(t),byo=i(x),E_=n(x,"LI",{});var iIe=s(E_);xue=n(iIe,"STRONG",{});var AAt=s(xue);Fyo=r(AAt,"ernie"),AAt.forEach(t),Tyo=r(iIe," \u2014 "),DO=n(iIe,"A",{href:!0});var LAt=s(DO);Myo=r(LAt,"ErnieModel"),LAt.forEach(t),Eyo=r(iIe," (ERNIE model)"),iIe.forEach(t),Cyo=i(x),C_=n(x,"LI",{});var dIe=s(C_);$ue=n(dIe,"STRONG",{});var yAt=s($ue);wyo=r(yAt,"flaubert"),yAt.forEach(t),Ayo=r(dIe," \u2014 "),GO=n(dIe,"A",{href:!0});var xAt=s(GO);Lyo=r(xAt,"FlaubertModel"),xAt.forEach(t),yyo=r(dIe," (FlauBERT model)"),dIe.forEach(t),xyo=i(x),w_=n(x,"LI",{});var cIe=s(w_);kue=n(cIe,"STRONG",{});var $At=s(kue);$yo=r($At,"flava"),$At.forEach(t),kyo=r(cIe," \u2014 "),OO=n(cIe,"A",{href:!0});var kAt=s(OO);Syo=r(kAt,"FlavaModel"),kAt.forEach(t),Ryo=r(cIe," (FLAVA model)"),cIe.forEach(t),Pyo=i(x),A_=n(x,"LI",{});var fIe=s(A_);Sue=n(fIe,"STRONG",{});var SAt=s(Sue);Byo=r(SAt,"fnet"),SAt.forEach(t),Iyo=r(fIe," \u2014 "),VO=n(fIe,"A",{href:!0});var RAt=s(VO);Nyo=r(RAt,"FNetModel"),RAt.forEach(t),qyo=r(fIe," (FNet model)"),fIe.forEach(t),jyo=i(x),L_=n(x,"LI",{});var mIe=s(L_);Rue=n(mIe,"STRONG",{});var PAt=s(Rue);Dyo=r(PAt,"fsmt"),PAt.forEach(t),Gyo=r(mIe," \u2014 "),XO=n(mIe,"A",{href:!0});var BAt=s(XO);Oyo=r(BAt,"FSMTModel"),BAt.forEach(t),Vyo=r(mIe," (FairSeq Machine-Translation model)"),mIe.forEach(t),Xyo=i(x),pl=n(x,"LI",{});var bB=s(pl);Pue=n(bB,"STRONG",{});var IAt=s(Pue);zyo=r(IAt,"funnel"),IAt.forEach(t),Qyo=r(bB," \u2014 "),zO=n(bB,"A",{href:!0});var NAt=s(zO);Wyo=r(NAt,"FunnelModel"),NAt.forEach(t),Uyo=r(bB," or "),QO=n(bB,"A",{href:!0});var qAt=s(QO);Hyo=r(qAt,"FunnelBaseModel"),qAt.forEach(t),Jyo=r(bB," (Funnel Transformer model)"),bB.forEach(t),Yyo=i(x),y_=n(x,"LI",{});var gIe=s(y_);Bue=n(gIe,"STRONG",{});var jAt=s(Bue);Kyo=r(jAt,"glpn"),jAt.forEach(t),Zyo=r(gIe," \u2014 "),WO=n(gIe,"A",{href:!0});var DAt=s(WO);e8o=r(DAt,"GLPNModel"),DAt.forEach(t),o8o=r(gIe," (GLPN model)"),gIe.forEach(t),r8o=i(x),x_=n(x,"LI",{});var hIe=s(x_);Iue=n(hIe,"STRONG",{});var GAt=s(Iue);t8o=r(GAt,"gpt2"),GAt.forEach(t),a8o=r(hIe," \u2014 "),UO=n(hIe,"A",{href:!0});var OAt=s(UO);n8o=r(OAt,"GPT2Model"),OAt.forEach(t),s8o=r(hIe," (OpenAI GPT-2 model)"),hIe.forEach(t),l8o=i(x),$_=n(x,"LI",{});var uIe=s($_);Nue=n(uIe,"STRONG",{});var VAt=s(Nue);i8o=r(VAt,"gpt_neo"),VAt.forEach(t),d8o=r(uIe," \u2014 "),HO=n(uIe,"A",{href:!0});var XAt=s(HO);c8o=r(XAt,"GPTNeoModel"),XAt.forEach(t),f8o=r(uIe," (GPT Neo model)"),uIe.forEach(t),m8o=i(x),k_=n(x,"LI",{});var pIe=s(k_);que=n(pIe,"STRONG",{});var zAt=s(que);g8o=r(zAt,"gpt_neox"),zAt.forEach(t),h8o=r(pIe," \u2014 "),JO=n(pIe,"A",{href:!0});var QAt=s(JO);u8o=r(QAt,"GPTNeoXModel"),QAt.forEach(t),p8o=r(pIe," (GPT NeoX model)"),pIe.forEach(t),_8o=i(x),S_=n(x,"LI",{});var _Ie=s(S_);jue=n(_Ie,"STRONG",{});var WAt=s(jue);v8o=r(WAt,"gptj"),WAt.forEach(t),b8o=r(_Ie," \u2014 "),YO=n(_Ie,"A",{href:!0});var UAt=s(YO);F8o=r(UAt,"GPTJModel"),UAt.forEach(t),T8o=r(_Ie," (GPT-J model)"),_Ie.forEach(t),M8o=i(x),R_=n(x,"LI",{});var vIe=s(R_);Due=n(vIe,"STRONG",{});var HAt=s(Due);E8o=r(HAt,"groupvit"),HAt.forEach(t),C8o=r(vIe," \u2014 "),KO=n(vIe,"A",{href:!0});var JAt=s(KO);w8o=r(JAt,"GroupViTModel"),JAt.forEach(t),A8o=r(vIe," (GroupViT model)"),vIe.forEach(t),L8o=i(x),P_=n(x,"LI",{});var bIe=s(P_);Gue=n(bIe,"STRONG",{});var YAt=s(Gue);y8o=r(YAt,"hubert"),YAt.forEach(t),x8o=r(bIe," \u2014 "),ZO=n(bIe,"A",{href:!0});var KAt=s(ZO);$8o=r(KAt,"HubertModel"),KAt.forEach(t),k8o=r(bIe," (Hubert model)"),bIe.forEach(t),S8o=i(x),B_=n(x,"LI",{});var FIe=s(B_);Oue=n(FIe,"STRONG",{});var ZAt=s(Oue);R8o=r(ZAt,"ibert"),ZAt.forEach(t),P8o=r(FIe," \u2014 "),eV=n(FIe,"A",{href:!0});var e6t=s(eV);B8o=r(e6t,"IBertModel"),e6t.forEach(t),I8o=r(FIe," (I-BERT model)"),FIe.forEach(t),N8o=i(x),I_=n(x,"LI",{});var TIe=s(I_);Vue=n(TIe,"STRONG",{});var o6t=s(Vue);q8o=r(o6t,"imagegpt"),o6t.forEach(t),j8o=r(TIe," \u2014 "),oV=n(TIe,"A",{href:!0});var r6t=s(oV);D8o=r(r6t,"ImageGPTModel"),r6t.forEach(t),G8o=r(TIe," (ImageGPT model)"),TIe.forEach(t),O8o=i(x),N_=n(x,"LI",{});var MIe=s(N_);Xue=n(MIe,"STRONG",{});var t6t=s(Xue);V8o=r(t6t,"layoutlm"),t6t.forEach(t),X8o=r(MIe," \u2014 "),rV=n(MIe,"A",{href:!0});var a6t=s(rV);z8o=r(a6t,"LayoutLMModel"),a6t.forEach(t),Q8o=r(MIe," (LayoutLM model)"),MIe.forEach(t),W8o=i(x),q_=n(x,"LI",{});var EIe=s(q_);zue=n(EIe,"STRONG",{});var n6t=s(zue);U8o=r(n6t,"layoutlmv2"),n6t.forEach(t),H8o=r(EIe," \u2014 "),tV=n(EIe,"A",{href:!0});var s6t=s(tV);J8o=r(s6t,"LayoutLMv2Model"),s6t.forEach(t),Y8o=r(EIe," (LayoutLMv2 model)"),EIe.forEach(t),K8o=i(x),j_=n(x,"LI",{});var CIe=s(j_);Que=n(CIe,"STRONG",{});var l6t=s(Que);Z8o=r(l6t,"layoutlmv3"),l6t.forEach(t),e9o=r(CIe," \u2014 "),aV=n(CIe,"A",{href:!0});var i6t=s(aV);o9o=r(i6t,"LayoutLMv3Model"),i6t.forEach(t),r9o=r(CIe," (LayoutLMv3 model)"),CIe.forEach(t),t9o=i(x),D_=n(x,"LI",{});var wIe=s(D_);Wue=n(wIe,"STRONG",{});var d6t=s(Wue);a9o=r(d6t,"led"),d6t.forEach(t),n9o=r(wIe," \u2014 "),nV=n(wIe,"A",{href:!0});var c6t=s(nV);s9o=r(c6t,"LEDModel"),c6t.forEach(t),l9o=r(wIe," (LED model)"),wIe.forEach(t),i9o=i(x),G_=n(x,"LI",{});var AIe=s(G_);Uue=n(AIe,"STRONG",{});var f6t=s(Uue);d9o=r(f6t,"levit"),f6t.forEach(t),c9o=r(AIe," \u2014 "),sV=n(AIe,"A",{href:!0});var m6t=s(sV);f9o=r(m6t,"LevitModel"),m6t.forEach(t),m9o=r(AIe," (LeViT model)"),AIe.forEach(t),g9o=i(x),O_=n(x,"LI",{});var LIe=s(O_);Hue=n(LIe,"STRONG",{});var g6t=s(Hue);h9o=r(g6t,"longformer"),g6t.forEach(t),u9o=r(LIe," \u2014 "),lV=n(LIe,"A",{href:!0});var h6t=s(lV);p9o=r(h6t,"LongformerModel"),h6t.forEach(t),_9o=r(LIe," (Longformer model)"),LIe.forEach(t),v9o=i(x),V_=n(x,"LI",{});var yIe=s(V_);Jue=n(yIe,"STRONG",{});var u6t=s(Jue);b9o=r(u6t,"longt5"),u6t.forEach(t),F9o=r(yIe," \u2014 "),iV=n(yIe,"A",{href:!0});var p6t=s(iV);T9o=r(p6t,"LongT5Model"),p6t.forEach(t),M9o=r(yIe," (LongT5 model)"),yIe.forEach(t),E9o=i(x),X_=n(x,"LI",{});var xIe=s(X_);Yue=n(xIe,"STRONG",{});var _6t=s(Yue);C9o=r(_6t,"luke"),_6t.forEach(t),w9o=r(xIe," \u2014 "),dV=n(xIe,"A",{href:!0});var v6t=s(dV);A9o=r(v6t,"LukeModel"),v6t.forEach(t),L9o=r(xIe," (LUKE model)"),xIe.forEach(t),y9o=i(x),z_=n(x,"LI",{});var $Ie=s(z_);Kue=n($Ie,"STRONG",{});var b6t=s(Kue);x9o=r(b6t,"lxmert"),b6t.forEach(t),$9o=r($Ie," \u2014 "),cV=n($Ie,"A",{href:!0});var F6t=s(cV);k9o=r(F6t,"LxmertModel"),F6t.forEach(t),S9o=r($Ie," (LXMERT model)"),$Ie.forEach(t),R9o=i(x),Q_=n(x,"LI",{});var kIe=s(Q_);Zue=n(kIe,"STRONG",{});var T6t=s(Zue);P9o=r(T6t,"m2m_100"),T6t.forEach(t),B9o=r(kIe," \u2014 "),fV=n(kIe,"A",{href:!0});var M6t=s(fV);I9o=r(M6t,"M2M100Model"),M6t.forEach(t),N9o=r(kIe," (M2M100 model)"),kIe.forEach(t),q9o=i(x),W_=n(x,"LI",{});var SIe=s(W_);epe=n(SIe,"STRONG",{});var E6t=s(epe);j9o=r(E6t,"marian"),E6t.forEach(t),D9o=r(SIe," \u2014 "),mV=n(SIe,"A",{href:!0});var C6t=s(mV);G9o=r(C6t,"MarianModel"),C6t.forEach(t),O9o=r(SIe," (Marian model)"),SIe.forEach(t),V9o=i(x),U_=n(x,"LI",{});var RIe=s(U_);ope=n(RIe,"STRONG",{});var w6t=s(ope);X9o=r(w6t,"maskformer"),w6t.forEach(t),z9o=r(RIe," \u2014 "),gV=n(RIe,"A",{href:!0});var A6t=s(gV);Q9o=r(A6t,"MaskFormerModel"),A6t.forEach(t),W9o=r(RIe," (MaskFormer model)"),RIe.forEach(t),U9o=i(x),H_=n(x,"LI",{});var PIe=s(H_);rpe=n(PIe,"STRONG",{});var L6t=s(rpe);H9o=r(L6t,"mbart"),L6t.forEach(t),J9o=r(PIe," \u2014 "),hV=n(PIe,"A",{href:!0});var y6t=s(hV);Y9o=r(y6t,"MBartModel"),y6t.forEach(t),K9o=r(PIe," (mBART model)"),PIe.forEach(t),Z9o=i(x),J_=n(x,"LI",{});var BIe=s(J_);tpe=n(BIe,"STRONG",{});var x6t=s(tpe);exo=r(x6t,"mctct"),x6t.forEach(t),oxo=r(BIe," \u2014 "),uV=n(BIe,"A",{href:!0});var $6t=s(uV);rxo=r($6t,"MCTCTModel"),$6t.forEach(t),txo=r(BIe," (M-CTC-T model)"),BIe.forEach(t),axo=i(x),Y_=n(x,"LI",{});var IIe=s(Y_);ape=n(IIe,"STRONG",{});var k6t=s(ape);nxo=r(k6t,"megatron-bert"),k6t.forEach(t),sxo=r(IIe," \u2014 "),pV=n(IIe,"A",{href:!0});var S6t=s(pV);lxo=r(S6t,"MegatronBertModel"),S6t.forEach(t),ixo=r(IIe," (Megatron-BERT model)"),IIe.forEach(t),dxo=i(x),K_=n(x,"LI",{});var NIe=s(K_);npe=n(NIe,"STRONG",{});var R6t=s(npe);cxo=r(R6t,"mobilebert"),R6t.forEach(t),fxo=r(NIe," \u2014 "),_V=n(NIe,"A",{href:!0});var P6t=s(_V);mxo=r(P6t,"MobileBertModel"),P6t.forEach(t),gxo=r(NIe," (MobileBERT model)"),NIe.forEach(t),hxo=i(x),Z_=n(x,"LI",{});var qIe=s(Z_);spe=n(qIe,"STRONG",{});var B6t=s(spe);uxo=r(B6t,"mobilevit"),B6t.forEach(t),pxo=r(qIe," \u2014 "),vV=n(qIe,"A",{href:!0});var I6t=s(vV);_xo=r(I6t,"MobileViTModel"),I6t.forEach(t),vxo=r(qIe," (MobileViT model)"),qIe.forEach(t),bxo=i(x),e2=n(x,"LI",{});var jIe=s(e2);lpe=n(jIe,"STRONG",{});var N6t=s(lpe);Fxo=r(N6t,"mpnet"),N6t.forEach(t),Txo=r(jIe," \u2014 "),bV=n(jIe,"A",{href:!0});var q6t=s(bV);Mxo=r(q6t,"MPNetModel"),q6t.forEach(t),Exo=r(jIe," (MPNet model)"),jIe.forEach(t),Cxo=i(x),o2=n(x,"LI",{});var DIe=s(o2);ipe=n(DIe,"STRONG",{});var j6t=s(ipe);wxo=r(j6t,"mt5"),j6t.forEach(t),Axo=r(DIe," \u2014 "),FV=n(DIe,"A",{href:!0});var D6t=s(FV);Lxo=r(D6t,"MT5Model"),D6t.forEach(t),yxo=r(DIe," (MT5 model)"),DIe.forEach(t),xxo=i(x),r2=n(x,"LI",{});var GIe=s(r2);dpe=n(GIe,"STRONG",{});var G6t=s(dpe);$xo=r(G6t,"mvp"),G6t.forEach(t),kxo=r(GIe," \u2014 "),TV=n(GIe,"A",{href:!0});var O6t=s(TV);Sxo=r(O6t,"MvpModel"),O6t.forEach(t),Rxo=r(GIe," (MVP model)"),GIe.forEach(t),Pxo=i(x),t2=n(x,"LI",{});var OIe=s(t2);cpe=n(OIe,"STRONG",{});var V6t=s(cpe);Bxo=r(V6t,"nezha"),V6t.forEach(t),Ixo=r(OIe," \u2014 "),MV=n(OIe,"A",{href:!0});var X6t=s(MV);Nxo=r(X6t,"NezhaModel"),X6t.forEach(t),qxo=r(OIe," (Nezha model)"),OIe.forEach(t),jxo=i(x),a2=n(x,"LI",{});var VIe=s(a2);fpe=n(VIe,"STRONG",{});var z6t=s(fpe);Dxo=r(z6t,"nllb"),z6t.forEach(t),Gxo=r(VIe," \u2014 "),EV=n(VIe,"A",{href:!0});var Q6t=s(EV);Oxo=r(Q6t,"M2M100Model"),Q6t.forEach(t),Vxo=r(VIe," (NLLB model)"),VIe.forEach(t),Xxo=i(x),n2=n(x,"LI",{});var XIe=s(n2);mpe=n(XIe,"STRONG",{});var W6t=s(mpe);zxo=r(W6t,"nystromformer"),W6t.forEach(t),Qxo=r(XIe," \u2014 "),CV=n(XIe,"A",{href:!0});var U6t=s(CV);Wxo=r(U6t,"NystromformerModel"),U6t.forEach(t),Uxo=r(XIe," (Nystr\xF6mformer model)"),XIe.forEach(t),Hxo=i(x),s2=n(x,"LI",{});var zIe=s(s2);gpe=n(zIe,"STRONG",{});var H6t=s(gpe);Jxo=r(H6t,"openai-gpt"),H6t.forEach(t),Yxo=r(zIe," \u2014 "),wV=n(zIe,"A",{href:!0});var J6t=s(wV);Kxo=r(J6t,"OpenAIGPTModel"),J6t.forEach(t),Zxo=r(zIe," (OpenAI GPT model)"),zIe.forEach(t),e$o=i(x),l2=n(x,"LI",{});var QIe=s(l2);hpe=n(QIe,"STRONG",{});var Y6t=s(hpe);o$o=r(Y6t,"opt"),Y6t.forEach(t),r$o=r(QIe," \u2014 "),AV=n(QIe,"A",{href:!0});var K6t=s(AV);t$o=r(K6t,"OPTModel"),K6t.forEach(t),a$o=r(QIe," (OPT model)"),QIe.forEach(t),n$o=i(x),i2=n(x,"LI",{});var WIe=s(i2);upe=n(WIe,"STRONG",{});var Z6t=s(upe);s$o=r(Z6t,"owlvit"),Z6t.forEach(t),l$o=r(WIe," \u2014 "),LV=n(WIe,"A",{href:!0});var e7t=s(LV);i$o=r(e7t,"OwlViTModel"),e7t.forEach(t),d$o=r(WIe," (OWL-ViT model)"),WIe.forEach(t),c$o=i(x),d2=n(x,"LI",{});var UIe=s(d2);ppe=n(UIe,"STRONG",{});var o7t=s(ppe);f$o=r(o7t,"pegasus"),o7t.forEach(t),m$o=r(UIe," \u2014 "),yV=n(UIe,"A",{href:!0});var r7t=s(yV);g$o=r(r7t,"PegasusModel"),r7t.forEach(t),h$o=r(UIe," (Pegasus model)"),UIe.forEach(t),u$o=i(x),c2=n(x,"LI",{});var HIe=s(c2);_pe=n(HIe,"STRONG",{});var t7t=s(_pe);p$o=r(t7t,"pegasus_x"),t7t.forEach(t),_$o=r(HIe," \u2014 "),xV=n(HIe,"A",{href:!0});var a7t=s(xV);v$o=r(a7t,"PegasusXModel"),a7t.forEach(t),b$o=r(HIe," (PEGASUS-X model)"),HIe.forEach(t),F$o=i(x),f2=n(x,"LI",{});var JIe=s(f2);vpe=n(JIe,"STRONG",{});var n7t=s(vpe);T$o=r(n7t,"perceiver"),n7t.forEach(t),M$o=r(JIe," \u2014 "),$V=n(JIe,"A",{href:!0});var s7t=s($V);E$o=r(s7t,"PerceiverModel"),s7t.forEach(t),C$o=r(JIe," (Perceiver model)"),JIe.forEach(t),w$o=i(x),m2=n(x,"LI",{});var YIe=s(m2);bpe=n(YIe,"STRONG",{});var l7t=s(bpe);A$o=r(l7t,"plbart"),l7t.forEach(t),L$o=r(YIe," \u2014 "),kV=n(YIe,"A",{href:!0});var i7t=s(kV);y$o=r(i7t,"PLBartModel"),i7t.forEach(t),x$o=r(YIe," (PLBart model)"),YIe.forEach(t),$$o=i(x),g2=n(x,"LI",{});var KIe=s(g2);Fpe=n(KIe,"STRONG",{});var d7t=s(Fpe);k$o=r(d7t,"poolformer"),d7t.forEach(t),S$o=r(KIe," \u2014 "),SV=n(KIe,"A",{href:!0});var c7t=s(SV);R$o=r(c7t,"PoolFormerModel"),c7t.forEach(t),P$o=r(KIe," (PoolFormer model)"),KIe.forEach(t),B$o=i(x),h2=n(x,"LI",{});var ZIe=s(h2);Tpe=n(ZIe,"STRONG",{});var f7t=s(Tpe);I$o=r(f7t,"prophetnet"),f7t.forEach(t),N$o=r(ZIe," \u2014 "),RV=n(ZIe,"A",{href:!0});var m7t=s(RV);q$o=r(m7t,"ProphetNetModel"),m7t.forEach(t),j$o=r(ZIe," (ProphetNet model)"),ZIe.forEach(t),D$o=i(x),u2=n(x,"LI",{});var eNe=s(u2);Mpe=n(eNe,"STRONG",{});var g7t=s(Mpe);G$o=r(g7t,"qdqbert"),g7t.forEach(t),O$o=r(eNe," \u2014 "),PV=n(eNe,"A",{href:!0});var h7t=s(PV);V$o=r(h7t,"QDQBertModel"),h7t.forEach(t),X$o=r(eNe," (QDQBert model)"),eNe.forEach(t),z$o=i(x),p2=n(x,"LI",{});var oNe=s(p2);Epe=n(oNe,"STRONG",{});var u7t=s(Epe);Q$o=r(u7t,"reformer"),u7t.forEach(t),W$o=r(oNe," \u2014 "),BV=n(oNe,"A",{href:!0});var p7t=s(BV);U$o=r(p7t,"ReformerModel"),p7t.forEach(t),H$o=r(oNe," (Reformer model)"),oNe.forEach(t),J$o=i(x),_2=n(x,"LI",{});var rNe=s(_2);Cpe=n(rNe,"STRONG",{});var _7t=s(Cpe);Y$o=r(_7t,"regnet"),_7t.forEach(t),K$o=r(rNe," \u2014 "),IV=n(rNe,"A",{href:!0});var v7t=s(IV);Z$o=r(v7t,"RegNetModel"),v7t.forEach(t),eko=r(rNe," (RegNet model)"),rNe.forEach(t),oko=i(x),v2=n(x,"LI",{});var tNe=s(v2);wpe=n(tNe,"STRONG",{});var b7t=s(wpe);rko=r(b7t,"rembert"),b7t.forEach(t),tko=r(tNe," \u2014 "),NV=n(tNe,"A",{href:!0});var F7t=s(NV);ako=r(F7t,"RemBertModel"),F7t.forEach(t),nko=r(tNe," (RemBERT model)"),tNe.forEach(t),sko=i(x),b2=n(x,"LI",{});var aNe=s(b2);Ape=n(aNe,"STRONG",{});var T7t=s(Ape);lko=r(T7t,"resnet"),T7t.forEach(t),iko=r(aNe," \u2014 "),qV=n(aNe,"A",{href:!0});var M7t=s(qV);dko=r(M7t,"ResNetModel"),M7t.forEach(t),cko=r(aNe," (ResNet model)"),aNe.forEach(t),fko=i(x),F2=n(x,"LI",{});var nNe=s(F2);Lpe=n(nNe,"STRONG",{});var E7t=s(Lpe);mko=r(E7t,"retribert"),E7t.forEach(t),gko=r(nNe," \u2014 "),jV=n(nNe,"A",{href:!0});var C7t=s(jV);hko=r(C7t,"RetriBertModel"),C7t.forEach(t),uko=r(nNe," (RetriBERT model)"),nNe.forEach(t),pko=i(x),T2=n(x,"LI",{});var sNe=s(T2);ype=n(sNe,"STRONG",{});var w7t=s(ype);_ko=r(w7t,"roberta"),w7t.forEach(t),vko=r(sNe," \u2014 "),DV=n(sNe,"A",{href:!0});var A7t=s(DV);bko=r(A7t,"RobertaModel"),A7t.forEach(t),Fko=r(sNe," (RoBERTa model)"),sNe.forEach(t),Tko=i(x),M2=n(x,"LI",{});var lNe=s(M2);xpe=n(lNe,"STRONG",{});var L7t=s(xpe);Mko=r(L7t,"roformer"),L7t.forEach(t),Eko=r(lNe," \u2014 "),GV=n(lNe,"A",{href:!0});var y7t=s(GV);Cko=r(y7t,"RoFormerModel"),y7t.forEach(t),wko=r(lNe," (RoFormer model)"),lNe.forEach(t),Ako=i(x),E2=n(x,"LI",{});var iNe=s(E2);$pe=n(iNe,"STRONG",{});var x7t=s($pe);Lko=r(x7t,"segformer"),x7t.forEach(t),yko=r(iNe," \u2014 "),OV=n(iNe,"A",{href:!0});var $7t=s(OV);xko=r($7t,"SegformerModel"),$7t.forEach(t),$ko=r(iNe," (SegFormer model)"),iNe.forEach(t),kko=i(x),C2=n(x,"LI",{});var dNe=s(C2);kpe=n(dNe,"STRONG",{});var k7t=s(kpe);Sko=r(k7t,"sew"),k7t.forEach(t),Rko=r(dNe," \u2014 "),VV=n(dNe,"A",{href:!0});var S7t=s(VV);Pko=r(S7t,"SEWModel"),S7t.forEach(t),Bko=r(dNe," (SEW model)"),dNe.forEach(t),Iko=i(x),w2=n(x,"LI",{});var cNe=s(w2);Spe=n(cNe,"STRONG",{});var R7t=s(Spe);Nko=r(R7t,"sew-d"),R7t.forEach(t),qko=r(cNe," \u2014 "),XV=n(cNe,"A",{href:!0});var P7t=s(XV);jko=r(P7t,"SEWDModel"),P7t.forEach(t),Dko=r(cNe," (SEW-D model)"),cNe.forEach(t),Gko=i(x),A2=n(x,"LI",{});var fNe=s(A2);Rpe=n(fNe,"STRONG",{});var B7t=s(Rpe);Oko=r(B7t,"speech_to_text"),B7t.forEach(t),Vko=r(fNe," \u2014 "),zV=n(fNe,"A",{href:!0});var I7t=s(zV);Xko=r(I7t,"Speech2TextModel"),I7t.forEach(t),zko=r(fNe," (Speech2Text model)"),fNe.forEach(t),Qko=i(x),L2=n(x,"LI",{});var mNe=s(L2);Ppe=n(mNe,"STRONG",{});var N7t=s(Ppe);Wko=r(N7t,"splinter"),N7t.forEach(t),Uko=r(mNe," \u2014 "),QV=n(mNe,"A",{href:!0});var q7t=s(QV);Hko=r(q7t,"SplinterModel"),q7t.forEach(t),Jko=r(mNe," (Splinter model)"),mNe.forEach(t),Yko=i(x),y2=n(x,"LI",{});var gNe=s(y2);Bpe=n(gNe,"STRONG",{});var j7t=s(Bpe);Kko=r(j7t,"squeezebert"),j7t.forEach(t),Zko=r(gNe," \u2014 "),WV=n(gNe,"A",{href:!0});var D7t=s(WV);eSo=r(D7t,"SqueezeBertModel"),D7t.forEach(t),oSo=r(gNe," (SqueezeBERT model)"),gNe.forEach(t),rSo=i(x),x2=n(x,"LI",{});var hNe=s(x2);Ipe=n(hNe,"STRONG",{});var G7t=s(Ipe);tSo=r(G7t,"swin"),G7t.forEach(t),aSo=r(hNe," \u2014 "),UV=n(hNe,"A",{href:!0});var O7t=s(UV);nSo=r(O7t,"SwinModel"),O7t.forEach(t),sSo=r(hNe," (Swin Transformer model)"),hNe.forEach(t),lSo=i(x),$2=n(x,"LI",{});var uNe=s($2);Npe=n(uNe,"STRONG",{});var V7t=s(Npe);iSo=r(V7t,"swinv2"),V7t.forEach(t),dSo=r(uNe," \u2014 "),HV=n(uNe,"A",{href:!0});var X7t=s(HV);cSo=r(X7t,"Swinv2Model"),X7t.forEach(t),fSo=r(uNe," (Swin Transformer V2 model)"),uNe.forEach(t),mSo=i(x),k2=n(x,"LI",{});var pNe=s(k2);qpe=n(pNe,"STRONG",{});var z7t=s(qpe);gSo=r(z7t,"t5"),z7t.forEach(t),hSo=r(pNe," \u2014 "),JV=n(pNe,"A",{href:!0});var Q7t=s(JV);uSo=r(Q7t,"T5Model"),Q7t.forEach(t),pSo=r(pNe," (T5 model)"),pNe.forEach(t),_So=i(x),S2=n(x,"LI",{});var _Ne=s(S2);jpe=n(_Ne,"STRONG",{});var W7t=s(jpe);vSo=r(W7t,"tapas"),W7t.forEach(t),bSo=r(_Ne," \u2014 "),YV=n(_Ne,"A",{href:!0});var U7t=s(YV);FSo=r(U7t,"TapasModel"),U7t.forEach(t),TSo=r(_Ne," (TAPAS model)"),_Ne.forEach(t),MSo=i(x),R2=n(x,"LI",{});var vNe=s(R2);Dpe=n(vNe,"STRONG",{});var H7t=s(Dpe);ESo=r(H7t,"trajectory_transformer"),H7t.forEach(t),CSo=r(vNe," \u2014 "),KV=n(vNe,"A",{href:!0});var J7t=s(KV);wSo=r(J7t,"TrajectoryTransformerModel"),J7t.forEach(t),ASo=r(vNe," (Trajectory Transformer model)"),vNe.forEach(t),LSo=i(x),P2=n(x,"LI",{});var bNe=s(P2);Gpe=n(bNe,"STRONG",{});var Y7t=s(Gpe);ySo=r(Y7t,"transfo-xl"),Y7t.forEach(t),xSo=r(bNe," \u2014 "),ZV=n(bNe,"A",{href:!0});var K7t=s(ZV);$So=r(K7t,"TransfoXLModel"),K7t.forEach(t),kSo=r(bNe," (Transformer-XL model)"),bNe.forEach(t),SSo=i(x),B2=n(x,"LI",{});var FNe=s(B2);Ope=n(FNe,"STRONG",{});var Z7t=s(Ope);RSo=r(Z7t,"unispeech"),Z7t.forEach(t),PSo=r(FNe," \u2014 "),eX=n(FNe,"A",{href:!0});var eLt=s(eX);BSo=r(eLt,"UniSpeechModel"),eLt.forEach(t),ISo=r(FNe," (UniSpeech model)"),FNe.forEach(t),NSo=i(x),I2=n(x,"LI",{});var TNe=s(I2);Vpe=n(TNe,"STRONG",{});var oLt=s(Vpe);qSo=r(oLt,"unispeech-sat"),oLt.forEach(t),jSo=r(TNe," \u2014 "),oX=n(TNe,"A",{href:!0});var rLt=s(oX);DSo=r(rLt,"UniSpeechSatModel"),rLt.forEach(t),GSo=r(TNe," (UniSpeechSat model)"),TNe.forEach(t),OSo=i(x),N2=n(x,"LI",{});var MNe=s(N2);Xpe=n(MNe,"STRONG",{});var tLt=s(Xpe);VSo=r(tLt,"van"),tLt.forEach(t),XSo=r(MNe," \u2014 "),rX=n(MNe,"A",{href:!0});var aLt=s(rX);zSo=r(aLt,"VanModel"),aLt.forEach(t),QSo=r(MNe," (VAN model)"),MNe.forEach(t),WSo=i(x),q2=n(x,"LI",{});var ENe=s(q2);zpe=n(ENe,"STRONG",{});var nLt=s(zpe);USo=r(nLt,"videomae"),nLt.forEach(t),HSo=r(ENe," \u2014 "),tX=n(ENe,"A",{href:!0});var sLt=s(tX);JSo=r(sLt,"VideoMAEModel"),sLt.forEach(t),YSo=r(ENe," (VideoMAE model)"),ENe.forEach(t),KSo=i(x),j2=n(x,"LI",{});var CNe=s(j2);Qpe=n(CNe,"STRONG",{});var lLt=s(Qpe);ZSo=r(lLt,"vilt"),lLt.forEach(t),eRo=r(CNe," \u2014 "),aX=n(CNe,"A",{href:!0});var iLt=s(aX);oRo=r(iLt,"ViltModel"),iLt.forEach(t),rRo=r(CNe," (ViLT model)"),CNe.forEach(t),tRo=i(x),D2=n(x,"LI",{});var wNe=s(D2);Wpe=n(wNe,"STRONG",{});var dLt=s(Wpe);aRo=r(dLt,"vision-text-dual-encoder"),dLt.forEach(t),nRo=r(wNe," \u2014 "),nX=n(wNe,"A",{href:!0});var cLt=s(nX);sRo=r(cLt,"VisionTextDualEncoderModel"),cLt.forEach(t),lRo=r(wNe," (VisionTextDualEncoder model)"),wNe.forEach(t),iRo=i(x),G2=n(x,"LI",{});var ANe=s(G2);Upe=n(ANe,"STRONG",{});var fLt=s(Upe);dRo=r(fLt,"visual_bert"),fLt.forEach(t),cRo=r(ANe," \u2014 "),sX=n(ANe,"A",{href:!0});var mLt=s(sX);fRo=r(mLt,"VisualBertModel"),mLt.forEach(t),mRo=r(ANe," (VisualBERT model)"),ANe.forEach(t),gRo=i(x),O2=n(x,"LI",{});var LNe=s(O2);Hpe=n(LNe,"STRONG",{});var gLt=s(Hpe);hRo=r(gLt,"vit"),gLt.forEach(t),uRo=r(LNe," \u2014 "),lX=n(LNe,"A",{href:!0});var hLt=s(lX);pRo=r(hLt,"ViTModel"),hLt.forEach(t),_Ro=r(LNe," (ViT model)"),LNe.forEach(t),vRo=i(x),V2=n(x,"LI",{});var yNe=s(V2);Jpe=n(yNe,"STRONG",{});var uLt=s(Jpe);bRo=r(uLt,"vit_mae"),uLt.forEach(t),FRo=r(yNe," \u2014 "),iX=n(yNe,"A",{href:!0});var pLt=s(iX);TRo=r(pLt,"ViTMAEModel"),pLt.forEach(t),MRo=r(yNe," (ViTMAE model)"),yNe.forEach(t),ERo=i(x),X2=n(x,"LI",{});var xNe=s(X2);Ype=n(xNe,"STRONG",{});var _Lt=s(Ype);CRo=r(_Lt,"wav2vec2"),_Lt.forEach(t),wRo=r(xNe," \u2014 "),dX=n(xNe,"A",{href:!0});var vLt=s(dX);ARo=r(vLt,"Wav2Vec2Model"),vLt.forEach(t),LRo=r(xNe," (Wav2Vec2 model)"),xNe.forEach(t),yRo=i(x),z2=n(x,"LI",{});var $Ne=s(z2);Kpe=n($Ne,"STRONG",{});var bLt=s(Kpe);xRo=r(bLt,"wav2vec2-conformer"),bLt.forEach(t),$Ro=r($Ne," \u2014 "),cX=n($Ne,"A",{href:!0});var FLt=s(cX);kRo=r(FLt,"Wav2Vec2ConformerModel"),FLt.forEach(t),SRo=r($Ne," (Wav2Vec2-Conformer model)"),$Ne.forEach(t),RRo=i(x),Q2=n(x,"LI",{});var kNe=s(Q2);Zpe=n(kNe,"STRONG",{});var TLt=s(Zpe);PRo=r(TLt,"wavlm"),TLt.forEach(t),BRo=r(kNe," \u2014 "),fX=n(kNe,"A",{href:!0});var MLt=s(fX);IRo=r(MLt,"WavLMModel"),MLt.forEach(t),NRo=r(kNe," (WavLM model)"),kNe.forEach(t),qRo=i(x),W2=n(x,"LI",{});var SNe=s(W2);e_e=n(SNe,"STRONG",{});var ELt=s(e_e);jRo=r(ELt,"xclip"),ELt.forEach(t),DRo=r(SNe," \u2014 "),mX=n(SNe,"A",{href:!0});var CLt=s(mX);GRo=r(CLt,"XCLIPModel"),CLt.forEach(t),ORo=r(SNe," (X-CLIP model)"),SNe.forEach(t),VRo=i(x),U2=n(x,"LI",{});var RNe=s(U2);o_e=n(RNe,"STRONG",{});var wLt=s(o_e);XRo=r(wLt,"xglm"),wLt.forEach(t),zRo=r(RNe," \u2014 "),gX=n(RNe,"A",{href:!0});var ALt=s(gX);QRo=r(ALt,"XGLMModel"),ALt.forEach(t),WRo=r(RNe," (XGLM model)"),RNe.forEach(t),URo=i(x),H2=n(x,"LI",{});var PNe=s(H2);r_e=n(PNe,"STRONG",{});var LLt=s(r_e);HRo=r(LLt,"xlm"),LLt.forEach(t),JRo=r(PNe," \u2014 "),hX=n(PNe,"A",{href:!0});var yLt=s(hX);YRo=r(yLt,"XLMModel"),yLt.forEach(t),KRo=r(PNe," (XLM model)"),PNe.forEach(t),ZRo=i(x),J2=n(x,"LI",{});var BNe=s(J2);t_e=n(BNe,"STRONG",{});var xLt=s(t_e);ePo=r(xLt,"xlm-prophetnet"),xLt.forEach(t),oPo=r(BNe," \u2014 "),uX=n(BNe,"A",{href:!0});var $Lt=s(uX);rPo=r($Lt,"XLMProphetNetModel"),$Lt.forEach(t),tPo=r(BNe," (XLM-ProphetNet model)"),BNe.forEach(t),aPo=i(x),Y2=n(x,"LI",{});var INe=s(Y2);a_e=n(INe,"STRONG",{});var kLt=s(a_e);nPo=r(kLt,"xlm-roberta"),kLt.forEach(t),sPo=r(INe," \u2014 "),pX=n(INe,"A",{href:!0});var SLt=s(pX);lPo=r(SLt,"XLMRobertaModel"),SLt.forEach(t),iPo=r(INe," (XLM-RoBERTa model)"),INe.forEach(t),dPo=i(x),K2=n(x,"LI",{});var NNe=s(K2);n_e=n(NNe,"STRONG",{});var RLt=s(n_e);cPo=r(RLt,"xlm-roberta-xl"),RLt.forEach(t),fPo=r(NNe," \u2014 "),_X=n(NNe,"A",{href:!0});var PLt=s(_X);mPo=r(PLt,"XLMRobertaXLModel"),PLt.forEach(t),gPo=r(NNe," (XLM-RoBERTa-XL model)"),NNe.forEach(t),hPo=i(x),Z2=n(x,"LI",{});var qNe=s(Z2);s_e=n(qNe,"STRONG",{});var BLt=s(s_e);uPo=r(BLt,"xlnet"),BLt.forEach(t),pPo=r(qNe," \u2014 "),vX=n(qNe,"A",{href:!0});var ILt=s(vX);_Po=r(ILt,"XLNetModel"),ILt.forEach(t),vPo=r(qNe," (XLNet model)"),qNe.forEach(t),bPo=i(x),ev=n(x,"LI",{});var jNe=s(ev);l_e=n(jNe,"STRONG",{});var NLt=s(l_e);FPo=r(NLt,"yolos"),NLt.forEach(t),TPo=r(jNe," \u2014 "),bX=n(jNe,"A",{href:!0});var qLt=s(bX);MPo=r(qLt,"YolosModel"),qLt.forEach(t),EPo=r(jNe," (YOLOS model)"),jNe.forEach(t),CPo=i(x),ov=n(x,"LI",{});var DNe=s(ov);i_e=n(DNe,"STRONG",{});var jLt=s(i_e);wPo=r(jLt,"yoso"),jLt.forEach(t),APo=r(DNe," \u2014 "),FX=n(DNe,"A",{href:!0});var DLt=s(FX);LPo=r(DLt,"YosoModel"),DLt.forEach(t),yPo=r(DNe," (YOSO model)"),DNe.forEach(t),x.forEach(t),xPo=i(Fa),rv=n(Fa,"P",{});var GNe=s(rv);$Po=r(GNe,"The model is set in evaluation mode by default using "),d_e=n(GNe,"CODE",{});var GLt=s(d_e);kPo=r(GLt,"model.eval()"),GLt.forEach(t),SPo=r(GNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c_e=n(GNe,"CODE",{});var OLt=s(c_e);RPo=r(OLt,"model.train()"),OLt.forEach(t),GNe.forEach(t),PPo=i(Fa),T(tv.$$.fragment,Fa),Fa.forEach(t),wl.forEach(t),QYe=i(f),bd=n(f,"H2",{class:!0});var seo=s(bd);av=n(seo,"A",{id:!0,class:!0,href:!0});var VLt=s(av);f_e=n(VLt,"SPAN",{});var XLt=s(f_e);T(ex.$$.fragment,XLt),XLt.forEach(t),VLt.forEach(t),BPo=i(seo),m_e=n(seo,"SPAN",{});var zLt=s(m_e);IPo=r(zLt,"AutoModelForPreTraining"),zLt.forEach(t),seo.forEach(t),WYe=i(f),Bo=n(f,"DIV",{class:!0});var Al=s(Bo);T(ox.$$.fragment,Al),NPo=i(Al),Fd=n(Al,"P",{});var Hse=s(Fd);qPo=r(Hse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TX=n(Hse,"A",{href:!0});var QLt=s(TX);jPo=r(QLt,"from_pretrained()"),QLt.forEach(t),DPo=r(Hse," class method or the "),MX=n(Hse,"A",{href:!0});var WLt=s(MX);GPo=r(WLt,"from_config()"),WLt.forEach(t),OPo=r(Hse,` class
method.`),Hse.forEach(t),VPo=i(Al),rx=n(Al,"P",{});var leo=s(rx);XPo=r(leo,"This class cannot be instantiated directly using "),g_e=n(leo,"CODE",{});var ULt=s(g_e);zPo=r(ULt,"__init__()"),ULt.forEach(t),QPo=r(leo," (throws an error)."),leo.forEach(t),WPo=i(Al),vt=n(Al,"DIV",{class:!0});var Fy=s(vt);T(tx.$$.fragment,Fy),UPo=i(Fy),h_e=n(Fy,"P",{});var HLt=s(h_e);HPo=r(HLt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HLt.forEach(t),JPo=i(Fy),Td=n(Fy,"P",{});var Jse=s(Td);YPo=r(Jse,`Note:
Loading a model from its configuration file does `),u_e=n(Jse,"STRONG",{});var JLt=s(u_e);KPo=r(JLt,"not"),JLt.forEach(t),ZPo=r(Jse,` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=n(Jse,"A",{href:!0});var YLt=s(EX);eBo=r(YLt,"from_pretrained()"),YLt.forEach(t),oBo=r(Jse," to load the model weights."),Jse.forEach(t),rBo=i(Fy),T(nv.$$.fragment,Fy),Fy.forEach(t),tBo=i(Al),eo=n(Al,"DIV",{class:!0});var Ta=s(eo);T(ax.$$.fragment,Ta),aBo=i(Ta),p_e=n(Ta,"P",{});var KLt=s(p_e);nBo=r(KLt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KLt.forEach(t),sBo=i(Ta),Ya=n(Ta,"P",{});var Ty=s(Ya);lBo=r(Ty,"The model class to instantiate is selected based on the "),__e=n(Ty,"CODE",{});var ZLt=s(__e);iBo=r(ZLt,"model_type"),ZLt.forEach(t),dBo=r(Ty,` property of the config object (either
passed as an argument or loaded from `),v_e=n(Ty,"CODE",{});var eyt=s(v_e);cBo=r(eyt,"pretrained_model_name_or_path"),eyt.forEach(t),fBo=r(Ty,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=n(Ty,"CODE",{});var oyt=s(b_e);mBo=r(oyt,"pretrained_model_name_or_path"),oyt.forEach(t),gBo=r(Ty,":"),Ty.forEach(t),hBo=i(Ta),G=n(Ta,"UL",{});var O=s(G);sv=n(O,"LI",{});var ONe=s(sv);F_e=n(ONe,"STRONG",{});var ryt=s(F_e);uBo=r(ryt,"albert"),ryt.forEach(t),pBo=r(ONe," \u2014 "),CX=n(ONe,"A",{href:!0});var tyt=s(CX);_Bo=r(tyt,"AlbertForPreTraining"),tyt.forEach(t),vBo=r(ONe," (ALBERT model)"),ONe.forEach(t),bBo=i(O),lv=n(O,"LI",{});var VNe=s(lv);T_e=n(VNe,"STRONG",{});var ayt=s(T_e);FBo=r(ayt,"bart"),ayt.forEach(t),TBo=r(VNe," \u2014 "),wX=n(VNe,"A",{href:!0});var nyt=s(wX);MBo=r(nyt,"BartForConditionalGeneration"),nyt.forEach(t),EBo=r(VNe," (BART model)"),VNe.forEach(t),CBo=i(O),iv=n(O,"LI",{});var XNe=s(iv);M_e=n(XNe,"STRONG",{});var syt=s(M_e);wBo=r(syt,"bert"),syt.forEach(t),ABo=r(XNe," \u2014 "),AX=n(XNe,"A",{href:!0});var lyt=s(AX);LBo=r(lyt,"BertForPreTraining"),lyt.forEach(t),yBo=r(XNe," (BERT model)"),XNe.forEach(t),xBo=i(O),dv=n(O,"LI",{});var zNe=s(dv);E_e=n(zNe,"STRONG",{});var iyt=s(E_e);$Bo=r(iyt,"big_bird"),iyt.forEach(t),kBo=r(zNe," \u2014 "),LX=n(zNe,"A",{href:!0});var dyt=s(LX);SBo=r(dyt,"BigBirdForPreTraining"),dyt.forEach(t),RBo=r(zNe," (BigBird model)"),zNe.forEach(t),PBo=i(O),cv=n(O,"LI",{});var QNe=s(cv);C_e=n(QNe,"STRONG",{});var cyt=s(C_e);BBo=r(cyt,"bloom"),cyt.forEach(t),IBo=r(QNe," \u2014 "),yX=n(QNe,"A",{href:!0});var fyt=s(yX);NBo=r(fyt,"BloomForCausalLM"),fyt.forEach(t),qBo=r(QNe," (BLOOM model)"),QNe.forEach(t),jBo=i(O),fv=n(O,"LI",{});var WNe=s(fv);w_e=n(WNe,"STRONG",{});var myt=s(w_e);DBo=r(myt,"camembert"),myt.forEach(t),GBo=r(WNe," \u2014 "),xX=n(WNe,"A",{href:!0});var gyt=s(xX);OBo=r(gyt,"CamembertForMaskedLM"),gyt.forEach(t),VBo=r(WNe," (CamemBERT model)"),WNe.forEach(t),XBo=i(O),mv=n(O,"LI",{});var UNe=s(mv);A_e=n(UNe,"STRONG",{});var hyt=s(A_e);zBo=r(hyt,"ctrl"),hyt.forEach(t),QBo=r(UNe," \u2014 "),$X=n(UNe,"A",{href:!0});var uyt=s($X);WBo=r(uyt,"CTRLLMHeadModel"),uyt.forEach(t),UBo=r(UNe," (CTRL model)"),UNe.forEach(t),HBo=i(O),gv=n(O,"LI",{});var HNe=s(gv);L_e=n(HNe,"STRONG",{});var pyt=s(L_e);JBo=r(pyt,"data2vec-text"),pyt.forEach(t),YBo=r(HNe," \u2014 "),kX=n(HNe,"A",{href:!0});var _yt=s(kX);KBo=r(_yt,"Data2VecTextForMaskedLM"),_yt.forEach(t),ZBo=r(HNe," (Data2VecText model)"),HNe.forEach(t),eIo=i(O),hv=n(O,"LI",{});var JNe=s(hv);y_e=n(JNe,"STRONG",{});var vyt=s(y_e);oIo=r(vyt,"deberta"),vyt.forEach(t),rIo=r(JNe," \u2014 "),SX=n(JNe,"A",{href:!0});var byt=s(SX);tIo=r(byt,"DebertaForMaskedLM"),byt.forEach(t),aIo=r(JNe," (DeBERTa model)"),JNe.forEach(t),nIo=i(O),uv=n(O,"LI",{});var YNe=s(uv);x_e=n(YNe,"STRONG",{});var Fyt=s(x_e);sIo=r(Fyt,"deberta-v2"),Fyt.forEach(t),lIo=r(YNe," \u2014 "),RX=n(YNe,"A",{href:!0});var Tyt=s(RX);iIo=r(Tyt,"DebertaV2ForMaskedLM"),Tyt.forEach(t),dIo=r(YNe," (DeBERTa-v2 model)"),YNe.forEach(t),cIo=i(O),pv=n(O,"LI",{});var KNe=s(pv);$_e=n(KNe,"STRONG",{});var Myt=s($_e);fIo=r(Myt,"distilbert"),Myt.forEach(t),mIo=r(KNe," \u2014 "),PX=n(KNe,"A",{href:!0});var Eyt=s(PX);gIo=r(Eyt,"DistilBertForMaskedLM"),Eyt.forEach(t),hIo=r(KNe," (DistilBERT model)"),KNe.forEach(t),uIo=i(O),_v=n(O,"LI",{});var ZNe=s(_v);k_e=n(ZNe,"STRONG",{});var Cyt=s(k_e);pIo=r(Cyt,"electra"),Cyt.forEach(t),_Io=r(ZNe," \u2014 "),BX=n(ZNe,"A",{href:!0});var wyt=s(BX);vIo=r(wyt,"ElectraForPreTraining"),wyt.forEach(t),bIo=r(ZNe," (ELECTRA model)"),ZNe.forEach(t),FIo=i(O),vv=n(O,"LI",{});var eqe=s(vv);S_e=n(eqe,"STRONG",{});var Ayt=s(S_e);TIo=r(Ayt,"ernie"),Ayt.forEach(t),MIo=r(eqe," \u2014 "),IX=n(eqe,"A",{href:!0});var Lyt=s(IX);EIo=r(Lyt,"ErnieForPreTraining"),Lyt.forEach(t),CIo=r(eqe," (ERNIE model)"),eqe.forEach(t),wIo=i(O),bv=n(O,"LI",{});var oqe=s(bv);R_e=n(oqe,"STRONG",{});var yyt=s(R_e);AIo=r(yyt,"flaubert"),yyt.forEach(t),LIo=r(oqe," \u2014 "),NX=n(oqe,"A",{href:!0});var xyt=s(NX);yIo=r(xyt,"FlaubertWithLMHeadModel"),xyt.forEach(t),xIo=r(oqe," (FlauBERT model)"),oqe.forEach(t),$Io=i(O),Fv=n(O,"LI",{});var rqe=s(Fv);P_e=n(rqe,"STRONG",{});var $yt=s(P_e);kIo=r($yt,"flava"),$yt.forEach(t),SIo=r(rqe," \u2014 "),qX=n(rqe,"A",{href:!0});var kyt=s(qX);RIo=r(kyt,"FlavaForPreTraining"),kyt.forEach(t),PIo=r(rqe," (FLAVA model)"),rqe.forEach(t),BIo=i(O),Tv=n(O,"LI",{});var tqe=s(Tv);B_e=n(tqe,"STRONG",{});var Syt=s(B_e);IIo=r(Syt,"fnet"),Syt.forEach(t),NIo=r(tqe," \u2014 "),jX=n(tqe,"A",{href:!0});var Ryt=s(jX);qIo=r(Ryt,"FNetForPreTraining"),Ryt.forEach(t),jIo=r(tqe," (FNet model)"),tqe.forEach(t),DIo=i(O),Mv=n(O,"LI",{});var aqe=s(Mv);I_e=n(aqe,"STRONG",{});var Pyt=s(I_e);GIo=r(Pyt,"fsmt"),Pyt.forEach(t),OIo=r(aqe," \u2014 "),DX=n(aqe,"A",{href:!0});var Byt=s(DX);VIo=r(Byt,"FSMTForConditionalGeneration"),Byt.forEach(t),XIo=r(aqe," (FairSeq Machine-Translation model)"),aqe.forEach(t),zIo=i(O),Ev=n(O,"LI",{});var nqe=s(Ev);N_e=n(nqe,"STRONG",{});var Iyt=s(N_e);QIo=r(Iyt,"funnel"),Iyt.forEach(t),WIo=r(nqe," \u2014 "),GX=n(nqe,"A",{href:!0});var Nyt=s(GX);UIo=r(Nyt,"FunnelForPreTraining"),Nyt.forEach(t),HIo=r(nqe," (Funnel Transformer model)"),nqe.forEach(t),JIo=i(O),Cv=n(O,"LI",{});var sqe=s(Cv);q_e=n(sqe,"STRONG",{});var qyt=s(q_e);YIo=r(qyt,"gpt2"),qyt.forEach(t),KIo=r(sqe," \u2014 "),OX=n(sqe,"A",{href:!0});var jyt=s(OX);ZIo=r(jyt,"GPT2LMHeadModel"),jyt.forEach(t),eNo=r(sqe," (OpenAI GPT-2 model)"),sqe.forEach(t),oNo=i(O),wv=n(O,"LI",{});var lqe=s(wv);j_e=n(lqe,"STRONG",{});var Dyt=s(j_e);rNo=r(Dyt,"ibert"),Dyt.forEach(t),tNo=r(lqe," \u2014 "),VX=n(lqe,"A",{href:!0});var Gyt=s(VX);aNo=r(Gyt,"IBertForMaskedLM"),Gyt.forEach(t),nNo=r(lqe," (I-BERT model)"),lqe.forEach(t),sNo=i(O),Av=n(O,"LI",{});var iqe=s(Av);D_e=n(iqe,"STRONG",{});var Oyt=s(D_e);lNo=r(Oyt,"layoutlm"),Oyt.forEach(t),iNo=r(iqe," \u2014 "),XX=n(iqe,"A",{href:!0});var Vyt=s(XX);dNo=r(Vyt,"LayoutLMForMaskedLM"),Vyt.forEach(t),cNo=r(iqe," (LayoutLM model)"),iqe.forEach(t),fNo=i(O),Lv=n(O,"LI",{});var dqe=s(Lv);G_e=n(dqe,"STRONG",{});var Xyt=s(G_e);mNo=r(Xyt,"longformer"),Xyt.forEach(t),gNo=r(dqe," \u2014 "),zX=n(dqe,"A",{href:!0});var zyt=s(zX);hNo=r(zyt,"LongformerForMaskedLM"),zyt.forEach(t),uNo=r(dqe," (Longformer model)"),dqe.forEach(t),pNo=i(O),yv=n(O,"LI",{});var cqe=s(yv);O_e=n(cqe,"STRONG",{});var Qyt=s(O_e);_No=r(Qyt,"luke"),Qyt.forEach(t),vNo=r(cqe," \u2014 "),QX=n(cqe,"A",{href:!0});var Wyt=s(QX);bNo=r(Wyt,"LukeForMaskedLM"),Wyt.forEach(t),FNo=r(cqe," (LUKE model)"),cqe.forEach(t),TNo=i(O),xv=n(O,"LI",{});var fqe=s(xv);V_e=n(fqe,"STRONG",{});var Uyt=s(V_e);MNo=r(Uyt,"lxmert"),Uyt.forEach(t),ENo=r(fqe," \u2014 "),WX=n(fqe,"A",{href:!0});var Hyt=s(WX);CNo=r(Hyt,"LxmertForPreTraining"),Hyt.forEach(t),wNo=r(fqe," (LXMERT model)"),fqe.forEach(t),ANo=i(O),$v=n(O,"LI",{});var mqe=s($v);X_e=n(mqe,"STRONG",{});var Jyt=s(X_e);LNo=r(Jyt,"megatron-bert"),Jyt.forEach(t),yNo=r(mqe," \u2014 "),UX=n(mqe,"A",{href:!0});var Yyt=s(UX);xNo=r(Yyt,"MegatronBertForPreTraining"),Yyt.forEach(t),$No=r(mqe," (Megatron-BERT model)"),mqe.forEach(t),kNo=i(O),kv=n(O,"LI",{});var gqe=s(kv);z_e=n(gqe,"STRONG",{});var Kyt=s(z_e);SNo=r(Kyt,"mobilebert"),Kyt.forEach(t),RNo=r(gqe," \u2014 "),HX=n(gqe,"A",{href:!0});var Zyt=s(HX);PNo=r(Zyt,"MobileBertForPreTraining"),Zyt.forEach(t),BNo=r(gqe," (MobileBERT model)"),gqe.forEach(t),INo=i(O),Sv=n(O,"LI",{});var hqe=s(Sv);Q_e=n(hqe,"STRONG",{});var e8t=s(Q_e);NNo=r(e8t,"mpnet"),e8t.forEach(t),qNo=r(hqe," \u2014 "),JX=n(hqe,"A",{href:!0});var o8t=s(JX);jNo=r(o8t,"MPNetForMaskedLM"),o8t.forEach(t),DNo=r(hqe," (MPNet model)"),hqe.forEach(t),GNo=i(O),Rv=n(O,"LI",{});var uqe=s(Rv);W_e=n(uqe,"STRONG",{});var r8t=s(W_e);ONo=r(r8t,"mvp"),r8t.forEach(t),VNo=r(uqe," \u2014 "),YX=n(uqe,"A",{href:!0});var t8t=s(YX);XNo=r(t8t,"MvpForConditionalGeneration"),t8t.forEach(t),zNo=r(uqe," (MVP model)"),uqe.forEach(t),QNo=i(O),Pv=n(O,"LI",{});var pqe=s(Pv);U_e=n(pqe,"STRONG",{});var a8t=s(U_e);WNo=r(a8t,"nezha"),a8t.forEach(t),UNo=r(pqe," \u2014 "),KX=n(pqe,"A",{href:!0});var n8t=s(KX);HNo=r(n8t,"NezhaForPreTraining"),n8t.forEach(t),JNo=r(pqe," (Nezha model)"),pqe.forEach(t),YNo=i(O),Bv=n(O,"LI",{});var _qe=s(Bv);H_e=n(_qe,"STRONG",{});var s8t=s(H_e);KNo=r(s8t,"openai-gpt"),s8t.forEach(t),ZNo=r(_qe," \u2014 "),ZX=n(_qe,"A",{href:!0});var l8t=s(ZX);eqo=r(l8t,"OpenAIGPTLMHeadModel"),l8t.forEach(t),oqo=r(_qe," (OpenAI GPT model)"),_qe.forEach(t),rqo=i(O),Iv=n(O,"LI",{});var vqe=s(Iv);J_e=n(vqe,"STRONG",{});var i8t=s(J_e);tqo=r(i8t,"retribert"),i8t.forEach(t),aqo=r(vqe," \u2014 "),ez=n(vqe,"A",{href:!0});var d8t=s(ez);nqo=r(d8t,"RetriBertModel"),d8t.forEach(t),sqo=r(vqe," (RetriBERT model)"),vqe.forEach(t),lqo=i(O),Nv=n(O,"LI",{});var bqe=s(Nv);Y_e=n(bqe,"STRONG",{});var c8t=s(Y_e);iqo=r(c8t,"roberta"),c8t.forEach(t),dqo=r(bqe," \u2014 "),oz=n(bqe,"A",{href:!0});var f8t=s(oz);cqo=r(f8t,"RobertaForMaskedLM"),f8t.forEach(t),fqo=r(bqe," (RoBERTa model)"),bqe.forEach(t),mqo=i(O),qv=n(O,"LI",{});var Fqe=s(qv);K_e=n(Fqe,"STRONG",{});var m8t=s(K_e);gqo=r(m8t,"splinter"),m8t.forEach(t),hqo=r(Fqe," \u2014 "),rz=n(Fqe,"A",{href:!0});var g8t=s(rz);uqo=r(g8t,"SplinterForPreTraining"),g8t.forEach(t),pqo=r(Fqe," (Splinter model)"),Fqe.forEach(t),_qo=i(O),jv=n(O,"LI",{});var Tqe=s(jv);Z_e=n(Tqe,"STRONG",{});var h8t=s(Z_e);vqo=r(h8t,"squeezebert"),h8t.forEach(t),bqo=r(Tqe," \u2014 "),tz=n(Tqe,"A",{href:!0});var u8t=s(tz);Fqo=r(u8t,"SqueezeBertForMaskedLM"),u8t.forEach(t),Tqo=r(Tqe," (SqueezeBERT model)"),Tqe.forEach(t),Mqo=i(O),Dv=n(O,"LI",{});var Mqe=s(Dv);e2e=n(Mqe,"STRONG",{});var p8t=s(e2e);Eqo=r(p8t,"t5"),p8t.forEach(t),Cqo=r(Mqe," \u2014 "),az=n(Mqe,"A",{href:!0});var _8t=s(az);wqo=r(_8t,"T5ForConditionalGeneration"),_8t.forEach(t),Aqo=r(Mqe," (T5 model)"),Mqe.forEach(t),Lqo=i(O),Gv=n(O,"LI",{});var Eqe=s(Gv);o2e=n(Eqe,"STRONG",{});var v8t=s(o2e);yqo=r(v8t,"tapas"),v8t.forEach(t),xqo=r(Eqe," \u2014 "),nz=n(Eqe,"A",{href:!0});var b8t=s(nz);$qo=r(b8t,"TapasForMaskedLM"),b8t.forEach(t),kqo=r(Eqe," (TAPAS model)"),Eqe.forEach(t),Sqo=i(O),Ov=n(O,"LI",{});var Cqe=s(Ov);r2e=n(Cqe,"STRONG",{});var F8t=s(r2e);Rqo=r(F8t,"transfo-xl"),F8t.forEach(t),Pqo=r(Cqe," \u2014 "),sz=n(Cqe,"A",{href:!0});var T8t=s(sz);Bqo=r(T8t,"TransfoXLLMHeadModel"),T8t.forEach(t),Iqo=r(Cqe," (Transformer-XL model)"),Cqe.forEach(t),Nqo=i(O),Vv=n(O,"LI",{});var wqe=s(Vv);t2e=n(wqe,"STRONG",{});var M8t=s(t2e);qqo=r(M8t,"unispeech"),M8t.forEach(t),jqo=r(wqe," \u2014 "),lz=n(wqe,"A",{href:!0});var E8t=s(lz);Dqo=r(E8t,"UniSpeechForPreTraining"),E8t.forEach(t),Gqo=r(wqe," (UniSpeech model)"),wqe.forEach(t),Oqo=i(O),Xv=n(O,"LI",{});var Aqe=s(Xv);a2e=n(Aqe,"STRONG",{});var C8t=s(a2e);Vqo=r(C8t,"unispeech-sat"),C8t.forEach(t),Xqo=r(Aqe," \u2014 "),iz=n(Aqe,"A",{href:!0});var w8t=s(iz);zqo=r(w8t,"UniSpeechSatForPreTraining"),w8t.forEach(t),Qqo=r(Aqe," (UniSpeechSat model)"),Aqe.forEach(t),Wqo=i(O),zv=n(O,"LI",{});var Lqe=s(zv);n2e=n(Lqe,"STRONG",{});var A8t=s(n2e);Uqo=r(A8t,"videomae"),A8t.forEach(t),Hqo=r(Lqe," \u2014 "),dz=n(Lqe,"A",{href:!0});var L8t=s(dz);Jqo=r(L8t,"VideoMAEForPreTraining"),L8t.forEach(t),Yqo=r(Lqe," (VideoMAE model)"),Lqe.forEach(t),Kqo=i(O),Qv=n(O,"LI",{});var yqe=s(Qv);s2e=n(yqe,"STRONG",{});var y8t=s(s2e);Zqo=r(y8t,"visual_bert"),y8t.forEach(t),ejo=r(yqe," \u2014 "),cz=n(yqe,"A",{href:!0});var x8t=s(cz);ojo=r(x8t,"VisualBertForPreTraining"),x8t.forEach(t),rjo=r(yqe," (VisualBERT model)"),yqe.forEach(t),tjo=i(O),Wv=n(O,"LI",{});var xqe=s(Wv);l2e=n(xqe,"STRONG",{});var $8t=s(l2e);ajo=r($8t,"vit_mae"),$8t.forEach(t),njo=r(xqe," \u2014 "),fz=n(xqe,"A",{href:!0});var k8t=s(fz);sjo=r(k8t,"ViTMAEForPreTraining"),k8t.forEach(t),ljo=r(xqe," (ViTMAE model)"),xqe.forEach(t),ijo=i(O),Uv=n(O,"LI",{});var $qe=s(Uv);i2e=n($qe,"STRONG",{});var S8t=s(i2e);djo=r(S8t,"wav2vec2"),S8t.forEach(t),cjo=r($qe," \u2014 "),mz=n($qe,"A",{href:!0});var R8t=s(mz);fjo=r(R8t,"Wav2Vec2ForPreTraining"),R8t.forEach(t),mjo=r($qe," (Wav2Vec2 model)"),$qe.forEach(t),gjo=i(O),Hv=n(O,"LI",{});var kqe=s(Hv);d2e=n(kqe,"STRONG",{});var P8t=s(d2e);hjo=r(P8t,"wav2vec2-conformer"),P8t.forEach(t),ujo=r(kqe," \u2014 "),gz=n(kqe,"A",{href:!0});var B8t=s(gz);pjo=r(B8t,"Wav2Vec2ConformerForPreTraining"),B8t.forEach(t),_jo=r(kqe," (Wav2Vec2-Conformer model)"),kqe.forEach(t),vjo=i(O),Jv=n(O,"LI",{});var Sqe=s(Jv);c2e=n(Sqe,"STRONG",{});var I8t=s(c2e);bjo=r(I8t,"xlm"),I8t.forEach(t),Fjo=r(Sqe," \u2014 "),hz=n(Sqe,"A",{href:!0});var N8t=s(hz);Tjo=r(N8t,"XLMWithLMHeadModel"),N8t.forEach(t),Mjo=r(Sqe," (XLM model)"),Sqe.forEach(t),Ejo=i(O),Yv=n(O,"LI",{});var Rqe=s(Yv);f2e=n(Rqe,"STRONG",{});var q8t=s(f2e);Cjo=r(q8t,"xlm-roberta"),q8t.forEach(t),wjo=r(Rqe," \u2014 "),uz=n(Rqe,"A",{href:!0});var j8t=s(uz);Ajo=r(j8t,"XLMRobertaForMaskedLM"),j8t.forEach(t),Ljo=r(Rqe," (XLM-RoBERTa model)"),Rqe.forEach(t),yjo=i(O),Kv=n(O,"LI",{});var Pqe=s(Kv);m2e=n(Pqe,"STRONG",{});var D8t=s(m2e);xjo=r(D8t,"xlm-roberta-xl"),D8t.forEach(t),$jo=r(Pqe," \u2014 "),pz=n(Pqe,"A",{href:!0});var G8t=s(pz);kjo=r(G8t,"XLMRobertaXLForMaskedLM"),G8t.forEach(t),Sjo=r(Pqe," (XLM-RoBERTa-XL model)"),Pqe.forEach(t),Rjo=i(O),Zv=n(O,"LI",{});var Bqe=s(Zv);g2e=n(Bqe,"STRONG",{});var O8t=s(g2e);Pjo=r(O8t,"xlnet"),O8t.forEach(t),Bjo=r(Bqe," \u2014 "),_z=n(Bqe,"A",{href:!0});var V8t=s(_z);Ijo=r(V8t,"XLNetLMHeadModel"),V8t.forEach(t),Njo=r(Bqe," (XLNet model)"),Bqe.forEach(t),O.forEach(t),qjo=i(Ta),e1=n(Ta,"P",{});var Iqe=s(e1);jjo=r(Iqe,"The model is set in evaluation mode by default using "),h2e=n(Iqe,"CODE",{});var X8t=s(h2e);Djo=r(X8t,"model.eval()"),X8t.forEach(t),Gjo=r(Iqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=n(Iqe,"CODE",{});var z8t=s(u2e);Ojo=r(z8t,"model.train()"),z8t.forEach(t),Iqe.forEach(t),Vjo=i(Ta),T(o1.$$.fragment,Ta),Ta.forEach(t),Al.forEach(t),UYe=i(f),Md=n(f,"H2",{class:!0});var ieo=s(Md);r1=n(ieo,"A",{id:!0,class:!0,href:!0});var Q8t=s(r1);p2e=n(Q8t,"SPAN",{});var W8t=s(p2e);T(nx.$$.fragment,W8t),W8t.forEach(t),Q8t.forEach(t),Xjo=i(ieo),_2e=n(ieo,"SPAN",{});var U8t=s(_2e);zjo=r(U8t,"AutoModelForCausalLM"),U8t.forEach(t),ieo.forEach(t),HYe=i(f),Io=n(f,"DIV",{class:!0});var Ll=s(Io);T(sx.$$.fragment,Ll),Qjo=i(Ll),Ed=n(Ll,"P",{});var Yse=s(Ed);Wjo=r(Yse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vz=n(Yse,"A",{href:!0});var H8t=s(vz);Ujo=r(H8t,"from_pretrained()"),H8t.forEach(t),Hjo=r(Yse," class method or the "),bz=n(Yse,"A",{href:!0});var J8t=s(bz);Jjo=r(J8t,"from_config()"),J8t.forEach(t),Yjo=r(Yse,` class
method.`),Yse.forEach(t),Kjo=i(Ll),lx=n(Ll,"P",{});var deo=s(lx);Zjo=r(deo,"This class cannot be instantiated directly using "),v2e=n(deo,"CODE",{});var Y8t=s(v2e);eDo=r(Y8t,"__init__()"),Y8t.forEach(t),oDo=r(deo," (throws an error)."),deo.forEach(t),rDo=i(Ll),bt=n(Ll,"DIV",{class:!0});var My=s(bt);T(ix.$$.fragment,My),tDo=i(My),b2e=n(My,"P",{});var K8t=s(b2e);aDo=r(K8t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),K8t.forEach(t),nDo=i(My),Cd=n(My,"P",{});var Kse=s(Cd);sDo=r(Kse,`Note:
Loading a model from its configuration file does `),F2e=n(Kse,"STRONG",{});var Z8t=s(F2e);lDo=r(Z8t,"not"),Z8t.forEach(t),iDo=r(Kse,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(Kse,"A",{href:!0});var e9t=s(Fz);dDo=r(e9t,"from_pretrained()"),e9t.forEach(t),cDo=r(Kse," to load the model weights."),Kse.forEach(t),fDo=i(My),T(t1.$$.fragment,My),My.forEach(t),mDo=i(Ll),oo=n(Ll,"DIV",{class:!0});var Ma=s(oo);T(dx.$$.fragment,Ma),gDo=i(Ma),T2e=n(Ma,"P",{});var o9t=s(T2e);hDo=r(o9t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),o9t.forEach(t),uDo=i(Ma),Ka=n(Ma,"P",{});var Ey=s(Ka);pDo=r(Ey,"The model class to instantiate is selected based on the "),M2e=n(Ey,"CODE",{});var r9t=s(M2e);_Do=r(r9t,"model_type"),r9t.forEach(t),vDo=r(Ey,` property of the config object (either
passed as an argument or loaded from `),E2e=n(Ey,"CODE",{});var t9t=s(E2e);bDo=r(t9t,"pretrained_model_name_or_path"),t9t.forEach(t),FDo=r(Ey,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C2e=n(Ey,"CODE",{});var a9t=s(C2e);TDo=r(a9t,"pretrained_model_name_or_path"),a9t.forEach(t),MDo=r(Ey,":"),Ey.forEach(t),EDo=i(Ma),z=n(Ma,"UL",{});var Q=s(z);a1=n(Q,"LI",{});var Nqe=s(a1);w2e=n(Nqe,"STRONG",{});var n9t=s(w2e);CDo=r(n9t,"bart"),n9t.forEach(t),wDo=r(Nqe," \u2014 "),Tz=n(Nqe,"A",{href:!0});var s9t=s(Tz);ADo=r(s9t,"BartForCausalLM"),s9t.forEach(t),LDo=r(Nqe," (BART model)"),Nqe.forEach(t),yDo=i(Q),n1=n(Q,"LI",{});var qqe=s(n1);A2e=n(qqe,"STRONG",{});var l9t=s(A2e);xDo=r(l9t,"bert"),l9t.forEach(t),$Do=r(qqe," \u2014 "),Mz=n(qqe,"A",{href:!0});var i9t=s(Mz);kDo=r(i9t,"BertLMHeadModel"),i9t.forEach(t),SDo=r(qqe," (BERT model)"),qqe.forEach(t),RDo=i(Q),s1=n(Q,"LI",{});var jqe=s(s1);L2e=n(jqe,"STRONG",{});var d9t=s(L2e);PDo=r(d9t,"bert-generation"),d9t.forEach(t),BDo=r(jqe," \u2014 "),Ez=n(jqe,"A",{href:!0});var c9t=s(Ez);IDo=r(c9t,"BertGenerationDecoder"),c9t.forEach(t),NDo=r(jqe," (Bert Generation model)"),jqe.forEach(t),qDo=i(Q),l1=n(Q,"LI",{});var Dqe=s(l1);y2e=n(Dqe,"STRONG",{});var f9t=s(y2e);jDo=r(f9t,"big_bird"),f9t.forEach(t),DDo=r(Dqe," \u2014 "),Cz=n(Dqe,"A",{href:!0});var m9t=s(Cz);GDo=r(m9t,"BigBirdForCausalLM"),m9t.forEach(t),ODo=r(Dqe," (BigBird model)"),Dqe.forEach(t),VDo=i(Q),i1=n(Q,"LI",{});var Gqe=s(i1);x2e=n(Gqe,"STRONG",{});var g9t=s(x2e);XDo=r(g9t,"bigbird_pegasus"),g9t.forEach(t),zDo=r(Gqe," \u2014 "),wz=n(Gqe,"A",{href:!0});var h9t=s(wz);QDo=r(h9t,"BigBirdPegasusForCausalLM"),h9t.forEach(t),WDo=r(Gqe," (BigBird-Pegasus model)"),Gqe.forEach(t),UDo=i(Q),d1=n(Q,"LI",{});var Oqe=s(d1);$2e=n(Oqe,"STRONG",{});var u9t=s($2e);HDo=r(u9t,"blenderbot"),u9t.forEach(t),JDo=r(Oqe," \u2014 "),Az=n(Oqe,"A",{href:!0});var p9t=s(Az);YDo=r(p9t,"BlenderbotForCausalLM"),p9t.forEach(t),KDo=r(Oqe," (Blenderbot model)"),Oqe.forEach(t),ZDo=i(Q),c1=n(Q,"LI",{});var Vqe=s(c1);k2e=n(Vqe,"STRONG",{});var _9t=s(k2e);eGo=r(_9t,"blenderbot-small"),_9t.forEach(t),oGo=r(Vqe," \u2014 "),Lz=n(Vqe,"A",{href:!0});var v9t=s(Lz);rGo=r(v9t,"BlenderbotSmallForCausalLM"),v9t.forEach(t),tGo=r(Vqe," (BlenderbotSmall model)"),Vqe.forEach(t),aGo=i(Q),f1=n(Q,"LI",{});var Xqe=s(f1);S2e=n(Xqe,"STRONG",{});var b9t=s(S2e);nGo=r(b9t,"bloom"),b9t.forEach(t),sGo=r(Xqe," \u2014 "),yz=n(Xqe,"A",{href:!0});var F9t=s(yz);lGo=r(F9t,"BloomForCausalLM"),F9t.forEach(t),iGo=r(Xqe," (BLOOM model)"),Xqe.forEach(t),dGo=i(Q),m1=n(Q,"LI",{});var zqe=s(m1);R2e=n(zqe,"STRONG",{});var T9t=s(R2e);cGo=r(T9t,"camembert"),T9t.forEach(t),fGo=r(zqe," \u2014 "),xz=n(zqe,"A",{href:!0});var M9t=s(xz);mGo=r(M9t,"CamembertForCausalLM"),M9t.forEach(t),gGo=r(zqe," (CamemBERT model)"),zqe.forEach(t),hGo=i(Q),g1=n(Q,"LI",{});var Qqe=s(g1);P2e=n(Qqe,"STRONG",{});var E9t=s(P2e);uGo=r(E9t,"codegen"),E9t.forEach(t),pGo=r(Qqe," \u2014 "),$z=n(Qqe,"A",{href:!0});var C9t=s($z);_Go=r(C9t,"CodeGenForCausalLM"),C9t.forEach(t),vGo=r(Qqe," (CodeGen model)"),Qqe.forEach(t),bGo=i(Q),h1=n(Q,"LI",{});var Wqe=s(h1);B2e=n(Wqe,"STRONG",{});var w9t=s(B2e);FGo=r(w9t,"ctrl"),w9t.forEach(t),TGo=r(Wqe," \u2014 "),kz=n(Wqe,"A",{href:!0});var A9t=s(kz);MGo=r(A9t,"CTRLLMHeadModel"),A9t.forEach(t),EGo=r(Wqe," (CTRL model)"),Wqe.forEach(t),CGo=i(Q),u1=n(Q,"LI",{});var Uqe=s(u1);I2e=n(Uqe,"STRONG",{});var L9t=s(I2e);wGo=r(L9t,"data2vec-text"),L9t.forEach(t),AGo=r(Uqe," \u2014 "),Sz=n(Uqe,"A",{href:!0});var y9t=s(Sz);LGo=r(y9t,"Data2VecTextForCausalLM"),y9t.forEach(t),yGo=r(Uqe," (Data2VecText model)"),Uqe.forEach(t),xGo=i(Q),p1=n(Q,"LI",{});var Hqe=s(p1);N2e=n(Hqe,"STRONG",{});var x9t=s(N2e);$Go=r(x9t,"electra"),x9t.forEach(t),kGo=r(Hqe," \u2014 "),Rz=n(Hqe,"A",{href:!0});var $9t=s(Rz);SGo=r($9t,"ElectraForCausalLM"),$9t.forEach(t),RGo=r(Hqe," (ELECTRA model)"),Hqe.forEach(t),PGo=i(Q),_1=n(Q,"LI",{});var Jqe=s(_1);q2e=n(Jqe,"STRONG",{});var k9t=s(q2e);BGo=r(k9t,"ernie"),k9t.forEach(t),IGo=r(Jqe," \u2014 "),Pz=n(Jqe,"A",{href:!0});var S9t=s(Pz);NGo=r(S9t,"ErnieForCausalLM"),S9t.forEach(t),qGo=r(Jqe," (ERNIE model)"),Jqe.forEach(t),jGo=i(Q),v1=n(Q,"LI",{});var Yqe=s(v1);j2e=n(Yqe,"STRONG",{});var R9t=s(j2e);DGo=r(R9t,"gpt2"),R9t.forEach(t),GGo=r(Yqe," \u2014 "),Bz=n(Yqe,"A",{href:!0});var P9t=s(Bz);OGo=r(P9t,"GPT2LMHeadModel"),P9t.forEach(t),VGo=r(Yqe," (OpenAI GPT-2 model)"),Yqe.forEach(t),XGo=i(Q),b1=n(Q,"LI",{});var Kqe=s(b1);D2e=n(Kqe,"STRONG",{});var B9t=s(D2e);zGo=r(B9t,"gpt_neo"),B9t.forEach(t),QGo=r(Kqe," \u2014 "),Iz=n(Kqe,"A",{href:!0});var I9t=s(Iz);WGo=r(I9t,"GPTNeoForCausalLM"),I9t.forEach(t),UGo=r(Kqe," (GPT Neo model)"),Kqe.forEach(t),HGo=i(Q),F1=n(Q,"LI",{});var Zqe=s(F1);G2e=n(Zqe,"STRONG",{});var N9t=s(G2e);JGo=r(N9t,"gpt_neox"),N9t.forEach(t),YGo=r(Zqe," \u2014 "),Nz=n(Zqe,"A",{href:!0});var q9t=s(Nz);KGo=r(q9t,"GPTNeoXForCausalLM"),q9t.forEach(t),ZGo=r(Zqe," (GPT NeoX model)"),Zqe.forEach(t),eOo=i(Q),T1=n(Q,"LI",{});var eje=s(T1);O2e=n(eje,"STRONG",{});var j9t=s(O2e);oOo=r(j9t,"gptj"),j9t.forEach(t),rOo=r(eje," \u2014 "),qz=n(eje,"A",{href:!0});var D9t=s(qz);tOo=r(D9t,"GPTJForCausalLM"),D9t.forEach(t),aOo=r(eje," (GPT-J model)"),eje.forEach(t),nOo=i(Q),M1=n(Q,"LI",{});var oje=s(M1);V2e=n(oje,"STRONG",{});var G9t=s(V2e);sOo=r(G9t,"marian"),G9t.forEach(t),lOo=r(oje," \u2014 "),jz=n(oje,"A",{href:!0});var O9t=s(jz);iOo=r(O9t,"MarianForCausalLM"),O9t.forEach(t),dOo=r(oje," (Marian model)"),oje.forEach(t),cOo=i(Q),E1=n(Q,"LI",{});var rje=s(E1);X2e=n(rje,"STRONG",{});var V9t=s(X2e);fOo=r(V9t,"mbart"),V9t.forEach(t),mOo=r(rje," \u2014 "),Dz=n(rje,"A",{href:!0});var X9t=s(Dz);gOo=r(X9t,"MBartForCausalLM"),X9t.forEach(t),hOo=r(rje," (mBART model)"),rje.forEach(t),uOo=i(Q),C1=n(Q,"LI",{});var tje=s(C1);z2e=n(tje,"STRONG",{});var z9t=s(z2e);pOo=r(z9t,"megatron-bert"),z9t.forEach(t),_Oo=r(tje," \u2014 "),Gz=n(tje,"A",{href:!0});var Q9t=s(Gz);vOo=r(Q9t,"MegatronBertForCausalLM"),Q9t.forEach(t),bOo=r(tje," (Megatron-BERT model)"),tje.forEach(t),FOo=i(Q),w1=n(Q,"LI",{});var aje=s(w1);Q2e=n(aje,"STRONG",{});var W9t=s(Q2e);TOo=r(W9t,"mvp"),W9t.forEach(t),MOo=r(aje," \u2014 "),Oz=n(aje,"A",{href:!0});var U9t=s(Oz);EOo=r(U9t,"MvpForCausalLM"),U9t.forEach(t),COo=r(aje," (MVP model)"),aje.forEach(t),wOo=i(Q),A1=n(Q,"LI",{});var nje=s(A1);W2e=n(nje,"STRONG",{});var H9t=s(W2e);AOo=r(H9t,"openai-gpt"),H9t.forEach(t),LOo=r(nje," \u2014 "),Vz=n(nje,"A",{href:!0});var J9t=s(Vz);yOo=r(J9t,"OpenAIGPTLMHeadModel"),J9t.forEach(t),xOo=r(nje," (OpenAI GPT model)"),nje.forEach(t),$Oo=i(Q),L1=n(Q,"LI",{});var sje=s(L1);U2e=n(sje,"STRONG",{});var Y9t=s(U2e);kOo=r(Y9t,"opt"),Y9t.forEach(t),SOo=r(sje," \u2014 "),Xz=n(sje,"A",{href:!0});var K9t=s(Xz);ROo=r(K9t,"OPTForCausalLM"),K9t.forEach(t),POo=r(sje," (OPT model)"),sje.forEach(t),BOo=i(Q),y1=n(Q,"LI",{});var lje=s(y1);H2e=n(lje,"STRONG",{});var Z9t=s(H2e);IOo=r(Z9t,"pegasus"),Z9t.forEach(t),NOo=r(lje," \u2014 "),zz=n(lje,"A",{href:!0});var ext=s(zz);qOo=r(ext,"PegasusForCausalLM"),ext.forEach(t),jOo=r(lje," (Pegasus model)"),lje.forEach(t),DOo=i(Q),x1=n(Q,"LI",{});var ije=s(x1);J2e=n(ije,"STRONG",{});var oxt=s(J2e);GOo=r(oxt,"plbart"),oxt.forEach(t),OOo=r(ije," \u2014 "),Qz=n(ije,"A",{href:!0});var rxt=s(Qz);VOo=r(rxt,"PLBartForCausalLM"),rxt.forEach(t),XOo=r(ije," (PLBart model)"),ije.forEach(t),zOo=i(Q),$1=n(Q,"LI",{});var dje=s($1);Y2e=n(dje,"STRONG",{});var txt=s(Y2e);QOo=r(txt,"prophetnet"),txt.forEach(t),WOo=r(dje," \u2014 "),Wz=n(dje,"A",{href:!0});var axt=s(Wz);UOo=r(axt,"ProphetNetForCausalLM"),axt.forEach(t),HOo=r(dje," (ProphetNet model)"),dje.forEach(t),JOo=i(Q),k1=n(Q,"LI",{});var cje=s(k1);K2e=n(cje,"STRONG",{});var nxt=s(K2e);YOo=r(nxt,"qdqbert"),nxt.forEach(t),KOo=r(cje," \u2014 "),Uz=n(cje,"A",{href:!0});var sxt=s(Uz);ZOo=r(sxt,"QDQBertLMHeadModel"),sxt.forEach(t),eVo=r(cje," (QDQBert model)"),cje.forEach(t),oVo=i(Q),S1=n(Q,"LI",{});var fje=s(S1);Z2e=n(fje,"STRONG",{});var lxt=s(Z2e);rVo=r(lxt,"reformer"),lxt.forEach(t),tVo=r(fje," \u2014 "),Hz=n(fje,"A",{href:!0});var ixt=s(Hz);aVo=r(ixt,"ReformerModelWithLMHead"),ixt.forEach(t),nVo=r(fje," (Reformer model)"),fje.forEach(t),sVo=i(Q),R1=n(Q,"LI",{});var mje=s(R1);eve=n(mje,"STRONG",{});var dxt=s(eve);lVo=r(dxt,"rembert"),dxt.forEach(t),iVo=r(mje," \u2014 "),Jz=n(mje,"A",{href:!0});var cxt=s(Jz);dVo=r(cxt,"RemBertForCausalLM"),cxt.forEach(t),cVo=r(mje," (RemBERT model)"),mje.forEach(t),fVo=i(Q),P1=n(Q,"LI",{});var gje=s(P1);ove=n(gje,"STRONG",{});var fxt=s(ove);mVo=r(fxt,"roberta"),fxt.forEach(t),gVo=r(gje," \u2014 "),Yz=n(gje,"A",{href:!0});var mxt=s(Yz);hVo=r(mxt,"RobertaForCausalLM"),mxt.forEach(t),uVo=r(gje," (RoBERTa model)"),gje.forEach(t),pVo=i(Q),B1=n(Q,"LI",{});var hje=s(B1);rve=n(hje,"STRONG",{});var gxt=s(rve);_Vo=r(gxt,"roformer"),gxt.forEach(t),vVo=r(hje," \u2014 "),Kz=n(hje,"A",{href:!0});var hxt=s(Kz);bVo=r(hxt,"RoFormerForCausalLM"),hxt.forEach(t),FVo=r(hje," (RoFormer model)"),hje.forEach(t),TVo=i(Q),I1=n(Q,"LI",{});var uje=s(I1);tve=n(uje,"STRONG",{});var uxt=s(tve);MVo=r(uxt,"speech_to_text_2"),uxt.forEach(t),EVo=r(uje," \u2014 "),Zz=n(uje,"A",{href:!0});var pxt=s(Zz);CVo=r(pxt,"Speech2Text2ForCausalLM"),pxt.forEach(t),wVo=r(uje," (Speech2Text2 model)"),uje.forEach(t),AVo=i(Q),N1=n(Q,"LI",{});var pje=s(N1);ave=n(pje,"STRONG",{});var _xt=s(ave);LVo=r(_xt,"transfo-xl"),_xt.forEach(t),yVo=r(pje," \u2014 "),eQ=n(pje,"A",{href:!0});var vxt=s(eQ);xVo=r(vxt,"TransfoXLLMHeadModel"),vxt.forEach(t),$Vo=r(pje," (Transformer-XL model)"),pje.forEach(t),kVo=i(Q),q1=n(Q,"LI",{});var _je=s(q1);nve=n(_je,"STRONG",{});var bxt=s(nve);SVo=r(bxt,"trocr"),bxt.forEach(t),RVo=r(_je," \u2014 "),oQ=n(_je,"A",{href:!0});var Fxt=s(oQ);PVo=r(Fxt,"TrOCRForCausalLM"),Fxt.forEach(t),BVo=r(_je," (TrOCR model)"),_je.forEach(t),IVo=i(Q),j1=n(Q,"LI",{});var vje=s(j1);sve=n(vje,"STRONG",{});var Txt=s(sve);NVo=r(Txt,"xglm"),Txt.forEach(t),qVo=r(vje," \u2014 "),rQ=n(vje,"A",{href:!0});var Mxt=s(rQ);jVo=r(Mxt,"XGLMForCausalLM"),Mxt.forEach(t),DVo=r(vje," (XGLM model)"),vje.forEach(t),GVo=i(Q),D1=n(Q,"LI",{});var bje=s(D1);lve=n(bje,"STRONG",{});var Ext=s(lve);OVo=r(Ext,"xlm"),Ext.forEach(t),VVo=r(bje," \u2014 "),tQ=n(bje,"A",{href:!0});var Cxt=s(tQ);XVo=r(Cxt,"XLMWithLMHeadModel"),Cxt.forEach(t),zVo=r(bje," (XLM model)"),bje.forEach(t),QVo=i(Q),G1=n(Q,"LI",{});var Fje=s(G1);ive=n(Fje,"STRONG",{});var wxt=s(ive);WVo=r(wxt,"xlm-prophetnet"),wxt.forEach(t),UVo=r(Fje," \u2014 "),aQ=n(Fje,"A",{href:!0});var Axt=s(aQ);HVo=r(Axt,"XLMProphetNetForCausalLM"),Axt.forEach(t),JVo=r(Fje," (XLM-ProphetNet model)"),Fje.forEach(t),YVo=i(Q),O1=n(Q,"LI",{});var Tje=s(O1);dve=n(Tje,"STRONG",{});var Lxt=s(dve);KVo=r(Lxt,"xlm-roberta"),Lxt.forEach(t),ZVo=r(Tje," \u2014 "),nQ=n(Tje,"A",{href:!0});var yxt=s(nQ);eXo=r(yxt,"XLMRobertaForCausalLM"),yxt.forEach(t),oXo=r(Tje," (XLM-RoBERTa model)"),Tje.forEach(t),rXo=i(Q),V1=n(Q,"LI",{});var Mje=s(V1);cve=n(Mje,"STRONG",{});var xxt=s(cve);tXo=r(xxt,"xlm-roberta-xl"),xxt.forEach(t),aXo=r(Mje," \u2014 "),sQ=n(Mje,"A",{href:!0});var $xt=s(sQ);nXo=r($xt,"XLMRobertaXLForCausalLM"),$xt.forEach(t),sXo=r(Mje," (XLM-RoBERTa-XL model)"),Mje.forEach(t),lXo=i(Q),X1=n(Q,"LI",{});var Eje=s(X1);fve=n(Eje,"STRONG",{});var kxt=s(fve);iXo=r(kxt,"xlnet"),kxt.forEach(t),dXo=r(Eje," \u2014 "),lQ=n(Eje,"A",{href:!0});var Sxt=s(lQ);cXo=r(Sxt,"XLNetLMHeadModel"),Sxt.forEach(t),fXo=r(Eje," (XLNet model)"),Eje.forEach(t),Q.forEach(t),mXo=i(Ma),z1=n(Ma,"P",{});var Cje=s(z1);gXo=r(Cje,"The model is set in evaluation mode by default using "),mve=n(Cje,"CODE",{});var Rxt=s(mve);hXo=r(Rxt,"model.eval()"),Rxt.forEach(t),uXo=r(Cje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gve=n(Cje,"CODE",{});var Pxt=s(gve);pXo=r(Pxt,"model.train()"),Pxt.forEach(t),Cje.forEach(t),_Xo=i(Ma),T(Q1.$$.fragment,Ma),Ma.forEach(t),Ll.forEach(t),JYe=i(f),wd=n(f,"H2",{class:!0});var ceo=s(wd);W1=n(ceo,"A",{id:!0,class:!0,href:!0});var Bxt=s(W1);hve=n(Bxt,"SPAN",{});var Ixt=s(hve);T(cx.$$.fragment,Ixt),Ixt.forEach(t),Bxt.forEach(t),vXo=i(ceo),uve=n(ceo,"SPAN",{});var Nxt=s(uve);bXo=r(Nxt,"AutoModelForMaskedLM"),Nxt.forEach(t),ceo.forEach(t),YYe=i(f),No=n(f,"DIV",{class:!0});var yl=s(No);T(fx.$$.fragment,yl),FXo=i(yl),Ad=n(yl,"P",{});var Zse=s(Ad);TXo=r(Zse,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),iQ=n(Zse,"A",{href:!0});var qxt=s(iQ);MXo=r(qxt,"from_pretrained()"),qxt.forEach(t),EXo=r(Zse," class method or the "),dQ=n(Zse,"A",{href:!0});var jxt=s(dQ);CXo=r(jxt,"from_config()"),jxt.forEach(t),wXo=r(Zse,` class
method.`),Zse.forEach(t),AXo=i(yl),mx=n(yl,"P",{});var feo=s(mx);LXo=r(feo,"This class cannot be instantiated directly using "),pve=n(feo,"CODE",{});var Dxt=s(pve);yXo=r(Dxt,"__init__()"),Dxt.forEach(t),xXo=r(feo," (throws an error)."),feo.forEach(t),$Xo=i(yl),Ft=n(yl,"DIV",{class:!0});var Cy=s(Ft);T(gx.$$.fragment,Cy),kXo=i(Cy),_ve=n(Cy,"P",{});var Gxt=s(_ve);SXo=r(Gxt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxt.forEach(t),RXo=i(Cy),Ld=n(Cy,"P",{});var ele=s(Ld);PXo=r(ele,`Note:
Loading a model from its configuration file does `),vve=n(ele,"STRONG",{});var Oxt=s(vve);BXo=r(Oxt,"not"),Oxt.forEach(t),IXo=r(ele,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(ele,"A",{href:!0});var Vxt=s(cQ);NXo=r(Vxt,"from_pretrained()"),Vxt.forEach(t),qXo=r(ele," to load the model weights."),ele.forEach(t),jXo=i(Cy),T(U1.$$.fragment,Cy),Cy.forEach(t),DXo=i(yl),ro=n(yl,"DIV",{class:!0});var Ea=s(ro);T(hx.$$.fragment,Ea),GXo=i(Ea),bve=n(Ea,"P",{});var Xxt=s(bve);OXo=r(Xxt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xxt.forEach(t),VXo=i(Ea),Za=n(Ea,"P",{});var wy=s(Za);XXo=r(wy,"The model class to instantiate is selected based on the "),Fve=n(wy,"CODE",{});var zxt=s(Fve);zXo=r(zxt,"model_type"),zxt.forEach(t),QXo=r(wy,` property of the config object (either
passed as an argument or loaded from `),Tve=n(wy,"CODE",{});var Qxt=s(Tve);WXo=r(Qxt,"pretrained_model_name_or_path"),Qxt.forEach(t),UXo=r(wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mve=n(wy,"CODE",{});var Wxt=s(Mve);HXo=r(Wxt,"pretrained_model_name_or_path"),Wxt.forEach(t),JXo=r(wy,":"),wy.forEach(t),YXo=i(Ea),U=n(Ea,"UL",{});var Y=s(U);H1=n(Y,"LI",{});var wje=s(H1);Eve=n(wje,"STRONG",{});var Uxt=s(Eve);KXo=r(Uxt,"albert"),Uxt.forEach(t),ZXo=r(wje," \u2014 "),fQ=n(wje,"A",{href:!0});var Hxt=s(fQ);ezo=r(Hxt,"AlbertForMaskedLM"),Hxt.forEach(t),ozo=r(wje," (ALBERT model)"),wje.forEach(t),rzo=i(Y),J1=n(Y,"LI",{});var Aje=s(J1);Cve=n(Aje,"STRONG",{});var Jxt=s(Cve);tzo=r(Jxt,"bart"),Jxt.forEach(t),azo=r(Aje," \u2014 "),mQ=n(Aje,"A",{href:!0});var Yxt=s(mQ);nzo=r(Yxt,"BartForConditionalGeneration"),Yxt.forEach(t),szo=r(Aje," (BART model)"),Aje.forEach(t),lzo=i(Y),Y1=n(Y,"LI",{});var Lje=s(Y1);wve=n(Lje,"STRONG",{});var Kxt=s(wve);izo=r(Kxt,"bert"),Kxt.forEach(t),dzo=r(Lje," \u2014 "),gQ=n(Lje,"A",{href:!0});var Zxt=s(gQ);czo=r(Zxt,"BertForMaskedLM"),Zxt.forEach(t),fzo=r(Lje," (BERT model)"),Lje.forEach(t),mzo=i(Y),K1=n(Y,"LI",{});var yje=s(K1);Ave=n(yje,"STRONG",{});var e$t=s(Ave);gzo=r(e$t,"big_bird"),e$t.forEach(t),hzo=r(yje," \u2014 "),hQ=n(yje,"A",{href:!0});var o$t=s(hQ);uzo=r(o$t,"BigBirdForMaskedLM"),o$t.forEach(t),pzo=r(yje," (BigBird model)"),yje.forEach(t),_zo=i(Y),Z1=n(Y,"LI",{});var xje=s(Z1);Lve=n(xje,"STRONG",{});var r$t=s(Lve);vzo=r(r$t,"camembert"),r$t.forEach(t),bzo=r(xje," \u2014 "),uQ=n(xje,"A",{href:!0});var t$t=s(uQ);Fzo=r(t$t,"CamembertForMaskedLM"),t$t.forEach(t),Tzo=r(xje," (CamemBERT model)"),xje.forEach(t),Mzo=i(Y),e4=n(Y,"LI",{});var $je=s(e4);yve=n($je,"STRONG",{});var a$t=s(yve);Ezo=r(a$t,"convbert"),a$t.forEach(t),Czo=r($je," \u2014 "),pQ=n($je,"A",{href:!0});var n$t=s(pQ);wzo=r(n$t,"ConvBertForMaskedLM"),n$t.forEach(t),Azo=r($je," (ConvBERT model)"),$je.forEach(t),Lzo=i(Y),o4=n(Y,"LI",{});var kje=s(o4);xve=n(kje,"STRONG",{});var s$t=s(xve);yzo=r(s$t,"data2vec-text"),s$t.forEach(t),xzo=r(kje," \u2014 "),_Q=n(kje,"A",{href:!0});var l$t=s(_Q);$zo=r(l$t,"Data2VecTextForMaskedLM"),l$t.forEach(t),kzo=r(kje," (Data2VecText model)"),kje.forEach(t),Szo=i(Y),r4=n(Y,"LI",{});var Sje=s(r4);$ve=n(Sje,"STRONG",{});var i$t=s($ve);Rzo=r(i$t,"deberta"),i$t.forEach(t),Pzo=r(Sje," \u2014 "),vQ=n(Sje,"A",{href:!0});var d$t=s(vQ);Bzo=r(d$t,"DebertaForMaskedLM"),d$t.forEach(t),Izo=r(Sje," (DeBERTa model)"),Sje.forEach(t),Nzo=i(Y),t4=n(Y,"LI",{});var Rje=s(t4);kve=n(Rje,"STRONG",{});var c$t=s(kve);qzo=r(c$t,"deberta-v2"),c$t.forEach(t),jzo=r(Rje," \u2014 "),bQ=n(Rje,"A",{href:!0});var f$t=s(bQ);Dzo=r(f$t,"DebertaV2ForMaskedLM"),f$t.forEach(t),Gzo=r(Rje," (DeBERTa-v2 model)"),Rje.forEach(t),Ozo=i(Y),a4=n(Y,"LI",{});var Pje=s(a4);Sve=n(Pje,"STRONG",{});var m$t=s(Sve);Vzo=r(m$t,"distilbert"),m$t.forEach(t),Xzo=r(Pje," \u2014 "),FQ=n(Pje,"A",{href:!0});var g$t=s(FQ);zzo=r(g$t,"DistilBertForMaskedLM"),g$t.forEach(t),Qzo=r(Pje," (DistilBERT model)"),Pje.forEach(t),Wzo=i(Y),n4=n(Y,"LI",{});var Bje=s(n4);Rve=n(Bje,"STRONG",{});var h$t=s(Rve);Uzo=r(h$t,"electra"),h$t.forEach(t),Hzo=r(Bje," \u2014 "),TQ=n(Bje,"A",{href:!0});var u$t=s(TQ);Jzo=r(u$t,"ElectraForMaskedLM"),u$t.forEach(t),Yzo=r(Bje," (ELECTRA model)"),Bje.forEach(t),Kzo=i(Y),s4=n(Y,"LI",{});var Ije=s(s4);Pve=n(Ije,"STRONG",{});var p$t=s(Pve);Zzo=r(p$t,"ernie"),p$t.forEach(t),eQo=r(Ije," \u2014 "),MQ=n(Ije,"A",{href:!0});var _$t=s(MQ);oQo=r(_$t,"ErnieForMaskedLM"),_$t.forEach(t),rQo=r(Ije," (ERNIE model)"),Ije.forEach(t),tQo=i(Y),l4=n(Y,"LI",{});var Nje=s(l4);Bve=n(Nje,"STRONG",{});var v$t=s(Bve);aQo=r(v$t,"flaubert"),v$t.forEach(t),nQo=r(Nje," \u2014 "),EQ=n(Nje,"A",{href:!0});var b$t=s(EQ);sQo=r(b$t,"FlaubertWithLMHeadModel"),b$t.forEach(t),lQo=r(Nje," (FlauBERT model)"),Nje.forEach(t),iQo=i(Y),i4=n(Y,"LI",{});var qje=s(i4);Ive=n(qje,"STRONG",{});var F$t=s(Ive);dQo=r(F$t,"fnet"),F$t.forEach(t),cQo=r(qje," \u2014 "),CQ=n(qje,"A",{href:!0});var T$t=s(CQ);fQo=r(T$t,"FNetForMaskedLM"),T$t.forEach(t),mQo=r(qje," (FNet model)"),qje.forEach(t),gQo=i(Y),d4=n(Y,"LI",{});var jje=s(d4);Nve=n(jje,"STRONG",{});var M$t=s(Nve);hQo=r(M$t,"funnel"),M$t.forEach(t),uQo=r(jje," \u2014 "),wQ=n(jje,"A",{href:!0});var E$t=s(wQ);pQo=r(E$t,"FunnelForMaskedLM"),E$t.forEach(t),_Qo=r(jje," (Funnel Transformer model)"),jje.forEach(t),vQo=i(Y),c4=n(Y,"LI",{});var Dje=s(c4);qve=n(Dje,"STRONG",{});var C$t=s(qve);bQo=r(C$t,"ibert"),C$t.forEach(t),FQo=r(Dje," \u2014 "),AQ=n(Dje,"A",{href:!0});var w$t=s(AQ);TQo=r(w$t,"IBertForMaskedLM"),w$t.forEach(t),MQo=r(Dje," (I-BERT model)"),Dje.forEach(t),EQo=i(Y),f4=n(Y,"LI",{});var Gje=s(f4);jve=n(Gje,"STRONG",{});var A$t=s(jve);CQo=r(A$t,"layoutlm"),A$t.forEach(t),wQo=r(Gje," \u2014 "),LQ=n(Gje,"A",{href:!0});var L$t=s(LQ);AQo=r(L$t,"LayoutLMForMaskedLM"),L$t.forEach(t),LQo=r(Gje," (LayoutLM model)"),Gje.forEach(t),yQo=i(Y),m4=n(Y,"LI",{});var Oje=s(m4);Dve=n(Oje,"STRONG",{});var y$t=s(Dve);xQo=r(y$t,"longformer"),y$t.forEach(t),$Qo=r(Oje," \u2014 "),yQ=n(Oje,"A",{href:!0});var x$t=s(yQ);kQo=r(x$t,"LongformerForMaskedLM"),x$t.forEach(t),SQo=r(Oje," (Longformer model)"),Oje.forEach(t),RQo=i(Y),g4=n(Y,"LI",{});var Vje=s(g4);Gve=n(Vje,"STRONG",{});var $$t=s(Gve);PQo=r($$t,"luke"),$$t.forEach(t),BQo=r(Vje," \u2014 "),xQ=n(Vje,"A",{href:!0});var k$t=s(xQ);IQo=r(k$t,"LukeForMaskedLM"),k$t.forEach(t),NQo=r(Vje," (LUKE model)"),Vje.forEach(t),qQo=i(Y),h4=n(Y,"LI",{});var Xje=s(h4);Ove=n(Xje,"STRONG",{});var S$t=s(Ove);jQo=r(S$t,"mbart"),S$t.forEach(t),DQo=r(Xje," \u2014 "),$Q=n(Xje,"A",{href:!0});var R$t=s($Q);GQo=r(R$t,"MBartForConditionalGeneration"),R$t.forEach(t),OQo=r(Xje," (mBART model)"),Xje.forEach(t),VQo=i(Y),u4=n(Y,"LI",{});var zje=s(u4);Vve=n(zje,"STRONG",{});var P$t=s(Vve);XQo=r(P$t,"megatron-bert"),P$t.forEach(t),zQo=r(zje," \u2014 "),kQ=n(zje,"A",{href:!0});var B$t=s(kQ);QQo=r(B$t,"MegatronBertForMaskedLM"),B$t.forEach(t),WQo=r(zje," (Megatron-BERT model)"),zje.forEach(t),UQo=i(Y),p4=n(Y,"LI",{});var Qje=s(p4);Xve=n(Qje,"STRONG",{});var I$t=s(Xve);HQo=r(I$t,"mobilebert"),I$t.forEach(t),JQo=r(Qje," \u2014 "),SQ=n(Qje,"A",{href:!0});var N$t=s(SQ);YQo=r(N$t,"MobileBertForMaskedLM"),N$t.forEach(t),KQo=r(Qje," (MobileBERT model)"),Qje.forEach(t),ZQo=i(Y),_4=n(Y,"LI",{});var Wje=s(_4);zve=n(Wje,"STRONG",{});var q$t=s(zve);eWo=r(q$t,"mpnet"),q$t.forEach(t),oWo=r(Wje," \u2014 "),RQ=n(Wje,"A",{href:!0});var j$t=s(RQ);rWo=r(j$t,"MPNetForMaskedLM"),j$t.forEach(t),tWo=r(Wje," (MPNet model)"),Wje.forEach(t),aWo=i(Y),v4=n(Y,"LI",{});var Uje=s(v4);Qve=n(Uje,"STRONG",{});var D$t=s(Qve);nWo=r(D$t,"mvp"),D$t.forEach(t),sWo=r(Uje," \u2014 "),PQ=n(Uje,"A",{href:!0});var G$t=s(PQ);lWo=r(G$t,"MvpForConditionalGeneration"),G$t.forEach(t),iWo=r(Uje," (MVP model)"),Uje.forEach(t),dWo=i(Y),b4=n(Y,"LI",{});var Hje=s(b4);Wve=n(Hje,"STRONG",{});var O$t=s(Wve);cWo=r(O$t,"nezha"),O$t.forEach(t),fWo=r(Hje," \u2014 "),BQ=n(Hje,"A",{href:!0});var V$t=s(BQ);mWo=r(V$t,"NezhaForMaskedLM"),V$t.forEach(t),gWo=r(Hje," (Nezha model)"),Hje.forEach(t),hWo=i(Y),F4=n(Y,"LI",{});var Jje=s(F4);Uve=n(Jje,"STRONG",{});var X$t=s(Uve);uWo=r(X$t,"nystromformer"),X$t.forEach(t),pWo=r(Jje," \u2014 "),IQ=n(Jje,"A",{href:!0});var z$t=s(IQ);_Wo=r(z$t,"NystromformerForMaskedLM"),z$t.forEach(t),vWo=r(Jje," (Nystr\xF6mformer model)"),Jje.forEach(t),bWo=i(Y),T4=n(Y,"LI",{});var Yje=s(T4);Hve=n(Yje,"STRONG",{});var Q$t=s(Hve);FWo=r(Q$t,"perceiver"),Q$t.forEach(t),TWo=r(Yje," \u2014 "),NQ=n(Yje,"A",{href:!0});var W$t=s(NQ);MWo=r(W$t,"PerceiverForMaskedLM"),W$t.forEach(t),EWo=r(Yje," (Perceiver model)"),Yje.forEach(t),CWo=i(Y),M4=n(Y,"LI",{});var Kje=s(M4);Jve=n(Kje,"STRONG",{});var U$t=s(Jve);wWo=r(U$t,"qdqbert"),U$t.forEach(t),AWo=r(Kje," \u2014 "),qQ=n(Kje,"A",{href:!0});var H$t=s(qQ);LWo=r(H$t,"QDQBertForMaskedLM"),H$t.forEach(t),yWo=r(Kje," (QDQBert model)"),Kje.forEach(t),xWo=i(Y),E4=n(Y,"LI",{});var Zje=s(E4);Yve=n(Zje,"STRONG",{});var J$t=s(Yve);$Wo=r(J$t,"reformer"),J$t.forEach(t),kWo=r(Zje," \u2014 "),jQ=n(Zje,"A",{href:!0});var Y$t=s(jQ);SWo=r(Y$t,"ReformerForMaskedLM"),Y$t.forEach(t),RWo=r(Zje," (Reformer model)"),Zje.forEach(t),PWo=i(Y),C4=n(Y,"LI",{});var eDe=s(C4);Kve=n(eDe,"STRONG",{});var K$t=s(Kve);BWo=r(K$t,"rembert"),K$t.forEach(t),IWo=r(eDe," \u2014 "),DQ=n(eDe,"A",{href:!0});var Z$t=s(DQ);NWo=r(Z$t,"RemBertForMaskedLM"),Z$t.forEach(t),qWo=r(eDe," (RemBERT model)"),eDe.forEach(t),jWo=i(Y),w4=n(Y,"LI",{});var oDe=s(w4);Zve=n(oDe,"STRONG",{});var ekt=s(Zve);DWo=r(ekt,"roberta"),ekt.forEach(t),GWo=r(oDe," \u2014 "),GQ=n(oDe,"A",{href:!0});var okt=s(GQ);OWo=r(okt,"RobertaForMaskedLM"),okt.forEach(t),VWo=r(oDe," (RoBERTa model)"),oDe.forEach(t),XWo=i(Y),A4=n(Y,"LI",{});var rDe=s(A4);e1e=n(rDe,"STRONG",{});var rkt=s(e1e);zWo=r(rkt,"roformer"),rkt.forEach(t),QWo=r(rDe," \u2014 "),OQ=n(rDe,"A",{href:!0});var tkt=s(OQ);WWo=r(tkt,"RoFormerForMaskedLM"),tkt.forEach(t),UWo=r(rDe," (RoFormer model)"),rDe.forEach(t),HWo=i(Y),L4=n(Y,"LI",{});var tDe=s(L4);o1e=n(tDe,"STRONG",{});var akt=s(o1e);JWo=r(akt,"squeezebert"),akt.forEach(t),YWo=r(tDe," \u2014 "),VQ=n(tDe,"A",{href:!0});var nkt=s(VQ);KWo=r(nkt,"SqueezeBertForMaskedLM"),nkt.forEach(t),ZWo=r(tDe," (SqueezeBERT model)"),tDe.forEach(t),eUo=i(Y),y4=n(Y,"LI",{});var aDe=s(y4);r1e=n(aDe,"STRONG",{});var skt=s(r1e);oUo=r(skt,"tapas"),skt.forEach(t),rUo=r(aDe," \u2014 "),XQ=n(aDe,"A",{href:!0});var lkt=s(XQ);tUo=r(lkt,"TapasForMaskedLM"),lkt.forEach(t),aUo=r(aDe," (TAPAS model)"),aDe.forEach(t),nUo=i(Y),x4=n(Y,"LI",{});var nDe=s(x4);t1e=n(nDe,"STRONG",{});var ikt=s(t1e);sUo=r(ikt,"wav2vec2"),ikt.forEach(t),lUo=r(nDe," \u2014 "),a1e=n(nDe,"CODE",{});var dkt=s(a1e);iUo=r(dkt,"Wav2Vec2ForMaskedLM"),dkt.forEach(t),dUo=r(nDe," (Wav2Vec2 model)"),nDe.forEach(t),cUo=i(Y),$4=n(Y,"LI",{});var sDe=s($4);n1e=n(sDe,"STRONG",{});var ckt=s(n1e);fUo=r(ckt,"xlm"),ckt.forEach(t),mUo=r(sDe," \u2014 "),zQ=n(sDe,"A",{href:!0});var fkt=s(zQ);gUo=r(fkt,"XLMWithLMHeadModel"),fkt.forEach(t),hUo=r(sDe," (XLM model)"),sDe.forEach(t),uUo=i(Y),k4=n(Y,"LI",{});var lDe=s(k4);s1e=n(lDe,"STRONG",{});var mkt=s(s1e);pUo=r(mkt,"xlm-roberta"),mkt.forEach(t),_Uo=r(lDe," \u2014 "),QQ=n(lDe,"A",{href:!0});var gkt=s(QQ);vUo=r(gkt,"XLMRobertaForMaskedLM"),gkt.forEach(t),bUo=r(lDe," (XLM-RoBERTa model)"),lDe.forEach(t),FUo=i(Y),S4=n(Y,"LI",{});var iDe=s(S4);l1e=n(iDe,"STRONG",{});var hkt=s(l1e);TUo=r(hkt,"xlm-roberta-xl"),hkt.forEach(t),MUo=r(iDe," \u2014 "),WQ=n(iDe,"A",{href:!0});var ukt=s(WQ);EUo=r(ukt,"XLMRobertaXLForMaskedLM"),ukt.forEach(t),CUo=r(iDe," (XLM-RoBERTa-XL model)"),iDe.forEach(t),wUo=i(Y),R4=n(Y,"LI",{});var dDe=s(R4);i1e=n(dDe,"STRONG",{});var pkt=s(i1e);AUo=r(pkt,"yoso"),pkt.forEach(t),LUo=r(dDe," \u2014 "),UQ=n(dDe,"A",{href:!0});var _kt=s(UQ);yUo=r(_kt,"YosoForMaskedLM"),_kt.forEach(t),xUo=r(dDe," (YOSO model)"),dDe.forEach(t),Y.forEach(t),$Uo=i(Ea),P4=n(Ea,"P",{});var cDe=s(P4);kUo=r(cDe,"The model is set in evaluation mode by default using "),d1e=n(cDe,"CODE",{});var vkt=s(d1e);SUo=r(vkt,"model.eval()"),vkt.forEach(t),RUo=r(cDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c1e=n(cDe,"CODE",{});var bkt=s(c1e);PUo=r(bkt,"model.train()"),bkt.forEach(t),cDe.forEach(t),BUo=i(Ea),T(B4.$$.fragment,Ea),Ea.forEach(t),yl.forEach(t),KYe=i(f),yd=n(f,"H2",{class:!0});var meo=s(yd);I4=n(meo,"A",{id:!0,class:!0,href:!0});var Fkt=s(I4);f1e=n(Fkt,"SPAN",{});var Tkt=s(f1e);T(ux.$$.fragment,Tkt),Tkt.forEach(t),Fkt.forEach(t),IUo=i(meo),m1e=n(meo,"SPAN",{});var Mkt=s(m1e);NUo=r(Mkt,"AutoModelForSeq2SeqLM"),Mkt.forEach(t),meo.forEach(t),ZYe=i(f),qo=n(f,"DIV",{class:!0});var xl=s(qo);T(px.$$.fragment,xl),qUo=i(xl),xd=n(xl,"P",{});var ole=s(xd);jUo=r(ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HQ=n(ole,"A",{href:!0});var Ekt=s(HQ);DUo=r(Ekt,"from_pretrained()"),Ekt.forEach(t),GUo=r(ole," class method or the "),JQ=n(ole,"A",{href:!0});var Ckt=s(JQ);OUo=r(Ckt,"from_config()"),Ckt.forEach(t),VUo=r(ole,` class
method.`),ole.forEach(t),XUo=i(xl),_x=n(xl,"P",{});var geo=s(_x);zUo=r(geo,"This class cannot be instantiated directly using "),g1e=n(geo,"CODE",{});var wkt=s(g1e);QUo=r(wkt,"__init__()"),wkt.forEach(t),WUo=r(geo," (throws an error)."),geo.forEach(t),UUo=i(xl),Tt=n(xl,"DIV",{class:!0});var Ay=s(Tt);T(vx.$$.fragment,Ay),HUo=i(Ay),h1e=n(Ay,"P",{});var Akt=s(h1e);JUo=r(Akt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Akt.forEach(t),YUo=i(Ay),$d=n(Ay,"P",{});var rle=s($d);KUo=r(rle,`Note:
Loading a model from its configuration file does `),u1e=n(rle,"STRONG",{});var Lkt=s(u1e);ZUo=r(Lkt,"not"),Lkt.forEach(t),eHo=r(rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=n(rle,"A",{href:!0});var ykt=s(YQ);oHo=r(ykt,"from_pretrained()"),ykt.forEach(t),rHo=r(rle," to load the model weights."),rle.forEach(t),tHo=i(Ay),T(N4.$$.fragment,Ay),Ay.forEach(t),aHo=i(xl),to=n(xl,"DIV",{class:!0});var Ca=s(to);T(bx.$$.fragment,Ca),nHo=i(Ca),p1e=n(Ca,"P",{});var xkt=s(p1e);sHo=r(xkt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xkt.forEach(t),lHo=i(Ca),en=n(Ca,"P",{});var Ly=s(en);iHo=r(Ly,"The model class to instantiate is selected based on the "),_1e=n(Ly,"CODE",{});var $kt=s(_1e);dHo=r($kt,"model_type"),$kt.forEach(t),cHo=r(Ly,` property of the config object (either
passed as an argument or loaded from `),v1e=n(Ly,"CODE",{});var kkt=s(v1e);fHo=r(kkt,"pretrained_model_name_or_path"),kkt.forEach(t),mHo=r(Ly,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b1e=n(Ly,"CODE",{});var Skt=s(b1e);gHo=r(Skt,"pretrained_model_name_or_path"),Skt.forEach(t),hHo=r(Ly,":"),Ly.forEach(t),uHo=i(Ca),fe=n(Ca,"UL",{});var pe=s(fe);q4=n(pe,"LI",{});var fDe=s(q4);F1e=n(fDe,"STRONG",{});var Rkt=s(F1e);pHo=r(Rkt,"bart"),Rkt.forEach(t),_Ho=r(fDe," \u2014 "),KQ=n(fDe,"A",{href:!0});var Pkt=s(KQ);vHo=r(Pkt,"BartForConditionalGeneration"),Pkt.forEach(t),bHo=r(fDe," (BART model)"),fDe.forEach(t),FHo=i(pe),j4=n(pe,"LI",{});var mDe=s(j4);T1e=n(mDe,"STRONG",{});var Bkt=s(T1e);THo=r(Bkt,"bigbird_pegasus"),Bkt.forEach(t),MHo=r(mDe," \u2014 "),ZQ=n(mDe,"A",{href:!0});var Ikt=s(ZQ);EHo=r(Ikt,"BigBirdPegasusForConditionalGeneration"),Ikt.forEach(t),CHo=r(mDe," (BigBird-Pegasus model)"),mDe.forEach(t),wHo=i(pe),D4=n(pe,"LI",{});var gDe=s(D4);M1e=n(gDe,"STRONG",{});var Nkt=s(M1e);AHo=r(Nkt,"blenderbot"),Nkt.forEach(t),LHo=r(gDe," \u2014 "),eW=n(gDe,"A",{href:!0});var qkt=s(eW);yHo=r(qkt,"BlenderbotForConditionalGeneration"),qkt.forEach(t),xHo=r(gDe," (Blenderbot model)"),gDe.forEach(t),$Ho=i(pe),G4=n(pe,"LI",{});var hDe=s(G4);E1e=n(hDe,"STRONG",{});var jkt=s(E1e);kHo=r(jkt,"blenderbot-small"),jkt.forEach(t),SHo=r(hDe," \u2014 "),oW=n(hDe,"A",{href:!0});var Dkt=s(oW);RHo=r(Dkt,"BlenderbotSmallForConditionalGeneration"),Dkt.forEach(t),PHo=r(hDe," (BlenderbotSmall model)"),hDe.forEach(t),BHo=i(pe),O4=n(pe,"LI",{});var uDe=s(O4);C1e=n(uDe,"STRONG",{});var Gkt=s(C1e);IHo=r(Gkt,"encoder-decoder"),Gkt.forEach(t),NHo=r(uDe," \u2014 "),rW=n(uDe,"A",{href:!0});var Okt=s(rW);qHo=r(Okt,"EncoderDecoderModel"),Okt.forEach(t),jHo=r(uDe," (Encoder decoder model)"),uDe.forEach(t),DHo=i(pe),V4=n(pe,"LI",{});var pDe=s(V4);w1e=n(pDe,"STRONG",{});var Vkt=s(w1e);GHo=r(Vkt,"fsmt"),Vkt.forEach(t),OHo=r(pDe," \u2014 "),tW=n(pDe,"A",{href:!0});var Xkt=s(tW);VHo=r(Xkt,"FSMTForConditionalGeneration"),Xkt.forEach(t),XHo=r(pDe," (FairSeq Machine-Translation model)"),pDe.forEach(t),zHo=i(pe),X4=n(pe,"LI",{});var _De=s(X4);A1e=n(_De,"STRONG",{});var zkt=s(A1e);QHo=r(zkt,"led"),zkt.forEach(t),WHo=r(_De," \u2014 "),aW=n(_De,"A",{href:!0});var Qkt=s(aW);UHo=r(Qkt,"LEDForConditionalGeneration"),Qkt.forEach(t),HHo=r(_De," (LED model)"),_De.forEach(t),JHo=i(pe),z4=n(pe,"LI",{});var vDe=s(z4);L1e=n(vDe,"STRONG",{});var Wkt=s(L1e);YHo=r(Wkt,"longt5"),Wkt.forEach(t),KHo=r(vDe," \u2014 "),nW=n(vDe,"A",{href:!0});var Ukt=s(nW);ZHo=r(Ukt,"LongT5ForConditionalGeneration"),Ukt.forEach(t),eJo=r(vDe," (LongT5 model)"),vDe.forEach(t),oJo=i(pe),Q4=n(pe,"LI",{});var bDe=s(Q4);y1e=n(bDe,"STRONG",{});var Hkt=s(y1e);rJo=r(Hkt,"m2m_100"),Hkt.forEach(t),tJo=r(bDe," \u2014 "),sW=n(bDe,"A",{href:!0});var Jkt=s(sW);aJo=r(Jkt,"M2M100ForConditionalGeneration"),Jkt.forEach(t),nJo=r(bDe," (M2M100 model)"),bDe.forEach(t),sJo=i(pe),W4=n(pe,"LI",{});var FDe=s(W4);x1e=n(FDe,"STRONG",{});var Ykt=s(x1e);lJo=r(Ykt,"marian"),Ykt.forEach(t),iJo=r(FDe," \u2014 "),lW=n(FDe,"A",{href:!0});var Kkt=s(lW);dJo=r(Kkt,"MarianMTModel"),Kkt.forEach(t),cJo=r(FDe," (Marian model)"),FDe.forEach(t),fJo=i(pe),U4=n(pe,"LI",{});var TDe=s(U4);$1e=n(TDe,"STRONG",{});var Zkt=s($1e);mJo=r(Zkt,"mbart"),Zkt.forEach(t),gJo=r(TDe," \u2014 "),iW=n(TDe,"A",{href:!0});var eSt=s(iW);hJo=r(eSt,"MBartForConditionalGeneration"),eSt.forEach(t),uJo=r(TDe," (mBART model)"),TDe.forEach(t),pJo=i(pe),H4=n(pe,"LI",{});var MDe=s(H4);k1e=n(MDe,"STRONG",{});var oSt=s(k1e);_Jo=r(oSt,"mt5"),oSt.forEach(t),vJo=r(MDe," \u2014 "),dW=n(MDe,"A",{href:!0});var rSt=s(dW);bJo=r(rSt,"MT5ForConditionalGeneration"),rSt.forEach(t),FJo=r(MDe," (MT5 model)"),MDe.forEach(t),TJo=i(pe),J4=n(pe,"LI",{});var EDe=s(J4);S1e=n(EDe,"STRONG",{});var tSt=s(S1e);MJo=r(tSt,"mvp"),tSt.forEach(t),EJo=r(EDe," \u2014 "),cW=n(EDe,"A",{href:!0});var aSt=s(cW);CJo=r(aSt,"MvpForConditionalGeneration"),aSt.forEach(t),wJo=r(EDe," (MVP model)"),EDe.forEach(t),AJo=i(pe),Y4=n(pe,"LI",{});var CDe=s(Y4);R1e=n(CDe,"STRONG",{});var nSt=s(R1e);LJo=r(nSt,"nllb"),nSt.forEach(t),yJo=r(CDe," \u2014 "),fW=n(CDe,"A",{href:!0});var sSt=s(fW);xJo=r(sSt,"M2M100ForConditionalGeneration"),sSt.forEach(t),$Jo=r(CDe," (NLLB model)"),CDe.forEach(t),kJo=i(pe),K4=n(pe,"LI",{});var wDe=s(K4);P1e=n(wDe,"STRONG",{});var lSt=s(P1e);SJo=r(lSt,"pegasus"),lSt.forEach(t),RJo=r(wDe," \u2014 "),mW=n(wDe,"A",{href:!0});var iSt=s(mW);PJo=r(iSt,"PegasusForConditionalGeneration"),iSt.forEach(t),BJo=r(wDe," (Pegasus model)"),wDe.forEach(t),IJo=i(pe),Z4=n(pe,"LI",{});var ADe=s(Z4);B1e=n(ADe,"STRONG",{});var dSt=s(B1e);NJo=r(dSt,"pegasus_x"),dSt.forEach(t),qJo=r(ADe," \u2014 "),gW=n(ADe,"A",{href:!0});var cSt=s(gW);jJo=r(cSt,"PegasusXForConditionalGeneration"),cSt.forEach(t),DJo=r(ADe," (PEGASUS-X model)"),ADe.forEach(t),GJo=i(pe),eb=n(pe,"LI",{});var LDe=s(eb);I1e=n(LDe,"STRONG",{});var fSt=s(I1e);OJo=r(fSt,"plbart"),fSt.forEach(t),VJo=r(LDe," \u2014 "),hW=n(LDe,"A",{href:!0});var mSt=s(hW);XJo=r(mSt,"PLBartForConditionalGeneration"),mSt.forEach(t),zJo=r(LDe," (PLBart model)"),LDe.forEach(t),QJo=i(pe),ob=n(pe,"LI",{});var yDe=s(ob);N1e=n(yDe,"STRONG",{});var gSt=s(N1e);WJo=r(gSt,"prophetnet"),gSt.forEach(t),UJo=r(yDe," \u2014 "),uW=n(yDe,"A",{href:!0});var hSt=s(uW);HJo=r(hSt,"ProphetNetForConditionalGeneration"),hSt.forEach(t),JJo=r(yDe," (ProphetNet model)"),yDe.forEach(t),YJo=i(pe),rb=n(pe,"LI",{});var xDe=s(rb);q1e=n(xDe,"STRONG",{});var uSt=s(q1e);KJo=r(uSt,"t5"),uSt.forEach(t),ZJo=r(xDe," \u2014 "),pW=n(xDe,"A",{href:!0});var pSt=s(pW);eYo=r(pSt,"T5ForConditionalGeneration"),pSt.forEach(t),oYo=r(xDe," (T5 model)"),xDe.forEach(t),rYo=i(pe),tb=n(pe,"LI",{});var $De=s(tb);j1e=n($De,"STRONG",{});var _St=s(j1e);tYo=r(_St,"xlm-prophetnet"),_St.forEach(t),aYo=r($De," \u2014 "),_W=n($De,"A",{href:!0});var vSt=s(_W);nYo=r(vSt,"XLMProphetNetForConditionalGeneration"),vSt.forEach(t),sYo=r($De," (XLM-ProphetNet model)"),$De.forEach(t),pe.forEach(t),lYo=i(Ca),ab=n(Ca,"P",{});var kDe=s(ab);iYo=r(kDe,"The model is set in evaluation mode by default using "),D1e=n(kDe,"CODE",{});var bSt=s(D1e);dYo=r(bSt,"model.eval()"),bSt.forEach(t),cYo=r(kDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G1e=n(kDe,"CODE",{});var FSt=s(G1e);fYo=r(FSt,"model.train()"),FSt.forEach(t),kDe.forEach(t),mYo=i(Ca),T(nb.$$.fragment,Ca),Ca.forEach(t),xl.forEach(t),eKe=i(f),kd=n(f,"H2",{class:!0});var heo=s(kd);sb=n(heo,"A",{id:!0,class:!0,href:!0});var TSt=s(sb);O1e=n(TSt,"SPAN",{});var MSt=s(O1e);T(Fx.$$.fragment,MSt),MSt.forEach(t),TSt.forEach(t),gYo=i(heo),V1e=n(heo,"SPAN",{});var ESt=s(V1e);hYo=r(ESt,"AutoModelForSequenceClassification"),ESt.forEach(t),heo.forEach(t),oKe=i(f),jo=n(f,"DIV",{class:!0});var $l=s(jo);T(Tx.$$.fragment,$l),uYo=i($l),Sd=n($l,"P",{});var tle=s(Sd);pYo=r(tle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),vW=n(tle,"A",{href:!0});var CSt=s(vW);_Yo=r(CSt,"from_pretrained()"),CSt.forEach(t),vYo=r(tle," class method or the "),bW=n(tle,"A",{href:!0});var wSt=s(bW);bYo=r(wSt,"from_config()"),wSt.forEach(t),FYo=r(tle,` class
method.`),tle.forEach(t),TYo=i($l),Mx=n($l,"P",{});var ueo=s(Mx);MYo=r(ueo,"This class cannot be instantiated directly using "),X1e=n(ueo,"CODE",{});var ASt=s(X1e);EYo=r(ASt,"__init__()"),ASt.forEach(t),CYo=r(ueo," (throws an error)."),ueo.forEach(t),wYo=i($l),Mt=n($l,"DIV",{class:!0});var yy=s(Mt);T(Ex.$$.fragment,yy),AYo=i(yy),z1e=n(yy,"P",{});var LSt=s(z1e);LYo=r(LSt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),LSt.forEach(t),yYo=i(yy),Rd=n(yy,"P",{});var ale=s(Rd);xYo=r(ale,`Note:
Loading a model from its configuration file does `),Q1e=n(ale,"STRONG",{});var ySt=s(Q1e);$Yo=r(ySt,"not"),ySt.forEach(t),kYo=r(ale,` load the model weights. It only affects the
model\u2019s configuration. Use `),FW=n(ale,"A",{href:!0});var xSt=s(FW);SYo=r(xSt,"from_pretrained()"),xSt.forEach(t),RYo=r(ale," to load the model weights."),ale.forEach(t),PYo=i(yy),T(lb.$$.fragment,yy),yy.forEach(t),BYo=i($l),ao=n($l,"DIV",{class:!0});var wa=s(ao);T(Cx.$$.fragment,wa),IYo=i(wa),W1e=n(wa,"P",{});var $St=s(W1e);NYo=r($St,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),$St.forEach(t),qYo=i(wa),on=n(wa,"P",{});var xy=s(on);jYo=r(xy,"The model class to instantiate is selected based on the "),U1e=n(xy,"CODE",{});var kSt=s(U1e);DYo=r(kSt,"model_type"),kSt.forEach(t),GYo=r(xy,` property of the config object (either
passed as an argument or loaded from `),H1e=n(xy,"CODE",{});var SSt=s(H1e);OYo=r(SSt,"pretrained_model_name_or_path"),SSt.forEach(t),VYo=r(xy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J1e=n(xy,"CODE",{});var RSt=s(J1e);XYo=r(RSt,"pretrained_model_name_or_path"),RSt.forEach(t),zYo=r(xy,":"),xy.forEach(t),QYo=i(wa),q=n(wa,"UL",{});var D=s(q);ib=n(D,"LI",{});var SDe=s(ib);Y1e=n(SDe,"STRONG",{});var PSt=s(Y1e);WYo=r(PSt,"albert"),PSt.forEach(t),UYo=r(SDe," \u2014 "),TW=n(SDe,"A",{href:!0});var BSt=s(TW);HYo=r(BSt,"AlbertForSequenceClassification"),BSt.forEach(t),JYo=r(SDe," (ALBERT model)"),SDe.forEach(t),YYo=i(D),db=n(D,"LI",{});var RDe=s(db);K1e=n(RDe,"STRONG",{});var ISt=s(K1e);KYo=r(ISt,"bart"),ISt.forEach(t),ZYo=r(RDe," \u2014 "),MW=n(RDe,"A",{href:!0});var NSt=s(MW);eKo=r(NSt,"BartForSequenceClassification"),NSt.forEach(t),oKo=r(RDe," (BART model)"),RDe.forEach(t),rKo=i(D),cb=n(D,"LI",{});var PDe=s(cb);Z1e=n(PDe,"STRONG",{});var qSt=s(Z1e);tKo=r(qSt,"bert"),qSt.forEach(t),aKo=r(PDe," \u2014 "),EW=n(PDe,"A",{href:!0});var jSt=s(EW);nKo=r(jSt,"BertForSequenceClassification"),jSt.forEach(t),sKo=r(PDe," (BERT model)"),PDe.forEach(t),lKo=i(D),fb=n(D,"LI",{});var BDe=s(fb);e4e=n(BDe,"STRONG",{});var DSt=s(e4e);iKo=r(DSt,"big_bird"),DSt.forEach(t),dKo=r(BDe," \u2014 "),CW=n(BDe,"A",{href:!0});var GSt=s(CW);cKo=r(GSt,"BigBirdForSequenceClassification"),GSt.forEach(t),fKo=r(BDe," (BigBird model)"),BDe.forEach(t),mKo=i(D),mb=n(D,"LI",{});var IDe=s(mb);o4e=n(IDe,"STRONG",{});var OSt=s(o4e);gKo=r(OSt,"bigbird_pegasus"),OSt.forEach(t),hKo=r(IDe," \u2014 "),wW=n(IDe,"A",{href:!0});var VSt=s(wW);uKo=r(VSt,"BigBirdPegasusForSequenceClassification"),VSt.forEach(t),pKo=r(IDe," (BigBird-Pegasus model)"),IDe.forEach(t),_Ko=i(D),gb=n(D,"LI",{});var NDe=s(gb);r4e=n(NDe,"STRONG",{});var XSt=s(r4e);vKo=r(XSt,"bloom"),XSt.forEach(t),bKo=r(NDe," \u2014 "),AW=n(NDe,"A",{href:!0});var zSt=s(AW);FKo=r(zSt,"BloomForSequenceClassification"),zSt.forEach(t),TKo=r(NDe," (BLOOM model)"),NDe.forEach(t),MKo=i(D),hb=n(D,"LI",{});var qDe=s(hb);t4e=n(qDe,"STRONG",{});var QSt=s(t4e);EKo=r(QSt,"camembert"),QSt.forEach(t),CKo=r(qDe," \u2014 "),LW=n(qDe,"A",{href:!0});var WSt=s(LW);wKo=r(WSt,"CamembertForSequenceClassification"),WSt.forEach(t),AKo=r(qDe," (CamemBERT model)"),qDe.forEach(t),LKo=i(D),ub=n(D,"LI",{});var jDe=s(ub);a4e=n(jDe,"STRONG",{});var USt=s(a4e);yKo=r(USt,"canine"),USt.forEach(t),xKo=r(jDe," \u2014 "),yW=n(jDe,"A",{href:!0});var HSt=s(yW);$Ko=r(HSt,"CanineForSequenceClassification"),HSt.forEach(t),kKo=r(jDe," (CANINE model)"),jDe.forEach(t),SKo=i(D),pb=n(D,"LI",{});var DDe=s(pb);n4e=n(DDe,"STRONG",{});var JSt=s(n4e);RKo=r(JSt,"convbert"),JSt.forEach(t),PKo=r(DDe," \u2014 "),xW=n(DDe,"A",{href:!0});var YSt=s(xW);BKo=r(YSt,"ConvBertForSequenceClassification"),YSt.forEach(t),IKo=r(DDe," (ConvBERT model)"),DDe.forEach(t),NKo=i(D),_b=n(D,"LI",{});var GDe=s(_b);s4e=n(GDe,"STRONG",{});var KSt=s(s4e);qKo=r(KSt,"ctrl"),KSt.forEach(t),jKo=r(GDe," \u2014 "),$W=n(GDe,"A",{href:!0});var ZSt=s($W);DKo=r(ZSt,"CTRLForSequenceClassification"),ZSt.forEach(t),GKo=r(GDe," (CTRL model)"),GDe.forEach(t),OKo=i(D),vb=n(D,"LI",{});var ODe=s(vb);l4e=n(ODe,"STRONG",{});var eRt=s(l4e);VKo=r(eRt,"data2vec-text"),eRt.forEach(t),XKo=r(ODe," \u2014 "),kW=n(ODe,"A",{href:!0});var oRt=s(kW);zKo=r(oRt,"Data2VecTextForSequenceClassification"),oRt.forEach(t),QKo=r(ODe," (Data2VecText model)"),ODe.forEach(t),WKo=i(D),bb=n(D,"LI",{});var VDe=s(bb);i4e=n(VDe,"STRONG",{});var rRt=s(i4e);UKo=r(rRt,"deberta"),rRt.forEach(t),HKo=r(VDe," \u2014 "),SW=n(VDe,"A",{href:!0});var tRt=s(SW);JKo=r(tRt,"DebertaForSequenceClassification"),tRt.forEach(t),YKo=r(VDe," (DeBERTa model)"),VDe.forEach(t),KKo=i(D),Fb=n(D,"LI",{});var XDe=s(Fb);d4e=n(XDe,"STRONG",{});var aRt=s(d4e);ZKo=r(aRt,"deberta-v2"),aRt.forEach(t),eZo=r(XDe," \u2014 "),RW=n(XDe,"A",{href:!0});var nRt=s(RW);oZo=r(nRt,"DebertaV2ForSequenceClassification"),nRt.forEach(t),rZo=r(XDe," (DeBERTa-v2 model)"),XDe.forEach(t),tZo=i(D),Tb=n(D,"LI",{});var zDe=s(Tb);c4e=n(zDe,"STRONG",{});var sRt=s(c4e);aZo=r(sRt,"distilbert"),sRt.forEach(t),nZo=r(zDe," \u2014 "),PW=n(zDe,"A",{href:!0});var lRt=s(PW);sZo=r(lRt,"DistilBertForSequenceClassification"),lRt.forEach(t),lZo=r(zDe," (DistilBERT model)"),zDe.forEach(t),iZo=i(D),Mb=n(D,"LI",{});var QDe=s(Mb);f4e=n(QDe,"STRONG",{});var iRt=s(f4e);dZo=r(iRt,"electra"),iRt.forEach(t),cZo=r(QDe," \u2014 "),BW=n(QDe,"A",{href:!0});var dRt=s(BW);fZo=r(dRt,"ElectraForSequenceClassification"),dRt.forEach(t),mZo=r(QDe," (ELECTRA model)"),QDe.forEach(t),gZo=i(D),Eb=n(D,"LI",{});var WDe=s(Eb);m4e=n(WDe,"STRONG",{});var cRt=s(m4e);hZo=r(cRt,"ernie"),cRt.forEach(t),uZo=r(WDe," \u2014 "),IW=n(WDe,"A",{href:!0});var fRt=s(IW);pZo=r(fRt,"ErnieForSequenceClassification"),fRt.forEach(t),_Zo=r(WDe," (ERNIE model)"),WDe.forEach(t),vZo=i(D),Cb=n(D,"LI",{});var UDe=s(Cb);g4e=n(UDe,"STRONG",{});var mRt=s(g4e);bZo=r(mRt,"flaubert"),mRt.forEach(t),FZo=r(UDe," \u2014 "),NW=n(UDe,"A",{href:!0});var gRt=s(NW);TZo=r(gRt,"FlaubertForSequenceClassification"),gRt.forEach(t),MZo=r(UDe," (FlauBERT model)"),UDe.forEach(t),EZo=i(D),wb=n(D,"LI",{});var HDe=s(wb);h4e=n(HDe,"STRONG",{});var hRt=s(h4e);CZo=r(hRt,"fnet"),hRt.forEach(t),wZo=r(HDe," \u2014 "),qW=n(HDe,"A",{href:!0});var uRt=s(qW);AZo=r(uRt,"FNetForSequenceClassification"),uRt.forEach(t),LZo=r(HDe," (FNet model)"),HDe.forEach(t),yZo=i(D),Ab=n(D,"LI",{});var JDe=s(Ab);u4e=n(JDe,"STRONG",{});var pRt=s(u4e);xZo=r(pRt,"funnel"),pRt.forEach(t),$Zo=r(JDe," \u2014 "),jW=n(JDe,"A",{href:!0});var _Rt=s(jW);kZo=r(_Rt,"FunnelForSequenceClassification"),_Rt.forEach(t),SZo=r(JDe," (Funnel Transformer model)"),JDe.forEach(t),RZo=i(D),Lb=n(D,"LI",{});var YDe=s(Lb);p4e=n(YDe,"STRONG",{});var vRt=s(p4e);PZo=r(vRt,"gpt2"),vRt.forEach(t),BZo=r(YDe," \u2014 "),DW=n(YDe,"A",{href:!0});var bRt=s(DW);IZo=r(bRt,"GPT2ForSequenceClassification"),bRt.forEach(t),NZo=r(YDe," (OpenAI GPT-2 model)"),YDe.forEach(t),qZo=i(D),yb=n(D,"LI",{});var KDe=s(yb);_4e=n(KDe,"STRONG",{});var FRt=s(_4e);jZo=r(FRt,"gpt_neo"),FRt.forEach(t),DZo=r(KDe," \u2014 "),GW=n(KDe,"A",{href:!0});var TRt=s(GW);GZo=r(TRt,"GPTNeoForSequenceClassification"),TRt.forEach(t),OZo=r(KDe," (GPT Neo model)"),KDe.forEach(t),VZo=i(D),xb=n(D,"LI",{});var ZDe=s(xb);v4e=n(ZDe,"STRONG",{});var MRt=s(v4e);XZo=r(MRt,"gptj"),MRt.forEach(t),zZo=r(ZDe," \u2014 "),OW=n(ZDe,"A",{href:!0});var ERt=s(OW);QZo=r(ERt,"GPTJForSequenceClassification"),ERt.forEach(t),WZo=r(ZDe," (GPT-J model)"),ZDe.forEach(t),UZo=i(D),$b=n(D,"LI",{});var eGe=s($b);b4e=n(eGe,"STRONG",{});var CRt=s(b4e);HZo=r(CRt,"ibert"),CRt.forEach(t),JZo=r(eGe," \u2014 "),VW=n(eGe,"A",{href:!0});var wRt=s(VW);YZo=r(wRt,"IBertForSequenceClassification"),wRt.forEach(t),KZo=r(eGe," (I-BERT model)"),eGe.forEach(t),ZZo=i(D),kb=n(D,"LI",{});var oGe=s(kb);F4e=n(oGe,"STRONG",{});var ARt=s(F4e);eer=r(ARt,"layoutlm"),ARt.forEach(t),oer=r(oGe," \u2014 "),XW=n(oGe,"A",{href:!0});var LRt=s(XW);rer=r(LRt,"LayoutLMForSequenceClassification"),LRt.forEach(t),ter=r(oGe," (LayoutLM model)"),oGe.forEach(t),aer=i(D),Sb=n(D,"LI",{});var rGe=s(Sb);T4e=n(rGe,"STRONG",{});var yRt=s(T4e);ner=r(yRt,"layoutlmv2"),yRt.forEach(t),ser=r(rGe," \u2014 "),zW=n(rGe,"A",{href:!0});var xRt=s(zW);ler=r(xRt,"LayoutLMv2ForSequenceClassification"),xRt.forEach(t),ier=r(rGe," (LayoutLMv2 model)"),rGe.forEach(t),der=i(D),Rb=n(D,"LI",{});var tGe=s(Rb);M4e=n(tGe,"STRONG",{});var $Rt=s(M4e);cer=r($Rt,"layoutlmv3"),$Rt.forEach(t),fer=r(tGe," \u2014 "),QW=n(tGe,"A",{href:!0});var kRt=s(QW);mer=r(kRt,"LayoutLMv3ForSequenceClassification"),kRt.forEach(t),ger=r(tGe," (LayoutLMv3 model)"),tGe.forEach(t),her=i(D),Pb=n(D,"LI",{});var aGe=s(Pb);E4e=n(aGe,"STRONG",{});var SRt=s(E4e);uer=r(SRt,"led"),SRt.forEach(t),per=r(aGe," \u2014 "),WW=n(aGe,"A",{href:!0});var RRt=s(WW);_er=r(RRt,"LEDForSequenceClassification"),RRt.forEach(t),ver=r(aGe," (LED model)"),aGe.forEach(t),ber=i(D),Bb=n(D,"LI",{});var nGe=s(Bb);C4e=n(nGe,"STRONG",{});var PRt=s(C4e);Fer=r(PRt,"longformer"),PRt.forEach(t),Ter=r(nGe," \u2014 "),UW=n(nGe,"A",{href:!0});var BRt=s(UW);Mer=r(BRt,"LongformerForSequenceClassification"),BRt.forEach(t),Eer=r(nGe," (Longformer model)"),nGe.forEach(t),Cer=i(D),Ib=n(D,"LI",{});var sGe=s(Ib);w4e=n(sGe,"STRONG",{});var IRt=s(w4e);wer=r(IRt,"luke"),IRt.forEach(t),Aer=r(sGe," \u2014 "),HW=n(sGe,"A",{href:!0});var NRt=s(HW);Ler=r(NRt,"LukeForSequenceClassification"),NRt.forEach(t),yer=r(sGe," (LUKE model)"),sGe.forEach(t),xer=i(D),Nb=n(D,"LI",{});var lGe=s(Nb);A4e=n(lGe,"STRONG",{});var qRt=s(A4e);$er=r(qRt,"mbart"),qRt.forEach(t),ker=r(lGe," \u2014 "),JW=n(lGe,"A",{href:!0});var jRt=s(JW);Ser=r(jRt,"MBartForSequenceClassification"),jRt.forEach(t),Rer=r(lGe," (mBART model)"),lGe.forEach(t),Per=i(D),qb=n(D,"LI",{});var iGe=s(qb);L4e=n(iGe,"STRONG",{});var DRt=s(L4e);Ber=r(DRt,"megatron-bert"),DRt.forEach(t),Ier=r(iGe," \u2014 "),YW=n(iGe,"A",{href:!0});var GRt=s(YW);Ner=r(GRt,"MegatronBertForSequenceClassification"),GRt.forEach(t),qer=r(iGe," (Megatron-BERT model)"),iGe.forEach(t),jer=i(D),jb=n(D,"LI",{});var dGe=s(jb);y4e=n(dGe,"STRONG",{});var ORt=s(y4e);Der=r(ORt,"mobilebert"),ORt.forEach(t),Ger=r(dGe," \u2014 "),KW=n(dGe,"A",{href:!0});var VRt=s(KW);Oer=r(VRt,"MobileBertForSequenceClassification"),VRt.forEach(t),Ver=r(dGe," (MobileBERT model)"),dGe.forEach(t),Xer=i(D),Db=n(D,"LI",{});var cGe=s(Db);x4e=n(cGe,"STRONG",{});var XRt=s(x4e);zer=r(XRt,"mpnet"),XRt.forEach(t),Qer=r(cGe," \u2014 "),ZW=n(cGe,"A",{href:!0});var zRt=s(ZW);Wer=r(zRt,"MPNetForSequenceClassification"),zRt.forEach(t),Uer=r(cGe," (MPNet model)"),cGe.forEach(t),Her=i(D),Gb=n(D,"LI",{});var fGe=s(Gb);$4e=n(fGe,"STRONG",{});var QRt=s($4e);Jer=r(QRt,"mvp"),QRt.forEach(t),Yer=r(fGe," \u2014 "),eU=n(fGe,"A",{href:!0});var WRt=s(eU);Ker=r(WRt,"MvpForSequenceClassification"),WRt.forEach(t),Zer=r(fGe," (MVP model)"),fGe.forEach(t),eor=i(D),Ob=n(D,"LI",{});var mGe=s(Ob);k4e=n(mGe,"STRONG",{});var URt=s(k4e);oor=r(URt,"nezha"),URt.forEach(t),ror=r(mGe," \u2014 "),oU=n(mGe,"A",{href:!0});var HRt=s(oU);tor=r(HRt,"NezhaForSequenceClassification"),HRt.forEach(t),aor=r(mGe," (Nezha model)"),mGe.forEach(t),nor=i(D),Vb=n(D,"LI",{});var gGe=s(Vb);S4e=n(gGe,"STRONG",{});var JRt=s(S4e);sor=r(JRt,"nystromformer"),JRt.forEach(t),lor=r(gGe," \u2014 "),rU=n(gGe,"A",{href:!0});var YRt=s(rU);ior=r(YRt,"NystromformerForSequenceClassification"),YRt.forEach(t),dor=r(gGe," (Nystr\xF6mformer model)"),gGe.forEach(t),cor=i(D),Xb=n(D,"LI",{});var hGe=s(Xb);R4e=n(hGe,"STRONG",{});var KRt=s(R4e);mor=r(KRt,"openai-gpt"),KRt.forEach(t),gor=r(hGe," \u2014 "),tU=n(hGe,"A",{href:!0});var ZRt=s(tU);hor=r(ZRt,"OpenAIGPTForSequenceClassification"),ZRt.forEach(t),uor=r(hGe," (OpenAI GPT model)"),hGe.forEach(t),por=i(D),zb=n(D,"LI",{});var uGe=s(zb);P4e=n(uGe,"STRONG",{});var ePt=s(P4e);_or=r(ePt,"opt"),ePt.forEach(t),vor=r(uGe," \u2014 "),aU=n(uGe,"A",{href:!0});var oPt=s(aU);bor=r(oPt,"OPTForSequenceClassification"),oPt.forEach(t),For=r(uGe," (OPT model)"),uGe.forEach(t),Tor=i(D),Qb=n(D,"LI",{});var pGe=s(Qb);B4e=n(pGe,"STRONG",{});var rPt=s(B4e);Mor=r(rPt,"perceiver"),rPt.forEach(t),Eor=r(pGe," \u2014 "),nU=n(pGe,"A",{href:!0});var tPt=s(nU);Cor=r(tPt,"PerceiverForSequenceClassification"),tPt.forEach(t),wor=r(pGe," (Perceiver model)"),pGe.forEach(t),Aor=i(D),Wb=n(D,"LI",{});var _Ge=s(Wb);I4e=n(_Ge,"STRONG",{});var aPt=s(I4e);Lor=r(aPt,"plbart"),aPt.forEach(t),yor=r(_Ge," \u2014 "),sU=n(_Ge,"A",{href:!0});var nPt=s(sU);xor=r(nPt,"PLBartForSequenceClassification"),nPt.forEach(t),$or=r(_Ge," (PLBart model)"),_Ge.forEach(t),kor=i(D),Ub=n(D,"LI",{});var vGe=s(Ub);N4e=n(vGe,"STRONG",{});var sPt=s(N4e);Sor=r(sPt,"qdqbert"),sPt.forEach(t),Ror=r(vGe," \u2014 "),lU=n(vGe,"A",{href:!0});var lPt=s(lU);Por=r(lPt,"QDQBertForSequenceClassification"),lPt.forEach(t),Bor=r(vGe," (QDQBert model)"),vGe.forEach(t),Ior=i(D),Hb=n(D,"LI",{});var bGe=s(Hb);q4e=n(bGe,"STRONG",{});var iPt=s(q4e);Nor=r(iPt,"reformer"),iPt.forEach(t),qor=r(bGe," \u2014 "),iU=n(bGe,"A",{href:!0});var dPt=s(iU);jor=r(dPt,"ReformerForSequenceClassification"),dPt.forEach(t),Dor=r(bGe," (Reformer model)"),bGe.forEach(t),Gor=i(D),Jb=n(D,"LI",{});var FGe=s(Jb);j4e=n(FGe,"STRONG",{});var cPt=s(j4e);Oor=r(cPt,"rembert"),cPt.forEach(t),Vor=r(FGe," \u2014 "),dU=n(FGe,"A",{href:!0});var fPt=s(dU);Xor=r(fPt,"RemBertForSequenceClassification"),fPt.forEach(t),zor=r(FGe," (RemBERT model)"),FGe.forEach(t),Qor=i(D),Yb=n(D,"LI",{});var TGe=s(Yb);D4e=n(TGe,"STRONG",{});var mPt=s(D4e);Wor=r(mPt,"roberta"),mPt.forEach(t),Uor=r(TGe," \u2014 "),cU=n(TGe,"A",{href:!0});var gPt=s(cU);Hor=r(gPt,"RobertaForSequenceClassification"),gPt.forEach(t),Jor=r(TGe," (RoBERTa model)"),TGe.forEach(t),Yor=i(D),Kb=n(D,"LI",{});var MGe=s(Kb);G4e=n(MGe,"STRONG",{});var hPt=s(G4e);Kor=r(hPt,"roformer"),hPt.forEach(t),Zor=r(MGe," \u2014 "),fU=n(MGe,"A",{href:!0});var uPt=s(fU);err=r(uPt,"RoFormerForSequenceClassification"),uPt.forEach(t),orr=r(MGe," (RoFormer model)"),MGe.forEach(t),rrr=i(D),Zb=n(D,"LI",{});var EGe=s(Zb);O4e=n(EGe,"STRONG",{});var pPt=s(O4e);trr=r(pPt,"squeezebert"),pPt.forEach(t),arr=r(EGe," \u2014 "),mU=n(EGe,"A",{href:!0});var _Pt=s(mU);nrr=r(_Pt,"SqueezeBertForSequenceClassification"),_Pt.forEach(t),srr=r(EGe," (SqueezeBERT model)"),EGe.forEach(t),lrr=i(D),eF=n(D,"LI",{});var CGe=s(eF);V4e=n(CGe,"STRONG",{});var vPt=s(V4e);irr=r(vPt,"tapas"),vPt.forEach(t),drr=r(CGe," \u2014 "),gU=n(CGe,"A",{href:!0});var bPt=s(gU);crr=r(bPt,"TapasForSequenceClassification"),bPt.forEach(t),frr=r(CGe," (TAPAS model)"),CGe.forEach(t),mrr=i(D),oF=n(D,"LI",{});var wGe=s(oF);X4e=n(wGe,"STRONG",{});var FPt=s(X4e);grr=r(FPt,"transfo-xl"),FPt.forEach(t),hrr=r(wGe," \u2014 "),hU=n(wGe,"A",{href:!0});var TPt=s(hU);urr=r(TPt,"TransfoXLForSequenceClassification"),TPt.forEach(t),prr=r(wGe," (Transformer-XL model)"),wGe.forEach(t),_rr=i(D),rF=n(D,"LI",{});var AGe=s(rF);z4e=n(AGe,"STRONG",{});var MPt=s(z4e);vrr=r(MPt,"xlm"),MPt.forEach(t),brr=r(AGe," \u2014 "),uU=n(AGe,"A",{href:!0});var EPt=s(uU);Frr=r(EPt,"XLMForSequenceClassification"),EPt.forEach(t),Trr=r(AGe," (XLM model)"),AGe.forEach(t),Mrr=i(D),tF=n(D,"LI",{});var LGe=s(tF);Q4e=n(LGe,"STRONG",{});var CPt=s(Q4e);Err=r(CPt,"xlm-roberta"),CPt.forEach(t),Crr=r(LGe," \u2014 "),pU=n(LGe,"A",{href:!0});var wPt=s(pU);wrr=r(wPt,"XLMRobertaForSequenceClassification"),wPt.forEach(t),Arr=r(LGe," (XLM-RoBERTa model)"),LGe.forEach(t),Lrr=i(D),aF=n(D,"LI",{});var yGe=s(aF);W4e=n(yGe,"STRONG",{});var APt=s(W4e);yrr=r(APt,"xlm-roberta-xl"),APt.forEach(t),xrr=r(yGe," \u2014 "),_U=n(yGe,"A",{href:!0});var LPt=s(_U);$rr=r(LPt,"XLMRobertaXLForSequenceClassification"),LPt.forEach(t),krr=r(yGe," (XLM-RoBERTa-XL model)"),yGe.forEach(t),Srr=i(D),nF=n(D,"LI",{});var xGe=s(nF);U4e=n(xGe,"STRONG",{});var yPt=s(U4e);Rrr=r(yPt,"xlnet"),yPt.forEach(t),Prr=r(xGe," \u2014 "),vU=n(xGe,"A",{href:!0});var xPt=s(vU);Brr=r(xPt,"XLNetForSequenceClassification"),xPt.forEach(t),Irr=r(xGe," (XLNet model)"),xGe.forEach(t),Nrr=i(D),sF=n(D,"LI",{});var $Ge=s(sF);H4e=n($Ge,"STRONG",{});var $Pt=s(H4e);qrr=r($Pt,"yoso"),$Pt.forEach(t),jrr=r($Ge," \u2014 "),bU=n($Ge,"A",{href:!0});var kPt=s(bU);Drr=r(kPt,"YosoForSequenceClassification"),kPt.forEach(t),Grr=r($Ge," (YOSO model)"),$Ge.forEach(t),D.forEach(t),Orr=i(wa),lF=n(wa,"P",{});var kGe=s(lF);Vrr=r(kGe,"The model is set in evaluation mode by default using "),J4e=n(kGe,"CODE",{});var SPt=s(J4e);Xrr=r(SPt,"model.eval()"),SPt.forEach(t),zrr=r(kGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y4e=n(kGe,"CODE",{});var RPt=s(Y4e);Qrr=r(RPt,"model.train()"),RPt.forEach(t),kGe.forEach(t),Wrr=i(wa),T(iF.$$.fragment,wa),wa.forEach(t),$l.forEach(t),rKe=i(f),Pd=n(f,"H2",{class:!0});var peo=s(Pd);dF=n(peo,"A",{id:!0,class:!0,href:!0});var PPt=s(dF);K4e=n(PPt,"SPAN",{});var BPt=s(K4e);T(wx.$$.fragment,BPt),BPt.forEach(t),PPt.forEach(t),Urr=i(peo),Z4e=n(peo,"SPAN",{});var IPt=s(Z4e);Hrr=r(IPt,"AutoModelForMultipleChoice"),IPt.forEach(t),peo.forEach(t),tKe=i(f),Do=n(f,"DIV",{class:!0});var kl=s(Do);T(Ax.$$.fragment,kl),Jrr=i(kl),Bd=n(kl,"P",{});var nle=s(Bd);Yrr=r(nle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FU=n(nle,"A",{href:!0});var NPt=s(FU);Krr=r(NPt,"from_pretrained()"),NPt.forEach(t),Zrr=r(nle," class method or the "),TU=n(nle,"A",{href:!0});var qPt=s(TU);etr=r(qPt,"from_config()"),qPt.forEach(t),otr=r(nle,` class
method.`),nle.forEach(t),rtr=i(kl),Lx=n(kl,"P",{});var _eo=s(Lx);ttr=r(_eo,"This class cannot be instantiated directly using "),ebe=n(_eo,"CODE",{});var jPt=s(ebe);atr=r(jPt,"__init__()"),jPt.forEach(t),ntr=r(_eo," (throws an error)."),_eo.forEach(t),str=i(kl),Et=n(kl,"DIV",{class:!0});var $y=s(Et);T(yx.$$.fragment,$y),ltr=i($y),obe=n($y,"P",{});var DPt=s(obe);itr=r(DPt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),DPt.forEach(t),dtr=i($y),Id=n($y,"P",{});var sle=s(Id);ctr=r(sle,`Note:
Loading a model from its configuration file does `),rbe=n(sle,"STRONG",{});var GPt=s(rbe);ftr=r(GPt,"not"),GPt.forEach(t),mtr=r(sle,` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=n(sle,"A",{href:!0});var OPt=s(MU);gtr=r(OPt,"from_pretrained()"),OPt.forEach(t),htr=r(sle," to load the model weights."),sle.forEach(t),utr=i($y),T(cF.$$.fragment,$y),$y.forEach(t),ptr=i(kl),no=n(kl,"DIV",{class:!0});var Aa=s(no);T(xx.$$.fragment,Aa),_tr=i(Aa),tbe=n(Aa,"P",{});var VPt=s(tbe);vtr=r(VPt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VPt.forEach(t),btr=i(Aa),rn=n(Aa,"P",{});var ky=s(rn);Ftr=r(ky,"The model class to instantiate is selected based on the "),abe=n(ky,"CODE",{});var XPt=s(abe);Ttr=r(XPt,"model_type"),XPt.forEach(t),Mtr=r(ky,` property of the config object (either
passed as an argument or loaded from `),nbe=n(ky,"CODE",{});var zPt=s(nbe);Etr=r(zPt,"pretrained_model_name_or_path"),zPt.forEach(t),Ctr=r(ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sbe=n(ky,"CODE",{});var QPt=s(sbe);wtr=r(QPt,"pretrained_model_name_or_path"),QPt.forEach(t),Atr=r(ky,":"),ky.forEach(t),Ltr=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);fF=n(ee,"LI",{});var SGe=s(fF);lbe=n(SGe,"STRONG",{});var WPt=s(lbe);ytr=r(WPt,"albert"),WPt.forEach(t),xtr=r(SGe," \u2014 "),EU=n(SGe,"A",{href:!0});var UPt=s(EU);$tr=r(UPt,"AlbertForMultipleChoice"),UPt.forEach(t),ktr=r(SGe," (ALBERT model)"),SGe.forEach(t),Str=i(ee),mF=n(ee,"LI",{});var RGe=s(mF);ibe=n(RGe,"STRONG",{});var HPt=s(ibe);Rtr=r(HPt,"bert"),HPt.forEach(t),Ptr=r(RGe," \u2014 "),CU=n(RGe,"A",{href:!0});var JPt=s(CU);Btr=r(JPt,"BertForMultipleChoice"),JPt.forEach(t),Itr=r(RGe," (BERT model)"),RGe.forEach(t),Ntr=i(ee),gF=n(ee,"LI",{});var PGe=s(gF);dbe=n(PGe,"STRONG",{});var YPt=s(dbe);qtr=r(YPt,"big_bird"),YPt.forEach(t),jtr=r(PGe," \u2014 "),wU=n(PGe,"A",{href:!0});var KPt=s(wU);Dtr=r(KPt,"BigBirdForMultipleChoice"),KPt.forEach(t),Gtr=r(PGe," (BigBird model)"),PGe.forEach(t),Otr=i(ee),hF=n(ee,"LI",{});var BGe=s(hF);cbe=n(BGe,"STRONG",{});var ZPt=s(cbe);Vtr=r(ZPt,"camembert"),ZPt.forEach(t),Xtr=r(BGe," \u2014 "),AU=n(BGe,"A",{href:!0});var eBt=s(AU);ztr=r(eBt,"CamembertForMultipleChoice"),eBt.forEach(t),Qtr=r(BGe," (CamemBERT model)"),BGe.forEach(t),Wtr=i(ee),uF=n(ee,"LI",{});var IGe=s(uF);fbe=n(IGe,"STRONG",{});var oBt=s(fbe);Utr=r(oBt,"canine"),oBt.forEach(t),Htr=r(IGe," \u2014 "),LU=n(IGe,"A",{href:!0});var rBt=s(LU);Jtr=r(rBt,"CanineForMultipleChoice"),rBt.forEach(t),Ytr=r(IGe," (CANINE model)"),IGe.forEach(t),Ktr=i(ee),pF=n(ee,"LI",{});var NGe=s(pF);mbe=n(NGe,"STRONG",{});var tBt=s(mbe);Ztr=r(tBt,"convbert"),tBt.forEach(t),ear=r(NGe," \u2014 "),yU=n(NGe,"A",{href:!0});var aBt=s(yU);oar=r(aBt,"ConvBertForMultipleChoice"),aBt.forEach(t),rar=r(NGe," (ConvBERT model)"),NGe.forEach(t),tar=i(ee),_F=n(ee,"LI",{});var qGe=s(_F);gbe=n(qGe,"STRONG",{});var nBt=s(gbe);aar=r(nBt,"data2vec-text"),nBt.forEach(t),nar=r(qGe," \u2014 "),xU=n(qGe,"A",{href:!0});var sBt=s(xU);sar=r(sBt,"Data2VecTextForMultipleChoice"),sBt.forEach(t),lar=r(qGe," (Data2VecText model)"),qGe.forEach(t),iar=i(ee),vF=n(ee,"LI",{});var jGe=s(vF);hbe=n(jGe,"STRONG",{});var lBt=s(hbe);dar=r(lBt,"deberta-v2"),lBt.forEach(t),car=r(jGe," \u2014 "),$U=n(jGe,"A",{href:!0});var iBt=s($U);far=r(iBt,"DebertaV2ForMultipleChoice"),iBt.forEach(t),mar=r(jGe," (DeBERTa-v2 model)"),jGe.forEach(t),gar=i(ee),bF=n(ee,"LI",{});var DGe=s(bF);ube=n(DGe,"STRONG",{});var dBt=s(ube);har=r(dBt,"distilbert"),dBt.forEach(t),uar=r(DGe," \u2014 "),kU=n(DGe,"A",{href:!0});var cBt=s(kU);par=r(cBt,"DistilBertForMultipleChoice"),cBt.forEach(t),_ar=r(DGe," (DistilBERT model)"),DGe.forEach(t),bar=i(ee),FF=n(ee,"LI",{});var GGe=s(FF);pbe=n(GGe,"STRONG",{});var fBt=s(pbe);Far=r(fBt,"electra"),fBt.forEach(t),Tar=r(GGe," \u2014 "),SU=n(GGe,"A",{href:!0});var mBt=s(SU);Mar=r(mBt,"ElectraForMultipleChoice"),mBt.forEach(t),Ear=r(GGe," (ELECTRA model)"),GGe.forEach(t),Car=i(ee),TF=n(ee,"LI",{});var OGe=s(TF);_be=n(OGe,"STRONG",{});var gBt=s(_be);war=r(gBt,"ernie"),gBt.forEach(t),Aar=r(OGe," \u2014 "),RU=n(OGe,"A",{href:!0});var hBt=s(RU);Lar=r(hBt,"ErnieForMultipleChoice"),hBt.forEach(t),yar=r(OGe," (ERNIE model)"),OGe.forEach(t),xar=i(ee),MF=n(ee,"LI",{});var VGe=s(MF);vbe=n(VGe,"STRONG",{});var uBt=s(vbe);$ar=r(uBt,"flaubert"),uBt.forEach(t),kar=r(VGe," \u2014 "),PU=n(VGe,"A",{href:!0});var pBt=s(PU);Sar=r(pBt,"FlaubertForMultipleChoice"),pBt.forEach(t),Rar=r(VGe," (FlauBERT model)"),VGe.forEach(t),Par=i(ee),EF=n(ee,"LI",{});var XGe=s(EF);bbe=n(XGe,"STRONG",{});var _Bt=s(bbe);Bar=r(_Bt,"fnet"),_Bt.forEach(t),Iar=r(XGe," \u2014 "),BU=n(XGe,"A",{href:!0});var vBt=s(BU);Nar=r(vBt,"FNetForMultipleChoice"),vBt.forEach(t),qar=r(XGe," (FNet model)"),XGe.forEach(t),jar=i(ee),CF=n(ee,"LI",{});var zGe=s(CF);Fbe=n(zGe,"STRONG",{});var bBt=s(Fbe);Dar=r(bBt,"funnel"),bBt.forEach(t),Gar=r(zGe," \u2014 "),IU=n(zGe,"A",{href:!0});var FBt=s(IU);Oar=r(FBt,"FunnelForMultipleChoice"),FBt.forEach(t),Var=r(zGe," (Funnel Transformer model)"),zGe.forEach(t),Xar=i(ee),wF=n(ee,"LI",{});var QGe=s(wF);Tbe=n(QGe,"STRONG",{});var TBt=s(Tbe);zar=r(TBt,"ibert"),TBt.forEach(t),Qar=r(QGe," \u2014 "),NU=n(QGe,"A",{href:!0});var MBt=s(NU);War=r(MBt,"IBertForMultipleChoice"),MBt.forEach(t),Uar=r(QGe," (I-BERT model)"),QGe.forEach(t),Har=i(ee),AF=n(ee,"LI",{});var WGe=s(AF);Mbe=n(WGe,"STRONG",{});var EBt=s(Mbe);Jar=r(EBt,"longformer"),EBt.forEach(t),Yar=r(WGe," \u2014 "),qU=n(WGe,"A",{href:!0});var CBt=s(qU);Kar=r(CBt,"LongformerForMultipleChoice"),CBt.forEach(t),Zar=r(WGe," (Longformer model)"),WGe.forEach(t),enr=i(ee),LF=n(ee,"LI",{});var UGe=s(LF);Ebe=n(UGe,"STRONG",{});var wBt=s(Ebe);onr=r(wBt,"luke"),wBt.forEach(t),rnr=r(UGe," \u2014 "),jU=n(UGe,"A",{href:!0});var ABt=s(jU);tnr=r(ABt,"LukeForMultipleChoice"),ABt.forEach(t),anr=r(UGe," (LUKE model)"),UGe.forEach(t),nnr=i(ee),yF=n(ee,"LI",{});var HGe=s(yF);Cbe=n(HGe,"STRONG",{});var LBt=s(Cbe);snr=r(LBt,"megatron-bert"),LBt.forEach(t),lnr=r(HGe," \u2014 "),DU=n(HGe,"A",{href:!0});var yBt=s(DU);inr=r(yBt,"MegatronBertForMultipleChoice"),yBt.forEach(t),dnr=r(HGe," (Megatron-BERT model)"),HGe.forEach(t),cnr=i(ee),xF=n(ee,"LI",{});var JGe=s(xF);wbe=n(JGe,"STRONG",{});var xBt=s(wbe);fnr=r(xBt,"mobilebert"),xBt.forEach(t),mnr=r(JGe," \u2014 "),GU=n(JGe,"A",{href:!0});var $Bt=s(GU);gnr=r($Bt,"MobileBertForMultipleChoice"),$Bt.forEach(t),hnr=r(JGe," (MobileBERT model)"),JGe.forEach(t),unr=i(ee),$F=n(ee,"LI",{});var YGe=s($F);Abe=n(YGe,"STRONG",{});var kBt=s(Abe);pnr=r(kBt,"mpnet"),kBt.forEach(t),_nr=r(YGe," \u2014 "),OU=n(YGe,"A",{href:!0});var SBt=s(OU);vnr=r(SBt,"MPNetForMultipleChoice"),SBt.forEach(t),bnr=r(YGe," (MPNet model)"),YGe.forEach(t),Fnr=i(ee),kF=n(ee,"LI",{});var KGe=s(kF);Lbe=n(KGe,"STRONG",{});var RBt=s(Lbe);Tnr=r(RBt,"nezha"),RBt.forEach(t),Mnr=r(KGe," \u2014 "),VU=n(KGe,"A",{href:!0});var PBt=s(VU);Enr=r(PBt,"NezhaForMultipleChoice"),PBt.forEach(t),Cnr=r(KGe," (Nezha model)"),KGe.forEach(t),wnr=i(ee),SF=n(ee,"LI",{});var ZGe=s(SF);ybe=n(ZGe,"STRONG",{});var BBt=s(ybe);Anr=r(BBt,"nystromformer"),BBt.forEach(t),Lnr=r(ZGe," \u2014 "),XU=n(ZGe,"A",{href:!0});var IBt=s(XU);ynr=r(IBt,"NystromformerForMultipleChoice"),IBt.forEach(t),xnr=r(ZGe," (Nystr\xF6mformer model)"),ZGe.forEach(t),$nr=i(ee),RF=n(ee,"LI",{});var eOe=s(RF);xbe=n(eOe,"STRONG",{});var NBt=s(xbe);knr=r(NBt,"qdqbert"),NBt.forEach(t),Snr=r(eOe," \u2014 "),zU=n(eOe,"A",{href:!0});var qBt=s(zU);Rnr=r(qBt,"QDQBertForMultipleChoice"),qBt.forEach(t),Pnr=r(eOe," (QDQBert model)"),eOe.forEach(t),Bnr=i(ee),PF=n(ee,"LI",{});var oOe=s(PF);$be=n(oOe,"STRONG",{});var jBt=s($be);Inr=r(jBt,"rembert"),jBt.forEach(t),Nnr=r(oOe," \u2014 "),QU=n(oOe,"A",{href:!0});var DBt=s(QU);qnr=r(DBt,"RemBertForMultipleChoice"),DBt.forEach(t),jnr=r(oOe," (RemBERT model)"),oOe.forEach(t),Dnr=i(ee),BF=n(ee,"LI",{});var rOe=s(BF);kbe=n(rOe,"STRONG",{});var GBt=s(kbe);Gnr=r(GBt,"roberta"),GBt.forEach(t),Onr=r(rOe," \u2014 "),WU=n(rOe,"A",{href:!0});var OBt=s(WU);Vnr=r(OBt,"RobertaForMultipleChoice"),OBt.forEach(t),Xnr=r(rOe," (RoBERTa model)"),rOe.forEach(t),znr=i(ee),IF=n(ee,"LI",{});var tOe=s(IF);Sbe=n(tOe,"STRONG",{});var VBt=s(Sbe);Qnr=r(VBt,"roformer"),VBt.forEach(t),Wnr=r(tOe," \u2014 "),UU=n(tOe,"A",{href:!0});var XBt=s(UU);Unr=r(XBt,"RoFormerForMultipleChoice"),XBt.forEach(t),Hnr=r(tOe," (RoFormer model)"),tOe.forEach(t),Jnr=i(ee),NF=n(ee,"LI",{});var aOe=s(NF);Rbe=n(aOe,"STRONG",{});var zBt=s(Rbe);Ynr=r(zBt,"squeezebert"),zBt.forEach(t),Knr=r(aOe," \u2014 "),HU=n(aOe,"A",{href:!0});var QBt=s(HU);Znr=r(QBt,"SqueezeBertForMultipleChoice"),QBt.forEach(t),esr=r(aOe," (SqueezeBERT model)"),aOe.forEach(t),osr=i(ee),qF=n(ee,"LI",{});var nOe=s(qF);Pbe=n(nOe,"STRONG",{});var WBt=s(Pbe);rsr=r(WBt,"xlm"),WBt.forEach(t),tsr=r(nOe," \u2014 "),JU=n(nOe,"A",{href:!0});var UBt=s(JU);asr=r(UBt,"XLMForMultipleChoice"),UBt.forEach(t),nsr=r(nOe," (XLM model)"),nOe.forEach(t),ssr=i(ee),jF=n(ee,"LI",{});var sOe=s(jF);Bbe=n(sOe,"STRONG",{});var HBt=s(Bbe);lsr=r(HBt,"xlm-roberta"),HBt.forEach(t),isr=r(sOe," \u2014 "),YU=n(sOe,"A",{href:!0});var JBt=s(YU);dsr=r(JBt,"XLMRobertaForMultipleChoice"),JBt.forEach(t),csr=r(sOe," (XLM-RoBERTa model)"),sOe.forEach(t),fsr=i(ee),DF=n(ee,"LI",{});var lOe=s(DF);Ibe=n(lOe,"STRONG",{});var YBt=s(Ibe);msr=r(YBt,"xlm-roberta-xl"),YBt.forEach(t),gsr=r(lOe," \u2014 "),KU=n(lOe,"A",{href:!0});var KBt=s(KU);hsr=r(KBt,"XLMRobertaXLForMultipleChoice"),KBt.forEach(t),usr=r(lOe," (XLM-RoBERTa-XL model)"),lOe.forEach(t),psr=i(ee),GF=n(ee,"LI",{});var iOe=s(GF);Nbe=n(iOe,"STRONG",{});var ZBt=s(Nbe);_sr=r(ZBt,"xlnet"),ZBt.forEach(t),vsr=r(iOe," \u2014 "),ZU=n(iOe,"A",{href:!0});var eIt=s(ZU);bsr=r(eIt,"XLNetForMultipleChoice"),eIt.forEach(t),Fsr=r(iOe," (XLNet model)"),iOe.forEach(t),Tsr=i(ee),OF=n(ee,"LI",{});var dOe=s(OF);qbe=n(dOe,"STRONG",{});var oIt=s(qbe);Msr=r(oIt,"yoso"),oIt.forEach(t),Esr=r(dOe," \u2014 "),eH=n(dOe,"A",{href:!0});var rIt=s(eH);Csr=r(rIt,"YosoForMultipleChoice"),rIt.forEach(t),wsr=r(dOe," (YOSO model)"),dOe.forEach(t),ee.forEach(t),Asr=i(Aa),VF=n(Aa,"P",{});var cOe=s(VF);Lsr=r(cOe,"The model is set in evaluation mode by default using "),jbe=n(cOe,"CODE",{});var tIt=s(jbe);ysr=r(tIt,"model.eval()"),tIt.forEach(t),xsr=r(cOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dbe=n(cOe,"CODE",{});var aIt=s(Dbe);$sr=r(aIt,"model.train()"),aIt.forEach(t),cOe.forEach(t),ksr=i(Aa),T(XF.$$.fragment,Aa),Aa.forEach(t),kl.forEach(t),aKe=i(f),Nd=n(f,"H2",{class:!0});var veo=s(Nd);zF=n(veo,"A",{id:!0,class:!0,href:!0});var nIt=s(zF);Gbe=n(nIt,"SPAN",{});var sIt=s(Gbe);T($x.$$.fragment,sIt),sIt.forEach(t),nIt.forEach(t),Ssr=i(veo),Obe=n(veo,"SPAN",{});var lIt=s(Obe);Rsr=r(lIt,"AutoModelForNextSentencePrediction"),lIt.forEach(t),veo.forEach(t),nKe=i(f),Go=n(f,"DIV",{class:!0});var Sl=s(Go);T(kx.$$.fragment,Sl),Psr=i(Sl),qd=n(Sl,"P",{});var lle=s(qd);Bsr=r(lle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),oH=n(lle,"A",{href:!0});var iIt=s(oH);Isr=r(iIt,"from_pretrained()"),iIt.forEach(t),Nsr=r(lle," class method or the "),rH=n(lle,"A",{href:!0});var dIt=s(rH);qsr=r(dIt,"from_config()"),dIt.forEach(t),jsr=r(lle,` class
method.`),lle.forEach(t),Dsr=i(Sl),Sx=n(Sl,"P",{});var beo=s(Sx);Gsr=r(beo,"This class cannot be instantiated directly using "),Vbe=n(beo,"CODE",{});var cIt=s(Vbe);Osr=r(cIt,"__init__()"),cIt.forEach(t),Vsr=r(beo," (throws an error)."),beo.forEach(t),Xsr=i(Sl),Ct=n(Sl,"DIV",{class:!0});var Sy=s(Ct);T(Rx.$$.fragment,Sy),zsr=i(Sy),Xbe=n(Sy,"P",{});var fIt=s(Xbe);Qsr=r(fIt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fIt.forEach(t),Wsr=i(Sy),jd=n(Sy,"P",{});var ile=s(jd);Usr=r(ile,`Note:
Loading a model from its configuration file does `),zbe=n(ile,"STRONG",{});var mIt=s(zbe);Hsr=r(mIt,"not"),mIt.forEach(t),Jsr=r(ile,` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=n(ile,"A",{href:!0});var gIt=s(tH);Ysr=r(gIt,"from_pretrained()"),gIt.forEach(t),Ksr=r(ile," to load the model weights."),ile.forEach(t),Zsr=i(Sy),T(QF.$$.fragment,Sy),Sy.forEach(t),elr=i(Sl),so=n(Sl,"DIV",{class:!0});var La=s(so);T(Px.$$.fragment,La),olr=i(La),Qbe=n(La,"P",{});var hIt=s(Qbe);rlr=r(hIt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hIt.forEach(t),tlr=i(La),tn=n(La,"P",{});var Ry=s(tn);alr=r(Ry,"The model class to instantiate is selected based on the "),Wbe=n(Ry,"CODE",{});var uIt=s(Wbe);nlr=r(uIt,"model_type"),uIt.forEach(t),slr=r(Ry,` property of the config object (either
passed as an argument or loaded from `),Ube=n(Ry,"CODE",{});var pIt=s(Ube);llr=r(pIt,"pretrained_model_name_or_path"),pIt.forEach(t),ilr=r(Ry,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hbe=n(Ry,"CODE",{});var _It=s(Hbe);dlr=r(_It,"pretrained_model_name_or_path"),_It.forEach(t),clr=r(Ry,":"),Ry.forEach(t),flr=i(La),Ue=n(La,"UL",{});var ct=s(Ue);WF=n(ct,"LI",{});var fOe=s(WF);Jbe=n(fOe,"STRONG",{});var vIt=s(Jbe);mlr=r(vIt,"bert"),vIt.forEach(t),glr=r(fOe," \u2014 "),aH=n(fOe,"A",{href:!0});var bIt=s(aH);hlr=r(bIt,"BertForNextSentencePrediction"),bIt.forEach(t),ulr=r(fOe," (BERT model)"),fOe.forEach(t),plr=i(ct),UF=n(ct,"LI",{});var mOe=s(UF);Ybe=n(mOe,"STRONG",{});var FIt=s(Ybe);_lr=r(FIt,"ernie"),FIt.forEach(t),vlr=r(mOe," \u2014 "),nH=n(mOe,"A",{href:!0});var TIt=s(nH);blr=r(TIt,"ErnieForNextSentencePrediction"),TIt.forEach(t),Flr=r(mOe," (ERNIE model)"),mOe.forEach(t),Tlr=i(ct),HF=n(ct,"LI",{});var gOe=s(HF);Kbe=n(gOe,"STRONG",{});var MIt=s(Kbe);Mlr=r(MIt,"fnet"),MIt.forEach(t),Elr=r(gOe," \u2014 "),sH=n(gOe,"A",{href:!0});var EIt=s(sH);Clr=r(EIt,"FNetForNextSentencePrediction"),EIt.forEach(t),wlr=r(gOe," (FNet model)"),gOe.forEach(t),Alr=i(ct),JF=n(ct,"LI",{});var hOe=s(JF);Zbe=n(hOe,"STRONG",{});var CIt=s(Zbe);Llr=r(CIt,"megatron-bert"),CIt.forEach(t),ylr=r(hOe," \u2014 "),lH=n(hOe,"A",{href:!0});var wIt=s(lH);xlr=r(wIt,"MegatronBertForNextSentencePrediction"),wIt.forEach(t),$lr=r(hOe," (Megatron-BERT model)"),hOe.forEach(t),klr=i(ct),YF=n(ct,"LI",{});var uOe=s(YF);eFe=n(uOe,"STRONG",{});var AIt=s(eFe);Slr=r(AIt,"mobilebert"),AIt.forEach(t),Rlr=r(uOe," \u2014 "),iH=n(uOe,"A",{href:!0});var LIt=s(iH);Plr=r(LIt,"MobileBertForNextSentencePrediction"),LIt.forEach(t),Blr=r(uOe," (MobileBERT model)"),uOe.forEach(t),Ilr=i(ct),KF=n(ct,"LI",{});var pOe=s(KF);oFe=n(pOe,"STRONG",{});var yIt=s(oFe);Nlr=r(yIt,"nezha"),yIt.forEach(t),qlr=r(pOe," \u2014 "),dH=n(pOe,"A",{href:!0});var xIt=s(dH);jlr=r(xIt,"NezhaForNextSentencePrediction"),xIt.forEach(t),Dlr=r(pOe," (Nezha model)"),pOe.forEach(t),Glr=i(ct),ZF=n(ct,"LI",{});var _Oe=s(ZF);rFe=n(_Oe,"STRONG",{});var $It=s(rFe);Olr=r($It,"qdqbert"),$It.forEach(t),Vlr=r(_Oe," \u2014 "),cH=n(_Oe,"A",{href:!0});var kIt=s(cH);Xlr=r(kIt,"QDQBertForNextSentencePrediction"),kIt.forEach(t),zlr=r(_Oe," (QDQBert model)"),_Oe.forEach(t),ct.forEach(t),Qlr=i(La),eT=n(La,"P",{});var vOe=s(eT);Wlr=r(vOe,"The model is set in evaluation mode by default using "),tFe=n(vOe,"CODE",{});var SIt=s(tFe);Ulr=r(SIt,"model.eval()"),SIt.forEach(t),Hlr=r(vOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aFe=n(vOe,"CODE",{});var RIt=s(aFe);Jlr=r(RIt,"model.train()"),RIt.forEach(t),vOe.forEach(t),Ylr=i(La),T(oT.$$.fragment,La),La.forEach(t),Sl.forEach(t),sKe=i(f),Dd=n(f,"H2",{class:!0});var Feo=s(Dd);rT=n(Feo,"A",{id:!0,class:!0,href:!0});var PIt=s(rT);nFe=n(PIt,"SPAN",{});var BIt=s(nFe);T(Bx.$$.fragment,BIt),BIt.forEach(t),PIt.forEach(t),Klr=i(Feo),sFe=n(Feo,"SPAN",{});var IIt=s(sFe);Zlr=r(IIt,"AutoModelForTokenClassification"),IIt.forEach(t),Feo.forEach(t),lKe=i(f),Oo=n(f,"DIV",{class:!0});var Rl=s(Oo);T(Ix.$$.fragment,Rl),eir=i(Rl),Gd=n(Rl,"P",{});var dle=s(Gd);oir=r(dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fH=n(dle,"A",{href:!0});var NIt=s(fH);rir=r(NIt,"from_pretrained()"),NIt.forEach(t),tir=r(dle," class method or the "),mH=n(dle,"A",{href:!0});var qIt=s(mH);air=r(qIt,"from_config()"),qIt.forEach(t),nir=r(dle,` class
method.`),dle.forEach(t),sir=i(Rl),Nx=n(Rl,"P",{});var Teo=s(Nx);lir=r(Teo,"This class cannot be instantiated directly using "),lFe=n(Teo,"CODE",{});var jIt=s(lFe);iir=r(jIt,"__init__()"),jIt.forEach(t),dir=r(Teo," (throws an error)."),Teo.forEach(t),cir=i(Rl),wt=n(Rl,"DIV",{class:!0});var Py=s(wt);T(qx.$$.fragment,Py),fir=i(Py),iFe=n(Py,"P",{});var DIt=s(iFe);mir=r(DIt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DIt.forEach(t),gir=i(Py),Od=n(Py,"P",{});var cle=s(Od);hir=r(cle,`Note:
Loading a model from its configuration file does `),dFe=n(cle,"STRONG",{});var GIt=s(dFe);uir=r(GIt,"not"),GIt.forEach(t),pir=r(cle,` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=n(cle,"A",{href:!0});var OIt=s(gH);_ir=r(OIt,"from_pretrained()"),OIt.forEach(t),vir=r(cle," to load the model weights."),cle.forEach(t),bir=i(Py),T(tT.$$.fragment,Py),Py.forEach(t),Fir=i(Rl),lo=n(Rl,"DIV",{class:!0});var ya=s(lo);T(jx.$$.fragment,ya),Tir=i(ya),cFe=n(ya,"P",{});var VIt=s(cFe);Mir=r(VIt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VIt.forEach(t),Eir=i(ya),an=n(ya,"P",{});var By=s(an);Cir=r(By,"The model class to instantiate is selected based on the "),fFe=n(By,"CODE",{});var XIt=s(fFe);wir=r(XIt,"model_type"),XIt.forEach(t),Air=r(By,` property of the config object (either
passed as an argument or loaded from `),mFe=n(By,"CODE",{});var zIt=s(mFe);Lir=r(zIt,"pretrained_model_name_or_path"),zIt.forEach(t),yir=r(By,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gFe=n(By,"CODE",{});var QIt=s(gFe);xir=r(QIt,"pretrained_model_name_or_path"),QIt.forEach(t),$ir=r(By,":"),By.forEach(t),kir=i(ya),H=n(ya,"UL",{});var K=s(H);aT=n(K,"LI",{});var bOe=s(aT);hFe=n(bOe,"STRONG",{});var WIt=s(hFe);Sir=r(WIt,"albert"),WIt.forEach(t),Rir=r(bOe," \u2014 "),hH=n(bOe,"A",{href:!0});var UIt=s(hH);Pir=r(UIt,"AlbertForTokenClassification"),UIt.forEach(t),Bir=r(bOe," (ALBERT model)"),bOe.forEach(t),Iir=i(K),nT=n(K,"LI",{});var FOe=s(nT);uFe=n(FOe,"STRONG",{});var HIt=s(uFe);Nir=r(HIt,"bert"),HIt.forEach(t),qir=r(FOe," \u2014 "),uH=n(FOe,"A",{href:!0});var JIt=s(uH);jir=r(JIt,"BertForTokenClassification"),JIt.forEach(t),Dir=r(FOe," (BERT model)"),FOe.forEach(t),Gir=i(K),sT=n(K,"LI",{});var TOe=s(sT);pFe=n(TOe,"STRONG",{});var YIt=s(pFe);Oir=r(YIt,"big_bird"),YIt.forEach(t),Vir=r(TOe," \u2014 "),pH=n(TOe,"A",{href:!0});var KIt=s(pH);Xir=r(KIt,"BigBirdForTokenClassification"),KIt.forEach(t),zir=r(TOe," (BigBird model)"),TOe.forEach(t),Qir=i(K),lT=n(K,"LI",{});var MOe=s(lT);_Fe=n(MOe,"STRONG",{});var ZIt=s(_Fe);Wir=r(ZIt,"bloom"),ZIt.forEach(t),Uir=r(MOe," \u2014 "),_H=n(MOe,"A",{href:!0});var eNt=s(_H);Hir=r(eNt,"BloomForTokenClassification"),eNt.forEach(t),Jir=r(MOe," (BLOOM model)"),MOe.forEach(t),Yir=i(K),iT=n(K,"LI",{});var EOe=s(iT);vFe=n(EOe,"STRONG",{});var oNt=s(vFe);Kir=r(oNt,"camembert"),oNt.forEach(t),Zir=r(EOe," \u2014 "),vH=n(EOe,"A",{href:!0});var rNt=s(vH);edr=r(rNt,"CamembertForTokenClassification"),rNt.forEach(t),odr=r(EOe," (CamemBERT model)"),EOe.forEach(t),rdr=i(K),dT=n(K,"LI",{});var COe=s(dT);bFe=n(COe,"STRONG",{});var tNt=s(bFe);tdr=r(tNt,"canine"),tNt.forEach(t),adr=r(COe," \u2014 "),bH=n(COe,"A",{href:!0});var aNt=s(bH);ndr=r(aNt,"CanineForTokenClassification"),aNt.forEach(t),sdr=r(COe," (CANINE model)"),COe.forEach(t),ldr=i(K),cT=n(K,"LI",{});var wOe=s(cT);FFe=n(wOe,"STRONG",{});var nNt=s(FFe);idr=r(nNt,"convbert"),nNt.forEach(t),ddr=r(wOe," \u2014 "),FH=n(wOe,"A",{href:!0});var sNt=s(FH);cdr=r(sNt,"ConvBertForTokenClassification"),sNt.forEach(t),fdr=r(wOe," (ConvBERT model)"),wOe.forEach(t),mdr=i(K),fT=n(K,"LI",{});var AOe=s(fT);TFe=n(AOe,"STRONG",{});var lNt=s(TFe);gdr=r(lNt,"data2vec-text"),lNt.forEach(t),hdr=r(AOe," \u2014 "),TH=n(AOe,"A",{href:!0});var iNt=s(TH);udr=r(iNt,"Data2VecTextForTokenClassification"),iNt.forEach(t),pdr=r(AOe," (Data2VecText model)"),AOe.forEach(t),_dr=i(K),mT=n(K,"LI",{});var LOe=s(mT);MFe=n(LOe,"STRONG",{});var dNt=s(MFe);vdr=r(dNt,"deberta"),dNt.forEach(t),bdr=r(LOe," \u2014 "),MH=n(LOe,"A",{href:!0});var cNt=s(MH);Fdr=r(cNt,"DebertaForTokenClassification"),cNt.forEach(t),Tdr=r(LOe," (DeBERTa model)"),LOe.forEach(t),Mdr=i(K),gT=n(K,"LI",{});var yOe=s(gT);EFe=n(yOe,"STRONG",{});var fNt=s(EFe);Edr=r(fNt,"deberta-v2"),fNt.forEach(t),Cdr=r(yOe," \u2014 "),EH=n(yOe,"A",{href:!0});var mNt=s(EH);wdr=r(mNt,"DebertaV2ForTokenClassification"),mNt.forEach(t),Adr=r(yOe," (DeBERTa-v2 model)"),yOe.forEach(t),Ldr=i(K),hT=n(K,"LI",{});var xOe=s(hT);CFe=n(xOe,"STRONG",{});var gNt=s(CFe);ydr=r(gNt,"distilbert"),gNt.forEach(t),xdr=r(xOe," \u2014 "),CH=n(xOe,"A",{href:!0});var hNt=s(CH);$dr=r(hNt,"DistilBertForTokenClassification"),hNt.forEach(t),kdr=r(xOe," (DistilBERT model)"),xOe.forEach(t),Sdr=i(K),uT=n(K,"LI",{});var $Oe=s(uT);wFe=n($Oe,"STRONG",{});var uNt=s(wFe);Rdr=r(uNt,"electra"),uNt.forEach(t),Pdr=r($Oe," \u2014 "),wH=n($Oe,"A",{href:!0});var pNt=s(wH);Bdr=r(pNt,"ElectraForTokenClassification"),pNt.forEach(t),Idr=r($Oe," (ELECTRA model)"),$Oe.forEach(t),Ndr=i(K),pT=n(K,"LI",{});var kOe=s(pT);AFe=n(kOe,"STRONG",{});var _Nt=s(AFe);qdr=r(_Nt,"ernie"),_Nt.forEach(t),jdr=r(kOe," \u2014 "),AH=n(kOe,"A",{href:!0});var vNt=s(AH);Ddr=r(vNt,"ErnieForTokenClassification"),vNt.forEach(t),Gdr=r(kOe," (ERNIE model)"),kOe.forEach(t),Odr=i(K),_T=n(K,"LI",{});var SOe=s(_T);LFe=n(SOe,"STRONG",{});var bNt=s(LFe);Vdr=r(bNt,"flaubert"),bNt.forEach(t),Xdr=r(SOe," \u2014 "),LH=n(SOe,"A",{href:!0});var FNt=s(LH);zdr=r(FNt,"FlaubertForTokenClassification"),FNt.forEach(t),Qdr=r(SOe," (FlauBERT model)"),SOe.forEach(t),Wdr=i(K),vT=n(K,"LI",{});var ROe=s(vT);yFe=n(ROe,"STRONG",{});var TNt=s(yFe);Udr=r(TNt,"fnet"),TNt.forEach(t),Hdr=r(ROe," \u2014 "),yH=n(ROe,"A",{href:!0});var MNt=s(yH);Jdr=r(MNt,"FNetForTokenClassification"),MNt.forEach(t),Ydr=r(ROe," (FNet model)"),ROe.forEach(t),Kdr=i(K),bT=n(K,"LI",{});var POe=s(bT);xFe=n(POe,"STRONG",{});var ENt=s(xFe);Zdr=r(ENt,"funnel"),ENt.forEach(t),ecr=r(POe," \u2014 "),xH=n(POe,"A",{href:!0});var CNt=s(xH);ocr=r(CNt,"FunnelForTokenClassification"),CNt.forEach(t),rcr=r(POe," (Funnel Transformer model)"),POe.forEach(t),tcr=i(K),FT=n(K,"LI",{});var BOe=s(FT);$Fe=n(BOe,"STRONG",{});var wNt=s($Fe);acr=r(wNt,"gpt2"),wNt.forEach(t),ncr=r(BOe," \u2014 "),$H=n(BOe,"A",{href:!0});var ANt=s($H);scr=r(ANt,"GPT2ForTokenClassification"),ANt.forEach(t),lcr=r(BOe," (OpenAI GPT-2 model)"),BOe.forEach(t),icr=i(K),TT=n(K,"LI",{});var IOe=s(TT);kFe=n(IOe,"STRONG",{});var LNt=s(kFe);dcr=r(LNt,"ibert"),LNt.forEach(t),ccr=r(IOe," \u2014 "),kH=n(IOe,"A",{href:!0});var yNt=s(kH);fcr=r(yNt,"IBertForTokenClassification"),yNt.forEach(t),mcr=r(IOe," (I-BERT model)"),IOe.forEach(t),gcr=i(K),MT=n(K,"LI",{});var NOe=s(MT);SFe=n(NOe,"STRONG",{});var xNt=s(SFe);hcr=r(xNt,"layoutlm"),xNt.forEach(t),ucr=r(NOe," \u2014 "),SH=n(NOe,"A",{href:!0});var $Nt=s(SH);pcr=r($Nt,"LayoutLMForTokenClassification"),$Nt.forEach(t),_cr=r(NOe," (LayoutLM model)"),NOe.forEach(t),vcr=i(K),ET=n(K,"LI",{});var qOe=s(ET);RFe=n(qOe,"STRONG",{});var kNt=s(RFe);bcr=r(kNt,"layoutlmv2"),kNt.forEach(t),Fcr=r(qOe," \u2014 "),RH=n(qOe,"A",{href:!0});var SNt=s(RH);Tcr=r(SNt,"LayoutLMv2ForTokenClassification"),SNt.forEach(t),Mcr=r(qOe," (LayoutLMv2 model)"),qOe.forEach(t),Ecr=i(K),CT=n(K,"LI",{});var jOe=s(CT);PFe=n(jOe,"STRONG",{});var RNt=s(PFe);Ccr=r(RNt,"layoutlmv3"),RNt.forEach(t),wcr=r(jOe," \u2014 "),PH=n(jOe,"A",{href:!0});var PNt=s(PH);Acr=r(PNt,"LayoutLMv3ForTokenClassification"),PNt.forEach(t),Lcr=r(jOe," (LayoutLMv3 model)"),jOe.forEach(t),ycr=i(K),wT=n(K,"LI",{});var DOe=s(wT);BFe=n(DOe,"STRONG",{});var BNt=s(BFe);xcr=r(BNt,"longformer"),BNt.forEach(t),$cr=r(DOe," \u2014 "),BH=n(DOe,"A",{href:!0});var INt=s(BH);kcr=r(INt,"LongformerForTokenClassification"),INt.forEach(t),Scr=r(DOe," (Longformer model)"),DOe.forEach(t),Rcr=i(K),AT=n(K,"LI",{});var GOe=s(AT);IFe=n(GOe,"STRONG",{});var NNt=s(IFe);Pcr=r(NNt,"luke"),NNt.forEach(t),Bcr=r(GOe," \u2014 "),IH=n(GOe,"A",{href:!0});var qNt=s(IH);Icr=r(qNt,"LukeForTokenClassification"),qNt.forEach(t),Ncr=r(GOe," (LUKE model)"),GOe.forEach(t),qcr=i(K),LT=n(K,"LI",{});var OOe=s(LT);NFe=n(OOe,"STRONG",{});var jNt=s(NFe);jcr=r(jNt,"megatron-bert"),jNt.forEach(t),Dcr=r(OOe," \u2014 "),NH=n(OOe,"A",{href:!0});var DNt=s(NH);Gcr=r(DNt,"MegatronBertForTokenClassification"),DNt.forEach(t),Ocr=r(OOe," (Megatron-BERT model)"),OOe.forEach(t),Vcr=i(K),yT=n(K,"LI",{});var VOe=s(yT);qFe=n(VOe,"STRONG",{});var GNt=s(qFe);Xcr=r(GNt,"mobilebert"),GNt.forEach(t),zcr=r(VOe," \u2014 "),qH=n(VOe,"A",{href:!0});var ONt=s(qH);Qcr=r(ONt,"MobileBertForTokenClassification"),ONt.forEach(t),Wcr=r(VOe," (MobileBERT model)"),VOe.forEach(t),Ucr=i(K),xT=n(K,"LI",{});var XOe=s(xT);jFe=n(XOe,"STRONG",{});var VNt=s(jFe);Hcr=r(VNt,"mpnet"),VNt.forEach(t),Jcr=r(XOe," \u2014 "),jH=n(XOe,"A",{href:!0});var XNt=s(jH);Ycr=r(XNt,"MPNetForTokenClassification"),XNt.forEach(t),Kcr=r(XOe," (MPNet model)"),XOe.forEach(t),Zcr=i(K),$T=n(K,"LI",{});var zOe=s($T);DFe=n(zOe,"STRONG",{});var zNt=s(DFe);efr=r(zNt,"nezha"),zNt.forEach(t),ofr=r(zOe," \u2014 "),DH=n(zOe,"A",{href:!0});var QNt=s(DH);rfr=r(QNt,"NezhaForTokenClassification"),QNt.forEach(t),tfr=r(zOe," (Nezha model)"),zOe.forEach(t),afr=i(K),kT=n(K,"LI",{});var QOe=s(kT);GFe=n(QOe,"STRONG",{});var WNt=s(GFe);nfr=r(WNt,"nystromformer"),WNt.forEach(t),sfr=r(QOe," \u2014 "),GH=n(QOe,"A",{href:!0});var UNt=s(GH);lfr=r(UNt,"NystromformerForTokenClassification"),UNt.forEach(t),ifr=r(QOe," (Nystr\xF6mformer model)"),QOe.forEach(t),dfr=i(K),ST=n(K,"LI",{});var WOe=s(ST);OFe=n(WOe,"STRONG",{});var HNt=s(OFe);cfr=r(HNt,"qdqbert"),HNt.forEach(t),ffr=r(WOe," \u2014 "),OH=n(WOe,"A",{href:!0});var JNt=s(OH);mfr=r(JNt,"QDQBertForTokenClassification"),JNt.forEach(t),gfr=r(WOe," (QDQBert model)"),WOe.forEach(t),hfr=i(K),RT=n(K,"LI",{});var UOe=s(RT);VFe=n(UOe,"STRONG",{});var YNt=s(VFe);ufr=r(YNt,"rembert"),YNt.forEach(t),pfr=r(UOe," \u2014 "),VH=n(UOe,"A",{href:!0});var KNt=s(VH);_fr=r(KNt,"RemBertForTokenClassification"),KNt.forEach(t),vfr=r(UOe," (RemBERT model)"),UOe.forEach(t),bfr=i(K),PT=n(K,"LI",{});var HOe=s(PT);XFe=n(HOe,"STRONG",{});var ZNt=s(XFe);Ffr=r(ZNt,"roberta"),ZNt.forEach(t),Tfr=r(HOe," \u2014 "),XH=n(HOe,"A",{href:!0});var eqt=s(XH);Mfr=r(eqt,"RobertaForTokenClassification"),eqt.forEach(t),Efr=r(HOe," (RoBERTa model)"),HOe.forEach(t),Cfr=i(K),BT=n(K,"LI",{});var JOe=s(BT);zFe=n(JOe,"STRONG",{});var oqt=s(zFe);wfr=r(oqt,"roformer"),oqt.forEach(t),Afr=r(JOe," \u2014 "),zH=n(JOe,"A",{href:!0});var rqt=s(zH);Lfr=r(rqt,"RoFormerForTokenClassification"),rqt.forEach(t),yfr=r(JOe," (RoFormer model)"),JOe.forEach(t),xfr=i(K),IT=n(K,"LI",{});var YOe=s(IT);QFe=n(YOe,"STRONG",{});var tqt=s(QFe);$fr=r(tqt,"squeezebert"),tqt.forEach(t),kfr=r(YOe," \u2014 "),QH=n(YOe,"A",{href:!0});var aqt=s(QH);Sfr=r(aqt,"SqueezeBertForTokenClassification"),aqt.forEach(t),Rfr=r(YOe," (SqueezeBERT model)"),YOe.forEach(t),Pfr=i(K),NT=n(K,"LI",{});var KOe=s(NT);WFe=n(KOe,"STRONG",{});var nqt=s(WFe);Bfr=r(nqt,"xlm"),nqt.forEach(t),Ifr=r(KOe," \u2014 "),WH=n(KOe,"A",{href:!0});var sqt=s(WH);Nfr=r(sqt,"XLMForTokenClassification"),sqt.forEach(t),qfr=r(KOe," (XLM model)"),KOe.forEach(t),jfr=i(K),qT=n(K,"LI",{});var ZOe=s(qT);UFe=n(ZOe,"STRONG",{});var lqt=s(UFe);Dfr=r(lqt,"xlm-roberta"),lqt.forEach(t),Gfr=r(ZOe," \u2014 "),UH=n(ZOe,"A",{href:!0});var iqt=s(UH);Ofr=r(iqt,"XLMRobertaForTokenClassification"),iqt.forEach(t),Vfr=r(ZOe," (XLM-RoBERTa model)"),ZOe.forEach(t),Xfr=i(K),jT=n(K,"LI",{});var eVe=s(jT);HFe=n(eVe,"STRONG",{});var dqt=s(HFe);zfr=r(dqt,"xlm-roberta-xl"),dqt.forEach(t),Qfr=r(eVe," \u2014 "),HH=n(eVe,"A",{href:!0});var cqt=s(HH);Wfr=r(cqt,"XLMRobertaXLForTokenClassification"),cqt.forEach(t),Ufr=r(eVe," (XLM-RoBERTa-XL model)"),eVe.forEach(t),Hfr=i(K),DT=n(K,"LI",{});var oVe=s(DT);JFe=n(oVe,"STRONG",{});var fqt=s(JFe);Jfr=r(fqt,"xlnet"),fqt.forEach(t),Yfr=r(oVe," \u2014 "),JH=n(oVe,"A",{href:!0});var mqt=s(JH);Kfr=r(mqt,"XLNetForTokenClassification"),mqt.forEach(t),Zfr=r(oVe," (XLNet model)"),oVe.forEach(t),emr=i(K),GT=n(K,"LI",{});var rVe=s(GT);YFe=n(rVe,"STRONG",{});var gqt=s(YFe);omr=r(gqt,"yoso"),gqt.forEach(t),rmr=r(rVe," \u2014 "),YH=n(rVe,"A",{href:!0});var hqt=s(YH);tmr=r(hqt,"YosoForTokenClassification"),hqt.forEach(t),amr=r(rVe," (YOSO model)"),rVe.forEach(t),K.forEach(t),nmr=i(ya),OT=n(ya,"P",{});var tVe=s(OT);smr=r(tVe,"The model is set in evaluation mode by default using "),KFe=n(tVe,"CODE",{});var uqt=s(KFe);lmr=r(uqt,"model.eval()"),uqt.forEach(t),imr=r(tVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZFe=n(tVe,"CODE",{});var pqt=s(ZFe);dmr=r(pqt,"model.train()"),pqt.forEach(t),tVe.forEach(t),cmr=i(ya),T(VT.$$.fragment,ya),ya.forEach(t),Rl.forEach(t),iKe=i(f),Vd=n(f,"H2",{class:!0});var Meo=s(Vd);XT=n(Meo,"A",{id:!0,class:!0,href:!0});var _qt=s(XT);eTe=n(_qt,"SPAN",{});var vqt=s(eTe);T(Dx.$$.fragment,vqt),vqt.forEach(t),_qt.forEach(t),fmr=i(Meo),oTe=n(Meo,"SPAN",{});var bqt=s(oTe);mmr=r(bqt,"AutoModelForQuestionAnswering"),bqt.forEach(t),Meo.forEach(t),dKe=i(f),Vo=n(f,"DIV",{class:!0});var Pl=s(Vo);T(Gx.$$.fragment,Pl),gmr=i(Pl),Xd=n(Pl,"P",{});var fle=s(Xd);hmr=r(fle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KH=n(fle,"A",{href:!0});var Fqt=s(KH);umr=r(Fqt,"from_pretrained()"),Fqt.forEach(t),pmr=r(fle," class method or the "),ZH=n(fle,"A",{href:!0});var Tqt=s(ZH);_mr=r(Tqt,"from_config()"),Tqt.forEach(t),vmr=r(fle,` class
method.`),fle.forEach(t),bmr=i(Pl),Ox=n(Pl,"P",{});var Eeo=s(Ox);Fmr=r(Eeo,"This class cannot be instantiated directly using "),rTe=n(Eeo,"CODE",{});var Mqt=s(rTe);Tmr=r(Mqt,"__init__()"),Mqt.forEach(t),Mmr=r(Eeo," (throws an error)."),Eeo.forEach(t),Emr=i(Pl),At=n(Pl,"DIV",{class:!0});var Iy=s(At);T(Vx.$$.fragment,Iy),Cmr=i(Iy),tTe=n(Iy,"P",{});var Eqt=s(tTe);wmr=r(Eqt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Eqt.forEach(t),Amr=i(Iy),zd=n(Iy,"P",{});var mle=s(zd);Lmr=r(mle,`Note:
Loading a model from its configuration file does `),aTe=n(mle,"STRONG",{});var Cqt=s(aTe);ymr=r(Cqt,"not"),Cqt.forEach(t),xmr=r(mle,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(mle,"A",{href:!0});var wqt=s(eJ);$mr=r(wqt,"from_pretrained()"),wqt.forEach(t),kmr=r(mle," to load the model weights."),mle.forEach(t),Smr=i(Iy),T(zT.$$.fragment,Iy),Iy.forEach(t),Rmr=i(Pl),io=n(Pl,"DIV",{class:!0});var xa=s(io);T(Xx.$$.fragment,xa),Pmr=i(xa),nTe=n(xa,"P",{});var Aqt=s(nTe);Bmr=r(Aqt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Aqt.forEach(t),Imr=i(xa),nn=n(xa,"P",{});var Ny=s(nn);Nmr=r(Ny,"The model class to instantiate is selected based on the "),sTe=n(Ny,"CODE",{});var Lqt=s(sTe);qmr=r(Lqt,"model_type"),Lqt.forEach(t),jmr=r(Ny,` property of the config object (either
passed as an argument or loaded from `),lTe=n(Ny,"CODE",{});var yqt=s(lTe);Dmr=r(yqt,"pretrained_model_name_or_path"),yqt.forEach(t),Gmr=r(Ny,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iTe=n(Ny,"CODE",{});var xqt=s(iTe);Omr=r(xqt,"pretrained_model_name_or_path"),xqt.forEach(t),Vmr=r(Ny,":"),Ny.forEach(t),Xmr=i(xa),V=n(xa,"UL",{});var X=s(V);QT=n(X,"LI",{});var aVe=s(QT);dTe=n(aVe,"STRONG",{});var $qt=s(dTe);zmr=r($qt,"albert"),$qt.forEach(t),Qmr=r(aVe," \u2014 "),oJ=n(aVe,"A",{href:!0});var kqt=s(oJ);Wmr=r(kqt,"AlbertForQuestionAnswering"),kqt.forEach(t),Umr=r(aVe," (ALBERT model)"),aVe.forEach(t),Hmr=i(X),WT=n(X,"LI",{});var nVe=s(WT);cTe=n(nVe,"STRONG",{});var Sqt=s(cTe);Jmr=r(Sqt,"bart"),Sqt.forEach(t),Ymr=r(nVe," \u2014 "),rJ=n(nVe,"A",{href:!0});var Rqt=s(rJ);Kmr=r(Rqt,"BartForQuestionAnswering"),Rqt.forEach(t),Zmr=r(nVe," (BART model)"),nVe.forEach(t),egr=i(X),UT=n(X,"LI",{});var sVe=s(UT);fTe=n(sVe,"STRONG",{});var Pqt=s(fTe);ogr=r(Pqt,"bert"),Pqt.forEach(t),rgr=r(sVe," \u2014 "),tJ=n(sVe,"A",{href:!0});var Bqt=s(tJ);tgr=r(Bqt,"BertForQuestionAnswering"),Bqt.forEach(t),agr=r(sVe," (BERT model)"),sVe.forEach(t),ngr=i(X),HT=n(X,"LI",{});var lVe=s(HT);mTe=n(lVe,"STRONG",{});var Iqt=s(mTe);sgr=r(Iqt,"big_bird"),Iqt.forEach(t),lgr=r(lVe," \u2014 "),aJ=n(lVe,"A",{href:!0});var Nqt=s(aJ);igr=r(Nqt,"BigBirdForQuestionAnswering"),Nqt.forEach(t),dgr=r(lVe," (BigBird model)"),lVe.forEach(t),cgr=i(X),JT=n(X,"LI",{});var iVe=s(JT);gTe=n(iVe,"STRONG",{});var qqt=s(gTe);fgr=r(qqt,"bigbird_pegasus"),qqt.forEach(t),mgr=r(iVe," \u2014 "),nJ=n(iVe,"A",{href:!0});var jqt=s(nJ);ggr=r(jqt,"BigBirdPegasusForQuestionAnswering"),jqt.forEach(t),hgr=r(iVe," (BigBird-Pegasus model)"),iVe.forEach(t),ugr=i(X),YT=n(X,"LI",{});var dVe=s(YT);hTe=n(dVe,"STRONG",{});var Dqt=s(hTe);pgr=r(Dqt,"camembert"),Dqt.forEach(t),_gr=r(dVe," \u2014 "),sJ=n(dVe,"A",{href:!0});var Gqt=s(sJ);vgr=r(Gqt,"CamembertForQuestionAnswering"),Gqt.forEach(t),bgr=r(dVe," (CamemBERT model)"),dVe.forEach(t),Fgr=i(X),KT=n(X,"LI",{});var cVe=s(KT);uTe=n(cVe,"STRONG",{});var Oqt=s(uTe);Tgr=r(Oqt,"canine"),Oqt.forEach(t),Mgr=r(cVe," \u2014 "),lJ=n(cVe,"A",{href:!0});var Vqt=s(lJ);Egr=r(Vqt,"CanineForQuestionAnswering"),Vqt.forEach(t),Cgr=r(cVe," (CANINE model)"),cVe.forEach(t),wgr=i(X),ZT=n(X,"LI",{});var fVe=s(ZT);pTe=n(fVe,"STRONG",{});var Xqt=s(pTe);Agr=r(Xqt,"convbert"),Xqt.forEach(t),Lgr=r(fVe," \u2014 "),iJ=n(fVe,"A",{href:!0});var zqt=s(iJ);ygr=r(zqt,"ConvBertForQuestionAnswering"),zqt.forEach(t),xgr=r(fVe," (ConvBERT model)"),fVe.forEach(t),$gr=i(X),eM=n(X,"LI",{});var mVe=s(eM);_Te=n(mVe,"STRONG",{});var Qqt=s(_Te);kgr=r(Qqt,"data2vec-text"),Qqt.forEach(t),Sgr=r(mVe," \u2014 "),dJ=n(mVe,"A",{href:!0});var Wqt=s(dJ);Rgr=r(Wqt,"Data2VecTextForQuestionAnswering"),Wqt.forEach(t),Pgr=r(mVe," (Data2VecText model)"),mVe.forEach(t),Bgr=i(X),oM=n(X,"LI",{});var gVe=s(oM);vTe=n(gVe,"STRONG",{});var Uqt=s(vTe);Igr=r(Uqt,"deberta"),Uqt.forEach(t),Ngr=r(gVe," \u2014 "),cJ=n(gVe,"A",{href:!0});var Hqt=s(cJ);qgr=r(Hqt,"DebertaForQuestionAnswering"),Hqt.forEach(t),jgr=r(gVe," (DeBERTa model)"),gVe.forEach(t),Dgr=i(X),rM=n(X,"LI",{});var hVe=s(rM);bTe=n(hVe,"STRONG",{});var Jqt=s(bTe);Ggr=r(Jqt,"deberta-v2"),Jqt.forEach(t),Ogr=r(hVe," \u2014 "),fJ=n(hVe,"A",{href:!0});var Yqt=s(fJ);Vgr=r(Yqt,"DebertaV2ForQuestionAnswering"),Yqt.forEach(t),Xgr=r(hVe," (DeBERTa-v2 model)"),hVe.forEach(t),zgr=i(X),tM=n(X,"LI",{});var uVe=s(tM);FTe=n(uVe,"STRONG",{});var Kqt=s(FTe);Qgr=r(Kqt,"distilbert"),Kqt.forEach(t),Wgr=r(uVe," \u2014 "),mJ=n(uVe,"A",{href:!0});var Zqt=s(mJ);Ugr=r(Zqt,"DistilBertForQuestionAnswering"),Zqt.forEach(t),Hgr=r(uVe," (DistilBERT model)"),uVe.forEach(t),Jgr=i(X),aM=n(X,"LI",{});var pVe=s(aM);TTe=n(pVe,"STRONG",{});var ejt=s(TTe);Ygr=r(ejt,"electra"),ejt.forEach(t),Kgr=r(pVe," \u2014 "),gJ=n(pVe,"A",{href:!0});var ojt=s(gJ);Zgr=r(ojt,"ElectraForQuestionAnswering"),ojt.forEach(t),ehr=r(pVe," (ELECTRA model)"),pVe.forEach(t),ohr=i(X),nM=n(X,"LI",{});var _Ve=s(nM);MTe=n(_Ve,"STRONG",{});var rjt=s(MTe);rhr=r(rjt,"ernie"),rjt.forEach(t),thr=r(_Ve," \u2014 "),hJ=n(_Ve,"A",{href:!0});var tjt=s(hJ);ahr=r(tjt,"ErnieForQuestionAnswering"),tjt.forEach(t),nhr=r(_Ve," (ERNIE model)"),_Ve.forEach(t),shr=i(X),sM=n(X,"LI",{});var vVe=s(sM);ETe=n(vVe,"STRONG",{});var ajt=s(ETe);lhr=r(ajt,"flaubert"),ajt.forEach(t),ihr=r(vVe," \u2014 "),uJ=n(vVe,"A",{href:!0});var njt=s(uJ);dhr=r(njt,"FlaubertForQuestionAnsweringSimple"),njt.forEach(t),chr=r(vVe," (FlauBERT model)"),vVe.forEach(t),fhr=i(X),lM=n(X,"LI",{});var bVe=s(lM);CTe=n(bVe,"STRONG",{});var sjt=s(CTe);mhr=r(sjt,"fnet"),sjt.forEach(t),ghr=r(bVe," \u2014 "),pJ=n(bVe,"A",{href:!0});var ljt=s(pJ);hhr=r(ljt,"FNetForQuestionAnswering"),ljt.forEach(t),uhr=r(bVe," (FNet model)"),bVe.forEach(t),phr=i(X),iM=n(X,"LI",{});var FVe=s(iM);wTe=n(FVe,"STRONG",{});var ijt=s(wTe);_hr=r(ijt,"funnel"),ijt.forEach(t),vhr=r(FVe," \u2014 "),_J=n(FVe,"A",{href:!0});var djt=s(_J);bhr=r(djt,"FunnelForQuestionAnswering"),djt.forEach(t),Fhr=r(FVe," (Funnel Transformer model)"),FVe.forEach(t),Thr=i(X),dM=n(X,"LI",{});var TVe=s(dM);ATe=n(TVe,"STRONG",{});var cjt=s(ATe);Mhr=r(cjt,"gptj"),cjt.forEach(t),Ehr=r(TVe," \u2014 "),vJ=n(TVe,"A",{href:!0});var fjt=s(vJ);Chr=r(fjt,"GPTJForQuestionAnswering"),fjt.forEach(t),whr=r(TVe," (GPT-J model)"),TVe.forEach(t),Ahr=i(X),cM=n(X,"LI",{});var MVe=s(cM);LTe=n(MVe,"STRONG",{});var mjt=s(LTe);Lhr=r(mjt,"ibert"),mjt.forEach(t),yhr=r(MVe," \u2014 "),bJ=n(MVe,"A",{href:!0});var gjt=s(bJ);xhr=r(gjt,"IBertForQuestionAnswering"),gjt.forEach(t),$hr=r(MVe," (I-BERT model)"),MVe.forEach(t),khr=i(X),fM=n(X,"LI",{});var EVe=s(fM);yTe=n(EVe,"STRONG",{});var hjt=s(yTe);Shr=r(hjt,"layoutlmv2"),hjt.forEach(t),Rhr=r(EVe," \u2014 "),FJ=n(EVe,"A",{href:!0});var ujt=s(FJ);Phr=r(ujt,"LayoutLMv2ForQuestionAnswering"),ujt.forEach(t),Bhr=r(EVe," (LayoutLMv2 model)"),EVe.forEach(t),Ihr=i(X),mM=n(X,"LI",{});var CVe=s(mM);xTe=n(CVe,"STRONG",{});var pjt=s(xTe);Nhr=r(pjt,"layoutlmv3"),pjt.forEach(t),qhr=r(CVe," \u2014 "),TJ=n(CVe,"A",{href:!0});var _jt=s(TJ);jhr=r(_jt,"LayoutLMv3ForQuestionAnswering"),_jt.forEach(t),Dhr=r(CVe," (LayoutLMv3 model)"),CVe.forEach(t),Ghr=i(X),gM=n(X,"LI",{});var wVe=s(gM);$Te=n(wVe,"STRONG",{});var vjt=s($Te);Ohr=r(vjt,"led"),vjt.forEach(t),Vhr=r(wVe," \u2014 "),MJ=n(wVe,"A",{href:!0});var bjt=s(MJ);Xhr=r(bjt,"LEDForQuestionAnswering"),bjt.forEach(t),zhr=r(wVe," (LED model)"),wVe.forEach(t),Qhr=i(X),hM=n(X,"LI",{});var AVe=s(hM);kTe=n(AVe,"STRONG",{});var Fjt=s(kTe);Whr=r(Fjt,"longformer"),Fjt.forEach(t),Uhr=r(AVe," \u2014 "),EJ=n(AVe,"A",{href:!0});var Tjt=s(EJ);Hhr=r(Tjt,"LongformerForQuestionAnswering"),Tjt.forEach(t),Jhr=r(AVe," (Longformer model)"),AVe.forEach(t),Yhr=i(X),uM=n(X,"LI",{});var LVe=s(uM);STe=n(LVe,"STRONG",{});var Mjt=s(STe);Khr=r(Mjt,"luke"),Mjt.forEach(t),Zhr=r(LVe," \u2014 "),CJ=n(LVe,"A",{href:!0});var Ejt=s(CJ);eur=r(Ejt,"LukeForQuestionAnswering"),Ejt.forEach(t),our=r(LVe," (LUKE model)"),LVe.forEach(t),rur=i(X),pM=n(X,"LI",{});var yVe=s(pM);RTe=n(yVe,"STRONG",{});var Cjt=s(RTe);tur=r(Cjt,"lxmert"),Cjt.forEach(t),aur=r(yVe," \u2014 "),wJ=n(yVe,"A",{href:!0});var wjt=s(wJ);nur=r(wjt,"LxmertForQuestionAnswering"),wjt.forEach(t),sur=r(yVe," (LXMERT model)"),yVe.forEach(t),lur=i(X),_M=n(X,"LI",{});var xVe=s(_M);PTe=n(xVe,"STRONG",{});var Ajt=s(PTe);iur=r(Ajt,"mbart"),Ajt.forEach(t),dur=r(xVe," \u2014 "),AJ=n(xVe,"A",{href:!0});var Ljt=s(AJ);cur=r(Ljt,"MBartForQuestionAnswering"),Ljt.forEach(t),fur=r(xVe," (mBART model)"),xVe.forEach(t),mur=i(X),vM=n(X,"LI",{});var $Ve=s(vM);BTe=n($Ve,"STRONG",{});var yjt=s(BTe);gur=r(yjt,"megatron-bert"),yjt.forEach(t),hur=r($Ve," \u2014 "),LJ=n($Ve,"A",{href:!0});var xjt=s(LJ);uur=r(xjt,"MegatronBertForQuestionAnswering"),xjt.forEach(t),pur=r($Ve," (Megatron-BERT model)"),$Ve.forEach(t),_ur=i(X),bM=n(X,"LI",{});var kVe=s(bM);ITe=n(kVe,"STRONG",{});var $jt=s(ITe);vur=r($jt,"mobilebert"),$jt.forEach(t),bur=r(kVe," \u2014 "),yJ=n(kVe,"A",{href:!0});var kjt=s(yJ);Fur=r(kjt,"MobileBertForQuestionAnswering"),kjt.forEach(t),Tur=r(kVe," (MobileBERT model)"),kVe.forEach(t),Mur=i(X),FM=n(X,"LI",{});var SVe=s(FM);NTe=n(SVe,"STRONG",{});var Sjt=s(NTe);Eur=r(Sjt,"mpnet"),Sjt.forEach(t),Cur=r(SVe," \u2014 "),xJ=n(SVe,"A",{href:!0});var Rjt=s(xJ);wur=r(Rjt,"MPNetForQuestionAnswering"),Rjt.forEach(t),Aur=r(SVe," (MPNet model)"),SVe.forEach(t),Lur=i(X),TM=n(X,"LI",{});var RVe=s(TM);qTe=n(RVe,"STRONG",{});var Pjt=s(qTe);yur=r(Pjt,"mvp"),Pjt.forEach(t),xur=r(RVe," \u2014 "),$J=n(RVe,"A",{href:!0});var Bjt=s($J);$ur=r(Bjt,"MvpForQuestionAnswering"),Bjt.forEach(t),kur=r(RVe," (MVP model)"),RVe.forEach(t),Sur=i(X),MM=n(X,"LI",{});var PVe=s(MM);jTe=n(PVe,"STRONG",{});var Ijt=s(jTe);Rur=r(Ijt,"nezha"),Ijt.forEach(t),Pur=r(PVe," \u2014 "),kJ=n(PVe,"A",{href:!0});var Njt=s(kJ);Bur=r(Njt,"NezhaForQuestionAnswering"),Njt.forEach(t),Iur=r(PVe," (Nezha model)"),PVe.forEach(t),Nur=i(X),EM=n(X,"LI",{});var BVe=s(EM);DTe=n(BVe,"STRONG",{});var qjt=s(DTe);qur=r(qjt,"nystromformer"),qjt.forEach(t),jur=r(BVe," \u2014 "),SJ=n(BVe,"A",{href:!0});var jjt=s(SJ);Dur=r(jjt,"NystromformerForQuestionAnswering"),jjt.forEach(t),Gur=r(BVe," (Nystr\xF6mformer model)"),BVe.forEach(t),Our=i(X),CM=n(X,"LI",{});var IVe=s(CM);GTe=n(IVe,"STRONG",{});var Djt=s(GTe);Vur=r(Djt,"qdqbert"),Djt.forEach(t),Xur=r(IVe," \u2014 "),RJ=n(IVe,"A",{href:!0});var Gjt=s(RJ);zur=r(Gjt,"QDQBertForQuestionAnswering"),Gjt.forEach(t),Qur=r(IVe," (QDQBert model)"),IVe.forEach(t),Wur=i(X),wM=n(X,"LI",{});var NVe=s(wM);OTe=n(NVe,"STRONG",{});var Ojt=s(OTe);Uur=r(Ojt,"reformer"),Ojt.forEach(t),Hur=r(NVe," \u2014 "),PJ=n(NVe,"A",{href:!0});var Vjt=s(PJ);Jur=r(Vjt,"ReformerForQuestionAnswering"),Vjt.forEach(t),Yur=r(NVe," (Reformer model)"),NVe.forEach(t),Kur=i(X),AM=n(X,"LI",{});var qVe=s(AM);VTe=n(qVe,"STRONG",{});var Xjt=s(VTe);Zur=r(Xjt,"rembert"),Xjt.forEach(t),epr=r(qVe," \u2014 "),BJ=n(qVe,"A",{href:!0});var zjt=s(BJ);opr=r(zjt,"RemBertForQuestionAnswering"),zjt.forEach(t),rpr=r(qVe," (RemBERT model)"),qVe.forEach(t),tpr=i(X),LM=n(X,"LI",{});var jVe=s(LM);XTe=n(jVe,"STRONG",{});var Qjt=s(XTe);apr=r(Qjt,"roberta"),Qjt.forEach(t),npr=r(jVe," \u2014 "),IJ=n(jVe,"A",{href:!0});var Wjt=s(IJ);spr=r(Wjt,"RobertaForQuestionAnswering"),Wjt.forEach(t),lpr=r(jVe," (RoBERTa model)"),jVe.forEach(t),ipr=i(X),yM=n(X,"LI",{});var DVe=s(yM);zTe=n(DVe,"STRONG",{});var Ujt=s(zTe);dpr=r(Ujt,"roformer"),Ujt.forEach(t),cpr=r(DVe," \u2014 "),NJ=n(DVe,"A",{href:!0});var Hjt=s(NJ);fpr=r(Hjt,"RoFormerForQuestionAnswering"),Hjt.forEach(t),mpr=r(DVe," (RoFormer model)"),DVe.forEach(t),gpr=i(X),xM=n(X,"LI",{});var GVe=s(xM);QTe=n(GVe,"STRONG",{});var Jjt=s(QTe);hpr=r(Jjt,"splinter"),Jjt.forEach(t),upr=r(GVe," \u2014 "),qJ=n(GVe,"A",{href:!0});var Yjt=s(qJ);ppr=r(Yjt,"SplinterForQuestionAnswering"),Yjt.forEach(t),_pr=r(GVe," (Splinter model)"),GVe.forEach(t),vpr=i(X),$M=n(X,"LI",{});var OVe=s($M);WTe=n(OVe,"STRONG",{});var Kjt=s(WTe);bpr=r(Kjt,"squeezebert"),Kjt.forEach(t),Fpr=r(OVe," \u2014 "),jJ=n(OVe,"A",{href:!0});var Zjt=s(jJ);Tpr=r(Zjt,"SqueezeBertForQuestionAnswering"),Zjt.forEach(t),Mpr=r(OVe," (SqueezeBERT model)"),OVe.forEach(t),Epr=i(X),kM=n(X,"LI",{});var VVe=s(kM);UTe=n(VVe,"STRONG",{});var eDt=s(UTe);Cpr=r(eDt,"xlm"),eDt.forEach(t),wpr=r(VVe," \u2014 "),DJ=n(VVe,"A",{href:!0});var oDt=s(DJ);Apr=r(oDt,"XLMForQuestionAnsweringSimple"),oDt.forEach(t),Lpr=r(VVe," (XLM model)"),VVe.forEach(t),ypr=i(X),SM=n(X,"LI",{});var XVe=s(SM);HTe=n(XVe,"STRONG",{});var rDt=s(HTe);xpr=r(rDt,"xlm-roberta"),rDt.forEach(t),$pr=r(XVe," \u2014 "),GJ=n(XVe,"A",{href:!0});var tDt=s(GJ);kpr=r(tDt,"XLMRobertaForQuestionAnswering"),tDt.forEach(t),Spr=r(XVe," (XLM-RoBERTa model)"),XVe.forEach(t),Rpr=i(X),RM=n(X,"LI",{});var zVe=s(RM);JTe=n(zVe,"STRONG",{});var aDt=s(JTe);Ppr=r(aDt,"xlm-roberta-xl"),aDt.forEach(t),Bpr=r(zVe," \u2014 "),OJ=n(zVe,"A",{href:!0});var nDt=s(OJ);Ipr=r(nDt,"XLMRobertaXLForQuestionAnswering"),nDt.forEach(t),Npr=r(zVe," (XLM-RoBERTa-XL model)"),zVe.forEach(t),qpr=i(X),PM=n(X,"LI",{});var QVe=s(PM);YTe=n(QVe,"STRONG",{});var sDt=s(YTe);jpr=r(sDt,"xlnet"),sDt.forEach(t),Dpr=r(QVe," \u2014 "),VJ=n(QVe,"A",{href:!0});var lDt=s(VJ);Gpr=r(lDt,"XLNetForQuestionAnsweringSimple"),lDt.forEach(t),Opr=r(QVe," (XLNet model)"),QVe.forEach(t),Vpr=i(X),BM=n(X,"LI",{});var WVe=s(BM);KTe=n(WVe,"STRONG",{});var iDt=s(KTe);Xpr=r(iDt,"yoso"),iDt.forEach(t),zpr=r(WVe," \u2014 "),XJ=n(WVe,"A",{href:!0});var dDt=s(XJ);Qpr=r(dDt,"YosoForQuestionAnswering"),dDt.forEach(t),Wpr=r(WVe," (YOSO model)"),WVe.forEach(t),X.forEach(t),Upr=i(xa),IM=n(xa,"P",{});var UVe=s(IM);Hpr=r(UVe,"The model is set in evaluation mode by default using "),ZTe=n(UVe,"CODE",{});var cDt=s(ZTe);Jpr=r(cDt,"model.eval()"),cDt.forEach(t),Ypr=r(UVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eMe=n(UVe,"CODE",{});var fDt=s(eMe);Kpr=r(fDt,"model.train()"),fDt.forEach(t),UVe.forEach(t),Zpr=i(xa),T(NM.$$.fragment,xa),xa.forEach(t),Pl.forEach(t),cKe=i(f),Qd=n(f,"H2",{class:!0});var Ceo=s(Qd);qM=n(Ceo,"A",{id:!0,class:!0,href:!0});var mDt=s(qM);oMe=n(mDt,"SPAN",{});var gDt=s(oMe);T(zx.$$.fragment,gDt),gDt.forEach(t),mDt.forEach(t),e_r=i(Ceo),rMe=n(Ceo,"SPAN",{});var hDt=s(rMe);o_r=r(hDt,"AutoModelForTableQuestionAnswering"),hDt.forEach(t),Ceo.forEach(t),fKe=i(f),Xo=n(f,"DIV",{class:!0});var Bl=s(Xo);T(Qx.$$.fragment,Bl),r_r=i(Bl),Wd=n(Bl,"P",{});var gle=s(Wd);t_r=r(gle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zJ=n(gle,"A",{href:!0});var uDt=s(zJ);a_r=r(uDt,"from_pretrained()"),uDt.forEach(t),n_r=r(gle," class method or the "),QJ=n(gle,"A",{href:!0});var pDt=s(QJ);s_r=r(pDt,"from_config()"),pDt.forEach(t),l_r=r(gle,` class
method.`),gle.forEach(t),i_r=i(Bl),Wx=n(Bl,"P",{});var weo=s(Wx);d_r=r(weo,"This class cannot be instantiated directly using "),tMe=n(weo,"CODE",{});var _Dt=s(tMe);c_r=r(_Dt,"__init__()"),_Dt.forEach(t),f_r=r(weo," (throws an error)."),weo.forEach(t),m_r=i(Bl),Lt=n(Bl,"DIV",{class:!0});var qy=s(Lt);T(Ux.$$.fragment,qy),g_r=i(qy),aMe=n(qy,"P",{});var vDt=s(aMe);h_r=r(vDt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),vDt.forEach(t),u_r=i(qy),Ud=n(qy,"P",{});var hle=s(Ud);p_r=r(hle,`Note:
Loading a model from its configuration file does `),nMe=n(hle,"STRONG",{});var bDt=s(nMe);__r=r(bDt,"not"),bDt.forEach(t),v_r=r(hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=n(hle,"A",{href:!0});var FDt=s(WJ);b_r=r(FDt,"from_pretrained()"),FDt.forEach(t),F_r=r(hle," to load the model weights."),hle.forEach(t),T_r=i(qy),T(jM.$$.fragment,qy),qy.forEach(t),M_r=i(Bl),co=n(Bl,"DIV",{class:!0});var $a=s(co);T(Hx.$$.fragment,$a),E_r=i($a),sMe=n($a,"P",{});var TDt=s(sMe);C_r=r(TDt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),TDt.forEach(t),w_r=i($a),sn=n($a,"P",{});var jy=s(sn);A_r=r(jy,"The model class to instantiate is selected based on the "),lMe=n(jy,"CODE",{});var MDt=s(lMe);L_r=r(MDt,"model_type"),MDt.forEach(t),y_r=r(jy,` property of the config object (either
passed as an argument or loaded from `),iMe=n(jy,"CODE",{});var EDt=s(iMe);x_r=r(EDt,"pretrained_model_name_or_path"),EDt.forEach(t),$_r=r(jy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=n(jy,"CODE",{});var CDt=s(dMe);k_r=r(CDt,"pretrained_model_name_or_path"),CDt.forEach(t),S_r=r(jy,":"),jy.forEach(t),R_r=i($a),cMe=n($a,"UL",{});var wDt=s(cMe);DM=n(wDt,"LI",{});var HVe=s(DM);fMe=n(HVe,"STRONG",{});var ADt=s(fMe);P_r=r(ADt,"tapas"),ADt.forEach(t),B_r=r(HVe," \u2014 "),UJ=n(HVe,"A",{href:!0});var LDt=s(UJ);I_r=r(LDt,"TapasForQuestionAnswering"),LDt.forEach(t),N_r=r(HVe," (TAPAS model)"),HVe.forEach(t),wDt.forEach(t),q_r=i($a),GM=n($a,"P",{});var JVe=s(GM);j_r=r(JVe,"The model is set in evaluation mode by default using "),mMe=n(JVe,"CODE",{});var yDt=s(mMe);D_r=r(yDt,"model.eval()"),yDt.forEach(t),G_r=r(JVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gMe=n(JVe,"CODE",{});var xDt=s(gMe);O_r=r(xDt,"model.train()"),xDt.forEach(t),JVe.forEach(t),V_r=i($a),T(OM.$$.fragment,$a),$a.forEach(t),Bl.forEach(t),mKe=i(f),Hd=n(f,"H2",{class:!0});var Aeo=s(Hd);VM=n(Aeo,"A",{id:!0,class:!0,href:!0});var $Dt=s(VM);hMe=n($Dt,"SPAN",{});var kDt=s(hMe);T(Jx.$$.fragment,kDt),kDt.forEach(t),$Dt.forEach(t),X_r=i(Aeo),uMe=n(Aeo,"SPAN",{});var SDt=s(uMe);z_r=r(SDt,"AutoModelForDocumentQuestionAnswering"),SDt.forEach(t),Aeo.forEach(t),gKe=i(f),zo=n(f,"DIV",{class:!0});var Il=s(zo);T(Yx.$$.fragment,Il),Q_r=i(Il),Jd=n(Il,"P",{});var ule=s(Jd);W_r=r(ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),HJ=n(ule,"A",{href:!0});var RDt=s(HJ);U_r=r(RDt,"from_pretrained()"),RDt.forEach(t),H_r=r(ule," class method or the "),JJ=n(ule,"A",{href:!0});var PDt=s(JJ);J_r=r(PDt,"from_config()"),PDt.forEach(t),Y_r=r(ule,` class
method.`),ule.forEach(t),K_r=i(Il),Kx=n(Il,"P",{});var Leo=s(Kx);Z_r=r(Leo,"This class cannot be instantiated directly using "),pMe=n(Leo,"CODE",{});var BDt=s(pMe);e2r=r(BDt,"__init__()"),BDt.forEach(t),o2r=r(Leo," (throws an error)."),Leo.forEach(t),r2r=i(Il),yt=n(Il,"DIV",{class:!0});var Dy=s(yt);T(Zx.$$.fragment,Dy),t2r=i(Dy),_Me=n(Dy,"P",{});var IDt=s(_Me);a2r=r(IDt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),IDt.forEach(t),n2r=i(Dy),Yd=n(Dy,"P",{});var ple=s(Yd);s2r=r(ple,`Note:
Loading a model from its configuration file does `),vMe=n(ple,"STRONG",{});var NDt=s(vMe);l2r=r(NDt,"not"),NDt.forEach(t),i2r=r(ple,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(ple,"A",{href:!0});var qDt=s(YJ);d2r=r(qDt,"from_pretrained()"),qDt.forEach(t),c2r=r(ple," to load the model weights."),ple.forEach(t),f2r=i(Dy),T(XM.$$.fragment,Dy),Dy.forEach(t),m2r=i(Il),fo=n(Il,"DIV",{class:!0});var ka=s(fo);T(e$.$$.fragment,ka),g2r=i(ka),bMe=n(ka,"P",{});var jDt=s(bMe);h2r=r(jDt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),jDt.forEach(t),u2r=i(ka),ln=n(ka,"P",{});var Gy=s(ln);p2r=r(Gy,"The model class to instantiate is selected based on the "),FMe=n(Gy,"CODE",{});var DDt=s(FMe);_2r=r(DDt,"model_type"),DDt.forEach(t),v2r=r(Gy,` property of the config object (either
passed as an argument or loaded from `),TMe=n(Gy,"CODE",{});var GDt=s(TMe);b2r=r(GDt,"pretrained_model_name_or_path"),GDt.forEach(t),F2r=r(Gy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MMe=n(Gy,"CODE",{});var ODt=s(MMe);T2r=r(ODt,"pretrained_model_name_or_path"),ODt.forEach(t),M2r=r(Gy,":"),Gy.forEach(t),E2r=i(ka),Kd=n(ka,"UL",{});var _le=s(Kd);zM=n(_le,"LI",{});var YVe=s(zM);EMe=n(YVe,"STRONG",{});var VDt=s(EMe);C2r=r(VDt,"layoutlm"),VDt.forEach(t),w2r=r(YVe," \u2014 "),KJ=n(YVe,"A",{href:!0});var XDt=s(KJ);A2r=r(XDt,"LayoutLMForQuestionAnswering"),XDt.forEach(t),L2r=r(YVe," (LayoutLM model)"),YVe.forEach(t),y2r=i(_le),QM=n(_le,"LI",{});var KVe=s(QM);CMe=n(KVe,"STRONG",{});var zDt=s(CMe);x2r=r(zDt,"layoutlmv2"),zDt.forEach(t),$2r=r(KVe," \u2014 "),ZJ=n(KVe,"A",{href:!0});var QDt=s(ZJ);k2r=r(QDt,"LayoutLMv2ForQuestionAnswering"),QDt.forEach(t),S2r=r(KVe," (LayoutLMv2 model)"),KVe.forEach(t),R2r=i(_le),WM=n(_le,"LI",{});var ZVe=s(WM);wMe=n(ZVe,"STRONG",{});var WDt=s(wMe);P2r=r(WDt,"layoutlmv3"),WDt.forEach(t),B2r=r(ZVe," \u2014 "),eY=n(ZVe,"A",{href:!0});var UDt=s(eY);I2r=r(UDt,"LayoutLMv3ForQuestionAnswering"),UDt.forEach(t),N2r=r(ZVe," (LayoutLMv3 model)"),ZVe.forEach(t),_le.forEach(t),q2r=i(ka),UM=n(ka,"P",{});var eXe=s(UM);j2r=r(eXe,"The model is set in evaluation mode by default using "),AMe=n(eXe,"CODE",{});var HDt=s(AMe);D2r=r(HDt,"model.eval()"),HDt.forEach(t),G2r=r(eXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LMe=n(eXe,"CODE",{});var JDt=s(LMe);O2r=r(JDt,"model.train()"),JDt.forEach(t),eXe.forEach(t),V2r=i(ka),T(HM.$$.fragment,ka),ka.forEach(t),Il.forEach(t),hKe=i(f),Zd=n(f,"H2",{class:!0});var yeo=s(Zd);JM=n(yeo,"A",{id:!0,class:!0,href:!0});var YDt=s(JM);yMe=n(YDt,"SPAN",{});var KDt=s(yMe);T(o$.$$.fragment,KDt),KDt.forEach(t),YDt.forEach(t),X2r=i(yeo),xMe=n(yeo,"SPAN",{});var ZDt=s(xMe);z2r=r(ZDt,"AutoModelForImageClassification"),ZDt.forEach(t),yeo.forEach(t),uKe=i(f),Qo=n(f,"DIV",{class:!0});var Nl=s(Qo);T(r$.$$.fragment,Nl),Q2r=i(Nl),ec=n(Nl,"P",{});var vle=s(ec);W2r=r(vle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),oY=n(vle,"A",{href:!0});var eGt=s(oY);U2r=r(eGt,"from_pretrained()"),eGt.forEach(t),H2r=r(vle," class method or the "),rY=n(vle,"A",{href:!0});var oGt=s(rY);J2r=r(oGt,"from_config()"),oGt.forEach(t),Y2r=r(vle,` class
method.`),vle.forEach(t),K2r=i(Nl),t$=n(Nl,"P",{});var xeo=s(t$);Z2r=r(xeo,"This class cannot be instantiated directly using "),$Me=n(xeo,"CODE",{});var rGt=s($Me);evr=r(rGt,"__init__()"),rGt.forEach(t),ovr=r(xeo," (throws an error)."),xeo.forEach(t),rvr=i(Nl),xt=n(Nl,"DIV",{class:!0});var Oy=s(xt);T(a$.$$.fragment,Oy),tvr=i(Oy),kMe=n(Oy,"P",{});var tGt=s(kMe);avr=r(tGt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),tGt.forEach(t),nvr=i(Oy),oc=n(Oy,"P",{});var ble=s(oc);svr=r(ble,`Note:
Loading a model from its configuration file does `),SMe=n(ble,"STRONG",{});var aGt=s(SMe);lvr=r(aGt,"not"),aGt.forEach(t),ivr=r(ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),tY=n(ble,"A",{href:!0});var nGt=s(tY);dvr=r(nGt,"from_pretrained()"),nGt.forEach(t),cvr=r(ble," to load the model weights."),ble.forEach(t),fvr=i(Oy),T(YM.$$.fragment,Oy),Oy.forEach(t),mvr=i(Nl),mo=n(Nl,"DIV",{class:!0});var Sa=s(mo);T(n$.$$.fragment,Sa),gvr=i(Sa),RMe=n(Sa,"P",{});var sGt=s(RMe);hvr=r(sGt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),sGt.forEach(t),uvr=i(Sa),dn=n(Sa,"P",{});var Vy=s(dn);pvr=r(Vy,"The model class to instantiate is selected based on the "),PMe=n(Vy,"CODE",{});var lGt=s(PMe);_vr=r(lGt,"model_type"),lGt.forEach(t),vvr=r(Vy,` property of the config object (either
passed as an argument or loaded from `),BMe=n(Vy,"CODE",{});var iGt=s(BMe);bvr=r(iGt,"pretrained_model_name_or_path"),iGt.forEach(t),Fvr=r(Vy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IMe=n(Vy,"CODE",{});var dGt=s(IMe);Tvr=r(dGt,"pretrained_model_name_or_path"),dGt.forEach(t),Mvr=r(Vy,":"),Vy.forEach(t),Evr=i(Sa),ve=n(Sa,"UL",{});var Fe=s(ve);KM=n(Fe,"LI",{});var oXe=s(KM);NMe=n(oXe,"STRONG",{});var cGt=s(NMe);Cvr=r(cGt,"beit"),cGt.forEach(t),wvr=r(oXe," \u2014 "),aY=n(oXe,"A",{href:!0});var fGt=s(aY);Avr=r(fGt,"BeitForImageClassification"),fGt.forEach(t),Lvr=r(oXe," (BEiT model)"),oXe.forEach(t),yvr=i(Fe),ZM=n(Fe,"LI",{});var rXe=s(ZM);qMe=n(rXe,"STRONG",{});var mGt=s(qMe);xvr=r(mGt,"convnext"),mGt.forEach(t),$vr=r(rXe," \u2014 "),nY=n(rXe,"A",{href:!0});var gGt=s(nY);kvr=r(gGt,"ConvNextForImageClassification"),gGt.forEach(t),Svr=r(rXe," (ConvNeXT model)"),rXe.forEach(t),Rvr=i(Fe),eE=n(Fe,"LI",{});var tXe=s(eE);jMe=n(tXe,"STRONG",{});var hGt=s(jMe);Pvr=r(hGt,"cvt"),hGt.forEach(t),Bvr=r(tXe," \u2014 "),sY=n(tXe,"A",{href:!0});var uGt=s(sY);Ivr=r(uGt,"CvtForImageClassification"),uGt.forEach(t),Nvr=r(tXe," (CvT model)"),tXe.forEach(t),qvr=i(Fe),oE=n(Fe,"LI",{});var aXe=s(oE);DMe=n(aXe,"STRONG",{});var pGt=s(DMe);jvr=r(pGt,"data2vec-vision"),pGt.forEach(t),Dvr=r(aXe," \u2014 "),lY=n(aXe,"A",{href:!0});var _Gt=s(lY);Gvr=r(_Gt,"Data2VecVisionForImageClassification"),_Gt.forEach(t),Ovr=r(aXe," (Data2VecVision model)"),aXe.forEach(t),Vvr=i(Fe),_l=n(Fe,"LI",{});var FB=s(_l);GMe=n(FB,"STRONG",{});var vGt=s(GMe);Xvr=r(vGt,"deit"),vGt.forEach(t),zvr=r(FB," \u2014 "),iY=n(FB,"A",{href:!0});var bGt=s(iY);Qvr=r(bGt,"DeiTForImageClassification"),bGt.forEach(t),Wvr=r(FB," or "),dY=n(FB,"A",{href:!0});var FGt=s(dY);Uvr=r(FGt,"DeiTForImageClassificationWithTeacher"),FGt.forEach(t),Hvr=r(FB," (DeiT model)"),FB.forEach(t),Jvr=i(Fe),rE=n(Fe,"LI",{});var nXe=s(rE);OMe=n(nXe,"STRONG",{});var TGt=s(OMe);Yvr=r(TGt,"imagegpt"),TGt.forEach(t),Kvr=r(nXe," \u2014 "),cY=n(nXe,"A",{href:!0});var MGt=s(cY);Zvr=r(MGt,"ImageGPTForImageClassification"),MGt.forEach(t),e1r=r(nXe," (ImageGPT model)"),nXe.forEach(t),o1r=i(Fe),vl=n(Fe,"LI",{});var TB=s(vl);VMe=n(TB,"STRONG",{});var EGt=s(VMe);r1r=r(EGt,"levit"),EGt.forEach(t),t1r=r(TB," \u2014 "),fY=n(TB,"A",{href:!0});var CGt=s(fY);a1r=r(CGt,"LevitForImageClassification"),CGt.forEach(t),n1r=r(TB," or "),mY=n(TB,"A",{href:!0});var wGt=s(mY);s1r=r(wGt,"LevitForImageClassificationWithTeacher"),wGt.forEach(t),l1r=r(TB," (LeViT model)"),TB.forEach(t),i1r=i(Fe),tE=n(Fe,"LI",{});var sXe=s(tE);XMe=n(sXe,"STRONG",{});var AGt=s(XMe);d1r=r(AGt,"mobilevit"),AGt.forEach(t),c1r=r(sXe," \u2014 "),gY=n(sXe,"A",{href:!0});var LGt=s(gY);f1r=r(LGt,"MobileViTForImageClassification"),LGt.forEach(t),m1r=r(sXe," (MobileViT model)"),sXe.forEach(t),g1r=i(Fe),$t=n(Fe,"LI",{});var Tm=s($t);zMe=n(Tm,"STRONG",{});var yGt=s(zMe);h1r=r(yGt,"perceiver"),yGt.forEach(t),u1r=r(Tm," \u2014 "),hY=n(Tm,"A",{href:!0});var xGt=s(hY);p1r=r(xGt,"PerceiverForImageClassificationLearned"),xGt.forEach(t),_1r=r(Tm," or "),uY=n(Tm,"A",{href:!0});var $Gt=s(uY);v1r=r($Gt,"PerceiverForImageClassificationFourier"),$Gt.forEach(t),b1r=r(Tm," or "),pY=n(Tm,"A",{href:!0});var kGt=s(pY);F1r=r(kGt,"PerceiverForImageClassificationConvProcessing"),kGt.forEach(t),T1r=r(Tm," (Perceiver model)"),Tm.forEach(t),M1r=i(Fe),aE=n(Fe,"LI",{});var lXe=s(aE);QMe=n(lXe,"STRONG",{});var SGt=s(QMe);E1r=r(SGt,"poolformer"),SGt.forEach(t),C1r=r(lXe," \u2014 "),_Y=n(lXe,"A",{href:!0});var RGt=s(_Y);w1r=r(RGt,"PoolFormerForImageClassification"),RGt.forEach(t),A1r=r(lXe," (PoolFormer model)"),lXe.forEach(t),L1r=i(Fe),nE=n(Fe,"LI",{});var iXe=s(nE);WMe=n(iXe,"STRONG",{});var PGt=s(WMe);y1r=r(PGt,"regnet"),PGt.forEach(t),x1r=r(iXe," \u2014 "),vY=n(iXe,"A",{href:!0});var BGt=s(vY);$1r=r(BGt,"RegNetForImageClassification"),BGt.forEach(t),k1r=r(iXe," (RegNet model)"),iXe.forEach(t),S1r=i(Fe),sE=n(Fe,"LI",{});var dXe=s(sE);UMe=n(dXe,"STRONG",{});var IGt=s(UMe);R1r=r(IGt,"resnet"),IGt.forEach(t),P1r=r(dXe," \u2014 "),bY=n(dXe,"A",{href:!0});var NGt=s(bY);B1r=r(NGt,"ResNetForImageClassification"),NGt.forEach(t),I1r=r(dXe," (ResNet model)"),dXe.forEach(t),N1r=i(Fe),lE=n(Fe,"LI",{});var cXe=s(lE);HMe=n(cXe,"STRONG",{});var qGt=s(HMe);q1r=r(qGt,"segformer"),qGt.forEach(t),j1r=r(cXe," \u2014 "),FY=n(cXe,"A",{href:!0});var jGt=s(FY);D1r=r(jGt,"SegformerForImageClassification"),jGt.forEach(t),G1r=r(cXe," (SegFormer model)"),cXe.forEach(t),O1r=i(Fe),iE=n(Fe,"LI",{});var fXe=s(iE);JMe=n(fXe,"STRONG",{});var DGt=s(JMe);V1r=r(DGt,"swin"),DGt.forEach(t),X1r=r(fXe," \u2014 "),TY=n(fXe,"A",{href:!0});var GGt=s(TY);z1r=r(GGt,"SwinForImageClassification"),GGt.forEach(t),Q1r=r(fXe," (Swin Transformer model)"),fXe.forEach(t),W1r=i(Fe),dE=n(Fe,"LI",{});var mXe=s(dE);YMe=n(mXe,"STRONG",{});var OGt=s(YMe);U1r=r(OGt,"swinv2"),OGt.forEach(t),H1r=r(mXe," \u2014 "),MY=n(mXe,"A",{href:!0});var VGt=s(MY);J1r=r(VGt,"Swinv2ForImageClassification"),VGt.forEach(t),Y1r=r(mXe," (Swin Transformer V2 model)"),mXe.forEach(t),K1r=i(Fe),cE=n(Fe,"LI",{});var gXe=s(cE);KMe=n(gXe,"STRONG",{});var XGt=s(KMe);Z1r=r(XGt,"van"),XGt.forEach(t),e4r=r(gXe," \u2014 "),EY=n(gXe,"A",{href:!0});var zGt=s(EY);o4r=r(zGt,"VanForImageClassification"),zGt.forEach(t),r4r=r(gXe," (VAN model)"),gXe.forEach(t),t4r=i(Fe),fE=n(Fe,"LI",{});var hXe=s(fE);ZMe=n(hXe,"STRONG",{});var QGt=s(ZMe);a4r=r(QGt,"vit"),QGt.forEach(t),n4r=r(hXe," \u2014 "),CY=n(hXe,"A",{href:!0});var WGt=s(CY);s4r=r(WGt,"ViTForImageClassification"),WGt.forEach(t),l4r=r(hXe," (ViT model)"),hXe.forEach(t),Fe.forEach(t),i4r=i(Sa),mE=n(Sa,"P",{});var uXe=s(mE);d4r=r(uXe,"The model is set in evaluation mode by default using "),eEe=n(uXe,"CODE",{});var UGt=s(eEe);c4r=r(UGt,"model.eval()"),UGt.forEach(t),f4r=r(uXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),oEe=n(uXe,"CODE",{});var HGt=s(oEe);m4r=r(HGt,"model.train()"),HGt.forEach(t),uXe.forEach(t),g4r=i(Sa),T(gE.$$.fragment,Sa),Sa.forEach(t),Nl.forEach(t),pKe=i(f),rc=n(f,"H2",{class:!0});var $eo=s(rc);hE=n($eo,"A",{id:!0,class:!0,href:!0});var JGt=s(hE);rEe=n(JGt,"SPAN",{});var YGt=s(rEe);T(s$.$$.fragment,YGt),YGt.forEach(t),JGt.forEach(t),h4r=i($eo),tEe=n($eo,"SPAN",{});var KGt=s(tEe);u4r=r(KGt,"AutoModelForVideoClassification"),KGt.forEach(t),$eo.forEach(t),_Ke=i(f),Wo=n(f,"DIV",{class:!0});var ql=s(Wo);T(l$.$$.fragment,ql),p4r=i(ql),tc=n(ql,"P",{});var Fle=s(tc);_4r=r(Fle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),wY=n(Fle,"A",{href:!0});var ZGt=s(wY);v4r=r(ZGt,"from_pretrained()"),ZGt.forEach(t),b4r=r(Fle," class method or the "),AY=n(Fle,"A",{href:!0});var eOt=s(AY);F4r=r(eOt,"from_config()"),eOt.forEach(t),T4r=r(Fle,` class
method.`),Fle.forEach(t),M4r=i(ql),i$=n(ql,"P",{});var keo=s(i$);E4r=r(keo,"This class cannot be instantiated directly using "),aEe=n(keo,"CODE",{});var oOt=s(aEe);C4r=r(oOt,"__init__()"),oOt.forEach(t),w4r=r(keo," (throws an error)."),keo.forEach(t),A4r=i(ql),kt=n(ql,"DIV",{class:!0});var Xy=s(kt);T(d$.$$.fragment,Xy),L4r=i(Xy),nEe=n(Xy,"P",{});var rOt=s(nEe);y4r=r(rOt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),rOt.forEach(t),x4r=i(Xy),ac=n(Xy,"P",{});var Tle=s(ac);$4r=r(Tle,`Note:
Loading a model from its configuration file does `),sEe=n(Tle,"STRONG",{});var tOt=s(sEe);k4r=r(tOt,"not"),tOt.forEach(t),S4r=r(Tle,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(Tle,"A",{href:!0});var aOt=s(LY);R4r=r(aOt,"from_pretrained()"),aOt.forEach(t),P4r=r(Tle," to load the model weights."),Tle.forEach(t),B4r=i(Xy),T(uE.$$.fragment,Xy),Xy.forEach(t),I4r=i(ql),go=n(ql,"DIV",{class:!0});var Ra=s(go);T(c$.$$.fragment,Ra),N4r=i(Ra),lEe=n(Ra,"P",{});var nOt=s(lEe);q4r=r(nOt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),nOt.forEach(t),j4r=i(Ra),cn=n(Ra,"P",{});var zy=s(cn);D4r=r(zy,"The model class to instantiate is selected based on the "),iEe=n(zy,"CODE",{});var sOt=s(iEe);G4r=r(sOt,"model_type"),sOt.forEach(t),O4r=r(zy,` property of the config object (either
passed as an argument or loaded from `),dEe=n(zy,"CODE",{});var lOt=s(dEe);V4r=r(lOt,"pretrained_model_name_or_path"),lOt.forEach(t),X4r=r(zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cEe=n(zy,"CODE",{});var iOt=s(cEe);z4r=r(iOt,"pretrained_model_name_or_path"),iOt.forEach(t),Q4r=r(zy,":"),zy.forEach(t),W4r=i(Ra),fEe=n(Ra,"UL",{});var dOt=s(fEe);pE=n(dOt,"LI",{});var pXe=s(pE);mEe=n(pXe,"STRONG",{});var cOt=s(mEe);U4r=r(cOt,"videomae"),cOt.forEach(t),H4r=r(pXe," \u2014 "),yY=n(pXe,"A",{href:!0});var fOt=s(yY);J4r=r(fOt,"VideoMAEForVideoClassification"),fOt.forEach(t),Y4r=r(pXe," (VideoMAE model)"),pXe.forEach(t),dOt.forEach(t),K4r=i(Ra),_E=n(Ra,"P",{});var _Xe=s(_E);Z4r=r(_Xe,"The model is set in evaluation mode by default using "),gEe=n(_Xe,"CODE",{});var mOt=s(gEe);ebr=r(mOt,"model.eval()"),mOt.forEach(t),obr=r(_Xe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hEe=n(_Xe,"CODE",{});var gOt=s(hEe);rbr=r(gOt,"model.train()"),gOt.forEach(t),_Xe.forEach(t),tbr=i(Ra),T(vE.$$.fragment,Ra),Ra.forEach(t),ql.forEach(t),vKe=i(f),nc=n(f,"H2",{class:!0});var Seo=s(nc);bE=n(Seo,"A",{id:!0,class:!0,href:!0});var hOt=s(bE);uEe=n(hOt,"SPAN",{});var uOt=s(uEe);T(f$.$$.fragment,uOt),uOt.forEach(t),hOt.forEach(t),abr=i(Seo),pEe=n(Seo,"SPAN",{});var pOt=s(pEe);nbr=r(pOt,"AutoModelForVision2Seq"),pOt.forEach(t),Seo.forEach(t),bKe=i(f),Uo=n(f,"DIV",{class:!0});var jl=s(Uo);T(m$.$$.fragment,jl),sbr=i(jl),sc=n(jl,"P",{});var Mle=s(sc);lbr=r(Mle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xY=n(Mle,"A",{href:!0});var _Ot=s(xY);ibr=r(_Ot,"from_pretrained()"),_Ot.forEach(t),dbr=r(Mle," class method or the "),$Y=n(Mle,"A",{href:!0});var vOt=s($Y);cbr=r(vOt,"from_config()"),vOt.forEach(t),fbr=r(Mle,` class
method.`),Mle.forEach(t),mbr=i(jl),g$=n(jl,"P",{});var Reo=s(g$);gbr=r(Reo,"This class cannot be instantiated directly using "),_Ee=n(Reo,"CODE",{});var bOt=s(_Ee);hbr=r(bOt,"__init__()"),bOt.forEach(t),ubr=r(Reo," (throws an error)."),Reo.forEach(t),pbr=i(jl),St=n(jl,"DIV",{class:!0});var Qy=s(St);T(h$.$$.fragment,Qy),_br=i(Qy),vEe=n(Qy,"P",{});var FOt=s(vEe);vbr=r(FOt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),FOt.forEach(t),bbr=i(Qy),lc=n(Qy,"P",{});var Ele=s(lc);Fbr=r(Ele,`Note:
Loading a model from its configuration file does `),bEe=n(Ele,"STRONG",{});var TOt=s(bEe);Tbr=r(TOt,"not"),TOt.forEach(t),Mbr=r(Ele,` load the model weights. It only affects the
model\u2019s configuration. Use `),kY=n(Ele,"A",{href:!0});var MOt=s(kY);Ebr=r(MOt,"from_pretrained()"),MOt.forEach(t),Cbr=r(Ele," to load the model weights."),Ele.forEach(t),wbr=i(Qy),T(FE.$$.fragment,Qy),Qy.forEach(t),Abr=i(jl),ho=n(jl,"DIV",{class:!0});var Pa=s(ho);T(u$.$$.fragment,Pa),Lbr=i(Pa),FEe=n(Pa,"P",{});var EOt=s(FEe);ybr=r(EOt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),EOt.forEach(t),xbr=i(Pa),fn=n(Pa,"P",{});var Wy=s(fn);$br=r(Wy,"The model class to instantiate is selected based on the "),TEe=n(Wy,"CODE",{});var COt=s(TEe);kbr=r(COt,"model_type"),COt.forEach(t),Sbr=r(Wy,` property of the config object (either
passed as an argument or loaded from `),MEe=n(Wy,"CODE",{});var wOt=s(MEe);Rbr=r(wOt,"pretrained_model_name_or_path"),wOt.forEach(t),Pbr=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EEe=n(Wy,"CODE",{});var AOt=s(EEe);Bbr=r(AOt,"pretrained_model_name_or_path"),AOt.forEach(t),Ibr=r(Wy,":"),Wy.forEach(t),Nbr=i(Pa),CEe=n(Pa,"UL",{});var LOt=s(CEe);TE=n(LOt,"LI",{});var vXe=s(TE);wEe=n(vXe,"STRONG",{});var yOt=s(wEe);qbr=r(yOt,"vision-encoder-decoder"),yOt.forEach(t),jbr=r(vXe," \u2014 "),SY=n(vXe,"A",{href:!0});var xOt=s(SY);Dbr=r(xOt,"VisionEncoderDecoderModel"),xOt.forEach(t),Gbr=r(vXe," (Vision Encoder decoder model)"),vXe.forEach(t),LOt.forEach(t),Obr=i(Pa),ME=n(Pa,"P",{});var bXe=s(ME);Vbr=r(bXe,"The model is set in evaluation mode by default using "),AEe=n(bXe,"CODE",{});var $Ot=s(AEe);Xbr=r($Ot,"model.eval()"),$Ot.forEach(t),zbr=r(bXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=n(bXe,"CODE",{});var kOt=s(LEe);Qbr=r(kOt,"model.train()"),kOt.forEach(t),bXe.forEach(t),Wbr=i(Pa),T(EE.$$.fragment,Pa),Pa.forEach(t),jl.forEach(t),FKe=i(f),ic=n(f,"H2",{class:!0});var Peo=s(ic);CE=n(Peo,"A",{id:!0,class:!0,href:!0});var SOt=s(CE);yEe=n(SOt,"SPAN",{});var ROt=s(yEe);T(p$.$$.fragment,ROt),ROt.forEach(t),SOt.forEach(t),Ubr=i(Peo),xEe=n(Peo,"SPAN",{});var POt=s(xEe);Hbr=r(POt,"AutoModelForVisualQuestionAnswering"),POt.forEach(t),Peo.forEach(t),TKe=i(f),Ho=n(f,"DIV",{class:!0});var Dl=s(Ho);T(_$.$$.fragment,Dl),Jbr=i(Dl),dc=n(Dl,"P",{});var Cle=s(dc);Ybr=r(Cle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),RY=n(Cle,"A",{href:!0});var BOt=s(RY);Kbr=r(BOt,"from_pretrained()"),BOt.forEach(t),Zbr=r(Cle," class method or the "),PY=n(Cle,"A",{href:!0});var IOt=s(PY);eFr=r(IOt,"from_config()"),IOt.forEach(t),oFr=r(Cle,` class
method.`),Cle.forEach(t),rFr=i(Dl),v$=n(Dl,"P",{});var Beo=s(v$);tFr=r(Beo,"This class cannot be instantiated directly using "),$Ee=n(Beo,"CODE",{});var NOt=s($Ee);aFr=r(NOt,"__init__()"),NOt.forEach(t),nFr=r(Beo," (throws an error)."),Beo.forEach(t),sFr=i(Dl),Rt=n(Dl,"DIV",{class:!0});var Uy=s(Rt);T(b$.$$.fragment,Uy),lFr=i(Uy),kEe=n(Uy,"P",{});var qOt=s(kEe);iFr=r(qOt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),qOt.forEach(t),dFr=i(Uy),cc=n(Uy,"P",{});var wle=s(cc);cFr=r(wle,`Note:
Loading a model from its configuration file does `),SEe=n(wle,"STRONG",{});var jOt=s(SEe);fFr=r(jOt,"not"),jOt.forEach(t),mFr=r(wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=n(wle,"A",{href:!0});var DOt=s(BY);gFr=r(DOt,"from_pretrained()"),DOt.forEach(t),hFr=r(wle," to load the model weights."),wle.forEach(t),uFr=i(Uy),T(wE.$$.fragment,Uy),Uy.forEach(t),pFr=i(Dl),uo=n(Dl,"DIV",{class:!0});var Ba=s(uo);T(F$.$$.fragment,Ba),_Fr=i(Ba),REe=n(Ba,"P",{});var GOt=s(REe);vFr=r(GOt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),GOt.forEach(t),bFr=i(Ba),mn=n(Ba,"P",{});var Hy=s(mn);FFr=r(Hy,"The model class to instantiate is selected based on the "),PEe=n(Hy,"CODE",{});var OOt=s(PEe);TFr=r(OOt,"model_type"),OOt.forEach(t),MFr=r(Hy,` property of the config object (either
passed as an argument or loaded from `),BEe=n(Hy,"CODE",{});var VOt=s(BEe);EFr=r(VOt,"pretrained_model_name_or_path"),VOt.forEach(t),CFr=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=n(Hy,"CODE",{});var XOt=s(IEe);wFr=r(XOt,"pretrained_model_name_or_path"),XOt.forEach(t),AFr=r(Hy,":"),Hy.forEach(t),LFr=i(Ba),NEe=n(Ba,"UL",{});var zOt=s(NEe);AE=n(zOt,"LI",{});var FXe=s(AE);qEe=n(FXe,"STRONG",{});var QOt=s(qEe);yFr=r(QOt,"vilt"),QOt.forEach(t),xFr=r(FXe," \u2014 "),IY=n(FXe,"A",{href:!0});var WOt=s(IY);$Fr=r(WOt,"ViltForQuestionAnswering"),WOt.forEach(t),kFr=r(FXe," (ViLT model)"),FXe.forEach(t),zOt.forEach(t),SFr=i(Ba),LE=n(Ba,"P",{});var TXe=s(LE);RFr=r(TXe,"The model is set in evaluation mode by default using "),jEe=n(TXe,"CODE",{});var UOt=s(jEe);PFr=r(UOt,"model.eval()"),UOt.forEach(t),BFr=r(TXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DEe=n(TXe,"CODE",{});var HOt=s(DEe);IFr=r(HOt,"model.train()"),HOt.forEach(t),TXe.forEach(t),NFr=i(Ba),T(yE.$$.fragment,Ba),Ba.forEach(t),Dl.forEach(t),MKe=i(f),fc=n(f,"H2",{class:!0});var Ieo=s(fc);xE=n(Ieo,"A",{id:!0,class:!0,href:!0});var JOt=s(xE);GEe=n(JOt,"SPAN",{});var YOt=s(GEe);T(T$.$$.fragment,YOt),YOt.forEach(t),JOt.forEach(t),qFr=i(Ieo),OEe=n(Ieo,"SPAN",{});var KOt=s(OEe);jFr=r(KOt,"AutoModelForAudioClassification"),KOt.forEach(t),Ieo.forEach(t),EKe=i(f),Jo=n(f,"DIV",{class:!0});var Gl=s(Jo);T(M$.$$.fragment,Gl),DFr=i(Gl),mc=n(Gl,"P",{});var Ale=s(mc);GFr=r(Ale,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),NY=n(Ale,"A",{href:!0});var ZOt=s(NY);OFr=r(ZOt,"from_pretrained()"),ZOt.forEach(t),VFr=r(Ale," class method or the "),qY=n(Ale,"A",{href:!0});var eVt=s(qY);XFr=r(eVt,"from_config()"),eVt.forEach(t),zFr=r(Ale,` class
method.`),Ale.forEach(t),QFr=i(Gl),E$=n(Gl,"P",{});var Neo=s(E$);WFr=r(Neo,"This class cannot be instantiated directly using "),VEe=n(Neo,"CODE",{});var oVt=s(VEe);UFr=r(oVt,"__init__()"),oVt.forEach(t),HFr=r(Neo," (throws an error)."),Neo.forEach(t),JFr=i(Gl),Pt=n(Gl,"DIV",{class:!0});var Jy=s(Pt);T(C$.$$.fragment,Jy),YFr=i(Jy),XEe=n(Jy,"P",{});var rVt=s(XEe);KFr=r(rVt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),rVt.forEach(t),ZFr=i(Jy),gc=n(Jy,"P",{});var Lle=s(gc);eTr=r(Lle,`Note:
Loading a model from its configuration file does `),zEe=n(Lle,"STRONG",{});var tVt=s(zEe);oTr=r(tVt,"not"),tVt.forEach(t),rTr=r(Lle,` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=n(Lle,"A",{href:!0});var aVt=s(jY);tTr=r(aVt,"from_pretrained()"),aVt.forEach(t),aTr=r(Lle," to load the model weights."),Lle.forEach(t),nTr=i(Jy),T($E.$$.fragment,Jy),Jy.forEach(t),sTr=i(Gl),po=n(Gl,"DIV",{class:!0});var Ia=s(po);T(w$.$$.fragment,Ia),lTr=i(Ia),QEe=n(Ia,"P",{});var nVt=s(QEe);iTr=r(nVt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),nVt.forEach(t),dTr=i(Ia),gn=n(Ia,"P",{});var Yy=s(gn);cTr=r(Yy,"The model class to instantiate is selected based on the "),WEe=n(Yy,"CODE",{});var sVt=s(WEe);fTr=r(sVt,"model_type"),sVt.forEach(t),mTr=r(Yy,` property of the config object (either
passed as an argument or loaded from `),UEe=n(Yy,"CODE",{});var lVt=s(UEe);gTr=r(lVt,"pretrained_model_name_or_path"),lVt.forEach(t),hTr=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HEe=n(Yy,"CODE",{});var iVt=s(HEe);uTr=r(iVt,"pretrained_model_name_or_path"),iVt.forEach(t),pTr=r(Yy,":"),Yy.forEach(t),_Tr=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);kE=n(Qe,"LI",{});var MXe=s(kE);JEe=n(MXe,"STRONG",{});var dVt=s(JEe);vTr=r(dVt,"data2vec-audio"),dVt.forEach(t),bTr=r(MXe," \u2014 "),DY=n(MXe,"A",{href:!0});var cVt=s(DY);FTr=r(cVt,"Data2VecAudioForSequenceClassification"),cVt.forEach(t),TTr=r(MXe," (Data2VecAudio model)"),MXe.forEach(t),MTr=i(Qe),SE=n(Qe,"LI",{});var EXe=s(SE);YEe=n(EXe,"STRONG",{});var fVt=s(YEe);ETr=r(fVt,"hubert"),fVt.forEach(t),CTr=r(EXe," \u2014 "),GY=n(EXe,"A",{href:!0});var mVt=s(GY);wTr=r(mVt,"HubertForSequenceClassification"),mVt.forEach(t),ATr=r(EXe," (Hubert model)"),EXe.forEach(t),LTr=i(Qe),RE=n(Qe,"LI",{});var CXe=s(RE);KEe=n(CXe,"STRONG",{});var gVt=s(KEe);yTr=r(gVt,"sew"),gVt.forEach(t),xTr=r(CXe," \u2014 "),OY=n(CXe,"A",{href:!0});var hVt=s(OY);$Tr=r(hVt,"SEWForSequenceClassification"),hVt.forEach(t),kTr=r(CXe," (SEW model)"),CXe.forEach(t),STr=i(Qe),PE=n(Qe,"LI",{});var wXe=s(PE);ZEe=n(wXe,"STRONG",{});var uVt=s(ZEe);RTr=r(uVt,"sew-d"),uVt.forEach(t),PTr=r(wXe," \u2014 "),VY=n(wXe,"A",{href:!0});var pVt=s(VY);BTr=r(pVt,"SEWDForSequenceClassification"),pVt.forEach(t),ITr=r(wXe," (SEW-D model)"),wXe.forEach(t),NTr=i(Qe),BE=n(Qe,"LI",{});var AXe=s(BE);eCe=n(AXe,"STRONG",{});var _Vt=s(eCe);qTr=r(_Vt,"unispeech"),_Vt.forEach(t),jTr=r(AXe," \u2014 "),XY=n(AXe,"A",{href:!0});var vVt=s(XY);DTr=r(vVt,"UniSpeechForSequenceClassification"),vVt.forEach(t),GTr=r(AXe," (UniSpeech model)"),AXe.forEach(t),OTr=i(Qe),IE=n(Qe,"LI",{});var LXe=s(IE);oCe=n(LXe,"STRONG",{});var bVt=s(oCe);VTr=r(bVt,"unispeech-sat"),bVt.forEach(t),XTr=r(LXe," \u2014 "),zY=n(LXe,"A",{href:!0});var FVt=s(zY);zTr=r(FVt,"UniSpeechSatForSequenceClassification"),FVt.forEach(t),QTr=r(LXe," (UniSpeechSat model)"),LXe.forEach(t),WTr=i(Qe),NE=n(Qe,"LI",{});var yXe=s(NE);rCe=n(yXe,"STRONG",{});var TVt=s(rCe);UTr=r(TVt,"wav2vec2"),TVt.forEach(t),HTr=r(yXe," \u2014 "),QY=n(yXe,"A",{href:!0});var MVt=s(QY);JTr=r(MVt,"Wav2Vec2ForSequenceClassification"),MVt.forEach(t),YTr=r(yXe," (Wav2Vec2 model)"),yXe.forEach(t),KTr=i(Qe),qE=n(Qe,"LI",{});var xXe=s(qE);tCe=n(xXe,"STRONG",{});var EVt=s(tCe);ZTr=r(EVt,"wav2vec2-conformer"),EVt.forEach(t),eMr=r(xXe," \u2014 "),WY=n(xXe,"A",{href:!0});var CVt=s(WY);oMr=r(CVt,"Wav2Vec2ConformerForSequenceClassification"),CVt.forEach(t),rMr=r(xXe," (Wav2Vec2-Conformer model)"),xXe.forEach(t),tMr=i(Qe),jE=n(Qe,"LI",{});var $Xe=s(jE);aCe=n($Xe,"STRONG",{});var wVt=s(aCe);aMr=r(wVt,"wavlm"),wVt.forEach(t),nMr=r($Xe," \u2014 "),UY=n($Xe,"A",{href:!0});var AVt=s(UY);sMr=r(AVt,"WavLMForSequenceClassification"),AVt.forEach(t),lMr=r($Xe," (WavLM model)"),$Xe.forEach(t),Qe.forEach(t),iMr=i(Ia),DE=n(Ia,"P",{});var kXe=s(DE);dMr=r(kXe,"The model is set in evaluation mode by default using "),nCe=n(kXe,"CODE",{});var LVt=s(nCe);cMr=r(LVt,"model.eval()"),LVt.forEach(t),fMr=r(kXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sCe=n(kXe,"CODE",{});var yVt=s(sCe);mMr=r(yVt,"model.train()"),yVt.forEach(t),kXe.forEach(t),gMr=i(Ia),T(GE.$$.fragment,Ia),Ia.forEach(t),Gl.forEach(t),CKe=i(f),hc=n(f,"H2",{class:!0});var qeo=s(hc);OE=n(qeo,"A",{id:!0,class:!0,href:!0});var xVt=s(OE);lCe=n(xVt,"SPAN",{});var $Vt=s(lCe);T(A$.$$.fragment,$Vt),$Vt.forEach(t),xVt.forEach(t),hMr=i(qeo),iCe=n(qeo,"SPAN",{});var kVt=s(iCe);uMr=r(kVt,"AutoModelForAudioFrameClassification"),kVt.forEach(t),qeo.forEach(t),wKe=i(f),Yo=n(f,"DIV",{class:!0});var Ol=s(Yo);T(L$.$$.fragment,Ol),pMr=i(Ol),uc=n(Ol,"P",{});var yle=s(uc);_Mr=r(yle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),HY=n(yle,"A",{href:!0});var SVt=s(HY);vMr=r(SVt,"from_pretrained()"),SVt.forEach(t),bMr=r(yle," class method or the "),JY=n(yle,"A",{href:!0});var RVt=s(JY);FMr=r(RVt,"from_config()"),RVt.forEach(t),TMr=r(yle,` class
method.`),yle.forEach(t),MMr=i(Ol),y$=n(Ol,"P",{});var jeo=s(y$);EMr=r(jeo,"This class cannot be instantiated directly using "),dCe=n(jeo,"CODE",{});var PVt=s(dCe);CMr=r(PVt,"__init__()"),PVt.forEach(t),wMr=r(jeo," (throws an error)."),jeo.forEach(t),AMr=i(Ol),Bt=n(Ol,"DIV",{class:!0});var Ky=s(Bt);T(x$.$$.fragment,Ky),LMr=i(Ky),cCe=n(Ky,"P",{});var BVt=s(cCe);yMr=r(BVt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),BVt.forEach(t),xMr=i(Ky),pc=n(Ky,"P",{});var xle=s(pc);$Mr=r(xle,`Note:
Loading a model from its configuration file does `),fCe=n(xle,"STRONG",{});var IVt=s(fCe);kMr=r(IVt,"not"),IVt.forEach(t),SMr=r(xle,` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=n(xle,"A",{href:!0});var NVt=s(YY);RMr=r(NVt,"from_pretrained()"),NVt.forEach(t),PMr=r(xle," to load the model weights."),xle.forEach(t),BMr=i(Ky),T(VE.$$.fragment,Ky),Ky.forEach(t),IMr=i(Ol),_o=n(Ol,"DIV",{class:!0});var Na=s(_o);T($$.$$.fragment,Na),NMr=i(Na),mCe=n(Na,"P",{});var qVt=s(mCe);qMr=r(qVt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),qVt.forEach(t),jMr=i(Na),hn=n(Na,"P",{});var Zy=s(hn);DMr=r(Zy,"The model class to instantiate is selected based on the "),gCe=n(Zy,"CODE",{});var jVt=s(gCe);GMr=r(jVt,"model_type"),jVt.forEach(t),OMr=r(Zy,` property of the config object (either
passed as an argument or loaded from `),hCe=n(Zy,"CODE",{});var DVt=s(hCe);VMr=r(DVt,"pretrained_model_name_or_path"),DVt.forEach(t),XMr=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=n(Zy,"CODE",{});var GVt=s(uCe);zMr=r(GVt,"pretrained_model_name_or_path"),GVt.forEach(t),QMr=r(Zy,":"),Zy.forEach(t),WMr=i(Na),ft=n(Na,"UL",{});var Vl=s(ft);XE=n(Vl,"LI",{});var SXe=s(XE);pCe=n(SXe,"STRONG",{});var OVt=s(pCe);UMr=r(OVt,"data2vec-audio"),OVt.forEach(t),HMr=r(SXe," \u2014 "),KY=n(SXe,"A",{href:!0});var VVt=s(KY);JMr=r(VVt,"Data2VecAudioForAudioFrameClassification"),VVt.forEach(t),YMr=r(SXe," (Data2VecAudio model)"),SXe.forEach(t),KMr=i(Vl),zE=n(Vl,"LI",{});var RXe=s(zE);_Ce=n(RXe,"STRONG",{});var XVt=s(_Ce);ZMr=r(XVt,"unispeech-sat"),XVt.forEach(t),eEr=r(RXe," \u2014 "),ZY=n(RXe,"A",{href:!0});var zVt=s(ZY);oEr=r(zVt,"UniSpeechSatForAudioFrameClassification"),zVt.forEach(t),rEr=r(RXe," (UniSpeechSat model)"),RXe.forEach(t),tEr=i(Vl),QE=n(Vl,"LI",{});var PXe=s(QE);vCe=n(PXe,"STRONG",{});var QVt=s(vCe);aEr=r(QVt,"wav2vec2"),QVt.forEach(t),nEr=r(PXe," \u2014 "),eK=n(PXe,"A",{href:!0});var WVt=s(eK);sEr=r(WVt,"Wav2Vec2ForAudioFrameClassification"),WVt.forEach(t),lEr=r(PXe," (Wav2Vec2 model)"),PXe.forEach(t),iEr=i(Vl),WE=n(Vl,"LI",{});var BXe=s(WE);bCe=n(BXe,"STRONG",{});var UVt=s(bCe);dEr=r(UVt,"wav2vec2-conformer"),UVt.forEach(t),cEr=r(BXe," \u2014 "),oK=n(BXe,"A",{href:!0});var HVt=s(oK);fEr=r(HVt,"Wav2Vec2ConformerForAudioFrameClassification"),HVt.forEach(t),mEr=r(BXe," (Wav2Vec2-Conformer model)"),BXe.forEach(t),gEr=i(Vl),UE=n(Vl,"LI",{});var IXe=s(UE);FCe=n(IXe,"STRONG",{});var JVt=s(FCe);hEr=r(JVt,"wavlm"),JVt.forEach(t),uEr=r(IXe," \u2014 "),rK=n(IXe,"A",{href:!0});var YVt=s(rK);pEr=r(YVt,"WavLMForAudioFrameClassification"),YVt.forEach(t),_Er=r(IXe," (WavLM model)"),IXe.forEach(t),Vl.forEach(t),vEr=i(Na),HE=n(Na,"P",{});var NXe=s(HE);bEr=r(NXe,"The model is set in evaluation mode by default using "),TCe=n(NXe,"CODE",{});var KVt=s(TCe);FEr=r(KVt,"model.eval()"),KVt.forEach(t),TEr=r(NXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),MCe=n(NXe,"CODE",{});var ZVt=s(MCe);MEr=r(ZVt,"model.train()"),ZVt.forEach(t),NXe.forEach(t),EEr=i(Na),T(JE.$$.fragment,Na),Na.forEach(t),Ol.forEach(t),AKe=i(f),_c=n(f,"H2",{class:!0});var Deo=s(_c);YE=n(Deo,"A",{id:!0,class:!0,href:!0});var eXt=s(YE);ECe=n(eXt,"SPAN",{});var oXt=s(ECe);T(k$.$$.fragment,oXt),oXt.forEach(t),eXt.forEach(t),CEr=i(Deo),CCe=n(Deo,"SPAN",{});var rXt=s(CCe);wEr=r(rXt,"AutoModelForCTC"),rXt.forEach(t),Deo.forEach(t),LKe=i(f),Ko=n(f,"DIV",{class:!0});var Xl=s(Ko);T(S$.$$.fragment,Xl),AEr=i(Xl),vc=n(Xl,"P",{});var $le=s(vc);LEr=r($le,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),tK=n($le,"A",{href:!0});var tXt=s(tK);yEr=r(tXt,"from_pretrained()"),tXt.forEach(t),xEr=r($le," class method or the "),aK=n($le,"A",{href:!0});var aXt=s(aK);$Er=r(aXt,"from_config()"),aXt.forEach(t),kEr=r($le,` class
method.`),$le.forEach(t),SEr=i(Xl),R$=n(Xl,"P",{});var Geo=s(R$);REr=r(Geo,"This class cannot be instantiated directly using "),wCe=n(Geo,"CODE",{});var nXt=s(wCe);PEr=r(nXt,"__init__()"),nXt.forEach(t),BEr=r(Geo," (throws an error)."),Geo.forEach(t),IEr=i(Xl),It=n(Xl,"DIV",{class:!0});var e8=s(It);T(P$.$$.fragment,e8),NEr=i(e8),ACe=n(e8,"P",{});var sXt=s(ACe);qEr=r(sXt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),sXt.forEach(t),jEr=i(e8),bc=n(e8,"P",{});var kle=s(bc);DEr=r(kle,`Note:
Loading a model from its configuration file does `),LCe=n(kle,"STRONG",{});var lXt=s(LCe);GEr=r(lXt,"not"),lXt.forEach(t),OEr=r(kle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(kle,"A",{href:!0});var iXt=s(nK);VEr=r(iXt,"from_pretrained()"),iXt.forEach(t),XEr=r(kle," to load the model weights."),kle.forEach(t),zEr=i(e8),T(KE.$$.fragment,e8),e8.forEach(t),QEr=i(Xl),vo=n(Xl,"DIV",{class:!0});var qa=s(vo);T(B$.$$.fragment,qa),WEr=i(qa),yCe=n(qa,"P",{});var dXt=s(yCe);UEr=r(dXt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),dXt.forEach(t),HEr=i(qa),un=n(qa,"P",{});var o8=s(un);JEr=r(o8,"The model class to instantiate is selected based on the "),xCe=n(o8,"CODE",{});var cXt=s(xCe);YEr=r(cXt,"model_type"),cXt.forEach(t),KEr=r(o8,` property of the config object (either
passed as an argument or loaded from `),$Ce=n(o8,"CODE",{});var fXt=s($Ce);ZEr=r(fXt,"pretrained_model_name_or_path"),fXt.forEach(t),eCr=r(o8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kCe=n(o8,"CODE",{});var mXt=s(kCe);oCr=r(mXt,"pretrained_model_name_or_path"),mXt.forEach(t),rCr=r(o8,":"),o8.forEach(t),tCr=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);ZE=n(Ie,"LI",{});var qXe=s(ZE);SCe=n(qXe,"STRONG",{});var gXt=s(SCe);aCr=r(gXt,"data2vec-audio"),gXt.forEach(t),nCr=r(qXe," \u2014 "),sK=n(qXe,"A",{href:!0});var hXt=s(sK);sCr=r(hXt,"Data2VecAudioForCTC"),hXt.forEach(t),lCr=r(qXe," (Data2VecAudio model)"),qXe.forEach(t),iCr=i(Ie),eC=n(Ie,"LI",{});var jXe=s(eC);RCe=n(jXe,"STRONG",{});var uXt=s(RCe);dCr=r(uXt,"hubert"),uXt.forEach(t),cCr=r(jXe," \u2014 "),lK=n(jXe,"A",{href:!0});var pXt=s(lK);fCr=r(pXt,"HubertForCTC"),pXt.forEach(t),mCr=r(jXe," (Hubert model)"),jXe.forEach(t),gCr=i(Ie),oC=n(Ie,"LI",{});var DXe=s(oC);PCe=n(DXe,"STRONG",{});var _Xt=s(PCe);hCr=r(_Xt,"mctct"),_Xt.forEach(t),uCr=r(DXe," \u2014 "),iK=n(DXe,"A",{href:!0});var vXt=s(iK);pCr=r(vXt,"MCTCTForCTC"),vXt.forEach(t),_Cr=r(DXe," (M-CTC-T model)"),DXe.forEach(t),vCr=i(Ie),rC=n(Ie,"LI",{});var GXe=s(rC);BCe=n(GXe,"STRONG",{});var bXt=s(BCe);bCr=r(bXt,"sew"),bXt.forEach(t),FCr=r(GXe," \u2014 "),dK=n(GXe,"A",{href:!0});var FXt=s(dK);TCr=r(FXt,"SEWForCTC"),FXt.forEach(t),MCr=r(GXe," (SEW model)"),GXe.forEach(t),ECr=i(Ie),tC=n(Ie,"LI",{});var OXe=s(tC);ICe=n(OXe,"STRONG",{});var TXt=s(ICe);CCr=r(TXt,"sew-d"),TXt.forEach(t),wCr=r(OXe," \u2014 "),cK=n(OXe,"A",{href:!0});var MXt=s(cK);ACr=r(MXt,"SEWDForCTC"),MXt.forEach(t),LCr=r(OXe," (SEW-D model)"),OXe.forEach(t),yCr=i(Ie),aC=n(Ie,"LI",{});var VXe=s(aC);NCe=n(VXe,"STRONG",{});var EXt=s(NCe);xCr=r(EXt,"unispeech"),EXt.forEach(t),$Cr=r(VXe," \u2014 "),fK=n(VXe,"A",{href:!0});var CXt=s(fK);kCr=r(CXt,"UniSpeechForCTC"),CXt.forEach(t),SCr=r(VXe," (UniSpeech model)"),VXe.forEach(t),RCr=i(Ie),nC=n(Ie,"LI",{});var XXe=s(nC);qCe=n(XXe,"STRONG",{});var wXt=s(qCe);PCr=r(wXt,"unispeech-sat"),wXt.forEach(t),BCr=r(XXe," \u2014 "),mK=n(XXe,"A",{href:!0});var AXt=s(mK);ICr=r(AXt,"UniSpeechSatForCTC"),AXt.forEach(t),NCr=r(XXe," (UniSpeechSat model)"),XXe.forEach(t),qCr=i(Ie),sC=n(Ie,"LI",{});var zXe=s(sC);jCe=n(zXe,"STRONG",{});var LXt=s(jCe);jCr=r(LXt,"wav2vec2"),LXt.forEach(t),DCr=r(zXe," \u2014 "),gK=n(zXe,"A",{href:!0});var yXt=s(gK);GCr=r(yXt,"Wav2Vec2ForCTC"),yXt.forEach(t),OCr=r(zXe," (Wav2Vec2 model)"),zXe.forEach(t),VCr=i(Ie),lC=n(Ie,"LI",{});var QXe=s(lC);DCe=n(QXe,"STRONG",{});var xXt=s(DCe);XCr=r(xXt,"wav2vec2-conformer"),xXt.forEach(t),zCr=r(QXe," \u2014 "),hK=n(QXe,"A",{href:!0});var $Xt=s(hK);QCr=r($Xt,"Wav2Vec2ConformerForCTC"),$Xt.forEach(t),WCr=r(QXe," (Wav2Vec2-Conformer model)"),QXe.forEach(t),UCr=i(Ie),iC=n(Ie,"LI",{});var WXe=s(iC);GCe=n(WXe,"STRONG",{});var kXt=s(GCe);HCr=r(kXt,"wavlm"),kXt.forEach(t),JCr=r(WXe," \u2014 "),uK=n(WXe,"A",{href:!0});var SXt=s(uK);YCr=r(SXt,"WavLMForCTC"),SXt.forEach(t),KCr=r(WXe," (WavLM model)"),WXe.forEach(t),Ie.forEach(t),ZCr=i(qa),dC=n(qa,"P",{});var UXe=s(dC);e3r=r(UXe,"The model is set in evaluation mode by default using "),OCe=n(UXe,"CODE",{});var RXt=s(OCe);o3r=r(RXt,"model.eval()"),RXt.forEach(t),r3r=r(UXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VCe=n(UXe,"CODE",{});var PXt=s(VCe);t3r=r(PXt,"model.train()"),PXt.forEach(t),UXe.forEach(t),a3r=i(qa),T(cC.$$.fragment,qa),qa.forEach(t),Xl.forEach(t),yKe=i(f),Fc=n(f,"H2",{class:!0});var Oeo=s(Fc);fC=n(Oeo,"A",{id:!0,class:!0,href:!0});var BXt=s(fC);XCe=n(BXt,"SPAN",{});var IXt=s(XCe);T(I$.$$.fragment,IXt),IXt.forEach(t),BXt.forEach(t),n3r=i(Oeo),zCe=n(Oeo,"SPAN",{});var NXt=s(zCe);s3r=r(NXt,"AutoModelForSpeechSeq2Seq"),NXt.forEach(t),Oeo.forEach(t),xKe=i(f),Zo=n(f,"DIV",{class:!0});var zl=s(Zo);T(N$.$$.fragment,zl),l3r=i(zl),Tc=n(zl,"P",{});var Sle=s(Tc);i3r=r(Sle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pK=n(Sle,"A",{href:!0});var qXt=s(pK);d3r=r(qXt,"from_pretrained()"),qXt.forEach(t),c3r=r(Sle," class method or the "),_K=n(Sle,"A",{href:!0});var jXt=s(_K);f3r=r(jXt,"from_config()"),jXt.forEach(t),m3r=r(Sle,` class
method.`),Sle.forEach(t),g3r=i(zl),q$=n(zl,"P",{});var Veo=s(q$);h3r=r(Veo,"This class cannot be instantiated directly using "),QCe=n(Veo,"CODE",{});var DXt=s(QCe);u3r=r(DXt,"__init__()"),DXt.forEach(t),p3r=r(Veo," (throws an error)."),Veo.forEach(t),_3r=i(zl),Nt=n(zl,"DIV",{class:!0});var r8=s(Nt);T(j$.$$.fragment,r8),v3r=i(r8),WCe=n(r8,"P",{});var GXt=s(WCe);b3r=r(GXt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),GXt.forEach(t),F3r=i(r8),Mc=n(r8,"P",{});var Rle=s(Mc);T3r=r(Rle,`Note:
Loading a model from its configuration file does `),UCe=n(Rle,"STRONG",{});var OXt=s(UCe);M3r=r(OXt,"not"),OXt.forEach(t),E3r=r(Rle,` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=n(Rle,"A",{href:!0});var VXt=s(vK);C3r=r(VXt,"from_pretrained()"),VXt.forEach(t),w3r=r(Rle," to load the model weights."),Rle.forEach(t),A3r=i(r8),T(mC.$$.fragment,r8),r8.forEach(t),L3r=i(zl),bo=n(zl,"DIV",{class:!0});var ja=s(bo);T(D$.$$.fragment,ja),y3r=i(ja),HCe=n(ja,"P",{});var XXt=s(HCe);x3r=r(XXt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),XXt.forEach(t),$3r=i(ja),pn=n(ja,"P",{});var t8=s(pn);k3r=r(t8,"The model class to instantiate is selected based on the "),JCe=n(t8,"CODE",{});var zXt=s(JCe);S3r=r(zXt,"model_type"),zXt.forEach(t),R3r=r(t8,` property of the config object (either
passed as an argument or loaded from `),YCe=n(t8,"CODE",{});var QXt=s(YCe);P3r=r(QXt,"pretrained_model_name_or_path"),QXt.forEach(t),B3r=r(t8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=n(t8,"CODE",{});var WXt=s(KCe);I3r=r(WXt,"pretrained_model_name_or_path"),WXt.forEach(t),N3r=r(t8,":"),t8.forEach(t),q3r=i(ja),G$=n(ja,"UL",{});var Xeo=s(G$);gC=n(Xeo,"LI",{});var HXe=s(gC);ZCe=n(HXe,"STRONG",{});var UXt=s(ZCe);j3r=r(UXt,"speech-encoder-decoder"),UXt.forEach(t),D3r=r(HXe," \u2014 "),bK=n(HXe,"A",{href:!0});var HXt=s(bK);G3r=r(HXt,"SpeechEncoderDecoderModel"),HXt.forEach(t),O3r=r(HXe," (Speech Encoder decoder model)"),HXe.forEach(t),V3r=i(Xeo),hC=n(Xeo,"LI",{});var JXe=s(hC);e3e=n(JXe,"STRONG",{});var JXt=s(e3e);X3r=r(JXt,"speech_to_text"),JXt.forEach(t),z3r=r(JXe," \u2014 "),FK=n(JXe,"A",{href:!0});var YXt=s(FK);Q3r=r(YXt,"Speech2TextForConditionalGeneration"),YXt.forEach(t),W3r=r(JXe," (Speech2Text model)"),JXe.forEach(t),Xeo.forEach(t),U3r=i(ja),uC=n(ja,"P",{});var YXe=s(uC);H3r=r(YXe,"The model is set in evaluation mode by default using "),o3e=n(YXe,"CODE",{});var KXt=s(o3e);J3r=r(KXt,"model.eval()"),KXt.forEach(t),Y3r=r(YXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r3e=n(YXe,"CODE",{});var ZXt=s(r3e);K3r=r(ZXt,"model.train()"),ZXt.forEach(t),YXe.forEach(t),Z3r=i(ja),T(pC.$$.fragment,ja),ja.forEach(t),zl.forEach(t),$Ke=i(f),Ec=n(f,"H2",{class:!0});var zeo=s(Ec);_C=n(zeo,"A",{id:!0,class:!0,href:!0});var ezt=s(_C);t3e=n(ezt,"SPAN",{});var ozt=s(t3e);T(O$.$$.fragment,ozt),ozt.forEach(t),ezt.forEach(t),e5r=i(zeo),a3e=n(zeo,"SPAN",{});var rzt=s(a3e);o5r=r(rzt,"AutoModelForAudioXVector"),rzt.forEach(t),zeo.forEach(t),kKe=i(f),er=n(f,"DIV",{class:!0});var Ql=s(er);T(V$.$$.fragment,Ql),r5r=i(Ql),Cc=n(Ql,"P",{});var Ple=s(Cc);t5r=r(Ple,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),TK=n(Ple,"A",{href:!0});var tzt=s(TK);a5r=r(tzt,"from_pretrained()"),tzt.forEach(t),n5r=r(Ple," class method or the "),MK=n(Ple,"A",{href:!0});var azt=s(MK);s5r=r(azt,"from_config()"),azt.forEach(t),l5r=r(Ple,` class
method.`),Ple.forEach(t),i5r=i(Ql),X$=n(Ql,"P",{});var Qeo=s(X$);d5r=r(Qeo,"This class cannot be instantiated directly using "),n3e=n(Qeo,"CODE",{});var nzt=s(n3e);c5r=r(nzt,"__init__()"),nzt.forEach(t),f5r=r(Qeo," (throws an error)."),Qeo.forEach(t),m5r=i(Ql),qt=n(Ql,"DIV",{class:!0});var a8=s(qt);T(z$.$$.fragment,a8),g5r=i(a8),s3e=n(a8,"P",{});var szt=s(s3e);h5r=r(szt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),szt.forEach(t),u5r=i(a8),wc=n(a8,"P",{});var Ble=s(wc);p5r=r(Ble,`Note:
Loading a model from its configuration file does `),l3e=n(Ble,"STRONG",{});var lzt=s(l3e);_5r=r(lzt,"not"),lzt.forEach(t),v5r=r(Ble,` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=n(Ble,"A",{href:!0});var izt=s(EK);b5r=r(izt,"from_pretrained()"),izt.forEach(t),F5r=r(Ble," to load the model weights."),Ble.forEach(t),T5r=i(a8),T(vC.$$.fragment,a8),a8.forEach(t),M5r=i(Ql),Fo=n(Ql,"DIV",{class:!0});var Da=s(Fo);T(Q$.$$.fragment,Da),E5r=i(Da),i3e=n(Da,"P",{});var dzt=s(i3e);C5r=r(dzt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dzt.forEach(t),w5r=i(Da),_n=n(Da,"P",{});var n8=s(_n);A5r=r(n8,"The model class to instantiate is selected based on the "),d3e=n(n8,"CODE",{});var czt=s(d3e);L5r=r(czt,"model_type"),czt.forEach(t),y5r=r(n8,` property of the config object (either
passed as an argument or loaded from `),c3e=n(n8,"CODE",{});var fzt=s(c3e);x5r=r(fzt,"pretrained_model_name_or_path"),fzt.forEach(t),$5r=r(n8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f3e=n(n8,"CODE",{});var mzt=s(f3e);k5r=r(mzt,"pretrained_model_name_or_path"),mzt.forEach(t),S5r=r(n8,":"),n8.forEach(t),R5r=i(Da),mt=n(Da,"UL",{});var Wl=s(mt);bC=n(Wl,"LI",{});var KXe=s(bC);m3e=n(KXe,"STRONG",{});var gzt=s(m3e);P5r=r(gzt,"data2vec-audio"),gzt.forEach(t),B5r=r(KXe," \u2014 "),CK=n(KXe,"A",{href:!0});var hzt=s(CK);I5r=r(hzt,"Data2VecAudioForXVector"),hzt.forEach(t),N5r=r(KXe," (Data2VecAudio model)"),KXe.forEach(t),q5r=i(Wl),FC=n(Wl,"LI",{});var ZXe=s(FC);g3e=n(ZXe,"STRONG",{});var uzt=s(g3e);j5r=r(uzt,"unispeech-sat"),uzt.forEach(t),D5r=r(ZXe," \u2014 "),wK=n(ZXe,"A",{href:!0});var pzt=s(wK);G5r=r(pzt,"UniSpeechSatForXVector"),pzt.forEach(t),O5r=r(ZXe," (UniSpeechSat model)"),ZXe.forEach(t),V5r=i(Wl),TC=n(Wl,"LI",{});var eze=s(TC);h3e=n(eze,"STRONG",{});var _zt=s(h3e);X5r=r(_zt,"wav2vec2"),_zt.forEach(t),z5r=r(eze," \u2014 "),AK=n(eze,"A",{href:!0});var vzt=s(AK);Q5r=r(vzt,"Wav2Vec2ForXVector"),vzt.forEach(t),W5r=r(eze," (Wav2Vec2 model)"),eze.forEach(t),U5r=i(Wl),MC=n(Wl,"LI",{});var oze=s(MC);u3e=n(oze,"STRONG",{});var bzt=s(u3e);H5r=r(bzt,"wav2vec2-conformer"),bzt.forEach(t),J5r=r(oze," \u2014 "),LK=n(oze,"A",{href:!0});var Fzt=s(LK);Y5r=r(Fzt,"Wav2Vec2ConformerForXVector"),Fzt.forEach(t),K5r=r(oze," (Wav2Vec2-Conformer model)"),oze.forEach(t),Z5r=i(Wl),EC=n(Wl,"LI",{});var rze=s(EC);p3e=n(rze,"STRONG",{});var Tzt=s(p3e);e0r=r(Tzt,"wavlm"),Tzt.forEach(t),o0r=r(rze," \u2014 "),yK=n(rze,"A",{href:!0});var Mzt=s(yK);r0r=r(Mzt,"WavLMForXVector"),Mzt.forEach(t),t0r=r(rze," (WavLM model)"),rze.forEach(t),Wl.forEach(t),a0r=i(Da),CC=n(Da,"P",{});var tze=s(CC);n0r=r(tze,"The model is set in evaluation mode by default using "),_3e=n(tze,"CODE",{});var Ezt=s(_3e);s0r=r(Ezt,"model.eval()"),Ezt.forEach(t),l0r=r(tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v3e=n(tze,"CODE",{});var Czt=s(v3e);i0r=r(Czt,"model.train()"),Czt.forEach(t),tze.forEach(t),d0r=i(Da),T(wC.$$.fragment,Da),Da.forEach(t),Ql.forEach(t),SKe=i(f),Ac=n(f,"H2",{class:!0});var Weo=s(Ac);AC=n(Weo,"A",{id:!0,class:!0,href:!0});var wzt=s(AC);b3e=n(wzt,"SPAN",{});var Azt=s(b3e);T(W$.$$.fragment,Azt),Azt.forEach(t),wzt.forEach(t),c0r=i(Weo),F3e=n(Weo,"SPAN",{});var Lzt=s(F3e);f0r=r(Lzt,"AutoModelForMaskedImageModeling"),Lzt.forEach(t),Weo.forEach(t),RKe=i(f),or=n(f,"DIV",{class:!0});var Ul=s(or);T(U$.$$.fragment,Ul),m0r=i(Ul),Lc=n(Ul,"P",{});var Ile=s(Lc);g0r=r(Ile,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),xK=n(Ile,"A",{href:!0});var yzt=s(xK);h0r=r(yzt,"from_pretrained()"),yzt.forEach(t),u0r=r(Ile," class method or the "),$K=n(Ile,"A",{href:!0});var xzt=s($K);p0r=r(xzt,"from_config()"),xzt.forEach(t),_0r=r(Ile,` class
method.`),Ile.forEach(t),v0r=i(Ul),H$=n(Ul,"P",{});var Ueo=s(H$);b0r=r(Ueo,"This class cannot be instantiated directly using "),T3e=n(Ueo,"CODE",{});var $zt=s(T3e);F0r=r($zt,"__init__()"),$zt.forEach(t),T0r=r(Ueo," (throws an error)."),Ueo.forEach(t),M0r=i(Ul),jt=n(Ul,"DIV",{class:!0});var s8=s(jt);T(J$.$$.fragment,s8),E0r=i(s8),M3e=n(s8,"P",{});var kzt=s(M3e);C0r=r(kzt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),kzt.forEach(t),w0r=i(s8),yc=n(s8,"P",{});var Nle=s(yc);A0r=r(Nle,`Note:
Loading a model from its configuration file does `),E3e=n(Nle,"STRONG",{});var Szt=s(E3e);L0r=r(Szt,"not"),Szt.forEach(t),y0r=r(Nle,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(Nle,"A",{href:!0});var Rzt=s(kK);x0r=r(Rzt,"from_pretrained()"),Rzt.forEach(t),$0r=r(Nle," to load the model weights."),Nle.forEach(t),k0r=i(s8),T(LC.$$.fragment,s8),s8.forEach(t),S0r=i(Ul),To=n(Ul,"DIV",{class:!0});var Ga=s(To);T(Y$.$$.fragment,Ga),R0r=i(Ga),C3e=n(Ga,"P",{});var Pzt=s(C3e);P0r=r(Pzt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Pzt.forEach(t),B0r=i(Ga),vn=n(Ga,"P",{});var l8=s(vn);I0r=r(l8,"The model class to instantiate is selected based on the "),w3e=n(l8,"CODE",{});var Bzt=s(w3e);N0r=r(Bzt,"model_type"),Bzt.forEach(t),q0r=r(l8,` property of the config object (either
passed as an argument or loaded from `),A3e=n(l8,"CODE",{});var Izt=s(A3e);j0r=r(Izt,"pretrained_model_name_or_path"),Izt.forEach(t),D0r=r(l8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L3e=n(l8,"CODE",{});var Nzt=s(L3e);G0r=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),O0r=r(l8,":"),l8.forEach(t),V0r=i(Ga),bn=n(Ga,"UL",{});var i8=s(bn);yC=n(i8,"LI",{});var aze=s(yC);y3e=n(aze,"STRONG",{});var qzt=s(y3e);X0r=r(qzt,"deit"),qzt.forEach(t),z0r=r(aze," \u2014 "),SK=n(aze,"A",{href:!0});var jzt=s(SK);Q0r=r(jzt,"DeiTForMaskedImageModeling"),jzt.forEach(t),W0r=r(aze," (DeiT model)"),aze.forEach(t),U0r=i(i8),xC=n(i8,"LI",{});var nze=s(xC);x3e=n(nze,"STRONG",{});var Dzt=s(x3e);H0r=r(Dzt,"swin"),Dzt.forEach(t),J0r=r(nze," \u2014 "),RK=n(nze,"A",{href:!0});var Gzt=s(RK);Y0r=r(Gzt,"SwinForMaskedImageModeling"),Gzt.forEach(t),K0r=r(nze," (Swin Transformer model)"),nze.forEach(t),Z0r=i(i8),$C=n(i8,"LI",{});var sze=s($C);$3e=n(sze,"STRONG",{});var Ozt=s($3e);ewr=r(Ozt,"swinv2"),Ozt.forEach(t),owr=r(sze," \u2014 "),PK=n(sze,"A",{href:!0});var Vzt=s(PK);rwr=r(Vzt,"Swinv2ForMaskedImageModeling"),Vzt.forEach(t),twr=r(sze," (Swin Transformer V2 model)"),sze.forEach(t),awr=i(i8),kC=n(i8,"LI",{});var lze=s(kC);k3e=n(lze,"STRONG",{});var Xzt=s(k3e);nwr=r(Xzt,"vit"),Xzt.forEach(t),swr=r(lze," \u2014 "),BK=n(lze,"A",{href:!0});var zzt=s(BK);lwr=r(zzt,"ViTForMaskedImageModeling"),zzt.forEach(t),iwr=r(lze," (ViT model)"),lze.forEach(t),i8.forEach(t),dwr=i(Ga),SC=n(Ga,"P",{});var ize=s(SC);cwr=r(ize,"The model is set in evaluation mode by default using "),S3e=n(ize,"CODE",{});var Qzt=s(S3e);fwr=r(Qzt,"model.eval()"),Qzt.forEach(t),mwr=r(ize,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R3e=n(ize,"CODE",{});var Wzt=s(R3e);gwr=r(Wzt,"model.train()"),Wzt.forEach(t),ize.forEach(t),hwr=i(Ga),T(RC.$$.fragment,Ga),Ga.forEach(t),Ul.forEach(t),PKe=i(f),xc=n(f,"H2",{class:!0});var Heo=s(xc);PC=n(Heo,"A",{id:!0,class:!0,href:!0});var Uzt=s(PC);P3e=n(Uzt,"SPAN",{});var Hzt=s(P3e);T(K$.$$.fragment,Hzt),Hzt.forEach(t),Uzt.forEach(t),uwr=i(Heo),B3e=n(Heo,"SPAN",{});var Jzt=s(B3e);pwr=r(Jzt,"AutoModelForObjectDetection"),Jzt.forEach(t),Heo.forEach(t),BKe=i(f),rr=n(f,"DIV",{class:!0});var Hl=s(rr);T(Z$.$$.fragment,Hl),_wr=i(Hl),$c=n(Hl,"P",{});var qle=s($c);vwr=r(qle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IK=n(qle,"A",{href:!0});var Yzt=s(IK);bwr=r(Yzt,"from_pretrained()"),Yzt.forEach(t),Fwr=r(qle," class method or the "),NK=n(qle,"A",{href:!0});var Kzt=s(NK);Twr=r(Kzt,"from_config()"),Kzt.forEach(t),Mwr=r(qle,` class
method.`),qle.forEach(t),Ewr=i(Hl),ek=n(Hl,"P",{});var Jeo=s(ek);Cwr=r(Jeo,"This class cannot be instantiated directly using "),I3e=n(Jeo,"CODE",{});var Zzt=s(I3e);wwr=r(Zzt,"__init__()"),Zzt.forEach(t),Awr=r(Jeo," (throws an error)."),Jeo.forEach(t),Lwr=i(Hl),Dt=n(Hl,"DIV",{class:!0});var d8=s(Dt);T(ok.$$.fragment,d8),ywr=i(d8),N3e=n(d8,"P",{});var eQt=s(N3e);xwr=r(eQt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),eQt.forEach(t),$wr=i(d8),kc=n(d8,"P",{});var jle=s(kc);kwr=r(jle,`Note:
Loading a model from its configuration file does `),q3e=n(jle,"STRONG",{});var oQt=s(q3e);Swr=r(oQt,"not"),oQt.forEach(t),Rwr=r(jle,` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=n(jle,"A",{href:!0});var rQt=s(qK);Pwr=r(rQt,"from_pretrained()"),rQt.forEach(t),Bwr=r(jle," to load the model weights."),jle.forEach(t),Iwr=i(d8),T(BC.$$.fragment,d8),d8.forEach(t),Nwr=i(Hl),Mo=n(Hl,"DIV",{class:!0});var Oa=s(Mo);T(rk.$$.fragment,Oa),qwr=i(Oa),j3e=n(Oa,"P",{});var tQt=s(j3e);jwr=r(tQt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),tQt.forEach(t),Dwr=i(Oa),Fn=n(Oa,"P",{});var c8=s(Fn);Gwr=r(c8,"The model class to instantiate is selected based on the "),D3e=n(c8,"CODE",{});var aQt=s(D3e);Owr=r(aQt,"model_type"),aQt.forEach(t),Vwr=r(c8,` property of the config object (either
passed as an argument or loaded from `),G3e=n(c8,"CODE",{});var nQt=s(G3e);Xwr=r(nQt,"pretrained_model_name_or_path"),nQt.forEach(t),zwr=r(c8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O3e=n(c8,"CODE",{});var sQt=s(O3e);Qwr=r(sQt,"pretrained_model_name_or_path"),sQt.forEach(t),Wwr=r(c8,":"),c8.forEach(t),Uwr=i(Oa),tk=n(Oa,"UL",{});var Yeo=s(tk);IC=n(Yeo,"LI",{});var dze=s(IC);V3e=n(dze,"STRONG",{});var lQt=s(V3e);Hwr=r(lQt,"detr"),lQt.forEach(t),Jwr=r(dze," \u2014 "),jK=n(dze,"A",{href:!0});var iQt=s(jK);Ywr=r(iQt,"DetrForObjectDetection"),iQt.forEach(t),Kwr=r(dze," (DETR model)"),dze.forEach(t),Zwr=i(Yeo),NC=n(Yeo,"LI",{});var cze=s(NC);X3e=n(cze,"STRONG",{});var dQt=s(X3e);eAr=r(dQt,"yolos"),dQt.forEach(t),oAr=r(cze," \u2014 "),DK=n(cze,"A",{href:!0});var cQt=s(DK);rAr=r(cQt,"YolosForObjectDetection"),cQt.forEach(t),tAr=r(cze," (YOLOS model)"),cze.forEach(t),Yeo.forEach(t),aAr=i(Oa),qC=n(Oa,"P",{});var fze=s(qC);nAr=r(fze,"The model is set in evaluation mode by default using "),z3e=n(fze,"CODE",{});var fQt=s(z3e);sAr=r(fQt,"model.eval()"),fQt.forEach(t),lAr=r(fze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q3e=n(fze,"CODE",{});var mQt=s(Q3e);iAr=r(mQt,"model.train()"),mQt.forEach(t),fze.forEach(t),dAr=i(Oa),T(jC.$$.fragment,Oa),Oa.forEach(t),Hl.forEach(t),IKe=i(f),Sc=n(f,"H2",{class:!0});var Keo=s(Sc);DC=n(Keo,"A",{id:!0,class:!0,href:!0});var gQt=s(DC);W3e=n(gQt,"SPAN",{});var hQt=s(W3e);T(ak.$$.fragment,hQt),hQt.forEach(t),gQt.forEach(t),cAr=i(Keo),U3e=n(Keo,"SPAN",{});var uQt=s(U3e);fAr=r(uQt,"AutoModelForImageSegmentation"),uQt.forEach(t),Keo.forEach(t),NKe=i(f),tr=n(f,"DIV",{class:!0});var Jl=s(tr);T(nk.$$.fragment,Jl),mAr=i(Jl),Rc=n(Jl,"P",{});var Dle=s(Rc);gAr=r(Dle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GK=n(Dle,"A",{href:!0});var pQt=s(GK);hAr=r(pQt,"from_pretrained()"),pQt.forEach(t),uAr=r(Dle," class method or the "),OK=n(Dle,"A",{href:!0});var _Qt=s(OK);pAr=r(_Qt,"from_config()"),_Qt.forEach(t),_Ar=r(Dle,` class
method.`),Dle.forEach(t),vAr=i(Jl),sk=n(Jl,"P",{});var Zeo=s(sk);bAr=r(Zeo,"This class cannot be instantiated directly using "),H3e=n(Zeo,"CODE",{});var vQt=s(H3e);FAr=r(vQt,"__init__()"),vQt.forEach(t),TAr=r(Zeo," (throws an error)."),Zeo.forEach(t),MAr=i(Jl),Gt=n(Jl,"DIV",{class:!0});var f8=s(Gt);T(lk.$$.fragment,f8),EAr=i(f8),J3e=n(f8,"P",{});var bQt=s(J3e);CAr=r(bQt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),bQt.forEach(t),wAr=i(f8),Pc=n(f8,"P",{});var Gle=s(Pc);AAr=r(Gle,`Note:
Loading a model from its configuration file does `),Y3e=n(Gle,"STRONG",{});var FQt=s(Y3e);LAr=r(FQt,"not"),FQt.forEach(t),yAr=r(Gle,` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=n(Gle,"A",{href:!0});var TQt=s(VK);xAr=r(TQt,"from_pretrained()"),TQt.forEach(t),$Ar=r(Gle," to load the model weights."),Gle.forEach(t),kAr=i(f8),T(GC.$$.fragment,f8),f8.forEach(t),SAr=i(Jl),Eo=n(Jl,"DIV",{class:!0});var Va=s(Eo);T(ik.$$.fragment,Va),RAr=i(Va),K3e=n(Va,"P",{});var MQt=s(K3e);PAr=r(MQt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),MQt.forEach(t),BAr=i(Va),Tn=n(Va,"P",{});var m8=s(Tn);IAr=r(m8,"The model class to instantiate is selected based on the "),Z3e=n(m8,"CODE",{});var EQt=s(Z3e);NAr=r(EQt,"model_type"),EQt.forEach(t),qAr=r(m8,` property of the config object (either
passed as an argument or loaded from `),e5e=n(m8,"CODE",{});var CQt=s(e5e);jAr=r(CQt,"pretrained_model_name_or_path"),CQt.forEach(t),DAr=r(m8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o5e=n(m8,"CODE",{});var wQt=s(o5e);GAr=r(wQt,"pretrained_model_name_or_path"),wQt.forEach(t),OAr=r(m8,":"),m8.forEach(t),VAr=i(Va),r5e=n(Va,"UL",{});var AQt=s(r5e);OC=n(AQt,"LI",{});var mze=s(OC);t5e=n(mze,"STRONG",{});var LQt=s(t5e);XAr=r(LQt,"detr"),LQt.forEach(t),zAr=r(mze," \u2014 "),XK=n(mze,"A",{href:!0});var yQt=s(XK);QAr=r(yQt,"DetrForSegmentation"),yQt.forEach(t),WAr=r(mze," (DETR model)"),mze.forEach(t),AQt.forEach(t),UAr=i(Va),VC=n(Va,"P",{});var gze=s(VC);HAr=r(gze,"The model is set in evaluation mode by default using "),a5e=n(gze,"CODE",{});var xQt=s(a5e);JAr=r(xQt,"model.eval()"),xQt.forEach(t),YAr=r(gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n5e=n(gze,"CODE",{});var $Qt=s(n5e);KAr=r($Qt,"model.train()"),$Qt.forEach(t),gze.forEach(t),ZAr=i(Va),T(XC.$$.fragment,Va),Va.forEach(t),Jl.forEach(t),qKe=i(f),Bc=n(f,"H2",{class:!0});var eoo=s(Bc);zC=n(eoo,"A",{id:!0,class:!0,href:!0});var kQt=s(zC);s5e=n(kQt,"SPAN",{});var SQt=s(s5e);T(dk.$$.fragment,SQt),SQt.forEach(t),kQt.forEach(t),e6r=i(eoo),l5e=n(eoo,"SPAN",{});var RQt=s(l5e);o6r=r(RQt,"AutoModelForSemanticSegmentation"),RQt.forEach(t),eoo.forEach(t),jKe=i(f),ar=n(f,"DIV",{class:!0});var Yl=s(ar);T(ck.$$.fragment,Yl),r6r=i(Yl),Ic=n(Yl,"P",{});var Ole=s(Ic);t6r=r(Ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zK=n(Ole,"A",{href:!0});var PQt=s(zK);a6r=r(PQt,"from_pretrained()"),PQt.forEach(t),n6r=r(Ole," class method or the "),QK=n(Ole,"A",{href:!0});var BQt=s(QK);s6r=r(BQt,"from_config()"),BQt.forEach(t),l6r=r(Ole,` class
method.`),Ole.forEach(t),i6r=i(Yl),fk=n(Yl,"P",{});var ooo=s(fk);d6r=r(ooo,"This class cannot be instantiated directly using "),i5e=n(ooo,"CODE",{});var IQt=s(i5e);c6r=r(IQt,"__init__()"),IQt.forEach(t),f6r=r(ooo," (throws an error)."),ooo.forEach(t),m6r=i(Yl),Ot=n(Yl,"DIV",{class:!0});var g8=s(Ot);T(mk.$$.fragment,g8),g6r=i(g8),d5e=n(g8,"P",{});var NQt=s(d5e);h6r=r(NQt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),NQt.forEach(t),u6r=i(g8),Nc=n(g8,"P",{});var Vle=s(Nc);p6r=r(Vle,`Note:
Loading a model from its configuration file does `),c5e=n(Vle,"STRONG",{});var qQt=s(c5e);_6r=r(qQt,"not"),qQt.forEach(t),v6r=r(Vle,` load the model weights. It only affects the
model\u2019s configuration. Use `),WK=n(Vle,"A",{href:!0});var jQt=s(WK);b6r=r(jQt,"from_pretrained()"),jQt.forEach(t),F6r=r(Vle," to load the model weights."),Vle.forEach(t),T6r=i(g8),T(QC.$$.fragment,g8),g8.forEach(t),M6r=i(Yl),Co=n(Yl,"DIV",{class:!0});var Xa=s(Co);T(gk.$$.fragment,Xa),E6r=i(Xa),f5e=n(Xa,"P",{});var DQt=s(f5e);C6r=r(DQt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),DQt.forEach(t),w6r=i(Xa),Mn=n(Xa,"P",{});var h8=s(Mn);A6r=r(h8,"The model class to instantiate is selected based on the "),m5e=n(h8,"CODE",{});var GQt=s(m5e);L6r=r(GQt,"model_type"),GQt.forEach(t),y6r=r(h8,` property of the config object (either
passed as an argument or loaded from `),g5e=n(h8,"CODE",{});var OQt=s(g5e);x6r=r(OQt,"pretrained_model_name_or_path"),OQt.forEach(t),$6r=r(h8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h5e=n(h8,"CODE",{});var VQt=s(h5e);k6r=r(VQt,"pretrained_model_name_or_path"),VQt.forEach(t),S6r=r(h8,":"),h8.forEach(t),R6r=i(Xa),gt=n(Xa,"UL",{});var Kl=s(gt);WC=n(Kl,"LI",{});var hze=s(WC);u5e=n(hze,"STRONG",{});var XQt=s(u5e);P6r=r(XQt,"beit"),XQt.forEach(t),B6r=r(hze," \u2014 "),UK=n(hze,"A",{href:!0});var zQt=s(UK);I6r=r(zQt,"BeitForSemanticSegmentation"),zQt.forEach(t),N6r=r(hze," (BEiT model)"),hze.forEach(t),q6r=i(Kl),UC=n(Kl,"LI",{});var uze=s(UC);p5e=n(uze,"STRONG",{});var QQt=s(p5e);j6r=r(QQt,"data2vec-vision"),QQt.forEach(t),D6r=r(uze," \u2014 "),HK=n(uze,"A",{href:!0});var WQt=s(HK);G6r=r(WQt,"Data2VecVisionForSemanticSegmentation"),WQt.forEach(t),O6r=r(uze," (Data2VecVision model)"),uze.forEach(t),V6r=i(Kl),HC=n(Kl,"LI",{});var pze=s(HC);_5e=n(pze,"STRONG",{});var UQt=s(_5e);X6r=r(UQt,"dpt"),UQt.forEach(t),z6r=r(pze," \u2014 "),JK=n(pze,"A",{href:!0});var HQt=s(JK);Q6r=r(HQt,"DPTForSemanticSegmentation"),HQt.forEach(t),W6r=r(pze," (DPT model)"),pze.forEach(t),U6r=i(Kl),JC=n(Kl,"LI",{});var _ze=s(JC);v5e=n(_ze,"STRONG",{});var JQt=s(v5e);H6r=r(JQt,"mobilevit"),JQt.forEach(t),J6r=r(_ze," \u2014 "),YK=n(_ze,"A",{href:!0});var YQt=s(YK);Y6r=r(YQt,"MobileViTForSemanticSegmentation"),YQt.forEach(t),K6r=r(_ze," (MobileViT model)"),_ze.forEach(t),Z6r=i(Kl),YC=n(Kl,"LI",{});var vze=s(YC);b5e=n(vze,"STRONG",{});var KQt=s(b5e);e7r=r(KQt,"segformer"),KQt.forEach(t),o7r=r(vze," \u2014 "),KK=n(vze,"A",{href:!0});var ZQt=s(KK);r7r=r(ZQt,"SegformerForSemanticSegmentation"),ZQt.forEach(t),t7r=r(vze," (SegFormer model)"),vze.forEach(t),Kl.forEach(t),a7r=i(Xa),KC=n(Xa,"P",{});var bze=s(KC);n7r=r(bze,"The model is set in evaluation mode by default using "),F5e=n(bze,"CODE",{});var eWt=s(F5e);s7r=r(eWt,"model.eval()"),eWt.forEach(t),l7r=r(bze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T5e=n(bze,"CODE",{});var oWt=s(T5e);i7r=r(oWt,"model.train()"),oWt.forEach(t),bze.forEach(t),d7r=i(Xa),T(ZC.$$.fragment,Xa),Xa.forEach(t),Yl.forEach(t),DKe=i(f),qc=n(f,"H2",{class:!0});var roo=s(qc);e3=n(roo,"A",{id:!0,class:!0,href:!0});var rWt=s(e3);M5e=n(rWt,"SPAN",{});var tWt=s(M5e);T(hk.$$.fragment,tWt),tWt.forEach(t),rWt.forEach(t),c7r=i(roo),E5e=n(roo,"SPAN",{});var aWt=s(E5e);f7r=r(aWt,"AutoModelForInstanceSegmentation"),aWt.forEach(t),roo.forEach(t),GKe=i(f),nr=n(f,"DIV",{class:!0});var Zl=s(nr);T(uk.$$.fragment,Zl),m7r=i(Zl),jc=n(Zl,"P",{});var Xle=s(jc);g7r=r(Xle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),ZK=n(Xle,"A",{href:!0});var nWt=s(ZK);h7r=r(nWt,"from_pretrained()"),nWt.forEach(t),u7r=r(Xle," class method or the "),eZ=n(Xle,"A",{href:!0});var sWt=s(eZ);p7r=r(sWt,"from_config()"),sWt.forEach(t),_7r=r(Xle,` class
method.`),Xle.forEach(t),v7r=i(Zl),pk=n(Zl,"P",{});var too=s(pk);b7r=r(too,"This class cannot be instantiated directly using "),C5e=n(too,"CODE",{});var lWt=s(C5e);F7r=r(lWt,"__init__()"),lWt.forEach(t),T7r=r(too," (throws an error)."),too.forEach(t),M7r=i(Zl),Vt=n(Zl,"DIV",{class:!0});var u8=s(Vt);T(_k.$$.fragment,u8),E7r=i(u8),w5e=n(u8,"P",{});var iWt=s(w5e);C7r=r(iWt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),iWt.forEach(t),w7r=i(u8),Dc=n(u8,"P",{});var zle=s(Dc);A7r=r(zle,`Note:
Loading a model from its configuration file does `),A5e=n(zle,"STRONG",{});var dWt=s(A5e);L7r=r(dWt,"not"),dWt.forEach(t),y7r=r(zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(zle,"A",{href:!0});var cWt=s(oZ);x7r=r(cWt,"from_pretrained()"),cWt.forEach(t),$7r=r(zle," to load the model weights."),zle.forEach(t),k7r=i(u8),T(o3.$$.fragment,u8),u8.forEach(t),S7r=i(Zl),wo=n(Zl,"DIV",{class:!0});var za=s(wo);T(vk.$$.fragment,za),R7r=i(za),L5e=n(za,"P",{});var fWt=s(L5e);P7r=r(fWt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),fWt.forEach(t),B7r=i(za),En=n(za,"P",{});var p8=s(En);I7r=r(p8,"The model class to instantiate is selected based on the "),y5e=n(p8,"CODE",{});var mWt=s(y5e);N7r=r(mWt,"model_type"),mWt.forEach(t),q7r=r(p8,` property of the config object (either
passed as an argument or loaded from `),x5e=n(p8,"CODE",{});var gWt=s(x5e);j7r=r(gWt,"pretrained_model_name_or_path"),gWt.forEach(t),D7r=r(p8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$5e=n(p8,"CODE",{});var hWt=s($5e);G7r=r(hWt,"pretrained_model_name_or_path"),hWt.forEach(t),O7r=r(p8,":"),p8.forEach(t),V7r=i(za),k5e=n(za,"UL",{});var uWt=s(k5e);r3=n(uWt,"LI",{});var Fze=s(r3);S5e=n(Fze,"STRONG",{});var pWt=s(S5e);X7r=r(pWt,"maskformer"),pWt.forEach(t),z7r=r(Fze," \u2014 "),rZ=n(Fze,"A",{href:!0});var _Wt=s(rZ);Q7r=r(_Wt,"MaskFormerForInstanceSegmentation"),_Wt.forEach(t),W7r=r(Fze," (MaskFormer model)"),Fze.forEach(t),uWt.forEach(t),U7r=i(za),t3=n(za,"P",{});var Tze=s(t3);H7r=r(Tze,"The model is set in evaluation mode by default using "),R5e=n(Tze,"CODE",{});var vWt=s(R5e);J7r=r(vWt,"model.eval()"),vWt.forEach(t),Y7r=r(Tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=n(Tze,"CODE",{});var bWt=s(P5e);K7r=r(bWt,"model.train()"),bWt.forEach(t),Tze.forEach(t),Z7r=i(za),T(a3.$$.fragment,za),za.forEach(t),Zl.forEach(t),OKe=i(f),Gc=n(f,"H2",{class:!0});var aoo=s(Gc);n3=n(aoo,"A",{id:!0,class:!0,href:!0});var FWt=s(n3);B5e=n(FWt,"SPAN",{});var TWt=s(B5e);T(bk.$$.fragment,TWt),TWt.forEach(t),FWt.forEach(t),eLr=i(aoo),I5e=n(aoo,"SPAN",{});var MWt=s(I5e);oLr=r(MWt,"TFAutoModel"),MWt.forEach(t),aoo.forEach(t),VKe=i(f),sr=n(f,"DIV",{class:!0});var ei=s(sr);T(Fk.$$.fragment,ei),rLr=i(ei),Oc=n(ei,"P",{});var Qle=s(Oc);tLr=r(Qle,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tZ=n(Qle,"A",{href:!0});var EWt=s(tZ);aLr=r(EWt,"from_pretrained()"),EWt.forEach(t),nLr=r(Qle," class method or the "),aZ=n(Qle,"A",{href:!0});var CWt=s(aZ);sLr=r(CWt,"from_config()"),CWt.forEach(t),lLr=r(Qle,` class
method.`),Qle.forEach(t),iLr=i(ei),Tk=n(ei,"P",{});var noo=s(Tk);dLr=r(noo,"This class cannot be instantiated directly using "),N5e=n(noo,"CODE",{});var wWt=s(N5e);cLr=r(wWt,"__init__()"),wWt.forEach(t),fLr=r(noo," (throws an error)."),noo.forEach(t),mLr=i(ei),Xt=n(ei,"DIV",{class:!0});var _8=s(Xt);T(Mk.$$.fragment,_8),gLr=i(_8),q5e=n(_8,"P",{});var AWt=s(q5e);hLr=r(AWt,"Instantiates one of the base model classes of the library from a configuration."),AWt.forEach(t),uLr=i(_8),Vc=n(_8,"P",{});var Wle=s(Vc);pLr=r(Wle,`Note:
Loading a model from its configuration file does `),j5e=n(Wle,"STRONG",{});var LWt=s(j5e);_Lr=r(LWt,"not"),LWt.forEach(t),vLr=r(Wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=n(Wle,"A",{href:!0});var yWt=s(nZ);bLr=r(yWt,"from_pretrained()"),yWt.forEach(t),FLr=r(Wle," to load the model weights."),Wle.forEach(t),TLr=i(_8),T(s3.$$.fragment,_8),_8.forEach(t),MLr=i(ei),Ir=n(ei,"DIV",{class:!0});var oi=s(Ir);T(Ek.$$.fragment,oi),ELr=i(oi),D5e=n(oi,"P",{});var xWt=s(D5e);CLr=r(xWt,"Instantiate one of the base model classes of the library from a pretrained model."),xWt.forEach(t),wLr=i(oi),Cn=n(oi,"P",{});var v8=s(Cn);ALr=r(v8,"The model class to instantiate is selected based on the "),G5e=n(v8,"CODE",{});var $Wt=s(G5e);LLr=r($Wt,"model_type"),$Wt.forEach(t),yLr=r(v8,` property of the config object (either
passed as an argument or loaded from `),O5e=n(v8,"CODE",{});var kWt=s(O5e);xLr=r(kWt,"pretrained_model_name_or_path"),kWt.forEach(t),$Lr=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=n(v8,"CODE",{});var SWt=s(V5e);kLr=r(SWt,"pretrained_model_name_or_path"),SWt.forEach(t),SLr=r(v8,":"),v8.forEach(t),RLr=i(oi),N=n(oi,"UL",{});var j=s(N);l3=n(j,"LI",{});var Mze=s(l3);X5e=n(Mze,"STRONG",{});var RWt=s(X5e);PLr=r(RWt,"albert"),RWt.forEach(t),BLr=r(Mze," \u2014 "),sZ=n(Mze,"A",{href:!0});var PWt=s(sZ);ILr=r(PWt,"TFAlbertModel"),PWt.forEach(t),NLr=r(Mze," (ALBERT model)"),Mze.forEach(t),qLr=i(j),i3=n(j,"LI",{});var Eze=s(i3);z5e=n(Eze,"STRONG",{});var BWt=s(z5e);jLr=r(BWt,"bart"),BWt.forEach(t),DLr=r(Eze," \u2014 "),lZ=n(Eze,"A",{href:!0});var IWt=s(lZ);GLr=r(IWt,"TFBartModel"),IWt.forEach(t),OLr=r(Eze," (BART model)"),Eze.forEach(t),VLr=i(j),d3=n(j,"LI",{});var Cze=s(d3);Q5e=n(Cze,"STRONG",{});var NWt=s(Q5e);XLr=r(NWt,"bert"),NWt.forEach(t),zLr=r(Cze," \u2014 "),iZ=n(Cze,"A",{href:!0});var qWt=s(iZ);QLr=r(qWt,"TFBertModel"),qWt.forEach(t),WLr=r(Cze," (BERT model)"),Cze.forEach(t),ULr=i(j),c3=n(j,"LI",{});var wze=s(c3);W5e=n(wze,"STRONG",{});var jWt=s(W5e);HLr=r(jWt,"blenderbot"),jWt.forEach(t),JLr=r(wze," \u2014 "),dZ=n(wze,"A",{href:!0});var DWt=s(dZ);YLr=r(DWt,"TFBlenderbotModel"),DWt.forEach(t),KLr=r(wze," (Blenderbot model)"),wze.forEach(t),ZLr=i(j),f3=n(j,"LI",{});var Aze=s(f3);U5e=n(Aze,"STRONG",{});var GWt=s(U5e);eyr=r(GWt,"blenderbot-small"),GWt.forEach(t),oyr=r(Aze," \u2014 "),cZ=n(Aze,"A",{href:!0});var OWt=s(cZ);ryr=r(OWt,"TFBlenderbotSmallModel"),OWt.forEach(t),tyr=r(Aze," (BlenderbotSmall model)"),Aze.forEach(t),ayr=i(j),m3=n(j,"LI",{});var Lze=s(m3);H5e=n(Lze,"STRONG",{});var VWt=s(H5e);nyr=r(VWt,"camembert"),VWt.forEach(t),syr=r(Lze," \u2014 "),fZ=n(Lze,"A",{href:!0});var XWt=s(fZ);lyr=r(XWt,"TFCamembertModel"),XWt.forEach(t),iyr=r(Lze," (CamemBERT model)"),Lze.forEach(t),dyr=i(j),g3=n(j,"LI",{});var yze=s(g3);J5e=n(yze,"STRONG",{});var zWt=s(J5e);cyr=r(zWt,"clip"),zWt.forEach(t),fyr=r(yze," \u2014 "),mZ=n(yze,"A",{href:!0});var QWt=s(mZ);myr=r(QWt,"TFCLIPModel"),QWt.forEach(t),gyr=r(yze," (CLIP model)"),yze.forEach(t),hyr=i(j),h3=n(j,"LI",{});var xze=s(h3);Y5e=n(xze,"STRONG",{});var WWt=s(Y5e);uyr=r(WWt,"convbert"),WWt.forEach(t),pyr=r(xze," \u2014 "),gZ=n(xze,"A",{href:!0});var UWt=s(gZ);_yr=r(UWt,"TFConvBertModel"),UWt.forEach(t),vyr=r(xze," (ConvBERT model)"),xze.forEach(t),byr=i(j),u3=n(j,"LI",{});var $ze=s(u3);K5e=n($ze,"STRONG",{});var HWt=s(K5e);Fyr=r(HWt,"convnext"),HWt.forEach(t),Tyr=r($ze," \u2014 "),hZ=n($ze,"A",{href:!0});var JWt=s(hZ);Myr=r(JWt,"TFConvNextModel"),JWt.forEach(t),Eyr=r($ze," (ConvNeXT model)"),$ze.forEach(t),Cyr=i(j),p3=n(j,"LI",{});var kze=s(p3);Z5e=n(kze,"STRONG",{});var YWt=s(Z5e);wyr=r(YWt,"ctrl"),YWt.forEach(t),Ayr=r(kze," \u2014 "),uZ=n(kze,"A",{href:!0});var KWt=s(uZ);Lyr=r(KWt,"TFCTRLModel"),KWt.forEach(t),yyr=r(kze," (CTRL model)"),kze.forEach(t),xyr=i(j),_3=n(j,"LI",{});var Sze=s(_3);e0e=n(Sze,"STRONG",{});var ZWt=s(e0e);$yr=r(ZWt,"data2vec-vision"),ZWt.forEach(t),kyr=r(Sze," \u2014 "),pZ=n(Sze,"A",{href:!0});var eUt=s(pZ);Syr=r(eUt,"TFData2VecVisionModel"),eUt.forEach(t),Ryr=r(Sze," (Data2VecVision model)"),Sze.forEach(t),Pyr=i(j),v3=n(j,"LI",{});var Rze=s(v3);o0e=n(Rze,"STRONG",{});var oUt=s(o0e);Byr=r(oUt,"deberta"),oUt.forEach(t),Iyr=r(Rze," \u2014 "),_Z=n(Rze,"A",{href:!0});var rUt=s(_Z);Nyr=r(rUt,"TFDebertaModel"),rUt.forEach(t),qyr=r(Rze," (DeBERTa model)"),Rze.forEach(t),jyr=i(j),b3=n(j,"LI",{});var Pze=s(b3);r0e=n(Pze,"STRONG",{});var tUt=s(r0e);Dyr=r(tUt,"deberta-v2"),tUt.forEach(t),Gyr=r(Pze," \u2014 "),vZ=n(Pze,"A",{href:!0});var aUt=s(vZ);Oyr=r(aUt,"TFDebertaV2Model"),aUt.forEach(t),Vyr=r(Pze," (DeBERTa-v2 model)"),Pze.forEach(t),Xyr=i(j),F3=n(j,"LI",{});var Bze=s(F3);t0e=n(Bze,"STRONG",{});var nUt=s(t0e);zyr=r(nUt,"deit"),nUt.forEach(t),Qyr=r(Bze," \u2014 "),bZ=n(Bze,"A",{href:!0});var sUt=s(bZ);Wyr=r(sUt,"TFDeiTModel"),sUt.forEach(t),Uyr=r(Bze," (DeiT model)"),Bze.forEach(t),Hyr=i(j),T3=n(j,"LI",{});var Ize=s(T3);a0e=n(Ize,"STRONG",{});var lUt=s(a0e);Jyr=r(lUt,"distilbert"),lUt.forEach(t),Yyr=r(Ize," \u2014 "),FZ=n(Ize,"A",{href:!0});var iUt=s(FZ);Kyr=r(iUt,"TFDistilBertModel"),iUt.forEach(t),Zyr=r(Ize," (DistilBERT model)"),Ize.forEach(t),e8r=i(j),M3=n(j,"LI",{});var Nze=s(M3);n0e=n(Nze,"STRONG",{});var dUt=s(n0e);o8r=r(dUt,"dpr"),dUt.forEach(t),r8r=r(Nze," \u2014 "),TZ=n(Nze,"A",{href:!0});var cUt=s(TZ);t8r=r(cUt,"TFDPRQuestionEncoder"),cUt.forEach(t),a8r=r(Nze," (DPR model)"),Nze.forEach(t),n8r=i(j),E3=n(j,"LI",{});var qze=s(E3);s0e=n(qze,"STRONG",{});var fUt=s(s0e);s8r=r(fUt,"electra"),fUt.forEach(t),l8r=r(qze," \u2014 "),MZ=n(qze,"A",{href:!0});var mUt=s(MZ);i8r=r(mUt,"TFElectraModel"),mUt.forEach(t),d8r=r(qze," (ELECTRA model)"),qze.forEach(t),c8r=i(j),C3=n(j,"LI",{});var jze=s(C3);l0e=n(jze,"STRONG",{});var gUt=s(l0e);f8r=r(gUt,"flaubert"),gUt.forEach(t),m8r=r(jze," \u2014 "),EZ=n(jze,"A",{href:!0});var hUt=s(EZ);g8r=r(hUt,"TFFlaubertModel"),hUt.forEach(t),h8r=r(jze," (FlauBERT model)"),jze.forEach(t),u8r=i(j),bl=n(j,"LI",{});var MB=s(bl);i0e=n(MB,"STRONG",{});var uUt=s(i0e);p8r=r(uUt,"funnel"),uUt.forEach(t),_8r=r(MB," \u2014 "),CZ=n(MB,"A",{href:!0});var pUt=s(CZ);v8r=r(pUt,"TFFunnelModel"),pUt.forEach(t),b8r=r(MB," or "),wZ=n(MB,"A",{href:!0});var _Ut=s(wZ);F8r=r(_Ut,"TFFunnelBaseModel"),_Ut.forEach(t),T8r=r(MB," (Funnel Transformer model)"),MB.forEach(t),M8r=i(j),w3=n(j,"LI",{});var Dze=s(w3);d0e=n(Dze,"STRONG",{});var vUt=s(d0e);E8r=r(vUt,"gpt2"),vUt.forEach(t),C8r=r(Dze," \u2014 "),AZ=n(Dze,"A",{href:!0});var bUt=s(AZ);w8r=r(bUt,"TFGPT2Model"),bUt.forEach(t),A8r=r(Dze," (OpenAI GPT-2 model)"),Dze.forEach(t),L8r=i(j),A3=n(j,"LI",{});var Gze=s(A3);c0e=n(Gze,"STRONG",{});var FUt=s(c0e);y8r=r(FUt,"gptj"),FUt.forEach(t),x8r=r(Gze," \u2014 "),LZ=n(Gze,"A",{href:!0});var TUt=s(LZ);$8r=r(TUt,"TFGPTJModel"),TUt.forEach(t),k8r=r(Gze," (GPT-J model)"),Gze.forEach(t),S8r=i(j),L3=n(j,"LI",{});var Oze=s(L3);f0e=n(Oze,"STRONG",{});var MUt=s(f0e);R8r=r(MUt,"hubert"),MUt.forEach(t),P8r=r(Oze," \u2014 "),yZ=n(Oze,"A",{href:!0});var EUt=s(yZ);B8r=r(EUt,"TFHubertModel"),EUt.forEach(t),I8r=r(Oze," (Hubert model)"),Oze.forEach(t),N8r=i(j),y3=n(j,"LI",{});var Vze=s(y3);m0e=n(Vze,"STRONG",{});var CUt=s(m0e);q8r=r(CUt,"layoutlm"),CUt.forEach(t),j8r=r(Vze," \u2014 "),xZ=n(Vze,"A",{href:!0});var wUt=s(xZ);D8r=r(wUt,"TFLayoutLMModel"),wUt.forEach(t),G8r=r(Vze," (LayoutLM model)"),Vze.forEach(t),O8r=i(j),x3=n(j,"LI",{});var Xze=s(x3);g0e=n(Xze,"STRONG",{});var AUt=s(g0e);V8r=r(AUt,"layoutlmv3"),AUt.forEach(t),X8r=r(Xze," \u2014 "),$Z=n(Xze,"A",{href:!0});var LUt=s($Z);z8r=r(LUt,"TFLayoutLMv3Model"),LUt.forEach(t),Q8r=r(Xze," (LayoutLMv3 model)"),Xze.forEach(t),W8r=i(j),$3=n(j,"LI",{});var zze=s($3);h0e=n(zze,"STRONG",{});var yUt=s(h0e);U8r=r(yUt,"led"),yUt.forEach(t),H8r=r(zze," \u2014 "),kZ=n(zze,"A",{href:!0});var xUt=s(kZ);J8r=r(xUt,"TFLEDModel"),xUt.forEach(t),Y8r=r(zze," (LED model)"),zze.forEach(t),K8r=i(j),k3=n(j,"LI",{});var Qze=s(k3);u0e=n(Qze,"STRONG",{});var $Ut=s(u0e);Z8r=r($Ut,"longformer"),$Ut.forEach(t),e9r=r(Qze," \u2014 "),SZ=n(Qze,"A",{href:!0});var kUt=s(SZ);o9r=r(kUt,"TFLongformerModel"),kUt.forEach(t),r9r=r(Qze," (Longformer model)"),Qze.forEach(t),t9r=i(j),S3=n(j,"LI",{});var Wze=s(S3);p0e=n(Wze,"STRONG",{});var SUt=s(p0e);a9r=r(SUt,"lxmert"),SUt.forEach(t),n9r=r(Wze," \u2014 "),RZ=n(Wze,"A",{href:!0});var RUt=s(RZ);s9r=r(RUt,"TFLxmertModel"),RUt.forEach(t),l9r=r(Wze," (LXMERT model)"),Wze.forEach(t),i9r=i(j),R3=n(j,"LI",{});var Uze=s(R3);_0e=n(Uze,"STRONG",{});var PUt=s(_0e);d9r=r(PUt,"marian"),PUt.forEach(t),c9r=r(Uze," \u2014 "),PZ=n(Uze,"A",{href:!0});var BUt=s(PZ);f9r=r(BUt,"TFMarianModel"),BUt.forEach(t),m9r=r(Uze," (Marian model)"),Uze.forEach(t),g9r=i(j),P3=n(j,"LI",{});var Hze=s(P3);v0e=n(Hze,"STRONG",{});var IUt=s(v0e);h9r=r(IUt,"mbart"),IUt.forEach(t),u9r=r(Hze," \u2014 "),BZ=n(Hze,"A",{href:!0});var NUt=s(BZ);p9r=r(NUt,"TFMBartModel"),NUt.forEach(t),_9r=r(Hze," (mBART model)"),Hze.forEach(t),v9r=i(j),B3=n(j,"LI",{});var Jze=s(B3);b0e=n(Jze,"STRONG",{});var qUt=s(b0e);b9r=r(qUt,"mobilebert"),qUt.forEach(t),F9r=r(Jze," \u2014 "),IZ=n(Jze,"A",{href:!0});var jUt=s(IZ);T9r=r(jUt,"TFMobileBertModel"),jUt.forEach(t),M9r=r(Jze," (MobileBERT model)"),Jze.forEach(t),E9r=i(j),I3=n(j,"LI",{});var Yze=s(I3);F0e=n(Yze,"STRONG",{});var DUt=s(F0e);C9r=r(DUt,"mobilevit"),DUt.forEach(t),w9r=r(Yze," \u2014 "),NZ=n(Yze,"A",{href:!0});var GUt=s(NZ);A9r=r(GUt,"TFMobileViTModel"),GUt.forEach(t),L9r=r(Yze," (MobileViT model)"),Yze.forEach(t),y9r=i(j),N3=n(j,"LI",{});var Kze=s(N3);T0e=n(Kze,"STRONG",{});var OUt=s(T0e);x9r=r(OUt,"mpnet"),OUt.forEach(t),$9r=r(Kze," \u2014 "),qZ=n(Kze,"A",{href:!0});var VUt=s(qZ);k9r=r(VUt,"TFMPNetModel"),VUt.forEach(t),S9r=r(Kze," (MPNet model)"),Kze.forEach(t),R9r=i(j),q3=n(j,"LI",{});var Zze=s(q3);M0e=n(Zze,"STRONG",{});var XUt=s(M0e);P9r=r(XUt,"mt5"),XUt.forEach(t),B9r=r(Zze," \u2014 "),jZ=n(Zze,"A",{href:!0});var zUt=s(jZ);I9r=r(zUt,"TFMT5Model"),zUt.forEach(t),N9r=r(Zze," (MT5 model)"),Zze.forEach(t),q9r=i(j),j3=n(j,"LI",{});var eQe=s(j3);E0e=n(eQe,"STRONG",{});var QUt=s(E0e);j9r=r(QUt,"openai-gpt"),QUt.forEach(t),D9r=r(eQe," \u2014 "),DZ=n(eQe,"A",{href:!0});var WUt=s(DZ);G9r=r(WUt,"TFOpenAIGPTModel"),WUt.forEach(t),O9r=r(eQe," (OpenAI GPT model)"),eQe.forEach(t),V9r=i(j),D3=n(j,"LI",{});var oQe=s(D3);C0e=n(oQe,"STRONG",{});var UUt=s(C0e);X9r=r(UUt,"opt"),UUt.forEach(t),z9r=r(oQe," \u2014 "),GZ=n(oQe,"A",{href:!0});var HUt=s(GZ);Q9r=r(HUt,"TFOPTModel"),HUt.forEach(t),W9r=r(oQe," (OPT model)"),oQe.forEach(t),U9r=i(j),G3=n(j,"LI",{});var rQe=s(G3);w0e=n(rQe,"STRONG",{});var JUt=s(w0e);H9r=r(JUt,"pegasus"),JUt.forEach(t),J9r=r(rQe," \u2014 "),OZ=n(rQe,"A",{href:!0});var YUt=s(OZ);Y9r=r(YUt,"TFPegasusModel"),YUt.forEach(t),K9r=r(rQe," (Pegasus model)"),rQe.forEach(t),Z9r=i(j),O3=n(j,"LI",{});var tQe=s(O3);A0e=n(tQe,"STRONG",{});var KUt=s(A0e);exr=r(KUt,"regnet"),KUt.forEach(t),oxr=r(tQe," \u2014 "),VZ=n(tQe,"A",{href:!0});var ZUt=s(VZ);rxr=r(ZUt,"TFRegNetModel"),ZUt.forEach(t),txr=r(tQe," (RegNet model)"),tQe.forEach(t),axr=i(j),V3=n(j,"LI",{});var aQe=s(V3);L0e=n(aQe,"STRONG",{});var eHt=s(L0e);nxr=r(eHt,"rembert"),eHt.forEach(t),sxr=r(aQe," \u2014 "),XZ=n(aQe,"A",{href:!0});var oHt=s(XZ);lxr=r(oHt,"TFRemBertModel"),oHt.forEach(t),ixr=r(aQe," (RemBERT model)"),aQe.forEach(t),dxr=i(j),X3=n(j,"LI",{});var nQe=s(X3);y0e=n(nQe,"STRONG",{});var rHt=s(y0e);cxr=r(rHt,"resnet"),rHt.forEach(t),fxr=r(nQe," \u2014 "),zZ=n(nQe,"A",{href:!0});var tHt=s(zZ);mxr=r(tHt,"TFResNetModel"),tHt.forEach(t),gxr=r(nQe," (ResNet model)"),nQe.forEach(t),hxr=i(j),z3=n(j,"LI",{});var sQe=s(z3);x0e=n(sQe,"STRONG",{});var aHt=s(x0e);uxr=r(aHt,"roberta"),aHt.forEach(t),pxr=r(sQe," \u2014 "),QZ=n(sQe,"A",{href:!0});var nHt=s(QZ);_xr=r(nHt,"TFRobertaModel"),nHt.forEach(t),vxr=r(sQe," (RoBERTa model)"),sQe.forEach(t),bxr=i(j),Q3=n(j,"LI",{});var lQe=s(Q3);$0e=n(lQe,"STRONG",{});var sHt=s($0e);Fxr=r(sHt,"roformer"),sHt.forEach(t),Txr=r(lQe," \u2014 "),WZ=n(lQe,"A",{href:!0});var lHt=s(WZ);Mxr=r(lHt,"TFRoFormerModel"),lHt.forEach(t),Exr=r(lQe," (RoFormer model)"),lQe.forEach(t),Cxr=i(j),W3=n(j,"LI",{});var iQe=s(W3);k0e=n(iQe,"STRONG",{});var iHt=s(k0e);wxr=r(iHt,"segformer"),iHt.forEach(t),Axr=r(iQe," \u2014 "),UZ=n(iQe,"A",{href:!0});var dHt=s(UZ);Lxr=r(dHt,"TFSegformerModel"),dHt.forEach(t),yxr=r(iQe," (SegFormer model)"),iQe.forEach(t),xxr=i(j),U3=n(j,"LI",{});var dQe=s(U3);S0e=n(dQe,"STRONG",{});var cHt=s(S0e);$xr=r(cHt,"speech_to_text"),cHt.forEach(t),kxr=r(dQe," \u2014 "),HZ=n(dQe,"A",{href:!0});var fHt=s(HZ);Sxr=r(fHt,"TFSpeech2TextModel"),fHt.forEach(t),Rxr=r(dQe," (Speech2Text model)"),dQe.forEach(t),Pxr=i(j),H3=n(j,"LI",{});var cQe=s(H3);R0e=n(cQe,"STRONG",{});var mHt=s(R0e);Bxr=r(mHt,"swin"),mHt.forEach(t),Ixr=r(cQe," \u2014 "),JZ=n(cQe,"A",{href:!0});var gHt=s(JZ);Nxr=r(gHt,"TFSwinModel"),gHt.forEach(t),qxr=r(cQe," (Swin Transformer model)"),cQe.forEach(t),jxr=i(j),J3=n(j,"LI",{});var fQe=s(J3);P0e=n(fQe,"STRONG",{});var hHt=s(P0e);Dxr=r(hHt,"t5"),hHt.forEach(t),Gxr=r(fQe," \u2014 "),YZ=n(fQe,"A",{href:!0});var uHt=s(YZ);Oxr=r(uHt,"TFT5Model"),uHt.forEach(t),Vxr=r(fQe," (T5 model)"),fQe.forEach(t),Xxr=i(j),Y3=n(j,"LI",{});var mQe=s(Y3);B0e=n(mQe,"STRONG",{});var pHt=s(B0e);zxr=r(pHt,"tapas"),pHt.forEach(t),Qxr=r(mQe," \u2014 "),KZ=n(mQe,"A",{href:!0});var _Ht=s(KZ);Wxr=r(_Ht,"TFTapasModel"),_Ht.forEach(t),Uxr=r(mQe," (TAPAS model)"),mQe.forEach(t),Hxr=i(j),K3=n(j,"LI",{});var gQe=s(K3);I0e=n(gQe,"STRONG",{});var vHt=s(I0e);Jxr=r(vHt,"transfo-xl"),vHt.forEach(t),Yxr=r(gQe," \u2014 "),ZZ=n(gQe,"A",{href:!0});var bHt=s(ZZ);Kxr=r(bHt,"TFTransfoXLModel"),bHt.forEach(t),Zxr=r(gQe," (Transformer-XL model)"),gQe.forEach(t),e$r=i(j),Z3=n(j,"LI",{});var hQe=s(Z3);N0e=n(hQe,"STRONG",{});var FHt=s(N0e);o$r=r(FHt,"vit"),FHt.forEach(t),r$r=r(hQe," \u2014 "),eee=n(hQe,"A",{href:!0});var THt=s(eee);t$r=r(THt,"TFViTModel"),THt.forEach(t),a$r=r(hQe," (ViT model)"),hQe.forEach(t),n$r=i(j),e5=n(j,"LI",{});var uQe=s(e5);q0e=n(uQe,"STRONG",{});var MHt=s(q0e);s$r=r(MHt,"vit_mae"),MHt.forEach(t),l$r=r(uQe," \u2014 "),oee=n(uQe,"A",{href:!0});var EHt=s(oee);i$r=r(EHt,"TFViTMAEModel"),EHt.forEach(t),d$r=r(uQe," (ViTMAE model)"),uQe.forEach(t),c$r=i(j),o5=n(j,"LI",{});var pQe=s(o5);j0e=n(pQe,"STRONG",{});var CHt=s(j0e);f$r=r(CHt,"wav2vec2"),CHt.forEach(t),m$r=r(pQe," \u2014 "),ree=n(pQe,"A",{href:!0});var wHt=s(ree);g$r=r(wHt,"TFWav2Vec2Model"),wHt.forEach(t),h$r=r(pQe," (Wav2Vec2 model)"),pQe.forEach(t),u$r=i(j),r5=n(j,"LI",{});var _Qe=s(r5);D0e=n(_Qe,"STRONG",{});var AHt=s(D0e);p$r=r(AHt,"xglm"),AHt.forEach(t),_$r=r(_Qe," \u2014 "),tee=n(_Qe,"A",{href:!0});var LHt=s(tee);v$r=r(LHt,"TFXGLMModel"),LHt.forEach(t),b$r=r(_Qe," (XGLM model)"),_Qe.forEach(t),F$r=i(j),t5=n(j,"LI",{});var vQe=s(t5);G0e=n(vQe,"STRONG",{});var yHt=s(G0e);T$r=r(yHt,"xlm"),yHt.forEach(t),M$r=r(vQe," \u2014 "),aee=n(vQe,"A",{href:!0});var xHt=s(aee);E$r=r(xHt,"TFXLMModel"),xHt.forEach(t),C$r=r(vQe," (XLM model)"),vQe.forEach(t),w$r=i(j),a5=n(j,"LI",{});var bQe=s(a5);O0e=n(bQe,"STRONG",{});var $Ht=s(O0e);A$r=r($Ht,"xlm-roberta"),$Ht.forEach(t),L$r=r(bQe," \u2014 "),nee=n(bQe,"A",{href:!0});var kHt=s(nee);y$r=r(kHt,"TFXLMRobertaModel"),kHt.forEach(t),x$r=r(bQe," (XLM-RoBERTa model)"),bQe.forEach(t),$$r=i(j),n5=n(j,"LI",{});var FQe=s(n5);V0e=n(FQe,"STRONG",{});var SHt=s(V0e);k$r=r(SHt,"xlnet"),SHt.forEach(t),S$r=r(FQe," \u2014 "),see=n(FQe,"A",{href:!0});var RHt=s(see);R$r=r(RHt,"TFXLNetModel"),RHt.forEach(t),P$r=r(FQe," (XLNet model)"),FQe.forEach(t),j.forEach(t),B$r=i(oi),T(s5.$$.fragment,oi),oi.forEach(t),ei.forEach(t),XKe=i(f),Xc=n(f,"H2",{class:!0});var soo=s(Xc);l5=n(soo,"A",{id:!0,class:!0,href:!0});var PHt=s(l5);X0e=n(PHt,"SPAN",{});var BHt=s(X0e);T(Ck.$$.fragment,BHt),BHt.forEach(t),PHt.forEach(t),I$r=i(soo),z0e=n(soo,"SPAN",{});var IHt=s(z0e);N$r=r(IHt,"TFAutoModelForPreTraining"),IHt.forEach(t),soo.forEach(t),zKe=i(f),lr=n(f,"DIV",{class:!0});var ri=s(lr);T(wk.$$.fragment,ri),q$r=i(ri),zc=n(ri,"P",{});var Ule=s(zc);j$r=r(Ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lee=n(Ule,"A",{href:!0});var NHt=s(lee);D$r=r(NHt,"from_pretrained()"),NHt.forEach(t),G$r=r(Ule," class method or the "),iee=n(Ule,"A",{href:!0});var qHt=s(iee);O$r=r(qHt,"from_config()"),qHt.forEach(t),V$r=r(Ule,` class
method.`),Ule.forEach(t),X$r=i(ri),Ak=n(ri,"P",{});var loo=s(Ak);z$r=r(loo,"This class cannot be instantiated directly using "),Q0e=n(loo,"CODE",{});var jHt=s(Q0e);Q$r=r(jHt,"__init__()"),jHt.forEach(t),W$r=r(loo," (throws an error)."),loo.forEach(t),U$r=i(ri),zt=n(ri,"DIV",{class:!0});var b8=s(zt);T(Lk.$$.fragment,b8),H$r=i(b8),W0e=n(b8,"P",{});var DHt=s(W0e);J$r=r(DHt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),DHt.forEach(t),Y$r=i(b8),Qc=n(b8,"P",{});var Hle=s(Qc);K$r=r(Hle,`Note:
Loading a model from its configuration file does `),U0e=n(Hle,"STRONG",{});var GHt=s(U0e);Z$r=r(GHt,"not"),GHt.forEach(t),ekr=r(Hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=n(Hle,"A",{href:!0});var OHt=s(dee);okr=r(OHt,"from_pretrained()"),OHt.forEach(t),rkr=r(Hle," to load the model weights."),Hle.forEach(t),tkr=i(b8),T(i5.$$.fragment,b8),b8.forEach(t),akr=i(ri),Nr=n(ri,"DIV",{class:!0});var ti=s(Nr);T(yk.$$.fragment,ti),nkr=i(ti),H0e=n(ti,"P",{});var VHt=s(H0e);skr=r(VHt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),VHt.forEach(t),lkr=i(ti),wn=n(ti,"P",{});var F8=s(wn);ikr=r(F8,"The model class to instantiate is selected based on the "),J0e=n(F8,"CODE",{});var XHt=s(J0e);dkr=r(XHt,"model_type"),XHt.forEach(t),ckr=r(F8,` property of the config object (either
passed as an argument or loaded from `),Y0e=n(F8,"CODE",{});var zHt=s(Y0e);fkr=r(zHt,"pretrained_model_name_or_path"),zHt.forEach(t),mkr=r(F8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K0e=n(F8,"CODE",{});var QHt=s(K0e);gkr=r(QHt,"pretrained_model_name_or_path"),QHt.forEach(t),hkr=r(F8,":"),F8.forEach(t),ukr=i(ti),se=n(ti,"UL",{});var le=s(se);d5=n(le,"LI",{});var TQe=s(d5);Z0e=n(TQe,"STRONG",{});var WHt=s(Z0e);pkr=r(WHt,"albert"),WHt.forEach(t),_kr=r(TQe," \u2014 "),cee=n(TQe,"A",{href:!0});var UHt=s(cee);vkr=r(UHt,"TFAlbertForPreTraining"),UHt.forEach(t),bkr=r(TQe," (ALBERT model)"),TQe.forEach(t),Fkr=i(le),c5=n(le,"LI",{});var MQe=s(c5);ewe=n(MQe,"STRONG",{});var HHt=s(ewe);Tkr=r(HHt,"bart"),HHt.forEach(t),Mkr=r(MQe," \u2014 "),fee=n(MQe,"A",{href:!0});var JHt=s(fee);Ekr=r(JHt,"TFBartForConditionalGeneration"),JHt.forEach(t),Ckr=r(MQe," (BART model)"),MQe.forEach(t),wkr=i(le),f5=n(le,"LI",{});var EQe=s(f5);owe=n(EQe,"STRONG",{});var YHt=s(owe);Akr=r(YHt,"bert"),YHt.forEach(t),Lkr=r(EQe," \u2014 "),mee=n(EQe,"A",{href:!0});var KHt=s(mee);ykr=r(KHt,"TFBertForPreTraining"),KHt.forEach(t),xkr=r(EQe," (BERT model)"),EQe.forEach(t),$kr=i(le),m5=n(le,"LI",{});var CQe=s(m5);rwe=n(CQe,"STRONG",{});var ZHt=s(rwe);kkr=r(ZHt,"camembert"),ZHt.forEach(t),Skr=r(CQe," \u2014 "),gee=n(CQe,"A",{href:!0});var eJt=s(gee);Rkr=r(eJt,"TFCamembertForMaskedLM"),eJt.forEach(t),Pkr=r(CQe," (CamemBERT model)"),CQe.forEach(t),Bkr=i(le),g5=n(le,"LI",{});var wQe=s(g5);twe=n(wQe,"STRONG",{});var oJt=s(twe);Ikr=r(oJt,"ctrl"),oJt.forEach(t),Nkr=r(wQe," \u2014 "),hee=n(wQe,"A",{href:!0});var rJt=s(hee);qkr=r(rJt,"TFCTRLLMHeadModel"),rJt.forEach(t),jkr=r(wQe," (CTRL model)"),wQe.forEach(t),Dkr=i(le),h5=n(le,"LI",{});var AQe=s(h5);awe=n(AQe,"STRONG",{});var tJt=s(awe);Gkr=r(tJt,"distilbert"),tJt.forEach(t),Okr=r(AQe," \u2014 "),uee=n(AQe,"A",{href:!0});var aJt=s(uee);Vkr=r(aJt,"TFDistilBertForMaskedLM"),aJt.forEach(t),Xkr=r(AQe," (DistilBERT model)"),AQe.forEach(t),zkr=i(le),u5=n(le,"LI",{});var LQe=s(u5);nwe=n(LQe,"STRONG",{});var nJt=s(nwe);Qkr=r(nJt,"electra"),nJt.forEach(t),Wkr=r(LQe," \u2014 "),pee=n(LQe,"A",{href:!0});var sJt=s(pee);Ukr=r(sJt,"TFElectraForPreTraining"),sJt.forEach(t),Hkr=r(LQe," (ELECTRA model)"),LQe.forEach(t),Jkr=i(le),p5=n(le,"LI",{});var yQe=s(p5);swe=n(yQe,"STRONG",{});var lJt=s(swe);Ykr=r(lJt,"flaubert"),lJt.forEach(t),Kkr=r(yQe," \u2014 "),_ee=n(yQe,"A",{href:!0});var iJt=s(_ee);Zkr=r(iJt,"TFFlaubertWithLMHeadModel"),iJt.forEach(t),eSr=r(yQe," (FlauBERT model)"),yQe.forEach(t),oSr=i(le),_5=n(le,"LI",{});var xQe=s(_5);lwe=n(xQe,"STRONG",{});var dJt=s(lwe);rSr=r(dJt,"funnel"),dJt.forEach(t),tSr=r(xQe," \u2014 "),vee=n(xQe,"A",{href:!0});var cJt=s(vee);aSr=r(cJt,"TFFunnelForPreTraining"),cJt.forEach(t),nSr=r(xQe," (Funnel Transformer model)"),xQe.forEach(t),sSr=i(le),v5=n(le,"LI",{});var $Qe=s(v5);iwe=n($Qe,"STRONG",{});var fJt=s(iwe);lSr=r(fJt,"gpt2"),fJt.forEach(t),iSr=r($Qe," \u2014 "),bee=n($Qe,"A",{href:!0});var mJt=s(bee);dSr=r(mJt,"TFGPT2LMHeadModel"),mJt.forEach(t),cSr=r($Qe," (OpenAI GPT-2 model)"),$Qe.forEach(t),fSr=i(le),b5=n(le,"LI",{});var kQe=s(b5);dwe=n(kQe,"STRONG",{});var gJt=s(dwe);mSr=r(gJt,"layoutlm"),gJt.forEach(t),gSr=r(kQe," \u2014 "),Fee=n(kQe,"A",{href:!0});var hJt=s(Fee);hSr=r(hJt,"TFLayoutLMForMaskedLM"),hJt.forEach(t),uSr=r(kQe," (LayoutLM model)"),kQe.forEach(t),pSr=i(le),F5=n(le,"LI",{});var SQe=s(F5);cwe=n(SQe,"STRONG",{});var uJt=s(cwe);_Sr=r(uJt,"lxmert"),uJt.forEach(t),vSr=r(SQe," \u2014 "),Tee=n(SQe,"A",{href:!0});var pJt=s(Tee);bSr=r(pJt,"TFLxmertForPreTraining"),pJt.forEach(t),FSr=r(SQe," (LXMERT model)"),SQe.forEach(t),TSr=i(le),T5=n(le,"LI",{});var RQe=s(T5);fwe=n(RQe,"STRONG",{});var _Jt=s(fwe);MSr=r(_Jt,"mobilebert"),_Jt.forEach(t),ESr=r(RQe," \u2014 "),Mee=n(RQe,"A",{href:!0});var vJt=s(Mee);CSr=r(vJt,"TFMobileBertForPreTraining"),vJt.forEach(t),wSr=r(RQe," (MobileBERT model)"),RQe.forEach(t),ASr=i(le),M5=n(le,"LI",{});var PQe=s(M5);mwe=n(PQe,"STRONG",{});var bJt=s(mwe);LSr=r(bJt,"mpnet"),bJt.forEach(t),ySr=r(PQe," \u2014 "),Eee=n(PQe,"A",{href:!0});var FJt=s(Eee);xSr=r(FJt,"TFMPNetForMaskedLM"),FJt.forEach(t),$Sr=r(PQe," (MPNet model)"),PQe.forEach(t),kSr=i(le),E5=n(le,"LI",{});var BQe=s(E5);gwe=n(BQe,"STRONG",{});var TJt=s(gwe);SSr=r(TJt,"openai-gpt"),TJt.forEach(t),RSr=r(BQe," \u2014 "),Cee=n(BQe,"A",{href:!0});var MJt=s(Cee);PSr=r(MJt,"TFOpenAIGPTLMHeadModel"),MJt.forEach(t),BSr=r(BQe," (OpenAI GPT model)"),BQe.forEach(t),ISr=i(le),C5=n(le,"LI",{});var IQe=s(C5);hwe=n(IQe,"STRONG",{});var EJt=s(hwe);NSr=r(EJt,"roberta"),EJt.forEach(t),qSr=r(IQe," \u2014 "),wee=n(IQe,"A",{href:!0});var CJt=s(wee);jSr=r(CJt,"TFRobertaForMaskedLM"),CJt.forEach(t),DSr=r(IQe," (RoBERTa model)"),IQe.forEach(t),GSr=i(le),w5=n(le,"LI",{});var NQe=s(w5);uwe=n(NQe,"STRONG",{});var wJt=s(uwe);OSr=r(wJt,"t5"),wJt.forEach(t),VSr=r(NQe," \u2014 "),Aee=n(NQe,"A",{href:!0});var AJt=s(Aee);XSr=r(AJt,"TFT5ForConditionalGeneration"),AJt.forEach(t),zSr=r(NQe," (T5 model)"),NQe.forEach(t),QSr=i(le),A5=n(le,"LI",{});var qQe=s(A5);pwe=n(qQe,"STRONG",{});var LJt=s(pwe);WSr=r(LJt,"tapas"),LJt.forEach(t),USr=r(qQe," \u2014 "),Lee=n(qQe,"A",{href:!0});var yJt=s(Lee);HSr=r(yJt,"TFTapasForMaskedLM"),yJt.forEach(t),JSr=r(qQe," (TAPAS model)"),qQe.forEach(t),YSr=i(le),L5=n(le,"LI",{});var jQe=s(L5);_we=n(jQe,"STRONG",{});var xJt=s(_we);KSr=r(xJt,"transfo-xl"),xJt.forEach(t),ZSr=r(jQe," \u2014 "),yee=n(jQe,"A",{href:!0});var $Jt=s(yee);eRr=r($Jt,"TFTransfoXLLMHeadModel"),$Jt.forEach(t),oRr=r(jQe," (Transformer-XL model)"),jQe.forEach(t),rRr=i(le),y5=n(le,"LI",{});var DQe=s(y5);vwe=n(DQe,"STRONG",{});var kJt=s(vwe);tRr=r(kJt,"vit_mae"),kJt.forEach(t),aRr=r(DQe," \u2014 "),xee=n(DQe,"A",{href:!0});var SJt=s(xee);nRr=r(SJt,"TFViTMAEForPreTraining"),SJt.forEach(t),sRr=r(DQe," (ViTMAE model)"),DQe.forEach(t),lRr=i(le),x5=n(le,"LI",{});var GQe=s(x5);bwe=n(GQe,"STRONG",{});var RJt=s(bwe);iRr=r(RJt,"xlm"),RJt.forEach(t),dRr=r(GQe," \u2014 "),$ee=n(GQe,"A",{href:!0});var PJt=s($ee);cRr=r(PJt,"TFXLMWithLMHeadModel"),PJt.forEach(t),fRr=r(GQe," (XLM model)"),GQe.forEach(t),mRr=i(le),$5=n(le,"LI",{});var OQe=s($5);Fwe=n(OQe,"STRONG",{});var BJt=s(Fwe);gRr=r(BJt,"xlm-roberta"),BJt.forEach(t),hRr=r(OQe," \u2014 "),kee=n(OQe,"A",{href:!0});var IJt=s(kee);uRr=r(IJt,"TFXLMRobertaForMaskedLM"),IJt.forEach(t),pRr=r(OQe," (XLM-RoBERTa model)"),OQe.forEach(t),_Rr=i(le),k5=n(le,"LI",{});var VQe=s(k5);Twe=n(VQe,"STRONG",{});var NJt=s(Twe);vRr=r(NJt,"xlnet"),NJt.forEach(t),bRr=r(VQe," \u2014 "),See=n(VQe,"A",{href:!0});var qJt=s(See);FRr=r(qJt,"TFXLNetLMHeadModel"),qJt.forEach(t),TRr=r(VQe," (XLNet model)"),VQe.forEach(t),le.forEach(t),MRr=i(ti),T(S5.$$.fragment,ti),ti.forEach(t),ri.forEach(t),QKe=i(f),Wc=n(f,"H2",{class:!0});var ioo=s(Wc);R5=n(ioo,"A",{id:!0,class:!0,href:!0});var jJt=s(R5);Mwe=n(jJt,"SPAN",{});var DJt=s(Mwe);T(xk.$$.fragment,DJt),DJt.forEach(t),jJt.forEach(t),ERr=i(ioo),Ewe=n(ioo,"SPAN",{});var GJt=s(Ewe);CRr=r(GJt,"TFAutoModelForCausalLM"),GJt.forEach(t),ioo.forEach(t),WKe=i(f),ir=n(f,"DIV",{class:!0});var ai=s(ir);T($k.$$.fragment,ai),wRr=i(ai),Uc=n(ai,"P",{});var Jle=s(Uc);ARr=r(Jle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Ree=n(Jle,"A",{href:!0});var OJt=s(Ree);LRr=r(OJt,"from_pretrained()"),OJt.forEach(t),yRr=r(Jle," class method or the "),Pee=n(Jle,"A",{href:!0});var VJt=s(Pee);xRr=r(VJt,"from_config()"),VJt.forEach(t),$Rr=r(Jle,` class
method.`),Jle.forEach(t),kRr=i(ai),kk=n(ai,"P",{});var doo=s(kk);SRr=r(doo,"This class cannot be instantiated directly using "),Cwe=n(doo,"CODE",{});var XJt=s(Cwe);RRr=r(XJt,"__init__()"),XJt.forEach(t),PRr=r(doo," (throws an error)."),doo.forEach(t),BRr=i(ai),Qt=n(ai,"DIV",{class:!0});var T8=s(Qt);T(Sk.$$.fragment,T8),IRr=i(T8),wwe=n(T8,"P",{});var zJt=s(wwe);NRr=r(zJt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zJt.forEach(t),qRr=i(T8),Hc=n(T8,"P",{});var Yle=s(Hc);jRr=r(Yle,`Note:
Loading a model from its configuration file does `),Awe=n(Yle,"STRONG",{});var QJt=s(Awe);DRr=r(QJt,"not"),QJt.forEach(t),GRr=r(Yle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bee=n(Yle,"A",{href:!0});var WJt=s(Bee);ORr=r(WJt,"from_pretrained()"),WJt.forEach(t),VRr=r(Yle," to load the model weights."),Yle.forEach(t),XRr=i(T8),T(P5.$$.fragment,T8),T8.forEach(t),zRr=i(ai),qr=n(ai,"DIV",{class:!0});var ni=s(qr);T(Rk.$$.fragment,ni),QRr=i(ni),Lwe=n(ni,"P",{});var UJt=s(Lwe);WRr=r(UJt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),UJt.forEach(t),URr=i(ni),An=n(ni,"P",{});var M8=s(An);HRr=r(M8,"The model class to instantiate is selected based on the "),ywe=n(M8,"CODE",{});var HJt=s(ywe);JRr=r(HJt,"model_type"),HJt.forEach(t),YRr=r(M8,` property of the config object (either
passed as an argument or loaded from `),xwe=n(M8,"CODE",{});var JJt=s(xwe);KRr=r(JJt,"pretrained_model_name_or_path"),JJt.forEach(t),ZRr=r(M8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=n(M8,"CODE",{});var YJt=s($we);ePr=r(YJt,"pretrained_model_name_or_path"),YJt.forEach(t),oPr=r(M8,":"),M8.forEach(t),rPr=i(ni),Me=n(ni,"UL",{});var Ce=s(Me);B5=n(Ce,"LI",{});var XQe=s(B5);kwe=n(XQe,"STRONG",{});var KJt=s(kwe);tPr=r(KJt,"bert"),KJt.forEach(t),aPr=r(XQe," \u2014 "),Iee=n(XQe,"A",{href:!0});var ZJt=s(Iee);nPr=r(ZJt,"TFBertLMHeadModel"),ZJt.forEach(t),sPr=r(XQe," (BERT model)"),XQe.forEach(t),lPr=i(Ce),I5=n(Ce,"LI",{});var zQe=s(I5);Swe=n(zQe,"STRONG",{});var eYt=s(Swe);iPr=r(eYt,"camembert"),eYt.forEach(t),dPr=r(zQe," \u2014 "),Nee=n(zQe,"A",{href:!0});var oYt=s(Nee);cPr=r(oYt,"TFCamembertForCausalLM"),oYt.forEach(t),fPr=r(zQe," (CamemBERT model)"),zQe.forEach(t),mPr=i(Ce),N5=n(Ce,"LI",{});var QQe=s(N5);Rwe=n(QQe,"STRONG",{});var rYt=s(Rwe);gPr=r(rYt,"ctrl"),rYt.forEach(t),hPr=r(QQe," \u2014 "),qee=n(QQe,"A",{href:!0});var tYt=s(qee);uPr=r(tYt,"TFCTRLLMHeadModel"),tYt.forEach(t),pPr=r(QQe," (CTRL model)"),QQe.forEach(t),_Pr=i(Ce),q5=n(Ce,"LI",{});var WQe=s(q5);Pwe=n(WQe,"STRONG",{});var aYt=s(Pwe);vPr=r(aYt,"gpt2"),aYt.forEach(t),bPr=r(WQe," \u2014 "),jee=n(WQe,"A",{href:!0});var nYt=s(jee);FPr=r(nYt,"TFGPT2LMHeadModel"),nYt.forEach(t),TPr=r(WQe," (OpenAI GPT-2 model)"),WQe.forEach(t),MPr=i(Ce),j5=n(Ce,"LI",{});var UQe=s(j5);Bwe=n(UQe,"STRONG",{});var sYt=s(Bwe);EPr=r(sYt,"gptj"),sYt.forEach(t),CPr=r(UQe," \u2014 "),Dee=n(UQe,"A",{href:!0});var lYt=s(Dee);wPr=r(lYt,"TFGPTJForCausalLM"),lYt.forEach(t),APr=r(UQe," (GPT-J model)"),UQe.forEach(t),LPr=i(Ce),D5=n(Ce,"LI",{});var HQe=s(D5);Iwe=n(HQe,"STRONG",{});var iYt=s(Iwe);yPr=r(iYt,"openai-gpt"),iYt.forEach(t),xPr=r(HQe," \u2014 "),Gee=n(HQe,"A",{href:!0});var dYt=s(Gee);$Pr=r(dYt,"TFOpenAIGPTLMHeadModel"),dYt.forEach(t),kPr=r(HQe," (OpenAI GPT model)"),HQe.forEach(t),SPr=i(Ce),G5=n(Ce,"LI",{});var JQe=s(G5);Nwe=n(JQe,"STRONG",{});var cYt=s(Nwe);RPr=r(cYt,"opt"),cYt.forEach(t),PPr=r(JQe," \u2014 "),Oee=n(JQe,"A",{href:!0});var fYt=s(Oee);BPr=r(fYt,"TFOPTForCausalLM"),fYt.forEach(t),IPr=r(JQe," (OPT model)"),JQe.forEach(t),NPr=i(Ce),O5=n(Ce,"LI",{});var YQe=s(O5);qwe=n(YQe,"STRONG",{});var mYt=s(qwe);qPr=r(mYt,"rembert"),mYt.forEach(t),jPr=r(YQe," \u2014 "),Vee=n(YQe,"A",{href:!0});var gYt=s(Vee);DPr=r(gYt,"TFRemBertForCausalLM"),gYt.forEach(t),GPr=r(YQe," (RemBERT model)"),YQe.forEach(t),OPr=i(Ce),V5=n(Ce,"LI",{});var KQe=s(V5);jwe=n(KQe,"STRONG",{});var hYt=s(jwe);VPr=r(hYt,"roberta"),hYt.forEach(t),XPr=r(KQe," \u2014 "),Xee=n(KQe,"A",{href:!0});var uYt=s(Xee);zPr=r(uYt,"TFRobertaForCausalLM"),uYt.forEach(t),QPr=r(KQe," (RoBERTa model)"),KQe.forEach(t),WPr=i(Ce),X5=n(Ce,"LI",{});var ZQe=s(X5);Dwe=n(ZQe,"STRONG",{});var pYt=s(Dwe);UPr=r(pYt,"roformer"),pYt.forEach(t),HPr=r(ZQe," \u2014 "),zee=n(ZQe,"A",{href:!0});var _Yt=s(zee);JPr=r(_Yt,"TFRoFormerForCausalLM"),_Yt.forEach(t),YPr=r(ZQe," (RoFormer model)"),ZQe.forEach(t),KPr=i(Ce),z5=n(Ce,"LI",{});var eWe=s(z5);Gwe=n(eWe,"STRONG",{});var vYt=s(Gwe);ZPr=r(vYt,"transfo-xl"),vYt.forEach(t),eBr=r(eWe," \u2014 "),Qee=n(eWe,"A",{href:!0});var bYt=s(Qee);oBr=r(bYt,"TFTransfoXLLMHeadModel"),bYt.forEach(t),rBr=r(eWe," (Transformer-XL model)"),eWe.forEach(t),tBr=i(Ce),Q5=n(Ce,"LI",{});var oWe=s(Q5);Owe=n(oWe,"STRONG",{});var FYt=s(Owe);aBr=r(FYt,"xglm"),FYt.forEach(t),nBr=r(oWe," \u2014 "),Wee=n(oWe,"A",{href:!0});var TYt=s(Wee);sBr=r(TYt,"TFXGLMForCausalLM"),TYt.forEach(t),lBr=r(oWe," (XGLM model)"),oWe.forEach(t),iBr=i(Ce),W5=n(Ce,"LI",{});var rWe=s(W5);Vwe=n(rWe,"STRONG",{});var MYt=s(Vwe);dBr=r(MYt,"xlm"),MYt.forEach(t),cBr=r(rWe," \u2014 "),Uee=n(rWe,"A",{href:!0});var EYt=s(Uee);fBr=r(EYt,"TFXLMWithLMHeadModel"),EYt.forEach(t),mBr=r(rWe," (XLM model)"),rWe.forEach(t),gBr=i(Ce),U5=n(Ce,"LI",{});var tWe=s(U5);Xwe=n(tWe,"STRONG",{});var CYt=s(Xwe);hBr=r(CYt,"xlnet"),CYt.forEach(t),uBr=r(tWe," \u2014 "),Hee=n(tWe,"A",{href:!0});var wYt=s(Hee);pBr=r(wYt,"TFXLNetLMHeadModel"),wYt.forEach(t),_Br=r(tWe," (XLNet model)"),tWe.forEach(t),Ce.forEach(t),vBr=i(ni),T(H5.$$.fragment,ni),ni.forEach(t),ai.forEach(t),UKe=i(f),Jc=n(f,"H2",{class:!0});var coo=s(Jc);J5=n(coo,"A",{id:!0,class:!0,href:!0});var AYt=s(J5);zwe=n(AYt,"SPAN",{});var LYt=s(zwe);T(Pk.$$.fragment,LYt),LYt.forEach(t),AYt.forEach(t),bBr=i(coo),Qwe=n(coo,"SPAN",{});var yYt=s(Qwe);FBr=r(yYt,"TFAutoModelForImageClassification"),yYt.forEach(t),coo.forEach(t),HKe=i(f),dr=n(f,"DIV",{class:!0});var si=s(dr);T(Bk.$$.fragment,si),TBr=i(si),Yc=n(si,"P",{});var Kle=s(Yc);MBr=r(Kle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jee=n(Kle,"A",{href:!0});var xYt=s(Jee);EBr=r(xYt,"from_pretrained()"),xYt.forEach(t),CBr=r(Kle," class method or the "),Yee=n(Kle,"A",{href:!0});var $Yt=s(Yee);wBr=r($Yt,"from_config()"),$Yt.forEach(t),ABr=r(Kle,` class
method.`),Kle.forEach(t),LBr=i(si),Ik=n(si,"P",{});var foo=s(Ik);yBr=r(foo,"This class cannot be instantiated directly using "),Wwe=n(foo,"CODE",{});var kYt=s(Wwe);xBr=r(kYt,"__init__()"),kYt.forEach(t),$Br=r(foo," (throws an error)."),foo.forEach(t),kBr=i(si),Wt=n(si,"DIV",{class:!0});var E8=s(Wt);T(Nk.$$.fragment,E8),SBr=i(E8),Uwe=n(E8,"P",{});var SYt=s(Uwe);RBr=r(SYt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),SYt.forEach(t),PBr=i(E8),Kc=n(E8,"P",{});var Zle=s(Kc);BBr=r(Zle,`Note:
Loading a model from its configuration file does `),Hwe=n(Zle,"STRONG",{});var RYt=s(Hwe);IBr=r(RYt,"not"),RYt.forEach(t),NBr=r(Zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=n(Zle,"A",{href:!0});var PYt=s(Kee);qBr=r(PYt,"from_pretrained()"),PYt.forEach(t),jBr=r(Zle," to load the model weights."),Zle.forEach(t),DBr=i(E8),T(Y5.$$.fragment,E8),E8.forEach(t),GBr=i(si),jr=n(si,"DIV",{class:!0});var li=s(jr);T(qk.$$.fragment,li),OBr=i(li),Jwe=n(li,"P",{});var BYt=s(Jwe);VBr=r(BYt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BYt.forEach(t),XBr=i(li),Ln=n(li,"P",{});var C8=s(Ln);zBr=r(C8,"The model class to instantiate is selected based on the "),Ywe=n(C8,"CODE",{});var IYt=s(Ywe);QBr=r(IYt,"model_type"),IYt.forEach(t),WBr=r(C8,` property of the config object (either
passed as an argument or loaded from `),Kwe=n(C8,"CODE",{});var NYt=s(Kwe);UBr=r(NYt,"pretrained_model_name_or_path"),NYt.forEach(t),HBr=r(C8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=n(C8,"CODE",{});var qYt=s(Zwe);JBr=r(qYt,"pretrained_model_name_or_path"),qYt.forEach(t),YBr=r(C8,":"),C8.forEach(t),KBr=i(li),Be=n(li,"UL",{});var We=s(Be);K5=n(We,"LI",{});var aWe=s(K5);eAe=n(aWe,"STRONG",{});var jYt=s(eAe);ZBr=r(jYt,"convnext"),jYt.forEach(t),eIr=r(aWe," \u2014 "),Zee=n(aWe,"A",{href:!0});var DYt=s(Zee);oIr=r(DYt,"TFConvNextForImageClassification"),DYt.forEach(t),rIr=r(aWe," (ConvNeXT model)"),aWe.forEach(t),tIr=i(We),Z5=n(We,"LI",{});var nWe=s(Z5);oAe=n(nWe,"STRONG",{});var GYt=s(oAe);aIr=r(GYt,"data2vec-vision"),GYt.forEach(t),nIr=r(nWe," \u2014 "),eoe=n(nWe,"A",{href:!0});var OYt=s(eoe);sIr=r(OYt,"TFData2VecVisionForImageClassification"),OYt.forEach(t),lIr=r(nWe," (Data2VecVision model)"),nWe.forEach(t),iIr=i(We),Fl=n(We,"LI",{});var EB=s(Fl);rAe=n(EB,"STRONG",{});var VYt=s(rAe);dIr=r(VYt,"deit"),VYt.forEach(t),cIr=r(EB," \u2014 "),ooe=n(EB,"A",{href:!0});var XYt=s(ooe);fIr=r(XYt,"TFDeiTForImageClassification"),XYt.forEach(t),mIr=r(EB," or "),roe=n(EB,"A",{href:!0});var zYt=s(roe);gIr=r(zYt,"TFDeiTForImageClassificationWithTeacher"),zYt.forEach(t),hIr=r(EB," (DeiT model)"),EB.forEach(t),uIr=i(We),e0=n(We,"LI",{});var sWe=s(e0);tAe=n(sWe,"STRONG",{});var QYt=s(tAe);pIr=r(QYt,"mobilevit"),QYt.forEach(t),_Ir=r(sWe," \u2014 "),toe=n(sWe,"A",{href:!0});var WYt=s(toe);vIr=r(WYt,"TFMobileViTForImageClassification"),WYt.forEach(t),bIr=r(sWe," (MobileViT model)"),sWe.forEach(t),FIr=i(We),o0=n(We,"LI",{});var lWe=s(o0);aAe=n(lWe,"STRONG",{});var UYt=s(aAe);TIr=r(UYt,"regnet"),UYt.forEach(t),MIr=r(lWe," \u2014 "),aoe=n(lWe,"A",{href:!0});var HYt=s(aoe);EIr=r(HYt,"TFRegNetForImageClassification"),HYt.forEach(t),CIr=r(lWe," (RegNet model)"),lWe.forEach(t),wIr=i(We),r0=n(We,"LI",{});var iWe=s(r0);nAe=n(iWe,"STRONG",{});var JYt=s(nAe);AIr=r(JYt,"resnet"),JYt.forEach(t),LIr=r(iWe," \u2014 "),noe=n(iWe,"A",{href:!0});var YYt=s(noe);yIr=r(YYt,"TFResNetForImageClassification"),YYt.forEach(t),xIr=r(iWe," (ResNet model)"),iWe.forEach(t),$Ir=i(We),t0=n(We,"LI",{});var dWe=s(t0);sAe=n(dWe,"STRONG",{});var KYt=s(sAe);kIr=r(KYt,"segformer"),KYt.forEach(t),SIr=r(dWe," \u2014 "),soe=n(dWe,"A",{href:!0});var ZYt=s(soe);RIr=r(ZYt,"TFSegformerForImageClassification"),ZYt.forEach(t),PIr=r(dWe," (SegFormer model)"),dWe.forEach(t),BIr=i(We),a0=n(We,"LI",{});var cWe=s(a0);lAe=n(cWe,"STRONG",{});var eKt=s(lAe);IIr=r(eKt,"swin"),eKt.forEach(t),NIr=r(cWe," \u2014 "),loe=n(cWe,"A",{href:!0});var oKt=s(loe);qIr=r(oKt,"TFSwinForImageClassification"),oKt.forEach(t),jIr=r(cWe," (Swin Transformer model)"),cWe.forEach(t),DIr=i(We),n0=n(We,"LI",{});var fWe=s(n0);iAe=n(fWe,"STRONG",{});var rKt=s(iAe);GIr=r(rKt,"vit"),rKt.forEach(t),OIr=r(fWe," \u2014 "),ioe=n(fWe,"A",{href:!0});var tKt=s(ioe);VIr=r(tKt,"TFViTForImageClassification"),tKt.forEach(t),XIr=r(fWe," (ViT model)"),fWe.forEach(t),We.forEach(t),zIr=i(li),T(s0.$$.fragment,li),li.forEach(t),si.forEach(t),JKe=i(f),Zc=n(f,"H2",{class:!0});var moo=s(Zc);l0=n(moo,"A",{id:!0,class:!0,href:!0});var aKt=s(l0);dAe=n(aKt,"SPAN",{});var nKt=s(dAe);T(jk.$$.fragment,nKt),nKt.forEach(t),aKt.forEach(t),QIr=i(moo),cAe=n(moo,"SPAN",{});var sKt=s(cAe);WIr=r(sKt,"TFAutoModelForSemanticSegmentation"),sKt.forEach(t),moo.forEach(t),YKe=i(f),cr=n(f,"DIV",{class:!0});var ii=s(cr);T(Dk.$$.fragment,ii),UIr=i(ii),ef=n(ii,"P",{});var eie=s(ef);HIr=r(eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),doe=n(eie,"A",{href:!0});var lKt=s(doe);JIr=r(lKt,"from_pretrained()"),lKt.forEach(t),YIr=r(eie," class method or the "),coe=n(eie,"A",{href:!0});var iKt=s(coe);KIr=r(iKt,"from_config()"),iKt.forEach(t),ZIr=r(eie,` class
method.`),eie.forEach(t),eNr=i(ii),Gk=n(ii,"P",{});var goo=s(Gk);oNr=r(goo,"This class cannot be instantiated directly using "),fAe=n(goo,"CODE",{});var dKt=s(fAe);rNr=r(dKt,"__init__()"),dKt.forEach(t),tNr=r(goo," (throws an error)."),goo.forEach(t),aNr=i(ii),Ut=n(ii,"DIV",{class:!0});var w8=s(Ut);T(Ok.$$.fragment,w8),nNr=i(w8),mAe=n(w8,"P",{});var cKt=s(mAe);sNr=r(cKt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),cKt.forEach(t),lNr=i(w8),of=n(w8,"P",{});var oie=s(of);iNr=r(oie,`Note:
Loading a model from its configuration file does `),gAe=n(oie,"STRONG",{});var fKt=s(gAe);dNr=r(fKt,"not"),fKt.forEach(t),cNr=r(oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(oie,"A",{href:!0});var mKt=s(foe);fNr=r(mKt,"from_pretrained()"),mKt.forEach(t),mNr=r(oie," to load the model weights."),oie.forEach(t),gNr=i(w8),T(i0.$$.fragment,w8),w8.forEach(t),hNr=i(ii),Dr=n(ii,"DIV",{class:!0});var di=s(Dr);T(Vk.$$.fragment,di),uNr=i(di),hAe=n(di,"P",{});var gKt=s(hAe);pNr=r(gKt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),gKt.forEach(t),_Nr=i(di),yn=n(di,"P",{});var A8=s(yn);vNr=r(A8,"The model class to instantiate is selected based on the "),uAe=n(A8,"CODE",{});var hKt=s(uAe);bNr=r(hKt,"model_type"),hKt.forEach(t),FNr=r(A8,` property of the config object (either
passed as an argument or loaded from `),pAe=n(A8,"CODE",{});var uKt=s(pAe);TNr=r(uKt,"pretrained_model_name_or_path"),uKt.forEach(t),MNr=r(A8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=n(A8,"CODE",{});var pKt=s(_Ae);ENr=r(pKt,"pretrained_model_name_or_path"),pKt.forEach(t),CNr=r(A8,":"),A8.forEach(t),wNr=i(di),rf=n(di,"UL",{});var rie=s(rf);d0=n(rie,"LI",{});var mWe=s(d0);vAe=n(mWe,"STRONG",{});var _Kt=s(vAe);ANr=r(_Kt,"data2vec-vision"),_Kt.forEach(t),LNr=r(mWe," \u2014 "),moe=n(mWe,"A",{href:!0});var vKt=s(moe);yNr=r(vKt,"TFData2VecVisionForSemanticSegmentation"),vKt.forEach(t),xNr=r(mWe," (Data2VecVision model)"),mWe.forEach(t),$Nr=i(rie),c0=n(rie,"LI",{});var gWe=s(c0);bAe=n(gWe,"STRONG",{});var bKt=s(bAe);kNr=r(bKt,"mobilevit"),bKt.forEach(t),SNr=r(gWe," \u2014 "),goe=n(gWe,"A",{href:!0});var FKt=s(goe);RNr=r(FKt,"TFMobileViTForSemanticSegmentation"),FKt.forEach(t),PNr=r(gWe," (MobileViT model)"),gWe.forEach(t),BNr=i(rie),f0=n(rie,"LI",{});var hWe=s(f0);FAe=n(hWe,"STRONG",{});var TKt=s(FAe);INr=r(TKt,"segformer"),TKt.forEach(t),NNr=r(hWe," \u2014 "),hoe=n(hWe,"A",{href:!0});var MKt=s(hoe);qNr=r(MKt,"TFSegformerForSemanticSegmentation"),MKt.forEach(t),jNr=r(hWe," (SegFormer model)"),hWe.forEach(t),rie.forEach(t),DNr=i(di),T(m0.$$.fragment,di),di.forEach(t),ii.forEach(t),KKe=i(f),tf=n(f,"H2",{class:!0});var hoo=s(tf);g0=n(hoo,"A",{id:!0,class:!0,href:!0});var EKt=s(g0);TAe=n(EKt,"SPAN",{});var CKt=s(TAe);T(Xk.$$.fragment,CKt),CKt.forEach(t),EKt.forEach(t),GNr=i(hoo),MAe=n(hoo,"SPAN",{});var wKt=s(MAe);ONr=r(wKt,"TFAutoModelForMaskedLM"),wKt.forEach(t),hoo.forEach(t),ZKe=i(f),fr=n(f,"DIV",{class:!0});var ci=s(fr);T(zk.$$.fragment,ci),VNr=i(ci),af=n(ci,"P",{});var tie=s(af);XNr=r(tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uoe=n(tie,"A",{href:!0});var AKt=s(uoe);zNr=r(AKt,"from_pretrained()"),AKt.forEach(t),QNr=r(tie," class method or the "),poe=n(tie,"A",{href:!0});var LKt=s(poe);WNr=r(LKt,"from_config()"),LKt.forEach(t),UNr=r(tie,` class
method.`),tie.forEach(t),HNr=i(ci),Qk=n(ci,"P",{});var uoo=s(Qk);JNr=r(uoo,"This class cannot be instantiated directly using "),EAe=n(uoo,"CODE",{});var yKt=s(EAe);YNr=r(yKt,"__init__()"),yKt.forEach(t),KNr=r(uoo," (throws an error)."),uoo.forEach(t),ZNr=i(ci),Ht=n(ci,"DIV",{class:!0});var L8=s(Ht);T(Wk.$$.fragment,L8),eqr=i(L8),CAe=n(L8,"P",{});var xKt=s(CAe);oqr=r(xKt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xKt.forEach(t),rqr=i(L8),nf=n(L8,"P",{});var aie=s(nf);tqr=r(aie,`Note:
Loading a model from its configuration file does `),wAe=n(aie,"STRONG",{});var $Kt=s(wAe);aqr=r($Kt,"not"),$Kt.forEach(t),nqr=r(aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(aie,"A",{href:!0});var kKt=s(_oe);sqr=r(kKt,"from_pretrained()"),kKt.forEach(t),lqr=r(aie," to load the model weights."),aie.forEach(t),iqr=i(L8),T(h0.$$.fragment,L8),L8.forEach(t),dqr=i(ci),Gr=n(ci,"DIV",{class:!0});var fi=s(Gr);T(Uk.$$.fragment,fi),cqr=i(fi),AAe=n(fi,"P",{});var SKt=s(AAe);fqr=r(SKt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),SKt.forEach(t),mqr=i(fi),xn=n(fi,"P",{});var y8=s(xn);gqr=r(y8,"The model class to instantiate is selected based on the "),LAe=n(y8,"CODE",{});var RKt=s(LAe);hqr=r(RKt,"model_type"),RKt.forEach(t),uqr=r(y8,` property of the config object (either
passed as an argument or loaded from `),yAe=n(y8,"CODE",{});var PKt=s(yAe);pqr=r(PKt,"pretrained_model_name_or_path"),PKt.forEach(t),_qr=r(y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=n(y8,"CODE",{});var BKt=s(xAe);vqr=r(BKt,"pretrained_model_name_or_path"),BKt.forEach(t),bqr=r(y8,":"),y8.forEach(t),Fqr=i(fi),me=n(fi,"UL",{});var _e=s(me);u0=n(_e,"LI",{});var uWe=s(u0);$Ae=n(uWe,"STRONG",{});var IKt=s($Ae);Tqr=r(IKt,"albert"),IKt.forEach(t),Mqr=r(uWe," \u2014 "),voe=n(uWe,"A",{href:!0});var NKt=s(voe);Eqr=r(NKt,"TFAlbertForMaskedLM"),NKt.forEach(t),Cqr=r(uWe," (ALBERT model)"),uWe.forEach(t),wqr=i(_e),p0=n(_e,"LI",{});var pWe=s(p0);kAe=n(pWe,"STRONG",{});var qKt=s(kAe);Aqr=r(qKt,"bert"),qKt.forEach(t),Lqr=r(pWe," \u2014 "),boe=n(pWe,"A",{href:!0});var jKt=s(boe);yqr=r(jKt,"TFBertForMaskedLM"),jKt.forEach(t),xqr=r(pWe," (BERT model)"),pWe.forEach(t),$qr=i(_e),_0=n(_e,"LI",{});var _We=s(_0);SAe=n(_We,"STRONG",{});var DKt=s(SAe);kqr=r(DKt,"camembert"),DKt.forEach(t),Sqr=r(_We," \u2014 "),Foe=n(_We,"A",{href:!0});var GKt=s(Foe);Rqr=r(GKt,"TFCamembertForMaskedLM"),GKt.forEach(t),Pqr=r(_We," (CamemBERT model)"),_We.forEach(t),Bqr=i(_e),v0=n(_e,"LI",{});var vWe=s(v0);RAe=n(vWe,"STRONG",{});var OKt=s(RAe);Iqr=r(OKt,"convbert"),OKt.forEach(t),Nqr=r(vWe," \u2014 "),Toe=n(vWe,"A",{href:!0});var VKt=s(Toe);qqr=r(VKt,"TFConvBertForMaskedLM"),VKt.forEach(t),jqr=r(vWe," (ConvBERT model)"),vWe.forEach(t),Dqr=i(_e),b0=n(_e,"LI",{});var bWe=s(b0);PAe=n(bWe,"STRONG",{});var XKt=s(PAe);Gqr=r(XKt,"deberta"),XKt.forEach(t),Oqr=r(bWe," \u2014 "),Moe=n(bWe,"A",{href:!0});var zKt=s(Moe);Vqr=r(zKt,"TFDebertaForMaskedLM"),zKt.forEach(t),Xqr=r(bWe," (DeBERTa model)"),bWe.forEach(t),zqr=i(_e),F0=n(_e,"LI",{});var FWe=s(F0);BAe=n(FWe,"STRONG",{});var QKt=s(BAe);Qqr=r(QKt,"deberta-v2"),QKt.forEach(t),Wqr=r(FWe," \u2014 "),Eoe=n(FWe,"A",{href:!0});var WKt=s(Eoe);Uqr=r(WKt,"TFDebertaV2ForMaskedLM"),WKt.forEach(t),Hqr=r(FWe," (DeBERTa-v2 model)"),FWe.forEach(t),Jqr=i(_e),T0=n(_e,"LI",{});var TWe=s(T0);IAe=n(TWe,"STRONG",{});var UKt=s(IAe);Yqr=r(UKt,"distilbert"),UKt.forEach(t),Kqr=r(TWe," \u2014 "),Coe=n(TWe,"A",{href:!0});var HKt=s(Coe);Zqr=r(HKt,"TFDistilBertForMaskedLM"),HKt.forEach(t),ejr=r(TWe," (DistilBERT model)"),TWe.forEach(t),ojr=i(_e),M0=n(_e,"LI",{});var MWe=s(M0);NAe=n(MWe,"STRONG",{});var JKt=s(NAe);rjr=r(JKt,"electra"),JKt.forEach(t),tjr=r(MWe," \u2014 "),woe=n(MWe,"A",{href:!0});var YKt=s(woe);ajr=r(YKt,"TFElectraForMaskedLM"),YKt.forEach(t),njr=r(MWe," (ELECTRA model)"),MWe.forEach(t),sjr=i(_e),E0=n(_e,"LI",{});var EWe=s(E0);qAe=n(EWe,"STRONG",{});var KKt=s(qAe);ljr=r(KKt,"flaubert"),KKt.forEach(t),ijr=r(EWe," \u2014 "),Aoe=n(EWe,"A",{href:!0});var ZKt=s(Aoe);djr=r(ZKt,"TFFlaubertWithLMHeadModel"),ZKt.forEach(t),cjr=r(EWe," (FlauBERT model)"),EWe.forEach(t),fjr=i(_e),C0=n(_e,"LI",{});var CWe=s(C0);jAe=n(CWe,"STRONG",{});var eZt=s(jAe);mjr=r(eZt,"funnel"),eZt.forEach(t),gjr=r(CWe," \u2014 "),Loe=n(CWe,"A",{href:!0});var oZt=s(Loe);hjr=r(oZt,"TFFunnelForMaskedLM"),oZt.forEach(t),ujr=r(CWe," (Funnel Transformer model)"),CWe.forEach(t),pjr=i(_e),w0=n(_e,"LI",{});var wWe=s(w0);DAe=n(wWe,"STRONG",{});var rZt=s(DAe);_jr=r(rZt,"layoutlm"),rZt.forEach(t),vjr=r(wWe," \u2014 "),yoe=n(wWe,"A",{href:!0});var tZt=s(yoe);bjr=r(tZt,"TFLayoutLMForMaskedLM"),tZt.forEach(t),Fjr=r(wWe," (LayoutLM model)"),wWe.forEach(t),Tjr=i(_e),A0=n(_e,"LI",{});var AWe=s(A0);GAe=n(AWe,"STRONG",{});var aZt=s(GAe);Mjr=r(aZt,"longformer"),aZt.forEach(t),Ejr=r(AWe," \u2014 "),xoe=n(AWe,"A",{href:!0});var nZt=s(xoe);Cjr=r(nZt,"TFLongformerForMaskedLM"),nZt.forEach(t),wjr=r(AWe," (Longformer model)"),AWe.forEach(t),Ajr=i(_e),L0=n(_e,"LI",{});var LWe=s(L0);OAe=n(LWe,"STRONG",{});var sZt=s(OAe);Ljr=r(sZt,"mobilebert"),sZt.forEach(t),yjr=r(LWe," \u2014 "),$oe=n(LWe,"A",{href:!0});var lZt=s($oe);xjr=r(lZt,"TFMobileBertForMaskedLM"),lZt.forEach(t),$jr=r(LWe," (MobileBERT model)"),LWe.forEach(t),kjr=i(_e),y0=n(_e,"LI",{});var yWe=s(y0);VAe=n(yWe,"STRONG",{});var iZt=s(VAe);Sjr=r(iZt,"mpnet"),iZt.forEach(t),Rjr=r(yWe," \u2014 "),koe=n(yWe,"A",{href:!0});var dZt=s(koe);Pjr=r(dZt,"TFMPNetForMaskedLM"),dZt.forEach(t),Bjr=r(yWe," (MPNet model)"),yWe.forEach(t),Ijr=i(_e),x0=n(_e,"LI",{});var xWe=s(x0);XAe=n(xWe,"STRONG",{});var cZt=s(XAe);Njr=r(cZt,"rembert"),cZt.forEach(t),qjr=r(xWe," \u2014 "),Soe=n(xWe,"A",{href:!0});var fZt=s(Soe);jjr=r(fZt,"TFRemBertForMaskedLM"),fZt.forEach(t),Djr=r(xWe," (RemBERT model)"),xWe.forEach(t),Gjr=i(_e),$0=n(_e,"LI",{});var $We=s($0);zAe=n($We,"STRONG",{});var mZt=s(zAe);Ojr=r(mZt,"roberta"),mZt.forEach(t),Vjr=r($We," \u2014 "),Roe=n($We,"A",{href:!0});var gZt=s(Roe);Xjr=r(gZt,"TFRobertaForMaskedLM"),gZt.forEach(t),zjr=r($We," (RoBERTa model)"),$We.forEach(t),Qjr=i(_e),k0=n(_e,"LI",{});var kWe=s(k0);QAe=n(kWe,"STRONG",{});var hZt=s(QAe);Wjr=r(hZt,"roformer"),hZt.forEach(t),Ujr=r(kWe," \u2014 "),Poe=n(kWe,"A",{href:!0});var uZt=s(Poe);Hjr=r(uZt,"TFRoFormerForMaskedLM"),uZt.forEach(t),Jjr=r(kWe," (RoFormer model)"),kWe.forEach(t),Yjr=i(_e),S0=n(_e,"LI",{});var SWe=s(S0);WAe=n(SWe,"STRONG",{});var pZt=s(WAe);Kjr=r(pZt,"tapas"),pZt.forEach(t),Zjr=r(SWe," \u2014 "),Boe=n(SWe,"A",{href:!0});var _Zt=s(Boe);eDr=r(_Zt,"TFTapasForMaskedLM"),_Zt.forEach(t),oDr=r(SWe," (TAPAS model)"),SWe.forEach(t),rDr=i(_e),R0=n(_e,"LI",{});var RWe=s(R0);UAe=n(RWe,"STRONG",{});var vZt=s(UAe);tDr=r(vZt,"xlm"),vZt.forEach(t),aDr=r(RWe," \u2014 "),Ioe=n(RWe,"A",{href:!0});var bZt=s(Ioe);nDr=r(bZt,"TFXLMWithLMHeadModel"),bZt.forEach(t),sDr=r(RWe," (XLM model)"),RWe.forEach(t),lDr=i(_e),P0=n(_e,"LI",{});var PWe=s(P0);HAe=n(PWe,"STRONG",{});var FZt=s(HAe);iDr=r(FZt,"xlm-roberta"),FZt.forEach(t),dDr=r(PWe," \u2014 "),Noe=n(PWe,"A",{href:!0});var TZt=s(Noe);cDr=r(TZt,"TFXLMRobertaForMaskedLM"),TZt.forEach(t),fDr=r(PWe," (XLM-RoBERTa model)"),PWe.forEach(t),_e.forEach(t),mDr=i(fi),T(B0.$$.fragment,fi),fi.forEach(t),ci.forEach(t),eZe=i(f),sf=n(f,"H2",{class:!0});var poo=s(sf);I0=n(poo,"A",{id:!0,class:!0,href:!0});var MZt=s(I0);JAe=n(MZt,"SPAN",{});var EZt=s(JAe);T(Hk.$$.fragment,EZt),EZt.forEach(t),MZt.forEach(t),gDr=i(poo),YAe=n(poo,"SPAN",{});var CZt=s(YAe);hDr=r(CZt,"TFAutoModelForSeq2SeqLM"),CZt.forEach(t),poo.forEach(t),oZe=i(f),mr=n(f,"DIV",{class:!0});var mi=s(mr);T(Jk.$$.fragment,mi),uDr=i(mi),lf=n(mi,"P",{});var nie=s(lf);pDr=r(nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qoe=n(nie,"A",{href:!0});var wZt=s(qoe);_Dr=r(wZt,"from_pretrained()"),wZt.forEach(t),vDr=r(nie," class method or the "),joe=n(nie,"A",{href:!0});var AZt=s(joe);bDr=r(AZt,"from_config()"),AZt.forEach(t),FDr=r(nie,` class
method.`),nie.forEach(t),TDr=i(mi),Yk=n(mi,"P",{});var _oo=s(Yk);MDr=r(_oo,"This class cannot be instantiated directly using "),KAe=n(_oo,"CODE",{});var LZt=s(KAe);EDr=r(LZt,"__init__()"),LZt.forEach(t),CDr=r(_oo," (throws an error)."),_oo.forEach(t),wDr=i(mi),Jt=n(mi,"DIV",{class:!0});var x8=s(Jt);T(Kk.$$.fragment,x8),ADr=i(x8),ZAe=n(x8,"P",{});var yZt=s(ZAe);LDr=r(yZt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yZt.forEach(t),yDr=i(x8),df=n(x8,"P",{});var sie=s(df);xDr=r(sie,`Note:
Loading a model from its configuration file does `),e6e=n(sie,"STRONG",{});var xZt=s(e6e);$Dr=r(xZt,"not"),xZt.forEach(t),kDr=r(sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=n(sie,"A",{href:!0});var $Zt=s(Doe);SDr=r($Zt,"from_pretrained()"),$Zt.forEach(t),RDr=r(sie," to load the model weights."),sie.forEach(t),PDr=i(x8),T(N0.$$.fragment,x8),x8.forEach(t),BDr=i(mi),Or=n(mi,"DIV",{class:!0});var gi=s(Or);T(Zk.$$.fragment,gi),IDr=i(gi),o6e=n(gi,"P",{});var kZt=s(o6e);NDr=r(kZt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kZt.forEach(t),qDr=i(gi),$n=n(gi,"P",{});var $8=s($n);jDr=r($8,"The model class to instantiate is selected based on the "),r6e=n($8,"CODE",{});var SZt=s(r6e);DDr=r(SZt,"model_type"),SZt.forEach(t),GDr=r($8,` property of the config object (either
passed as an argument or loaded from `),t6e=n($8,"CODE",{});var RZt=s(t6e);ODr=r(RZt,"pretrained_model_name_or_path"),RZt.forEach(t),VDr=r($8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a6e=n($8,"CODE",{});var PZt=s(a6e);XDr=r(PZt,"pretrained_model_name_or_path"),PZt.forEach(t),zDr=r($8,":"),$8.forEach(t),QDr=i(gi),ye=n(gi,"UL",{});var Ne=s(ye);q0=n(Ne,"LI",{});var BWe=s(q0);n6e=n(BWe,"STRONG",{});var BZt=s(n6e);WDr=r(BZt,"bart"),BZt.forEach(t),UDr=r(BWe," \u2014 "),Goe=n(BWe,"A",{href:!0});var IZt=s(Goe);HDr=r(IZt,"TFBartForConditionalGeneration"),IZt.forEach(t),JDr=r(BWe," (BART model)"),BWe.forEach(t),YDr=i(Ne),j0=n(Ne,"LI",{});var IWe=s(j0);s6e=n(IWe,"STRONG",{});var NZt=s(s6e);KDr=r(NZt,"blenderbot"),NZt.forEach(t),ZDr=r(IWe," \u2014 "),Ooe=n(IWe,"A",{href:!0});var qZt=s(Ooe);eGr=r(qZt,"TFBlenderbotForConditionalGeneration"),qZt.forEach(t),oGr=r(IWe," (Blenderbot model)"),IWe.forEach(t),rGr=i(Ne),D0=n(Ne,"LI",{});var NWe=s(D0);l6e=n(NWe,"STRONG",{});var jZt=s(l6e);tGr=r(jZt,"blenderbot-small"),jZt.forEach(t),aGr=r(NWe," \u2014 "),Voe=n(NWe,"A",{href:!0});var DZt=s(Voe);nGr=r(DZt,"TFBlenderbotSmallForConditionalGeneration"),DZt.forEach(t),sGr=r(NWe," (BlenderbotSmall model)"),NWe.forEach(t),lGr=i(Ne),G0=n(Ne,"LI",{});var qWe=s(G0);i6e=n(qWe,"STRONG",{});var GZt=s(i6e);iGr=r(GZt,"encoder-decoder"),GZt.forEach(t),dGr=r(qWe," \u2014 "),Xoe=n(qWe,"A",{href:!0});var OZt=s(Xoe);cGr=r(OZt,"TFEncoderDecoderModel"),OZt.forEach(t),fGr=r(qWe," (Encoder decoder model)"),qWe.forEach(t),mGr=i(Ne),O0=n(Ne,"LI",{});var jWe=s(O0);d6e=n(jWe,"STRONG",{});var VZt=s(d6e);gGr=r(VZt,"led"),VZt.forEach(t),hGr=r(jWe," \u2014 "),zoe=n(jWe,"A",{href:!0});var XZt=s(zoe);uGr=r(XZt,"TFLEDForConditionalGeneration"),XZt.forEach(t),pGr=r(jWe," (LED model)"),jWe.forEach(t),_Gr=i(Ne),V0=n(Ne,"LI",{});var DWe=s(V0);c6e=n(DWe,"STRONG",{});var zZt=s(c6e);vGr=r(zZt,"marian"),zZt.forEach(t),bGr=r(DWe," \u2014 "),Qoe=n(DWe,"A",{href:!0});var QZt=s(Qoe);FGr=r(QZt,"TFMarianMTModel"),QZt.forEach(t),TGr=r(DWe," (Marian model)"),DWe.forEach(t),MGr=i(Ne),X0=n(Ne,"LI",{});var GWe=s(X0);f6e=n(GWe,"STRONG",{});var WZt=s(f6e);EGr=r(WZt,"mbart"),WZt.forEach(t),CGr=r(GWe," \u2014 "),Woe=n(GWe,"A",{href:!0});var UZt=s(Woe);wGr=r(UZt,"TFMBartForConditionalGeneration"),UZt.forEach(t),AGr=r(GWe," (mBART model)"),GWe.forEach(t),LGr=i(Ne),z0=n(Ne,"LI",{});var OWe=s(z0);m6e=n(OWe,"STRONG",{});var HZt=s(m6e);yGr=r(HZt,"mt5"),HZt.forEach(t),xGr=r(OWe," \u2014 "),Uoe=n(OWe,"A",{href:!0});var JZt=s(Uoe);$Gr=r(JZt,"TFMT5ForConditionalGeneration"),JZt.forEach(t),kGr=r(OWe," (MT5 model)"),OWe.forEach(t),SGr=i(Ne),Q0=n(Ne,"LI",{});var VWe=s(Q0);g6e=n(VWe,"STRONG",{});var YZt=s(g6e);RGr=r(YZt,"pegasus"),YZt.forEach(t),PGr=r(VWe," \u2014 "),Hoe=n(VWe,"A",{href:!0});var KZt=s(Hoe);BGr=r(KZt,"TFPegasusForConditionalGeneration"),KZt.forEach(t),IGr=r(VWe," (Pegasus model)"),VWe.forEach(t),NGr=i(Ne),W0=n(Ne,"LI",{});var XWe=s(W0);h6e=n(XWe,"STRONG",{});var ZZt=s(h6e);qGr=r(ZZt,"t5"),ZZt.forEach(t),jGr=r(XWe," \u2014 "),Joe=n(XWe,"A",{href:!0});var eea=s(Joe);DGr=r(eea,"TFT5ForConditionalGeneration"),eea.forEach(t),GGr=r(XWe," (T5 model)"),XWe.forEach(t),Ne.forEach(t),OGr=i(gi),T(U0.$$.fragment,gi),gi.forEach(t),mi.forEach(t),rZe=i(f),cf=n(f,"H2",{class:!0});var voo=s(cf);H0=n(voo,"A",{id:!0,class:!0,href:!0});var oea=s(H0);u6e=n(oea,"SPAN",{});var rea=s(u6e);T(eS.$$.fragment,rea),rea.forEach(t),oea.forEach(t),VGr=i(voo),p6e=n(voo,"SPAN",{});var tea=s(p6e);XGr=r(tea,"TFAutoModelForSequenceClassification"),tea.forEach(t),voo.forEach(t),tZe=i(f),gr=n(f,"DIV",{class:!0});var hi=s(gr);T(oS.$$.fragment,hi),zGr=i(hi),ff=n(hi,"P",{});var lie=s(ff);QGr=r(lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yoe=n(lie,"A",{href:!0});var aea=s(Yoe);WGr=r(aea,"from_pretrained()"),aea.forEach(t),UGr=r(lie," class method or the "),Koe=n(lie,"A",{href:!0});var nea=s(Koe);HGr=r(nea,"from_config()"),nea.forEach(t),JGr=r(lie,` class
method.`),lie.forEach(t),YGr=i(hi),rS=n(hi,"P",{});var boo=s(rS);KGr=r(boo,"This class cannot be instantiated directly using "),_6e=n(boo,"CODE",{});var sea=s(_6e);ZGr=r(sea,"__init__()"),sea.forEach(t),eOr=r(boo," (throws an error)."),boo.forEach(t),oOr=i(hi),Yt=n(hi,"DIV",{class:!0});var k8=s(Yt);T(tS.$$.fragment,k8),rOr=i(k8),v6e=n(k8,"P",{});var lea=s(v6e);tOr=r(lea,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lea.forEach(t),aOr=i(k8),mf=n(k8,"P",{});var iie=s(mf);nOr=r(iie,`Note:
Loading a model from its configuration file does `),b6e=n(iie,"STRONG",{});var iea=s(b6e);sOr=r(iea,"not"),iea.forEach(t),lOr=r(iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=n(iie,"A",{href:!0});var dea=s(Zoe);iOr=r(dea,"from_pretrained()"),dea.forEach(t),dOr=r(iie," to load the model weights."),iie.forEach(t),cOr=i(k8),T(J0.$$.fragment,k8),k8.forEach(t),fOr=i(hi),Vr=n(hi,"DIV",{class:!0});var ui=s(Vr);T(aS.$$.fragment,ui),mOr=i(ui),F6e=n(ui,"P",{});var cea=s(F6e);gOr=r(cea,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cea.forEach(t),hOr=i(ui),kn=n(ui,"P",{});var S8=s(kn);uOr=r(S8,"The model class to instantiate is selected based on the "),T6e=n(S8,"CODE",{});var fea=s(T6e);pOr=r(fea,"model_type"),fea.forEach(t),_Or=r(S8,` property of the config object (either
passed as an argument or loaded from `),M6e=n(S8,"CODE",{});var mea=s(M6e);vOr=r(mea,"pretrained_model_name_or_path"),mea.forEach(t),bOr=r(S8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=n(S8,"CODE",{});var gea=s(E6e);FOr=r(gea,"pretrained_model_name_or_path"),gea.forEach(t),TOr=r(S8,":"),S8.forEach(t),MOr=i(ui),re=n(ui,"UL",{});var ae=s(re);Y0=n(ae,"LI",{});var zWe=s(Y0);C6e=n(zWe,"STRONG",{});var hea=s(C6e);EOr=r(hea,"albert"),hea.forEach(t),COr=r(zWe," \u2014 "),ere=n(zWe,"A",{href:!0});var uea=s(ere);wOr=r(uea,"TFAlbertForSequenceClassification"),uea.forEach(t),AOr=r(zWe," (ALBERT model)"),zWe.forEach(t),LOr=i(ae),K0=n(ae,"LI",{});var QWe=s(K0);w6e=n(QWe,"STRONG",{});var pea=s(w6e);yOr=r(pea,"bert"),pea.forEach(t),xOr=r(QWe," \u2014 "),ore=n(QWe,"A",{href:!0});var _ea=s(ore);$Or=r(_ea,"TFBertForSequenceClassification"),_ea.forEach(t),kOr=r(QWe," (BERT model)"),QWe.forEach(t),SOr=i(ae),Z0=n(ae,"LI",{});var WWe=s(Z0);A6e=n(WWe,"STRONG",{});var vea=s(A6e);ROr=r(vea,"camembert"),vea.forEach(t),POr=r(WWe," \u2014 "),rre=n(WWe,"A",{href:!0});var bea=s(rre);BOr=r(bea,"TFCamembertForSequenceClassification"),bea.forEach(t),IOr=r(WWe," (CamemBERT model)"),WWe.forEach(t),NOr=i(ae),ew=n(ae,"LI",{});var UWe=s(ew);L6e=n(UWe,"STRONG",{});var Fea=s(L6e);qOr=r(Fea,"convbert"),Fea.forEach(t),jOr=r(UWe," \u2014 "),tre=n(UWe,"A",{href:!0});var Tea=s(tre);DOr=r(Tea,"TFConvBertForSequenceClassification"),Tea.forEach(t),GOr=r(UWe," (ConvBERT model)"),UWe.forEach(t),OOr=i(ae),ow=n(ae,"LI",{});var HWe=s(ow);y6e=n(HWe,"STRONG",{});var Mea=s(y6e);VOr=r(Mea,"ctrl"),Mea.forEach(t),XOr=r(HWe," \u2014 "),are=n(HWe,"A",{href:!0});var Eea=s(are);zOr=r(Eea,"TFCTRLForSequenceClassification"),Eea.forEach(t),QOr=r(HWe," (CTRL model)"),HWe.forEach(t),WOr=i(ae),rw=n(ae,"LI",{});var JWe=s(rw);x6e=n(JWe,"STRONG",{});var Cea=s(x6e);UOr=r(Cea,"deberta"),Cea.forEach(t),HOr=r(JWe," \u2014 "),nre=n(JWe,"A",{href:!0});var wea=s(nre);JOr=r(wea,"TFDebertaForSequenceClassification"),wea.forEach(t),YOr=r(JWe," (DeBERTa model)"),JWe.forEach(t),KOr=i(ae),tw=n(ae,"LI",{});var YWe=s(tw);$6e=n(YWe,"STRONG",{});var Aea=s($6e);ZOr=r(Aea,"deberta-v2"),Aea.forEach(t),eVr=r(YWe," \u2014 "),sre=n(YWe,"A",{href:!0});var Lea=s(sre);oVr=r(Lea,"TFDebertaV2ForSequenceClassification"),Lea.forEach(t),rVr=r(YWe," (DeBERTa-v2 model)"),YWe.forEach(t),tVr=i(ae),aw=n(ae,"LI",{});var KWe=s(aw);k6e=n(KWe,"STRONG",{});var yea=s(k6e);aVr=r(yea,"distilbert"),yea.forEach(t),nVr=r(KWe," \u2014 "),lre=n(KWe,"A",{href:!0});var xea=s(lre);sVr=r(xea,"TFDistilBertForSequenceClassification"),xea.forEach(t),lVr=r(KWe," (DistilBERT model)"),KWe.forEach(t),iVr=i(ae),nw=n(ae,"LI",{});var ZWe=s(nw);S6e=n(ZWe,"STRONG",{});var $ea=s(S6e);dVr=r($ea,"electra"),$ea.forEach(t),cVr=r(ZWe," \u2014 "),ire=n(ZWe,"A",{href:!0});var kea=s(ire);fVr=r(kea,"TFElectraForSequenceClassification"),kea.forEach(t),mVr=r(ZWe," (ELECTRA model)"),ZWe.forEach(t),gVr=i(ae),sw=n(ae,"LI",{});var eUe=s(sw);R6e=n(eUe,"STRONG",{});var Sea=s(R6e);hVr=r(Sea,"flaubert"),Sea.forEach(t),uVr=r(eUe," \u2014 "),dre=n(eUe,"A",{href:!0});var Rea=s(dre);pVr=r(Rea,"TFFlaubertForSequenceClassification"),Rea.forEach(t),_Vr=r(eUe," (FlauBERT model)"),eUe.forEach(t),vVr=i(ae),lw=n(ae,"LI",{});var oUe=s(lw);P6e=n(oUe,"STRONG",{});var Pea=s(P6e);bVr=r(Pea,"funnel"),Pea.forEach(t),FVr=r(oUe," \u2014 "),cre=n(oUe,"A",{href:!0});var Bea=s(cre);TVr=r(Bea,"TFFunnelForSequenceClassification"),Bea.forEach(t),MVr=r(oUe," (Funnel Transformer model)"),oUe.forEach(t),EVr=i(ae),iw=n(ae,"LI",{});var rUe=s(iw);B6e=n(rUe,"STRONG",{});var Iea=s(B6e);CVr=r(Iea,"gpt2"),Iea.forEach(t),wVr=r(rUe," \u2014 "),fre=n(rUe,"A",{href:!0});var Nea=s(fre);AVr=r(Nea,"TFGPT2ForSequenceClassification"),Nea.forEach(t),LVr=r(rUe," (OpenAI GPT-2 model)"),rUe.forEach(t),yVr=i(ae),dw=n(ae,"LI",{});var tUe=s(dw);I6e=n(tUe,"STRONG",{});var qea=s(I6e);xVr=r(qea,"gptj"),qea.forEach(t),$Vr=r(tUe," \u2014 "),mre=n(tUe,"A",{href:!0});var jea=s(mre);kVr=r(jea,"TFGPTJForSequenceClassification"),jea.forEach(t),SVr=r(tUe," (GPT-J model)"),tUe.forEach(t),RVr=i(ae),cw=n(ae,"LI",{});var aUe=s(cw);N6e=n(aUe,"STRONG",{});var Dea=s(N6e);PVr=r(Dea,"layoutlm"),Dea.forEach(t),BVr=r(aUe," \u2014 "),gre=n(aUe,"A",{href:!0});var Gea=s(gre);IVr=r(Gea,"TFLayoutLMForSequenceClassification"),Gea.forEach(t),NVr=r(aUe," (LayoutLM model)"),aUe.forEach(t),qVr=i(ae),fw=n(ae,"LI",{});var nUe=s(fw);q6e=n(nUe,"STRONG",{});var Oea=s(q6e);jVr=r(Oea,"layoutlmv3"),Oea.forEach(t),DVr=r(nUe," \u2014 "),hre=n(nUe,"A",{href:!0});var Vea=s(hre);GVr=r(Vea,"TFLayoutLMv3ForSequenceClassification"),Vea.forEach(t),OVr=r(nUe," (LayoutLMv3 model)"),nUe.forEach(t),VVr=i(ae),mw=n(ae,"LI",{});var sUe=s(mw);j6e=n(sUe,"STRONG",{});var Xea=s(j6e);XVr=r(Xea,"longformer"),Xea.forEach(t),zVr=r(sUe," \u2014 "),ure=n(sUe,"A",{href:!0});var zea=s(ure);QVr=r(zea,"TFLongformerForSequenceClassification"),zea.forEach(t),WVr=r(sUe," (Longformer model)"),sUe.forEach(t),UVr=i(ae),gw=n(ae,"LI",{});var lUe=s(gw);D6e=n(lUe,"STRONG",{});var Qea=s(D6e);HVr=r(Qea,"mobilebert"),Qea.forEach(t),JVr=r(lUe," \u2014 "),pre=n(lUe,"A",{href:!0});var Wea=s(pre);YVr=r(Wea,"TFMobileBertForSequenceClassification"),Wea.forEach(t),KVr=r(lUe," (MobileBERT model)"),lUe.forEach(t),ZVr=i(ae),hw=n(ae,"LI",{});var iUe=s(hw);G6e=n(iUe,"STRONG",{});var Uea=s(G6e);eXr=r(Uea,"mpnet"),Uea.forEach(t),oXr=r(iUe," \u2014 "),_re=n(iUe,"A",{href:!0});var Hea=s(_re);rXr=r(Hea,"TFMPNetForSequenceClassification"),Hea.forEach(t),tXr=r(iUe," (MPNet model)"),iUe.forEach(t),aXr=i(ae),uw=n(ae,"LI",{});var dUe=s(uw);O6e=n(dUe,"STRONG",{});var Jea=s(O6e);nXr=r(Jea,"openai-gpt"),Jea.forEach(t),sXr=r(dUe," \u2014 "),vre=n(dUe,"A",{href:!0});var Yea=s(vre);lXr=r(Yea,"TFOpenAIGPTForSequenceClassification"),Yea.forEach(t),iXr=r(dUe," (OpenAI GPT model)"),dUe.forEach(t),dXr=i(ae),pw=n(ae,"LI",{});var cUe=s(pw);V6e=n(cUe,"STRONG",{});var Kea=s(V6e);cXr=r(Kea,"rembert"),Kea.forEach(t),fXr=r(cUe," \u2014 "),bre=n(cUe,"A",{href:!0});var Zea=s(bre);mXr=r(Zea,"TFRemBertForSequenceClassification"),Zea.forEach(t),gXr=r(cUe," (RemBERT model)"),cUe.forEach(t),hXr=i(ae),_w=n(ae,"LI",{});var fUe=s(_w);X6e=n(fUe,"STRONG",{});var eoa=s(X6e);uXr=r(eoa,"roberta"),eoa.forEach(t),pXr=r(fUe," \u2014 "),Fre=n(fUe,"A",{href:!0});var ooa=s(Fre);_Xr=r(ooa,"TFRobertaForSequenceClassification"),ooa.forEach(t),vXr=r(fUe," (RoBERTa model)"),fUe.forEach(t),bXr=i(ae),vw=n(ae,"LI",{});var mUe=s(vw);z6e=n(mUe,"STRONG",{});var roa=s(z6e);FXr=r(roa,"roformer"),roa.forEach(t),TXr=r(mUe," \u2014 "),Tre=n(mUe,"A",{href:!0});var toa=s(Tre);MXr=r(toa,"TFRoFormerForSequenceClassification"),toa.forEach(t),EXr=r(mUe," (RoFormer model)"),mUe.forEach(t),CXr=i(ae),bw=n(ae,"LI",{});var gUe=s(bw);Q6e=n(gUe,"STRONG",{});var aoa=s(Q6e);wXr=r(aoa,"tapas"),aoa.forEach(t),AXr=r(gUe," \u2014 "),Mre=n(gUe,"A",{href:!0});var noa=s(Mre);LXr=r(noa,"TFTapasForSequenceClassification"),noa.forEach(t),yXr=r(gUe," (TAPAS model)"),gUe.forEach(t),xXr=i(ae),Fw=n(ae,"LI",{});var hUe=s(Fw);W6e=n(hUe,"STRONG",{});var soa=s(W6e);$Xr=r(soa,"transfo-xl"),soa.forEach(t),kXr=r(hUe," \u2014 "),Ere=n(hUe,"A",{href:!0});var loa=s(Ere);SXr=r(loa,"TFTransfoXLForSequenceClassification"),loa.forEach(t),RXr=r(hUe," (Transformer-XL model)"),hUe.forEach(t),PXr=i(ae),Tw=n(ae,"LI",{});var uUe=s(Tw);U6e=n(uUe,"STRONG",{});var ioa=s(U6e);BXr=r(ioa,"xlm"),ioa.forEach(t),IXr=r(uUe," \u2014 "),Cre=n(uUe,"A",{href:!0});var doa=s(Cre);NXr=r(doa,"TFXLMForSequenceClassification"),doa.forEach(t),qXr=r(uUe," (XLM model)"),uUe.forEach(t),jXr=i(ae),Mw=n(ae,"LI",{});var pUe=s(Mw);H6e=n(pUe,"STRONG",{});var coa=s(H6e);DXr=r(coa,"xlm-roberta"),coa.forEach(t),GXr=r(pUe," \u2014 "),wre=n(pUe,"A",{href:!0});var foa=s(wre);OXr=r(foa,"TFXLMRobertaForSequenceClassification"),foa.forEach(t),VXr=r(pUe," (XLM-RoBERTa model)"),pUe.forEach(t),XXr=i(ae),Ew=n(ae,"LI",{});var _Ue=s(Ew);J6e=n(_Ue,"STRONG",{});var moa=s(J6e);zXr=r(moa,"xlnet"),moa.forEach(t),QXr=r(_Ue," \u2014 "),Are=n(_Ue,"A",{href:!0});var goa=s(Are);WXr=r(goa,"TFXLNetForSequenceClassification"),goa.forEach(t),UXr=r(_Ue," (XLNet model)"),_Ue.forEach(t),ae.forEach(t),HXr=i(ui),T(Cw.$$.fragment,ui),ui.forEach(t),hi.forEach(t),aZe=i(f),gf=n(f,"H2",{class:!0});var Foo=s(gf);ww=n(Foo,"A",{id:!0,class:!0,href:!0});var hoa=s(ww);Y6e=n(hoa,"SPAN",{});var uoa=s(Y6e);T(nS.$$.fragment,uoa),uoa.forEach(t),hoa.forEach(t),JXr=i(Foo),K6e=n(Foo,"SPAN",{});var poa=s(K6e);YXr=r(poa,"TFAutoModelForMultipleChoice"),poa.forEach(t),Foo.forEach(t),nZe=i(f),hr=n(f,"DIV",{class:!0});var pi=s(hr);T(sS.$$.fragment,pi),KXr=i(pi),hf=n(pi,"P",{});var die=s(hf);ZXr=r(die,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lre=n(die,"A",{href:!0});var _oa=s(Lre);ezr=r(_oa,"from_pretrained()"),_oa.forEach(t),ozr=r(die," class method or the "),yre=n(die,"A",{href:!0});var voa=s(yre);rzr=r(voa,"from_config()"),voa.forEach(t),tzr=r(die,` class
method.`),die.forEach(t),azr=i(pi),lS=n(pi,"P",{});var Too=s(lS);nzr=r(Too,"This class cannot be instantiated directly using "),Z6e=n(Too,"CODE",{});var boa=s(Z6e);szr=r(boa,"__init__()"),boa.forEach(t),lzr=r(Too," (throws an error)."),Too.forEach(t),izr=i(pi),Kt=n(pi,"DIV",{class:!0});var R8=s(Kt);T(iS.$$.fragment,R8),dzr=i(R8),e7e=n(R8,"P",{});var Foa=s(e7e);czr=r(Foa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Foa.forEach(t),fzr=i(R8),uf=n(R8,"P",{});var cie=s(uf);mzr=r(cie,`Note:
Loading a model from its configuration file does `),o7e=n(cie,"STRONG",{});var Toa=s(o7e);gzr=r(Toa,"not"),Toa.forEach(t),hzr=r(cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=n(cie,"A",{href:!0});var Moa=s(xre);uzr=r(Moa,"from_pretrained()"),Moa.forEach(t),pzr=r(cie," to load the model weights."),cie.forEach(t),_zr=i(R8),T(Aw.$$.fragment,R8),R8.forEach(t),vzr=i(pi),Xr=n(pi,"DIV",{class:!0});var _i=s(Xr);T(dS.$$.fragment,_i),bzr=i(_i),r7e=n(_i,"P",{});var Eoa=s(r7e);Fzr=r(Eoa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Eoa.forEach(t),Tzr=i(_i),Sn=n(_i,"P",{});var P8=s(Sn);Mzr=r(P8,"The model class to instantiate is selected based on the "),t7e=n(P8,"CODE",{});var Coa=s(t7e);Ezr=r(Coa,"model_type"),Coa.forEach(t),Czr=r(P8,` property of the config object (either
passed as an argument or loaded from `),a7e=n(P8,"CODE",{});var woa=s(a7e);wzr=r(woa,"pretrained_model_name_or_path"),woa.forEach(t),Azr=r(P8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(P8,"CODE",{});var Aoa=s(n7e);Lzr=r(Aoa,"pretrained_model_name_or_path"),Aoa.forEach(t),yzr=r(P8,":"),P8.forEach(t),xzr=i(_i),be=n(_i,"UL",{});var Te=s(be);Lw=n(Te,"LI",{});var vUe=s(Lw);s7e=n(vUe,"STRONG",{});var Loa=s(s7e);$zr=r(Loa,"albert"),Loa.forEach(t),kzr=r(vUe," \u2014 "),$re=n(vUe,"A",{href:!0});var yoa=s($re);Szr=r(yoa,"TFAlbertForMultipleChoice"),yoa.forEach(t),Rzr=r(vUe," (ALBERT model)"),vUe.forEach(t),Pzr=i(Te),yw=n(Te,"LI",{});var bUe=s(yw);l7e=n(bUe,"STRONG",{});var xoa=s(l7e);Bzr=r(xoa,"bert"),xoa.forEach(t),Izr=r(bUe," \u2014 "),kre=n(bUe,"A",{href:!0});var $oa=s(kre);Nzr=r($oa,"TFBertForMultipleChoice"),$oa.forEach(t),qzr=r(bUe," (BERT model)"),bUe.forEach(t),jzr=i(Te),xw=n(Te,"LI",{});var FUe=s(xw);i7e=n(FUe,"STRONG",{});var koa=s(i7e);Dzr=r(koa,"camembert"),koa.forEach(t),Gzr=r(FUe," \u2014 "),Sre=n(FUe,"A",{href:!0});var Soa=s(Sre);Ozr=r(Soa,"TFCamembertForMultipleChoice"),Soa.forEach(t),Vzr=r(FUe," (CamemBERT model)"),FUe.forEach(t),Xzr=i(Te),$w=n(Te,"LI",{});var TUe=s($w);d7e=n(TUe,"STRONG",{});var Roa=s(d7e);zzr=r(Roa,"convbert"),Roa.forEach(t),Qzr=r(TUe," \u2014 "),Rre=n(TUe,"A",{href:!0});var Poa=s(Rre);Wzr=r(Poa,"TFConvBertForMultipleChoice"),Poa.forEach(t),Uzr=r(TUe," (ConvBERT model)"),TUe.forEach(t),Hzr=i(Te),kw=n(Te,"LI",{});var MUe=s(kw);c7e=n(MUe,"STRONG",{});var Boa=s(c7e);Jzr=r(Boa,"distilbert"),Boa.forEach(t),Yzr=r(MUe," \u2014 "),Pre=n(MUe,"A",{href:!0});var Ioa=s(Pre);Kzr=r(Ioa,"TFDistilBertForMultipleChoice"),Ioa.forEach(t),Zzr=r(MUe," (DistilBERT model)"),MUe.forEach(t),eQr=i(Te),Sw=n(Te,"LI",{});var EUe=s(Sw);f7e=n(EUe,"STRONG",{});var Noa=s(f7e);oQr=r(Noa,"electra"),Noa.forEach(t),rQr=r(EUe," \u2014 "),Bre=n(EUe,"A",{href:!0});var qoa=s(Bre);tQr=r(qoa,"TFElectraForMultipleChoice"),qoa.forEach(t),aQr=r(EUe," (ELECTRA model)"),EUe.forEach(t),nQr=i(Te),Rw=n(Te,"LI",{});var CUe=s(Rw);m7e=n(CUe,"STRONG",{});var joa=s(m7e);sQr=r(joa,"flaubert"),joa.forEach(t),lQr=r(CUe," \u2014 "),Ire=n(CUe,"A",{href:!0});var Doa=s(Ire);iQr=r(Doa,"TFFlaubertForMultipleChoice"),Doa.forEach(t),dQr=r(CUe," (FlauBERT model)"),CUe.forEach(t),cQr=i(Te),Pw=n(Te,"LI",{});var wUe=s(Pw);g7e=n(wUe,"STRONG",{});var Goa=s(g7e);fQr=r(Goa,"funnel"),Goa.forEach(t),mQr=r(wUe," \u2014 "),Nre=n(wUe,"A",{href:!0});var Ooa=s(Nre);gQr=r(Ooa,"TFFunnelForMultipleChoice"),Ooa.forEach(t),hQr=r(wUe," (Funnel Transformer model)"),wUe.forEach(t),uQr=i(Te),Bw=n(Te,"LI",{});var AUe=s(Bw);h7e=n(AUe,"STRONG",{});var Voa=s(h7e);pQr=r(Voa,"longformer"),Voa.forEach(t),_Qr=r(AUe," \u2014 "),qre=n(AUe,"A",{href:!0});var Xoa=s(qre);vQr=r(Xoa,"TFLongformerForMultipleChoice"),Xoa.forEach(t),bQr=r(AUe," (Longformer model)"),AUe.forEach(t),FQr=i(Te),Iw=n(Te,"LI",{});var LUe=s(Iw);u7e=n(LUe,"STRONG",{});var zoa=s(u7e);TQr=r(zoa,"mobilebert"),zoa.forEach(t),MQr=r(LUe," \u2014 "),jre=n(LUe,"A",{href:!0});var Qoa=s(jre);EQr=r(Qoa,"TFMobileBertForMultipleChoice"),Qoa.forEach(t),CQr=r(LUe," (MobileBERT model)"),LUe.forEach(t),wQr=i(Te),Nw=n(Te,"LI",{});var yUe=s(Nw);p7e=n(yUe,"STRONG",{});var Woa=s(p7e);AQr=r(Woa,"mpnet"),Woa.forEach(t),LQr=r(yUe," \u2014 "),Dre=n(yUe,"A",{href:!0});var Uoa=s(Dre);yQr=r(Uoa,"TFMPNetForMultipleChoice"),Uoa.forEach(t),xQr=r(yUe," (MPNet model)"),yUe.forEach(t),$Qr=i(Te),qw=n(Te,"LI",{});var xUe=s(qw);_7e=n(xUe,"STRONG",{});var Hoa=s(_7e);kQr=r(Hoa,"rembert"),Hoa.forEach(t),SQr=r(xUe," \u2014 "),Gre=n(xUe,"A",{href:!0});var Joa=s(Gre);RQr=r(Joa,"TFRemBertForMultipleChoice"),Joa.forEach(t),PQr=r(xUe," (RemBERT model)"),xUe.forEach(t),BQr=i(Te),jw=n(Te,"LI",{});var $Ue=s(jw);v7e=n($Ue,"STRONG",{});var Yoa=s(v7e);IQr=r(Yoa,"roberta"),Yoa.forEach(t),NQr=r($Ue," \u2014 "),Ore=n($Ue,"A",{href:!0});var Koa=s(Ore);qQr=r(Koa,"TFRobertaForMultipleChoice"),Koa.forEach(t),jQr=r($Ue," (RoBERTa model)"),$Ue.forEach(t),DQr=i(Te),Dw=n(Te,"LI",{});var kUe=s(Dw);b7e=n(kUe,"STRONG",{});var Zoa=s(b7e);GQr=r(Zoa,"roformer"),Zoa.forEach(t),OQr=r(kUe," \u2014 "),Vre=n(kUe,"A",{href:!0});var era=s(Vre);VQr=r(era,"TFRoFormerForMultipleChoice"),era.forEach(t),XQr=r(kUe," (RoFormer model)"),kUe.forEach(t),zQr=i(Te),Gw=n(Te,"LI",{});var SUe=s(Gw);F7e=n(SUe,"STRONG",{});var ora=s(F7e);QQr=r(ora,"xlm"),ora.forEach(t),WQr=r(SUe," \u2014 "),Xre=n(SUe,"A",{href:!0});var rra=s(Xre);UQr=r(rra,"TFXLMForMultipleChoice"),rra.forEach(t),HQr=r(SUe," (XLM model)"),SUe.forEach(t),JQr=i(Te),Ow=n(Te,"LI",{});var RUe=s(Ow);T7e=n(RUe,"STRONG",{});var tra=s(T7e);YQr=r(tra,"xlm-roberta"),tra.forEach(t),KQr=r(RUe," \u2014 "),zre=n(RUe,"A",{href:!0});var ara=s(zre);ZQr=r(ara,"TFXLMRobertaForMultipleChoice"),ara.forEach(t),eWr=r(RUe," (XLM-RoBERTa model)"),RUe.forEach(t),oWr=i(Te),Vw=n(Te,"LI",{});var PUe=s(Vw);M7e=n(PUe,"STRONG",{});var nra=s(M7e);rWr=r(nra,"xlnet"),nra.forEach(t),tWr=r(PUe," \u2014 "),Qre=n(PUe,"A",{href:!0});var sra=s(Qre);aWr=r(sra,"TFXLNetForMultipleChoice"),sra.forEach(t),nWr=r(PUe," (XLNet model)"),PUe.forEach(t),Te.forEach(t),sWr=i(_i),T(Xw.$$.fragment,_i),_i.forEach(t),pi.forEach(t),sZe=i(f),pf=n(f,"H2",{class:!0});var Moo=s(pf);zw=n(Moo,"A",{id:!0,class:!0,href:!0});var lra=s(zw);E7e=n(lra,"SPAN",{});var ira=s(E7e);T(cS.$$.fragment,ira),ira.forEach(t),lra.forEach(t),lWr=i(Moo),C7e=n(Moo,"SPAN",{});var dra=s(C7e);iWr=r(dra,"TFAutoModelForNextSentencePrediction"),dra.forEach(t),Moo.forEach(t),lZe=i(f),ur=n(f,"DIV",{class:!0});var vi=s(ur);T(fS.$$.fragment,vi),dWr=i(vi),_f=n(vi,"P",{});var fie=s(_f);cWr=r(fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wre=n(fie,"A",{href:!0});var cra=s(Wre);fWr=r(cra,"from_pretrained()"),cra.forEach(t),mWr=r(fie," class method or the "),Ure=n(fie,"A",{href:!0});var fra=s(Ure);gWr=r(fra,"from_config()"),fra.forEach(t),hWr=r(fie,` class
method.`),fie.forEach(t),uWr=i(vi),mS=n(vi,"P",{});var Eoo=s(mS);pWr=r(Eoo,"This class cannot be instantiated directly using "),w7e=n(Eoo,"CODE",{});var mra=s(w7e);_Wr=r(mra,"__init__()"),mra.forEach(t),vWr=r(Eoo," (throws an error)."),Eoo.forEach(t),bWr=i(vi),Zt=n(vi,"DIV",{class:!0});var B8=s(Zt);T(gS.$$.fragment,B8),FWr=i(B8),A7e=n(B8,"P",{});var gra=s(A7e);TWr=r(gra,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gra.forEach(t),MWr=i(B8),vf=n(B8,"P",{});var mie=s(vf);EWr=r(mie,`Note:
Loading a model from its configuration file does `),L7e=n(mie,"STRONG",{});var hra=s(L7e);CWr=r(hra,"not"),hra.forEach(t),wWr=r(mie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hre=n(mie,"A",{href:!0});var ura=s(Hre);AWr=r(ura,"from_pretrained()"),ura.forEach(t),LWr=r(mie," to load the model weights."),mie.forEach(t),yWr=i(B8),T(Qw.$$.fragment,B8),B8.forEach(t),xWr=i(vi),zr=n(vi,"DIV",{class:!0});var bi=s(zr);T(hS.$$.fragment,bi),$Wr=i(bi),y7e=n(bi,"P",{});var pra=s(y7e);kWr=r(pra,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),pra.forEach(t),SWr=i(bi),Rn=n(bi,"P",{});var I8=s(Rn);RWr=r(I8,"The model class to instantiate is selected based on the "),x7e=n(I8,"CODE",{});var _ra=s(x7e);PWr=r(_ra,"model_type"),_ra.forEach(t),BWr=r(I8,` property of the config object (either
passed as an argument or loaded from `),$7e=n(I8,"CODE",{});var vra=s($7e);IWr=r(vra,"pretrained_model_name_or_path"),vra.forEach(t),NWr=r(I8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k7e=n(I8,"CODE",{});var bra=s(k7e);qWr=r(bra,"pretrained_model_name_or_path"),bra.forEach(t),jWr=r(I8,":"),I8.forEach(t),DWr=i(bi),uS=n(bi,"UL",{});var Coo=s(uS);Ww=n(Coo,"LI",{});var BUe=s(Ww);S7e=n(BUe,"STRONG",{});var Fra=s(S7e);GWr=r(Fra,"bert"),Fra.forEach(t),OWr=r(BUe," \u2014 "),Jre=n(BUe,"A",{href:!0});var Tra=s(Jre);VWr=r(Tra,"TFBertForNextSentencePrediction"),Tra.forEach(t),XWr=r(BUe," (BERT model)"),BUe.forEach(t),zWr=i(Coo),Uw=n(Coo,"LI",{});var IUe=s(Uw);R7e=n(IUe,"STRONG",{});var Mra=s(R7e);QWr=r(Mra,"mobilebert"),Mra.forEach(t),WWr=r(IUe," \u2014 "),Yre=n(IUe,"A",{href:!0});var Era=s(Yre);UWr=r(Era,"TFMobileBertForNextSentencePrediction"),Era.forEach(t),HWr=r(IUe," (MobileBERT model)"),IUe.forEach(t),Coo.forEach(t),JWr=i(bi),T(Hw.$$.fragment,bi),bi.forEach(t),vi.forEach(t),iZe=i(f),bf=n(f,"H2",{class:!0});var woo=s(bf);Jw=n(woo,"A",{id:!0,class:!0,href:!0});var Cra=s(Jw);P7e=n(Cra,"SPAN",{});var wra=s(P7e);T(pS.$$.fragment,wra),wra.forEach(t),Cra.forEach(t),YWr=i(woo),B7e=n(woo,"SPAN",{});var Ara=s(B7e);KWr=r(Ara,"TFAutoModelForTableQuestionAnswering"),Ara.forEach(t),woo.forEach(t),dZe=i(f),pr=n(f,"DIV",{class:!0});var Fi=s(pr);T(_S.$$.fragment,Fi),ZWr=i(Fi),Ff=n(Fi,"P",{});var gie=s(Ff);eUr=r(gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kre=n(gie,"A",{href:!0});var Lra=s(Kre);oUr=r(Lra,"from_pretrained()"),Lra.forEach(t),rUr=r(gie," class method or the "),Zre=n(gie,"A",{href:!0});var yra=s(Zre);tUr=r(yra,"from_config()"),yra.forEach(t),aUr=r(gie,` class
method.`),gie.forEach(t),nUr=i(Fi),vS=n(Fi,"P",{});var Aoo=s(vS);sUr=r(Aoo,"This class cannot be instantiated directly using "),I7e=n(Aoo,"CODE",{});var xra=s(I7e);lUr=r(xra,"__init__()"),xra.forEach(t),iUr=r(Aoo," (throws an error)."),Aoo.forEach(t),dUr=i(Fi),ea=n(Fi,"DIV",{class:!0});var N8=s(ea);T(bS.$$.fragment,N8),cUr=i(N8),N7e=n(N8,"P",{});var $ra=s(N7e);fUr=r($ra,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$ra.forEach(t),mUr=i(N8),Tf=n(N8,"P",{});var hie=s(Tf);gUr=r(hie,`Note:
Loading a model from its configuration file does `),q7e=n(hie,"STRONG",{});var kra=s(q7e);hUr=r(kra,"not"),kra.forEach(t),uUr=r(hie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=n(hie,"A",{href:!0});var Sra=s(ete);pUr=r(Sra,"from_pretrained()"),Sra.forEach(t),_Ur=r(hie," to load the model weights."),hie.forEach(t),vUr=i(N8),T(Yw.$$.fragment,N8),N8.forEach(t),bUr=i(Fi),Qr=n(Fi,"DIV",{class:!0});var Ti=s(Qr);T(FS.$$.fragment,Ti),FUr=i(Ti),j7e=n(Ti,"P",{});var Rra=s(j7e);TUr=r(Rra,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Rra.forEach(t),MUr=i(Ti),Pn=n(Ti,"P",{});var q8=s(Pn);EUr=r(q8,"The model class to instantiate is selected based on the "),D7e=n(q8,"CODE",{});var Pra=s(D7e);CUr=r(Pra,"model_type"),Pra.forEach(t),wUr=r(q8,` property of the config object (either
passed as an argument or loaded from `),G7e=n(q8,"CODE",{});var Bra=s(G7e);AUr=r(Bra,"pretrained_model_name_or_path"),Bra.forEach(t),LUr=r(q8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(q8,"CODE",{});var Ira=s(O7e);yUr=r(Ira,"pretrained_model_name_or_path"),Ira.forEach(t),xUr=r(q8,":"),q8.forEach(t),$Ur=i(Ti),V7e=n(Ti,"UL",{});var Nra=s(V7e);Kw=n(Nra,"LI",{});var NUe=s(Kw);X7e=n(NUe,"STRONG",{});var qra=s(X7e);kUr=r(qra,"tapas"),qra.forEach(t),SUr=r(NUe," \u2014 "),ote=n(NUe,"A",{href:!0});var jra=s(ote);RUr=r(jra,"TFTapasForQuestionAnswering"),jra.forEach(t),PUr=r(NUe," (TAPAS model)"),NUe.forEach(t),Nra.forEach(t),BUr=i(Ti),T(Zw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),cZe=i(f),Mf=n(f,"H2",{class:!0});var Loo=s(Mf);eA=n(Loo,"A",{id:!0,class:!0,href:!0});var Dra=s(eA);z7e=n(Dra,"SPAN",{});var Gra=s(z7e);T(TS.$$.fragment,Gra),Gra.forEach(t),Dra.forEach(t),IUr=i(Loo),Q7e=n(Loo,"SPAN",{});var Ora=s(Q7e);NUr=r(Ora,"TFAutoModelForDocumentQuestionAnswering"),Ora.forEach(t),Loo.forEach(t),fZe=i(f),_r=n(f,"DIV",{class:!0});var Mi=s(_r);T(MS.$$.fragment,Mi),qUr=i(Mi),Ef=n(Mi,"P",{});var uie=s(Ef);jUr=r(uie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),rte=n(uie,"A",{href:!0});var Vra=s(rte);DUr=r(Vra,"from_pretrained()"),Vra.forEach(t),GUr=r(uie," class method or the "),tte=n(uie,"A",{href:!0});var Xra=s(tte);OUr=r(Xra,"from_config()"),Xra.forEach(t),VUr=r(uie,` class
method.`),uie.forEach(t),XUr=i(Mi),ES=n(Mi,"P",{});var yoo=s(ES);zUr=r(yoo,"This class cannot be instantiated directly using "),W7e=n(yoo,"CODE",{});var zra=s(W7e);QUr=r(zra,"__init__()"),zra.forEach(t),WUr=r(yoo," (throws an error)."),yoo.forEach(t),UUr=i(Mi),oa=n(Mi,"DIV",{class:!0});var j8=s(oa);T(CS.$$.fragment,j8),HUr=i(j8),U7e=n(j8,"P",{});var Qra=s(U7e);JUr=r(Qra,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Qra.forEach(t),YUr=i(j8),Cf=n(j8,"P",{});var pie=s(Cf);KUr=r(pie,`Note:
Loading a model from its configuration file does `),H7e=n(pie,"STRONG",{});var Wra=s(H7e);ZUr=r(Wra,"not"),Wra.forEach(t),eHr=r(pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=n(pie,"A",{href:!0});var Ura=s(ate);oHr=r(Ura,"from_pretrained()"),Ura.forEach(t),rHr=r(pie," to load the model weights."),pie.forEach(t),tHr=i(j8),T(oA.$$.fragment,j8),j8.forEach(t),aHr=i(Mi),Wr=n(Mi,"DIV",{class:!0});var Ei=s(Wr);T(wS.$$.fragment,Ei),nHr=i(Ei),J7e=n(Ei,"P",{});var Hra=s(J7e);sHr=r(Hra,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Hra.forEach(t),lHr=i(Ei),Bn=n(Ei,"P",{});var D8=s(Bn);iHr=r(D8,"The model class to instantiate is selected based on the "),Y7e=n(D8,"CODE",{});var Jra=s(Y7e);dHr=r(Jra,"model_type"),Jra.forEach(t),cHr=r(D8,` property of the config object (either
passed as an argument or loaded from `),K7e=n(D8,"CODE",{});var Yra=s(K7e);fHr=r(Yra,"pretrained_model_name_or_path"),Yra.forEach(t),mHr=r(D8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z7e=n(D8,"CODE",{});var Kra=s(Z7e);gHr=r(Kra,"pretrained_model_name_or_path"),Kra.forEach(t),hHr=r(D8,":"),D8.forEach(t),uHr=i(Ei),eLe=n(Ei,"UL",{});var Zra=s(eLe);rA=n(Zra,"LI",{});var qUe=s(rA);oLe=n(qUe,"STRONG",{});var eta=s(oLe);pHr=r(eta,"layoutlm"),eta.forEach(t),_Hr=r(qUe," \u2014 "),nte=n(qUe,"A",{href:!0});var ota=s(nte);vHr=r(ota,"TFLayoutLMForQuestionAnswering"),ota.forEach(t),bHr=r(qUe," (LayoutLM model)"),qUe.forEach(t),Zra.forEach(t),FHr=i(Ei),T(tA.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),mZe=i(f),wf=n(f,"H2",{class:!0});var xoo=s(wf);aA=n(xoo,"A",{id:!0,class:!0,href:!0});var rta=s(aA);rLe=n(rta,"SPAN",{});var tta=s(rLe);T(AS.$$.fragment,tta),tta.forEach(t),rta.forEach(t),THr=i(xoo),tLe=n(xoo,"SPAN",{});var ata=s(tLe);MHr=r(ata,"TFAutoModelForTokenClassification"),ata.forEach(t),xoo.forEach(t),gZe=i(f),vr=n(f,"DIV",{class:!0});var Ci=s(vr);T(LS.$$.fragment,Ci),EHr=i(Ci),Af=n(Ci,"P",{});var _ie=s(Af);CHr=r(_ie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ste=n(_ie,"A",{href:!0});var nta=s(ste);wHr=r(nta,"from_pretrained()"),nta.forEach(t),AHr=r(_ie," class method or the "),lte=n(_ie,"A",{href:!0});var sta=s(lte);LHr=r(sta,"from_config()"),sta.forEach(t),yHr=r(_ie,` class
method.`),_ie.forEach(t),xHr=i(Ci),yS=n(Ci,"P",{});var $oo=s(yS);$Hr=r($oo,"This class cannot be instantiated directly using "),aLe=n($oo,"CODE",{});var lta=s(aLe);kHr=r(lta,"__init__()"),lta.forEach(t),SHr=r($oo," (throws an error)."),$oo.forEach(t),RHr=i(Ci),ra=n(Ci,"DIV",{class:!0});var G8=s(ra);T(xS.$$.fragment,G8),PHr=i(G8),nLe=n(G8,"P",{});var ita=s(nLe);BHr=r(ita,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ita.forEach(t),IHr=i(G8),Lf=n(G8,"P",{});var vie=s(Lf);NHr=r(vie,`Note:
Loading a model from its configuration file does `),sLe=n(vie,"STRONG",{});var dta=s(sLe);qHr=r(dta,"not"),dta.forEach(t),jHr=r(vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ite=n(vie,"A",{href:!0});var cta=s(ite);DHr=r(cta,"from_pretrained()"),cta.forEach(t),GHr=r(vie," to load the model weights."),vie.forEach(t),OHr=i(G8),T(nA.$$.fragment,G8),G8.forEach(t),VHr=i(Ci),Ur=n(Ci,"DIV",{class:!0});var wi=s(Ur);T($S.$$.fragment,wi),XHr=i(wi),lLe=n(wi,"P",{});var fta=s(lLe);zHr=r(fta,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),fta.forEach(t),QHr=i(wi),In=n(wi,"P",{});var O8=s(In);WHr=r(O8,"The model class to instantiate is selected based on the "),iLe=n(O8,"CODE",{});var mta=s(iLe);UHr=r(mta,"model_type"),mta.forEach(t),HHr=r(O8,` property of the config object (either
passed as an argument or loaded from `),dLe=n(O8,"CODE",{});var gta=s(dLe);JHr=r(gta,"pretrained_model_name_or_path"),gta.forEach(t),YHr=r(O8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cLe=n(O8,"CODE",{});var hta=s(cLe);KHr=r(hta,"pretrained_model_name_or_path"),hta.forEach(t),ZHr=r(O8,":"),O8.forEach(t),eJr=i(wi),de=n(wi,"UL",{});var he=s(de);sA=n(he,"LI",{});var jUe=s(sA);fLe=n(jUe,"STRONG",{});var uta=s(fLe);oJr=r(uta,"albert"),uta.forEach(t),rJr=r(jUe," \u2014 "),dte=n(jUe,"A",{href:!0});var pta=s(dte);tJr=r(pta,"TFAlbertForTokenClassification"),pta.forEach(t),aJr=r(jUe," (ALBERT model)"),jUe.forEach(t),nJr=i(he),lA=n(he,"LI",{});var DUe=s(lA);mLe=n(DUe,"STRONG",{});var _ta=s(mLe);sJr=r(_ta,"bert"),_ta.forEach(t),lJr=r(DUe," \u2014 "),cte=n(DUe,"A",{href:!0});var vta=s(cte);iJr=r(vta,"TFBertForTokenClassification"),vta.forEach(t),dJr=r(DUe," (BERT model)"),DUe.forEach(t),cJr=i(he),iA=n(he,"LI",{});var GUe=s(iA);gLe=n(GUe,"STRONG",{});var bta=s(gLe);fJr=r(bta,"camembert"),bta.forEach(t),mJr=r(GUe," \u2014 "),fte=n(GUe,"A",{href:!0});var Fta=s(fte);gJr=r(Fta,"TFCamembertForTokenClassification"),Fta.forEach(t),hJr=r(GUe," (CamemBERT model)"),GUe.forEach(t),uJr=i(he),dA=n(he,"LI",{});var OUe=s(dA);hLe=n(OUe,"STRONG",{});var Tta=s(hLe);pJr=r(Tta,"convbert"),Tta.forEach(t),_Jr=r(OUe," \u2014 "),mte=n(OUe,"A",{href:!0});var Mta=s(mte);vJr=r(Mta,"TFConvBertForTokenClassification"),Mta.forEach(t),bJr=r(OUe," (ConvBERT model)"),OUe.forEach(t),FJr=i(he),cA=n(he,"LI",{});var VUe=s(cA);uLe=n(VUe,"STRONG",{});var Eta=s(uLe);TJr=r(Eta,"deberta"),Eta.forEach(t),MJr=r(VUe," \u2014 "),gte=n(VUe,"A",{href:!0});var Cta=s(gte);EJr=r(Cta,"TFDebertaForTokenClassification"),Cta.forEach(t),CJr=r(VUe," (DeBERTa model)"),VUe.forEach(t),wJr=i(he),fA=n(he,"LI",{});var XUe=s(fA);pLe=n(XUe,"STRONG",{});var wta=s(pLe);AJr=r(wta,"deberta-v2"),wta.forEach(t),LJr=r(XUe," \u2014 "),hte=n(XUe,"A",{href:!0});var Ata=s(hte);yJr=r(Ata,"TFDebertaV2ForTokenClassification"),Ata.forEach(t),xJr=r(XUe," (DeBERTa-v2 model)"),XUe.forEach(t),$Jr=i(he),mA=n(he,"LI",{});var zUe=s(mA);_Le=n(zUe,"STRONG",{});var Lta=s(_Le);kJr=r(Lta,"distilbert"),Lta.forEach(t),SJr=r(zUe," \u2014 "),ute=n(zUe,"A",{href:!0});var yta=s(ute);RJr=r(yta,"TFDistilBertForTokenClassification"),yta.forEach(t),PJr=r(zUe," (DistilBERT model)"),zUe.forEach(t),BJr=i(he),gA=n(he,"LI",{});var QUe=s(gA);vLe=n(QUe,"STRONG",{});var xta=s(vLe);IJr=r(xta,"electra"),xta.forEach(t),NJr=r(QUe," \u2014 "),pte=n(QUe,"A",{href:!0});var $ta=s(pte);qJr=r($ta,"TFElectraForTokenClassification"),$ta.forEach(t),jJr=r(QUe," (ELECTRA model)"),QUe.forEach(t),DJr=i(he),hA=n(he,"LI",{});var WUe=s(hA);bLe=n(WUe,"STRONG",{});var kta=s(bLe);GJr=r(kta,"flaubert"),kta.forEach(t),OJr=r(WUe," \u2014 "),_te=n(WUe,"A",{href:!0});var Sta=s(_te);VJr=r(Sta,"TFFlaubertForTokenClassification"),Sta.forEach(t),XJr=r(WUe," (FlauBERT model)"),WUe.forEach(t),zJr=i(he),uA=n(he,"LI",{});var UUe=s(uA);FLe=n(UUe,"STRONG",{});var Rta=s(FLe);QJr=r(Rta,"funnel"),Rta.forEach(t),WJr=r(UUe," \u2014 "),vte=n(UUe,"A",{href:!0});var Pta=s(vte);UJr=r(Pta,"TFFunnelForTokenClassification"),Pta.forEach(t),HJr=r(UUe," (Funnel Transformer model)"),UUe.forEach(t),JJr=i(he),pA=n(he,"LI",{});var HUe=s(pA);TLe=n(HUe,"STRONG",{});var Bta=s(TLe);YJr=r(Bta,"layoutlm"),Bta.forEach(t),KJr=r(HUe," \u2014 "),bte=n(HUe,"A",{href:!0});var Ita=s(bte);ZJr=r(Ita,"TFLayoutLMForTokenClassification"),Ita.forEach(t),eYr=r(HUe," (LayoutLM model)"),HUe.forEach(t),oYr=i(he),_A=n(he,"LI",{});var JUe=s(_A);MLe=n(JUe,"STRONG",{});var Nta=s(MLe);rYr=r(Nta,"layoutlmv3"),Nta.forEach(t),tYr=r(JUe," \u2014 "),Fte=n(JUe,"A",{href:!0});var qta=s(Fte);aYr=r(qta,"TFLayoutLMv3ForTokenClassification"),qta.forEach(t),nYr=r(JUe," (LayoutLMv3 model)"),JUe.forEach(t),sYr=i(he),vA=n(he,"LI",{});var YUe=s(vA);ELe=n(YUe,"STRONG",{});var jta=s(ELe);lYr=r(jta,"longformer"),jta.forEach(t),iYr=r(YUe," \u2014 "),Tte=n(YUe,"A",{href:!0});var Dta=s(Tte);dYr=r(Dta,"TFLongformerForTokenClassification"),Dta.forEach(t),cYr=r(YUe," (Longformer model)"),YUe.forEach(t),fYr=i(he),bA=n(he,"LI",{});var KUe=s(bA);CLe=n(KUe,"STRONG",{});var Gta=s(CLe);mYr=r(Gta,"mobilebert"),Gta.forEach(t),gYr=r(KUe," \u2014 "),Mte=n(KUe,"A",{href:!0});var Ota=s(Mte);hYr=r(Ota,"TFMobileBertForTokenClassification"),Ota.forEach(t),uYr=r(KUe," (MobileBERT model)"),KUe.forEach(t),pYr=i(he),FA=n(he,"LI",{});var ZUe=s(FA);wLe=n(ZUe,"STRONG",{});var Vta=s(wLe);_Yr=r(Vta,"mpnet"),Vta.forEach(t),vYr=r(ZUe," \u2014 "),Ete=n(ZUe,"A",{href:!0});var Xta=s(Ete);bYr=r(Xta,"TFMPNetForTokenClassification"),Xta.forEach(t),FYr=r(ZUe," (MPNet model)"),ZUe.forEach(t),TYr=i(he),TA=n(he,"LI",{});var eHe=s(TA);ALe=n(eHe,"STRONG",{});var zta=s(ALe);MYr=r(zta,"rembert"),zta.forEach(t),EYr=r(eHe," \u2014 "),Cte=n(eHe,"A",{href:!0});var Qta=s(Cte);CYr=r(Qta,"TFRemBertForTokenClassification"),Qta.forEach(t),wYr=r(eHe," (RemBERT model)"),eHe.forEach(t),AYr=i(he),MA=n(he,"LI",{});var oHe=s(MA);LLe=n(oHe,"STRONG",{});var Wta=s(LLe);LYr=r(Wta,"roberta"),Wta.forEach(t),yYr=r(oHe," \u2014 "),wte=n(oHe,"A",{href:!0});var Uta=s(wte);xYr=r(Uta,"TFRobertaForTokenClassification"),Uta.forEach(t),$Yr=r(oHe," (RoBERTa model)"),oHe.forEach(t),kYr=i(he),EA=n(he,"LI",{});var rHe=s(EA);yLe=n(rHe,"STRONG",{});var Hta=s(yLe);SYr=r(Hta,"roformer"),Hta.forEach(t),RYr=r(rHe," \u2014 "),Ate=n(rHe,"A",{href:!0});var Jta=s(Ate);PYr=r(Jta,"TFRoFormerForTokenClassification"),Jta.forEach(t),BYr=r(rHe," (RoFormer model)"),rHe.forEach(t),IYr=i(he),CA=n(he,"LI",{});var tHe=s(CA);xLe=n(tHe,"STRONG",{});var Yta=s(xLe);NYr=r(Yta,"xlm"),Yta.forEach(t),qYr=r(tHe," \u2014 "),Lte=n(tHe,"A",{href:!0});var Kta=s(Lte);jYr=r(Kta,"TFXLMForTokenClassification"),Kta.forEach(t),DYr=r(tHe," (XLM model)"),tHe.forEach(t),GYr=i(he),wA=n(he,"LI",{});var aHe=s(wA);$Le=n(aHe,"STRONG",{});var Zta=s($Le);OYr=r(Zta,"xlm-roberta"),Zta.forEach(t),VYr=r(aHe," \u2014 "),yte=n(aHe,"A",{href:!0});var eaa=s(yte);XYr=r(eaa,"TFXLMRobertaForTokenClassification"),eaa.forEach(t),zYr=r(aHe," (XLM-RoBERTa model)"),aHe.forEach(t),QYr=i(he),AA=n(he,"LI",{});var nHe=s(AA);kLe=n(nHe,"STRONG",{});var oaa=s(kLe);WYr=r(oaa,"xlnet"),oaa.forEach(t),UYr=r(nHe," \u2014 "),xte=n(nHe,"A",{href:!0});var raa=s(xte);HYr=r(raa,"TFXLNetForTokenClassification"),raa.forEach(t),JYr=r(nHe," (XLNet model)"),nHe.forEach(t),he.forEach(t),YYr=i(wi),T(LA.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),hZe=i(f),yf=n(f,"H2",{class:!0});var koo=s(yf);yA=n(koo,"A",{id:!0,class:!0,href:!0});var taa=s(yA);SLe=n(taa,"SPAN",{});var aaa=s(SLe);T(kS.$$.fragment,aaa),aaa.forEach(t),taa.forEach(t),KYr=i(koo),RLe=n(koo,"SPAN",{});var naa=s(RLe);ZYr=r(naa,"TFAutoModelForQuestionAnswering"),naa.forEach(t),koo.forEach(t),uZe=i(f),br=n(f,"DIV",{class:!0});var Ai=s(br);T(SS.$$.fragment,Ai),eKr=i(Ai),xf=n(Ai,"P",{});var bie=s(xf);oKr=r(bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$te=n(bie,"A",{href:!0});var saa=s($te);rKr=r(saa,"from_pretrained()"),saa.forEach(t),tKr=r(bie," class method or the "),kte=n(bie,"A",{href:!0});var laa=s(kte);aKr=r(laa,"from_config()"),laa.forEach(t),nKr=r(bie,` class
method.`),bie.forEach(t),sKr=i(Ai),RS=n(Ai,"P",{});var Soo=s(RS);lKr=r(Soo,"This class cannot be instantiated directly using "),PLe=n(Soo,"CODE",{});var iaa=s(PLe);iKr=r(iaa,"__init__()"),iaa.forEach(t),dKr=r(Soo," (throws an error)."),Soo.forEach(t),cKr=i(Ai),ta=n(Ai,"DIV",{class:!0});var V8=s(ta);T(PS.$$.fragment,V8),fKr=i(V8),BLe=n(V8,"P",{});var daa=s(BLe);mKr=r(daa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),daa.forEach(t),gKr=i(V8),$f=n(V8,"P",{});var Fie=s($f);hKr=r(Fie,`Note:
Loading a model from its configuration file does `),ILe=n(Fie,"STRONG",{});var caa=s(ILe);uKr=r(caa,"not"),caa.forEach(t),pKr=r(Fie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ste=n(Fie,"A",{href:!0});var faa=s(Ste);_Kr=r(faa,"from_pretrained()"),faa.forEach(t),vKr=r(Fie," to load the model weights."),Fie.forEach(t),bKr=i(V8),T(xA.$$.fragment,V8),V8.forEach(t),FKr=i(Ai),Hr=n(Ai,"DIV",{class:!0});var Li=s(Hr);T(BS.$$.fragment,Li),TKr=i(Li),NLe=n(Li,"P",{});var maa=s(NLe);MKr=r(maa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),maa.forEach(t),EKr=i(Li),Nn=n(Li,"P",{});var X8=s(Nn);CKr=r(X8,"The model class to instantiate is selected based on the "),qLe=n(X8,"CODE",{});var gaa=s(qLe);wKr=r(gaa,"model_type"),gaa.forEach(t),AKr=r(X8,` property of the config object (either
passed as an argument or loaded from `),jLe=n(X8,"CODE",{});var haa=s(jLe);LKr=r(haa,"pretrained_model_name_or_path"),haa.forEach(t),yKr=r(X8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DLe=n(X8,"CODE",{});var uaa=s(DLe);xKr=r(uaa,"pretrained_model_name_or_path"),uaa.forEach(t),$Kr=r(X8,":"),X8.forEach(t),kKr=i(Li),ce=n(Li,"UL",{});var ue=s(ce);$A=n(ue,"LI",{});var sHe=s($A);GLe=n(sHe,"STRONG",{});var paa=s(GLe);SKr=r(paa,"albert"),paa.forEach(t),RKr=r(sHe," \u2014 "),Rte=n(sHe,"A",{href:!0});var _aa=s(Rte);PKr=r(_aa,"TFAlbertForQuestionAnswering"),_aa.forEach(t),BKr=r(sHe," (ALBERT model)"),sHe.forEach(t),IKr=i(ue),kA=n(ue,"LI",{});var lHe=s(kA);OLe=n(lHe,"STRONG",{});var vaa=s(OLe);NKr=r(vaa,"bert"),vaa.forEach(t),qKr=r(lHe," \u2014 "),Pte=n(lHe,"A",{href:!0});var baa=s(Pte);jKr=r(baa,"TFBertForQuestionAnswering"),baa.forEach(t),DKr=r(lHe," (BERT model)"),lHe.forEach(t),GKr=i(ue),SA=n(ue,"LI",{});var iHe=s(SA);VLe=n(iHe,"STRONG",{});var Faa=s(VLe);OKr=r(Faa,"camembert"),Faa.forEach(t),VKr=r(iHe," \u2014 "),Bte=n(iHe,"A",{href:!0});var Taa=s(Bte);XKr=r(Taa,"TFCamembertForQuestionAnswering"),Taa.forEach(t),zKr=r(iHe," (CamemBERT model)"),iHe.forEach(t),QKr=i(ue),RA=n(ue,"LI",{});var dHe=s(RA);XLe=n(dHe,"STRONG",{});var Maa=s(XLe);WKr=r(Maa,"convbert"),Maa.forEach(t),UKr=r(dHe," \u2014 "),Ite=n(dHe,"A",{href:!0});var Eaa=s(Ite);HKr=r(Eaa,"TFConvBertForQuestionAnswering"),Eaa.forEach(t),JKr=r(dHe," (ConvBERT model)"),dHe.forEach(t),YKr=i(ue),PA=n(ue,"LI",{});var cHe=s(PA);zLe=n(cHe,"STRONG",{});var Caa=s(zLe);KKr=r(Caa,"deberta"),Caa.forEach(t),ZKr=r(cHe," \u2014 "),Nte=n(cHe,"A",{href:!0});var waa=s(Nte);eZr=r(waa,"TFDebertaForQuestionAnswering"),waa.forEach(t),oZr=r(cHe," (DeBERTa model)"),cHe.forEach(t),rZr=i(ue),BA=n(ue,"LI",{});var fHe=s(BA);QLe=n(fHe,"STRONG",{});var Aaa=s(QLe);tZr=r(Aaa,"deberta-v2"),Aaa.forEach(t),aZr=r(fHe," \u2014 "),qte=n(fHe,"A",{href:!0});var Laa=s(qte);nZr=r(Laa,"TFDebertaV2ForQuestionAnswering"),Laa.forEach(t),sZr=r(fHe," (DeBERTa-v2 model)"),fHe.forEach(t),lZr=i(ue),IA=n(ue,"LI",{});var mHe=s(IA);WLe=n(mHe,"STRONG",{});var yaa=s(WLe);iZr=r(yaa,"distilbert"),yaa.forEach(t),dZr=r(mHe," \u2014 "),jte=n(mHe,"A",{href:!0});var xaa=s(jte);cZr=r(xaa,"TFDistilBertForQuestionAnswering"),xaa.forEach(t),fZr=r(mHe," (DistilBERT model)"),mHe.forEach(t),mZr=i(ue),NA=n(ue,"LI",{});var gHe=s(NA);ULe=n(gHe,"STRONG",{});var $aa=s(ULe);gZr=r($aa,"electra"),$aa.forEach(t),hZr=r(gHe," \u2014 "),Dte=n(gHe,"A",{href:!0});var kaa=s(Dte);uZr=r(kaa,"TFElectraForQuestionAnswering"),kaa.forEach(t),pZr=r(gHe," (ELECTRA model)"),gHe.forEach(t),_Zr=i(ue),qA=n(ue,"LI",{});var hHe=s(qA);HLe=n(hHe,"STRONG",{});var Saa=s(HLe);vZr=r(Saa,"flaubert"),Saa.forEach(t),bZr=r(hHe," \u2014 "),Gte=n(hHe,"A",{href:!0});var Raa=s(Gte);FZr=r(Raa,"TFFlaubertForQuestionAnsweringSimple"),Raa.forEach(t),TZr=r(hHe," (FlauBERT model)"),hHe.forEach(t),MZr=i(ue),jA=n(ue,"LI",{});var uHe=s(jA);JLe=n(uHe,"STRONG",{});var Paa=s(JLe);EZr=r(Paa,"funnel"),Paa.forEach(t),CZr=r(uHe," \u2014 "),Ote=n(uHe,"A",{href:!0});var Baa=s(Ote);wZr=r(Baa,"TFFunnelForQuestionAnswering"),Baa.forEach(t),AZr=r(uHe," (Funnel Transformer model)"),uHe.forEach(t),LZr=i(ue),DA=n(ue,"LI",{});var pHe=s(DA);YLe=n(pHe,"STRONG",{});var Iaa=s(YLe);yZr=r(Iaa,"gptj"),Iaa.forEach(t),xZr=r(pHe," \u2014 "),Vte=n(pHe,"A",{href:!0});var Naa=s(Vte);$Zr=r(Naa,"TFGPTJForQuestionAnswering"),Naa.forEach(t),kZr=r(pHe," (GPT-J model)"),pHe.forEach(t),SZr=i(ue),GA=n(ue,"LI",{});var _He=s(GA);KLe=n(_He,"STRONG",{});var qaa=s(KLe);RZr=r(qaa,"layoutlmv3"),qaa.forEach(t),PZr=r(_He," \u2014 "),Xte=n(_He,"A",{href:!0});var jaa=s(Xte);BZr=r(jaa,"TFLayoutLMv3ForQuestionAnswering"),jaa.forEach(t),IZr=r(_He," (LayoutLMv3 model)"),_He.forEach(t),NZr=i(ue),OA=n(ue,"LI",{});var vHe=s(OA);ZLe=n(vHe,"STRONG",{});var Daa=s(ZLe);qZr=r(Daa,"longformer"),Daa.forEach(t),jZr=r(vHe," \u2014 "),zte=n(vHe,"A",{href:!0});var Gaa=s(zte);DZr=r(Gaa,"TFLongformerForQuestionAnswering"),Gaa.forEach(t),GZr=r(vHe," (Longformer model)"),vHe.forEach(t),OZr=i(ue),VA=n(ue,"LI",{});var bHe=s(VA);eye=n(bHe,"STRONG",{});var Oaa=s(eye);VZr=r(Oaa,"mobilebert"),Oaa.forEach(t),XZr=r(bHe," \u2014 "),Qte=n(bHe,"A",{href:!0});var Vaa=s(Qte);zZr=r(Vaa,"TFMobileBertForQuestionAnswering"),Vaa.forEach(t),QZr=r(bHe," (MobileBERT model)"),bHe.forEach(t),WZr=i(ue),XA=n(ue,"LI",{});var FHe=s(XA);oye=n(FHe,"STRONG",{});var Xaa=s(oye);UZr=r(Xaa,"mpnet"),Xaa.forEach(t),HZr=r(FHe," \u2014 "),Wte=n(FHe,"A",{href:!0});var zaa=s(Wte);JZr=r(zaa,"TFMPNetForQuestionAnswering"),zaa.forEach(t),YZr=r(FHe," (MPNet model)"),FHe.forEach(t),KZr=i(ue),zA=n(ue,"LI",{});var THe=s(zA);rye=n(THe,"STRONG",{});var Qaa=s(rye);ZZr=r(Qaa,"rembert"),Qaa.forEach(t),eet=r(THe," \u2014 "),Ute=n(THe,"A",{href:!0});var Waa=s(Ute);oet=r(Waa,"TFRemBertForQuestionAnswering"),Waa.forEach(t),ret=r(THe," (RemBERT model)"),THe.forEach(t),tet=i(ue),QA=n(ue,"LI",{});var MHe=s(QA);tye=n(MHe,"STRONG",{});var Uaa=s(tye);aet=r(Uaa,"roberta"),Uaa.forEach(t),net=r(MHe," \u2014 "),Hte=n(MHe,"A",{href:!0});var Haa=s(Hte);set=r(Haa,"TFRobertaForQuestionAnswering"),Haa.forEach(t),iet=r(MHe," (RoBERTa model)"),MHe.forEach(t),det=i(ue),WA=n(ue,"LI",{});var EHe=s(WA);aye=n(EHe,"STRONG",{});var Jaa=s(aye);cet=r(Jaa,"roformer"),Jaa.forEach(t),fet=r(EHe," \u2014 "),Jte=n(EHe,"A",{href:!0});var Yaa=s(Jte);met=r(Yaa,"TFRoFormerForQuestionAnswering"),Yaa.forEach(t),get=r(EHe," (RoFormer model)"),EHe.forEach(t),het=i(ue),UA=n(ue,"LI",{});var CHe=s(UA);nye=n(CHe,"STRONG",{});var Kaa=s(nye);uet=r(Kaa,"xlm"),Kaa.forEach(t),pet=r(CHe," \u2014 "),Yte=n(CHe,"A",{href:!0});var Zaa=s(Yte);_et=r(Zaa,"TFXLMForQuestionAnsweringSimple"),Zaa.forEach(t),vet=r(CHe," (XLM model)"),CHe.forEach(t),bet=i(ue),HA=n(ue,"LI",{});var wHe=s(HA);sye=n(wHe,"STRONG",{});var ena=s(sye);Fet=r(ena,"xlm-roberta"),ena.forEach(t),Tet=r(wHe," \u2014 "),Kte=n(wHe,"A",{href:!0});var ona=s(Kte);Met=r(ona,"TFXLMRobertaForQuestionAnswering"),ona.forEach(t),Eet=r(wHe," (XLM-RoBERTa model)"),wHe.forEach(t),Cet=i(ue),JA=n(ue,"LI",{});var AHe=s(JA);lye=n(AHe,"STRONG",{});var rna=s(lye);wet=r(rna,"xlnet"),rna.forEach(t),Aet=r(AHe," \u2014 "),Zte=n(AHe,"A",{href:!0});var tna=s(Zte);Let=r(tna,"TFXLNetForQuestionAnsweringSimple"),tna.forEach(t),yet=r(AHe," (XLNet model)"),AHe.forEach(t),ue.forEach(t),xet=i(Li),T(YA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),pZe=i(f),kf=n(f,"H2",{class:!0});var Roo=s(kf);KA=n(Roo,"A",{id:!0,class:!0,href:!0});var ana=s(KA);iye=n(ana,"SPAN",{});var nna=s(iye);T(IS.$$.fragment,nna),nna.forEach(t),ana.forEach(t),$et=i(Roo),dye=n(Roo,"SPAN",{});var sna=s(dye);ket=r(sna,"TFAutoModelForVision2Seq"),sna.forEach(t),Roo.forEach(t),_Ze=i(f),Fr=n(f,"DIV",{class:!0});var yi=s(Fr);T(NS.$$.fragment,yi),Set=i(yi),Sf=n(yi,"P",{});var Tie=s(Sf);Ret=r(Tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=n(Tie,"A",{href:!0});var lna=s(eae);Pet=r(lna,"from_pretrained()"),lna.forEach(t),Bet=r(Tie," class method or the "),oae=n(Tie,"A",{href:!0});var ina=s(oae);Iet=r(ina,"from_config()"),ina.forEach(t),Net=r(Tie,` class
method.`),Tie.forEach(t),qet=i(yi),qS=n(yi,"P",{});var Poo=s(qS);jet=r(Poo,"This class cannot be instantiated directly using "),cye=n(Poo,"CODE",{});var dna=s(cye);Det=r(dna,"__init__()"),dna.forEach(t),Get=r(Poo," (throws an error)."),Poo.forEach(t),Oet=i(yi),aa=n(yi,"DIV",{class:!0});var z8=s(aa);T(jS.$$.fragment,z8),Vet=i(z8),fye=n(z8,"P",{});var cna=s(fye);Xet=r(cna,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),cna.forEach(t),zet=i(z8),Rf=n(z8,"P",{});var Mie=s(Rf);Qet=r(Mie,`Note:
Loading a model from its configuration file does `),mye=n(Mie,"STRONG",{});var fna=s(mye);Wet=r(fna,"not"),fna.forEach(t),Uet=r(Mie,` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=n(Mie,"A",{href:!0});var mna=s(rae);Het=r(mna,"from_pretrained()"),mna.forEach(t),Jet=r(Mie," to load the model weights."),Mie.forEach(t),Yet=i(z8),T(ZA.$$.fragment,z8),z8.forEach(t),Ket=i(yi),Jr=n(yi,"DIV",{class:!0});var xi=s(Jr);T(DS.$$.fragment,xi),Zet=i(xi),gye=n(xi,"P",{});var gna=s(gye);eot=r(gna,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gna.forEach(t),oot=i(xi),qn=n(xi,"P",{});var Q8=s(qn);rot=r(Q8,"The model class to instantiate is selected based on the "),hye=n(Q8,"CODE",{});var hna=s(hye);tot=r(hna,"model_type"),hna.forEach(t),aot=r(Q8,` property of the config object (either
passed as an argument or loaded from `),uye=n(Q8,"CODE",{});var una=s(uye);not=r(una,"pretrained_model_name_or_path"),una.forEach(t),sot=r(Q8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pye=n(Q8,"CODE",{});var pna=s(pye);lot=r(pna,"pretrained_model_name_or_path"),pna.forEach(t),iot=r(Q8,":"),Q8.forEach(t),dot=i(xi),_ye=n(xi,"UL",{});var _na=s(_ye);e6=n(_na,"LI",{});var LHe=s(e6);vye=n(LHe,"STRONG",{});var vna=s(vye);cot=r(vna,"vision-encoder-decoder"),vna.forEach(t),fot=r(LHe," \u2014 "),tae=n(LHe,"A",{href:!0});var bna=s(tae);mot=r(bna,"TFVisionEncoderDecoderModel"),bna.forEach(t),got=r(LHe," (Vision Encoder decoder model)"),LHe.forEach(t),_na.forEach(t),hot=i(xi),T(o6.$$.fragment,xi),xi.forEach(t),yi.forEach(t),vZe=i(f),Pf=n(f,"H2",{class:!0});var Boo=s(Pf);r6=n(Boo,"A",{id:!0,class:!0,href:!0});var Fna=s(r6);bye=n(Fna,"SPAN",{});var Tna=s(bye);T(GS.$$.fragment,Tna),Tna.forEach(t),Fna.forEach(t),uot=i(Boo),Fye=n(Boo,"SPAN",{});var Mna=s(Fye);pot=r(Mna,"TFAutoModelForSpeechSeq2Seq"),Mna.forEach(t),Boo.forEach(t),bZe=i(f),Tr=n(f,"DIV",{class:!0});var $i=s(Tr);T(OS.$$.fragment,$i),_ot=i($i),Bf=n($i,"P",{});var Eie=s(Bf);vot=r(Eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),aae=n(Eie,"A",{href:!0});var Ena=s(aae);bot=r(Ena,"from_pretrained()"),Ena.forEach(t),Fot=r(Eie," class method or the "),nae=n(Eie,"A",{href:!0});var Cna=s(nae);Tot=r(Cna,"from_config()"),Cna.forEach(t),Mot=r(Eie,` class
method.`),Eie.forEach(t),Eot=i($i),VS=n($i,"P",{});var Ioo=s(VS);Cot=r(Ioo,"This class cannot be instantiated directly using "),Tye=n(Ioo,"CODE",{});var wna=s(Tye);wot=r(wna,"__init__()"),wna.forEach(t),Aot=r(Ioo," (throws an error)."),Ioo.forEach(t),Lot=i($i),na=n($i,"DIV",{class:!0});var W8=s(na);T(XS.$$.fragment,W8),yot=i(W8),Mye=n(W8,"P",{});var Ana=s(Mye);xot=r(Ana,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ana.forEach(t),$ot=i(W8),If=n(W8,"P",{});var Cie=s(If);kot=r(Cie,`Note:
Loading a model from its configuration file does `),Eye=n(Cie,"STRONG",{});var Lna=s(Eye);Sot=r(Lna,"not"),Lna.forEach(t),Rot=r(Cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=n(Cie,"A",{href:!0});var yna=s(sae);Pot=r(yna,"from_pretrained()"),yna.forEach(t),Bot=r(Cie," to load the model weights."),Cie.forEach(t),Iot=i(W8),T(t6.$$.fragment,W8),W8.forEach(t),Not=i($i),Yr=n($i,"DIV",{class:!0});var ki=s(Yr);T(zS.$$.fragment,ki),qot=i(ki),Cye=n(ki,"P",{});var xna=s(Cye);jot=r(xna,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),xna.forEach(t),Dot=i(ki),jn=n(ki,"P",{});var U8=s(jn);Got=r(U8,"The model class to instantiate is selected based on the "),wye=n(U8,"CODE",{});var $na=s(wye);Oot=r($na,"model_type"),$na.forEach(t),Vot=r(U8,` property of the config object (either
passed as an argument or loaded from `),Aye=n(U8,"CODE",{});var kna=s(Aye);Xot=r(kna,"pretrained_model_name_or_path"),kna.forEach(t),zot=r(U8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lye=n(U8,"CODE",{});var Sna=s(Lye);Qot=r(Sna,"pretrained_model_name_or_path"),Sna.forEach(t),Wot=r(U8,":"),U8.forEach(t),Uot=i(ki),yye=n(ki,"UL",{});var Rna=s(yye);a6=n(Rna,"LI",{});var yHe=s(a6);xye=n(yHe,"STRONG",{});var Pna=s(xye);Hot=r(Pna,"speech_to_text"),Pna.forEach(t),Jot=r(yHe," \u2014 "),lae=n(yHe,"A",{href:!0});var Bna=s(lae);Yot=r(Bna,"TFSpeech2TextForConditionalGeneration"),Bna.forEach(t),Kot=r(yHe," (Speech2Text model)"),yHe.forEach(t),Rna.forEach(t),Zot=i(ki),T(n6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),FZe=i(f),Nf=n(f,"H2",{class:!0});var Noo=s(Nf);s6=n(Noo,"A",{id:!0,class:!0,href:!0});var Ina=s(s6);$ye=n(Ina,"SPAN",{});var Nna=s($ye);T(QS.$$.fragment,Nna),Nna.forEach(t),Ina.forEach(t),ert=i(Noo),kye=n(Noo,"SPAN",{});var qna=s(kye);ort=r(qna,"FlaxAutoModel"),qna.forEach(t),Noo.forEach(t),TZe=i(f),Mr=n(f,"DIV",{class:!0});var Si=s(Mr);T(WS.$$.fragment,Si),rrt=i(Si),qf=n(Si,"P",{});var wie=s(qf);trt=r(wie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),iae=n(wie,"A",{href:!0});var jna=s(iae);art=r(jna,"from_pretrained()"),jna.forEach(t),nrt=r(wie," class method or the "),dae=n(wie,"A",{href:!0});var Dna=s(dae);srt=r(Dna,"from_config()"),Dna.forEach(t),lrt=r(wie,` class
method.`),wie.forEach(t),irt=i(Si),US=n(Si,"P",{});var qoo=s(US);drt=r(qoo,"This class cannot be instantiated directly using "),Sye=n(qoo,"CODE",{});var Gna=s(Sye);crt=r(Gna,"__init__()"),Gna.forEach(t),frt=r(qoo," (throws an error)."),qoo.forEach(t),mrt=i(Si),sa=n(Si,"DIV",{class:!0});var H8=s(sa);T(HS.$$.fragment,H8),grt=i(H8),Rye=n(H8,"P",{});var Ona=s(Rye);hrt=r(Ona,"Instantiates one of the base model classes of the library from a configuration."),Ona.forEach(t),urt=i(H8),jf=n(H8,"P",{});var Aie=s(jf);prt=r(Aie,`Note:
Loading a model from its configuration file does `),Pye=n(Aie,"STRONG",{});var Vna=s(Pye);_rt=r(Vna,"not"),Vna.forEach(t),vrt=r(Aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cae=n(Aie,"A",{href:!0});var Xna=s(cae);brt=r(Xna,"from_pretrained()"),Xna.forEach(t),Frt=r(Aie," to load the model weights."),Aie.forEach(t),Trt=i(H8),T(l6.$$.fragment,H8),H8.forEach(t),Mrt=i(Si),Kr=n(Si,"DIV",{class:!0});var Ri=s(Kr);T(JS.$$.fragment,Ri),Ert=i(Ri),Bye=n(Ri,"P",{});var zna=s(Bye);Crt=r(zna,"Instantiate one of the base model classes of the library from a pretrained model."),zna.forEach(t),wrt=i(Ri),Dn=n(Ri,"P",{});var J8=s(Dn);Art=r(J8,"The model class to instantiate is selected based on the "),Iye=n(J8,"CODE",{});var Qna=s(Iye);Lrt=r(Qna,"model_type"),Qna.forEach(t),yrt=r(J8,` property of the config object (either
passed as an argument or loaded from `),Nye=n(J8,"CODE",{});var Wna=s(Nye);xrt=r(Wna,"pretrained_model_name_or_path"),Wna.forEach(t),$rt=r(J8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=n(J8,"CODE",{});var Una=s(qye);krt=r(Una,"pretrained_model_name_or_path"),Una.forEach(t),Srt=r(J8,":"),J8.forEach(t),Rrt=i(Ri),te=n(Ri,"UL",{});var ne=s(te);i6=n(ne,"LI",{});var xHe=s(i6);jye=n(xHe,"STRONG",{});var Hna=s(jye);Prt=r(Hna,"albert"),Hna.forEach(t),Brt=r(xHe," \u2014 "),fae=n(xHe,"A",{href:!0});var Jna=s(fae);Irt=r(Jna,"FlaxAlbertModel"),Jna.forEach(t),Nrt=r(xHe," (ALBERT model)"),xHe.forEach(t),qrt=i(ne),d6=n(ne,"LI",{});var $He=s(d6);Dye=n($He,"STRONG",{});var Yna=s(Dye);jrt=r(Yna,"bart"),Yna.forEach(t),Drt=r($He," \u2014 "),mae=n($He,"A",{href:!0});var Kna=s(mae);Grt=r(Kna,"FlaxBartModel"),Kna.forEach(t),Ort=r($He," (BART model)"),$He.forEach(t),Vrt=i(ne),c6=n(ne,"LI",{});var kHe=s(c6);Gye=n(kHe,"STRONG",{});var Zna=s(Gye);Xrt=r(Zna,"beit"),Zna.forEach(t),zrt=r(kHe," \u2014 "),gae=n(kHe,"A",{href:!0});var esa=s(gae);Qrt=r(esa,"FlaxBeitModel"),esa.forEach(t),Wrt=r(kHe," (BEiT model)"),kHe.forEach(t),Urt=i(ne),f6=n(ne,"LI",{});var SHe=s(f6);Oye=n(SHe,"STRONG",{});var osa=s(Oye);Hrt=r(osa,"bert"),osa.forEach(t),Jrt=r(SHe," \u2014 "),hae=n(SHe,"A",{href:!0});var rsa=s(hae);Yrt=r(rsa,"FlaxBertModel"),rsa.forEach(t),Krt=r(SHe," (BERT model)"),SHe.forEach(t),Zrt=i(ne),m6=n(ne,"LI",{});var RHe=s(m6);Vye=n(RHe,"STRONG",{});var tsa=s(Vye);ett=r(tsa,"big_bird"),tsa.forEach(t),ott=r(RHe," \u2014 "),uae=n(RHe,"A",{href:!0});var asa=s(uae);rtt=r(asa,"FlaxBigBirdModel"),asa.forEach(t),ttt=r(RHe," (BigBird model)"),RHe.forEach(t),att=i(ne),g6=n(ne,"LI",{});var PHe=s(g6);Xye=n(PHe,"STRONG",{});var nsa=s(Xye);ntt=r(nsa,"blenderbot"),nsa.forEach(t),stt=r(PHe," \u2014 "),pae=n(PHe,"A",{href:!0});var ssa=s(pae);ltt=r(ssa,"FlaxBlenderbotModel"),ssa.forEach(t),itt=r(PHe," (Blenderbot model)"),PHe.forEach(t),dtt=i(ne),h6=n(ne,"LI",{});var BHe=s(h6);zye=n(BHe,"STRONG",{});var lsa=s(zye);ctt=r(lsa,"blenderbot-small"),lsa.forEach(t),ftt=r(BHe," \u2014 "),_ae=n(BHe,"A",{href:!0});var isa=s(_ae);mtt=r(isa,"FlaxBlenderbotSmallModel"),isa.forEach(t),gtt=r(BHe," (BlenderbotSmall model)"),BHe.forEach(t),htt=i(ne),u6=n(ne,"LI",{});var IHe=s(u6);Qye=n(IHe,"STRONG",{});var dsa=s(Qye);utt=r(dsa,"clip"),dsa.forEach(t),ptt=r(IHe," \u2014 "),vae=n(IHe,"A",{href:!0});var csa=s(vae);_tt=r(csa,"FlaxCLIPModel"),csa.forEach(t),vtt=r(IHe," (CLIP model)"),IHe.forEach(t),btt=i(ne),p6=n(ne,"LI",{});var NHe=s(p6);Wye=n(NHe,"STRONG",{});var fsa=s(Wye);Ftt=r(fsa,"distilbert"),fsa.forEach(t),Ttt=r(NHe," \u2014 "),bae=n(NHe,"A",{href:!0});var msa=s(bae);Mtt=r(msa,"FlaxDistilBertModel"),msa.forEach(t),Ett=r(NHe," (DistilBERT model)"),NHe.forEach(t),Ctt=i(ne),_6=n(ne,"LI",{});var qHe=s(_6);Uye=n(qHe,"STRONG",{});var gsa=s(Uye);wtt=r(gsa,"electra"),gsa.forEach(t),Att=r(qHe," \u2014 "),Fae=n(qHe,"A",{href:!0});var hsa=s(Fae);Ltt=r(hsa,"FlaxElectraModel"),hsa.forEach(t),ytt=r(qHe," (ELECTRA model)"),qHe.forEach(t),xtt=i(ne),v6=n(ne,"LI",{});var jHe=s(v6);Hye=n(jHe,"STRONG",{});var usa=s(Hye);$tt=r(usa,"gpt2"),usa.forEach(t),ktt=r(jHe," \u2014 "),Tae=n(jHe,"A",{href:!0});var psa=s(Tae);Stt=r(psa,"FlaxGPT2Model"),psa.forEach(t),Rtt=r(jHe," (OpenAI GPT-2 model)"),jHe.forEach(t),Ptt=i(ne),b6=n(ne,"LI",{});var DHe=s(b6);Jye=n(DHe,"STRONG",{});var _sa=s(Jye);Btt=r(_sa,"gpt_neo"),_sa.forEach(t),Itt=r(DHe," \u2014 "),Mae=n(DHe,"A",{href:!0});var vsa=s(Mae);Ntt=r(vsa,"FlaxGPTNeoModel"),vsa.forEach(t),qtt=r(DHe," (GPT Neo model)"),DHe.forEach(t),jtt=i(ne),F6=n(ne,"LI",{});var GHe=s(F6);Yye=n(GHe,"STRONG",{});var bsa=s(Yye);Dtt=r(bsa,"gptj"),bsa.forEach(t),Gtt=r(GHe," \u2014 "),Eae=n(GHe,"A",{href:!0});var Fsa=s(Eae);Ott=r(Fsa,"FlaxGPTJModel"),Fsa.forEach(t),Vtt=r(GHe," (GPT-J model)"),GHe.forEach(t),Xtt=i(ne),T6=n(ne,"LI",{});var OHe=s(T6);Kye=n(OHe,"STRONG",{});var Tsa=s(Kye);ztt=r(Tsa,"longt5"),Tsa.forEach(t),Qtt=r(OHe," \u2014 "),Cae=n(OHe,"A",{href:!0});var Msa=s(Cae);Wtt=r(Msa,"FlaxLongT5Model"),Msa.forEach(t),Utt=r(OHe," (LongT5 model)"),OHe.forEach(t),Htt=i(ne),M6=n(ne,"LI",{});var VHe=s(M6);Zye=n(VHe,"STRONG",{});var Esa=s(Zye);Jtt=r(Esa,"marian"),Esa.forEach(t),Ytt=r(VHe," \u2014 "),wae=n(VHe,"A",{href:!0});var Csa=s(wae);Ktt=r(Csa,"FlaxMarianModel"),Csa.forEach(t),Ztt=r(VHe," (Marian model)"),VHe.forEach(t),eat=i(ne),E6=n(ne,"LI",{});var XHe=s(E6);e8e=n(XHe,"STRONG",{});var wsa=s(e8e);oat=r(wsa,"mbart"),wsa.forEach(t),rat=r(XHe," \u2014 "),Aae=n(XHe,"A",{href:!0});var Asa=s(Aae);tat=r(Asa,"FlaxMBartModel"),Asa.forEach(t),aat=r(XHe," (mBART model)"),XHe.forEach(t),nat=i(ne),C6=n(ne,"LI",{});var zHe=s(C6);o8e=n(zHe,"STRONG",{});var Lsa=s(o8e);sat=r(Lsa,"mt5"),Lsa.forEach(t),lat=r(zHe," \u2014 "),Lae=n(zHe,"A",{href:!0});var ysa=s(Lae);iat=r(ysa,"FlaxMT5Model"),ysa.forEach(t),dat=r(zHe," (MT5 model)"),zHe.forEach(t),cat=i(ne),w6=n(ne,"LI",{});var QHe=s(w6);r8e=n(QHe,"STRONG",{});var xsa=s(r8e);fat=r(xsa,"opt"),xsa.forEach(t),mat=r(QHe," \u2014 "),yae=n(QHe,"A",{href:!0});var $sa=s(yae);gat=r($sa,"FlaxOPTModel"),$sa.forEach(t),hat=r(QHe," (OPT model)"),QHe.forEach(t),uat=i(ne),A6=n(ne,"LI",{});var WHe=s(A6);t8e=n(WHe,"STRONG",{});var ksa=s(t8e);pat=r(ksa,"pegasus"),ksa.forEach(t),_at=r(WHe," \u2014 "),xae=n(WHe,"A",{href:!0});var Ssa=s(xae);vat=r(Ssa,"FlaxPegasusModel"),Ssa.forEach(t),bat=r(WHe," (Pegasus model)"),WHe.forEach(t),Fat=i(ne),L6=n(ne,"LI",{});var UHe=s(L6);a8e=n(UHe,"STRONG",{});var Rsa=s(a8e);Tat=r(Rsa,"roberta"),Rsa.forEach(t),Mat=r(UHe," \u2014 "),$ae=n(UHe,"A",{href:!0});var Psa=s($ae);Eat=r(Psa,"FlaxRobertaModel"),Psa.forEach(t),Cat=r(UHe," (RoBERTa model)"),UHe.forEach(t),wat=i(ne),y6=n(ne,"LI",{});var HHe=s(y6);n8e=n(HHe,"STRONG",{});var Bsa=s(n8e);Aat=r(Bsa,"roformer"),Bsa.forEach(t),Lat=r(HHe," \u2014 "),kae=n(HHe,"A",{href:!0});var Isa=s(kae);yat=r(Isa,"FlaxRoFormerModel"),Isa.forEach(t),xat=r(HHe," (RoFormer model)"),HHe.forEach(t),$at=i(ne),x6=n(ne,"LI",{});var JHe=s(x6);s8e=n(JHe,"STRONG",{});var Nsa=s(s8e);kat=r(Nsa,"t5"),Nsa.forEach(t),Sat=r(JHe," \u2014 "),Sae=n(JHe,"A",{href:!0});var qsa=s(Sae);Rat=r(qsa,"FlaxT5Model"),qsa.forEach(t),Pat=r(JHe," (T5 model)"),JHe.forEach(t),Bat=i(ne),$6=n(ne,"LI",{});var YHe=s($6);l8e=n(YHe,"STRONG",{});var jsa=s(l8e);Iat=r(jsa,"vision-text-dual-encoder"),jsa.forEach(t),Nat=r(YHe," \u2014 "),Rae=n(YHe,"A",{href:!0});var Dsa=s(Rae);qat=r(Dsa,"FlaxVisionTextDualEncoderModel"),Dsa.forEach(t),jat=r(YHe," (VisionTextDualEncoder model)"),YHe.forEach(t),Dat=i(ne),k6=n(ne,"LI",{});var KHe=s(k6);i8e=n(KHe,"STRONG",{});var Gsa=s(i8e);Gat=r(Gsa,"vit"),Gsa.forEach(t),Oat=r(KHe," \u2014 "),Pae=n(KHe,"A",{href:!0});var Osa=s(Pae);Vat=r(Osa,"FlaxViTModel"),Osa.forEach(t),Xat=r(KHe," (ViT model)"),KHe.forEach(t),zat=i(ne),S6=n(ne,"LI",{});var ZHe=s(S6);d8e=n(ZHe,"STRONG",{});var Vsa=s(d8e);Qat=r(Vsa,"wav2vec2"),Vsa.forEach(t),Wat=r(ZHe," \u2014 "),Bae=n(ZHe,"A",{href:!0});var Xsa=s(Bae);Uat=r(Xsa,"FlaxWav2Vec2Model"),Xsa.forEach(t),Hat=r(ZHe," (Wav2Vec2 model)"),ZHe.forEach(t),Jat=i(ne),R6=n(ne,"LI",{});var eJe=s(R6);c8e=n(eJe,"STRONG",{});var zsa=s(c8e);Yat=r(zsa,"xglm"),zsa.forEach(t),Kat=r(eJe," \u2014 "),Iae=n(eJe,"A",{href:!0});var Qsa=s(Iae);Zat=r(Qsa,"FlaxXGLMModel"),Qsa.forEach(t),ent=r(eJe," (XGLM model)"),eJe.forEach(t),ont=i(ne),P6=n(ne,"LI",{});var oJe=s(P6);f8e=n(oJe,"STRONG",{});var Wsa=s(f8e);rnt=r(Wsa,"xlm-roberta"),Wsa.forEach(t),tnt=r(oJe," \u2014 "),Nae=n(oJe,"A",{href:!0});var Usa=s(Nae);ant=r(Usa,"FlaxXLMRobertaModel"),Usa.forEach(t),nnt=r(oJe," (XLM-RoBERTa model)"),oJe.forEach(t),ne.forEach(t),snt=i(Ri),T(B6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),MZe=i(f),Df=n(f,"H2",{class:!0});var joo=s(Df);I6=n(joo,"A",{id:!0,class:!0,href:!0});var Hsa=s(I6);m8e=n(Hsa,"SPAN",{});var Jsa=s(m8e);T(YS.$$.fragment,Jsa),Jsa.forEach(t),Hsa.forEach(t),lnt=i(joo),g8e=n(joo,"SPAN",{});var Ysa=s(g8e);int=r(Ysa,"FlaxAutoModelForCausalLM"),Ysa.forEach(t),joo.forEach(t),EZe=i(f),Er=n(f,"DIV",{class:!0});var Pi=s(Er);T(KS.$$.fragment,Pi),dnt=i(Pi),Gf=n(Pi,"P",{});var Lie=s(Gf);cnt=r(Lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qae=n(Lie,"A",{href:!0});var Ksa=s(qae);fnt=r(Ksa,"from_pretrained()"),Ksa.forEach(t),mnt=r(Lie," class method or the "),jae=n(Lie,"A",{href:!0});var Zsa=s(jae);gnt=r(Zsa,"from_config()"),Zsa.forEach(t),hnt=r(Lie,` class
method.`),Lie.forEach(t),unt=i(Pi),ZS=n(Pi,"P",{});var Doo=s(ZS);pnt=r(Doo,"This class cannot be instantiated directly using "),h8e=n(Doo,"CODE",{});var ela=s(h8e);_nt=r(ela,"__init__()"),ela.forEach(t),vnt=r(Doo," (throws an error)."),Doo.forEach(t),bnt=i(Pi),la=n(Pi,"DIV",{class:!0});var Y8=s(la);T(eR.$$.fragment,Y8),Fnt=i(Y8),u8e=n(Y8,"P",{});var ola=s(u8e);Tnt=r(ola,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ola.forEach(t),Mnt=i(Y8),Of=n(Y8,"P",{});var yie=s(Of);Ent=r(yie,`Note:
Loading a model from its configuration file does `),p8e=n(yie,"STRONG",{});var rla=s(p8e);Cnt=r(rla,"not"),rla.forEach(t),wnt=r(yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=n(yie,"A",{href:!0});var tla=s(Dae);Ant=r(tla,"from_pretrained()"),tla.forEach(t),Lnt=r(yie," to load the model weights."),yie.forEach(t),ynt=i(Y8),T(N6.$$.fragment,Y8),Y8.forEach(t),xnt=i(Pi),Zr=n(Pi,"DIV",{class:!0});var Bi=s(Zr);T(oR.$$.fragment,Bi),$nt=i(Bi),_8e=n(Bi,"P",{});var ala=s(_8e);knt=r(ala,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ala.forEach(t),Snt=i(Bi),Gn=n(Bi,"P",{});var K8=s(Gn);Rnt=r(K8,"The model class to instantiate is selected based on the "),v8e=n(K8,"CODE",{});var nla=s(v8e);Pnt=r(nla,"model_type"),nla.forEach(t),Bnt=r(K8,` property of the config object (either
passed as an argument or loaded from `),b8e=n(K8,"CODE",{});var sla=s(b8e);Int=r(sla,"pretrained_model_name_or_path"),sla.forEach(t),Nnt=r(K8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=n(K8,"CODE",{});var lla=s(F8e);qnt=r(lla,"pretrained_model_name_or_path"),lla.forEach(t),jnt=r(K8,":"),K8.forEach(t),Dnt=i(Bi),xe=n(Bi,"UL",{});var qe=s(xe);q6=n(qe,"LI",{});var rJe=s(q6);T8e=n(rJe,"STRONG",{});var ila=s(T8e);Gnt=r(ila,"bart"),ila.forEach(t),Ont=r(rJe," \u2014 "),Gae=n(rJe,"A",{href:!0});var dla=s(Gae);Vnt=r(dla,"FlaxBartForCausalLM"),dla.forEach(t),Xnt=r(rJe," (BART model)"),rJe.forEach(t),znt=i(qe),j6=n(qe,"LI",{});var tJe=s(j6);M8e=n(tJe,"STRONG",{});var cla=s(M8e);Qnt=r(cla,"bert"),cla.forEach(t),Wnt=r(tJe," \u2014 "),Oae=n(tJe,"A",{href:!0});var fla=s(Oae);Unt=r(fla,"FlaxBertForCausalLM"),fla.forEach(t),Hnt=r(tJe," (BERT model)"),tJe.forEach(t),Jnt=i(qe),D6=n(qe,"LI",{});var aJe=s(D6);E8e=n(aJe,"STRONG",{});var mla=s(E8e);Ynt=r(mla,"big_bird"),mla.forEach(t),Knt=r(aJe," \u2014 "),Vae=n(aJe,"A",{href:!0});var gla=s(Vae);Znt=r(gla,"FlaxBigBirdForCausalLM"),gla.forEach(t),est=r(aJe," (BigBird model)"),aJe.forEach(t),ost=i(qe),G6=n(qe,"LI",{});var nJe=s(G6);C8e=n(nJe,"STRONG",{});var hla=s(C8e);rst=r(hla,"electra"),hla.forEach(t),tst=r(nJe," \u2014 "),Xae=n(nJe,"A",{href:!0});var ula=s(Xae);ast=r(ula,"FlaxElectraForCausalLM"),ula.forEach(t),nst=r(nJe," (ELECTRA model)"),nJe.forEach(t),sst=i(qe),O6=n(qe,"LI",{});var sJe=s(O6);w8e=n(sJe,"STRONG",{});var pla=s(w8e);lst=r(pla,"gpt2"),pla.forEach(t),ist=r(sJe," \u2014 "),zae=n(sJe,"A",{href:!0});var _la=s(zae);dst=r(_la,"FlaxGPT2LMHeadModel"),_la.forEach(t),cst=r(sJe," (OpenAI GPT-2 model)"),sJe.forEach(t),fst=i(qe),V6=n(qe,"LI",{});var lJe=s(V6);A8e=n(lJe,"STRONG",{});var vla=s(A8e);mst=r(vla,"gpt_neo"),vla.forEach(t),gst=r(lJe," \u2014 "),Qae=n(lJe,"A",{href:!0});var bla=s(Qae);hst=r(bla,"FlaxGPTNeoForCausalLM"),bla.forEach(t),ust=r(lJe," (GPT Neo model)"),lJe.forEach(t),pst=i(qe),X6=n(qe,"LI",{});var iJe=s(X6);L8e=n(iJe,"STRONG",{});var Fla=s(L8e);_st=r(Fla,"gptj"),Fla.forEach(t),vst=r(iJe," \u2014 "),Wae=n(iJe,"A",{href:!0});var Tla=s(Wae);bst=r(Tla,"FlaxGPTJForCausalLM"),Tla.forEach(t),Fst=r(iJe," (GPT-J model)"),iJe.forEach(t),Tst=i(qe),z6=n(qe,"LI",{});var dJe=s(z6);y8e=n(dJe,"STRONG",{});var Mla=s(y8e);Mst=r(Mla,"opt"),Mla.forEach(t),Est=r(dJe," \u2014 "),Uae=n(dJe,"A",{href:!0});var Ela=s(Uae);Cst=r(Ela,"FlaxOPTForCausalLM"),Ela.forEach(t),wst=r(dJe," (OPT model)"),dJe.forEach(t),Ast=i(qe),Q6=n(qe,"LI",{});var cJe=s(Q6);x8e=n(cJe,"STRONG",{});var Cla=s(x8e);Lst=r(Cla,"roberta"),Cla.forEach(t),yst=r(cJe," \u2014 "),Hae=n(cJe,"A",{href:!0});var wla=s(Hae);xst=r(wla,"FlaxRobertaForCausalLM"),wla.forEach(t),$st=r(cJe," (RoBERTa model)"),cJe.forEach(t),kst=i(qe),W6=n(qe,"LI",{});var fJe=s(W6);$8e=n(fJe,"STRONG",{});var Ala=s($8e);Sst=r(Ala,"xglm"),Ala.forEach(t),Rst=r(fJe," \u2014 "),Jae=n(fJe,"A",{href:!0});var Lla=s(Jae);Pst=r(Lla,"FlaxXGLMForCausalLM"),Lla.forEach(t),Bst=r(fJe," (XGLM model)"),fJe.forEach(t),qe.forEach(t),Ist=i(Bi),T(U6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),CZe=i(f),Vf=n(f,"H2",{class:!0});var Goo=s(Vf);H6=n(Goo,"A",{id:!0,class:!0,href:!0});var yla=s(H6);k8e=n(yla,"SPAN",{});var xla=s(k8e);T(rR.$$.fragment,xla),xla.forEach(t),yla.forEach(t),Nst=i(Goo),S8e=n(Goo,"SPAN",{});var $la=s(S8e);qst=r($la,"FlaxAutoModelForPreTraining"),$la.forEach(t),Goo.forEach(t),wZe=i(f),Cr=n(f,"DIV",{class:!0});var Ii=s(Cr);T(tR.$$.fragment,Ii),jst=i(Ii),Xf=n(Ii,"P",{});var xie=s(Xf);Dst=r(xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Yae=n(xie,"A",{href:!0});var kla=s(Yae);Gst=r(kla,"from_pretrained()"),kla.forEach(t),Ost=r(xie," class method or the "),Kae=n(xie,"A",{href:!0});var Sla=s(Kae);Vst=r(Sla,"from_config()"),Sla.forEach(t),Xst=r(xie,` class
method.`),xie.forEach(t),zst=i(Ii),aR=n(Ii,"P",{});var Ooo=s(aR);Qst=r(Ooo,"This class cannot be instantiated directly using "),R8e=n(Ooo,"CODE",{});var Rla=s(R8e);Wst=r(Rla,"__init__()"),Rla.forEach(t),Ust=r(Ooo," (throws an error)."),Ooo.forEach(t),Hst=i(Ii),ia=n(Ii,"DIV",{class:!0});var Z8=s(ia);T(nR.$$.fragment,Z8),Jst=i(Z8),P8e=n(Z8,"P",{});var Pla=s(P8e);Yst=r(Pla,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Pla.forEach(t),Kst=i(Z8),zf=n(Z8,"P",{});var $ie=s(zf);Zst=r($ie,`Note:
Loading a model from its configuration file does `),B8e=n($ie,"STRONG",{});var Bla=s(B8e);elt=r(Bla,"not"),Bla.forEach(t),olt=r($ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=n($ie,"A",{href:!0});var Ila=s(Zae);rlt=r(Ila,"from_pretrained()"),Ila.forEach(t),tlt=r($ie," to load the model weights."),$ie.forEach(t),alt=i(Z8),T(J6.$$.fragment,Z8),Z8.forEach(t),nlt=i(Ii),et=n(Ii,"DIV",{class:!0});var Ni=s(et);T(sR.$$.fragment,Ni),slt=i(Ni),I8e=n(Ni,"P",{});var Nla=s(I8e);llt=r(Nla,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Nla.forEach(t),ilt=i(Ni),On=n(Ni,"P",{});var e9=s(On);dlt=r(e9,"The model class to instantiate is selected based on the "),N8e=n(e9,"CODE",{});var qla=s(N8e);clt=r(qla,"model_type"),qla.forEach(t),flt=r(e9,` property of the config object (either
passed as an argument or loaded from `),q8e=n(e9,"CODE",{});var jla=s(q8e);mlt=r(jla,"pretrained_model_name_or_path"),jla.forEach(t),glt=r(e9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j8e=n(e9,"CODE",{});var Dla=s(j8e);hlt=r(Dla,"pretrained_model_name_or_path"),Dla.forEach(t),ult=r(e9,":"),e9.forEach(t),plt=i(Ni),Ee=n(Ni,"UL",{});var we=s(Ee);Y6=n(we,"LI",{});var mJe=s(Y6);D8e=n(mJe,"STRONG",{});var Gla=s(D8e);_lt=r(Gla,"albert"),Gla.forEach(t),vlt=r(mJe," \u2014 "),ene=n(mJe,"A",{href:!0});var Ola=s(ene);blt=r(Ola,"FlaxAlbertForPreTraining"),Ola.forEach(t),Flt=r(mJe," (ALBERT model)"),mJe.forEach(t),Tlt=i(we),K6=n(we,"LI",{});var gJe=s(K6);G8e=n(gJe,"STRONG",{});var Vla=s(G8e);Mlt=r(Vla,"bart"),Vla.forEach(t),Elt=r(gJe," \u2014 "),one=n(gJe,"A",{href:!0});var Xla=s(one);Clt=r(Xla,"FlaxBartForConditionalGeneration"),Xla.forEach(t),wlt=r(gJe," (BART model)"),gJe.forEach(t),Alt=i(we),Z6=n(we,"LI",{});var hJe=s(Z6);O8e=n(hJe,"STRONG",{});var zla=s(O8e);Llt=r(zla,"bert"),zla.forEach(t),ylt=r(hJe," \u2014 "),rne=n(hJe,"A",{href:!0});var Qla=s(rne);xlt=r(Qla,"FlaxBertForPreTraining"),Qla.forEach(t),$lt=r(hJe," (BERT model)"),hJe.forEach(t),klt=i(we),e7=n(we,"LI",{});var uJe=s(e7);V8e=n(uJe,"STRONG",{});var Wla=s(V8e);Slt=r(Wla,"big_bird"),Wla.forEach(t),Rlt=r(uJe," \u2014 "),tne=n(uJe,"A",{href:!0});var Ula=s(tne);Plt=r(Ula,"FlaxBigBirdForPreTraining"),Ula.forEach(t),Blt=r(uJe," (BigBird model)"),uJe.forEach(t),Ilt=i(we),o7=n(we,"LI",{});var pJe=s(o7);X8e=n(pJe,"STRONG",{});var Hla=s(X8e);Nlt=r(Hla,"electra"),Hla.forEach(t),qlt=r(pJe," \u2014 "),ane=n(pJe,"A",{href:!0});var Jla=s(ane);jlt=r(Jla,"FlaxElectraForPreTraining"),Jla.forEach(t),Dlt=r(pJe," (ELECTRA model)"),pJe.forEach(t),Glt=i(we),r7=n(we,"LI",{});var _Je=s(r7);z8e=n(_Je,"STRONG",{});var Yla=s(z8e);Olt=r(Yla,"longt5"),Yla.forEach(t),Vlt=r(_Je," \u2014 "),nne=n(_Je,"A",{href:!0});var Kla=s(nne);Xlt=r(Kla,"FlaxLongT5ForConditionalGeneration"),Kla.forEach(t),zlt=r(_Je," (LongT5 model)"),_Je.forEach(t),Qlt=i(we),t7=n(we,"LI",{});var vJe=s(t7);Q8e=n(vJe,"STRONG",{});var Zla=s(Q8e);Wlt=r(Zla,"mbart"),Zla.forEach(t),Ult=r(vJe," \u2014 "),sne=n(vJe,"A",{href:!0});var eia=s(sne);Hlt=r(eia,"FlaxMBartForConditionalGeneration"),eia.forEach(t),Jlt=r(vJe," (mBART model)"),vJe.forEach(t),Ylt=i(we),a7=n(we,"LI",{});var bJe=s(a7);W8e=n(bJe,"STRONG",{});var oia=s(W8e);Klt=r(oia,"mt5"),oia.forEach(t),Zlt=r(bJe," \u2014 "),lne=n(bJe,"A",{href:!0});var ria=s(lne);eit=r(ria,"FlaxMT5ForConditionalGeneration"),ria.forEach(t),oit=r(bJe," (MT5 model)"),bJe.forEach(t),rit=i(we),n7=n(we,"LI",{});var FJe=s(n7);U8e=n(FJe,"STRONG",{});var tia=s(U8e);tit=r(tia,"roberta"),tia.forEach(t),ait=r(FJe," \u2014 "),ine=n(FJe,"A",{href:!0});var aia=s(ine);nit=r(aia,"FlaxRobertaForMaskedLM"),aia.forEach(t),sit=r(FJe," (RoBERTa model)"),FJe.forEach(t),lit=i(we),s7=n(we,"LI",{});var TJe=s(s7);H8e=n(TJe,"STRONG",{});var nia=s(H8e);iit=r(nia,"roformer"),nia.forEach(t),dit=r(TJe," \u2014 "),dne=n(TJe,"A",{href:!0});var sia=s(dne);cit=r(sia,"FlaxRoFormerForMaskedLM"),sia.forEach(t),fit=r(TJe," (RoFormer model)"),TJe.forEach(t),mit=i(we),l7=n(we,"LI",{});var MJe=s(l7);J8e=n(MJe,"STRONG",{});var lia=s(J8e);git=r(lia,"t5"),lia.forEach(t),hit=r(MJe," \u2014 "),cne=n(MJe,"A",{href:!0});var iia=s(cne);uit=r(iia,"FlaxT5ForConditionalGeneration"),iia.forEach(t),pit=r(MJe," (T5 model)"),MJe.forEach(t),_it=i(we),i7=n(we,"LI",{});var EJe=s(i7);Y8e=n(EJe,"STRONG",{});var dia=s(Y8e);vit=r(dia,"wav2vec2"),dia.forEach(t),bit=r(EJe," \u2014 "),fne=n(EJe,"A",{href:!0});var cia=s(fne);Fit=r(cia,"FlaxWav2Vec2ForPreTraining"),cia.forEach(t),Tit=r(EJe," (Wav2Vec2 model)"),EJe.forEach(t),Mit=i(we),d7=n(we,"LI",{});var CJe=s(d7);K8e=n(CJe,"STRONG",{});var fia=s(K8e);Eit=r(fia,"xlm-roberta"),fia.forEach(t),Cit=r(CJe," \u2014 "),mne=n(CJe,"A",{href:!0});var mia=s(mne);wit=r(mia,"FlaxXLMRobertaForMaskedLM"),mia.forEach(t),Ait=r(CJe," (XLM-RoBERTa model)"),CJe.forEach(t),we.forEach(t),Lit=i(Ni),T(c7.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),AZe=i(f),Qf=n(f,"H2",{class:!0});var Voo=s(Qf);f7=n(Voo,"A",{id:!0,class:!0,href:!0});var gia=s(f7);Z8e=n(gia,"SPAN",{});var hia=s(Z8e);T(lR.$$.fragment,hia),hia.forEach(t),gia.forEach(t),yit=i(Voo),e9e=n(Voo,"SPAN",{});var uia=s(e9e);xit=r(uia,"FlaxAutoModelForMaskedLM"),uia.forEach(t),Voo.forEach(t),LZe=i(f),wr=n(f,"DIV",{class:!0});var qi=s(wr);T(iR.$$.fragment,qi),$it=i(qi),Wf=n(qi,"P",{});var kie=s(Wf);kit=r(kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gne=n(kie,"A",{href:!0});var pia=s(gne);Sit=r(pia,"from_pretrained()"),pia.forEach(t),Rit=r(kie," class method or the "),hne=n(kie,"A",{href:!0});var _ia=s(hne);Pit=r(_ia,"from_config()"),_ia.forEach(t),Bit=r(kie,` class
method.`),kie.forEach(t),Iit=i(qi),dR=n(qi,"P",{});var Xoo=s(dR);Nit=r(Xoo,"This class cannot be instantiated directly using "),o9e=n(Xoo,"CODE",{});var via=s(o9e);qit=r(via,"__init__()"),via.forEach(t),jit=r(Xoo," (throws an error)."),Xoo.forEach(t),Dit=i(qi),da=n(qi,"DIV",{class:!0});var o9=s(da);T(cR.$$.fragment,o9),Git=i(o9),r9e=n(o9,"P",{});var bia=s(r9e);Oit=r(bia,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),bia.forEach(t),Vit=i(o9),Uf=n(o9,"P",{});var Sie=s(Uf);Xit=r(Sie,`Note:
Loading a model from its configuration file does `),t9e=n(Sie,"STRONG",{});var Fia=s(t9e);zit=r(Fia,"not"),Fia.forEach(t),Qit=r(Sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),une=n(Sie,"A",{href:!0});var Tia=s(une);Wit=r(Tia,"from_pretrained()"),Tia.forEach(t),Uit=r(Sie," to load the model weights."),Sie.forEach(t),Hit=i(o9),T(m7.$$.fragment,o9),o9.forEach(t),Jit=i(qi),ot=n(qi,"DIV",{class:!0});var ji=s(ot);T(fR.$$.fragment,ji),Yit=i(ji),a9e=n(ji,"P",{});var Mia=s(a9e);Kit=r(Mia,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Mia.forEach(t),Zit=i(ji),Vn=n(ji,"P",{});var r9=s(Vn);edt=r(r9,"The model class to instantiate is selected based on the "),n9e=n(r9,"CODE",{});var Eia=s(n9e);odt=r(Eia,"model_type"),Eia.forEach(t),rdt=r(r9,` property of the config object (either
passed as an argument or loaded from `),s9e=n(r9,"CODE",{});var Cia=s(s9e);tdt=r(Cia,"pretrained_model_name_or_path"),Cia.forEach(t),adt=r(r9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=n(r9,"CODE",{});var wia=s(l9e);ndt=r(wia,"pretrained_model_name_or_path"),wia.forEach(t),sdt=r(r9,":"),r9.forEach(t),ldt=i(ji),$e=n(ji,"UL",{});var je=s($e);g7=n(je,"LI",{});var wJe=s(g7);i9e=n(wJe,"STRONG",{});var Aia=s(i9e);idt=r(Aia,"albert"),Aia.forEach(t),ddt=r(wJe," \u2014 "),pne=n(wJe,"A",{href:!0});var Lia=s(pne);cdt=r(Lia,"FlaxAlbertForMaskedLM"),Lia.forEach(t),fdt=r(wJe," (ALBERT model)"),wJe.forEach(t),mdt=i(je),h7=n(je,"LI",{});var AJe=s(h7);d9e=n(AJe,"STRONG",{});var yia=s(d9e);gdt=r(yia,"bart"),yia.forEach(t),hdt=r(AJe," \u2014 "),_ne=n(AJe,"A",{href:!0});var xia=s(_ne);udt=r(xia,"FlaxBartForConditionalGeneration"),xia.forEach(t),pdt=r(AJe," (BART model)"),AJe.forEach(t),_dt=i(je),u7=n(je,"LI",{});var LJe=s(u7);c9e=n(LJe,"STRONG",{});var $ia=s(c9e);vdt=r($ia,"bert"),$ia.forEach(t),bdt=r(LJe," \u2014 "),vne=n(LJe,"A",{href:!0});var kia=s(vne);Fdt=r(kia,"FlaxBertForMaskedLM"),kia.forEach(t),Tdt=r(LJe," (BERT model)"),LJe.forEach(t),Mdt=i(je),p7=n(je,"LI",{});var yJe=s(p7);f9e=n(yJe,"STRONG",{});var Sia=s(f9e);Edt=r(Sia,"big_bird"),Sia.forEach(t),Cdt=r(yJe," \u2014 "),bne=n(yJe,"A",{href:!0});var Ria=s(bne);wdt=r(Ria,"FlaxBigBirdForMaskedLM"),Ria.forEach(t),Adt=r(yJe," (BigBird model)"),yJe.forEach(t),Ldt=i(je),_7=n(je,"LI",{});var xJe=s(_7);m9e=n(xJe,"STRONG",{});var Pia=s(m9e);ydt=r(Pia,"distilbert"),Pia.forEach(t),xdt=r(xJe," \u2014 "),Fne=n(xJe,"A",{href:!0});var Bia=s(Fne);$dt=r(Bia,"FlaxDistilBertForMaskedLM"),Bia.forEach(t),kdt=r(xJe," (DistilBERT model)"),xJe.forEach(t),Sdt=i(je),v7=n(je,"LI",{});var $Je=s(v7);g9e=n($Je,"STRONG",{});var Iia=s(g9e);Rdt=r(Iia,"electra"),Iia.forEach(t),Pdt=r($Je," \u2014 "),Tne=n($Je,"A",{href:!0});var Nia=s(Tne);Bdt=r(Nia,"FlaxElectraForMaskedLM"),Nia.forEach(t),Idt=r($Je," (ELECTRA model)"),$Je.forEach(t),Ndt=i(je),b7=n(je,"LI",{});var kJe=s(b7);h9e=n(kJe,"STRONG",{});var qia=s(h9e);qdt=r(qia,"mbart"),qia.forEach(t),jdt=r(kJe," \u2014 "),Mne=n(kJe,"A",{href:!0});var jia=s(Mne);Ddt=r(jia,"FlaxMBartForConditionalGeneration"),jia.forEach(t),Gdt=r(kJe," (mBART model)"),kJe.forEach(t),Odt=i(je),F7=n(je,"LI",{});var SJe=s(F7);u9e=n(SJe,"STRONG",{});var Dia=s(u9e);Vdt=r(Dia,"roberta"),Dia.forEach(t),Xdt=r(SJe," \u2014 "),Ene=n(SJe,"A",{href:!0});var Gia=s(Ene);zdt=r(Gia,"FlaxRobertaForMaskedLM"),Gia.forEach(t),Qdt=r(SJe," (RoBERTa model)"),SJe.forEach(t),Wdt=i(je),T7=n(je,"LI",{});var RJe=s(T7);p9e=n(RJe,"STRONG",{});var Oia=s(p9e);Udt=r(Oia,"roformer"),Oia.forEach(t),Hdt=r(RJe," \u2014 "),Cne=n(RJe,"A",{href:!0});var Via=s(Cne);Jdt=r(Via,"FlaxRoFormerForMaskedLM"),Via.forEach(t),Ydt=r(RJe," (RoFormer model)"),RJe.forEach(t),Kdt=i(je),M7=n(je,"LI",{});var PJe=s(M7);_9e=n(PJe,"STRONG",{});var Xia=s(_9e);Zdt=r(Xia,"xlm-roberta"),Xia.forEach(t),ect=r(PJe," \u2014 "),wne=n(PJe,"A",{href:!0});var zia=s(wne);oct=r(zia,"FlaxXLMRobertaForMaskedLM"),zia.forEach(t),rct=r(PJe," (XLM-RoBERTa model)"),PJe.forEach(t),je.forEach(t),tct=i(ji),T(E7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),yZe=i(f),Hf=n(f,"H2",{class:!0});var zoo=s(Hf);C7=n(zoo,"A",{id:!0,class:!0,href:!0});var Qia=s(C7);v9e=n(Qia,"SPAN",{});var Wia=s(v9e);T(mR.$$.fragment,Wia),Wia.forEach(t),Qia.forEach(t),act=i(zoo),b9e=n(zoo,"SPAN",{});var Uia=s(b9e);nct=r(Uia,"FlaxAutoModelForSeq2SeqLM"),Uia.forEach(t),zoo.forEach(t),xZe=i(f),Ar=n(f,"DIV",{class:!0});var Di=s(Ar);T(gR.$$.fragment,Di),sct=i(Di),Jf=n(Di,"P",{});var Rie=s(Jf);lct=r(Rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Ane=n(Rie,"A",{href:!0});var Hia=s(Ane);ict=r(Hia,"from_pretrained()"),Hia.forEach(t),dct=r(Rie," class method or the "),Lne=n(Rie,"A",{href:!0});var Jia=s(Lne);cct=r(Jia,"from_config()"),Jia.forEach(t),fct=r(Rie,` class
method.`),Rie.forEach(t),mct=i(Di),hR=n(Di,"P",{});var Qoo=s(hR);gct=r(Qoo,"This class cannot be instantiated directly using "),F9e=n(Qoo,"CODE",{});var Yia=s(F9e);hct=r(Yia,"__init__()"),Yia.forEach(t),uct=r(Qoo," (throws an error)."),Qoo.forEach(t),pct=i(Di),ca=n(Di,"DIV",{class:!0});var t9=s(ca);T(uR.$$.fragment,t9),_ct=i(t9),T9e=n(t9,"P",{});var Kia=s(T9e);vct=r(Kia,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Kia.forEach(t),bct=i(t9),Yf=n(t9,"P",{});var Pie=s(Yf);Fct=r(Pie,`Note:
Loading a model from its configuration file does `),M9e=n(Pie,"STRONG",{});var Zia=s(M9e);Tct=r(Zia,"not"),Zia.forEach(t),Mct=r(Pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yne=n(Pie,"A",{href:!0});var eda=s(yne);Ect=r(eda,"from_pretrained()"),eda.forEach(t),Cct=r(Pie," to load the model weights."),Pie.forEach(t),wct=i(t9),T(w7.$$.fragment,t9),t9.forEach(t),Act=i(Di),rt=n(Di,"DIV",{class:!0});var Gi=s(rt);T(pR.$$.fragment,Gi),Lct=i(Gi),E9e=n(Gi,"P",{});var oda=s(E9e);yct=r(oda,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oda.forEach(t),xct=i(Gi),Xn=n(Gi,"P",{});var a9=s(Xn);$ct=r(a9,"The model class to instantiate is selected based on the "),C9e=n(a9,"CODE",{});var rda=s(C9e);kct=r(rda,"model_type"),rda.forEach(t),Sct=r(a9,` property of the config object (either
passed as an argument or loaded from `),w9e=n(a9,"CODE",{});var tda=s(w9e);Rct=r(tda,"pretrained_model_name_or_path"),tda.forEach(t),Pct=r(a9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A9e=n(a9,"CODE",{});var ada=s(A9e);Bct=r(ada,"pretrained_model_name_or_path"),ada.forEach(t),Ict=r(a9,":"),a9.forEach(t),Nct=i(Gi),ke=n(Gi,"UL",{});var De=s(ke);A7=n(De,"LI",{});var BJe=s(A7);L9e=n(BJe,"STRONG",{});var nda=s(L9e);qct=r(nda,"bart"),nda.forEach(t),jct=r(BJe," \u2014 "),xne=n(BJe,"A",{href:!0});var sda=s(xne);Dct=r(sda,"FlaxBartForConditionalGeneration"),sda.forEach(t),Gct=r(BJe," (BART model)"),BJe.forEach(t),Oct=i(De),L7=n(De,"LI",{});var IJe=s(L7);y9e=n(IJe,"STRONG",{});var lda=s(y9e);Vct=r(lda,"blenderbot"),lda.forEach(t),Xct=r(IJe," \u2014 "),$ne=n(IJe,"A",{href:!0});var ida=s($ne);zct=r(ida,"FlaxBlenderbotForConditionalGeneration"),ida.forEach(t),Qct=r(IJe," (Blenderbot model)"),IJe.forEach(t),Wct=i(De),y7=n(De,"LI",{});var NJe=s(y7);x9e=n(NJe,"STRONG",{});var dda=s(x9e);Uct=r(dda,"blenderbot-small"),dda.forEach(t),Hct=r(NJe," \u2014 "),kne=n(NJe,"A",{href:!0});var cda=s(kne);Jct=r(cda,"FlaxBlenderbotSmallForConditionalGeneration"),cda.forEach(t),Yct=r(NJe," (BlenderbotSmall model)"),NJe.forEach(t),Kct=i(De),x7=n(De,"LI",{});var qJe=s(x7);$9e=n(qJe,"STRONG",{});var fda=s($9e);Zct=r(fda,"encoder-decoder"),fda.forEach(t),eft=r(qJe," \u2014 "),Sne=n(qJe,"A",{href:!0});var mda=s(Sne);oft=r(mda,"FlaxEncoderDecoderModel"),mda.forEach(t),rft=r(qJe," (Encoder decoder model)"),qJe.forEach(t),tft=i(De),$7=n(De,"LI",{});var jJe=s($7);k9e=n(jJe,"STRONG",{});var gda=s(k9e);aft=r(gda,"longt5"),gda.forEach(t),nft=r(jJe," \u2014 "),Rne=n(jJe,"A",{href:!0});var hda=s(Rne);sft=r(hda,"FlaxLongT5ForConditionalGeneration"),hda.forEach(t),lft=r(jJe," (LongT5 model)"),jJe.forEach(t),ift=i(De),k7=n(De,"LI",{});var DJe=s(k7);S9e=n(DJe,"STRONG",{});var uda=s(S9e);dft=r(uda,"marian"),uda.forEach(t),cft=r(DJe," \u2014 "),Pne=n(DJe,"A",{href:!0});var pda=s(Pne);fft=r(pda,"FlaxMarianMTModel"),pda.forEach(t),mft=r(DJe," (Marian model)"),DJe.forEach(t),gft=i(De),S7=n(De,"LI",{});var GJe=s(S7);R9e=n(GJe,"STRONG",{});var _da=s(R9e);hft=r(_da,"mbart"),_da.forEach(t),uft=r(GJe," \u2014 "),Bne=n(GJe,"A",{href:!0});var vda=s(Bne);pft=r(vda,"FlaxMBartForConditionalGeneration"),vda.forEach(t),_ft=r(GJe," (mBART model)"),GJe.forEach(t),vft=i(De),R7=n(De,"LI",{});var OJe=s(R7);P9e=n(OJe,"STRONG",{});var bda=s(P9e);bft=r(bda,"mt5"),bda.forEach(t),Fft=r(OJe," \u2014 "),Ine=n(OJe,"A",{href:!0});var Fda=s(Ine);Tft=r(Fda,"FlaxMT5ForConditionalGeneration"),Fda.forEach(t),Mft=r(OJe," (MT5 model)"),OJe.forEach(t),Eft=i(De),P7=n(De,"LI",{});var VJe=s(P7);B9e=n(VJe,"STRONG",{});var Tda=s(B9e);Cft=r(Tda,"pegasus"),Tda.forEach(t),wft=r(VJe," \u2014 "),Nne=n(VJe,"A",{href:!0});var Mda=s(Nne);Aft=r(Mda,"FlaxPegasusForConditionalGeneration"),Mda.forEach(t),Lft=r(VJe," (Pegasus model)"),VJe.forEach(t),yft=i(De),B7=n(De,"LI",{});var XJe=s(B7);I9e=n(XJe,"STRONG",{});var Eda=s(I9e);xft=r(Eda,"t5"),Eda.forEach(t),$ft=r(XJe," \u2014 "),qne=n(XJe,"A",{href:!0});var Cda=s(qne);kft=r(Cda,"FlaxT5ForConditionalGeneration"),Cda.forEach(t),Sft=r(XJe," (T5 model)"),XJe.forEach(t),De.forEach(t),Rft=i(Gi),T(I7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),$Ze=i(f),Kf=n(f,"H2",{class:!0});var Woo=s(Kf);N7=n(Woo,"A",{id:!0,class:!0,href:!0});var wda=s(N7);N9e=n(wda,"SPAN",{});var Ada=s(N9e);T(_R.$$.fragment,Ada),Ada.forEach(t),wda.forEach(t),Pft=i(Woo),q9e=n(Woo,"SPAN",{});var Lda=s(q9e);Bft=r(Lda,"FlaxAutoModelForSequenceClassification"),Lda.forEach(t),Woo.forEach(t),kZe=i(f),Lr=n(f,"DIV",{class:!0});var Oi=s(Lr);T(vR.$$.fragment,Oi),Ift=i(Oi),Zf=n(Oi,"P",{});var Bie=s(Zf);Nft=r(Bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),jne=n(Bie,"A",{href:!0});var yda=s(jne);qft=r(yda,"from_pretrained()"),yda.forEach(t),jft=r(Bie," class method or the "),Dne=n(Bie,"A",{href:!0});var xda=s(Dne);Dft=r(xda,"from_config()"),xda.forEach(t),Gft=r(Bie,` class
method.`),Bie.forEach(t),Oft=i(Oi),bR=n(Oi,"P",{});var Uoo=s(bR);Vft=r(Uoo,"This class cannot be instantiated directly using "),j9e=n(Uoo,"CODE",{});var $da=s(j9e);Xft=r($da,"__init__()"),$da.forEach(t),zft=r(Uoo," (throws an error)."),Uoo.forEach(t),Qft=i(Oi),fa=n(Oi,"DIV",{class:!0});var n9=s(fa);T(FR.$$.fragment,n9),Wft=i(n9),D9e=n(n9,"P",{});var kda=s(D9e);Uft=r(kda,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),kda.forEach(t),Hft=i(n9),em=n(n9,"P",{});var Iie=s(em);Jft=r(Iie,`Note:
Loading a model from its configuration file does `),G9e=n(Iie,"STRONG",{});var Sda=s(G9e);Yft=r(Sda,"not"),Sda.forEach(t),Kft=r(Iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gne=n(Iie,"A",{href:!0});var Rda=s(Gne);Zft=r(Rda,"from_pretrained()"),Rda.forEach(t),emt=r(Iie," to load the model weights."),Iie.forEach(t),omt=i(n9),T(q7.$$.fragment,n9),n9.forEach(t),rmt=i(Oi),tt=n(Oi,"DIV",{class:!0});var Vi=s(tt);T(TR.$$.fragment,Vi),tmt=i(Vi),O9e=n(Vi,"P",{});var Pda=s(O9e);amt=r(Pda,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Pda.forEach(t),nmt=i(Vi),zn=n(Vi,"P",{});var s9=s(zn);smt=r(s9,"The model class to instantiate is selected based on the "),V9e=n(s9,"CODE",{});var Bda=s(V9e);lmt=r(Bda,"model_type"),Bda.forEach(t),imt=r(s9,` property of the config object (either
passed as an argument or loaded from `),X9e=n(s9,"CODE",{});var Ida=s(X9e);dmt=r(Ida,"pretrained_model_name_or_path"),Ida.forEach(t),cmt=r(s9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=n(s9,"CODE",{});var Nda=s(z9e);fmt=r(Nda,"pretrained_model_name_or_path"),Nda.forEach(t),mmt=r(s9,":"),s9.forEach(t),gmt=i(Vi),Se=n(Vi,"UL",{});var Ge=s(Se);j7=n(Ge,"LI",{});var zJe=s(j7);Q9e=n(zJe,"STRONG",{});var qda=s(Q9e);hmt=r(qda,"albert"),qda.forEach(t),umt=r(zJe," \u2014 "),One=n(zJe,"A",{href:!0});var jda=s(One);pmt=r(jda,"FlaxAlbertForSequenceClassification"),jda.forEach(t),_mt=r(zJe," (ALBERT model)"),zJe.forEach(t),vmt=i(Ge),D7=n(Ge,"LI",{});var QJe=s(D7);W9e=n(QJe,"STRONG",{});var Dda=s(W9e);bmt=r(Dda,"bart"),Dda.forEach(t),Fmt=r(QJe," \u2014 "),Vne=n(QJe,"A",{href:!0});var Gda=s(Vne);Tmt=r(Gda,"FlaxBartForSequenceClassification"),Gda.forEach(t),Mmt=r(QJe," (BART model)"),QJe.forEach(t),Emt=i(Ge),G7=n(Ge,"LI",{});var WJe=s(G7);U9e=n(WJe,"STRONG",{});var Oda=s(U9e);Cmt=r(Oda,"bert"),Oda.forEach(t),wmt=r(WJe," \u2014 "),Xne=n(WJe,"A",{href:!0});var Vda=s(Xne);Amt=r(Vda,"FlaxBertForSequenceClassification"),Vda.forEach(t),Lmt=r(WJe," (BERT model)"),WJe.forEach(t),ymt=i(Ge),O7=n(Ge,"LI",{});var UJe=s(O7);H9e=n(UJe,"STRONG",{});var Xda=s(H9e);xmt=r(Xda,"big_bird"),Xda.forEach(t),$mt=r(UJe," \u2014 "),zne=n(UJe,"A",{href:!0});var zda=s(zne);kmt=r(zda,"FlaxBigBirdForSequenceClassification"),zda.forEach(t),Smt=r(UJe," (BigBird model)"),UJe.forEach(t),Rmt=i(Ge),V7=n(Ge,"LI",{});var HJe=s(V7);J9e=n(HJe,"STRONG",{});var Qda=s(J9e);Pmt=r(Qda,"distilbert"),Qda.forEach(t),Bmt=r(HJe," \u2014 "),Qne=n(HJe,"A",{href:!0});var Wda=s(Qne);Imt=r(Wda,"FlaxDistilBertForSequenceClassification"),Wda.forEach(t),Nmt=r(HJe," (DistilBERT model)"),HJe.forEach(t),qmt=i(Ge),X7=n(Ge,"LI",{});var JJe=s(X7);Y9e=n(JJe,"STRONG",{});var Uda=s(Y9e);jmt=r(Uda,"electra"),Uda.forEach(t),Dmt=r(JJe," \u2014 "),Wne=n(JJe,"A",{href:!0});var Hda=s(Wne);Gmt=r(Hda,"FlaxElectraForSequenceClassification"),Hda.forEach(t),Omt=r(JJe," (ELECTRA model)"),JJe.forEach(t),Vmt=i(Ge),z7=n(Ge,"LI",{});var YJe=s(z7);K9e=n(YJe,"STRONG",{});var Jda=s(K9e);Xmt=r(Jda,"mbart"),Jda.forEach(t),zmt=r(YJe," \u2014 "),Une=n(YJe,"A",{href:!0});var Yda=s(Une);Qmt=r(Yda,"FlaxMBartForSequenceClassification"),Yda.forEach(t),Wmt=r(YJe," (mBART model)"),YJe.forEach(t),Umt=i(Ge),Q7=n(Ge,"LI",{});var KJe=s(Q7);Z9e=n(KJe,"STRONG",{});var Kda=s(Z9e);Hmt=r(Kda,"roberta"),Kda.forEach(t),Jmt=r(KJe," \u2014 "),Hne=n(KJe,"A",{href:!0});var Zda=s(Hne);Ymt=r(Zda,"FlaxRobertaForSequenceClassification"),Zda.forEach(t),Kmt=r(KJe," (RoBERTa model)"),KJe.forEach(t),Zmt=i(Ge),W7=n(Ge,"LI",{});var ZJe=s(W7);exe=n(ZJe,"STRONG",{});var eca=s(exe);egt=r(eca,"roformer"),eca.forEach(t),ogt=r(ZJe," \u2014 "),Jne=n(ZJe,"A",{href:!0});var oca=s(Jne);rgt=r(oca,"FlaxRoFormerForSequenceClassification"),oca.forEach(t),tgt=r(ZJe," (RoFormer model)"),ZJe.forEach(t),agt=i(Ge),U7=n(Ge,"LI",{});var eYe=s(U7);oxe=n(eYe,"STRONG",{});var rca=s(oxe);ngt=r(rca,"xlm-roberta"),rca.forEach(t),sgt=r(eYe," \u2014 "),Yne=n(eYe,"A",{href:!0});var tca=s(Yne);lgt=r(tca,"FlaxXLMRobertaForSequenceClassification"),tca.forEach(t),igt=r(eYe," (XLM-RoBERTa model)"),eYe.forEach(t),Ge.forEach(t),dgt=i(Vi),T(H7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),SZe=i(f),om=n(f,"H2",{class:!0});var Hoo=s(om);J7=n(Hoo,"A",{id:!0,class:!0,href:!0});var aca=s(J7);rxe=n(aca,"SPAN",{});var nca=s(rxe);T(MR.$$.fragment,nca),nca.forEach(t),aca.forEach(t),cgt=i(Hoo),txe=n(Hoo,"SPAN",{});var sca=s(txe);fgt=r(sca,"FlaxAutoModelForQuestionAnswering"),sca.forEach(t),Hoo.forEach(t),RZe=i(f),yr=n(f,"DIV",{class:!0});var Xi=s(yr);T(ER.$$.fragment,Xi),mgt=i(Xi),rm=n(Xi,"P",{});var Nie=s(rm);ggt=r(Nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Kne=n(Nie,"A",{href:!0});var lca=s(Kne);hgt=r(lca,"from_pretrained()"),lca.forEach(t),ugt=r(Nie," class method or the "),Zne=n(Nie,"A",{href:!0});var ica=s(Zne);pgt=r(ica,"from_config()"),ica.forEach(t),_gt=r(Nie,` class
method.`),Nie.forEach(t),vgt=i(Xi),CR=n(Xi,"P",{});var Joo=s(CR);bgt=r(Joo,"This class cannot be instantiated directly using "),axe=n(Joo,"CODE",{});var dca=s(axe);Fgt=r(dca,"__init__()"),dca.forEach(t),Tgt=r(Joo," (throws an error)."),Joo.forEach(t),Mgt=i(Xi),ma=n(Xi,"DIV",{class:!0});var l9=s(ma);T(wR.$$.fragment,l9),Egt=i(l9),nxe=n(l9,"P",{});var cca=s(nxe);Cgt=r(cca,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cca.forEach(t),wgt=i(l9),tm=n(l9,"P",{});var qie=s(tm);Agt=r(qie,`Note:
Loading a model from its configuration file does `),sxe=n(qie,"STRONG",{});var fca=s(sxe);Lgt=r(fca,"not"),fca.forEach(t),ygt=r(qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ese=n(qie,"A",{href:!0});var mca=s(ese);xgt=r(mca,"from_pretrained()"),mca.forEach(t),$gt=r(qie," to load the model weights."),qie.forEach(t),kgt=i(l9),T(Y7.$$.fragment,l9),l9.forEach(t),Sgt=i(Xi),at=n(Xi,"DIV",{class:!0});var zi=s(at);T(AR.$$.fragment,zi),Rgt=i(zi),lxe=n(zi,"P",{});var gca=s(lxe);Pgt=r(gca,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),gca.forEach(t),Bgt=i(zi),Qn=n(zi,"P",{});var i9=s(Qn);Igt=r(i9,"The model class to instantiate is selected based on the "),ixe=n(i9,"CODE",{});var hca=s(ixe);Ngt=r(hca,"model_type"),hca.forEach(t),qgt=r(i9,` property of the config object (either
passed as an argument or loaded from `),dxe=n(i9,"CODE",{});var uca=s(dxe);jgt=r(uca,"pretrained_model_name_or_path"),uca.forEach(t),Dgt=r(i9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cxe=n(i9,"CODE",{});var pca=s(cxe);Ggt=r(pca,"pretrained_model_name_or_path"),pca.forEach(t),Ogt=r(i9,":"),i9.forEach(t),Vgt=i(zi),Re=n(zi,"UL",{});var Oe=s(Re);K7=n(Oe,"LI",{});var oYe=s(K7);fxe=n(oYe,"STRONG",{});var _ca=s(fxe);Xgt=r(_ca,"albert"),_ca.forEach(t),zgt=r(oYe," \u2014 "),ose=n(oYe,"A",{href:!0});var vca=s(ose);Qgt=r(vca,"FlaxAlbertForQuestionAnswering"),vca.forEach(t),Wgt=r(oYe," (ALBERT model)"),oYe.forEach(t),Ugt=i(Oe),Z7=n(Oe,"LI",{});var rYe=s(Z7);mxe=n(rYe,"STRONG",{});var bca=s(mxe);Hgt=r(bca,"bart"),bca.forEach(t),Jgt=r(rYe," \u2014 "),rse=n(rYe,"A",{href:!0});var Fca=s(rse);Ygt=r(Fca,"FlaxBartForQuestionAnswering"),Fca.forEach(t),Kgt=r(rYe," (BART model)"),rYe.forEach(t),Zgt=i(Oe),eL=n(Oe,"LI",{});var tYe=s(eL);gxe=n(tYe,"STRONG",{});var Tca=s(gxe);eht=r(Tca,"bert"),Tca.forEach(t),oht=r(tYe," \u2014 "),tse=n(tYe,"A",{href:!0});var Mca=s(tse);rht=r(Mca,"FlaxBertForQuestionAnswering"),Mca.forEach(t),tht=r(tYe," (BERT model)"),tYe.forEach(t),aht=i(Oe),oL=n(Oe,"LI",{});var aYe=s(oL);hxe=n(aYe,"STRONG",{});var Eca=s(hxe);nht=r(Eca,"big_bird"),Eca.forEach(t),sht=r(aYe," \u2014 "),ase=n(aYe,"A",{href:!0});var Cca=s(ase);lht=r(Cca,"FlaxBigBirdForQuestionAnswering"),Cca.forEach(t),iht=r(aYe," (BigBird model)"),aYe.forEach(t),dht=i(Oe),rL=n(Oe,"LI",{});var nYe=s(rL);uxe=n(nYe,"STRONG",{});var wca=s(uxe);cht=r(wca,"distilbert"),wca.forEach(t),fht=r(nYe," \u2014 "),nse=n(nYe,"A",{href:!0});var Aca=s(nse);mht=r(Aca,"FlaxDistilBertForQuestionAnswering"),Aca.forEach(t),ght=r(nYe," (DistilBERT model)"),nYe.forEach(t),hht=i(Oe),tL=n(Oe,"LI",{});var sYe=s(tL);pxe=n(sYe,"STRONG",{});var Lca=s(pxe);uht=r(Lca,"electra"),Lca.forEach(t),pht=r(sYe," \u2014 "),sse=n(sYe,"A",{href:!0});var yca=s(sse);_ht=r(yca,"FlaxElectraForQuestionAnswering"),yca.forEach(t),vht=r(sYe," (ELECTRA model)"),sYe.forEach(t),bht=i(Oe),aL=n(Oe,"LI",{});var lYe=s(aL);_xe=n(lYe,"STRONG",{});var xca=s(_xe);Fht=r(xca,"mbart"),xca.forEach(t),Tht=r(lYe," \u2014 "),lse=n(lYe,"A",{href:!0});var $ca=s(lse);Mht=r($ca,"FlaxMBartForQuestionAnswering"),$ca.forEach(t),Eht=r(lYe," (mBART model)"),lYe.forEach(t),Cht=i(Oe),nL=n(Oe,"LI",{});var iYe=s(nL);vxe=n(iYe,"STRONG",{});var kca=s(vxe);wht=r(kca,"roberta"),kca.forEach(t),Aht=r(iYe," \u2014 "),ise=n(iYe,"A",{href:!0});var Sca=s(ise);Lht=r(Sca,"FlaxRobertaForQuestionAnswering"),Sca.forEach(t),yht=r(iYe," (RoBERTa model)"),iYe.forEach(t),xht=i(Oe),sL=n(Oe,"LI",{});var dYe=s(sL);bxe=n(dYe,"STRONG",{});var Rca=s(bxe);$ht=r(Rca,"roformer"),Rca.forEach(t),kht=r(dYe," \u2014 "),dse=n(dYe,"A",{href:!0});var Pca=s(dse);Sht=r(Pca,"FlaxRoFormerForQuestionAnswering"),Pca.forEach(t),Rht=r(dYe," (RoFormer model)"),dYe.forEach(t),Pht=i(Oe),lL=n(Oe,"LI",{});var cYe=s(lL);Fxe=n(cYe,"STRONG",{});var Bca=s(Fxe);Bht=r(Bca,"xlm-roberta"),Bca.forEach(t),Iht=r(cYe," \u2014 "),cse=n(cYe,"A",{href:!0});var Ica=s(cse);Nht=r(Ica,"FlaxXLMRobertaForQuestionAnswering"),Ica.forEach(t),qht=r(cYe," (XLM-RoBERTa model)"),cYe.forEach(t),Oe.forEach(t),jht=i(zi),T(iL.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),PZe=i(f),am=n(f,"H2",{class:!0});var Yoo=s(am);dL=n(Yoo,"A",{id:!0,class:!0,href:!0});var Nca=s(dL);Txe=n(Nca,"SPAN",{});var qca=s(Txe);T(LR.$$.fragment,qca),qca.forEach(t),Nca.forEach(t),Dht=i(Yoo),Mxe=n(Yoo,"SPAN",{});var jca=s(Mxe);Ght=r(jca,"FlaxAutoModelForTokenClassification"),jca.forEach(t),Yoo.forEach(t),BZe=i(f),xr=n(f,"DIV",{class:!0});var Qi=s(xr);T(yR.$$.fragment,Qi),Oht=i(Qi),nm=n(Qi,"P",{});var jie=s(nm);Vht=r(jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),fse=n(jie,"A",{href:!0});var Dca=s(fse);Xht=r(Dca,"from_pretrained()"),Dca.forEach(t),zht=r(jie," class method or the "),mse=n(jie,"A",{href:!0});var Gca=s(mse);Qht=r(Gca,"from_config()"),Gca.forEach(t),Wht=r(jie,` class
method.`),jie.forEach(t),Uht=i(Qi),xR=n(Qi,"P",{});var Koo=s(xR);Hht=r(Koo,"This class cannot be instantiated directly using "),Exe=n(Koo,"CODE",{});var Oca=s(Exe);Jht=r(Oca,"__init__()"),Oca.forEach(t),Yht=r(Koo," (throws an error)."),Koo.forEach(t),Kht=i(Qi),ga=n(Qi,"DIV",{class:!0});var d9=s(ga);T($R.$$.fragment,d9),Zht=i(d9),Cxe=n(d9,"P",{});var Vca=s(Cxe);eut=r(Vca,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Vca.forEach(t),out=i(d9),sm=n(d9,"P",{});var Die=s(sm);rut=r(Die,`Note:
Loading a model from its configuration file does `),wxe=n(Die,"STRONG",{});var Xca=s(wxe);tut=r(Xca,"not"),Xca.forEach(t),aut=r(Die,` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=n(Die,"A",{href:!0});var zca=s(gse);nut=r(zca,"from_pretrained()"),zca.forEach(t),sut=r(Die," to load the model weights."),Die.forEach(t),lut=i(d9),T(cL.$$.fragment,d9),d9.forEach(t),iut=i(Qi),nt=n(Qi,"DIV",{class:!0});var Wi=s(nt);T(kR.$$.fragment,Wi),dut=i(Wi),Axe=n(Wi,"P",{});var Qca=s(Axe);cut=r(Qca,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Qca.forEach(t),fut=i(Wi),Wn=n(Wi,"P",{});var c9=s(Wn);mut=r(c9,"The model class to instantiate is selected based on the "),Lxe=n(c9,"CODE",{});var Wca=s(Lxe);gut=r(Wca,"model_type"),Wca.forEach(t),hut=r(c9,` property of the config object (either
passed as an argument or loaded from `),yxe=n(c9,"CODE",{});var Uca=s(yxe);uut=r(Uca,"pretrained_model_name_or_path"),Uca.forEach(t),put=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xxe=n(c9,"CODE",{});var Hca=s(xxe);_ut=r(Hca,"pretrained_model_name_or_path"),Hca.forEach(t),vut=r(c9,":"),c9.forEach(t),but=i(Wi),Xe=n(Wi,"UL",{});var Ao=s(Xe);fL=n(Ao,"LI",{});var fYe=s(fL);$xe=n(fYe,"STRONG",{});var Jca=s($xe);Fut=r(Jca,"albert"),Jca.forEach(t),Tut=r(fYe," \u2014 "),hse=n(fYe,"A",{href:!0});var Yca=s(hse);Mut=r(Yca,"FlaxAlbertForTokenClassification"),Yca.forEach(t),Eut=r(fYe," (ALBERT model)"),fYe.forEach(t),Cut=i(Ao),mL=n(Ao,"LI",{});var mYe=s(mL);kxe=n(mYe,"STRONG",{});var Kca=s(kxe);wut=r(Kca,"bert"),Kca.forEach(t),Aut=r(mYe," \u2014 "),use=n(mYe,"A",{href:!0});var Zca=s(use);Lut=r(Zca,"FlaxBertForTokenClassification"),Zca.forEach(t),yut=r(mYe," (BERT model)"),mYe.forEach(t),xut=i(Ao),gL=n(Ao,"LI",{});var gYe=s(gL);Sxe=n(gYe,"STRONG",{});var efa=s(Sxe);$ut=r(efa,"big_bird"),efa.forEach(t),kut=r(gYe," \u2014 "),pse=n(gYe,"A",{href:!0});var ofa=s(pse);Sut=r(ofa,"FlaxBigBirdForTokenClassification"),ofa.forEach(t),Rut=r(gYe," (BigBird model)"),gYe.forEach(t),Put=i(Ao),hL=n(Ao,"LI",{});var hYe=s(hL);Rxe=n(hYe,"STRONG",{});var rfa=s(Rxe);But=r(rfa,"distilbert"),rfa.forEach(t),Iut=r(hYe," \u2014 "),_se=n(hYe,"A",{href:!0});var tfa=s(_se);Nut=r(tfa,"FlaxDistilBertForTokenClassification"),tfa.forEach(t),qut=r(hYe," (DistilBERT model)"),hYe.forEach(t),jut=i(Ao),uL=n(Ao,"LI",{});var uYe=s(uL);Pxe=n(uYe,"STRONG",{});var afa=s(Pxe);Dut=r(afa,"electra"),afa.forEach(t),Gut=r(uYe," \u2014 "),vse=n(uYe,"A",{href:!0});var nfa=s(vse);Out=r(nfa,"FlaxElectraForTokenClassification"),nfa.forEach(t),Vut=r(uYe," (ELECTRA model)"),uYe.forEach(t),Xut=i(Ao),pL=n(Ao,"LI",{});var pYe=s(pL);Bxe=n(pYe,"STRONG",{});var sfa=s(Bxe);zut=r(sfa,"roberta"),sfa.forEach(t),Qut=r(pYe," \u2014 "),bse=n(pYe,"A",{href:!0});var lfa=s(bse);Wut=r(lfa,"FlaxRobertaForTokenClassification"),lfa.forEach(t),Uut=r(pYe," (RoBERTa model)"),pYe.forEach(t),Hut=i(Ao),_L=n(Ao,"LI",{});var _Ye=s(_L);Ixe=n(_Ye,"STRONG",{});var ifa=s(Ixe);Jut=r(ifa,"roformer"),ifa.forEach(t),Yut=r(_Ye," \u2014 "),Fse=n(_Ye,"A",{href:!0});var dfa=s(Fse);Kut=r(dfa,"FlaxRoFormerForTokenClassification"),dfa.forEach(t),Zut=r(_Ye," (RoFormer model)"),_Ye.forEach(t),ept=i(Ao),vL=n(Ao,"LI",{});var vYe=s(vL);Nxe=n(vYe,"STRONG",{});var cfa=s(Nxe);opt=r(cfa,"xlm-roberta"),cfa.forEach(t),rpt=r(vYe," \u2014 "),Tse=n(vYe,"A",{href:!0});var ffa=s(Tse);tpt=r(ffa,"FlaxXLMRobertaForTokenClassification"),ffa.forEach(t),apt=r(vYe," (XLM-RoBERTa model)"),vYe.forEach(t),Ao.forEach(t),npt=i(Wi),T(bL.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),IZe=i(f),lm=n(f,"H2",{class:!0});var Zoo=s(lm);FL=n(Zoo,"A",{id:!0,class:!0,href:!0});var mfa=s(FL);qxe=n(mfa,"SPAN",{});var gfa=s(qxe);T(SR.$$.fragment,gfa),gfa.forEach(t),mfa.forEach(t),spt=i(Zoo),jxe=n(Zoo,"SPAN",{});var hfa=s(jxe);lpt=r(hfa,"FlaxAutoModelForMultipleChoice"),hfa.forEach(t),Zoo.forEach(t),NZe=i(f),$r=n(f,"DIV",{class:!0});var Ui=s($r);T(RR.$$.fragment,Ui),ipt=i(Ui),im=n(Ui,"P",{});var Gie=s(im);dpt=r(Gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Mse=n(Gie,"A",{href:!0});var ufa=s(Mse);cpt=r(ufa,"from_pretrained()"),ufa.forEach(t),fpt=r(Gie," class method or the "),Ese=n(Gie,"A",{href:!0});var pfa=s(Ese);mpt=r(pfa,"from_config()"),pfa.forEach(t),gpt=r(Gie,` class
method.`),Gie.forEach(t),hpt=i(Ui),PR=n(Ui,"P",{});var ero=s(PR);upt=r(ero,"This class cannot be instantiated directly using "),Dxe=n(ero,"CODE",{});var _fa=s(Dxe);ppt=r(_fa,"__init__()"),_fa.forEach(t),_pt=r(ero," (throws an error)."),ero.forEach(t),vpt=i(Ui),ha=n(Ui,"DIV",{class:!0});var f9=s(ha);T(BR.$$.fragment,f9),bpt=i(f9),Gxe=n(f9,"P",{});var vfa=s(Gxe);Fpt=r(vfa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vfa.forEach(t),Tpt=i(f9),dm=n(f9,"P",{});var Oie=s(dm);Mpt=r(Oie,`Note:
Loading a model from its configuration file does `),Oxe=n(Oie,"STRONG",{});var bfa=s(Oxe);Ept=r(bfa,"not"),bfa.forEach(t),Cpt=r(Oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=n(Oie,"A",{href:!0});var Ffa=s(Cse);wpt=r(Ffa,"from_pretrained()"),Ffa.forEach(t),Apt=r(Oie," to load the model weights."),Oie.forEach(t),Lpt=i(f9),T(TL.$$.fragment,f9),f9.forEach(t),ypt=i(Ui),st=n(Ui,"DIV",{class:!0});var Hi=s(st);T(IR.$$.fragment,Hi),xpt=i(Hi),Vxe=n(Hi,"P",{});var Tfa=s(Vxe);$pt=r(Tfa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Tfa.forEach(t),kpt=i(Hi),Un=n(Hi,"P",{});var m9=s(Un);Spt=r(m9,"The model class to instantiate is selected based on the "),Xxe=n(m9,"CODE",{});var Mfa=s(Xxe);Rpt=r(Mfa,"model_type"),Mfa.forEach(t),Ppt=r(m9,` property of the config object (either
passed as an argument or loaded from `),zxe=n(m9,"CODE",{});var Efa=s(zxe);Bpt=r(Efa,"pretrained_model_name_or_path"),Efa.forEach(t),Ipt=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qxe=n(m9,"CODE",{});var Cfa=s(Qxe);Npt=r(Cfa,"pretrained_model_name_or_path"),Cfa.forEach(t),qpt=r(m9,":"),m9.forEach(t),jpt=i(Hi),ze=n(Hi,"UL",{});var Lo=s(ze);ML=n(Lo,"LI",{});var bYe=s(ML);Wxe=n(bYe,"STRONG",{});var wfa=s(Wxe);Dpt=r(wfa,"albert"),wfa.forEach(t),Gpt=r(bYe," \u2014 "),wse=n(bYe,"A",{href:!0});var Afa=s(wse);Opt=r(Afa,"FlaxAlbertForMultipleChoice"),Afa.forEach(t),Vpt=r(bYe," (ALBERT model)"),bYe.forEach(t),Xpt=i(Lo),EL=n(Lo,"LI",{});var FYe=s(EL);Uxe=n(FYe,"STRONG",{});var Lfa=s(Uxe);zpt=r(Lfa,"bert"),Lfa.forEach(t),Qpt=r(FYe," \u2014 "),Ase=n(FYe,"A",{href:!0});var yfa=s(Ase);Wpt=r(yfa,"FlaxBertForMultipleChoice"),yfa.forEach(t),Upt=r(FYe," (BERT model)"),FYe.forEach(t),Hpt=i(Lo),CL=n(Lo,"LI",{});var TYe=s(CL);Hxe=n(TYe,"STRONG",{});var xfa=s(Hxe);Jpt=r(xfa,"big_bird"),xfa.forEach(t),Ypt=r(TYe," \u2014 "),Lse=n(TYe,"A",{href:!0});var $fa=s(Lse);Kpt=r($fa,"FlaxBigBirdForMultipleChoice"),$fa.forEach(t),Zpt=r(TYe," (BigBird model)"),TYe.forEach(t),e_t=i(Lo),wL=n(Lo,"LI",{});var MYe=s(wL);Jxe=n(MYe,"STRONG",{});var kfa=s(Jxe);o_t=r(kfa,"distilbert"),kfa.forEach(t),r_t=r(MYe," \u2014 "),yse=n(MYe,"A",{href:!0});var Sfa=s(yse);t_t=r(Sfa,"FlaxDistilBertForMultipleChoice"),Sfa.forEach(t),a_t=r(MYe," (DistilBERT model)"),MYe.forEach(t),n_t=i(Lo),AL=n(Lo,"LI",{});var EYe=s(AL);Yxe=n(EYe,"STRONG",{});var Rfa=s(Yxe);s_t=r(Rfa,"electra"),Rfa.forEach(t),l_t=r(EYe," \u2014 "),xse=n(EYe,"A",{href:!0});var Pfa=s(xse);i_t=r(Pfa,"FlaxElectraForMultipleChoice"),Pfa.forEach(t),d_t=r(EYe," (ELECTRA model)"),EYe.forEach(t),c_t=i(Lo),LL=n(Lo,"LI",{});var CYe=s(LL);Kxe=n(CYe,"STRONG",{});var Bfa=s(Kxe);f_t=r(Bfa,"roberta"),Bfa.forEach(t),m_t=r(CYe," \u2014 "),$se=n(CYe,"A",{href:!0});var Ifa=s($se);g_t=r(Ifa,"FlaxRobertaForMultipleChoice"),Ifa.forEach(t),h_t=r(CYe," (RoBERTa model)"),CYe.forEach(t),u_t=i(Lo),yL=n(Lo,"LI",{});var wYe=s(yL);Zxe=n(wYe,"STRONG",{});var Nfa=s(Zxe);p_t=r(Nfa,"roformer"),Nfa.forEach(t),__t=r(wYe," \u2014 "),kse=n(wYe,"A",{href:!0});var qfa=s(kse);v_t=r(qfa,"FlaxRoFormerForMultipleChoice"),qfa.forEach(t),b_t=r(wYe," (RoFormer model)"),wYe.forEach(t),F_t=i(Lo),xL=n(Lo,"LI",{});var AYe=s(xL);e$e=n(AYe,"STRONG",{});var jfa=s(e$e);T_t=r(jfa,"xlm-roberta"),jfa.forEach(t),M_t=r(AYe," \u2014 "),Sse=n(AYe,"A",{href:!0});var Dfa=s(Sse);E_t=r(Dfa,"FlaxXLMRobertaForMultipleChoice"),Dfa.forEach(t),C_t=r(AYe," (XLM-RoBERTa model)"),AYe.forEach(t),Lo.forEach(t),w_t=i(Hi),T($L.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),qZe=i(f),cm=n(f,"H2",{class:!0});var oro=s(cm);kL=n(oro,"A",{id:!0,class:!0,href:!0});var Gfa=s(kL);o$e=n(Gfa,"SPAN",{});var Ofa=s(o$e);T(NR.$$.fragment,Ofa),Ofa.forEach(t),Gfa.forEach(t),A_t=i(oro),r$e=n(oro,"SPAN",{});var Vfa=s(r$e);L_t=r(Vfa,"FlaxAutoModelForNextSentencePrediction"),Vfa.forEach(t),oro.forEach(t),jZe=i(f),kr=n(f,"DIV",{class:!0});var Ji=s(kr);T(qR.$$.fragment,Ji),y_t=i(Ji),fm=n(Ji,"P",{});var Vie=s(fm);x_t=r(Vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Rse=n(Vie,"A",{href:!0});var Xfa=s(Rse);$_t=r(Xfa,"from_pretrained()"),Xfa.forEach(t),k_t=r(Vie," class method or the "),Pse=n(Vie,"A",{href:!0});var zfa=s(Pse);S_t=r(zfa,"from_config()"),zfa.forEach(t),R_t=r(Vie,` class
method.`),Vie.forEach(t),P_t=i(Ji),jR=n(Ji,"P",{});var rro=s(jR);B_t=r(rro,"This class cannot be instantiated directly using "),t$e=n(rro,"CODE",{});var Qfa=s(t$e);I_t=r(Qfa,"__init__()"),Qfa.forEach(t),N_t=r(rro," (throws an error)."),rro.forEach(t),q_t=i(Ji),ua=n(Ji,"DIV",{class:!0});var g9=s(ua);T(DR.$$.fragment,g9),j_t=i(g9),a$e=n(g9,"P",{});var Wfa=s(a$e);D_t=r(Wfa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wfa.forEach(t),G_t=i(g9),mm=n(g9,"P",{});var Xie=s(mm);O_t=r(Xie,`Note:
Loading a model from its configuration file does `),n$e=n(Xie,"STRONG",{});var Ufa=s(n$e);V_t=r(Ufa,"not"),Ufa.forEach(t),X_t=r(Xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bse=n(Xie,"A",{href:!0});var Hfa=s(Bse);z_t=r(Hfa,"from_pretrained()"),Hfa.forEach(t),Q_t=r(Xie," to load the model weights."),Xie.forEach(t),W_t=i(g9),T(SL.$$.fragment,g9),g9.forEach(t),U_t=i(Ji),lt=n(Ji,"DIV",{class:!0});var Yi=s(lt);T(GR.$$.fragment,Yi),H_t=i(Yi),s$e=n(Yi,"P",{});var Jfa=s(s$e);J_t=r(Jfa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Jfa.forEach(t),Y_t=i(Yi),Hn=n(Yi,"P",{});var h9=s(Hn);K_t=r(h9,"The model class to instantiate is selected based on the "),l$e=n(h9,"CODE",{});var Yfa=s(l$e);Z_t=r(Yfa,"model_type"),Yfa.forEach(t),e2t=r(h9,` property of the config object (either
passed as an argument or loaded from `),i$e=n(h9,"CODE",{});var Kfa=s(i$e);o2t=r(Kfa,"pretrained_model_name_or_path"),Kfa.forEach(t),r2t=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=n(h9,"CODE",{});var Zfa=s(d$e);t2t=r(Zfa,"pretrained_model_name_or_path"),Zfa.forEach(t),a2t=r(h9,":"),h9.forEach(t),n2t=i(Yi),c$e=n(Yi,"UL",{});var ema=s(c$e);RL=n(ema,"LI",{});var LYe=s(RL);f$e=n(LYe,"STRONG",{});var oma=s(f$e);s2t=r(oma,"bert"),oma.forEach(t),l2t=r(LYe," \u2014 "),Ise=n(LYe,"A",{href:!0});var rma=s(Ise);i2t=r(rma,"FlaxBertForNextSentencePrediction"),rma.forEach(t),d2t=r(LYe," (BERT model)"),LYe.forEach(t),ema.forEach(t),c2t=i(Yi),T(PL.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),DZe=i(f),gm=n(f,"H2",{class:!0});var tro=s(gm);BL=n(tro,"A",{id:!0,class:!0,href:!0});var tma=s(BL);m$e=n(tma,"SPAN",{});var ama=s(m$e);T(OR.$$.fragment,ama),ama.forEach(t),tma.forEach(t),f2t=i(tro),g$e=n(tro,"SPAN",{});var nma=s(g$e);m2t=r(nma,"FlaxAutoModelForImageClassification"),nma.forEach(t),tro.forEach(t),GZe=i(f),Sr=n(f,"DIV",{class:!0});var Ki=s(Sr);T(VR.$$.fragment,Ki),g2t=i(Ki),hm=n(Ki,"P",{});var zie=s(hm);h2t=r(zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nse=n(zie,"A",{href:!0});var sma=s(Nse);u2t=r(sma,"from_pretrained()"),sma.forEach(t),p2t=r(zie," class method or the "),qse=n(zie,"A",{href:!0});var lma=s(qse);_2t=r(lma,"from_config()"),lma.forEach(t),v2t=r(zie,` class
method.`),zie.forEach(t),b2t=i(Ki),XR=n(Ki,"P",{});var aro=s(XR);F2t=r(aro,"This class cannot be instantiated directly using "),h$e=n(aro,"CODE",{});var ima=s(h$e);T2t=r(ima,"__init__()"),ima.forEach(t),M2t=r(aro," (throws an error)."),aro.forEach(t),E2t=i(Ki),pa=n(Ki,"DIV",{class:!0});var u9=s(pa);T(zR.$$.fragment,u9),C2t=i(u9),u$e=n(u9,"P",{});var dma=s(u$e);w2t=r(dma,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),dma.forEach(t),A2t=i(u9),um=n(u9,"P",{});var Qie=s(um);L2t=r(Qie,`Note:
Loading a model from its configuration file does `),p$e=n(Qie,"STRONG",{});var cma=s(p$e);y2t=r(cma,"not"),cma.forEach(t),x2t=r(Qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=n(Qie,"A",{href:!0});var fma=s(jse);$2t=r(fma,"from_pretrained()"),fma.forEach(t),k2t=r(Qie," to load the model weights."),Qie.forEach(t),S2t=i(u9),T(IL.$$.fragment,u9),u9.forEach(t),R2t=i(Ki),it=n(Ki,"DIV",{class:!0});var Zi=s(it);T(QR.$$.fragment,Zi),P2t=i(Zi),_$e=n(Zi,"P",{});var mma=s(_$e);B2t=r(mma,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),mma.forEach(t),I2t=i(Zi),Jn=n(Zi,"P",{});var p9=s(Jn);N2t=r(p9,"The model class to instantiate is selected based on the "),v$e=n(p9,"CODE",{});var gma=s(v$e);q2t=r(gma,"model_type"),gma.forEach(t),j2t=r(p9,` property of the config object (either
passed as an argument or loaded from `),b$e=n(p9,"CODE",{});var hma=s(b$e);D2t=r(hma,"pretrained_model_name_or_path"),hma.forEach(t),G2t=r(p9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=n(p9,"CODE",{});var uma=s(F$e);O2t=r(uma,"pretrained_model_name_or_path"),uma.forEach(t),V2t=r(p9,":"),p9.forEach(t),X2t=i(Zi),WR=n(Zi,"UL",{});var nro=s(WR);NL=n(nro,"LI",{});var yYe=s(NL);T$e=n(yYe,"STRONG",{});var pma=s(T$e);z2t=r(pma,"beit"),pma.forEach(t),Q2t=r(yYe," \u2014 "),Dse=n(yYe,"A",{href:!0});var _ma=s(Dse);W2t=r(_ma,"FlaxBeitForImageClassification"),_ma.forEach(t),U2t=r(yYe," (BEiT model)"),yYe.forEach(t),H2t=i(nro),qL=n(nro,"LI",{});var xYe=s(qL);M$e=n(xYe,"STRONG",{});var vma=s(M$e);J2t=r(vma,"vit"),vma.forEach(t),Y2t=r(xYe," \u2014 "),Gse=n(xYe,"A",{href:!0});var bma=s(Gse);K2t=r(bma,"FlaxViTForImageClassification"),bma.forEach(t),Z2t=r(xYe," (ViT model)"),xYe.forEach(t),nro.forEach(t),evt=i(Zi),T(jL.$$.fragment,Zi),Zi.forEach(t),Ki.forEach(t),OZe=i(f),pm=n(f,"H2",{class:!0});var sro=s(pm);DL=n(sro,"A",{id:!0,class:!0,href:!0});var Fma=s(DL);E$e=n(Fma,"SPAN",{});var Tma=s(E$e);T(UR.$$.fragment,Tma),Tma.forEach(t),Fma.forEach(t),ovt=i(sro),C$e=n(sro,"SPAN",{});var Mma=s(C$e);rvt=r(Mma,"FlaxAutoModelForVision2Seq"),Mma.forEach(t),sro.forEach(t),VZe=i(f),Rr=n(f,"DIV",{class:!0});var ed=s(Rr);T(HR.$$.fragment,ed),tvt=i(ed),_m=n(ed,"P",{});var Wie=s(_m);avt=r(Wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ose=n(Wie,"A",{href:!0});var Ema=s(Ose);nvt=r(Ema,"from_pretrained()"),Ema.forEach(t),svt=r(Wie," class method or the "),Vse=n(Wie,"A",{href:!0});var Cma=s(Vse);lvt=r(Cma,"from_config()"),Cma.forEach(t),ivt=r(Wie,` class
method.`),Wie.forEach(t),dvt=i(ed),JR=n(ed,"P",{});var lro=s(JR);cvt=r(lro,"This class cannot be instantiated directly using "),w$e=n(lro,"CODE",{});var wma=s(w$e);fvt=r(wma,"__init__()"),wma.forEach(t),mvt=r(lro," (throws an error)."),lro.forEach(t),gvt=i(ed),_a=n(ed,"DIV",{class:!0});var _9=s(_a);T(YR.$$.fragment,_9),hvt=i(_9),A$e=n(_9,"P",{});var Ama=s(A$e);uvt=r(Ama,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ama.forEach(t),pvt=i(_9),vm=n(_9,"P",{});var Uie=s(vm);_vt=r(Uie,`Note:
Loading a model from its configuration file does `),L$e=n(Uie,"STRONG",{});var Lma=s(L$e);vvt=r(Lma,"not"),Lma.forEach(t),bvt=r(Uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=n(Uie,"A",{href:!0});var yma=s(Xse);Fvt=r(yma,"from_pretrained()"),yma.forEach(t),Tvt=r(Uie," to load the model weights."),Uie.forEach(t),Mvt=i(_9),T(GL.$$.fragment,_9),_9.forEach(t),Evt=i(ed),dt=n(ed,"DIV",{class:!0});var od=s(dt);T(KR.$$.fragment,od),Cvt=i(od),y$e=n(od,"P",{});var xma=s(y$e);wvt=r(xma,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xma.forEach(t),Avt=i(od),Yn=n(od,"P",{});var v9=s(Yn);Lvt=r(v9,"The model class to instantiate is selected based on the "),x$e=n(v9,"CODE",{});var $ma=s(x$e);yvt=r($ma,"model_type"),$ma.forEach(t),xvt=r(v9,` property of the config object (either
passed as an argument or loaded from `),$$e=n(v9,"CODE",{});var kma=s($$e);$vt=r(kma,"pretrained_model_name_or_path"),kma.forEach(t),kvt=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=n(v9,"CODE",{});var Sma=s(k$e);Svt=r(Sma,"pretrained_model_name_or_path"),Sma.forEach(t),Rvt=r(v9,":"),v9.forEach(t),Pvt=i(od),S$e=n(od,"UL",{});var Rma=s(S$e);OL=n(Rma,"LI",{});var $Ye=s(OL);R$e=n($Ye,"STRONG",{});var Pma=s(R$e);Bvt=r(Pma,"vision-encoder-decoder"),Pma.forEach(t),Ivt=r($Ye," \u2014 "),zse=n($Ye,"A",{href:!0});var Bma=s(zse);Nvt=r(Bma,"FlaxVisionEncoderDecoderModel"),Bma.forEach(t),qvt=r($Ye," (Vision Encoder decoder model)"),$Ye.forEach(t),Rma.forEach(t),jvt=i(od),T(VL.$$.fragment,od),od.forEach(t),ed.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Hha)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(u,"class","relative group"),c(Zn,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoConfig"),c(os,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoModel"),c(rs,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoTokenizer"),c(id,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertModel"),c(Am,"id","extending-the-auto-classes"),c(Am,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Am,"href","#extending-the-auto-classes"),c(dd,"class","relative group"),c(ym,"id","transformers.AutoConfig"),c(ym,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ym,"href","#transformers.AutoConfig"),c(cd,"class","relative group"),c($B,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(kB,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertConfig"),c(SB,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartConfig"),c(RB,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitConfig"),c(PB,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertConfig"),c(BB,"href","/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(IB,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdConfig"),c(NB,"href","/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(qB,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(jB,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(DB,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomConfig"),c(GB,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertConfig"),c(OB,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineConfig"),c(VB,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPConfig"),c(XB,"href","/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenConfig"),c(zB,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertConfig"),c(QB,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextConfig"),c(WB,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLConfig"),c(UB,"href","/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtConfig"),c(HB,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(JB,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(YB,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(KB,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaConfig"),c(ZB,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(eI,"href","/docs/transformers/v4.22.1/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(oI,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTConfig"),c(rI,"href","/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrConfig"),c(tI,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertConfig"),c(aI,"href","/docs/transformers/v4.22.1/en/model_doc/donut#transformers.DonutSwinConfig"),c(nI,"href","/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRConfig"),c(sI,"href","/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTConfig"),c(lI,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraConfig"),c(iI,"href","/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(dI,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieConfig"),c(cI,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertConfig"),c(fI,"href","/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaConfig"),c(mI,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetConfig"),c(gI,"href","/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTConfig"),c(hI,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelConfig"),c(uI,"href","/docs/transformers/v4.22.1/en/model_doc/glpn#transformers.GLPNConfig"),c(pI,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Config"),c(_I,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(vI,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(bI,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJConfig"),c(FI,"href","/docs/transformers/v4.22.1/en/model_doc/groupvit#transformers.GroupViTConfig"),c(TI,"href","/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertConfig"),c(MI,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertConfig"),c(EI,"href","/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(CI,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(wI,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(AI,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(LI,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDConfig"),c(yI,"href","/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitConfig"),c(xI,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerConfig"),c($I,"href","/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Config"),c(kI,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeConfig"),c(SI,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertConfig"),c(RI,"href","/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Config"),c(PI,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianConfig"),c(BI,"href","/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(II,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartConfig"),c(NI,"href","/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTConfig"),c(qI,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(jI,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(DI,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(GI,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetConfig"),c(OI,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Config"),c(VI,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpConfig"),c(XI,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaConfig"),c(zI,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(QI,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(WI,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTConfig"),c(UI,"href","/docs/transformers/v4.22.1/en/model_doc/owlvit#transformers.OwlViTConfig"),c(HI,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusConfig"),c(JI,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(YI,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverConfig"),c(KI,"href","/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartConfig"),c(ZI,"href","/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(eN,"href","/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(oN,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(rN,"href","/docs/transformers/v4.22.1/en/model_doc/rag#transformers.RagConfig"),c(tN,"href","/docs/transformers/v4.22.1/en/model_doc/realm#transformers.RealmConfig"),c(aN,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerConfig"),c(nN,"href","/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetConfig"),c(sN,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertConfig"),c(lN,"href","/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetConfig"),c(iN,"href","/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertConfig"),c(dN,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaConfig"),c(cN,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerConfig"),c(fN,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerConfig"),c(mN,"href","/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWConfig"),c(gN,"href","/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDConfig"),c(hN,"href","/docs/transformers/v4.22.1/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(uN,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(pN,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(_N,"href","/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterConfig"),c(vN,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(bN,"href","/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinConfig"),c(FN,"href","/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2Config"),c(TN,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Config"),c(MN,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasConfig"),c(EN,"href","/docs/transformers/v4.22.1/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(CN,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(wN,"href","/docs/transformers/v4.22.1/en/model_doc/trocr#transformers.TrOCRConfig"),c(AN,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(LN,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(yN,"href","/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanConfig"),c(xN,"href","/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEConfig"),c($N,"href","/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltConfig"),c(kN,"href","/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(SN,"href","/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(RN,"href","/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(PN,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTConfig"),c(BN,"href","/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(IN,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(NN,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(qN,"href","/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMConfig"),c(jN,"href","/docs/transformers/v4.22.1/en/model_doc/xclip#transformers.XCLIPConfig"),c(DN,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMConfig"),c(GN,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMConfig"),c(ON,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(VN,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(XN,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(zN,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetConfig"),c(QN,"href","/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosConfig"),c(WN,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoConfig"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"id","transformers.AutoTokenizer"),c(Uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uh,"href","#transformers.AutoTokenizer"),c(md,"class","relative group"),c(UN,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(HN,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertTokenizer"),c(JN,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(YN,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartTokenizer"),c(KN,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartTokenizerFast"),c(ZN,"href","/docs/transformers/v4.22.1/en/model_doc/barthez#transformers.BarthezTokenizer"),c(eq,"href","/docs/transformers/v4.22.1/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(oq,"href","/docs/transformers/v4.22.1/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(rq,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(tq,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(aq,"href","/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(nq,"href","/docs/transformers/v4.22.1/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(sq,"href","/docs/transformers/v4.22.1/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(lq,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(iq,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(dq,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(cq,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(fq,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(mq,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(gq,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(hq,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(uq,"href","/docs/transformers/v4.22.1/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(pq,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertTokenizer"),c(_q,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(vq,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineTokenizer"),c(bq,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizer"),c(Fq,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Tq,"href","/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Mq,"href","/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(Eq,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(Cq,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(wq,"href","/docs/transformers/v4.22.1/en/model_doc/cpm#transformers.CpmTokenizer"),c(Aq,"href","/docs/transformers/v4.22.1/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(Lq,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(yq,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaTokenizer"),c(xq,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c($q,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaTokenizer"),c(kq,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(Sq,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(Rq,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(Pq,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Bq,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(Iq,"href","/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(Nq,"href","/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(qq,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraTokenizer"),c(jq,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(Dq,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(Gq,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(Oq,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(Vq,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetTokenizer"),c(Xq,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(zq,"href","/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(Qq,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelTokenizer"),c(Wq,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(Uq,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Hq,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Jq,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Yq,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Kq,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(Zq,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ej,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(oj,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizer"),c(rj,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(tj,"href","/docs/transformers/v4.22.1/en/model_doc/herbert#transformers.HerbertTokenizer"),c(aj,"href","/docs/transformers/v4.22.1/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(nj,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(sj,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaTokenizer"),c(lj,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(ij,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(dj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(cj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(fj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(mj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(gj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(hj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(uj,"href","/docs/transformers/v4.22.1/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(pj,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDTokenizer"),c(_j,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDTokenizerFast"),c(vj,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerTokenizer"),c(bj,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(Fj,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Tokenizer"),c(Tj,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5TokenizerFast"),c(Mj,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeTokenizer"),c(Ej,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(Cj,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(wj,"href","/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(Aj,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianTokenizer"),c(Lj,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartTokenizer"),c(yj,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(xj,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBart50Tokenizer"),c($j,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(kj,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(Sj,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(Rj,"href","/docs/transformers/v4.22.1/en/model_doc/mluke#transformers.MLukeTokenizer"),c(Pj,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(Bj,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(Ij,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(Nj,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(qj,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Tokenizer"),c(jj,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5TokenizerFast"),c(Dj,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpTokenizer"),c(Gj,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(Oj,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(Vj,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(Xj,"href","/docs/transformers/v4.22.1/en/model_doc/nllb#transformers.NllbTokenizer"),c(zj,"href","/docs/transformers/v4.22.1/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(Qj,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertTokenizer"),c(Wj,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Uj,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(Hj,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(Jj,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Yj,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizer"),c(Kj,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Zj,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(eD,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(oD,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(rD,"href","/docs/transformers/v4.22.1/en/model_doc/phobert#transformers.PhobertTokenizer"),c(tD,"href","/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartTokenizer"),c(aD,"href","/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(nD,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(sD,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(lD,"href","/docs/transformers/v4.22.1/en/model_doc/rag#transformers.RagTokenizer"),c(iD,"href","/docs/transformers/v4.22.1/en/model_doc/realm#transformers.RealmTokenizer"),c(dD,"href","/docs/transformers/v4.22.1/en/model_doc/realm#transformers.RealmTokenizerFast"),c(cD,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerTokenizer"),c(fD,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(mD,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertTokenizer"),c(gD,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(hD,"href","/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(uD,"href","/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(pD,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_D,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vD,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(bD,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(FD,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(TD,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(MD,"href","/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterTokenizer"),c(ED,"href","/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(CD,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(wD,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(AD,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Tokenizer"),c(LD,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5TokenizerFast"),c(yD,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasTokenizer"),c(xD,"href","/docs/transformers/v4.22.1/en/model_doc/tapex#transformers.TapexTokenizer"),c($D,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(kD,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(SD,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(RD,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizer"),c(PD,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertTokenizerFast"),c(BD,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ID,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ND,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(qD,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizer"),c(jD,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(DD,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMTokenizer"),c(GD,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(OD,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMTokenizer"),c(VD,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(XD,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(zD,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(QD,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(WD,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(UD,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(HD,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(JD,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertTokenizer"),c(YD,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoFeatureExtractor"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoFeatureExtractor"),c(gd,"class","relative group"),c(KD,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(ZD,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(eG,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(oG,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rG,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(tG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(aG,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(nG,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(sG,"href","/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(lG,"href","/docs/transformers/v4.22.1/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(iG,"href","/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(dG,"href","/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(cG,"href","/docs/transformers/v4.22.1/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(fG,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(mG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(gG,"href","/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(hG,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(uG,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(pG,"href","/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(_G,"href","/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(vG,"href","/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(bG,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(FG,"href","/docs/transformers/v4.22.1/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(TG,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(MG,"href","/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(EG,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(CG,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(wG,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(AG,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(LG,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(yG,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(xG,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c($G,"href","/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(kG,"href","/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(SG,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(RG,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(BG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IG,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(NG,"href","/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bp,"id","transformers.AutoProcessor"),c(bp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bp,"href","#transformers.AutoProcessor"),c(hd,"class","relative group"),c(qG,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jG,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPProcessor"),c(DG,"href","/docs/transformers/v4.22.1/en/model_doc/donut#transformers.DonutProcessor"),c(GG,"href","/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaProcessor"),c(OG,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPProcessor"),c(VG,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(XG,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(zG,"href","/docs/transformers/v4.22.1/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(QG,"href","/docs/transformers/v4.22.1/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(WG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HG,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(JG,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(YG,"href","/docs/transformers/v4.22.1/en/model_doc/trocr#transformers.TrOCRProcessor"),c(KG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZG,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eO,"href","/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltProcessor"),c(oO,"href","/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(rO,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(tO,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(aO,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(nO,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPProcessor"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xp,"id","transformers.AutoModel"),c(Xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xp,"href","#transformers.AutoModel"),c(pd,"class","relative group"),c(sO,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lO,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iO,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dO,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertModel"),c(cO,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartModel"),c(fO,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitModel"),c(mO,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertModel"),c(gO,"href","/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(hO,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdModel"),c(uO,"href","/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(pO,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(_O,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(vO,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomModel"),c(bO,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertModel"),c(FO,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineModel"),c(TO,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.CLIPModel"),c(MO,"href","/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenModel"),c(EO,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertModel"),c(CO,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextModel"),c(wO,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLModel"),c(AO,"href","/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtModel"),c(LO,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(yO,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(xO,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c($O,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaModel"),c(kO,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(SO,"href","/docs/transformers/v4.22.1/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(RO,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTModel"),c(PO,"href","/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrModel"),c(BO,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertModel"),c(IO,"href","/docs/transformers/v4.22.1/en/model_doc/donut#transformers.DonutSwinModel"),c(NO,"href","/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(qO,"href","/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTModel"),c(jO,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraModel"),c(DO,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieModel"),c(GO,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertModel"),c(OO,"href","/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaModel"),c(VO,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetModel"),c(XO,"href","/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTModel"),c(zO,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelModel"),c(QO,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelBaseModel"),c(WO,"href","/docs/transformers/v4.22.1/en/model_doc/glpn#transformers.GLPNModel"),c(UO,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2Model"),c(HO,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(JO,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(YO,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJModel"),c(KO,"href","/docs/transformers/v4.22.1/en/model_doc/groupvit#transformers.GroupViTModel"),c(ZO,"href","/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertModel"),c(eV,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertModel"),c(oV,"href","/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(rV,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(tV,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(aV,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(nV,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDModel"),c(sV,"href","/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitModel"),c(lV,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerModel"),c(iV,"href","/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5Model"),c(dV,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeModel"),c(cV,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertModel"),c(fV,"href","/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Model"),c(mV,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianModel"),c(gV,"href","/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerModel"),c(hV,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartModel"),c(uV,"href","/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTModel"),c(pV,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(_V,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertModel"),c(vV,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTModel"),c(bV,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetModel"),c(FV,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5Model"),c(TV,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpModel"),c(MV,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaModel"),c(EV,"href","/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100Model"),c(CV,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerModel"),c(wV,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(AV,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTModel"),c(LV,"href","/docs/transformers/v4.22.1/en/model_doc/owlvit#transformers.OwlViTModel"),c(yV,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusModel"),c(xV,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXModel"),c($V,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverModel"),c(kV,"href","/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartModel"),c(SV,"href","/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerModel"),c(RV,"href","/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(PV,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertModel"),c(BV,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerModel"),c(IV,"href","/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetModel"),c(NV,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertModel"),c(qV,"href","/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetModel"),c(jV,"href","/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertModel"),c(DV,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaModel"),c(GV,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerModel"),c(OV,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerModel"),c(VV,"href","/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWModel"),c(XV,"href","/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDModel"),c(zV,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(QV,"href","/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterModel"),c(WV,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(UV,"href","/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinModel"),c(HV,"href","/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2Model"),c(JV,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5Model"),c(YV,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasModel"),c(KV,"href","/docs/transformers/v4.22.1/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(ZV,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(eX,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechModel"),c(oX,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(rX,"href","/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanModel"),c(tX,"href","/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEModel"),c(aX,"href","/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltModel"),c(nX,"href","/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(sX,"href","/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertModel"),c(lX,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTModel"),c(iX,"href","/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(dX,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(cX,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(fX,"href","/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMModel"),c(mX,"href","/docs/transformers/v4.22.1/en/model_doc/xclip#transformers.XCLIPModel"),c(gX,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMModel"),c(hX,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMModel"),c(uX,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(pX,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(_X,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(vX,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetModel"),c(bX,"href","/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosModel"),c(FX,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(av,"id","transformers.AutoModelForPreTraining"),c(av,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(av,"href","#transformers.AutoModelForPreTraining"),c(bd,"class","relative group"),c(TX,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MX,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EX,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CX,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForPreTraining"),c(wX,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(AX,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForPreTraining"),c(LX,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(yX,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForCausalLM"),c(xX,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c($X,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(kX,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(SX,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(RX,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(PX,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(BX,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForPreTraining"),c(IX,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(NX,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(qX,"href","/docs/transformers/v4.22.1/en/model_doc/flava#transformers.FlavaForPreTraining"),c(jX,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForPreTraining"),c(DX,"href","/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(GX,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(OX,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(VX,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(XX,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(zX,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(QX,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForMaskedLM"),c(WX,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(UX,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(HX,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(JX,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(YX,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(KX,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(ZX,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(ez,"href","/docs/transformers/v4.22.1/en/model_doc/retribert#transformers.RetriBertModel"),c(oz,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(rz,"href","/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(tz,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(az,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(nz,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(sz,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(lz,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(iz,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(dz,"href","/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(cz,"href","/docs/transformers/v4.22.1/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(fz,"href","/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(mz,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(gz,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(hz,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(uz,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(pz,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(_z,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r1,"id","transformers.AutoModelForCausalLM"),c(r1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r1,"href","#transformers.AutoModelForCausalLM"),c(Md,"class","relative group"),c(vz,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bz,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForCausalLM"),c(Mz,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertLMHeadModel"),c(Ez,"href","/docs/transformers/v4.22.1/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(Cz,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(wz,"href","/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Az,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Lz,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(yz,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForCausalLM"),c(xz,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForCausalLM"),c($z,"href","/docs/transformers/v4.22.1/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(kz,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Sz,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(Rz,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Pz,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(Bz,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Iz,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Nz,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(qz,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(jz,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianForCausalLM"),c(Dz,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Gz,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(Oz,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForCausalLM"),c(Vz,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Xz,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTForCausalLM"),c(zz,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Qz,"href","/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(Wz,"href","/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(Uz,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(Hz,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(Jz,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(Yz,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(Kz,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(Zz,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(eQ,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(oQ,"href","/docs/transformers/v4.22.1/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(rQ,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(tQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(aQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(nQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(sQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(lQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W1,"id","transformers.AutoModelForMaskedLM"),c(W1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W1,"href","#transformers.AutoModelForMaskedLM"),c(wd,"class","relative group"),c(iQ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(mQ,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(gQ,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForMaskedLM"),c(hQ,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(uQ,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(pQ,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(_Q,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(vQ,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(bQ,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(FQ,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(TQ,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(MQ,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(EQ,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(CQ,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(wQ,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(AQ,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(LQ,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(yQ,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(xQ,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForMaskedLM"),c($Q,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(kQ,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(SQ,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(RQ,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(PQ,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(BQ,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(IQ,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(NQ,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(qQ,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(jQ,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(DQ,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(GQ,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(OQ,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(VQ,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(XQ,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(zQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(WQ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(UQ,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I4,"id","transformers.AutoModelForSeq2SeqLM"),c(I4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I4,"href","#transformers.AutoModelForSeq2SeqLM"),c(yd,"class","relative group"),c(HQ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JQ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YQ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KQ,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(ZQ,"href","/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(eW,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(oW,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(rW,"href","/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(tW,"href","/docs/transformers/v4.22.1/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(aW,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(nW,"href","/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(sW,"href","/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(lW,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.MarianMTModel"),c(iW,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(dW,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(cW,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(fW,"href","/docs/transformers/v4.22.1/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(mW,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(gW,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(hW,"href","/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(uW,"href","/docs/transformers/v4.22.1/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(pW,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(_W,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sb,"id","transformers.AutoModelForSequenceClassification"),c(sb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sb,"href","#transformers.AutoModelForSequenceClassification"),c(kd,"class","relative group"),c(vW,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FW,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TW,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(MW,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForSequenceClassification"),c(EW,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForSequenceClassification"),c(CW,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(wW,"href","/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(AW,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(LW,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(yW,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(xW,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c($W,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(kW,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(SW,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(RW,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(PW,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(BW,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(IW,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(NW,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(qW,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(jW,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(DW,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(GW,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(OW,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(VW,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(XW,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(zW,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(QW,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(WW,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDForSequenceClassification"),c(UW,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(HW,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(JW,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(YW,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(KW,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(ZW,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(eU,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(oU,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(rU,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(tU,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(aU,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(nU,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(sU,"href","/docs/transformers/v4.22.1/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(lU,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(iU,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(dU,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(cU,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(fU,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(mU,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(gU,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(hU,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(uU,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(pU,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(_U,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(vU,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(bU,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dF,"id","transformers.AutoModelForMultipleChoice"),c(dF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dF,"href","#transformers.AutoModelForMultipleChoice"),c(Pd,"class","relative group"),c(FU,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TU,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MU,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EU,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(CU,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForMultipleChoice"),c(wU,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(AU,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(LU,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(yU,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(xU,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c($U,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(kU,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(SU,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(RU,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(PU,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(BU,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(IU,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(NU,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(qU,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(jU,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(DU,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(GU,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(OU,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(VU,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(XU,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(zU,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(QU,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(WU,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(UU,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(HU,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(JU,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(YU,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(KU,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(ZU,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(eH,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zF,"id","transformers.AutoModelForNextSentencePrediction"),c(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zF,"href","#transformers.AutoModelForNextSentencePrediction"),c(Nd,"class","relative group"),c(oH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aH,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(nH,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(sH,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(lH,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(iH,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(dH,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(cH,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rT,"id","transformers.AutoModelForTokenClassification"),c(rT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rT,"href","#transformers.AutoModelForTokenClassification"),c(Dd,"class","relative group"),c(fH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hH,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(uH,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForTokenClassification"),c(pH,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(_H,"href","/docs/transformers/v4.22.1/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(vH,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(bH,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForTokenClassification"),c(FH,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(TH,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(MH,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(EH,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(CH,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(wH,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(AH,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(LH,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(yH,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(xH,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c($H,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(kH,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(SH,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(RH,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(PH,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(BH,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(IH,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForTokenClassification"),c(NH,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(qH,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(jH,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(DH,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(GH,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(OH,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(VH,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(XH,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(zH,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(QH,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(WH,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(UH,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(HH,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(JH,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(YH,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XT,"id","transformers.AutoModelForQuestionAnswering"),c(XT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XT,"href","#transformers.AutoModelForQuestionAnswering"),c(Vd,"class","relative group"),c(KH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZH,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(rJ,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(tJ,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(aJ,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(nJ,"href","/docs/transformers/v4.22.1/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(sJ,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(lJ,"href","/docs/transformers/v4.22.1/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(iJ,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(dJ,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(cJ,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(fJ,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(mJ,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(gJ,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(hJ,"href","/docs/transformers/v4.22.1/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(uJ,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(pJ,"href","/docs/transformers/v4.22.1/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(_J,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(vJ,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(bJ,"href","/docs/transformers/v4.22.1/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(FJ,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(TJ,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(MJ,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(EJ,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(CJ,"href","/docs/transformers/v4.22.1/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(wJ,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(AJ,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(LJ,"href","/docs/transformers/v4.22.1/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(yJ,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(xJ,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c($J,"href","/docs/transformers/v4.22.1/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(kJ,"href","/docs/transformers/v4.22.1/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(SJ,"href","/docs/transformers/v4.22.1/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(RJ,"href","/docs/transformers/v4.22.1/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(PJ,"href","/docs/transformers/v4.22.1/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(BJ,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(IJ,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(NJ,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(qJ,"href","/docs/transformers/v4.22.1/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(jJ,"href","/docs/transformers/v4.22.1/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(DJ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(GJ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(OJ,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(VJ,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(XJ,"href","/docs/transformers/v4.22.1/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qM,"id","transformers.AutoModelForTableQuestionAnswering"),c(qM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qM,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Qd,"class","relative group"),c(zJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UJ,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VM,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(VM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VM,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(Hd,"class","relative group"),c(HJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KJ,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(ZJ,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(eY,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JM,"id","transformers.AutoModelForImageClassification"),c(JM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JM,"href","#transformers.AutoModelForImageClassification"),c(Zd,"class","relative group"),c(oY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aY,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitForImageClassification"),c(nY,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(sY,"href","/docs/transformers/v4.22.1/en/model_doc/cvt#transformers.CvtForImageClassification"),c(lY,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(iY,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTForImageClassification"),c(dY,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(cY,"href","/docs/transformers/v4.22.1/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(fY,"href","/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitForImageClassification"),c(mY,"href","/docs/transformers/v4.22.1/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(gY,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(hY,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(uY,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(pY,"href","/docs/transformers/v4.22.1/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(_Y,"href","/docs/transformers/v4.22.1/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(vY,"href","/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(bY,"href","/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(FY,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(TY,"href","/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinForImageClassification"),c(MY,"href","/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(EY,"href","/docs/transformers/v4.22.1/en/model_doc/van#transformers.VanForImageClassification"),c(CY,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTForImageClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hE,"id","transformers.AutoModelForVideoClassification"),c(hE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hE,"href","#transformers.AutoModelForVideoClassification"),c(rc,"class","relative group"),c(wY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/v4.22.1/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bE,"id","transformers.AutoModelForVision2Seq"),c(bE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bE,"href","#transformers.AutoModelForVision2Seq"),c(nc,"class","relative group"),c(xY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($Y,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SY,"href","/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CE,"id","transformers.AutoModelForVisualQuestionAnswering"),c(CE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CE,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(ic,"class","relative group"),c(RY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IY,"href","/docs/transformers/v4.22.1/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xE,"id","transformers.AutoModelForAudioClassification"),c(xE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xE,"href","#transformers.AutoModelForAudioClassification"),c(fc,"class","relative group"),c(NY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DY,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(GY,"href","/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(OY,"href","/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(VY,"href","/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(XY,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(zY,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(QY,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(WY,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UY,"href","/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OE,"id","transformers.AutoModelForAudioFrameClassification"),c(OE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OE,"href","#transformers.AutoModelForAudioFrameClassification"),c(hc,"class","relative group"),c(HY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YY,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KY,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(ZY,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(eK,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(oK,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(rK,"href","/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YE,"id","transformers.AutoModelForCTC"),c(YE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YE,"href","#transformers.AutoModelForCTC"),c(_c,"class","relative group"),c(tK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(lK,"href","/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.HubertForCTC"),c(iK,"href","/docs/transformers/v4.22.1/en/model_doc/mctct#transformers.MCTCTForCTC"),c(dK,"href","/docs/transformers/v4.22.1/en/model_doc/sew#transformers.SEWForCTC"),c(cK,"href","/docs/transformers/v4.22.1/en/model_doc/sew-d#transformers.SEWDForCTC"),c(fK,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(mK,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(gK,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(hK,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(uK,"href","/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForCTC"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fC,"id","transformers.AutoModelForSpeechSeq2Seq"),c(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fC,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Fc,"class","relative group"),c(pK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_K,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bK,"href","/docs/transformers/v4.22.1/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(FK,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_C,"id","transformers.AutoModelForAudioXVector"),c(_C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_C,"href","#transformers.AutoModelForAudioXVector"),c(Ec,"class","relative group"),c(TK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CK,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(wK,"href","/docs/transformers/v4.22.1/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(AK,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(LK,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(yK,"href","/docs/transformers/v4.22.1/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AC,"id","transformers.AutoModelForMaskedImageModeling"),c(AC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AC,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ac,"class","relative group"),c(xK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($K,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SK,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(RK,"href","/docs/transformers/v4.22.1/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(PK,"href","/docs/transformers/v4.22.1/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(BK,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PC,"id","transformers.AutoModelForObjectDetection"),c(PC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PC,"href","#transformers.AutoModelForObjectDetection"),c(xc,"class","relative group"),c(IK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jK,"href","/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DK,"href","/docs/transformers/v4.22.1/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.AutoModelForImageSegmentation"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.AutoModelForImageSegmentation"),c(Sc,"class","relative group"),c(GK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XK,"href","/docs/transformers/v4.22.1/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zC,"id","transformers.AutoModelForSemanticSegmentation"),c(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zC,"href","#transformers.AutoModelForSemanticSegmentation"),c(Bc,"class","relative group"),c(zK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UK,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(HK,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JK,"href","/docs/transformers/v4.22.1/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YK,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(KK,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e3,"id","transformers.AutoModelForInstanceSegmentation"),c(e3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e3,"href","#transformers.AutoModelForInstanceSegmentation"),c(qc,"class","relative group"),c(ZK,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eZ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oZ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rZ,"href","/docs/transformers/v4.22.1/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n3,"id","transformers.TFAutoModel"),c(n3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n3,"href","#transformers.TFAutoModel"),c(Gc,"class","relative group"),c(tZ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aZ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nZ,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sZ,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertModel"),c(lZ,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.TFBartModel"),c(iZ,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertModel"),c(dZ,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(cZ,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(fZ,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertModel"),c(mZ,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.TFCLIPModel"),c(gZ,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertModel"),c(hZ,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.TFConvNextModel"),c(uZ,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pZ,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_Z,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaModel"),c(vZ,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bZ,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.TFDeiTModel"),c(FZ,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(TZ,"href","/docs/transformers/v4.22.1/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(MZ,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraModel"),c(EZ,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(CZ,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelModel"),c(wZ,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(AZ,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2Model"),c(LZ,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJModel"),c(yZ,"href","/docs/transformers/v4.22.1/en/model_doc/hubert#transformers.TFHubertModel"),c(xZ,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c($Z,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(kZ,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.TFLEDModel"),c(SZ,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerModel"),c(RZ,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.TFLxmertModel"),c(PZ,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.TFMarianModel"),c(BZ,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.TFMBartModel"),c(IZ,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(NZ,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(qZ,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetModel"),c(jZ,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.TFMT5Model"),c(DZ,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(GZ,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.TFOPTModel"),c(OZ,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.TFPegasusModel"),c(VZ,"href","/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.TFRegNetModel"),c(XZ,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertModel"),c(zZ,"href","/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.TFResNetModel"),c(QZ,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaModel"),c(WZ,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerModel"),c(UZ,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.TFSegformerModel"),c(HZ,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(JZ,"href","/docs/transformers/v4.22.1/en/model_doc/swin#transformers.TFSwinModel"),c(YZ,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.TFT5Model"),c(KZ,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasModel"),c(ZZ,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(eee,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.TFViTModel"),c(oee,"href","/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(ree,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(tee,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.TFXGLMModel"),c(aee,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMModel"),c(nee,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(see,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l5,"id","transformers.TFAutoModelForPreTraining"),c(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l5,"href","#transformers.TFAutoModelForPreTraining"),c(Xc,"class","relative group"),c(lee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cee,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(fee,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(mee,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForPreTraining"),c(gee,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hee,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(uee,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(pee,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(_ee,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(vee,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(bee,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Fee,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Tee,"href","/docs/transformers/v4.22.1/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(Mee,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(Eee,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Cee,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(wee,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Aee,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Lee,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(yee,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(xee,"href","/docs/transformers/v4.22.1/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c($ee,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(kee,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(See,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R5,"id","transformers.TFAutoModelForCausalLM"),c(R5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R5,"href","#transformers.TFAutoModelForCausalLM"),c(Wc,"class","relative group"),c(Ree,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iee,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(Nee,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(qee,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(jee,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Dee,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Gee,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Oee,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Vee,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Xee,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(zee,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(Qee,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Wee,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Uee,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Hee,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J5,"id","transformers.TFAutoModelForImageClassification"),c(J5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J5,"href","#transformers.TFAutoModelForImageClassification"),c(Jc,"class","relative group"),c(Jee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kee,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zee,"href","/docs/transformers/v4.22.1/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(eoe,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(ooe,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(roe,"href","/docs/transformers/v4.22.1/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(toe,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(aoe,"href","/docs/transformers/v4.22.1/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(noe,"href","/docs/transformers/v4.22.1/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(soe,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(loe,"href","/docs/transformers/v4.22.1/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(ioe,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.TFViTForImageClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l0,"id","transformers.TFAutoModelForSemanticSegmentation"),c(l0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l0,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(Zc,"class","relative group"),c(doe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/v4.22.1/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(goe,"href","/docs/transformers/v4.22.1/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(hoe,"href","/docs/transformers/v4.22.1/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g0,"id","transformers.TFAutoModelForMaskedLM"),c(g0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g0,"href","#transformers.TFAutoModelForMaskedLM"),c(tf,"class","relative group"),c(uoe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(voe,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(boe,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(Foe,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Toe,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(Moe,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(Eoe,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(Coe,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(woe,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Aoe,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Loe,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(yoe,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(xoe,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c($oe,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(koe,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Soe,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Roe,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Poe,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Boe,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Ioe,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Noe,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I0,"id","transformers.TFAutoModelForSeq2SeqLM"),c(I0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I0,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(sf,"class","relative group"),c(qoe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(joe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Doe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Goe,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Ooe,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Voe,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Xoe,"href","/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(zoe,"href","/docs/transformers/v4.22.1/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(Qoe,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.TFMarianMTModel"),c(Woe,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Uoe,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Hoe,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Joe,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H0,"id","transformers.TFAutoModelForSequenceClassification"),c(H0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H0,"href","#transformers.TFAutoModelForSequenceClassification"),c(cf,"class","relative group"),c(Yoe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Koe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zoe,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ere,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(ore,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(rre,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(tre,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(are,"href","/docs/transformers/v4.22.1/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(nre,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(sre,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(lre,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(ire,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(dre,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(cre,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(fre,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(mre,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(gre,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(hre,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(ure,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(pre,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(_re,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(vre,"href","/docs/transformers/v4.22.1/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(bre,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(Fre,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(Tre,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(Mre,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(Ere,"href","/docs/transformers/v4.22.1/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(Cre,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(wre,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(Are,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ww,"id","transformers.TFAutoModelForMultipleChoice"),c(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ww,"href","#transformers.TFAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Lre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($re,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(kre,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Sre,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Rre,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Pre,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(Bre,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(Ire,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(Nre,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(qre,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(jre,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Dre,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Gre,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Ore,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Vre,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Xre,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(zre,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(Qre,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zw,"id","transformers.TFAutoModelForNextSentencePrediction"),c(zw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zw,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(pf,"class","relative group"),c(Wre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ure,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jre,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Yre,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jw,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(Jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jw,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(bf,"class","relative group"),c(Kre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zre,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ete,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ote,"href","/docs/transformers/v4.22.1/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(eA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Mf,"class","relative group"),c(rte,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tte,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ate,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nte,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aA,"id","transformers.TFAutoModelForTokenClassification"),c(aA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aA,"href","#transformers.TFAutoModelForTokenClassification"),c(wf,"class","relative group"),c(ste,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lte,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ite,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dte,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(cte,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(fte,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(mte,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(gte,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(hte,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(ute,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(pte,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(_te,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(vte,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(bte,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Fte,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(Tte,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Mte,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Ete,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Cte,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(wte,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Ate,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Lte,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(yte,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(xte,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yA,"id","transformers.TFAutoModelForQuestionAnswering"),c(yA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yA,"href","#transformers.TFAutoModelForQuestionAnswering"),c(yf,"class","relative group"),c($te,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kte,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ste,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rte,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Pte,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Bte,"href","/docs/transformers/v4.22.1/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Ite,"href","/docs/transformers/v4.22.1/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Nte,"href","/docs/transformers/v4.22.1/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(qte,"href","/docs/transformers/v4.22.1/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(jte,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Dte,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Gte,"href","/docs/transformers/v4.22.1/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Ote,"href","/docs/transformers/v4.22.1/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Vte,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Xte,"href","/docs/transformers/v4.22.1/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(zte,"href","/docs/transformers/v4.22.1/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(Qte,"href","/docs/transformers/v4.22.1/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Wte,"href","/docs/transformers/v4.22.1/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(Ute,"href","/docs/transformers/v4.22.1/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(Hte,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Jte,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Yte,"href","/docs/transformers/v4.22.1/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(Kte,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(Zte,"href","/docs/transformers/v4.22.1/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KA,"id","transformers.TFAutoModelForVision2Seq"),c(KA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KA,"href","#transformers.TFAutoModelForVision2Seq"),c(kf,"class","relative group"),c(eae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tae,"href","/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Pf,"class","relative group"),c(aae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lae,"href","/docs/transformers/v4.22.1/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s6,"id","transformers.FlaxAutoModel"),c(s6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s6,"href","#transformers.FlaxAutoModel"),c(Nf,"class","relative group"),c(iae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fae,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertModel"),c(mae,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartModel"),c(gae,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.FlaxBeitModel"),c(hae,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertModel"),c(uae,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(pae,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(_ae,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(vae,"href","/docs/transformers/v4.22.1/en/model_doc/clip#transformers.FlaxCLIPModel"),c(bae,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Fae,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraModel"),c(Tae,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Mae,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Eae,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Cae,"href","/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(wae,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.FlaxMarianModel"),c(Aae,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Lae,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.FlaxMT5Model"),c(yae,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.FlaxOPTModel"),c(xae,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c($ae,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(kae,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Sae,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.FlaxT5Model"),c(Rae,"href","/docs/transformers/v4.22.1/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Pae,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.FlaxViTModel"),c(Bae,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Iae,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Nae,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I6,"id","transformers.FlaxAutoModelForCausalLM"),c(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I6,"href","#transformers.FlaxAutoModelForCausalLM"),c(Df,"class","relative group"),c(qae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gae,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Oae,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Vae,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Xae,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(zae,"href","/docs/transformers/v4.22.1/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(Qae,"href","/docs/transformers/v4.22.1/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Wae,"href","/docs/transformers/v4.22.1/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Uae,"href","/docs/transformers/v4.22.1/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(Hae,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Jae,"href","/docs/transformers/v4.22.1/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H6,"id","transformers.FlaxAutoModelForPreTraining"),c(H6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H6,"href","#transformers.FlaxAutoModelForPreTraining"),c(Vf,"class","relative group"),c(Yae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zae,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ene,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(one,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(rne,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(tne,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(ane,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(nne,"href","/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(sne,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(lne,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ine,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(dne,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(cne,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(fne,"href","/docs/transformers/v4.22.1/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(mne,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f7,"id","transformers.FlaxAutoModelForMaskedLM"),c(f7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f7,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Qf,"class","relative group"),c(gne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(une,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pne,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(_ne,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(vne,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(bne,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Fne,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Tne,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Mne,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ene,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Cne,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(wne,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C7,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C7,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Hf,"class","relative group"),c(Ane,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xne,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c($ne,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(kne,"href","/docs/transformers/v4.22.1/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Sne,"href","/docs/transformers/v4.22.1/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Rne,"href","/docs/transformers/v4.22.1/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Pne,"href","/docs/transformers/v4.22.1/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Bne,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ine,"href","/docs/transformers/v4.22.1/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Nne,"href","/docs/transformers/v4.22.1/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(qne,"href","/docs/transformers/v4.22.1/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N7,"id","transformers.FlaxAutoModelForSequenceClassification"),c(N7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N7,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Kf,"class","relative group"),c(jne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(One,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Vne,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Xne,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(zne,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Qne,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Wne,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Une,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Hne,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Jne,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Yne,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J7,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(J7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J7,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(om,"class","relative group"),c(Kne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zne,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ese,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ose,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(rse,"href","/docs/transformers/v4.22.1/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(tse,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(ase,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(nse,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(sse,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(lse,"href","/docs/transformers/v4.22.1/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(ise,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(dse,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(cse,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dL,"id","transformers.FlaxAutoModelForTokenClassification"),c(dL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dL,"href","#transformers.FlaxAutoModelForTokenClassification"),c(am,"class","relative group"),c(fse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hse,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(use,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(pse,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(_se,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(vse,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(bse,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Fse,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Tse,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FL,"id","transformers.FlaxAutoModelForMultipleChoice"),c(FL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FL,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(lm,"class","relative group"),c(Mse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ese,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wse,"href","/docs/transformers/v4.22.1/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Ase,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Lse,"href","/docs/transformers/v4.22.1/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(yse,"href","/docs/transformers/v4.22.1/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(xse,"href","/docs/transformers/v4.22.1/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c($se,"href","/docs/transformers/v4.22.1/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(kse,"href","/docs/transformers/v4.22.1/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Sse,"href","/docs/transformers/v4.22.1/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kL,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(kL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kL,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(cm,"class","relative group"),c(Rse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ise,"href","/docs/transformers/v4.22.1/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BL,"id","transformers.FlaxAutoModelForImageClassification"),c(BL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BL,"href","#transformers.FlaxAutoModelForImageClassification"),c(gm,"class","relative group"),c(Nse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dse,"href","/docs/transformers/v4.22.1/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Gse,"href","/docs/transformers/v4.22.1/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DL,"id","transformers.FlaxAutoModelForVision2Seq"),c(DL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DL,"href","#transformers.FlaxAutoModelForVision2Seq"),c(pm,"class","relative group"),c(Ose,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Xse,"href","/docs/transformers/v4.22.1/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zse,"href","/docs/transformers/v4.22.1/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),v(f,b,_),v(f,u,_),e(u,m),e(m,p),M(d,p,null),e(u,h),e(u,yo),e(yo,rd),v(f,Mm,_),v(f,pt,_),e(pt,td),e(pt,ad),e(ad,b9),e(pt,Em),v(f,Ve,_),v(f,He,_),e(He,nd),e(He,Zn),e(Zn,F9),e(He,es),e(He,os),e(os,T9),e(He,sd),e(He,rs),e(rs,M9),e(He,ld),v(f,Cm,_),M(Qa,f,_),v(f,Je,_),v(f,Ae,_),e(Ae,CB),e(Ae,id),e(id,wB),e(Ae,AB),v(f,xo,_),v(f,Wa,_),e(Wa,LB),e(Wa,wm),e(wm,yB),e(Wa,iro),v(f,kYe,_),v(f,dd,_),e(dd,Am),e(Am,Hie),M(E9,Hie,null),e(dd,dro),e(dd,Jie),e(Jie,cro),v(f,SYe,_),v(f,ts,_),e(ts,fro),e(ts,Yie),e(Yie,mro),e(ts,gro),e(ts,Kie),e(Kie,hro),e(ts,uro),v(f,RYe,_),M(C9,f,_),v(f,PYe,_),v(f,xB,_),e(xB,pro),v(f,BYe,_),M(Lm,f,_),v(f,IYe,_),v(f,cd,_),e(cd,ym),e(ym,Zie),M(w9,Zie,null),e(cd,_ro),e(cd,ede),e(ede,vro),v(f,NYe,_),v(f,$o,_),M(A9,$o,null),e($o,bro),e($o,L9),e(L9,Fro),e(L9,$B),e($B,Tro),e(L9,Mro),e($o,Ero),e($o,y9),e(y9,Cro),e(y9,ode),e(ode,wro),e(y9,Aro),e($o,Lro),e($o,Pr),M(x9,Pr,null),e(Pr,yro),e(Pr,rde),e(rde,xro),e(Pr,$ro),e(Pr,fd),e(fd,kro),e(fd,tde),e(tde,Sro),e(fd,Rro),e(fd,ade),e(ade,Pro),e(fd,Bro),e(Pr,Iro),e(Pr,A),e(A,xm),e(xm,nde),e(nde,Nro),e(xm,qro),e(xm,kB),e(kB,jro),e(xm,Dro),e(A,Gro),e(A,$m),e($m,sde),e(sde,Oro),e($m,Vro),e($m,SB),e(SB,Xro),e($m,zro),e(A,Qro),e(A,km),e(km,lde),e(lde,Wro),e(km,Uro),e(km,RB),e(RB,Hro),e(km,Jro),e(A,Yro),e(A,Sm),e(Sm,ide),e(ide,Kro),e(Sm,Zro),e(Sm,PB),e(PB,eto),e(Sm,oto),e(A,rto),e(A,Rm),e(Rm,dde),e(dde,tto),e(Rm,ato),e(Rm,BB),e(BB,nto),e(Rm,sto),e(A,lto),e(A,Pm),e(Pm,cde),e(cde,ito),e(Pm,dto),e(Pm,IB),e(IB,cto),e(Pm,fto),e(A,mto),e(A,Bm),e(Bm,fde),e(fde,gto),e(Bm,hto),e(Bm,NB),e(NB,uto),e(Bm,pto),e(A,_to),e(A,Im),e(Im,mde),e(mde,vto),e(Im,bto),e(Im,qB),e(qB,Fto),e(Im,Tto),e(A,Mto),e(A,Nm),e(Nm,gde),e(gde,Eto),e(Nm,Cto),e(Nm,jB),e(jB,wto),e(Nm,Ato),e(A,Lto),e(A,qm),e(qm,hde),e(hde,yto),e(qm,xto),e(qm,DB),e(DB,$to),e(qm,kto),e(A,Sto),e(A,jm),e(jm,ude),e(ude,Rto),e(jm,Pto),e(jm,GB),e(GB,Bto),e(jm,Ito),e(A,Nto),e(A,Dm),e(Dm,pde),e(pde,qto),e(Dm,jto),e(Dm,OB),e(OB,Dto),e(Dm,Gto),e(A,Oto),e(A,Gm),e(Gm,_de),e(_de,Vto),e(Gm,Xto),e(Gm,VB),e(VB,zto),e(Gm,Qto),e(A,Wto),e(A,Om),e(Om,vde),e(vde,Uto),e(Om,Hto),e(Om,XB),e(XB,Jto),e(Om,Yto),e(A,Kto),e(A,Vm),e(Vm,bde),e(bde,Zto),e(Vm,eao),e(Vm,zB),e(zB,oao),e(Vm,rao),e(A,tao),e(A,Xm),e(Xm,Fde),e(Fde,aao),e(Xm,nao),e(Xm,QB),e(QB,sao),e(Xm,lao),e(A,iao),e(A,zm),e(zm,Tde),e(Tde,dao),e(zm,cao),e(zm,WB),e(WB,fao),e(zm,mao),e(A,gao),e(A,Qm),e(Qm,Mde),e(Mde,hao),e(Qm,uao),e(Qm,UB),e(UB,pao),e(Qm,_ao),e(A,vao),e(A,Wm),e(Wm,Ede),e(Ede,bao),e(Wm,Fao),e(Wm,HB),e(HB,Tao),e(Wm,Mao),e(A,Eao),e(A,Um),e(Um,Cde),e(Cde,Cao),e(Um,wao),e(Um,JB),e(JB,Aao),e(Um,Lao),e(A,yao),e(A,Hm),e(Hm,wde),e(wde,xao),e(Hm,$ao),e(Hm,YB),e(YB,kao),e(Hm,Sao),e(A,Rao),e(A,Jm),e(Jm,Ade),e(Ade,Pao),e(Jm,Bao),e(Jm,KB),e(KB,Iao),e(Jm,Nao),e(A,qao),e(A,Ym),e(Ym,Lde),e(Lde,jao),e(Ym,Dao),e(Ym,ZB),e(ZB,Gao),e(Ym,Oao),e(A,Vao),e(A,Km),e(Km,yde),e(yde,Xao),e(Km,zao),e(Km,eI),e(eI,Qao),e(Km,Wao),e(A,Uao),e(A,Zm),e(Zm,xde),e(xde,Hao),e(Zm,Jao),e(Zm,oI),e(oI,Yao),e(Zm,Kao),e(A,Zao),e(A,eg),e(eg,$de),e($de,eno),e(eg,ono),e(eg,rI),e(rI,rno),e(eg,tno),e(A,ano),e(A,og),e(og,kde),e(kde,nno),e(og,sno),e(og,tI),e(tI,lno),e(og,ino),e(A,dno),e(A,rg),e(rg,Sde),e(Sde,cno),e(rg,fno),e(rg,aI),e(aI,mno),e(rg,gno),e(A,hno),e(A,tg),e(tg,Rde),e(Rde,uno),e(tg,pno),e(tg,nI),e(nI,_no),e(tg,vno),e(A,bno),e(A,ag),e(ag,Pde),e(Pde,Fno),e(ag,Tno),e(ag,sI),e(sI,Mno),e(ag,Eno),e(A,Cno),e(A,ng),e(ng,Bde),e(Bde,wno),e(ng,Ano),e(ng,lI),e(lI,Lno),e(ng,yno),e(A,xno),e(A,sg),e(sg,Ide),e(Ide,$no),e(sg,kno),e(sg,iI),e(iI,Sno),e(sg,Rno),e(A,Pno),e(A,lg),e(lg,Nde),e(Nde,Bno),e(lg,Ino),e(lg,dI),e(dI,Nno),e(lg,qno),e(A,jno),e(A,ig),e(ig,qde),e(qde,Dno),e(ig,Gno),e(ig,cI),e(cI,Ono),e(ig,Vno),e(A,Xno),e(A,dg),e(dg,jde),e(jde,zno),e(dg,Qno),e(dg,fI),e(fI,Wno),e(dg,Uno),e(A,Hno),e(A,cg),e(cg,Dde),e(Dde,Jno),e(cg,Yno),e(cg,mI),e(mI,Kno),e(cg,Zno),e(A,eso),e(A,fg),e(fg,Gde),e(Gde,oso),e(fg,rso),e(fg,gI),e(gI,tso),e(fg,aso),e(A,nso),e(A,mg),e(mg,Ode),e(Ode,sso),e(mg,lso),e(mg,hI),e(hI,iso),e(mg,dso),e(A,cso),e(A,gg),e(gg,Vde),e(Vde,fso),e(gg,mso),e(gg,uI),e(uI,gso),e(gg,hso),e(A,uso),e(A,hg),e(hg,Xde),e(Xde,pso),e(hg,_so),e(hg,pI),e(pI,vso),e(hg,bso),e(A,Fso),e(A,ug),e(ug,zde),e(zde,Tso),e(ug,Mso),e(ug,_I),e(_I,Eso),e(ug,Cso),e(A,wso),e(A,pg),e(pg,Qde),e(Qde,Aso),e(pg,Lso),e(pg,vI),e(vI,yso),e(pg,xso),e(A,$so),e(A,_g),e(_g,Wde),e(Wde,kso),e(_g,Sso),e(_g,bI),e(bI,Rso),e(_g,Pso),e(A,Bso),e(A,vg),e(vg,Ude),e(Ude,Iso),e(vg,Nso),e(vg,FI),e(FI,qso),e(vg,jso),e(A,Dso),e(A,bg),e(bg,Hde),e(Hde,Gso),e(bg,Oso),e(bg,TI),e(TI,Vso),e(bg,Xso),e(A,zso),e(A,Fg),e(Fg,Jde),e(Jde,Qso),e(Fg,Wso),e(Fg,MI),e(MI,Uso),e(Fg,Hso),e(A,Jso),e(A,Tg),e(Tg,Yde),e(Yde,Yso),e(Tg,Kso),e(Tg,EI),e(EI,Zso),e(Tg,elo),e(A,olo),e(A,Mg),e(Mg,Kde),e(Kde,rlo),e(Mg,tlo),e(Mg,CI),e(CI,alo),e(Mg,nlo),e(A,slo),e(A,Eg),e(Eg,Zde),e(Zde,llo),e(Eg,ilo),e(Eg,wI),e(wI,dlo),e(Eg,clo),e(A,flo),e(A,Cg),e(Cg,ece),e(ece,mlo),e(Cg,glo),e(Cg,AI),e(AI,hlo),e(Cg,ulo),e(A,plo),e(A,wg),e(wg,oce),e(oce,_lo),e(wg,vlo),e(wg,LI),e(LI,blo),e(wg,Flo),e(A,Tlo),e(A,Ag),e(Ag,rce),e(rce,Mlo),e(Ag,Elo),e(Ag,yI),e(yI,Clo),e(Ag,wlo),e(A,Alo),e(A,Lg),e(Lg,tce),e(tce,Llo),e(Lg,ylo),e(Lg,xI),e(xI,xlo),e(Lg,$lo),e(A,klo),e(A,yg),e(yg,ace),e(ace,Slo),e(yg,Rlo),e(yg,$I),e($I,Plo),e(yg,Blo),e(A,Ilo),e(A,xg),e(xg,nce),e(nce,Nlo),e(xg,qlo),e(xg,kI),e(kI,jlo),e(xg,Dlo),e(A,Glo),e(A,$g),e($g,sce),e(sce,Olo),e($g,Vlo),e($g,SI),e(SI,Xlo),e($g,zlo),e(A,Qlo),e(A,kg),e(kg,lce),e(lce,Wlo),e(kg,Ulo),e(kg,RI),e(RI,Hlo),e(kg,Jlo),e(A,Ylo),e(A,Sg),e(Sg,ice),e(ice,Klo),e(Sg,Zlo),e(Sg,PI),e(PI,eio),e(Sg,oio),e(A,rio),e(A,Rg),e(Rg,dce),e(dce,tio),e(Rg,aio),e(Rg,BI),e(BI,nio),e(Rg,sio),e(A,lio),e(A,Pg),e(Pg,cce),e(cce,iio),e(Pg,dio),e(Pg,II),e(II,cio),e(Pg,fio),e(A,mio),e(A,Bg),e(Bg,fce),e(fce,gio),e(Bg,hio),e(Bg,NI),e(NI,uio),e(Bg,pio),e(A,_io),e(A,Ig),e(Ig,mce),e(mce,vio),e(Ig,bio),e(Ig,qI),e(qI,Fio),e(Ig,Tio),e(A,Mio),e(A,Ng),e(Ng,gce),e(gce,Eio),e(Ng,Cio),e(Ng,jI),e(jI,wio),e(Ng,Aio),e(A,Lio),e(A,qg),e(qg,hce),e(hce,yio),e(qg,xio),e(qg,DI),e(DI,$io),e(qg,kio),e(A,Sio),e(A,jg),e(jg,uce),e(uce,Rio),e(jg,Pio),e(jg,GI),e(GI,Bio),e(jg,Iio),e(A,Nio),e(A,Dg),e(Dg,pce),e(pce,qio),e(Dg,jio),e(Dg,OI),e(OI,Dio),e(Dg,Gio),e(A,Oio),e(A,Gg),e(Gg,_ce),e(_ce,Vio),e(Gg,Xio),e(Gg,VI),e(VI,zio),e(Gg,Qio),e(A,Wio),e(A,Og),e(Og,vce),e(vce,Uio),e(Og,Hio),e(Og,XI),e(XI,Jio),e(Og,Yio),e(A,Kio),e(A,Vg),e(Vg,bce),e(bce,Zio),e(Vg,edo),e(Vg,zI),e(zI,odo),e(Vg,rdo),e(A,tdo),e(A,Xg),e(Xg,Fce),e(Fce,ado),e(Xg,ndo),e(Xg,QI),e(QI,sdo),e(Xg,ldo),e(A,ido),e(A,zg),e(zg,Tce),e(Tce,ddo),e(zg,cdo),e(zg,WI),e(WI,fdo),e(zg,mdo),e(A,gdo),e(A,Qg),e(Qg,Mce),e(Mce,hdo),e(Qg,udo),e(Qg,UI),e(UI,pdo),e(Qg,_do),e(A,vdo),e(A,Wg),e(Wg,Ece),e(Ece,bdo),e(Wg,Fdo),e(Wg,HI),e(HI,Tdo),e(Wg,Mdo),e(A,Edo),e(A,Ug),e(Ug,Cce),e(Cce,Cdo),e(Ug,wdo),e(Ug,JI),e(JI,Ado),e(Ug,Ldo),e(A,ydo),e(A,Hg),e(Hg,wce),e(wce,xdo),e(Hg,$do),e(Hg,YI),e(YI,kdo),e(Hg,Sdo),e(A,Rdo),e(A,Jg),e(Jg,Ace),e(Ace,Pdo),e(Jg,Bdo),e(Jg,KI),e(KI,Ido),e(Jg,Ndo),e(A,qdo),e(A,Yg),e(Yg,Lce),e(Lce,jdo),e(Yg,Ddo),e(Yg,ZI),e(ZI,Gdo),e(Yg,Odo),e(A,Vdo),e(A,Kg),e(Kg,yce),e(yce,Xdo),e(Kg,zdo),e(Kg,eN),e(eN,Qdo),e(Kg,Wdo),e(A,Udo),e(A,Zg),e(Zg,xce),e(xce,Hdo),e(Zg,Jdo),e(Zg,oN),e(oN,Ydo),e(Zg,Kdo),e(A,Zdo),e(A,eh),e(eh,$ce),e($ce,eco),e(eh,oco),e(eh,rN),e(rN,rco),e(eh,tco),e(A,aco),e(A,oh),e(oh,kce),e(kce,nco),e(oh,sco),e(oh,tN),e(tN,lco),e(oh,ico),e(A,dco),e(A,rh),e(rh,Sce),e(Sce,cco),e(rh,fco),e(rh,aN),e(aN,mco),e(rh,gco),e(A,hco),e(A,th),e(th,Rce),e(Rce,uco),e(th,pco),e(th,nN),e(nN,_co),e(th,vco),e(A,bco),e(A,ah),e(ah,Pce),e(Pce,Fco),e(ah,Tco),e(ah,sN),e(sN,Mco),e(ah,Eco),e(A,Cco),e(A,nh),e(nh,Bce),e(Bce,wco),e(nh,Aco),e(nh,lN),e(lN,Lco),e(nh,yco),e(A,xco),e(A,sh),e(sh,Ice),e(Ice,$co),e(sh,kco),e(sh,iN),e(iN,Sco),e(sh,Rco),e(A,Pco),e(A,lh),e(lh,Nce),e(Nce,Bco),e(lh,Ico),e(lh,dN),e(dN,Nco),e(lh,qco),e(A,jco),e(A,ih),e(ih,qce),e(qce,Dco),e(ih,Gco),e(ih,cN),e(cN,Oco),e(ih,Vco),e(A,Xco),e(A,dh),e(dh,jce),e(jce,zco),e(dh,Qco),e(dh,fN),e(fN,Wco),e(dh,Uco),e(A,Hco),e(A,ch),e(ch,Dce),e(Dce,Jco),e(ch,Yco),e(ch,mN),e(mN,Kco),e(ch,Zco),e(A,efo),e(A,fh),e(fh,Gce),e(Gce,ofo),e(fh,rfo),e(fh,gN),e(gN,tfo),e(fh,afo),e(A,nfo),e(A,mh),e(mh,Oce),e(Oce,sfo),e(mh,lfo),e(mh,hN),e(hN,ifo),e(mh,dfo),e(A,cfo),e(A,gh),e(gh,Vce),e(Vce,ffo),e(gh,mfo),e(gh,uN),e(uN,gfo),e(gh,hfo),e(A,ufo),e(A,hh),e(hh,Xce),e(Xce,pfo),e(hh,_fo),e(hh,pN),e(pN,vfo),e(hh,bfo),e(A,Ffo),e(A,uh),e(uh,zce),e(zce,Tfo),e(uh,Mfo),e(uh,_N),e(_N,Efo),e(uh,Cfo),e(A,wfo),e(A,ph),e(ph,Qce),e(Qce,Afo),e(ph,Lfo),e(ph,vN),e(vN,yfo),e(ph,xfo),e(A,$fo),e(A,_h),e(_h,Wce),e(Wce,kfo),e(_h,Sfo),e(_h,bN),e(bN,Rfo),e(_h,Pfo),e(A,Bfo),e(A,vh),e(vh,Uce),e(Uce,Ifo),e(vh,Nfo),e(vh,FN),e(FN,qfo),e(vh,jfo),e(A,Dfo),e(A,bh),e(bh,Hce),e(Hce,Gfo),e(bh,Ofo),e(bh,TN),e(TN,Vfo),e(bh,Xfo),e(A,zfo),e(A,Fh),e(Fh,Jce),e(Jce,Qfo),e(Fh,Wfo),e(Fh,MN),e(MN,Ufo),e(Fh,Hfo),e(A,Jfo),e(A,Th),e(Th,Yce),e(Yce,Yfo),e(Th,Kfo),e(Th,EN),e(EN,Zfo),e(Th,emo),e(A,omo),e(A,Mh),e(Mh,Kce),e(Kce,rmo),e(Mh,tmo),e(Mh,CN),e(CN,amo),e(Mh,nmo),e(A,smo),e(A,Eh),e(Eh,Zce),e(Zce,lmo),e(Eh,imo),e(Eh,wN),e(wN,dmo),e(Eh,cmo),e(A,fmo),e(A,Ch),e(Ch,efe),e(efe,mmo),e(Ch,gmo),e(Ch,AN),e(AN,hmo),e(Ch,umo),e(A,pmo),e(A,wh),e(wh,ofe),e(ofe,_mo),e(wh,vmo),e(wh,LN),e(LN,bmo),e(wh,Fmo),e(A,Tmo),e(A,Ah),e(Ah,rfe),e(rfe,Mmo),e(Ah,Emo),e(Ah,yN),e(yN,Cmo),e(Ah,wmo),e(A,Amo),e(A,Lh),e(Lh,tfe),e(tfe,Lmo),e(Lh,ymo),e(Lh,xN),e(xN,xmo),e(Lh,$mo),e(A,kmo),e(A,yh),e(yh,afe),e(afe,Smo),e(yh,Rmo),e(yh,$N),e($N,Pmo),e(yh,Bmo),e(A,Imo),e(A,xh),e(xh,nfe),e(nfe,Nmo),e(xh,qmo),e(xh,kN),e(kN,jmo),e(xh,Dmo),e(A,Gmo),e(A,$h),e($h,sfe),e(sfe,Omo),e($h,Vmo),e($h,SN),e(SN,Xmo),e($h,zmo),e(A,Qmo),e(A,kh),e(kh,lfe),e(lfe,Wmo),e(kh,Umo),e(kh,RN),e(RN,Hmo),e(kh,Jmo),e(A,Ymo),e(A,Sh),e(Sh,ife),e(ife,Kmo),e(Sh,Zmo),e(Sh,PN),e(PN,ego),e(Sh,ogo),e(A,rgo),e(A,Rh),e(Rh,dfe),e(dfe,tgo),e(Rh,ago),e(Rh,BN),e(BN,ngo),e(Rh,sgo),e(A,lgo),e(A,Ph),e(Ph,cfe),e(cfe,igo),e(Ph,dgo),e(Ph,IN),e(IN,cgo),e(Ph,fgo),e(A,mgo),e(A,Bh),e(Bh,ffe),e(ffe,ggo),e(Bh,hgo),e(Bh,NN),e(NN,ugo),e(Bh,pgo),e(A,_go),e(A,Ih),e(Ih,mfe),e(mfe,vgo),e(Ih,bgo),e(Ih,qN),e(qN,Fgo),e(Ih,Tgo),e(A,Mgo),e(A,Nh),e(Nh,gfe),e(gfe,Ego),e(Nh,Cgo),e(Nh,jN),e(jN,wgo),e(Nh,Ago),e(A,Lgo),e(A,qh),e(qh,hfe),e(hfe,ygo),e(qh,xgo),e(qh,DN),e(DN,$go),e(qh,kgo),e(A,Sgo),e(A,jh),e(jh,ufe),e(ufe,Rgo),e(jh,Pgo),e(jh,GN),e(GN,Bgo),e(jh,Igo),e(A,Ngo),e(A,Dh),e(Dh,pfe),e(pfe,qgo),e(Dh,jgo),e(Dh,ON),e(ON,Dgo),e(Dh,Ggo),e(A,Ogo),e(A,Gh),e(Gh,_fe),e(_fe,Vgo),e(Gh,Xgo),e(Gh,VN),e(VN,zgo),e(Gh,Qgo),e(A,Wgo),e(A,Oh),e(Oh,vfe),e(vfe,Ugo),e(Oh,Hgo),e(Oh,XN),e(XN,Jgo),e(Oh,Ygo),e(A,Kgo),e(A,Vh),e(Vh,bfe),e(bfe,Zgo),e(Vh,eho),e(Vh,zN),e(zN,oho),e(Vh,rho),e(A,tho),e(A,Xh),e(Xh,Ffe),e(Ffe,aho),e(Xh,nho),e(Xh,QN),e(QN,sho),e(Xh,lho),e(A,iho),e(A,zh),e(zh,Tfe),e(Tfe,dho),e(zh,cho),e(zh,WN),e(WN,fho),e(zh,mho),e(Pr,gho),M(Qh,Pr,null),e($o,hho),e($o,Wh),M($9,Wh,null),e(Wh,uho),e(Wh,Mfe),e(Mfe,pho),v(f,qYe,_),v(f,md,_),e(md,Uh),e(Uh,Efe),M(k9,Efe,null),e(md,_ho),e(md,Cfe),e(Cfe,vho),v(f,jYe,_),v(f,ko,_),M(S9,ko,null),e(ko,bho),e(ko,R9),e(R9,Fho),e(R9,UN),e(UN,Tho),e(R9,Mho),e(ko,Eho),e(ko,P9),e(P9,Cho),e(P9,wfe),e(wfe,who),e(P9,Aho),e(ko,Lho),e(ko,Br),M(B9,Br,null),e(Br,yho),e(Br,Afe),e(Afe,xho),e(Br,$ho),e(Br,Ua),e(Ua,kho),e(Ua,Lfe),e(Lfe,Sho),e(Ua,Rho),e(Ua,yfe),e(yfe,Pho),e(Ua,Bho),e(Ua,xfe),e(xfe,Iho),e(Ua,Nho),e(Br,qho),e(Br,k),e(k,as),e(as,$fe),e($fe,jho),e(as,Dho),e(as,HN),e(HN,Gho),e(as,Oho),e(as,JN),e(JN,Vho),e(as,Xho),e(k,zho),e(k,ns),e(ns,kfe),e(kfe,Qho),e(ns,Who),e(ns,YN),e(YN,Uho),e(ns,Hho),e(ns,KN),e(KN,Jho),e(ns,Yho),e(k,Kho),e(k,ss),e(ss,Sfe),e(Sfe,Zho),e(ss,euo),e(ss,ZN),e(ZN,ouo),e(ss,ruo),e(ss,eq),e(eq,tuo),e(ss,auo),e(k,nuo),e(k,Hh),e(Hh,Rfe),e(Rfe,suo),e(Hh,luo),e(Hh,oq),e(oq,iuo),e(Hh,duo),e(k,cuo),e(k,ls),e(ls,Pfe),e(Pfe,fuo),e(ls,muo),e(ls,rq),e(rq,guo),e(ls,huo),e(ls,tq),e(tq,uuo),e(ls,puo),e(k,_uo),e(k,Jh),e(Jh,Bfe),e(Bfe,vuo),e(Jh,buo),e(Jh,aq),e(aq,Fuo),e(Jh,Tuo),e(k,Muo),e(k,Yh),e(Yh,Ife),e(Ife,Euo),e(Yh,Cuo),e(Yh,nq),e(nq,wuo),e(Yh,Auo),e(k,Luo),e(k,Kh),e(Kh,Nfe),e(Nfe,yuo),e(Kh,xuo),e(Kh,sq),e(sq,$uo),e(Kh,kuo),e(k,Suo),e(k,is),e(is,qfe),e(qfe,Ruo),e(is,Puo),e(is,lq),e(lq,Buo),e(is,Iuo),e(is,iq),e(iq,Nuo),e(is,quo),e(k,juo),e(k,ds),e(ds,jfe),e(jfe,Duo),e(ds,Guo),e(ds,dq),e(dq,Ouo),e(ds,Vuo),e(ds,cq),e(cq,Xuo),e(ds,zuo),e(k,Quo),e(k,cs),e(cs,Dfe),e(Dfe,Wuo),e(cs,Uuo),e(cs,fq),e(fq,Huo),e(cs,Juo),e(cs,mq),e(mq,Yuo),e(cs,Kuo),e(k,Zuo),e(k,Zh),e(Zh,Gfe),e(Gfe,epo),e(Zh,opo),e(Zh,gq),e(gq,rpo),e(Zh,tpo),e(k,apo),e(k,eu),e(eu,Ofe),e(Ofe,npo),e(eu,spo),e(eu,hq),e(hq,lpo),e(eu,ipo),e(k,dpo),e(k,ou),e(ou,Vfe),e(Vfe,cpo),e(ou,fpo),e(ou,uq),e(uq,mpo),e(ou,gpo),e(k,hpo),e(k,fs),e(fs,Xfe),e(Xfe,upo),e(fs,ppo),e(fs,pq),e(pq,_po),e(fs,vpo),e(fs,_q),e(_q,bpo),e(fs,Fpo),e(k,Tpo),e(k,ru),e(ru,zfe),e(zfe,Mpo),e(ru,Epo),e(ru,vq),e(vq,Cpo),e(ru,wpo),e(k,Apo),e(k,ms),e(ms,Qfe),e(Qfe,Lpo),e(ms,ypo),e(ms,bq),e(bq,xpo),e(ms,$po),e(ms,Fq),e(Fq,kpo),e(ms,Spo),e(k,Rpo),e(k,gs),e(gs,Wfe),e(Wfe,Ppo),e(gs,Bpo),e(gs,Tq),e(Tq,Ipo),e(gs,Npo),e(gs,Mq),e(Mq,qpo),e(gs,jpo),e(k,Dpo),e(k,hs),e(hs,Ufe),e(Ufe,Gpo),e(hs,Opo),e(hs,Eq),e(Eq,Vpo),e(hs,Xpo),e(hs,Cq),e(Cq,zpo),e(hs,Qpo),e(k,Wpo),e(k,us),e(us,Hfe),e(Hfe,Upo),e(us,Hpo),e(us,wq),e(wq,Jpo),e(us,Ypo),e(us,Aq),e(Aq,Kpo),e(us,Zpo),e(k,e_o),e(k,tu),e(tu,Jfe),e(Jfe,o_o),e(tu,r_o),e(tu,Lq),e(Lq,t_o),e(tu,a_o),e(k,n_o),e(k,ps),e(ps,Yfe),e(Yfe,s_o),e(ps,l_o),e(ps,yq),e(yq,i_o),e(ps,d_o),e(ps,xq),e(xq,c_o),e(ps,f_o),e(k,m_o),e(k,_s),e(_s,Kfe),e(Kfe,g_o),e(_s,h_o),e(_s,$q),e($q,u_o),e(_s,p_o),e(_s,kq),e(kq,__o),e(_s,v_o),e(k,b_o),e(k,vs),e(vs,Zfe),e(Zfe,F_o),e(vs,T_o),e(vs,Sq),e(Sq,M_o),e(vs,E_o),e(vs,Rq),e(Rq,C_o),e(vs,w_o),e(k,A_o),e(k,bs),e(bs,eme),e(eme,L_o),e(bs,y_o),e(bs,Pq),e(Pq,x_o),e(bs,$_o),e(bs,Bq),e(Bq,k_o),e(bs,S_o),e(k,R_o),e(k,Fs),e(Fs,ome),e(ome,P_o),e(Fs,B_o),e(Fs,Iq),e(Iq,I_o),e(Fs,N_o),e(Fs,Nq),e(Nq,q_o),e(Fs,j_o),e(k,D_o),e(k,Ts),e(Ts,rme),e(rme,G_o),e(Ts,O_o),e(Ts,qq),e(qq,V_o),e(Ts,X_o),e(Ts,jq),e(jq,z_o),e(Ts,Q_o),e(k,W_o),e(k,Ms),e(Ms,tme),e(tme,U_o),e(Ms,H_o),e(Ms,Dq),e(Dq,J_o),e(Ms,Y_o),e(Ms,Gq),e(Gq,K_o),e(Ms,Z_o),e(k,e2o),e(k,au),e(au,ame),e(ame,o2o),e(au,r2o),e(au,Oq),e(Oq,t2o),e(au,a2o),e(k,n2o),e(k,Es),e(Es,nme),e(nme,s2o),e(Es,l2o),e(Es,Vq),e(Vq,i2o),e(Es,d2o),e(Es,Xq),e(Xq,c2o),e(Es,f2o),e(k,m2o),e(k,nu),e(nu,sme),e(sme,g2o),e(nu,h2o),e(nu,zq),e(zq,u2o),e(nu,p2o),e(k,_2o),e(k,Cs),e(Cs,lme),e(lme,v2o),e(Cs,b2o),e(Cs,Qq),e(Qq,F2o),e(Cs,T2o),e(Cs,Wq),e(Wq,M2o),e(Cs,E2o),e(k,C2o),e(k,ws),e(ws,ime),e(ime,w2o),e(ws,A2o),e(ws,Uq),e(Uq,L2o),e(ws,y2o),e(ws,Hq),e(Hq,x2o),e(ws,$2o),e(k,k2o),e(k,As),e(As,dme),e(dme,S2o),e(As,R2o),e(As,Jq),e(Jq,P2o),e(As,B2o),e(As,Yq),e(Yq,I2o),e(As,N2o),e(k,q2o),e(k,su),e(su,cme),e(cme,j2o),e(su,D2o),e(su,Kq),e(Kq,G2o),e(su,O2o),e(k,V2o),e(k,Ls),e(Ls,fme),e(fme,X2o),e(Ls,z2o),e(Ls,Zq),e(Zq,Q2o),e(Ls,W2o),e(Ls,ej),e(ej,U2o),e(Ls,H2o),e(k,J2o),e(k,ys),e(ys,mme),e(mme,Y2o),e(ys,K2o),e(ys,oj),e(oj,Z2o),e(ys,evo),e(ys,rj),e(rj,ovo),e(ys,rvo),e(k,tvo),e(k,xs),e(xs,gme),e(gme,avo),e(xs,nvo),e(xs,tj),e(tj,svo),e(xs,lvo),e(xs,aj),e(aj,ivo),e(xs,dvo),e(k,cvo),e(k,lu),e(lu,hme),e(hme,fvo),e(lu,mvo),e(lu,nj),e(nj,gvo),e(lu,hvo),e(k,uvo),e(k,$s),e($s,ume),e(ume,pvo),e($s,_vo),e($s,sj),e(sj,vvo),e($s,bvo),e($s,lj),e(lj,Fvo),e($s,Tvo),e(k,Mvo),e(k,ks),e(ks,pme),e(pme,Evo),e(ks,Cvo),e(ks,ij),e(ij,wvo),e(ks,Avo),e(ks,dj),e(dj,Lvo),e(ks,yvo),e(k,xvo),e(k,Ss),e(Ss,_me),e(_me,$vo),e(Ss,kvo),e(Ss,cj),e(cj,Svo),e(Ss,Rvo),e(Ss,fj),e(fj,Pvo),e(Ss,Bvo),e(k,Ivo),e(k,Rs),e(Rs,vme),e(vme,Nvo),e(Rs,qvo),e(Rs,mj),e(mj,jvo),e(Rs,Dvo),e(Rs,gj),e(gj,Gvo),e(Rs,Ovo),e(k,Vvo),e(k,Ps),e(Ps,bme),e(bme,Xvo),e(Ps,zvo),e(Ps,hj),e(hj,Qvo),e(Ps,Wvo),e(Ps,uj),e(uj,Uvo),e(Ps,Hvo),e(k,Jvo),e(k,Bs),e(Bs,Fme),e(Fme,Yvo),e(Bs,Kvo),e(Bs,pj),e(pj,Zvo),e(Bs,e1o),e(Bs,_j),e(_j,o1o),e(Bs,r1o),e(k,t1o),e(k,Is),e(Is,Tme),e(Tme,a1o),e(Is,n1o),e(Is,vj),e(vj,s1o),e(Is,l1o),e(Is,bj),e(bj,i1o),e(Is,d1o),e(k,c1o),e(k,Ns),e(Ns,Mme),e(Mme,f1o),e(Ns,m1o),e(Ns,Fj),e(Fj,g1o),e(Ns,h1o),e(Ns,Tj),e(Tj,u1o),e(Ns,p1o),e(k,_1o),e(k,iu),e(iu,Eme),e(Eme,v1o),e(iu,b1o),e(iu,Mj),e(Mj,F1o),e(iu,T1o),e(k,M1o),e(k,qs),e(qs,Cme),e(Cme,E1o),e(qs,C1o),e(qs,Ej),e(Ej,w1o),e(qs,A1o),e(qs,Cj),e(Cj,L1o),e(qs,y1o),e(k,x1o),e(k,du),e(du,wme),e(wme,$1o),e(du,k1o),e(du,wj),e(wj,S1o),e(du,R1o),e(k,P1o),e(k,cu),e(cu,Ame),e(Ame,B1o),e(cu,I1o),e(cu,Aj),e(Aj,N1o),e(cu,q1o),e(k,j1o),e(k,js),e(js,Lme),e(Lme,D1o),e(js,G1o),e(js,Lj),e(Lj,O1o),e(js,V1o),e(js,yj),e(yj,X1o),e(js,z1o),e(k,Q1o),e(k,Ds),e(Ds,yme),e(yme,W1o),e(Ds,U1o),e(Ds,xj),e(xj,H1o),e(Ds,J1o),e(Ds,$j),e($j,Y1o),e(Ds,K1o),e(k,Z1o),e(k,Gs),e(Gs,xme),e(xme,e4o),e(Gs,o4o),e(Gs,kj),e(kj,r4o),e(Gs,t4o),e(Gs,Sj),e(Sj,a4o),e(Gs,n4o),e(k,s4o),e(k,fu),e(fu,$me),e($me,l4o),e(fu,i4o),e(fu,Rj),e(Rj,d4o),e(fu,c4o),e(k,f4o),e(k,Os),e(Os,kme),e(kme,m4o),e(Os,g4o),e(Os,Pj),e(Pj,h4o),e(Os,u4o),e(Os,Bj),e(Bj,p4o),e(Os,_4o),e(k,v4o),e(k,Vs),e(Vs,Sme),e(Sme,b4o),e(Vs,F4o),e(Vs,Ij),e(Ij,T4o),e(Vs,M4o),e(Vs,Nj),e(Nj,E4o),e(Vs,C4o),e(k,w4o),e(k,Xs),e(Xs,Rme),e(Rme,A4o),e(Xs,L4o),e(Xs,qj),e(qj,y4o),e(Xs,x4o),e(Xs,jj),e(jj,$4o),e(Xs,k4o),e(k,S4o),e(k,zs),e(zs,Pme),e(Pme,R4o),e(zs,P4o),e(zs,Dj),e(Dj,B4o),e(zs,I4o),e(zs,Gj),e(Gj,N4o),e(zs,q4o),e(k,j4o),e(k,Qs),e(Qs,Bme),e(Bme,D4o),e(Qs,G4o),e(Qs,Oj),e(Oj,O4o),e(Qs,V4o),e(Qs,Vj),e(Vj,X4o),e(Qs,z4o),e(k,Q4o),e(k,Ws),e(Ws,Ime),e(Ime,W4o),e(Ws,U4o),e(Ws,Xj),e(Xj,H4o),e(Ws,J4o),e(Ws,zj),e(zj,Y4o),e(Ws,K4o),e(k,Z4o),e(k,Us),e(Us,Nme),e(Nme,ebo),e(Us,obo),e(Us,Qj),e(Qj,rbo),e(Us,tbo),e(Us,Wj),e(Wj,abo),e(Us,nbo),e(k,sbo),e(k,Hs),e(Hs,qme),e(qme,lbo),e(Hs,ibo),e(Hs,Uj),e(Uj,dbo),e(Hs,cbo),e(Hs,Hj),e(Hj,fbo),e(Hs,mbo),e(k,gbo),e(k,mu),e(mu,jme),e(jme,hbo),e(mu,ubo),e(mu,Jj),e(Jj,pbo),e(mu,_bo),e(k,vbo),e(k,Js),e(Js,Dme),e(Dme,bbo),e(Js,Fbo),e(Js,Yj),e(Yj,Tbo),e(Js,Mbo),e(Js,Kj),e(Kj,Ebo),e(Js,Cbo),e(k,wbo),e(k,Ys),e(Ys,Gme),e(Gme,Abo),e(Ys,Lbo),e(Ys,Zj),e(Zj,ybo),e(Ys,xbo),e(Ys,eD),e(eD,$bo),e(Ys,kbo),e(k,Sbo),e(k,gu),e(gu,Ome),e(Ome,Rbo),e(gu,Pbo),e(gu,oD),e(oD,Bbo),e(gu,Ibo),e(k,Nbo),e(k,hu),e(hu,Vme),e(Vme,qbo),e(hu,jbo),e(hu,rD),e(rD,Dbo),e(hu,Gbo),e(k,Obo),e(k,uu),e(uu,Xme),e(Xme,Vbo),e(uu,Xbo),e(uu,tD),e(tD,zbo),e(uu,Qbo),e(k,Wbo),e(k,pu),e(pu,zme),e(zme,Ubo),e(pu,Hbo),e(pu,aD),e(aD,Jbo),e(pu,Ybo),e(k,Kbo),e(k,Ks),e(Ks,Qme),e(Qme,Zbo),e(Ks,eFo),e(Ks,nD),e(nD,oFo),e(Ks,rFo),e(Ks,sD),e(sD,tFo),e(Ks,aFo),e(k,nFo),e(k,_u),e(_u,Wme),e(Wme,sFo),e(_u,lFo),e(_u,lD),e(lD,iFo),e(_u,dFo),e(k,cFo),e(k,Zs),e(Zs,Ume),e(Ume,fFo),e(Zs,mFo),e(Zs,iD),e(iD,gFo),e(Zs,hFo),e(Zs,dD),e(dD,uFo),e(Zs,pFo),e(k,_Fo),e(k,el),e(el,Hme),e(Hme,vFo),e(el,bFo),e(el,cD),e(cD,FFo),e(el,TFo),e(el,fD),e(fD,MFo),e(el,EFo),e(k,CFo),e(k,ol),e(ol,Jme),e(Jme,wFo),e(ol,AFo),e(ol,mD),e(mD,LFo),e(ol,yFo),e(ol,gD),e(gD,xFo),e(ol,$Fo),e(k,kFo),e(k,rl),e(rl,Yme),e(Yme,SFo),e(rl,RFo),e(rl,hD),e(hD,PFo),e(rl,BFo),e(rl,uD),e(uD,IFo),e(rl,NFo),e(k,qFo),e(k,tl),e(tl,Kme),e(Kme,jFo),e(tl,DFo),e(tl,pD),e(pD,GFo),e(tl,OFo),e(tl,_D),e(_D,VFo),e(tl,XFo),e(k,zFo),e(k,al),e(al,Zme),e(Zme,QFo),e(al,WFo),e(al,vD),e(vD,UFo),e(al,HFo),e(al,bD),e(bD,JFo),e(al,YFo),e(k,KFo),e(k,vu),e(vu,ege),e(ege,ZFo),e(vu,eTo),e(vu,FD),e(FD,oTo),e(vu,rTo),e(k,tTo),e(k,bu),e(bu,oge),e(oge,aTo),e(bu,nTo),e(bu,TD),e(TD,sTo),e(bu,lTo),e(k,iTo),e(k,nl),e(nl,rge),e(rge,dTo),e(nl,cTo),e(nl,MD),e(MD,fTo),e(nl,mTo),e(nl,ED),e(ED,gTo),e(nl,hTo),e(k,uTo),e(k,sl),e(sl,tge),e(tge,pTo),e(sl,_To),e(sl,CD),e(CD,vTo),e(sl,bTo),e(sl,wD),e(wD,FTo),e(sl,TTo),e(k,MTo),e(k,ll),e(ll,age),e(age,ETo),e(ll,CTo),e(ll,AD),e(AD,wTo),e(ll,ATo),e(ll,LD),e(LD,LTo),e(ll,yTo),e(k,xTo),e(k,Fu),e(Fu,nge),e(nge,$To),e(Fu,kTo),e(Fu,yD),e(yD,STo),e(Fu,RTo),e(k,PTo),e(k,Tu),e(Tu,sge),e(sge,BTo),e(Tu,ITo),e(Tu,xD),e(xD,NTo),e(Tu,qTo),e(k,jTo),e(k,Mu),e(Mu,lge),e(lge,DTo),e(Mu,GTo),e(Mu,$D),e($D,OTo),e(Mu,VTo),e(k,XTo),e(k,il),e(il,ige),e(ige,zTo),e(il,QTo),e(il,kD),e(kD,WTo),e(il,UTo),e(il,SD),e(SD,HTo),e(il,JTo),e(k,YTo),e(k,dl),e(dl,dge),e(dge,KTo),e(dl,ZTo),e(dl,RD),e(RD,eMo),e(dl,oMo),e(dl,PD),e(PD,rMo),e(dl,tMo),e(k,aMo),e(k,Eu),e(Eu,cge),e(cge,nMo),e(Eu,sMo),e(Eu,BD),e(BD,lMo),e(Eu,iMo),e(k,dMo),e(k,Cu),e(Cu,fge),e(fge,cMo),e(Cu,fMo),e(Cu,ID),e(ID,mMo),e(Cu,gMo),e(k,hMo),e(k,wu),e(wu,mge),e(mge,uMo),e(wu,pMo),e(wu,ND),e(ND,_Mo),e(wu,vMo),e(k,bMo),e(k,cl),e(cl,gge),e(gge,FMo),e(cl,TMo),e(cl,qD),e(qD,MMo),e(cl,EMo),e(cl,jD),e(jD,CMo),e(cl,wMo),e(k,AMo),e(k,fl),e(fl,hge),e(hge,LMo),e(fl,yMo),e(fl,DD),e(DD,xMo),e(fl,$Mo),e(fl,GD),e(GD,kMo),e(fl,SMo),e(k,RMo),e(k,Au),e(Au,uge),e(uge,PMo),e(Au,BMo),e(Au,OD),e(OD,IMo),e(Au,NMo),e(k,qMo),e(k,Lu),e(Lu,pge),e(pge,jMo),e(Lu,DMo),e(Lu,VD),e(VD,GMo),e(Lu,OMo),e(k,VMo),e(k,ml),e(ml,_ge),e(_ge,XMo),e(ml,zMo),e(ml,XD),e(XD,QMo),e(ml,WMo),e(ml,zD),e(zD,UMo),e(ml,HMo),e(k,JMo),e(k,gl),e(gl,vge),e(vge,YMo),e(gl,KMo),e(gl,QD),e(QD,ZMo),e(gl,eEo),e(gl,WD),e(WD,oEo),e(gl,rEo),e(k,tEo),e(k,hl),e(hl,bge),e(bge,aEo),e(hl,nEo),e(hl,UD),e(UD,sEo),e(hl,lEo),e(hl,HD),e(HD,iEo),e(hl,dEo),e(k,cEo),e(k,ul),e(ul,Fge),e(Fge,fEo),e(ul,mEo),e(ul,JD),e(JD,gEo),e(ul,hEo),e(ul,YD),e(YD,uEo),e(ul,pEo),e(Br,_Eo),M(yu,Br,null),e(ko,vEo),e(ko,xu),M(I9,xu,null),e(xu,bEo),e(xu,Tge),e(Tge,FEo),v(f,DYe,_),v(f,gd,_),e(gd,$u),e($u,Mge),M(N9,Mge,null),e(gd,TEo),e(gd,Ege),e(Ege,MEo),v(f,GYe,_),v(f,So,_),M(q9,So,null),e(So,EEo),e(So,j9),e(j9,CEo),e(j9,KD),e(KD,wEo),e(j9,AEo),e(So,LEo),e(So,D9),e(D9,yEo),e(D9,Cge),e(Cge,xEo),e(D9,$Eo),e(So,kEo),e(So,Ye),M(G9,Ye,null),e(Ye,SEo),e(Ye,wge),e(wge,REo),e(Ye,PEo),e(Ye,Ha),e(Ha,BEo),e(Ha,Age),e(Age,IEo),e(Ha,NEo),e(Ha,Lge),e(Lge,qEo),e(Ha,jEo),e(Ha,yge),e(yge,DEo),e(Ha,GEo),e(Ye,OEo),e(Ye,W),e(W,ku),e(ku,xge),e(xge,VEo),e(ku,XEo),e(ku,ZD),e(ZD,zEo),e(ku,QEo),e(W,WEo),e(W,Su),e(Su,$ge),e($ge,UEo),e(Su,HEo),e(Su,eG),e(eG,JEo),e(Su,YEo),e(W,KEo),e(W,Ru),e(Ru,kge),e(kge,ZEo),e(Ru,eCo),e(Ru,oG),e(oG,oCo),e(Ru,rCo),e(W,tCo),e(W,Pu),e(Pu,Sge),e(Sge,aCo),e(Pu,nCo),e(Pu,rG),e(rG,sCo),e(Pu,lCo),e(W,iCo),e(W,Bu),e(Bu,Rge),e(Rge,dCo),e(Bu,cCo),e(Bu,tG),e(tG,fCo),e(Bu,mCo),e(W,gCo),e(W,Iu),e(Iu,Pge),e(Pge,hCo),e(Iu,uCo),e(Iu,aG),e(aG,pCo),e(Iu,_Co),e(W,vCo),e(W,Nu),e(Nu,Bge),e(Bge,bCo),e(Nu,FCo),e(Nu,nG),e(nG,TCo),e(Nu,MCo),e(W,ECo),e(W,qu),e(qu,Ige),e(Ige,CCo),e(qu,wCo),e(qu,sG),e(sG,ACo),e(qu,LCo),e(W,yCo),e(W,ju),e(ju,Nge),e(Nge,xCo),e(ju,$Co),e(ju,lG),e(lG,kCo),e(ju,SCo),e(W,RCo),e(W,Du),e(Du,qge),e(qge,PCo),e(Du,BCo),e(Du,iG),e(iG,ICo),e(Du,NCo),e(W,qCo),e(W,Gu),e(Gu,jge),e(jge,jCo),e(Gu,DCo),e(Gu,dG),e(dG,GCo),e(Gu,OCo),e(W,VCo),e(W,Ou),e(Ou,Dge),e(Dge,XCo),e(Ou,zCo),e(Ou,cG),e(cG,QCo),e(Ou,WCo),e(W,UCo),e(W,Vu),e(Vu,Gge),e(Gge,HCo),e(Vu,JCo),e(Vu,fG),e(fG,YCo),e(Vu,KCo),e(W,ZCo),e(W,Xu),e(Xu,Oge),e(Oge,e3o),e(Xu,o3o),e(Xu,mG),e(mG,r3o),e(Xu,t3o),e(W,a3o),e(W,zu),e(zu,Vge),e(Vge,n3o),e(zu,s3o),e(zu,gG),e(gG,l3o),e(zu,i3o),e(W,d3o),e(W,Qu),e(Qu,Xge),e(Xge,c3o),e(Qu,f3o),e(Qu,hG),e(hG,m3o),e(Qu,g3o),e(W,h3o),e(W,Wu),e(Wu,zge),e(zge,u3o),e(Wu,p3o),e(Wu,uG),e(uG,_3o),e(Wu,v3o),e(W,b3o),e(W,Uu),e(Uu,Qge),e(Qge,F3o),e(Uu,T3o),e(Uu,pG),e(pG,M3o),e(Uu,E3o),e(W,C3o),e(W,Hu),e(Hu,Wge),e(Wge,w3o),e(Hu,A3o),e(Hu,_G),e(_G,L3o),e(Hu,y3o),e(W,x3o),e(W,Ju),e(Ju,Uge),e(Uge,$3o),e(Ju,k3o),e(Ju,vG),e(vG,S3o),e(Ju,R3o),e(W,P3o),e(W,Yu),e(Yu,Hge),e(Hge,B3o),e(Yu,I3o),e(Yu,bG),e(bG,N3o),e(Yu,q3o),e(W,j3o),e(W,Ku),e(Ku,Jge),e(Jge,D3o),e(Ku,G3o),e(Ku,FG),e(FG,O3o),e(Ku,V3o),e(W,X3o),e(W,Zu),e(Zu,Yge),e(Yge,z3o),e(Zu,Q3o),e(Zu,TG),e(TG,W3o),e(Zu,U3o),e(W,H3o),e(W,ep),e(ep,Kge),e(Kge,J3o),e(ep,Y3o),e(ep,MG),e(MG,K3o),e(ep,Z3o),e(W,e5o),e(W,op),e(op,Zge),e(Zge,o5o),e(op,r5o),e(op,EG),e(EG,t5o),e(op,a5o),e(W,n5o),e(W,rp),e(rp,ehe),e(ehe,s5o),e(rp,l5o),e(rp,CG),e(CG,i5o),e(rp,d5o),e(W,c5o),e(W,tp),e(tp,ohe),e(ohe,f5o),e(tp,m5o),e(tp,wG),e(wG,g5o),e(tp,h5o),e(W,u5o),e(W,ap),e(ap,rhe),e(rhe,p5o),e(ap,_5o),e(ap,AG),e(AG,v5o),e(ap,b5o),e(W,F5o),e(W,np),e(np,the),e(the,T5o),e(np,M5o),e(np,LG),e(LG,E5o),e(np,C5o),e(W,w5o),e(W,sp),e(sp,ahe),e(ahe,A5o),e(sp,L5o),e(sp,yG),e(yG,y5o),e(sp,x5o),e(W,$5o),e(W,lp),e(lp,nhe),e(nhe,k5o),e(lp,S5o),e(lp,xG),e(xG,R5o),e(lp,P5o),e(W,B5o),e(W,ip),e(ip,she),e(she,I5o),e(ip,N5o),e(ip,$G),e($G,q5o),e(ip,j5o),e(W,D5o),e(W,dp),e(dp,lhe),e(lhe,G5o),e(dp,O5o),e(dp,kG),e(kG,V5o),e(dp,X5o),e(W,z5o),e(W,cp),e(cp,ihe),e(ihe,Q5o),e(cp,W5o),e(cp,SG),e(SG,U5o),e(cp,H5o),e(W,J5o),e(W,fp),e(fp,dhe),e(dhe,Y5o),e(fp,K5o),e(fp,RG),e(RG,Z5o),e(fp,e0o),e(W,o0o),e(W,mp),e(mp,che),e(che,r0o),e(mp,t0o),e(mp,PG),e(PG,a0o),e(mp,n0o),e(W,s0o),e(W,gp),e(gp,fhe),e(fhe,l0o),e(gp,i0o),e(gp,BG),e(BG,d0o),e(gp,c0o),e(W,f0o),e(W,hp),e(hp,mhe),e(mhe,m0o),e(hp,g0o),e(hp,IG),e(IG,h0o),e(hp,u0o),e(W,p0o),e(W,up),e(up,ghe),e(ghe,_0o),e(up,v0o),e(up,NG),e(NG,b0o),e(up,F0o),e(Ye,T0o),M(pp,Ye,null),e(Ye,M0o),M(_p,Ye,null),e(So,E0o),e(So,vp),M(O9,vp,null),e(vp,C0o),e(vp,hhe),e(hhe,w0o),v(f,OYe,_),v(f,hd,_),e(hd,bp),e(bp,uhe),M(V9,uhe,null),e(hd,A0o),e(hd,phe),e(phe,L0o),v(f,VYe,_),v(f,Ro,_),M(X9,Ro,null),e(Ro,y0o),e(Ro,z9),e(z9,x0o),e(z9,qG),e(qG,$0o),e(z9,k0o),e(Ro,S0o),e(Ro,Q9),e(Q9,R0o),e(Q9,_he),e(_he,P0o),e(Q9,B0o),e(Ro,I0o),e(Ro,Ke),M(W9,Ke,null),e(Ke,N0o),e(Ke,vhe),e(vhe,q0o),e(Ke,j0o),e(Ke,ud),e(ud,D0o),e(ud,bhe),e(bhe,G0o),e(ud,O0o),e(ud,Fhe),e(Fhe,V0o),e(ud,X0o),e(Ke,z0o),e(Ke,ie),e(ie,Fp),e(Fp,The),e(The,Q0o),e(Fp,W0o),e(Fp,jG),e(jG,U0o),e(Fp,H0o),e(ie,J0o),e(ie,Tp),e(Tp,Mhe),e(Mhe,Y0o),e(Tp,K0o),e(Tp,DG),e(DG,Z0o),e(Tp,ewo),e(ie,owo),e(ie,Mp),e(Mp,Ehe),e(Ehe,rwo),e(Mp,two),e(Mp,GG),e(GG,awo),e(Mp,nwo),e(ie,swo),e(ie,Ep),e(Ep,Che),e(Che,lwo),e(Ep,iwo),e(Ep,OG),e(OG,dwo),e(Ep,cwo),e(ie,fwo),e(ie,Cp),e(Cp,whe),e(whe,mwo),e(Cp,gwo),e(Cp,VG),e(VG,hwo),e(Cp,uwo),e(ie,pwo),e(ie,wp),e(wp,Ahe),e(Ahe,_wo),e(wp,vwo),e(wp,XG),e(XG,bwo),e(wp,Fwo),e(ie,Two),e(ie,Ap),e(Ap,Lhe),e(Lhe,Mwo),e(Ap,Ewo),e(Ap,zG),e(zG,Cwo),e(Ap,wwo),e(ie,Awo),e(ie,Lp),e(Lp,yhe),e(yhe,Lwo),e(Lp,ywo),e(Lp,QG),e(QG,xwo),e(Lp,$wo),e(ie,kwo),e(ie,yp),e(yp,xhe),e(xhe,Swo),e(yp,Rwo),e(yp,WG),e(WG,Pwo),e(yp,Bwo),e(ie,Iwo),e(ie,xp),e(xp,$he),e($he,Nwo),e(xp,qwo),e(xp,UG),e(UG,jwo),e(xp,Dwo),e(ie,Gwo),e(ie,$p),e($p,khe),e(khe,Owo),e($p,Vwo),e($p,HG),e(HG,Xwo),e($p,zwo),e(ie,Qwo),e(ie,kp),e(kp,She),e(She,Wwo),e(kp,Uwo),e(kp,JG),e(JG,Hwo),e(kp,Jwo),e(ie,Ywo),e(ie,Sp),e(Sp,Rhe),e(Rhe,Kwo),e(Sp,Zwo),e(Sp,YG),e(YG,eAo),e(Sp,oAo),e(ie,rAo),e(ie,Rp),e(Rp,Phe),e(Phe,tAo),e(Rp,aAo),e(Rp,KG),e(KG,nAo),e(Rp,sAo),e(ie,lAo),e(ie,Pp),e(Pp,Bhe),e(Bhe,iAo),e(Pp,dAo),e(Pp,ZG),e(ZG,cAo),e(Pp,fAo),e(ie,mAo),e(ie,Bp),e(Bp,Ihe),e(Ihe,gAo),e(Bp,hAo),e(Bp,eO),e(eO,uAo),e(Bp,pAo),e(ie,_Ao),e(ie,Ip),e(Ip,Nhe),e(Nhe,vAo),e(Ip,bAo),e(Ip,oO),e(oO,FAo),e(Ip,TAo),e(ie,MAo),e(ie,Np),e(Np,qhe),e(qhe,EAo),e(Np,CAo),e(Np,rO),e(rO,wAo),e(Np,AAo),e(ie,LAo),e(ie,qp),e(qp,jhe),e(jhe,yAo),e(qp,xAo),e(qp,tO),e(tO,$Ao),e(qp,kAo),e(ie,SAo),e(ie,jp),e(jp,Dhe),e(Dhe,RAo),e(jp,PAo),e(jp,aO),e(aO,BAo),e(jp,IAo),e(ie,NAo),e(ie,Dp),e(Dp,Ghe),e(Ghe,qAo),e(Dp,jAo),e(Dp,nO),e(nO,DAo),e(Dp,GAo),e(Ke,OAo),M(Gp,Ke,null),e(Ke,VAo),M(Op,Ke,null),e(Ro,XAo),e(Ro,Vp),M(U9,Vp,null),e(Vp,zAo),e(Vp,Ohe),e(Ohe,QAo),v(f,XYe,_),v(f,pd,_),e(pd,Xp),e(Xp,Vhe),M(H9,Vhe,null),e(pd,WAo),e(pd,Xhe),e(Xhe,UAo),v(f,zYe,_),v(f,Po,_),M(J9,Po,null),e(Po,HAo),e(Po,_d),e(_d,JAo),e(_d,sO),e(sO,YAo),e(_d,KAo),e(_d,lO),e(lO,ZAo),e(_d,e6o),e(Po,o6o),e(Po,Y9),e(Y9,r6o),e(Y9,zhe),e(zhe,t6o),e(Y9,a6o),e(Po,n6o),e(Po,_t),M(K9,_t,null),e(_t,s6o),e(_t,Qhe),e(Qhe,l6o),e(_t,i6o),e(_t,vd),e(vd,d6o),e(vd,Whe),e(Whe,c6o),e(vd,f6o),e(vd,iO),e(iO,m6o),e(vd,g6o),e(_t,h6o),M(zp,_t,null),e(Po,u6o),e(Po,Ze),M(Z9,Ze,null),e(Ze,p6o),e(Ze,Uhe),e(Uhe,_6o),e(Ze,v6o),e(Ze,Ja),e(Ja,b6o),e(Ja,Hhe),e(Hhe,F6o),e(Ja,T6o),e(Ja,Jhe),e(Jhe,M6o),e(Ja,E6o),e(Ja,Yhe),e(Yhe,C6o),e(Ja,w6o),e(Ze,A6o),e(Ze,y),e(y,Qp),e(Qp,Khe),e(Khe,L6o),e(Qp,y6o),e(Qp,dO),e(dO,x6o),e(Qp,$6o),e(y,k6o),e(y,Wp),e(Wp,Zhe),e(Zhe,S6o),e(Wp,R6o),e(Wp,cO),e(cO,P6o),e(Wp,B6o),e(y,I6o),e(y,Up),e(Up,eue),e(eue,N6o),e(Up,q6o),e(Up,fO),e(fO,j6o),e(Up,D6o),e(y,G6o),e(y,Hp),e(Hp,oue),e(oue,O6o),e(Hp,V6o),e(Hp,mO),e(mO,X6o),e(Hp,z6o),e(y,Q6o),e(y,Jp),e(Jp,rue),e(rue,W6o),e(Jp,U6o),e(Jp,gO),e(gO,H6o),e(Jp,J6o),e(y,Y6o),e(y,Yp),e(Yp,tue),e(tue,K6o),e(Yp,Z6o),e(Yp,hO),e(hO,e7o),e(Yp,o7o),e(y,r7o),e(y,Kp),e(Kp,aue),e(aue,t7o),e(Kp,a7o),e(Kp,uO),e(uO,n7o),e(Kp,s7o),e(y,l7o),e(y,Zp),e(Zp,nue),e(nue,i7o),e(Zp,d7o),e(Zp,pO),e(pO,c7o),e(Zp,f7o),e(y,m7o),e(y,e_),e(e_,sue),e(sue,g7o),e(e_,h7o),e(e_,_O),e(_O,u7o),e(e_,p7o),e(y,_7o),e(y,o_),e(o_,lue),e(lue,v7o),e(o_,b7o),e(o_,vO),e(vO,F7o),e(o_,T7o),e(y,M7o),e(y,r_),e(r_,iue),e(iue,E7o),e(r_,C7o),e(r_,bO),e(bO,w7o),e(r_,A7o),e(y,L7o),e(y,t_),e(t_,due),e(due,y7o),e(t_,x7o),e(t_,FO),e(FO,$7o),e(t_,k7o),e(y,S7o),e(y,a_),e(a_,cue),e(cue,R7o),e(a_,P7o),e(a_,TO),e(TO,B7o),e(a_,I7o),e(y,N7o),e(y,n_),e(n_,fue),e(fue,q7o),e(n_,j7o),e(n_,MO),e(MO,D7o),e(n_,G7o),e(y,O7o),e(y,s_),e(s_,mue),e(mue,V7o),e(s_,X7o),e(s_,EO),e(EO,z7o),e(s_,Q7o),e(y,W7o),e(y,l_),e(l_,gue),e(gue,U7o),e(l_,H7o),e(l_,CO),e(CO,J7o),e(l_,Y7o),e(y,K7o),e(y,i_),e(i_,hue),e(hue,Z7o),e(i_,eLo),e(i_,wO),e(wO,oLo),e(i_,rLo),e(y,tLo),e(y,d_),e(d_,uue),e(uue,aLo),e(d_,nLo),e(d_,AO),e(AO,sLo),e(d_,lLo),e(y,iLo),e(y,c_),e(c_,pue),e(pue,dLo),e(c_,cLo),e(c_,LO),e(LO,fLo),e(c_,mLo),e(y,gLo),e(y,f_),e(f_,_ue),e(_ue,hLo),e(f_,uLo),e(f_,yO),e(yO,pLo),e(f_,_Lo),e(y,vLo),e(y,m_),e(m_,vue),e(vue,bLo),e(m_,FLo),e(m_,xO),e(xO,TLo),e(m_,MLo),e(y,ELo),e(y,g_),e(g_,bue),e(bue,CLo),e(g_,wLo),e(g_,$O),e($O,ALo),e(g_,LLo),e(y,yLo),e(y,h_),e(h_,Fue),e(Fue,xLo),e(h_,$Lo),e(h_,kO),e(kO,kLo),e(h_,SLo),e(y,RLo),e(y,u_),e(u_,Tue),e(Tue,PLo),e(u_,BLo),e(u_,SO),e(SO,ILo),e(u_,NLo),e(y,qLo),e(y,p_),e(p_,Mue),e(Mue,jLo),e(p_,DLo),e(p_,RO),e(RO,GLo),e(p_,OLo),e(y,VLo),e(y,__),e(__,Eue),e(Eue,XLo),e(__,zLo),e(__,PO),e(PO,QLo),e(__,WLo),e(y,ULo),e(y,v_),e(v_,Cue),e(Cue,HLo),e(v_,JLo),e(v_,BO),e(BO,YLo),e(v_,KLo),e(y,ZLo),e(y,b_),e(b_,wue),e(wue,eyo),e(b_,oyo),e(b_,IO),e(IO,ryo),e(b_,tyo),e(y,ayo),e(y,F_),e(F_,Aue),e(Aue,nyo),e(F_,syo),e(F_,NO),e(NO,lyo),e(F_,iyo),e(y,dyo),e(y,T_),e(T_,Lue),e(Lue,cyo),e(T_,fyo),e(T_,qO),e(qO,myo),e(T_,gyo),e(y,hyo),e(y,M_),e(M_,yue),e(yue,uyo),e(M_,pyo),e(M_,jO),e(jO,_yo),e(M_,vyo),e(y,byo),e(y,E_),e(E_,xue),e(xue,Fyo),e(E_,Tyo),e(E_,DO),e(DO,Myo),e(E_,Eyo),e(y,Cyo),e(y,C_),e(C_,$ue),e($ue,wyo),e(C_,Ayo),e(C_,GO),e(GO,Lyo),e(C_,yyo),e(y,xyo),e(y,w_),e(w_,kue),e(kue,$yo),e(w_,kyo),e(w_,OO),e(OO,Syo),e(w_,Ryo),e(y,Pyo),e(y,A_),e(A_,Sue),e(Sue,Byo),e(A_,Iyo),e(A_,VO),e(VO,Nyo),e(A_,qyo),e(y,jyo),e(y,L_),e(L_,Rue),e(Rue,Dyo),e(L_,Gyo),e(L_,XO),e(XO,Oyo),e(L_,Vyo),e(y,Xyo),e(y,pl),e(pl,Pue),e(Pue,zyo),e(pl,Qyo),e(pl,zO),e(zO,Wyo),e(pl,Uyo),e(pl,QO),e(QO,Hyo),e(pl,Jyo),e(y,Yyo),e(y,y_),e(y_,Bue),e(Bue,Kyo),e(y_,Zyo),e(y_,WO),e(WO,e8o),e(y_,o8o),e(y,r8o),e(y,x_),e(x_,Iue),e(Iue,t8o),e(x_,a8o),e(x_,UO),e(UO,n8o),e(x_,s8o),e(y,l8o),e(y,$_),e($_,Nue),e(Nue,i8o),e($_,d8o),e($_,HO),e(HO,c8o),e($_,f8o),e(y,m8o),e(y,k_),e(k_,que),e(que,g8o),e(k_,h8o),e(k_,JO),e(JO,u8o),e(k_,p8o),e(y,_8o),e(y,S_),e(S_,jue),e(jue,v8o),e(S_,b8o),e(S_,YO),e(YO,F8o),e(S_,T8o),e(y,M8o),e(y,R_),e(R_,Due),e(Due,E8o),e(R_,C8o),e(R_,KO),e(KO,w8o),e(R_,A8o),e(y,L8o),e(y,P_),e(P_,Gue),e(Gue,y8o),e(P_,x8o),e(P_,ZO),e(ZO,$8o),e(P_,k8o),e(y,S8o),e(y,B_),e(B_,Oue),e(Oue,R8o),e(B_,P8o),e(B_,eV),e(eV,B8o),e(B_,I8o),e(y,N8o),e(y,I_),e(I_,Vue),e(Vue,q8o),e(I_,j8o),e(I_,oV),e(oV,D8o),e(I_,G8o),e(y,O8o),e(y,N_),e(N_,Xue),e(Xue,V8o),e(N_,X8o),e(N_,rV),e(rV,z8o),e(N_,Q8o),e(y,W8o),e(y,q_),e(q_,zue),e(zue,U8o),e(q_,H8o),e(q_,tV),e(tV,J8o),e(q_,Y8o),e(y,K8o),e(y,j_),e(j_,Que),e(Que,Z8o),e(j_,e9o),e(j_,aV),e(aV,o9o),e(j_,r9o),e(y,t9o),e(y,D_),e(D_,Wue),e(Wue,a9o),e(D_,n9o),e(D_,nV),e(nV,s9o),e(D_,l9o),e(y,i9o),e(y,G_),e(G_,Uue),e(Uue,d9o),e(G_,c9o),e(G_,sV),e(sV,f9o),e(G_,m9o),e(y,g9o),e(y,O_),e(O_,Hue),e(Hue,h9o),e(O_,u9o),e(O_,lV),e(lV,p9o),e(O_,_9o),e(y,v9o),e(y,V_),e(V_,Jue),e(Jue,b9o),e(V_,F9o),e(V_,iV),e(iV,T9o),e(V_,M9o),e(y,E9o),e(y,X_),e(X_,Yue),e(Yue,C9o),e(X_,w9o),e(X_,dV),e(dV,A9o),e(X_,L9o),e(y,y9o),e(y,z_),e(z_,Kue),e(Kue,x9o),e(z_,$9o),e(z_,cV),e(cV,k9o),e(z_,S9o),e(y,R9o),e(y,Q_),e(Q_,Zue),e(Zue,P9o),e(Q_,B9o),e(Q_,fV),e(fV,I9o),e(Q_,N9o),e(y,q9o),e(y,W_),e(W_,epe),e(epe,j9o),e(W_,D9o),e(W_,mV),e(mV,G9o),e(W_,O9o),e(y,V9o),e(y,U_),e(U_,ope),e(ope,X9o),e(U_,z9o),e(U_,gV),e(gV,Q9o),e(U_,W9o),e(y,U9o),e(y,H_),e(H_,rpe),e(rpe,H9o),e(H_,J9o),e(H_,hV),e(hV,Y9o),e(H_,K9o),e(y,Z9o),e(y,J_),e(J_,tpe),e(tpe,exo),e(J_,oxo),e(J_,uV),e(uV,rxo),e(J_,txo),e(y,axo),e(y,Y_),e(Y_,ape),e(ape,nxo),e(Y_,sxo),e(Y_,pV),e(pV,lxo),e(Y_,ixo),e(y,dxo),e(y,K_),e(K_,npe),e(npe,cxo),e(K_,fxo),e(K_,_V),e(_V,mxo),e(K_,gxo),e(y,hxo),e(y,Z_),e(Z_,spe),e(spe,uxo),e(Z_,pxo),e(Z_,vV),e(vV,_xo),e(Z_,vxo),e(y,bxo),e(y,e2),e(e2,lpe),e(lpe,Fxo),e(e2,Txo),e(e2,bV),e(bV,Mxo),e(e2,Exo),e(y,Cxo),e(y,o2),e(o2,ipe),e(ipe,wxo),e(o2,Axo),e(o2,FV),e(FV,Lxo),e(o2,yxo),e(y,xxo),e(y,r2),e(r2,dpe),e(dpe,$xo),e(r2,kxo),e(r2,TV),e(TV,Sxo),e(r2,Rxo),e(y,Pxo),e(y,t2),e(t2,cpe),e(cpe,Bxo),e(t2,Ixo),e(t2,MV),e(MV,Nxo),e(t2,qxo),e(y,jxo),e(y,a2),e(a2,fpe),e(fpe,Dxo),e(a2,Gxo),e(a2,EV),e(EV,Oxo),e(a2,Vxo),e(y,Xxo),e(y,n2),e(n2,mpe),e(mpe,zxo),e(n2,Qxo),e(n2,CV),e(CV,Wxo),e(n2,Uxo),e(y,Hxo),e(y,s2),e(s2,gpe),e(gpe,Jxo),e(s2,Yxo),e(s2,wV),e(wV,Kxo),e(s2,Zxo),e(y,e$o),e(y,l2),e(l2,hpe),e(hpe,o$o),e(l2,r$o),e(l2,AV),e(AV,t$o),e(l2,a$o),e(y,n$o),e(y,i2),e(i2,upe),e(upe,s$o),e(i2,l$o),e(i2,LV),e(LV,i$o),e(i2,d$o),e(y,c$o),e(y,d2),e(d2,ppe),e(ppe,f$o),e(d2,m$o),e(d2,yV),e(yV,g$o),e(d2,h$o),e(y,u$o),e(y,c2),e(c2,_pe),e(_pe,p$o),e(c2,_$o),e(c2,xV),e(xV,v$o),e(c2,b$o),e(y,F$o),e(y,f2),e(f2,vpe),e(vpe,T$o),e(f2,M$o),e(f2,$V),e($V,E$o),e(f2,C$o),e(y,w$o),e(y,m2),e(m2,bpe),e(bpe,A$o),e(m2,L$o),e(m2,kV),e(kV,y$o),e(m2,x$o),e(y,$$o),e(y,g2),e(g2,Fpe),e(Fpe,k$o),e(g2,S$o),e(g2,SV),e(SV,R$o),e(g2,P$o),e(y,B$o),e(y,h2),e(h2,Tpe),e(Tpe,I$o),e(h2,N$o),e(h2,RV),e(RV,q$o),e(h2,j$o),e(y,D$o),e(y,u2),e(u2,Mpe),e(Mpe,G$o),e(u2,O$o),e(u2,PV),e(PV,V$o),e(u2,X$o),e(y,z$o),e(y,p2),e(p2,Epe),e(Epe,Q$o),e(p2,W$o),e(p2,BV),e(BV,U$o),e(p2,H$o),e(y,J$o),e(y,_2),e(_2,Cpe),e(Cpe,Y$o),e(_2,K$o),e(_2,IV),e(IV,Z$o),e(_2,eko),e(y,oko),e(y,v2),e(v2,wpe),e(wpe,rko),e(v2,tko),e(v2,NV),e(NV,ako),e(v2,nko),e(y,sko),e(y,b2),e(b2,Ape),e(Ape,lko),e(b2,iko),e(b2,qV),e(qV,dko),e(b2,cko),e(y,fko),e(y,F2),e(F2,Lpe),e(Lpe,mko),e(F2,gko),e(F2,jV),e(jV,hko),e(F2,uko),e(y,pko),e(y,T2),e(T2,ype),e(ype,_ko),e(T2,vko),e(T2,DV),e(DV,bko),e(T2,Fko),e(y,Tko),e(y,M2),e(M2,xpe),e(xpe,Mko),e(M2,Eko),e(M2,GV),e(GV,Cko),e(M2,wko),e(y,Ako),e(y,E2),e(E2,$pe),e($pe,Lko),e(E2,yko),e(E2,OV),e(OV,xko),e(E2,$ko),e(y,kko),e(y,C2),e(C2,kpe),e(kpe,Sko),e(C2,Rko),e(C2,VV),e(VV,Pko),e(C2,Bko),e(y,Iko),e(y,w2),e(w2,Spe),e(Spe,Nko),e(w2,qko),e(w2,XV),e(XV,jko),e(w2,Dko),e(y,Gko),e(y,A2),e(A2,Rpe),e(Rpe,Oko),e(A2,Vko),e(A2,zV),e(zV,Xko),e(A2,zko),e(y,Qko),e(y,L2),e(L2,Ppe),e(Ppe,Wko),e(L2,Uko),e(L2,QV),e(QV,Hko),e(L2,Jko),e(y,Yko),e(y,y2),e(y2,Bpe),e(Bpe,Kko),e(y2,Zko),e(y2,WV),e(WV,eSo),e(y2,oSo),e(y,rSo),e(y,x2),e(x2,Ipe),e(Ipe,tSo),e(x2,aSo),e(x2,UV),e(UV,nSo),e(x2,sSo),e(y,lSo),e(y,$2),e($2,Npe),e(Npe,iSo),e($2,dSo),e($2,HV),e(HV,cSo),e($2,fSo),e(y,mSo),e(y,k2),e(k2,qpe),e(qpe,gSo),e(k2,hSo),e(k2,JV),e(JV,uSo),e(k2,pSo),e(y,_So),e(y,S2),e(S2,jpe),e(jpe,vSo),e(S2,bSo),e(S2,YV),e(YV,FSo),e(S2,TSo),e(y,MSo),e(y,R2),e(R2,Dpe),e(Dpe,ESo),e(R2,CSo),e(R2,KV),e(KV,wSo),e(R2,ASo),e(y,LSo),e(y,P2),e(P2,Gpe),e(Gpe,ySo),e(P2,xSo),e(P2,ZV),e(ZV,$So),e(P2,kSo),e(y,SSo),e(y,B2),e(B2,Ope),e(Ope,RSo),e(B2,PSo),e(B2,eX),e(eX,BSo),e(B2,ISo),e(y,NSo),e(y,I2),e(I2,Vpe),e(Vpe,qSo),e(I2,jSo),e(I2,oX),e(oX,DSo),e(I2,GSo),e(y,OSo),e(y,N2),e(N2,Xpe),e(Xpe,VSo),e(N2,XSo),e(N2,rX),e(rX,zSo),e(N2,QSo),e(y,WSo),e(y,q2),e(q2,zpe),e(zpe,USo),e(q2,HSo),e(q2,tX),e(tX,JSo),e(q2,YSo),e(y,KSo),e(y,j2),e(j2,Qpe),e(Qpe,ZSo),e(j2,eRo),e(j2,aX),e(aX,oRo),e(j2,rRo),e(y,tRo),e(y,D2),e(D2,Wpe),e(Wpe,aRo),e(D2,nRo),e(D2,nX),e(nX,sRo),e(D2,lRo),e(y,iRo),e(y,G2),e(G2,Upe),e(Upe,dRo),e(G2,cRo),e(G2,sX),e(sX,fRo),e(G2,mRo),e(y,gRo),e(y,O2),e(O2,Hpe),e(Hpe,hRo),e(O2,uRo),e(O2,lX),e(lX,pRo),e(O2,_Ro),e(y,vRo),e(y,V2),e(V2,Jpe),e(Jpe,bRo),e(V2,FRo),e(V2,iX),e(iX,TRo),e(V2,MRo),e(y,ERo),e(y,X2),e(X2,Ype),e(Ype,CRo),e(X2,wRo),e(X2,dX),e(dX,ARo),e(X2,LRo),e(y,yRo),e(y,z2),e(z2,Kpe),e(Kpe,xRo),e(z2,$Ro),e(z2,cX),e(cX,kRo),e(z2,SRo),e(y,RRo),e(y,Q2),e(Q2,Zpe),e(Zpe,PRo),e(Q2,BRo),e(Q2,fX),e(fX,IRo),e(Q2,NRo),e(y,qRo),e(y,W2),e(W2,e_e),e(e_e,jRo),e(W2,DRo),e(W2,mX),e(mX,GRo),e(W2,ORo),e(y,VRo),e(y,U2),e(U2,o_e),e(o_e,XRo),e(U2,zRo),e(U2,gX),e(gX,QRo),e(U2,WRo),e(y,URo),e(y,H2),e(H2,r_e),e(r_e,HRo),e(H2,JRo),e(H2,hX),e(hX,YRo),e(H2,KRo),e(y,ZRo),e(y,J2),e(J2,t_e),e(t_e,ePo),e(J2,oPo),e(J2,uX),e(uX,rPo),e(J2,tPo),e(y,aPo),e(y,Y2),e(Y2,a_e),e(a_e,nPo),e(Y2,sPo),e(Y2,pX),e(pX,lPo),e(Y2,iPo),e(y,dPo),e(y,K2),e(K2,n_e),e(n_e,cPo),e(K2,fPo),e(K2,_X),e(_X,mPo),e(K2,gPo),e(y,hPo),e(y,Z2),e(Z2,s_e),e(s_e,uPo),e(Z2,pPo),e(Z2,vX),e(vX,_Po),e(Z2,vPo),e(y,bPo),e(y,ev),e(ev,l_e),e(l_e,FPo),e(ev,TPo),e(ev,bX),e(bX,MPo),e(ev,EPo),e(y,CPo),e(y,ov),e(ov,i_e),e(i_e,wPo),e(ov,APo),e(ov,FX),e(FX,LPo),e(ov,yPo),e(Ze,xPo),e(Ze,rv),e(rv,$Po),e(rv,d_e),e(d_e,kPo),e(rv,SPo),e(rv,c_e),e(c_e,RPo),e(Ze,PPo),M(tv,Ze,null),v(f,QYe,_),v(f,bd,_),e(bd,av),e(av,f_e),M(ex,f_e,null),e(bd,BPo),e(bd,m_e),e(m_e,IPo),v(f,WYe,_),v(f,Bo,_),M(ox,Bo,null),e(Bo,NPo),e(Bo,Fd),e(Fd,qPo),e(Fd,TX),e(TX,jPo),e(Fd,DPo),e(Fd,MX),e(MX,GPo),e(Fd,OPo),e(Bo,VPo),e(Bo,rx),e(rx,XPo),e(rx,g_e),e(g_e,zPo),e(rx,QPo),e(Bo,WPo),e(Bo,vt),M(tx,vt,null),e(vt,UPo),e(vt,h_e),e(h_e,HPo),e(vt,JPo),e(vt,Td),e(Td,YPo),e(Td,u_e),e(u_e,KPo),e(Td,ZPo),e(Td,EX),e(EX,eBo),e(Td,oBo),e(vt,rBo),M(nv,vt,null),e(Bo,tBo),e(Bo,eo),M(ax,eo,null),e(eo,aBo),e(eo,p_e),e(p_e,nBo),e(eo,sBo),e(eo,Ya),e(Ya,lBo),e(Ya,__e),e(__e,iBo),e(Ya,dBo),e(Ya,v_e),e(v_e,cBo),e(Ya,fBo),e(Ya,b_e),e(b_e,mBo),e(Ya,gBo),e(eo,hBo),e(eo,G),e(G,sv),e(sv,F_e),e(F_e,uBo),e(sv,pBo),e(sv,CX),e(CX,_Bo),e(sv,vBo),e(G,bBo),e(G,lv),e(lv,T_e),e(T_e,FBo),e(lv,TBo),e(lv,wX),e(wX,MBo),e(lv,EBo),e(G,CBo),e(G,iv),e(iv,M_e),e(M_e,wBo),e(iv,ABo),e(iv,AX),e(AX,LBo),e(iv,yBo),e(G,xBo),e(G,dv),e(dv,E_e),e(E_e,$Bo),e(dv,kBo),e(dv,LX),e(LX,SBo),e(dv,RBo),e(G,PBo),e(G,cv),e(cv,C_e),e(C_e,BBo),e(cv,IBo),e(cv,yX),e(yX,NBo),e(cv,qBo),e(G,jBo),e(G,fv),e(fv,w_e),e(w_e,DBo),e(fv,GBo),e(fv,xX),e(xX,OBo),e(fv,VBo),e(G,XBo),e(G,mv),e(mv,A_e),e(A_e,zBo),e(mv,QBo),e(mv,$X),e($X,WBo),e(mv,UBo),e(G,HBo),e(G,gv),e(gv,L_e),e(L_e,JBo),e(gv,YBo),e(gv,kX),e(kX,KBo),e(gv,ZBo),e(G,eIo),e(G,hv),e(hv,y_e),e(y_e,oIo),e(hv,rIo),e(hv,SX),e(SX,tIo),e(hv,aIo),e(G,nIo),e(G,uv),e(uv,x_e),e(x_e,sIo),e(uv,lIo),e(uv,RX),e(RX,iIo),e(uv,dIo),e(G,cIo),e(G,pv),e(pv,$_e),e($_e,fIo),e(pv,mIo),e(pv,PX),e(PX,gIo),e(pv,hIo),e(G,uIo),e(G,_v),e(_v,k_e),e(k_e,pIo),e(_v,_Io),e(_v,BX),e(BX,vIo),e(_v,bIo),e(G,FIo),e(G,vv),e(vv,S_e),e(S_e,TIo),e(vv,MIo),e(vv,IX),e(IX,EIo),e(vv,CIo),e(G,wIo),e(G,bv),e(bv,R_e),e(R_e,AIo),e(bv,LIo),e(bv,NX),e(NX,yIo),e(bv,xIo),e(G,$Io),e(G,Fv),e(Fv,P_e),e(P_e,kIo),e(Fv,SIo),e(Fv,qX),e(qX,RIo),e(Fv,PIo),e(G,BIo),e(G,Tv),e(Tv,B_e),e(B_e,IIo),e(Tv,NIo),e(Tv,jX),e(jX,qIo),e(Tv,jIo),e(G,DIo),e(G,Mv),e(Mv,I_e),e(I_e,GIo),e(Mv,OIo),e(Mv,DX),e(DX,VIo),e(Mv,XIo),e(G,zIo),e(G,Ev),e(Ev,N_e),e(N_e,QIo),e(Ev,WIo),e(Ev,GX),e(GX,UIo),e(Ev,HIo),e(G,JIo),e(G,Cv),e(Cv,q_e),e(q_e,YIo),e(Cv,KIo),e(Cv,OX),e(OX,ZIo),e(Cv,eNo),e(G,oNo),e(G,wv),e(wv,j_e),e(j_e,rNo),e(wv,tNo),e(wv,VX),e(VX,aNo),e(wv,nNo),e(G,sNo),e(G,Av),e(Av,D_e),e(D_e,lNo),e(Av,iNo),e(Av,XX),e(XX,dNo),e(Av,cNo),e(G,fNo),e(G,Lv),e(Lv,G_e),e(G_e,mNo),e(Lv,gNo),e(Lv,zX),e(zX,hNo),e(Lv,uNo),e(G,pNo),e(G,yv),e(yv,O_e),e(O_e,_No),e(yv,vNo),e(yv,QX),e(QX,bNo),e(yv,FNo),e(G,TNo),e(G,xv),e(xv,V_e),e(V_e,MNo),e(xv,ENo),e(xv,WX),e(WX,CNo),e(xv,wNo),e(G,ANo),e(G,$v),e($v,X_e),e(X_e,LNo),e($v,yNo),e($v,UX),e(UX,xNo),e($v,$No),e(G,kNo),e(G,kv),e(kv,z_e),e(z_e,SNo),e(kv,RNo),e(kv,HX),e(HX,PNo),e(kv,BNo),e(G,INo),e(G,Sv),e(Sv,Q_e),e(Q_e,NNo),e(Sv,qNo),e(Sv,JX),e(JX,jNo),e(Sv,DNo),e(G,GNo),e(G,Rv),e(Rv,W_e),e(W_e,ONo),e(Rv,VNo),e(Rv,YX),e(YX,XNo),e(Rv,zNo),e(G,QNo),e(G,Pv),e(Pv,U_e),e(U_e,WNo),e(Pv,UNo),e(Pv,KX),e(KX,HNo),e(Pv,JNo),e(G,YNo),e(G,Bv),e(Bv,H_e),e(H_e,KNo),e(Bv,ZNo),e(Bv,ZX),e(ZX,eqo),e(Bv,oqo),e(G,rqo),e(G,Iv),e(Iv,J_e),e(J_e,tqo),e(Iv,aqo),e(Iv,ez),e(ez,nqo),e(Iv,sqo),e(G,lqo),e(G,Nv),e(Nv,Y_e),e(Y_e,iqo),e(Nv,dqo),e(Nv,oz),e(oz,cqo),e(Nv,fqo),e(G,mqo),e(G,qv),e(qv,K_e),e(K_e,gqo),e(qv,hqo),e(qv,rz),e(rz,uqo),e(qv,pqo),e(G,_qo),e(G,jv),e(jv,Z_e),e(Z_e,vqo),e(jv,bqo),e(jv,tz),e(tz,Fqo),e(jv,Tqo),e(G,Mqo),e(G,Dv),e(Dv,e2e),e(e2e,Eqo),e(Dv,Cqo),e(Dv,az),e(az,wqo),e(Dv,Aqo),e(G,Lqo),e(G,Gv),e(Gv,o2e),e(o2e,yqo),e(Gv,xqo),e(Gv,nz),e(nz,$qo),e(Gv,kqo),e(G,Sqo),e(G,Ov),e(Ov,r2e),e(r2e,Rqo),e(Ov,Pqo),e(Ov,sz),e(sz,Bqo),e(Ov,Iqo),e(G,Nqo),e(G,Vv),e(Vv,t2e),e(t2e,qqo),e(Vv,jqo),e(Vv,lz),e(lz,Dqo),e(Vv,Gqo),e(G,Oqo),e(G,Xv),e(Xv,a2e),e(a2e,Vqo),e(Xv,Xqo),e(Xv,iz),e(iz,zqo),e(Xv,Qqo),e(G,Wqo),e(G,zv),e(zv,n2e),e(n2e,Uqo),e(zv,Hqo),e(zv,dz),e(dz,Jqo),e(zv,Yqo),e(G,Kqo),e(G,Qv),e(Qv,s2e),e(s2e,Zqo),e(Qv,ejo),e(Qv,cz),e(cz,ojo),e(Qv,rjo),e(G,tjo),e(G,Wv),e(Wv,l2e),e(l2e,ajo),e(Wv,njo),e(Wv,fz),e(fz,sjo),e(Wv,ljo),e(G,ijo),e(G,Uv),e(Uv,i2e),e(i2e,djo),e(Uv,cjo),e(Uv,mz),e(mz,fjo),e(Uv,mjo),e(G,gjo),e(G,Hv),e(Hv,d2e),e(d2e,hjo),e(Hv,ujo),e(Hv,gz),e(gz,pjo),e(Hv,_jo),e(G,vjo),e(G,Jv),e(Jv,c2e),e(c2e,bjo),e(Jv,Fjo),e(Jv,hz),e(hz,Tjo),e(Jv,Mjo),e(G,Ejo),e(G,Yv),e(Yv,f2e),e(f2e,Cjo),e(Yv,wjo),e(Yv,uz),e(uz,Ajo),e(Yv,Ljo),e(G,yjo),e(G,Kv),e(Kv,m2e),e(m2e,xjo),e(Kv,$jo),e(Kv,pz),e(pz,kjo),e(Kv,Sjo),e(G,Rjo),e(G,Zv),e(Zv,g2e),e(g2e,Pjo),e(Zv,Bjo),e(Zv,_z),e(_z,Ijo),e(Zv,Njo),e(eo,qjo),e(eo,e1),e(e1,jjo),e(e1,h2e),e(h2e,Djo),e(e1,Gjo),e(e1,u2e),e(u2e,Ojo),e(eo,Vjo),M(o1,eo,null),v(f,UYe,_),v(f,Md,_),e(Md,r1),e(r1,p2e),M(nx,p2e,null),e(Md,Xjo),e(Md,_2e),e(_2e,zjo),v(f,HYe,_),v(f,Io,_),M(sx,Io,null),e(Io,Qjo),e(Io,Ed),e(Ed,Wjo),e(Ed,vz),e(vz,Ujo),e(Ed,Hjo),e(Ed,bz),e(bz,Jjo),e(Ed,Yjo),e(Io,Kjo),e(Io,lx),e(lx,Zjo),e(lx,v2e),e(v2e,eDo),e(lx,oDo),e(Io,rDo),e(Io,bt),M(ix,bt,null),e(bt,tDo),e(bt,b2e),e(b2e,aDo),e(bt,nDo),e(bt,Cd),e(Cd,sDo),e(Cd,F2e),e(F2e,lDo),e(Cd,iDo),e(Cd,Fz),e(Fz,dDo),e(Cd,cDo),e(bt,fDo),M(t1,bt,null),e(Io,mDo),e(Io,oo),M(dx,oo,null),e(oo,gDo),e(oo,T2e),e(T2e,hDo),e(oo,uDo),e(oo,Ka),e(Ka,pDo),e(Ka,M2e),e(M2e,_Do),e(Ka,vDo),e(Ka,E2e),e(E2e,bDo),e(Ka,FDo),e(Ka,C2e),e(C2e,TDo),e(Ka,MDo),e(oo,EDo),e(oo,z),e(z,a1),e(a1,w2e),e(w2e,CDo),e(a1,wDo),e(a1,Tz),e(Tz,ADo),e(a1,LDo),e(z,yDo),e(z,n1),e(n1,A2e),e(A2e,xDo),e(n1,$Do),e(n1,Mz),e(Mz,kDo),e(n1,SDo),e(z,RDo),e(z,s1),e(s1,L2e),e(L2e,PDo),e(s1,BDo),e(s1,Ez),e(Ez,IDo),e(s1,NDo),e(z,qDo),e(z,l1),e(l1,y2e),e(y2e,jDo),e(l1,DDo),e(l1,Cz),e(Cz,GDo),e(l1,ODo),e(z,VDo),e(z,i1),e(i1,x2e),e(x2e,XDo),e(i1,zDo),e(i1,wz),e(wz,QDo),e(i1,WDo),e(z,UDo),e(z,d1),e(d1,$2e),e($2e,HDo),e(d1,JDo),e(d1,Az),e(Az,YDo),e(d1,KDo),e(z,ZDo),e(z,c1),e(c1,k2e),e(k2e,eGo),e(c1,oGo),e(c1,Lz),e(Lz,rGo),e(c1,tGo),e(z,aGo),e(z,f1),e(f1,S2e),e(S2e,nGo),e(f1,sGo),e(f1,yz),e(yz,lGo),e(f1,iGo),e(z,dGo),e(z,m1),e(m1,R2e),e(R2e,cGo),e(m1,fGo),e(m1,xz),e(xz,mGo),e(m1,gGo),e(z,hGo),e(z,g1),e(g1,P2e),e(P2e,uGo),e(g1,pGo),e(g1,$z),e($z,_Go),e(g1,vGo),e(z,bGo),e(z,h1),e(h1,B2e),e(B2e,FGo),e(h1,TGo),e(h1,kz),e(kz,MGo),e(h1,EGo),e(z,CGo),e(z,u1),e(u1,I2e),e(I2e,wGo),e(u1,AGo),e(u1,Sz),e(Sz,LGo),e(u1,yGo),e(z,xGo),e(z,p1),e(p1,N2e),e(N2e,$Go),e(p1,kGo),e(p1,Rz),e(Rz,SGo),e(p1,RGo),e(z,PGo),e(z,_1),e(_1,q2e),e(q2e,BGo),e(_1,IGo),e(_1,Pz),e(Pz,NGo),e(_1,qGo),e(z,jGo),e(z,v1),e(v1,j2e),e(j2e,DGo),e(v1,GGo),e(v1,Bz),e(Bz,OGo),e(v1,VGo),e(z,XGo),e(z,b1),e(b1,D2e),e(D2e,zGo),e(b1,QGo),e(b1,Iz),e(Iz,WGo),e(b1,UGo),e(z,HGo),e(z,F1),e(F1,G2e),e(G2e,JGo),e(F1,YGo),e(F1,Nz),e(Nz,KGo),e(F1,ZGo),e(z,eOo),e(z,T1),e(T1,O2e),e(O2e,oOo),e(T1,rOo),e(T1,qz),e(qz,tOo),e(T1,aOo),e(z,nOo),e(z,M1),e(M1,V2e),e(V2e,sOo),e(M1,lOo),e(M1,jz),e(jz,iOo),e(M1,dOo),e(z,cOo),e(z,E1),e(E1,X2e),e(X2e,fOo),e(E1,mOo),e(E1,Dz),e(Dz,gOo),e(E1,hOo),e(z,uOo),e(z,C1),e(C1,z2e),e(z2e,pOo),e(C1,_Oo),e(C1,Gz),e(Gz,vOo),e(C1,bOo),e(z,FOo),e(z,w1),e(w1,Q2e),e(Q2e,TOo),e(w1,MOo),e(w1,Oz),e(Oz,EOo),e(w1,COo),e(z,wOo),e(z,A1),e(A1,W2e),e(W2e,AOo),e(A1,LOo),e(A1,Vz),e(Vz,yOo),e(A1,xOo),e(z,$Oo),e(z,L1),e(L1,U2e),e(U2e,kOo),e(L1,SOo),e(L1,Xz),e(Xz,ROo),e(L1,POo),e(z,BOo),e(z,y1),e(y1,H2e),e(H2e,IOo),e(y1,NOo),e(y1,zz),e(zz,qOo),e(y1,jOo),e(z,DOo),e(z,x1),e(x1,J2e),e(J2e,GOo),e(x1,OOo),e(x1,Qz),e(Qz,VOo),e(x1,XOo),e(z,zOo),e(z,$1),e($1,Y2e),e(Y2e,QOo),e($1,WOo),e($1,Wz),e(Wz,UOo),e($1,HOo),e(z,JOo),e(z,k1),e(k1,K2e),e(K2e,YOo),e(k1,KOo),e(k1,Uz),e(Uz,ZOo),e(k1,eVo),e(z,oVo),e(z,S1),e(S1,Z2e),e(Z2e,rVo),e(S1,tVo),e(S1,Hz),e(Hz,aVo),e(S1,nVo),e(z,sVo),e(z,R1),e(R1,eve),e(eve,lVo),e(R1,iVo),e(R1,Jz),e(Jz,dVo),e(R1,cVo),e(z,fVo),e(z,P1),e(P1,ove),e(ove,mVo),e(P1,gVo),e(P1,Yz),e(Yz,hVo),e(P1,uVo),e(z,pVo),e(z,B1),e(B1,rve),e(rve,_Vo),e(B1,vVo),e(B1,Kz),e(Kz,bVo),e(B1,FVo),e(z,TVo),e(z,I1),e(I1,tve),e(tve,MVo),e(I1,EVo),e(I1,Zz),e(Zz,CVo),e(I1,wVo),e(z,AVo),e(z,N1),e(N1,ave),e(ave,LVo),e(N1,yVo),e(N1,eQ),e(eQ,xVo),e(N1,$Vo),e(z,kVo),e(z,q1),e(q1,nve),e(nve,SVo),e(q1,RVo),e(q1,oQ),e(oQ,PVo),e(q1,BVo),e(z,IVo),e(z,j1),e(j1,sve),e(sve,NVo),e(j1,qVo),e(j1,rQ),e(rQ,jVo),e(j1,DVo),e(z,GVo),e(z,D1),e(D1,lve),e(lve,OVo),e(D1,VVo),e(D1,tQ),e(tQ,XVo),e(D1,zVo),e(z,QVo),e(z,G1),e(G1,ive),e(ive,WVo),e(G1,UVo),e(G1,aQ),e(aQ,HVo),e(G1,JVo),e(z,YVo),e(z,O1),e(O1,dve),e(dve,KVo),e(O1,ZVo),e(O1,nQ),e(nQ,eXo),e(O1,oXo),e(z,rXo),e(z,V1),e(V1,cve),e(cve,tXo),e(V1,aXo),e(V1,sQ),e(sQ,nXo),e(V1,sXo),e(z,lXo),e(z,X1),e(X1,fve),e(fve,iXo),e(X1,dXo),e(X1,lQ),e(lQ,cXo),e(X1,fXo),e(oo,mXo),e(oo,z1),e(z1,gXo),e(z1,mve),e(mve,hXo),e(z1,uXo),e(z1,gve),e(gve,pXo),e(oo,_Xo),M(Q1,oo,null),v(f,JYe,_),v(f,wd,_),e(wd,W1),e(W1,hve),M(cx,hve,null),e(wd,vXo),e(wd,uve),e(uve,bXo),v(f,YYe,_),v(f,No,_),M(fx,No,null),e(No,FXo),e(No,Ad),e(Ad,TXo),e(Ad,iQ),e(iQ,MXo),e(Ad,EXo),e(Ad,dQ),e(dQ,CXo),e(Ad,wXo),e(No,AXo),e(No,mx),e(mx,LXo),e(mx,pve),e(pve,yXo),e(mx,xXo),e(No,$Xo),e(No,Ft),M(gx,Ft,null),e(Ft,kXo),e(Ft,_ve),e(_ve,SXo),e(Ft,RXo),e(Ft,Ld),e(Ld,PXo),e(Ld,vve),e(vve,BXo),e(Ld,IXo),e(Ld,cQ),e(cQ,NXo),e(Ld,qXo),e(Ft,jXo),M(U1,Ft,null),e(No,DXo),e(No,ro),M(hx,ro,null),e(ro,GXo),e(ro,bve),e(bve,OXo),e(ro,VXo),e(ro,Za),e(Za,XXo),e(Za,Fve),e(Fve,zXo),e(Za,QXo),e(Za,Tve),e(Tve,WXo),e(Za,UXo),e(Za,Mve),e(Mve,HXo),e(Za,JXo),e(ro,YXo),e(ro,U),e(U,H1),e(H1,Eve),e(Eve,KXo),e(H1,ZXo),e(H1,fQ),e(fQ,ezo),e(H1,ozo),e(U,rzo),e(U,J1),e(J1,Cve),e(Cve,tzo),e(J1,azo),e(J1,mQ),e(mQ,nzo),e(J1,szo),e(U,lzo),e(U,Y1),e(Y1,wve),e(wve,izo),e(Y1,dzo),e(Y1,gQ),e(gQ,czo),e(Y1,fzo),e(U,mzo),e(U,K1),e(K1,Ave),e(Ave,gzo),e(K1,hzo),e(K1,hQ),e(hQ,uzo),e(K1,pzo),e(U,_zo),e(U,Z1),e(Z1,Lve),e(Lve,vzo),e(Z1,bzo),e(Z1,uQ),e(uQ,Fzo),e(Z1,Tzo),e(U,Mzo),e(U,e4),e(e4,yve),e(yve,Ezo),e(e4,Czo),e(e4,pQ),e(pQ,wzo),e(e4,Azo),e(U,Lzo),e(U,o4),e(o4,xve),e(xve,yzo),e(o4,xzo),e(o4,_Q),e(_Q,$zo),e(o4,kzo),e(U,Szo),e(U,r4),e(r4,$ve),e($ve,Rzo),e(r4,Pzo),e(r4,vQ),e(vQ,Bzo),e(r4,Izo),e(U,Nzo),e(U,t4),e(t4,kve),e(kve,qzo),e(t4,jzo),e(t4,bQ),e(bQ,Dzo),e(t4,Gzo),e(U,Ozo),e(U,a4),e(a4,Sve),e(Sve,Vzo),e(a4,Xzo),e(a4,FQ),e(FQ,zzo),e(a4,Qzo),e(U,Wzo),e(U,n4),e(n4,Rve),e(Rve,Uzo),e(n4,Hzo),e(n4,TQ),e(TQ,Jzo),e(n4,Yzo),e(U,Kzo),e(U,s4),e(s4,Pve),e(Pve,Zzo),e(s4,eQo),e(s4,MQ),e(MQ,oQo),e(s4,rQo),e(U,tQo),e(U,l4),e(l4,Bve),e(Bve,aQo),e(l4,nQo),e(l4,EQ),e(EQ,sQo),e(l4,lQo),e(U,iQo),e(U,i4),e(i4,Ive),e(Ive,dQo),e(i4,cQo),e(i4,CQ),e(CQ,fQo),e(i4,mQo),e(U,gQo),e(U,d4),e(d4,Nve),e(Nve,hQo),e(d4,uQo),e(d4,wQ),e(wQ,pQo),e(d4,_Qo),e(U,vQo),e(U,c4),e(c4,qve),e(qve,bQo),e(c4,FQo),e(c4,AQ),e(AQ,TQo),e(c4,MQo),e(U,EQo),e(U,f4),e(f4,jve),e(jve,CQo),e(f4,wQo),e(f4,LQ),e(LQ,AQo),e(f4,LQo),e(U,yQo),e(U,m4),e(m4,Dve),e(Dve,xQo),e(m4,$Qo),e(m4,yQ),e(yQ,kQo),e(m4,SQo),e(U,RQo),e(U,g4),e(g4,Gve),e(Gve,PQo),e(g4,BQo),e(g4,xQ),e(xQ,IQo),e(g4,NQo),e(U,qQo),e(U,h4),e(h4,Ove),e(Ove,jQo),e(h4,DQo),e(h4,$Q),e($Q,GQo),e(h4,OQo),e(U,VQo),e(U,u4),e(u4,Vve),e(Vve,XQo),e(u4,zQo),e(u4,kQ),e(kQ,QQo),e(u4,WQo),e(U,UQo),e(U,p4),e(p4,Xve),e(Xve,HQo),e(p4,JQo),e(p4,SQ),e(SQ,YQo),e(p4,KQo),e(U,ZQo),e(U,_4),e(_4,zve),e(zve,eWo),e(_4,oWo),e(_4,RQ),e(RQ,rWo),e(_4,tWo),e(U,aWo),e(U,v4),e(v4,Qve),e(Qve,nWo),e(v4,sWo),e(v4,PQ),e(PQ,lWo),e(v4,iWo),e(U,dWo),e(U,b4),e(b4,Wve),e(Wve,cWo),e(b4,fWo),e(b4,BQ),e(BQ,mWo),e(b4,gWo),e(U,hWo),e(U,F4),e(F4,Uve),e(Uve,uWo),e(F4,pWo),e(F4,IQ),e(IQ,_Wo),e(F4,vWo),e(U,bWo),e(U,T4),e(T4,Hve),e(Hve,FWo),e(T4,TWo),e(T4,NQ),e(NQ,MWo),e(T4,EWo),e(U,CWo),e(U,M4),e(M4,Jve),e(Jve,wWo),e(M4,AWo),e(M4,qQ),e(qQ,LWo),e(M4,yWo),e(U,xWo),e(U,E4),e(E4,Yve),e(Yve,$Wo),e(E4,kWo),e(E4,jQ),e(jQ,SWo),e(E4,RWo),e(U,PWo),e(U,C4),e(C4,Kve),e(Kve,BWo),e(C4,IWo),e(C4,DQ),e(DQ,NWo),e(C4,qWo),e(U,jWo),e(U,w4),e(w4,Zve),e(Zve,DWo),e(w4,GWo),e(w4,GQ),e(GQ,OWo),e(w4,VWo),e(U,XWo),e(U,A4),e(A4,e1e),e(e1e,zWo),e(A4,QWo),e(A4,OQ),e(OQ,WWo),e(A4,UWo),e(U,HWo),e(U,L4),e(L4,o1e),e(o1e,JWo),e(L4,YWo),e(L4,VQ),e(VQ,KWo),e(L4,ZWo),e(U,eUo),e(U,y4),e(y4,r1e),e(r1e,oUo),e(y4,rUo),e(y4,XQ),e(XQ,tUo),e(y4,aUo),e(U,nUo),e(U,x4),e(x4,t1e),e(t1e,sUo),e(x4,lUo),e(x4,a1e),e(a1e,iUo),e(x4,dUo),e(U,cUo),e(U,$4),e($4,n1e),e(n1e,fUo),e($4,mUo),e($4,zQ),e(zQ,gUo),e($4,hUo),e(U,uUo),e(U,k4),e(k4,s1e),e(s1e,pUo),e(k4,_Uo),e(k4,QQ),e(QQ,vUo),e(k4,bUo),e(U,FUo),e(U,S4),e(S4,l1e),e(l1e,TUo),e(S4,MUo),e(S4,WQ),e(WQ,EUo),e(S4,CUo),e(U,wUo),e(U,R4),e(R4,i1e),e(i1e,AUo),e(R4,LUo),e(R4,UQ),e(UQ,yUo),e(R4,xUo),e(ro,$Uo),e(ro,P4),e(P4,kUo),e(P4,d1e),e(d1e,SUo),e(P4,RUo),e(P4,c1e),e(c1e,PUo),e(ro,BUo),M(B4,ro,null),v(f,KYe,_),v(f,yd,_),e(yd,I4),e(I4,f1e),M(ux,f1e,null),e(yd,IUo),e(yd,m1e),e(m1e,NUo),v(f,ZYe,_),v(f,qo,_),M(px,qo,null),e(qo,qUo),e(qo,xd),e(xd,jUo),e(xd,HQ),e(HQ,DUo),e(xd,GUo),e(xd,JQ),e(JQ,OUo),e(xd,VUo),e(qo,XUo),e(qo,_x),e(_x,zUo),e(_x,g1e),e(g1e,QUo),e(_x,WUo),e(qo,UUo),e(qo,Tt),M(vx,Tt,null),e(Tt,HUo),e(Tt,h1e),e(h1e,JUo),e(Tt,YUo),e(Tt,$d),e($d,KUo),e($d,u1e),e(u1e,ZUo),e($d,eHo),e($d,YQ),e(YQ,oHo),e($d,rHo),e(Tt,tHo),M(N4,Tt,null),e(qo,aHo),e(qo,to),M(bx,to,null),e(to,nHo),e(to,p1e),e(p1e,sHo),e(to,lHo),e(to,en),e(en,iHo),e(en,_1e),e(_1e,dHo),e(en,cHo),e(en,v1e),e(v1e,fHo),e(en,mHo),e(en,b1e),e(b1e,gHo),e(en,hHo),e(to,uHo),e(to,fe),e(fe,q4),e(q4,F1e),e(F1e,pHo),e(q4,_Ho),e(q4,KQ),e(KQ,vHo),e(q4,bHo),e(fe,FHo),e(fe,j4),e(j4,T1e),e(T1e,THo),e(j4,MHo),e(j4,ZQ),e(ZQ,EHo),e(j4,CHo),e(fe,wHo),e(fe,D4),e(D4,M1e),e(M1e,AHo),e(D4,LHo),e(D4,eW),e(eW,yHo),e(D4,xHo),e(fe,$Ho),e(fe,G4),e(G4,E1e),e(E1e,kHo),e(G4,SHo),e(G4,oW),e(oW,RHo),e(G4,PHo),e(fe,BHo),e(fe,O4),e(O4,C1e),e(C1e,IHo),e(O4,NHo),e(O4,rW),e(rW,qHo),e(O4,jHo),e(fe,DHo),e(fe,V4),e(V4,w1e),e(w1e,GHo),e(V4,OHo),e(V4,tW),e(tW,VHo),e(V4,XHo),e(fe,zHo),e(fe,X4),e(X4,A1e),e(A1e,QHo),e(X4,WHo),e(X4,aW),e(aW,UHo),e(X4,HHo),e(fe,JHo),e(fe,z4),e(z4,L1e),e(L1e,YHo),e(z4,KHo),e(z4,nW),e(nW,ZHo),e(z4,eJo),e(fe,oJo),e(fe,Q4),e(Q4,y1e),e(y1e,rJo),e(Q4,tJo),e(Q4,sW),e(sW,aJo),e(Q4,nJo),e(fe,sJo),e(fe,W4),e(W4,x1e),e(x1e,lJo),e(W4,iJo),e(W4,lW),e(lW,dJo),e(W4,cJo),e(fe,fJo),e(fe,U4),e(U4,$1e),e($1e,mJo),e(U4,gJo),e(U4,iW),e(iW,hJo),e(U4,uJo),e(fe,pJo),e(fe,H4),e(H4,k1e),e(k1e,_Jo),e(H4,vJo),e(H4,dW),e(dW,bJo),e(H4,FJo),e(fe,TJo),e(fe,J4),e(J4,S1e),e(S1e,MJo),e(J4,EJo),e(J4,cW),e(cW,CJo),e(J4,wJo),e(fe,AJo),e(fe,Y4),e(Y4,R1e),e(R1e,LJo),e(Y4,yJo),e(Y4,fW),e(fW,xJo),e(Y4,$Jo),e(fe,kJo),e(fe,K4),e(K4,P1e),e(P1e,SJo),e(K4,RJo),e(K4,mW),e(mW,PJo),e(K4,BJo),e(fe,IJo),e(fe,Z4),e(Z4,B1e),e(B1e,NJo),e(Z4,qJo),e(Z4,gW),e(gW,jJo),e(Z4,DJo),e(fe,GJo),e(fe,eb),e(eb,I1e),e(I1e,OJo),e(eb,VJo),e(eb,hW),e(hW,XJo),e(eb,zJo),e(fe,QJo),e(fe,ob),e(ob,N1e),e(N1e,WJo),e(ob,UJo),e(ob,uW),e(uW,HJo),e(ob,JJo),e(fe,YJo),e(fe,rb),e(rb,q1e),e(q1e,KJo),e(rb,ZJo),e(rb,pW),e(pW,eYo),e(rb,oYo),e(fe,rYo),e(fe,tb),e(tb,j1e),e(j1e,tYo),e(tb,aYo),e(tb,_W),e(_W,nYo),e(tb,sYo),e(to,lYo),e(to,ab),e(ab,iYo),e(ab,D1e),e(D1e,dYo),e(ab,cYo),e(ab,G1e),e(G1e,fYo),e(to,mYo),M(nb,to,null),v(f,eKe,_),v(f,kd,_),e(kd,sb),e(sb,O1e),M(Fx,O1e,null),e(kd,gYo),e(kd,V1e),e(V1e,hYo),v(f,oKe,_),v(f,jo,_),M(Tx,jo,null),e(jo,uYo),e(jo,Sd),e(Sd,pYo),e(Sd,vW),e(vW,_Yo),e(Sd,vYo),e(Sd,bW),e(bW,bYo),e(Sd,FYo),e(jo,TYo),e(jo,Mx),e(Mx,MYo),e(Mx,X1e),e(X1e,EYo),e(Mx,CYo),e(jo,wYo),e(jo,Mt),M(Ex,Mt,null),e(Mt,AYo),e(Mt,z1e),e(z1e,LYo),e(Mt,yYo),e(Mt,Rd),e(Rd,xYo),e(Rd,Q1e),e(Q1e,$Yo),e(Rd,kYo),e(Rd,FW),e(FW,SYo),e(Rd,RYo),e(Mt,PYo),M(lb,Mt,null),e(jo,BYo),e(jo,ao),M(Cx,ao,null),e(ao,IYo),e(ao,W1e),e(W1e,NYo),e(ao,qYo),e(ao,on),e(on,jYo),e(on,U1e),e(U1e,DYo),e(on,GYo),e(on,H1e),e(H1e,OYo),e(on,VYo),e(on,J1e),e(J1e,XYo),e(on,zYo),e(ao,QYo),e(ao,q),e(q,ib),e(ib,Y1e),e(Y1e,WYo),e(ib,UYo),e(ib,TW),e(TW,HYo),e(ib,JYo),e(q,YYo),e(q,db),e(db,K1e),e(K1e,KYo),e(db,ZYo),e(db,MW),e(MW,eKo),e(db,oKo),e(q,rKo),e(q,cb),e(cb,Z1e),e(Z1e,tKo),e(cb,aKo),e(cb,EW),e(EW,nKo),e(cb,sKo),e(q,lKo),e(q,fb),e(fb,e4e),e(e4e,iKo),e(fb,dKo),e(fb,CW),e(CW,cKo),e(fb,fKo),e(q,mKo),e(q,mb),e(mb,o4e),e(o4e,gKo),e(mb,hKo),e(mb,wW),e(wW,uKo),e(mb,pKo),e(q,_Ko),e(q,gb),e(gb,r4e),e(r4e,vKo),e(gb,bKo),e(gb,AW),e(AW,FKo),e(gb,TKo),e(q,MKo),e(q,hb),e(hb,t4e),e(t4e,EKo),e(hb,CKo),e(hb,LW),e(LW,wKo),e(hb,AKo),e(q,LKo),e(q,ub),e(ub,a4e),e(a4e,yKo),e(ub,xKo),e(ub,yW),e(yW,$Ko),e(ub,kKo),e(q,SKo),e(q,pb),e(pb,n4e),e(n4e,RKo),e(pb,PKo),e(pb,xW),e(xW,BKo),e(pb,IKo),e(q,NKo),e(q,_b),e(_b,s4e),e(s4e,qKo),e(_b,jKo),e(_b,$W),e($W,DKo),e(_b,GKo),e(q,OKo),e(q,vb),e(vb,l4e),e(l4e,VKo),e(vb,XKo),e(vb,kW),e(kW,zKo),e(vb,QKo),e(q,WKo),e(q,bb),e(bb,i4e),e(i4e,UKo),e(bb,HKo),e(bb,SW),e(SW,JKo),e(bb,YKo),e(q,KKo),e(q,Fb),e(Fb,d4e),e(d4e,ZKo),e(Fb,eZo),e(Fb,RW),e(RW,oZo),e(Fb,rZo),e(q,tZo),e(q,Tb),e(Tb,c4e),e(c4e,aZo),e(Tb,nZo),e(Tb,PW),e(PW,sZo),e(Tb,lZo),e(q,iZo),e(q,Mb),e(Mb,f4e),e(f4e,dZo),e(Mb,cZo),e(Mb,BW),e(BW,fZo),e(Mb,mZo),e(q,gZo),e(q,Eb),e(Eb,m4e),e(m4e,hZo),e(Eb,uZo),e(Eb,IW),e(IW,pZo),e(Eb,_Zo),e(q,vZo),e(q,Cb),e(Cb,g4e),e(g4e,bZo),e(Cb,FZo),e(Cb,NW),e(NW,TZo),e(Cb,MZo),e(q,EZo),e(q,wb),e(wb,h4e),e(h4e,CZo),e(wb,wZo),e(wb,qW),e(qW,AZo),e(wb,LZo),e(q,yZo),e(q,Ab),e(Ab,u4e),e(u4e,xZo),e(Ab,$Zo),e(Ab,jW),e(jW,kZo),e(Ab,SZo),e(q,RZo),e(q,Lb),e(Lb,p4e),e(p4e,PZo),e(Lb,BZo),e(Lb,DW),e(DW,IZo),e(Lb,NZo),e(q,qZo),e(q,yb),e(yb,_4e),e(_4e,jZo),e(yb,DZo),e(yb,GW),e(GW,GZo),e(yb,OZo),e(q,VZo),e(q,xb),e(xb,v4e),e(v4e,XZo),e(xb,zZo),e(xb,OW),e(OW,QZo),e(xb,WZo),e(q,UZo),e(q,$b),e($b,b4e),e(b4e,HZo),e($b,JZo),e($b,VW),e(VW,YZo),e($b,KZo),e(q,ZZo),e(q,kb),e(kb,F4e),e(F4e,eer),e(kb,oer),e(kb,XW),e(XW,rer),e(kb,ter),e(q,aer),e(q,Sb),e(Sb,T4e),e(T4e,ner),e(Sb,ser),e(Sb,zW),e(zW,ler),e(Sb,ier),e(q,der),e(q,Rb),e(Rb,M4e),e(M4e,cer),e(Rb,fer),e(Rb,QW),e(QW,mer),e(Rb,ger),e(q,her),e(q,Pb),e(Pb,E4e),e(E4e,uer),e(Pb,per),e(Pb,WW),e(WW,_er),e(Pb,ver),e(q,ber),e(q,Bb),e(Bb,C4e),e(C4e,Fer),e(Bb,Ter),e(Bb,UW),e(UW,Mer),e(Bb,Eer),e(q,Cer),e(q,Ib),e(Ib,w4e),e(w4e,wer),e(Ib,Aer),e(Ib,HW),e(HW,Ler),e(Ib,yer),e(q,xer),e(q,Nb),e(Nb,A4e),e(A4e,$er),e(Nb,ker),e(Nb,JW),e(JW,Ser),e(Nb,Rer),e(q,Per),e(q,qb),e(qb,L4e),e(L4e,Ber),e(qb,Ier),e(qb,YW),e(YW,Ner),e(qb,qer),e(q,jer),e(q,jb),e(jb,y4e),e(y4e,Der),e(jb,Ger),e(jb,KW),e(KW,Oer),e(jb,Ver),e(q,Xer),e(q,Db),e(Db,x4e),e(x4e,zer),e(Db,Qer),e(Db,ZW),e(ZW,Wer),e(Db,Uer),e(q,Her),e(q,Gb),e(Gb,$4e),e($4e,Jer),e(Gb,Yer),e(Gb,eU),e(eU,Ker),e(Gb,Zer),e(q,eor),e(q,Ob),e(Ob,k4e),e(k4e,oor),e(Ob,ror),e(Ob,oU),e(oU,tor),e(Ob,aor),e(q,nor),e(q,Vb),e(Vb,S4e),e(S4e,sor),e(Vb,lor),e(Vb,rU),e(rU,ior),e(Vb,dor),e(q,cor),e(q,Xb),e(Xb,R4e),e(R4e,mor),e(Xb,gor),e(Xb,tU),e(tU,hor),e(Xb,uor),e(q,por),e(q,zb),e(zb,P4e),e(P4e,_or),e(zb,vor),e(zb,aU),e(aU,bor),e(zb,For),e(q,Tor),e(q,Qb),e(Qb,B4e),e(B4e,Mor),e(Qb,Eor),e(Qb,nU),e(nU,Cor),e(Qb,wor),e(q,Aor),e(q,Wb),e(Wb,I4e),e(I4e,Lor),e(Wb,yor),e(Wb,sU),e(sU,xor),e(Wb,$or),e(q,kor),e(q,Ub),e(Ub,N4e),e(N4e,Sor),e(Ub,Ror),e(Ub,lU),e(lU,Por),e(Ub,Bor),e(q,Ior),e(q,Hb),e(Hb,q4e),e(q4e,Nor),e(Hb,qor),e(Hb,iU),e(iU,jor),e(Hb,Dor),e(q,Gor),e(q,Jb),e(Jb,j4e),e(j4e,Oor),e(Jb,Vor),e(Jb,dU),e(dU,Xor),e(Jb,zor),e(q,Qor),e(q,Yb),e(Yb,D4e),e(D4e,Wor),e(Yb,Uor),e(Yb,cU),e(cU,Hor),e(Yb,Jor),e(q,Yor),e(q,Kb),e(Kb,G4e),e(G4e,Kor),e(Kb,Zor),e(Kb,fU),e(fU,err),e(Kb,orr),e(q,rrr),e(q,Zb),e(Zb,O4e),e(O4e,trr),e(Zb,arr),e(Zb,mU),e(mU,nrr),e(Zb,srr),e(q,lrr),e(q,eF),e(eF,V4e),e(V4e,irr),e(eF,drr),e(eF,gU),e(gU,crr),e(eF,frr),e(q,mrr),e(q,oF),e(oF,X4e),e(X4e,grr),e(oF,hrr),e(oF,hU),e(hU,urr),e(oF,prr),e(q,_rr),e(q,rF),e(rF,z4e),e(z4e,vrr),e(rF,brr),e(rF,uU),e(uU,Frr),e(rF,Trr),e(q,Mrr),e(q,tF),e(tF,Q4e),e(Q4e,Err),e(tF,Crr),e(tF,pU),e(pU,wrr),e(tF,Arr),e(q,Lrr),e(q,aF),e(aF,W4e),e(W4e,yrr),e(aF,xrr),e(aF,_U),e(_U,$rr),e(aF,krr),e(q,Srr),e(q,nF),e(nF,U4e),e(U4e,Rrr),e(nF,Prr),e(nF,vU),e(vU,Brr),e(nF,Irr),e(q,Nrr),e(q,sF),e(sF,H4e),e(H4e,qrr),e(sF,jrr),e(sF,bU),e(bU,Drr),e(sF,Grr),e(ao,Orr),e(ao,lF),e(lF,Vrr),e(lF,J4e),e(J4e,Xrr),e(lF,zrr),e(lF,Y4e),e(Y4e,Qrr),e(ao,Wrr),M(iF,ao,null),v(f,rKe,_),v(f,Pd,_),e(Pd,dF),e(dF,K4e),M(wx,K4e,null),e(Pd,Urr),e(Pd,Z4e),e(Z4e,Hrr),v(f,tKe,_),v(f,Do,_),M(Ax,Do,null),e(Do,Jrr),e(Do,Bd),e(Bd,Yrr),e(Bd,FU),e(FU,Krr),e(Bd,Zrr),e(Bd,TU),e(TU,etr),e(Bd,otr),e(Do,rtr),e(Do,Lx),e(Lx,ttr),e(Lx,ebe),e(ebe,atr),e(Lx,ntr),e(Do,str),e(Do,Et),M(yx,Et,null),e(Et,ltr),e(Et,obe),e(obe,itr),e(Et,dtr),e(Et,Id),e(Id,ctr),e(Id,rbe),e(rbe,ftr),e(Id,mtr),e(Id,MU),e(MU,gtr),e(Id,htr),e(Et,utr),M(cF,Et,null),e(Do,ptr),e(Do,no),M(xx,no,null),e(no,_tr),e(no,tbe),e(tbe,vtr),e(no,btr),e(no,rn),e(rn,Ftr),e(rn,abe),e(abe,Ttr),e(rn,Mtr),e(rn,nbe),e(nbe,Etr),e(rn,Ctr),e(rn,sbe),e(sbe,wtr),e(rn,Atr),e(no,Ltr),e(no,Z),e(Z,fF),e(fF,lbe),e(lbe,ytr),e(fF,xtr),e(fF,EU),e(EU,$tr),e(fF,ktr),e(Z,Str),e(Z,mF),e(mF,ibe),e(ibe,Rtr),e(mF,Ptr),e(mF,CU),e(CU,Btr),e(mF,Itr),e(Z,Ntr),e(Z,gF),e(gF,dbe),e(dbe,qtr),e(gF,jtr),e(gF,wU),e(wU,Dtr),e(gF,Gtr),e(Z,Otr),e(Z,hF),e(hF,cbe),e(cbe,Vtr),e(hF,Xtr),e(hF,AU),e(AU,ztr),e(hF,Qtr),e(Z,Wtr),e(Z,uF),e(uF,fbe),e(fbe,Utr),e(uF,Htr),e(uF,LU),e(LU,Jtr),e(uF,Ytr),e(Z,Ktr),e(Z,pF),e(pF,mbe),e(mbe,Ztr),e(pF,ear),e(pF,yU),e(yU,oar),e(pF,rar),e(Z,tar),e(Z,_F),e(_F,gbe),e(gbe,aar),e(_F,nar),e(_F,xU),e(xU,sar),e(_F,lar),e(Z,iar),e(Z,vF),e(vF,hbe),e(hbe,dar),e(vF,car),e(vF,$U),e($U,far),e(vF,mar),e(Z,gar),e(Z,bF),e(bF,ube),e(ube,har),e(bF,uar),e(bF,kU),e(kU,par),e(bF,_ar),e(Z,bar),e(Z,FF),e(FF,pbe),e(pbe,Far),e(FF,Tar),e(FF,SU),e(SU,Mar),e(FF,Ear),e(Z,Car),e(Z,TF),e(TF,_be),e(_be,war),e(TF,Aar),e(TF,RU),e(RU,Lar),e(TF,yar),e(Z,xar),e(Z,MF),e(MF,vbe),e(vbe,$ar),e(MF,kar),e(MF,PU),e(PU,Sar),e(MF,Rar),e(Z,Par),e(Z,EF),e(EF,bbe),e(bbe,Bar),e(EF,Iar),e(EF,BU),e(BU,Nar),e(EF,qar),e(Z,jar),e(Z,CF),e(CF,Fbe),e(Fbe,Dar),e(CF,Gar),e(CF,IU),e(IU,Oar),e(CF,Var),e(Z,Xar),e(Z,wF),e(wF,Tbe),e(Tbe,zar),e(wF,Qar),e(wF,NU),e(NU,War),e(wF,Uar),e(Z,Har),e(Z,AF),e(AF,Mbe),e(Mbe,Jar),e(AF,Yar),e(AF,qU),e(qU,Kar),e(AF,Zar),e(Z,enr),e(Z,LF),e(LF,Ebe),e(Ebe,onr),e(LF,rnr),e(LF,jU),e(jU,tnr),e(LF,anr),e(Z,nnr),e(Z,yF),e(yF,Cbe),e(Cbe,snr),e(yF,lnr),e(yF,DU),e(DU,inr),e(yF,dnr),e(Z,cnr),e(Z,xF),e(xF,wbe),e(wbe,fnr),e(xF,mnr),e(xF,GU),e(GU,gnr),e(xF,hnr),e(Z,unr),e(Z,$F),e($F,Abe),e(Abe,pnr),e($F,_nr),e($F,OU),e(OU,vnr),e($F,bnr),e(Z,Fnr),e(Z,kF),e(kF,Lbe),e(Lbe,Tnr),e(kF,Mnr),e(kF,VU),e(VU,Enr),e(kF,Cnr),e(Z,wnr),e(Z,SF),e(SF,ybe),e(ybe,Anr),e(SF,Lnr),e(SF,XU),e(XU,ynr),e(SF,xnr),e(Z,$nr),e(Z,RF),e(RF,xbe),e(xbe,knr),e(RF,Snr),e(RF,zU),e(zU,Rnr),e(RF,Pnr),e(Z,Bnr),e(Z,PF),e(PF,$be),e($be,Inr),e(PF,Nnr),e(PF,QU),e(QU,qnr),e(PF,jnr),e(Z,Dnr),e(Z,BF),e(BF,kbe),e(kbe,Gnr),e(BF,Onr),e(BF,WU),e(WU,Vnr),e(BF,Xnr),e(Z,znr),e(Z,IF),e(IF,Sbe),e(Sbe,Qnr),e(IF,Wnr),e(IF,UU),e(UU,Unr),e(IF,Hnr),e(Z,Jnr),e(Z,NF),e(NF,Rbe),e(Rbe,Ynr),e(NF,Knr),e(NF,HU),e(HU,Znr),e(NF,esr),e(Z,osr),e(Z,qF),e(qF,Pbe),e(Pbe,rsr),e(qF,tsr),e(qF,JU),e(JU,asr),e(qF,nsr),e(Z,ssr),e(Z,jF),e(jF,Bbe),e(Bbe,lsr),e(jF,isr),e(jF,YU),e(YU,dsr),e(jF,csr),e(Z,fsr),e(Z,DF),e(DF,Ibe),e(Ibe,msr),e(DF,gsr),e(DF,KU),e(KU,hsr),e(DF,usr),e(Z,psr),e(Z,GF),e(GF,Nbe),e(Nbe,_sr),e(GF,vsr),e(GF,ZU),e(ZU,bsr),e(GF,Fsr),e(Z,Tsr),e(Z,OF),e(OF,qbe),e(qbe,Msr),e(OF,Esr),e(OF,eH),e(eH,Csr),e(OF,wsr),e(no,Asr),e(no,VF),e(VF,Lsr),e(VF,jbe),e(jbe,ysr),e(VF,xsr),e(VF,Dbe),e(Dbe,$sr),e(no,ksr),M(XF,no,null),v(f,aKe,_),v(f,Nd,_),e(Nd,zF),e(zF,Gbe),M($x,Gbe,null),e(Nd,Ssr),e(Nd,Obe),e(Obe,Rsr),v(f,nKe,_),v(f,Go,_),M(kx,Go,null),e(Go,Psr),e(Go,qd),e(qd,Bsr),e(qd,oH),e(oH,Isr),e(qd,Nsr),e(qd,rH),e(rH,qsr),e(qd,jsr),e(Go,Dsr),e(Go,Sx),e(Sx,Gsr),e(Sx,Vbe),e(Vbe,Osr),e(Sx,Vsr),e(Go,Xsr),e(Go,Ct),M(Rx,Ct,null),e(Ct,zsr),e(Ct,Xbe),e(Xbe,Qsr),e(Ct,Wsr),e(Ct,jd),e(jd,Usr),e(jd,zbe),e(zbe,Hsr),e(jd,Jsr),e(jd,tH),e(tH,Ysr),e(jd,Ksr),e(Ct,Zsr),M(QF,Ct,null),e(Go,elr),e(Go,so),M(Px,so,null),e(so,olr),e(so,Qbe),e(Qbe,rlr),e(so,tlr),e(so,tn),e(tn,alr),e(tn,Wbe),e(Wbe,nlr),e(tn,slr),e(tn,Ube),e(Ube,llr),e(tn,ilr),e(tn,Hbe),e(Hbe,dlr),e(tn,clr),e(so,flr),e(so,Ue),e(Ue,WF),e(WF,Jbe),e(Jbe,mlr),e(WF,glr),e(WF,aH),e(aH,hlr),e(WF,ulr),e(Ue,plr),e(Ue,UF),e(UF,Ybe),e(Ybe,_lr),e(UF,vlr),e(UF,nH),e(nH,blr),e(UF,Flr),e(Ue,Tlr),e(Ue,HF),e(HF,Kbe),e(Kbe,Mlr),e(HF,Elr),e(HF,sH),e(sH,Clr),e(HF,wlr),e(Ue,Alr),e(Ue,JF),e(JF,Zbe),e(Zbe,Llr),e(JF,ylr),e(JF,lH),e(lH,xlr),e(JF,$lr),e(Ue,klr),e(Ue,YF),e(YF,eFe),e(eFe,Slr),e(YF,Rlr),e(YF,iH),e(iH,Plr),e(YF,Blr),e(Ue,Ilr),e(Ue,KF),e(KF,oFe),e(oFe,Nlr),e(KF,qlr),e(KF,dH),e(dH,jlr),e(KF,Dlr),e(Ue,Glr),e(Ue,ZF),e(ZF,rFe),e(rFe,Olr),e(ZF,Vlr),e(ZF,cH),e(cH,Xlr),e(ZF,zlr),e(so,Qlr),e(so,eT),e(eT,Wlr),e(eT,tFe),e(tFe,Ulr),e(eT,Hlr),e(eT,aFe),e(aFe,Jlr),e(so,Ylr),M(oT,so,null),v(f,sKe,_),v(f,Dd,_),e(Dd,rT),e(rT,nFe),M(Bx,nFe,null),e(Dd,Klr),e(Dd,sFe),e(sFe,Zlr),v(f,lKe,_),v(f,Oo,_),M(Ix,Oo,null),e(Oo,eir),e(Oo,Gd),e(Gd,oir),e(Gd,fH),e(fH,rir),e(Gd,tir),e(Gd,mH),e(mH,air),e(Gd,nir),e(Oo,sir),e(Oo,Nx),e(Nx,lir),e(Nx,lFe),e(lFe,iir),e(Nx,dir),e(Oo,cir),e(Oo,wt),M(qx,wt,null),e(wt,fir),e(wt,iFe),e(iFe,mir),e(wt,gir),e(wt,Od),e(Od,hir),e(Od,dFe),e(dFe,uir),e(Od,pir),e(Od,gH),e(gH,_ir),e(Od,vir),e(wt,bir),M(tT,wt,null),e(Oo,Fir),e(Oo,lo),M(jx,lo,null),e(lo,Tir),e(lo,cFe),e(cFe,Mir),e(lo,Eir),e(lo,an),e(an,Cir),e(an,fFe),e(fFe,wir),e(an,Air),e(an,mFe),e(mFe,Lir),e(an,yir),e(an,gFe),e(gFe,xir),e(an,$ir),e(lo,kir),e(lo,H),e(H,aT),e(aT,hFe),e(hFe,Sir),e(aT,Rir),e(aT,hH),e(hH,Pir),e(aT,Bir),e(H,Iir),e(H,nT),e(nT,uFe),e(uFe,Nir),e(nT,qir),e(nT,uH),e(uH,jir),e(nT,Dir),e(H,Gir),e(H,sT),e(sT,pFe),e(pFe,Oir),e(sT,Vir),e(sT,pH),e(pH,Xir),e(sT,zir),e(H,Qir),e(H,lT),e(lT,_Fe),e(_Fe,Wir),e(lT,Uir),e(lT,_H),e(_H,Hir),e(lT,Jir),e(H,Yir),e(H,iT),e(iT,vFe),e(vFe,Kir),e(iT,Zir),e(iT,vH),e(vH,edr),e(iT,odr),e(H,rdr),e(H,dT),e(dT,bFe),e(bFe,tdr),e(dT,adr),e(dT,bH),e(bH,ndr),e(dT,sdr),e(H,ldr),e(H,cT),e(cT,FFe),e(FFe,idr),e(cT,ddr),e(cT,FH),e(FH,cdr),e(cT,fdr),e(H,mdr),e(H,fT),e(fT,TFe),e(TFe,gdr),e(fT,hdr),e(fT,TH),e(TH,udr),e(fT,pdr),e(H,_dr),e(H,mT),e(mT,MFe),e(MFe,vdr),e(mT,bdr),e(mT,MH),e(MH,Fdr),e(mT,Tdr),e(H,Mdr),e(H,gT),e(gT,EFe),e(EFe,Edr),e(gT,Cdr),e(gT,EH),e(EH,wdr),e(gT,Adr),e(H,Ldr),e(H,hT),e(hT,CFe),e(CFe,ydr),e(hT,xdr),e(hT,CH),e(CH,$dr),e(hT,kdr),e(H,Sdr),e(H,uT),e(uT,wFe),e(wFe,Rdr),e(uT,Pdr),e(uT,wH),e(wH,Bdr),e(uT,Idr),e(H,Ndr),e(H,pT),e(pT,AFe),e(AFe,qdr),e(pT,jdr),e(pT,AH),e(AH,Ddr),e(pT,Gdr),e(H,Odr),e(H,_T),e(_T,LFe),e(LFe,Vdr),e(_T,Xdr),e(_T,LH),e(LH,zdr),e(_T,Qdr),e(H,Wdr),e(H,vT),e(vT,yFe),e(yFe,Udr),e(vT,Hdr),e(vT,yH),e(yH,Jdr),e(vT,Ydr),e(H,Kdr),e(H,bT),e(bT,xFe),e(xFe,Zdr),e(bT,ecr),e(bT,xH),e(xH,ocr),e(bT,rcr),e(H,tcr),e(H,FT),e(FT,$Fe),e($Fe,acr),e(FT,ncr),e(FT,$H),e($H,scr),e(FT,lcr),e(H,icr),e(H,TT),e(TT,kFe),e(kFe,dcr),e(TT,ccr),e(TT,kH),e(kH,fcr),e(TT,mcr),e(H,gcr),e(H,MT),e(MT,SFe),e(SFe,hcr),e(MT,ucr),e(MT,SH),e(SH,pcr),e(MT,_cr),e(H,vcr),e(H,ET),e(ET,RFe),e(RFe,bcr),e(ET,Fcr),e(ET,RH),e(RH,Tcr),e(ET,Mcr),e(H,Ecr),e(H,CT),e(CT,PFe),e(PFe,Ccr),e(CT,wcr),e(CT,PH),e(PH,Acr),e(CT,Lcr),e(H,ycr),e(H,wT),e(wT,BFe),e(BFe,xcr),e(wT,$cr),e(wT,BH),e(BH,kcr),e(wT,Scr),e(H,Rcr),e(H,AT),e(AT,IFe),e(IFe,Pcr),e(AT,Bcr),e(AT,IH),e(IH,Icr),e(AT,Ncr),e(H,qcr),e(H,LT),e(LT,NFe),e(NFe,jcr),e(LT,Dcr),e(LT,NH),e(NH,Gcr),e(LT,Ocr),e(H,Vcr),e(H,yT),e(yT,qFe),e(qFe,Xcr),e(yT,zcr),e(yT,qH),e(qH,Qcr),e(yT,Wcr),e(H,Ucr),e(H,xT),e(xT,jFe),e(jFe,Hcr),e(xT,Jcr),e(xT,jH),e(jH,Ycr),e(xT,Kcr),e(H,Zcr),e(H,$T),e($T,DFe),e(DFe,efr),e($T,ofr),e($T,DH),e(DH,rfr),e($T,tfr),e(H,afr),e(H,kT),e(kT,GFe),e(GFe,nfr),e(kT,sfr),e(kT,GH),e(GH,lfr),e(kT,ifr),e(H,dfr),e(H,ST),e(ST,OFe),e(OFe,cfr),e(ST,ffr),e(ST,OH),e(OH,mfr),e(ST,gfr),e(H,hfr),e(H,RT),e(RT,VFe),e(VFe,ufr),e(RT,pfr),e(RT,VH),e(VH,_fr),e(RT,vfr),e(H,bfr),e(H,PT),e(PT,XFe),e(XFe,Ffr),e(PT,Tfr),e(PT,XH),e(XH,Mfr),e(PT,Efr),e(H,Cfr),e(H,BT),e(BT,zFe),e(zFe,wfr),e(BT,Afr),e(BT,zH),e(zH,Lfr),e(BT,yfr),e(H,xfr),e(H,IT),e(IT,QFe),e(QFe,$fr),e(IT,kfr),e(IT,QH),e(QH,Sfr),e(IT,Rfr),e(H,Pfr),e(H,NT),e(NT,WFe),e(WFe,Bfr),e(NT,Ifr),e(NT,WH),e(WH,Nfr),e(NT,qfr),e(H,jfr),e(H,qT),e(qT,UFe),e(UFe,Dfr),e(qT,Gfr),e(qT,UH),e(UH,Ofr),e(qT,Vfr),e(H,Xfr),e(H,jT),e(jT,HFe),e(HFe,zfr),e(jT,Qfr),e(jT,HH),e(HH,Wfr),e(jT,Ufr),e(H,Hfr),e(H,DT),e(DT,JFe),e(JFe,Jfr),e(DT,Yfr),e(DT,JH),e(JH,Kfr),e(DT,Zfr),e(H,emr),e(H,GT),e(GT,YFe),e(YFe,omr),e(GT,rmr),e(GT,YH),e(YH,tmr),e(GT,amr),e(lo,nmr),e(lo,OT),e(OT,smr),e(OT,KFe),e(KFe,lmr),e(OT,imr),e(OT,ZFe),e(ZFe,dmr),e(lo,cmr),M(VT,lo,null),v(f,iKe,_),v(f,Vd,_),e(Vd,XT),e(XT,eTe),M(Dx,eTe,null),e(Vd,fmr),e(Vd,oTe),e(oTe,mmr),v(f,dKe,_),v(f,Vo,_),M(Gx,Vo,null),e(Vo,gmr),e(Vo,Xd),e(Xd,hmr),e(Xd,KH),e(KH,umr),e(Xd,pmr),e(Xd,ZH),e(ZH,_mr),e(Xd,vmr),e(Vo,bmr),e(Vo,Ox),e(Ox,Fmr),e(Ox,rTe),e(rTe,Tmr),e(Ox,Mmr),e(Vo,Emr),e(Vo,At),M(Vx,At,null),e(At,Cmr),e(At,tTe),e(tTe,wmr),e(At,Amr),e(At,zd),e(zd,Lmr),e(zd,aTe),e(aTe,ymr),e(zd,xmr),e(zd,eJ),e(eJ,$mr),e(zd,kmr),e(At,Smr),M(zT,At,null),e(Vo,Rmr),e(Vo,io),M(Xx,io,null),e(io,Pmr),e(io,nTe),e(nTe,Bmr),e(io,Imr),e(io,nn),e(nn,Nmr),e(nn,sTe),e(sTe,qmr),e(nn,jmr),e(nn,lTe),e(lTe,Dmr),e(nn,Gmr),e(nn,iTe),e(iTe,Omr),e(nn,Vmr),e(io,Xmr),e(io,V),e(V,QT),e(QT,dTe),e(dTe,zmr),e(QT,Qmr),e(QT,oJ),e(oJ,Wmr),e(QT,Umr),e(V,Hmr),e(V,WT),e(WT,cTe),e(cTe,Jmr),e(WT,Ymr),e(WT,rJ),e(rJ,Kmr),e(WT,Zmr),e(V,egr),e(V,UT),e(UT,fTe),e(fTe,ogr),e(UT,rgr),e(UT,tJ),e(tJ,tgr),e(UT,agr),e(V,ngr),e(V,HT),e(HT,mTe),e(mTe,sgr),e(HT,lgr),e(HT,aJ),e(aJ,igr),e(HT,dgr),e(V,cgr),e(V,JT),e(JT,gTe),e(gTe,fgr),e(JT,mgr),e(JT,nJ),e(nJ,ggr),e(JT,hgr),e(V,ugr),e(V,YT),e(YT,hTe),e(hTe,pgr),e(YT,_gr),e(YT,sJ),e(sJ,vgr),e(YT,bgr),e(V,Fgr),e(V,KT),e(KT,uTe),e(uTe,Tgr),e(KT,Mgr),e(KT,lJ),e(lJ,Egr),e(KT,Cgr),e(V,wgr),e(V,ZT),e(ZT,pTe),e(pTe,Agr),e(ZT,Lgr),e(ZT,iJ),e(iJ,ygr),e(ZT,xgr),e(V,$gr),e(V,eM),e(eM,_Te),e(_Te,kgr),e(eM,Sgr),e(eM,dJ),e(dJ,Rgr),e(eM,Pgr),e(V,Bgr),e(V,oM),e(oM,vTe),e(vTe,Igr),e(oM,Ngr),e(oM,cJ),e(cJ,qgr),e(oM,jgr),e(V,Dgr),e(V,rM),e(rM,bTe),e(bTe,Ggr),e(rM,Ogr),e(rM,fJ),e(fJ,Vgr),e(rM,Xgr),e(V,zgr),e(V,tM),e(tM,FTe),e(FTe,Qgr),e(tM,Wgr),e(tM,mJ),e(mJ,Ugr),e(tM,Hgr),e(V,Jgr),e(V,aM),e(aM,TTe),e(TTe,Ygr),e(aM,Kgr),e(aM,gJ),e(gJ,Zgr),e(aM,ehr),e(V,ohr),e(V,nM),e(nM,MTe),e(MTe,rhr),e(nM,thr),e(nM,hJ),e(hJ,ahr),e(nM,nhr),e(V,shr),e(V,sM),e(sM,ETe),e(ETe,lhr),e(sM,ihr),e(sM,uJ),e(uJ,dhr),e(sM,chr),e(V,fhr),e(V,lM),e(lM,CTe),e(CTe,mhr),e(lM,ghr),e(lM,pJ),e(pJ,hhr),e(lM,uhr),e(V,phr),e(V,iM),e(iM,wTe),e(wTe,_hr),e(iM,vhr),e(iM,_J),e(_J,bhr),e(iM,Fhr),e(V,Thr),e(V,dM),e(dM,ATe),e(ATe,Mhr),e(dM,Ehr),e(dM,vJ),e(vJ,Chr),e(dM,whr),e(V,Ahr),e(V,cM),e(cM,LTe),e(LTe,Lhr),e(cM,yhr),e(cM,bJ),e(bJ,xhr),e(cM,$hr),e(V,khr),e(V,fM),e(fM,yTe),e(yTe,Shr),e(fM,Rhr),e(fM,FJ),e(FJ,Phr),e(fM,Bhr),e(V,Ihr),e(V,mM),e(mM,xTe),e(xTe,Nhr),e(mM,qhr),e(mM,TJ),e(TJ,jhr),e(mM,Dhr),e(V,Ghr),e(V,gM),e(gM,$Te),e($Te,Ohr),e(gM,Vhr),e(gM,MJ),e(MJ,Xhr),e(gM,zhr),e(V,Qhr),e(V,hM),e(hM,kTe),e(kTe,Whr),e(hM,Uhr),e(hM,EJ),e(EJ,Hhr),e(hM,Jhr),e(V,Yhr),e(V,uM),e(uM,STe),e(STe,Khr),e(uM,Zhr),e(uM,CJ),e(CJ,eur),e(uM,our),e(V,rur),e(V,pM),e(pM,RTe),e(RTe,tur),e(pM,aur),e(pM,wJ),e(wJ,nur),e(pM,sur),e(V,lur),e(V,_M),e(_M,PTe),e(PTe,iur),e(_M,dur),e(_M,AJ),e(AJ,cur),e(_M,fur),e(V,mur),e(V,vM),e(vM,BTe),e(BTe,gur),e(vM,hur),e(vM,LJ),e(LJ,uur),e(vM,pur),e(V,_ur),e(V,bM),e(bM,ITe),e(ITe,vur),e(bM,bur),e(bM,yJ),e(yJ,Fur),e(bM,Tur),e(V,Mur),e(V,FM),e(FM,NTe),e(NTe,Eur),e(FM,Cur),e(FM,xJ),e(xJ,wur),e(FM,Aur),e(V,Lur),e(V,TM),e(TM,qTe),e(qTe,yur),e(TM,xur),e(TM,$J),e($J,$ur),e(TM,kur),e(V,Sur),e(V,MM),e(MM,jTe),e(jTe,Rur),e(MM,Pur),e(MM,kJ),e(kJ,Bur),e(MM,Iur),e(V,Nur),e(V,EM),e(EM,DTe),e(DTe,qur),e(EM,jur),e(EM,SJ),e(SJ,Dur),e(EM,Gur),e(V,Our),e(V,CM),e(CM,GTe),e(GTe,Vur),e(CM,Xur),e(CM,RJ),e(RJ,zur),e(CM,Qur),e(V,Wur),e(V,wM),e(wM,OTe),e(OTe,Uur),e(wM,Hur),e(wM,PJ),e(PJ,Jur),e(wM,Yur),e(V,Kur),e(V,AM),e(AM,VTe),e(VTe,Zur),e(AM,epr),e(AM,BJ),e(BJ,opr),e(AM,rpr),e(V,tpr),e(V,LM),e(LM,XTe),e(XTe,apr),e(LM,npr),e(LM,IJ),e(IJ,spr),e(LM,lpr),e(V,ipr),e(V,yM),e(yM,zTe),e(zTe,dpr),e(yM,cpr),e(yM,NJ),e(NJ,fpr),e(yM,mpr),e(V,gpr),e(V,xM),e(xM,QTe),e(QTe,hpr),e(xM,upr),e(xM,qJ),e(qJ,ppr),e(xM,_pr),e(V,vpr),e(V,$M),e($M,WTe),e(WTe,bpr),e($M,Fpr),e($M,jJ),e(jJ,Tpr),e($M,Mpr),e(V,Epr),e(V,kM),e(kM,UTe),e(UTe,Cpr),e(kM,wpr),e(kM,DJ),e(DJ,Apr),e(kM,Lpr),e(V,ypr),e(V,SM),e(SM,HTe),e(HTe,xpr),e(SM,$pr),e(SM,GJ),e(GJ,kpr),e(SM,Spr),e(V,Rpr),e(V,RM),e(RM,JTe),e(JTe,Ppr),e(RM,Bpr),e(RM,OJ),e(OJ,Ipr),e(RM,Npr),e(V,qpr),e(V,PM),e(PM,YTe),e(YTe,jpr),e(PM,Dpr),e(PM,VJ),e(VJ,Gpr),e(PM,Opr),e(V,Vpr),e(V,BM),e(BM,KTe),e(KTe,Xpr),e(BM,zpr),e(BM,XJ),e(XJ,Qpr),e(BM,Wpr),e(io,Upr),e(io,IM),e(IM,Hpr),e(IM,ZTe),e(ZTe,Jpr),e(IM,Ypr),e(IM,eMe),e(eMe,Kpr),e(io,Zpr),M(NM,io,null),v(f,cKe,_),v(f,Qd,_),e(Qd,qM),e(qM,oMe),M(zx,oMe,null),e(Qd,e_r),e(Qd,rMe),e(rMe,o_r),v(f,fKe,_),v(f,Xo,_),M(Qx,Xo,null),e(Xo,r_r),e(Xo,Wd),e(Wd,t_r),e(Wd,zJ),e(zJ,a_r),e(Wd,n_r),e(Wd,QJ),e(QJ,s_r),e(Wd,l_r),e(Xo,i_r),e(Xo,Wx),e(Wx,d_r),e(Wx,tMe),e(tMe,c_r),e(Wx,f_r),e(Xo,m_r),e(Xo,Lt),M(Ux,Lt,null),e(Lt,g_r),e(Lt,aMe),e(aMe,h_r),e(Lt,u_r),e(Lt,Ud),e(Ud,p_r),e(Ud,nMe),e(nMe,__r),e(Ud,v_r),e(Ud,WJ),e(WJ,b_r),e(Ud,F_r),e(Lt,T_r),M(jM,Lt,null),e(Xo,M_r),e(Xo,co),M(Hx,co,null),e(co,E_r),e(co,sMe),e(sMe,C_r),e(co,w_r),e(co,sn),e(sn,A_r),e(sn,lMe),e(lMe,L_r),e(sn,y_r),e(sn,iMe),e(iMe,x_r),e(sn,$_r),e(sn,dMe),e(dMe,k_r),e(sn,S_r),e(co,R_r),e(co,cMe),e(cMe,DM),e(DM,fMe),e(fMe,P_r),e(DM,B_r),e(DM,UJ),e(UJ,I_r),e(DM,N_r),e(co,q_r),e(co,GM),e(GM,j_r),e(GM,mMe),e(mMe,D_r),e(GM,G_r),e(GM,gMe),e(gMe,O_r),e(co,V_r),M(OM,co,null),v(f,mKe,_),v(f,Hd,_),e(Hd,VM),e(VM,hMe),M(Jx,hMe,null),e(Hd,X_r),e(Hd,uMe),e(uMe,z_r),v(f,gKe,_),v(f,zo,_),M(Yx,zo,null),e(zo,Q_r),e(zo,Jd),e(Jd,W_r),e(Jd,HJ),e(HJ,U_r),e(Jd,H_r),e(Jd,JJ),e(JJ,J_r),e(Jd,Y_r),e(zo,K_r),e(zo,Kx),e(Kx,Z_r),e(Kx,pMe),e(pMe,e2r),e(Kx,o2r),e(zo,r2r),e(zo,yt),M(Zx,yt,null),e(yt,t2r),e(yt,_Me),e(_Me,a2r),e(yt,n2r),e(yt,Yd),e(Yd,s2r),e(Yd,vMe),e(vMe,l2r),e(Yd,i2r),e(Yd,YJ),e(YJ,d2r),e(Yd,c2r),e(yt,f2r),M(XM,yt,null),e(zo,m2r),e(zo,fo),M(e$,fo,null),e(fo,g2r),e(fo,bMe),e(bMe,h2r),e(fo,u2r),e(fo,ln),e(ln,p2r),e(ln,FMe),e(FMe,_2r),e(ln,v2r),e(ln,TMe),e(TMe,b2r),e(ln,F2r),e(ln,MMe),e(MMe,T2r),e(ln,M2r),e(fo,E2r),e(fo,Kd),e(Kd,zM),e(zM,EMe),e(EMe,C2r),e(zM,w2r),e(zM,KJ),e(KJ,A2r),e(zM,L2r),e(Kd,y2r),e(Kd,QM),e(QM,CMe),e(CMe,x2r),e(QM,$2r),e(QM,ZJ),e(ZJ,k2r),e(QM,S2r),e(Kd,R2r),e(Kd,WM),e(WM,wMe),e(wMe,P2r),e(WM,B2r),e(WM,eY),e(eY,I2r),e(WM,N2r),e(fo,q2r),e(fo,UM),e(UM,j2r),e(UM,AMe),e(AMe,D2r),e(UM,G2r),e(UM,LMe),e(LMe,O2r),e(fo,V2r),M(HM,fo,null),v(f,hKe,_),v(f,Zd,_),e(Zd,JM),e(JM,yMe),M(o$,yMe,null),e(Zd,X2r),e(Zd,xMe),e(xMe,z2r),v(f,uKe,_),v(f,Qo,_),M(r$,Qo,null),e(Qo,Q2r),e(Qo,ec),e(ec,W2r),e(ec,oY),e(oY,U2r),e(ec,H2r),e(ec,rY),e(rY,J2r),e(ec,Y2r),e(Qo,K2r),e(Qo,t$),e(t$,Z2r),e(t$,$Me),e($Me,evr),e(t$,ovr),e(Qo,rvr),e(Qo,xt),M(a$,xt,null),e(xt,tvr),e(xt,kMe),e(kMe,avr),e(xt,nvr),e(xt,oc),e(oc,svr),e(oc,SMe),e(SMe,lvr),e(oc,ivr),e(oc,tY),e(tY,dvr),e(oc,cvr),e(xt,fvr),M(YM,xt,null),e(Qo,mvr),e(Qo,mo),M(n$,mo,null),e(mo,gvr),e(mo,RMe),e(RMe,hvr),e(mo,uvr),e(mo,dn),e(dn,pvr),e(dn,PMe),e(PMe,_vr),e(dn,vvr),e(dn,BMe),e(BMe,bvr),e(dn,Fvr),e(dn,IMe),e(IMe,Tvr),e(dn,Mvr),e(mo,Evr),e(mo,ve),e(ve,KM),e(KM,NMe),e(NMe,Cvr),e(KM,wvr),e(KM,aY),e(aY,Avr),e(KM,Lvr),e(ve,yvr),e(ve,ZM),e(ZM,qMe),e(qMe,xvr),e(ZM,$vr),e(ZM,nY),e(nY,kvr),e(ZM,Svr),e(ve,Rvr),e(ve,eE),e(eE,jMe),e(jMe,Pvr),e(eE,Bvr),e(eE,sY),e(sY,Ivr),e(eE,Nvr),e(ve,qvr),e(ve,oE),e(oE,DMe),e(DMe,jvr),e(oE,Dvr),e(oE,lY),e(lY,Gvr),e(oE,Ovr),e(ve,Vvr),e(ve,_l),e(_l,GMe),e(GMe,Xvr),e(_l,zvr),e(_l,iY),e(iY,Qvr),e(_l,Wvr),e(_l,dY),e(dY,Uvr),e(_l,Hvr),e(ve,Jvr),e(ve,rE),e(rE,OMe),e(OMe,Yvr),e(rE,Kvr),e(rE,cY),e(cY,Zvr),e(rE,e1r),e(ve,o1r),e(ve,vl),e(vl,VMe),e(VMe,r1r),e(vl,t1r),e(vl,fY),e(fY,a1r),e(vl,n1r),e(vl,mY),e(mY,s1r),e(vl,l1r),e(ve,i1r),e(ve,tE),e(tE,XMe),e(XMe,d1r),e(tE,c1r),e(tE,gY),e(gY,f1r),e(tE,m1r),e(ve,g1r),e(ve,$t),e($t,zMe),e(zMe,h1r),e($t,u1r),e($t,hY),e(hY,p1r),e($t,_1r),e($t,uY),e(uY,v1r),e($t,b1r),e($t,pY),e(pY,F1r),e($t,T1r),e(ve,M1r),e(ve,aE),e(aE,QMe),e(QMe,E1r),e(aE,C1r),e(aE,_Y),e(_Y,w1r),e(aE,A1r),e(ve,L1r),e(ve,nE),e(nE,WMe),e(WMe,y1r),e(nE,x1r),e(nE,vY),e(vY,$1r),e(nE,k1r),e(ve,S1r),e(ve,sE),e(sE,UMe),e(UMe,R1r),e(sE,P1r),e(sE,bY),e(bY,B1r),e(sE,I1r),e(ve,N1r),e(ve,lE),e(lE,HMe),e(HMe,q1r),e(lE,j1r),e(lE,FY),e(FY,D1r),e(lE,G1r),e(ve,O1r),e(ve,iE),e(iE,JMe),e(JMe,V1r),e(iE,X1r),e(iE,TY),e(TY,z1r),e(iE,Q1r),e(ve,W1r),e(ve,dE),e(dE,YMe),e(YMe,U1r),e(dE,H1r),e(dE,MY),e(MY,J1r),e(dE,Y1r),e(ve,K1r),e(ve,cE),e(cE,KMe),e(KMe,Z1r),e(cE,e4r),e(cE,EY),e(EY,o4r),e(cE,r4r),e(ve,t4r),e(ve,fE),e(fE,ZMe),e(ZMe,a4r),e(fE,n4r),e(fE,CY),e(CY,s4r),e(fE,l4r),e(mo,i4r),e(mo,mE),e(mE,d4r),e(mE,eEe),e(eEe,c4r),e(mE,f4r),e(mE,oEe),e(oEe,m4r),e(mo,g4r),M(gE,mo,null),v(f,pKe,_),v(f,rc,_),e(rc,hE),e(hE,rEe),M(s$,rEe,null),e(rc,h4r),e(rc,tEe),e(tEe,u4r),v(f,_Ke,_),v(f,Wo,_),M(l$,Wo,null),e(Wo,p4r),e(Wo,tc),e(tc,_4r),e(tc,wY),e(wY,v4r),e(tc,b4r),e(tc,AY),e(AY,F4r),e(tc,T4r),e(Wo,M4r),e(Wo,i$),e(i$,E4r),e(i$,aEe),e(aEe,C4r),e(i$,w4r),e(Wo,A4r),e(Wo,kt),M(d$,kt,null),e(kt,L4r),e(kt,nEe),e(nEe,y4r),e(kt,x4r),e(kt,ac),e(ac,$4r),e(ac,sEe),e(sEe,k4r),e(ac,S4r),e(ac,LY),e(LY,R4r),e(ac,P4r),e(kt,B4r),M(uE,kt,null),e(Wo,I4r),e(Wo,go),M(c$,go,null),e(go,N4r),e(go,lEe),e(lEe,q4r),e(go,j4r),e(go,cn),e(cn,D4r),e(cn,iEe),e(iEe,G4r),e(cn,O4r),e(cn,dEe),e(dEe,V4r),e(cn,X4r),e(cn,cEe),e(cEe,z4r),e(cn,Q4r),e(go,W4r),e(go,fEe),e(fEe,pE),e(pE,mEe),e(mEe,U4r),e(pE,H4r),e(pE,yY),e(yY,J4r),e(pE,Y4r),e(go,K4r),e(go,_E),e(_E,Z4r),e(_E,gEe),e(gEe,ebr),e(_E,obr),e(_E,hEe),e(hEe,rbr),e(go,tbr),M(vE,go,null),v(f,vKe,_),v(f,nc,_),e(nc,bE),e(bE,uEe),M(f$,uEe,null),e(nc,abr),e(nc,pEe),e(pEe,nbr),v(f,bKe,_),v(f,Uo,_),M(m$,Uo,null),e(Uo,sbr),e(Uo,sc),e(sc,lbr),e(sc,xY),e(xY,ibr),e(sc,dbr),e(sc,$Y),e($Y,cbr),e(sc,fbr),e(Uo,mbr),e(Uo,g$),e(g$,gbr),e(g$,_Ee),e(_Ee,hbr),e(g$,ubr),e(Uo,pbr),e(Uo,St),M(h$,St,null),e(St,_br),e(St,vEe),e(vEe,vbr),e(St,bbr),e(St,lc),e(lc,Fbr),e(lc,bEe),e(bEe,Tbr),e(lc,Mbr),e(lc,kY),e(kY,Ebr),e(lc,Cbr),e(St,wbr),M(FE,St,null),e(Uo,Abr),e(Uo,ho),M(u$,ho,null),e(ho,Lbr),e(ho,FEe),e(FEe,ybr),e(ho,xbr),e(ho,fn),e(fn,$br),e(fn,TEe),e(TEe,kbr),e(fn,Sbr),e(fn,MEe),e(MEe,Rbr),e(fn,Pbr),e(fn,EEe),e(EEe,Bbr),e(fn,Ibr),e(ho,Nbr),e(ho,CEe),e(CEe,TE),e(TE,wEe),e(wEe,qbr),e(TE,jbr),e(TE,SY),e(SY,Dbr),e(TE,Gbr),e(ho,Obr),e(ho,ME),e(ME,Vbr),e(ME,AEe),e(AEe,Xbr),e(ME,zbr),e(ME,LEe),e(LEe,Qbr),e(ho,Wbr),M(EE,ho,null),v(f,FKe,_),v(f,ic,_),e(ic,CE),e(CE,yEe),M(p$,yEe,null),e(ic,Ubr),e(ic,xEe),e(xEe,Hbr),v(f,TKe,_),v(f,Ho,_),M(_$,Ho,null),e(Ho,Jbr),e(Ho,dc),e(dc,Ybr),e(dc,RY),e(RY,Kbr),e(dc,Zbr),e(dc,PY),e(PY,eFr),e(dc,oFr),e(Ho,rFr),e(Ho,v$),e(v$,tFr),e(v$,$Ee),e($Ee,aFr),e(v$,nFr),e(Ho,sFr),e(Ho,Rt),M(b$,Rt,null),e(Rt,lFr),e(Rt,kEe),e(kEe,iFr),e(Rt,dFr),e(Rt,cc),e(cc,cFr),e(cc,SEe),e(SEe,fFr),e(cc,mFr),e(cc,BY),e(BY,gFr),e(cc,hFr),e(Rt,uFr),M(wE,Rt,null),e(Ho,pFr),e(Ho,uo),M(F$,uo,null),e(uo,_Fr),e(uo,REe),e(REe,vFr),e(uo,bFr),e(uo,mn),e(mn,FFr),e(mn,PEe),e(PEe,TFr),e(mn,MFr),e(mn,BEe),e(BEe,EFr),e(mn,CFr),e(mn,IEe),e(IEe,wFr),e(mn,AFr),e(uo,LFr),e(uo,NEe),e(NEe,AE),e(AE,qEe),e(qEe,yFr),e(AE,xFr),e(AE,IY),e(IY,$Fr),e(AE,kFr),e(uo,SFr),e(uo,LE),e(LE,RFr),e(LE,jEe),e(jEe,PFr),e(LE,BFr),e(LE,DEe),e(DEe,IFr),e(uo,NFr),M(yE,uo,null),v(f,MKe,_),v(f,fc,_),e(fc,xE),e(xE,GEe),M(T$,GEe,null),e(fc,qFr),e(fc,OEe),e(OEe,jFr),v(f,EKe,_),v(f,Jo,_),M(M$,Jo,null),e(Jo,DFr),e(Jo,mc),e(mc,GFr),e(mc,NY),e(NY,OFr),e(mc,VFr),e(mc,qY),e(qY,XFr),e(mc,zFr),e(Jo,QFr),e(Jo,E$),e(E$,WFr),e(E$,VEe),e(VEe,UFr),e(E$,HFr),e(Jo,JFr),e(Jo,Pt),M(C$,Pt,null),e(Pt,YFr),e(Pt,XEe),e(XEe,KFr),e(Pt,ZFr),e(Pt,gc),e(gc,eTr),e(gc,zEe),e(zEe,oTr),e(gc,rTr),e(gc,jY),e(jY,tTr),e(gc,aTr),e(Pt,nTr),M($E,Pt,null),e(Jo,sTr),e(Jo,po),M(w$,po,null),e(po,lTr),e(po,QEe),e(QEe,iTr),e(po,dTr),e(po,gn),e(gn,cTr),e(gn,WEe),e(WEe,fTr),e(gn,mTr),e(gn,UEe),e(UEe,gTr),e(gn,hTr),e(gn,HEe),e(HEe,uTr),e(gn,pTr),e(po,_Tr),e(po,Pe),e(Pe,kE),e(kE,JEe),e(JEe,vTr),e(kE,bTr),e(kE,DY),e(DY,FTr),e(kE,TTr),e(Pe,MTr),e(Pe,SE),e(SE,YEe),e(YEe,ETr),e(SE,CTr),e(SE,GY),e(GY,wTr),e(SE,ATr),e(Pe,LTr),e(Pe,RE),e(RE,KEe),e(KEe,yTr),e(RE,xTr),e(RE,OY),e(OY,$Tr),e(RE,kTr),e(Pe,STr),e(Pe,PE),e(PE,ZEe),e(ZEe,RTr),e(PE,PTr),e(PE,VY),e(VY,BTr),e(PE,ITr),e(Pe,NTr),e(Pe,BE),e(BE,eCe),e(eCe,qTr),e(BE,jTr),e(BE,XY),e(XY,DTr),e(BE,GTr),e(Pe,OTr),e(Pe,IE),e(IE,oCe),e(oCe,VTr),e(IE,XTr),e(IE,zY),e(zY,zTr),e(IE,QTr),e(Pe,WTr),e(Pe,NE),e(NE,rCe),e(rCe,UTr),e(NE,HTr),e(NE,QY),e(QY,JTr),e(NE,YTr),e(Pe,KTr),e(Pe,qE),e(qE,tCe),e(tCe,ZTr),e(qE,eMr),e(qE,WY),e(WY,oMr),e(qE,rMr),e(Pe,tMr),e(Pe,jE),e(jE,aCe),e(aCe,aMr),e(jE,nMr),e(jE,UY),e(UY,sMr),e(jE,lMr),e(po,iMr),e(po,DE),e(DE,dMr),e(DE,nCe),e(nCe,cMr),e(DE,fMr),e(DE,sCe),e(sCe,mMr),e(po,gMr),M(GE,po,null),v(f,CKe,_),v(f,hc,_),e(hc,OE),e(OE,lCe),M(A$,lCe,null),e(hc,hMr),e(hc,iCe),e(iCe,uMr),v(f,wKe,_),v(f,Yo,_),M(L$,Yo,null),e(Yo,pMr),e(Yo,uc),e(uc,_Mr),e(uc,HY),e(HY,vMr),e(uc,bMr),e(uc,JY),e(JY,FMr),e(uc,TMr),e(Yo,MMr),e(Yo,y$),e(y$,EMr),e(y$,dCe),e(dCe,CMr),e(y$,wMr),e(Yo,AMr),e(Yo,Bt),M(x$,Bt,null),e(Bt,LMr),e(Bt,cCe),e(cCe,yMr),e(Bt,xMr),e(Bt,pc),e(pc,$Mr),e(pc,fCe),e(fCe,kMr),e(pc,SMr),e(pc,YY),e(YY,RMr),e(pc,PMr),e(Bt,BMr),M(VE,Bt,null),e(Yo,IMr),e(Yo,_o),M($$,_o,null),e(_o,NMr),e(_o,mCe),e(mCe,qMr),e(_o,jMr),e(_o,hn),e(hn,DMr),e(hn,gCe),e(gCe,GMr),e(hn,OMr),e(hn,hCe),e(hCe,VMr),e(hn,XMr),e(hn,uCe),e(uCe,zMr),e(hn,QMr),e(_o,WMr),e(_o,ft),e(ft,XE),e(XE,pCe),e(pCe,UMr),e(XE,HMr),e(XE,KY),e(KY,JMr),e(XE,YMr),e(ft,KMr),e(ft,zE),e(zE,_Ce),e(_Ce,ZMr),e(zE,eEr),e(zE,ZY),e(ZY,oEr),e(zE,rEr),e(ft,tEr),e(ft,QE),e(QE,vCe),e(vCe,aEr),e(QE,nEr),e(QE,eK),e(eK,sEr),e(QE,lEr),e(ft,iEr),e(ft,WE),e(WE,bCe),e(bCe,dEr),e(WE,cEr),e(WE,oK),e(oK,fEr),e(WE,mEr),e(ft,gEr),e(ft,UE),e(UE,FCe),e(FCe,hEr),e(UE,uEr),e(UE,rK),e(rK,pEr),e(UE,_Er),e(_o,vEr),e(_o,HE),e(HE,bEr),e(HE,TCe),e(TCe,FEr),e(HE,TEr),e(HE,MCe),e(MCe,MEr),e(_o,EEr),M(JE,_o,null),v(f,AKe,_),v(f,_c,_),e(_c,YE),e(YE,ECe),M(k$,ECe,null),e(_c,CEr),e(_c,CCe),e(CCe,wEr),v(f,LKe,_),v(f,Ko,_),M(S$,Ko,null),e(Ko,AEr),e(Ko,vc),e(vc,LEr),e(vc,tK),e(tK,yEr),e(vc,xEr),e(vc,aK),e(aK,$Er),e(vc,kEr),e(Ko,SEr),e(Ko,R$),e(R$,REr),e(R$,wCe),e(wCe,PEr),e(R$,BEr),e(Ko,IEr),e(Ko,It),M(P$,It,null),e(It,NEr),e(It,ACe),e(ACe,qEr),e(It,jEr),e(It,bc),e(bc,DEr),e(bc,LCe),e(LCe,GEr),e(bc,OEr),e(bc,nK),e(nK,VEr),e(bc,XEr),e(It,zEr),M(KE,It,null),e(Ko,QEr),e(Ko,vo),M(B$,vo,null),e(vo,WEr),e(vo,yCe),e(yCe,UEr),e(vo,HEr),e(vo,un),e(un,JEr),e(un,xCe),e(xCe,YEr),e(un,KEr),e(un,$Ce),e($Ce,ZEr),e(un,eCr),e(un,kCe),e(kCe,oCr),e(un,rCr),e(vo,tCr),e(vo,Le),e(Le,ZE),e(ZE,SCe),e(SCe,aCr),e(ZE,nCr),e(ZE,sK),e(sK,sCr),e(ZE,lCr),e(Le,iCr),e(Le,eC),e(eC,RCe),e(RCe,dCr),e(eC,cCr),e(eC,lK),e(lK,fCr),e(eC,mCr),e(Le,gCr),e(Le,oC),e(oC,PCe),e(PCe,hCr),e(oC,uCr),e(oC,iK),e(iK,pCr),e(oC,_Cr),e(Le,vCr),e(Le,rC),e(rC,BCe),e(BCe,bCr),e(rC,FCr),e(rC,dK),e(dK,TCr),e(rC,MCr),e(Le,ECr),e(Le,tC),e(tC,ICe),e(ICe,CCr),e(tC,wCr),e(tC,cK),e(cK,ACr),e(tC,LCr),e(Le,yCr),e(Le,aC),e(aC,NCe),e(NCe,xCr),e(aC,$Cr),e(aC,fK),e(fK,kCr),e(aC,SCr),e(Le,RCr),e(Le,nC),e(nC,qCe),e(qCe,PCr),e(nC,BCr),e(nC,mK),e(mK,ICr),e(nC,NCr),e(Le,qCr),e(Le,sC),e(sC,jCe),e(jCe,jCr),e(sC,DCr),e(sC,gK),e(gK,GCr),e(sC,OCr),e(Le,VCr),e(Le,lC),e(lC,DCe),e(DCe,XCr),e(lC,zCr),e(lC,hK),e(hK,QCr),e(lC,WCr),e(Le,UCr),e(Le,iC),e(iC,GCe),e(GCe,HCr),e(iC,JCr),e(iC,uK),e(uK,YCr),e(iC,KCr),e(vo,ZCr),e(vo,dC),e(dC,e3r),e(dC,OCe),e(OCe,o3r),e(dC,r3r),e(dC,VCe),e(VCe,t3r),e(vo,a3r),M(cC,vo,null),v(f,yKe,_),v(f,Fc,_),e(Fc,fC),e(fC,XCe),M(I$,XCe,null),e(Fc,n3r),e(Fc,zCe),e(zCe,s3r),v(f,xKe,_),v(f,Zo,_),M(N$,Zo,null),e(Zo,l3r),e(Zo,Tc),e(Tc,i3r),e(Tc,pK),e(pK,d3r),e(Tc,c3r),e(Tc,_K),e(_K,f3r),e(Tc,m3r),e(Zo,g3r),e(Zo,q$),e(q$,h3r),e(q$,QCe),e(QCe,u3r),e(q$,p3r),e(Zo,_3r),e(Zo,Nt),M(j$,Nt,null),e(Nt,v3r),e(Nt,WCe),e(WCe,b3r),e(Nt,F3r),e(Nt,Mc),e(Mc,T3r),e(Mc,UCe),e(UCe,M3r),e(Mc,E3r),e(Mc,vK),e(vK,C3r),e(Mc,w3r),e(Nt,A3r),M(mC,Nt,null),e(Zo,L3r),e(Zo,bo),M(D$,bo,null),e(bo,y3r),e(bo,HCe),e(HCe,x3r),e(bo,$3r),e(bo,pn),e(pn,k3r),e(pn,JCe),e(JCe,S3r),e(pn,R3r),e(pn,YCe),e(YCe,P3r),e(pn,B3r),e(pn,KCe),e(KCe,I3r),e(pn,N3r),e(bo,q3r),e(bo,G$),e(G$,gC),e(gC,ZCe),e(ZCe,j3r),e(gC,D3r),e(gC,bK),e(bK,G3r),e(gC,O3r),e(G$,V3r),e(G$,hC),e(hC,e3e),e(e3e,X3r),e(hC,z3r),e(hC,FK),e(FK,Q3r),e(hC,W3r),e(bo,U3r),e(bo,uC),e(uC,H3r),e(uC,o3e),e(o3e,J3r),e(uC,Y3r),e(uC,r3e),e(r3e,K3r),e(bo,Z3r),M(pC,bo,null),v(f,$Ke,_),v(f,Ec,_),e(Ec,_C),e(_C,t3e),M(O$,t3e,null),e(Ec,e5r),e(Ec,a3e),e(a3e,o5r),v(f,kKe,_),v(f,er,_),M(V$,er,null),e(er,r5r),e(er,Cc),e(Cc,t5r),e(Cc,TK),e(TK,a5r),e(Cc,n5r),e(Cc,MK),e(MK,s5r),e(Cc,l5r),e(er,i5r),e(er,X$),e(X$,d5r),e(X$,n3e),e(n3e,c5r),e(X$,f5r),e(er,m5r),e(er,qt),M(z$,qt,null),e(qt,g5r),e(qt,s3e),e(s3e,h5r),e(qt,u5r),e(qt,wc),e(wc,p5r),e(wc,l3e),e(l3e,_5r),e(wc,v5r),e(wc,EK),e(EK,b5r),e(wc,F5r),e(qt,T5r),M(vC,qt,null),e(er,M5r),e(er,Fo),M(Q$,Fo,null),e(Fo,E5r),e(Fo,i3e),e(i3e,C5r),e(Fo,w5r),e(Fo,_n),e(_n,A5r),e(_n,d3e),e(d3e,L5r),e(_n,y5r),e(_n,c3e),e(c3e,x5r),e(_n,$5r),e(_n,f3e),e(f3e,k5r),e(_n,S5r),e(Fo,R5r),e(Fo,mt),e(mt,bC),e(bC,m3e),e(m3e,P5r),e(bC,B5r),e(bC,CK),e(CK,I5r),e(bC,N5r),e(mt,q5r),e(mt,FC),e(FC,g3e),e(g3e,j5r),e(FC,D5r),e(FC,wK),e(wK,G5r),e(FC,O5r),e(mt,V5r),e(mt,TC),e(TC,h3e),e(h3e,X5r),e(TC,z5r),e(TC,AK),e(AK,Q5r),e(TC,W5r),e(mt,U5r),e(mt,MC),e(MC,u3e),e(u3e,H5r),e(MC,J5r),e(MC,LK),e(LK,Y5r),e(MC,K5r),e(mt,Z5r),e(mt,EC),e(EC,p3e),e(p3e,e0r),e(EC,o0r),e(EC,yK),e(yK,r0r),e(EC,t0r),e(Fo,a0r),e(Fo,CC),e(CC,n0r),e(CC,_3e),e(_3e,s0r),e(CC,l0r),e(CC,v3e),e(v3e,i0r),e(Fo,d0r),M(wC,Fo,null),v(f,SKe,_),v(f,Ac,_),e(Ac,AC),e(AC,b3e),M(W$,b3e,null),e(Ac,c0r),e(Ac,F3e),e(F3e,f0r),v(f,RKe,_),v(f,or,_),M(U$,or,null),e(or,m0r),e(or,Lc),e(Lc,g0r),e(Lc,xK),e(xK,h0r),e(Lc,u0r),e(Lc,$K),e($K,p0r),e(Lc,_0r),e(or,v0r),e(or,H$),e(H$,b0r),e(H$,T3e),e(T3e,F0r),e(H$,T0r),e(or,M0r),e(or,jt),M(J$,jt,null),e(jt,E0r),e(jt,M3e),e(M3e,C0r),e(jt,w0r),e(jt,yc),e(yc,A0r),e(yc,E3e),e(E3e,L0r),e(yc,y0r),e(yc,kK),e(kK,x0r),e(yc,$0r),e(jt,k0r),M(LC,jt,null),e(or,S0r),e(or,To),M(Y$,To,null),e(To,R0r),e(To,C3e),e(C3e,P0r),e(To,B0r),e(To,vn),e(vn,I0r),e(vn,w3e),e(w3e,N0r),e(vn,q0r),e(vn,A3e),e(A3e,j0r),e(vn,D0r),e(vn,L3e),e(L3e,G0r),e(vn,O0r),e(To,V0r),e(To,bn),e(bn,yC),e(yC,y3e),e(y3e,X0r),e(yC,z0r),e(yC,SK),e(SK,Q0r),e(yC,W0r),e(bn,U0r),e(bn,xC),e(xC,x3e),e(x3e,H0r),e(xC,J0r),e(xC,RK),e(RK,Y0r),e(xC,K0r),e(bn,Z0r),e(bn,$C),e($C,$3e),e($3e,ewr),e($C,owr),e($C,PK),e(PK,rwr),e($C,twr),e(bn,awr),e(bn,kC),e(kC,k3e),e(k3e,nwr),e(kC,swr),e(kC,BK),e(BK,lwr),e(kC,iwr),e(To,dwr),e(To,SC),e(SC,cwr),e(SC,S3e),e(S3e,fwr),e(SC,mwr),e(SC,R3e),e(R3e,gwr),e(To,hwr),M(RC,To,null),v(f,PKe,_),v(f,xc,_),e(xc,PC),e(PC,P3e),M(K$,P3e,null),e(xc,uwr),e(xc,B3e),e(B3e,pwr),v(f,BKe,_),v(f,rr,_),M(Z$,rr,null),e(rr,_wr),e(rr,$c),e($c,vwr),e($c,IK),e(IK,bwr),e($c,Fwr),e($c,NK),e(NK,Twr),e($c,Mwr),e(rr,Ewr),e(rr,ek),e(ek,Cwr),e(ek,I3e),e(I3e,wwr),e(ek,Awr),e(rr,Lwr),e(rr,Dt),M(ok,Dt,null),e(Dt,ywr),e(Dt,N3e),e(N3e,xwr),e(Dt,$wr),e(Dt,kc),e(kc,kwr),e(kc,q3e),e(q3e,Swr),e(kc,Rwr),e(kc,qK),e(qK,Pwr),e(kc,Bwr),e(Dt,Iwr),M(BC,Dt,null),e(rr,Nwr),e(rr,Mo),M(rk,Mo,null),e(Mo,qwr),e(Mo,j3e),e(j3e,jwr),e(Mo,Dwr),e(Mo,Fn),e(Fn,Gwr),e(Fn,D3e),e(D3e,Owr),e(Fn,Vwr),e(Fn,G3e),e(G3e,Xwr),e(Fn,zwr),e(Fn,O3e),e(O3e,Qwr),e(Fn,Wwr),e(Mo,Uwr),e(Mo,tk),e(tk,IC),e(IC,V3e),e(V3e,Hwr),e(IC,Jwr),e(IC,jK),e(jK,Ywr),e(IC,Kwr),e(tk,Zwr),e(tk,NC),e(NC,X3e),e(X3e,eAr),e(NC,oAr),e(NC,DK),e(DK,rAr),e(NC,tAr),e(Mo,aAr),e(Mo,qC),e(qC,nAr),e(qC,z3e),e(z3e,sAr),e(qC,lAr),e(qC,Q3e),e(Q3e,iAr),e(Mo,dAr),M(jC,Mo,null),v(f,IKe,_),v(f,Sc,_),e(Sc,DC),e(DC,W3e),M(ak,W3e,null),e(Sc,cAr),e(Sc,U3e),e(U3e,fAr),v(f,NKe,_),v(f,tr,_),M(nk,tr,null),e(tr,mAr),e(tr,Rc),e(Rc,gAr),e(Rc,GK),e(GK,hAr),e(Rc,uAr),e(Rc,OK),e(OK,pAr),e(Rc,_Ar),e(tr,vAr),e(tr,sk),e(sk,bAr),e(sk,H3e),e(H3e,FAr),e(sk,TAr),e(tr,MAr),e(tr,Gt),M(lk,Gt,null),e(Gt,EAr),e(Gt,J3e),e(J3e,CAr),e(Gt,wAr),e(Gt,Pc),e(Pc,AAr),e(Pc,Y3e),e(Y3e,LAr),e(Pc,yAr),e(Pc,VK),e(VK,xAr),e(Pc,$Ar),e(Gt,kAr),M(GC,Gt,null),e(tr,SAr),e(tr,Eo),M(ik,Eo,null),e(Eo,RAr),e(Eo,K3e),e(K3e,PAr),e(Eo,BAr),e(Eo,Tn),e(Tn,IAr),e(Tn,Z3e),e(Z3e,NAr),e(Tn,qAr),e(Tn,e5e),e(e5e,jAr),e(Tn,DAr),e(Tn,o5e),e(o5e,GAr),e(Tn,OAr),e(Eo,VAr),e(Eo,r5e),e(r5e,OC),e(OC,t5e),e(t5e,XAr),e(OC,zAr),e(OC,XK),e(XK,QAr),e(OC,WAr),e(Eo,UAr),e(Eo,VC),e(VC,HAr),e(VC,a5e),e(a5e,JAr),e(VC,YAr),e(VC,n5e),e(n5e,KAr),e(Eo,ZAr),M(XC,Eo,null),v(f,qKe,_),v(f,Bc,_),e(Bc,zC),e(zC,s5e),M(dk,s5e,null),e(Bc,e6r),e(Bc,l5e),e(l5e,o6r),v(f,jKe,_),v(f,ar,_),M(ck,ar,null),e(ar,r6r),e(ar,Ic),e(Ic,t6r),e(Ic,zK),e(zK,a6r),e(Ic,n6r),e(Ic,QK),e(QK,s6r),e(Ic,l6r),e(ar,i6r),e(ar,fk),e(fk,d6r),e(fk,i5e),e(i5e,c6r),e(fk,f6r),e(ar,m6r),e(ar,Ot),M(mk,Ot,null),e(Ot,g6r),e(Ot,d5e),e(d5e,h6r),e(Ot,u6r),e(Ot,Nc),e(Nc,p6r),e(Nc,c5e),e(c5e,_6r),e(Nc,v6r),e(Nc,WK),e(WK,b6r),e(Nc,F6r),e(Ot,T6r),M(QC,Ot,null),e(ar,M6r),e(ar,Co),M(gk,Co,null),e(Co,E6r),e(Co,f5e),e(f5e,C6r),e(Co,w6r),e(Co,Mn),e(Mn,A6r),e(Mn,m5e),e(m5e,L6r),e(Mn,y6r),e(Mn,g5e),e(g5e,x6r),e(Mn,$6r),e(Mn,h5e),e(h5e,k6r),e(Mn,S6r),e(Co,R6r),e(Co,gt),e(gt,WC),e(WC,u5e),e(u5e,P6r),e(WC,B6r),e(WC,UK),e(UK,I6r),e(WC,N6r),e(gt,q6r),e(gt,UC),e(UC,p5e),e(p5e,j6r),e(UC,D6r),e(UC,HK),e(HK,G6r),e(UC,O6r),e(gt,V6r),e(gt,HC),e(HC,_5e),e(_5e,X6r),e(HC,z6r),e(HC,JK),e(JK,Q6r),e(HC,W6r),e(gt,U6r),e(gt,JC),e(JC,v5e),e(v5e,H6r),e(JC,J6r),e(JC,YK),e(YK,Y6r),e(JC,K6r),e(gt,Z6r),e(gt,YC),e(YC,b5e),e(b5e,e7r),e(YC,o7r),e(YC,KK),e(KK,r7r),e(YC,t7r),e(Co,a7r),e(Co,KC),e(KC,n7r),e(KC,F5e),e(F5e,s7r),e(KC,l7r),e(KC,T5e),e(T5e,i7r),e(Co,d7r),M(ZC,Co,null),v(f,DKe,_),v(f,qc,_),e(qc,e3),e(e3,M5e),M(hk,M5e,null),e(qc,c7r),e(qc,E5e),e(E5e,f7r),v(f,GKe,_),v(f,nr,_),M(uk,nr,null),e(nr,m7r),e(nr,jc),e(jc,g7r),e(jc,ZK),e(ZK,h7r),e(jc,u7r),e(jc,eZ),e(eZ,p7r),e(jc,_7r),e(nr,v7r),e(nr,pk),e(pk,b7r),e(pk,C5e),e(C5e,F7r),e(pk,T7r),e(nr,M7r),e(nr,Vt),M(_k,Vt,null),e(Vt,E7r),e(Vt,w5e),e(w5e,C7r),e(Vt,w7r),e(Vt,Dc),e(Dc,A7r),e(Dc,A5e),e(A5e,L7r),e(Dc,y7r),e(Dc,oZ),e(oZ,x7r),e(Dc,$7r),e(Vt,k7r),M(o3,Vt,null),e(nr,S7r),e(nr,wo),M(vk,wo,null),e(wo,R7r),e(wo,L5e),e(L5e,P7r),e(wo,B7r),e(wo,En),e(En,I7r),e(En,y5e),e(y5e,N7r),e(En,q7r),e(En,x5e),e(x5e,j7r),e(En,D7r),e(En,$5e),e($5e,G7r),e(En,O7r),e(wo,V7r),e(wo,k5e),e(k5e,r3),e(r3,S5e),e(S5e,X7r),e(r3,z7r),e(r3,rZ),e(rZ,Q7r),e(r3,W7r),e(wo,U7r),e(wo,t3),e(t3,H7r),e(t3,R5e),e(R5e,J7r),e(t3,Y7r),e(t3,P5e),e(P5e,K7r),e(wo,Z7r),M(a3,wo,null),v(f,OKe,_),v(f,Gc,_),e(Gc,n3),e(n3,B5e),M(bk,B5e,null),e(Gc,eLr),e(Gc,I5e),e(I5e,oLr),v(f,VKe,_),v(f,sr,_),M(Fk,sr,null),e(sr,rLr),e(sr,Oc),e(Oc,tLr),e(Oc,tZ),e(tZ,aLr),e(Oc,nLr),e(Oc,aZ),e(aZ,sLr),e(Oc,lLr),e(sr,iLr),e(sr,Tk),e(Tk,dLr),e(Tk,N5e),e(N5e,cLr),e(Tk,fLr),e(sr,mLr),e(sr,Xt),M(Mk,Xt,null),e(Xt,gLr),e(Xt,q5e),e(q5e,hLr),e(Xt,uLr),e(Xt,Vc),e(Vc,pLr),e(Vc,j5e),e(j5e,_Lr),e(Vc,vLr),e(Vc,nZ),e(nZ,bLr),e(Vc,FLr),e(Xt,TLr),M(s3,Xt,null),e(sr,MLr),e(sr,Ir),M(Ek,Ir,null),e(Ir,ELr),e(Ir,D5e),e(D5e,CLr),e(Ir,wLr),e(Ir,Cn),e(Cn,ALr),e(Cn,G5e),e(G5e,LLr),e(Cn,yLr),e(Cn,O5e),e(O5e,xLr),e(Cn,$Lr),e(Cn,V5e),e(V5e,kLr),e(Cn,SLr),e(Ir,RLr),e(Ir,N),e(N,l3),e(l3,X5e),e(X5e,PLr),e(l3,BLr),e(l3,sZ),e(sZ,ILr),e(l3,NLr),e(N,qLr),e(N,i3),e(i3,z5e),e(z5e,jLr),e(i3,DLr),e(i3,lZ),e(lZ,GLr),e(i3,OLr),e(N,VLr),e(N,d3),e(d3,Q5e),e(Q5e,XLr),e(d3,zLr),e(d3,iZ),e(iZ,QLr),e(d3,WLr),e(N,ULr),e(N,c3),e(c3,W5e),e(W5e,HLr),e(c3,JLr),e(c3,dZ),e(dZ,YLr),e(c3,KLr),e(N,ZLr),e(N,f3),e(f3,U5e),e(U5e,eyr),e(f3,oyr),e(f3,cZ),e(cZ,ryr),e(f3,tyr),e(N,ayr),e(N,m3),e(m3,H5e),e(H5e,nyr),e(m3,syr),e(m3,fZ),e(fZ,lyr),e(m3,iyr),e(N,dyr),e(N,g3),e(g3,J5e),e(J5e,cyr),e(g3,fyr),e(g3,mZ),e(mZ,myr),e(g3,gyr),e(N,hyr),e(N,h3),e(h3,Y5e),e(Y5e,uyr),e(h3,pyr),e(h3,gZ),e(gZ,_yr),e(h3,vyr),e(N,byr),e(N,u3),e(u3,K5e),e(K5e,Fyr),e(u3,Tyr),e(u3,hZ),e(hZ,Myr),e(u3,Eyr),e(N,Cyr),e(N,p3),e(p3,Z5e),e(Z5e,wyr),e(p3,Ayr),e(p3,uZ),e(uZ,Lyr),e(p3,yyr),e(N,xyr),e(N,_3),e(_3,e0e),e(e0e,$yr),e(_3,kyr),e(_3,pZ),e(pZ,Syr),e(_3,Ryr),e(N,Pyr),e(N,v3),e(v3,o0e),e(o0e,Byr),e(v3,Iyr),e(v3,_Z),e(_Z,Nyr),e(v3,qyr),e(N,jyr),e(N,b3),e(b3,r0e),e(r0e,Dyr),e(b3,Gyr),e(b3,vZ),e(vZ,Oyr),e(b3,Vyr),e(N,Xyr),e(N,F3),e(F3,t0e),e(t0e,zyr),e(F3,Qyr),e(F3,bZ),e(bZ,Wyr),e(F3,Uyr),e(N,Hyr),e(N,T3),e(T3,a0e),e(a0e,Jyr),e(T3,Yyr),e(T3,FZ),e(FZ,Kyr),e(T3,Zyr),e(N,e8r),e(N,M3),e(M3,n0e),e(n0e,o8r),e(M3,r8r),e(M3,TZ),e(TZ,t8r),e(M3,a8r),e(N,n8r),e(N,E3),e(E3,s0e),e(s0e,s8r),e(E3,l8r),e(E3,MZ),e(MZ,i8r),e(E3,d8r),e(N,c8r),e(N,C3),e(C3,l0e),e(l0e,f8r),e(C3,m8r),e(C3,EZ),e(EZ,g8r),e(C3,h8r),e(N,u8r),e(N,bl),e(bl,i0e),e(i0e,p8r),e(bl,_8r),e(bl,CZ),e(CZ,v8r),e(bl,b8r),e(bl,wZ),e(wZ,F8r),e(bl,T8r),e(N,M8r),e(N,w3),e(w3,d0e),e(d0e,E8r),e(w3,C8r),e(w3,AZ),e(AZ,w8r),e(w3,A8r),e(N,L8r),e(N,A3),e(A3,c0e),e(c0e,y8r),e(A3,x8r),e(A3,LZ),e(LZ,$8r),e(A3,k8r),e(N,S8r),e(N,L3),e(L3,f0e),e(f0e,R8r),e(L3,P8r),e(L3,yZ),e(yZ,B8r),e(L3,I8r),e(N,N8r),e(N,y3),e(y3,m0e),e(m0e,q8r),e(y3,j8r),e(y3,xZ),e(xZ,D8r),e(y3,G8r),e(N,O8r),e(N,x3),e(x3,g0e),e(g0e,V8r),e(x3,X8r),e(x3,$Z),e($Z,z8r),e(x3,Q8r),e(N,W8r),e(N,$3),e($3,h0e),e(h0e,U8r),e($3,H8r),e($3,kZ),e(kZ,J8r),e($3,Y8r),e(N,K8r),e(N,k3),e(k3,u0e),e(u0e,Z8r),e(k3,e9r),e(k3,SZ),e(SZ,o9r),e(k3,r9r),e(N,t9r),e(N,S3),e(S3,p0e),e(p0e,a9r),e(S3,n9r),e(S3,RZ),e(RZ,s9r),e(S3,l9r),e(N,i9r),e(N,R3),e(R3,_0e),e(_0e,d9r),e(R3,c9r),e(R3,PZ),e(PZ,f9r),e(R3,m9r),e(N,g9r),e(N,P3),e(P3,v0e),e(v0e,h9r),e(P3,u9r),e(P3,BZ),e(BZ,p9r),e(P3,_9r),e(N,v9r),e(N,B3),e(B3,b0e),e(b0e,b9r),e(B3,F9r),e(B3,IZ),e(IZ,T9r),e(B3,M9r),e(N,E9r),e(N,I3),e(I3,F0e),e(F0e,C9r),e(I3,w9r),e(I3,NZ),e(NZ,A9r),e(I3,L9r),e(N,y9r),e(N,N3),e(N3,T0e),e(T0e,x9r),e(N3,$9r),e(N3,qZ),e(qZ,k9r),e(N3,S9r),e(N,R9r),e(N,q3),e(q3,M0e),e(M0e,P9r),e(q3,B9r),e(q3,jZ),e(jZ,I9r),e(q3,N9r),e(N,q9r),e(N,j3),e(j3,E0e),e(E0e,j9r),e(j3,D9r),e(j3,DZ),e(DZ,G9r),e(j3,O9r),e(N,V9r),e(N,D3),e(D3,C0e),e(C0e,X9r),e(D3,z9r),e(D3,GZ),e(GZ,Q9r),e(D3,W9r),e(N,U9r),e(N,G3),e(G3,w0e),e(w0e,H9r),e(G3,J9r),e(G3,OZ),e(OZ,Y9r),e(G3,K9r),e(N,Z9r),e(N,O3),e(O3,A0e),e(A0e,exr),e(O3,oxr),e(O3,VZ),e(VZ,rxr),e(O3,txr),e(N,axr),e(N,V3),e(V3,L0e),e(L0e,nxr),e(V3,sxr),e(V3,XZ),e(XZ,lxr),e(V3,ixr),e(N,dxr),e(N,X3),e(X3,y0e),e(y0e,cxr),e(X3,fxr),e(X3,zZ),e(zZ,mxr),e(X3,gxr),e(N,hxr),e(N,z3),e(z3,x0e),e(x0e,uxr),e(z3,pxr),e(z3,QZ),e(QZ,_xr),e(z3,vxr),e(N,bxr),e(N,Q3),e(Q3,$0e),e($0e,Fxr),e(Q3,Txr),e(Q3,WZ),e(WZ,Mxr),e(Q3,Exr),e(N,Cxr),e(N,W3),e(W3,k0e),e(k0e,wxr),e(W3,Axr),e(W3,UZ),e(UZ,Lxr),e(W3,yxr),e(N,xxr),e(N,U3),e(U3,S0e),e(S0e,$xr),e(U3,kxr),e(U3,HZ),e(HZ,Sxr),e(U3,Rxr),e(N,Pxr),e(N,H3),e(H3,R0e),e(R0e,Bxr),e(H3,Ixr),e(H3,JZ),e(JZ,Nxr),e(H3,qxr),e(N,jxr),e(N,J3),e(J3,P0e),e(P0e,Dxr),e(J3,Gxr),e(J3,YZ),e(YZ,Oxr),e(J3,Vxr),e(N,Xxr),e(N,Y3),e(Y3,B0e),e(B0e,zxr),e(Y3,Qxr),e(Y3,KZ),e(KZ,Wxr),e(Y3,Uxr),e(N,Hxr),e(N,K3),e(K3,I0e),e(I0e,Jxr),e(K3,Yxr),e(K3,ZZ),e(ZZ,Kxr),e(K3,Zxr),e(N,e$r),e(N,Z3),e(Z3,N0e),e(N0e,o$r),e(Z3,r$r),e(Z3,eee),e(eee,t$r),e(Z3,a$r),e(N,n$r),e(N,e5),e(e5,q0e),e(q0e,s$r),e(e5,l$r),e(e5,oee),e(oee,i$r),e(e5,d$r),e(N,c$r),e(N,o5),e(o5,j0e),e(j0e,f$r),e(o5,m$r),e(o5,ree),e(ree,g$r),e(o5,h$r),e(N,u$r),e(N,r5),e(r5,D0e),e(D0e,p$r),e(r5,_$r),e(r5,tee),e(tee,v$r),e(r5,b$r),e(N,F$r),e(N,t5),e(t5,G0e),e(G0e,T$r),e(t5,M$r),e(t5,aee),e(aee,E$r),e(t5,C$r),e(N,w$r),e(N,a5),e(a5,O0e),e(O0e,A$r),e(a5,L$r),e(a5,nee),e(nee,y$r),e(a5,x$r),e(N,$$r),e(N,n5),e(n5,V0e),e(V0e,k$r),e(n5,S$r),e(n5,see),e(see,R$r),e(n5,P$r),e(Ir,B$r),M(s5,Ir,null),v(f,XKe,_),v(f,Xc,_),e(Xc,l5),e(l5,X0e),M(Ck,X0e,null),e(Xc,I$r),e(Xc,z0e),e(z0e,N$r),v(f,zKe,_),v(f,lr,_),M(wk,lr,null),e(lr,q$r),e(lr,zc),e(zc,j$r),e(zc,lee),e(lee,D$r),e(zc,G$r),e(zc,iee),e(iee,O$r),e(zc,V$r),e(lr,X$r),e(lr,Ak),e(Ak,z$r),e(Ak,Q0e),e(Q0e,Q$r),e(Ak,W$r),e(lr,U$r),e(lr,zt),M(Lk,zt,null),e(zt,H$r),e(zt,W0e),e(W0e,J$r),e(zt,Y$r),e(zt,Qc),e(Qc,K$r),e(Qc,U0e),e(U0e,Z$r),e(Qc,ekr),e(Qc,dee),e(dee,okr),e(Qc,rkr),e(zt,tkr),M(i5,zt,null),e(lr,akr),e(lr,Nr),M(yk,Nr,null),e(Nr,nkr),e(Nr,H0e),e(H0e,skr),e(Nr,lkr),e(Nr,wn),e(wn,ikr),e(wn,J0e),e(J0e,dkr),e(wn,ckr),e(wn,Y0e),e(Y0e,fkr),e(wn,mkr),e(wn,K0e),e(K0e,gkr),e(wn,hkr),e(Nr,ukr),e(Nr,se),e(se,d5),e(d5,Z0e),e(Z0e,pkr),e(d5,_kr),e(d5,cee),e(cee,vkr),e(d5,bkr),e(se,Fkr),e(se,c5),e(c5,ewe),e(ewe,Tkr),e(c5,Mkr),e(c5,fee),e(fee,Ekr),e(c5,Ckr),e(se,wkr),e(se,f5),e(f5,owe),e(owe,Akr),e(f5,Lkr),e(f5,mee),e(mee,ykr),e(f5,xkr),e(se,$kr),e(se,m5),e(m5,rwe),e(rwe,kkr),e(m5,Skr),e(m5,gee),e(gee,Rkr),e(m5,Pkr),e(se,Bkr),e(se,g5),e(g5,twe),e(twe,Ikr),e(g5,Nkr),e(g5,hee),e(hee,qkr),e(g5,jkr),e(se,Dkr),e(se,h5),e(h5,awe),e(awe,Gkr),e(h5,Okr),e(h5,uee),e(uee,Vkr),e(h5,Xkr),e(se,zkr),e(se,u5),e(u5,nwe),e(nwe,Qkr),e(u5,Wkr),e(u5,pee),e(pee,Ukr),e(u5,Hkr),e(se,Jkr),e(se,p5),e(p5,swe),e(swe,Ykr),e(p5,Kkr),e(p5,_ee),e(_ee,Zkr),e(p5,eSr),e(se,oSr),e(se,_5),e(_5,lwe),e(lwe,rSr),e(_5,tSr),e(_5,vee),e(vee,aSr),e(_5,nSr),e(se,sSr),e(se,v5),e(v5,iwe),e(iwe,lSr),e(v5,iSr),e(v5,bee),e(bee,dSr),e(v5,cSr),e(se,fSr),e(se,b5),e(b5,dwe),e(dwe,mSr),e(b5,gSr),e(b5,Fee),e(Fee,hSr),e(b5,uSr),e(se,pSr),e(se,F5),e(F5,cwe),e(cwe,_Sr),e(F5,vSr),e(F5,Tee),e(Tee,bSr),e(F5,FSr),e(se,TSr),e(se,T5),e(T5,fwe),e(fwe,MSr),e(T5,ESr),e(T5,Mee),e(Mee,CSr),e(T5,wSr),e(se,ASr),e(se,M5),e(M5,mwe),e(mwe,LSr),e(M5,ySr),e(M5,Eee),e(Eee,xSr),e(M5,$Sr),e(se,kSr),e(se,E5),e(E5,gwe),e(gwe,SSr),e(E5,RSr),e(E5,Cee),e(Cee,PSr),e(E5,BSr),e(se,ISr),e(se,C5),e(C5,hwe),e(hwe,NSr),e(C5,qSr),e(C5,wee),e(wee,jSr),e(C5,DSr),e(se,GSr),e(se,w5),e(w5,uwe),e(uwe,OSr),e(w5,VSr),e(w5,Aee),e(Aee,XSr),e(w5,zSr),e(se,QSr),e(se,A5),e(A5,pwe),e(pwe,WSr),e(A5,USr),e(A5,Lee),e(Lee,HSr),e(A5,JSr),e(se,YSr),e(se,L5),e(L5,_we),e(_we,KSr),e(L5,ZSr),e(L5,yee),e(yee,eRr),e(L5,oRr),e(se,rRr),e(se,y5),e(y5,vwe),e(vwe,tRr),e(y5,aRr),e(y5,xee),e(xee,nRr),e(y5,sRr),e(se,lRr),e(se,x5),e(x5,bwe),e(bwe,iRr),e(x5,dRr),e(x5,$ee),e($ee,cRr),e(x5,fRr),e(se,mRr),e(se,$5),e($5,Fwe),e(Fwe,gRr),e($5,hRr),e($5,kee),e(kee,uRr),e($5,pRr),e(se,_Rr),e(se,k5),e(k5,Twe),e(Twe,vRr),e(k5,bRr),e(k5,See),e(See,FRr),e(k5,TRr),e(Nr,MRr),M(S5,Nr,null),v(f,QKe,_),v(f,Wc,_),e(Wc,R5),e(R5,Mwe),M(xk,Mwe,null),e(Wc,ERr),e(Wc,Ewe),e(Ewe,CRr),v(f,WKe,_),v(f,ir,_),M($k,ir,null),e(ir,wRr),e(ir,Uc),e(Uc,ARr),e(Uc,Ree),e(Ree,LRr),e(Uc,yRr),e(Uc,Pee),e(Pee,xRr),e(Uc,$Rr),e(ir,kRr),e(ir,kk),e(kk,SRr),e(kk,Cwe),e(Cwe,RRr),e(kk,PRr),e(ir,BRr),e(ir,Qt),M(Sk,Qt,null),e(Qt,IRr),e(Qt,wwe),e(wwe,NRr),e(Qt,qRr),e(Qt,Hc),e(Hc,jRr),e(Hc,Awe),e(Awe,DRr),e(Hc,GRr),e(Hc,Bee),e(Bee,ORr),e(Hc,VRr),e(Qt,XRr),M(P5,Qt,null),e(ir,zRr),e(ir,qr),M(Rk,qr,null),e(qr,QRr),e(qr,Lwe),e(Lwe,WRr),e(qr,URr),e(qr,An),e(An,HRr),e(An,ywe),e(ywe,JRr),e(An,YRr),e(An,xwe),e(xwe,KRr),e(An,ZRr),e(An,$we),e($we,ePr),e(An,oPr),e(qr,rPr),e(qr,Me),e(Me,B5),e(B5,kwe),e(kwe,tPr),e(B5,aPr),e(B5,Iee),e(Iee,nPr),e(B5,sPr),e(Me,lPr),e(Me,I5),e(I5,Swe),e(Swe,iPr),e(I5,dPr),e(I5,Nee),e(Nee,cPr),e(I5,fPr),e(Me,mPr),e(Me,N5),e(N5,Rwe),e(Rwe,gPr),e(N5,hPr),e(N5,qee),e(qee,uPr),e(N5,pPr),e(Me,_Pr),e(Me,q5),e(q5,Pwe),e(Pwe,vPr),e(q5,bPr),e(q5,jee),e(jee,FPr),e(q5,TPr),e(Me,MPr),e(Me,j5),e(j5,Bwe),e(Bwe,EPr),e(j5,CPr),e(j5,Dee),e(Dee,wPr),e(j5,APr),e(Me,LPr),e(Me,D5),e(D5,Iwe),e(Iwe,yPr),e(D5,xPr),e(D5,Gee),e(Gee,$Pr),e(D5,kPr),e(Me,SPr),e(Me,G5),e(G5,Nwe),e(Nwe,RPr),e(G5,PPr),e(G5,Oee),e(Oee,BPr),e(G5,IPr),e(Me,NPr),e(Me,O5),e(O5,qwe),e(qwe,qPr),e(O5,jPr),e(O5,Vee),e(Vee,DPr),e(O5,GPr),e(Me,OPr),e(Me,V5),e(V5,jwe),e(jwe,VPr),e(V5,XPr),e(V5,Xee),e(Xee,zPr),e(V5,QPr),e(Me,WPr),e(Me,X5),e(X5,Dwe),e(Dwe,UPr),e(X5,HPr),e(X5,zee),e(zee,JPr),e(X5,YPr),e(Me,KPr),e(Me,z5),e(z5,Gwe),e(Gwe,ZPr),e(z5,eBr),e(z5,Qee),e(Qee,oBr),e(z5,rBr),e(Me,tBr),e(Me,Q5),e(Q5,Owe),e(Owe,aBr),e(Q5,nBr),e(Q5,Wee),e(Wee,sBr),e(Q5,lBr),e(Me,iBr),e(Me,W5),e(W5,Vwe),e(Vwe,dBr),e(W5,cBr),e(W5,Uee),e(Uee,fBr),e(W5,mBr),e(Me,gBr),e(Me,U5),e(U5,Xwe),e(Xwe,hBr),e(U5,uBr),e(U5,Hee),e(Hee,pBr),e(U5,_Br),e(qr,vBr),M(H5,qr,null),v(f,UKe,_),v(f,Jc,_),e(Jc,J5),e(J5,zwe),M(Pk,zwe,null),e(Jc,bBr),e(Jc,Qwe),e(Qwe,FBr),v(f,HKe,_),v(f,dr,_),M(Bk,dr,null),e(dr,TBr),e(dr,Yc),e(Yc,MBr),e(Yc,Jee),e(Jee,EBr),e(Yc,CBr),e(Yc,Yee),e(Yee,wBr),e(Yc,ABr),e(dr,LBr),e(dr,Ik),e(Ik,yBr),e(Ik,Wwe),e(Wwe,xBr),e(Ik,$Br),e(dr,kBr),e(dr,Wt),M(Nk,Wt,null),e(Wt,SBr),e(Wt,Uwe),e(Uwe,RBr),e(Wt,PBr),e(Wt,Kc),e(Kc,BBr),e(Kc,Hwe),e(Hwe,IBr),e(Kc,NBr),e(Kc,Kee),e(Kee,qBr),e(Kc,jBr),e(Wt,DBr),M(Y5,Wt,null),e(dr,GBr),e(dr,jr),M(qk,jr,null),e(jr,OBr),e(jr,Jwe),e(Jwe,VBr),e(jr,XBr),e(jr,Ln),e(Ln,zBr),e(Ln,Ywe),e(Ywe,QBr),e(Ln,WBr),e(Ln,Kwe),e(Kwe,UBr),e(Ln,HBr),e(Ln,Zwe),e(Zwe,JBr),e(Ln,YBr),e(jr,KBr),e(jr,Be),e(Be,K5),e(K5,eAe),e(eAe,ZBr),e(K5,eIr),e(K5,Zee),e(Zee,oIr),e(K5,rIr),e(Be,tIr),e(Be,Z5),e(Z5,oAe),e(oAe,aIr),e(Z5,nIr),e(Z5,eoe),e(eoe,sIr),e(Z5,lIr),e(Be,iIr),e(Be,Fl),e(Fl,rAe),e(rAe,dIr),e(Fl,cIr),e(Fl,ooe),e(ooe,fIr),e(Fl,mIr),e(Fl,roe),e(roe,gIr),e(Fl,hIr),e(Be,uIr),e(Be,e0),e(e0,tAe),e(tAe,pIr),e(e0,_Ir),e(e0,toe),e(toe,vIr),e(e0,bIr),e(Be,FIr),e(Be,o0),e(o0,aAe),e(aAe,TIr),e(o0,MIr),e(o0,aoe),e(aoe,EIr),e(o0,CIr),e(Be,wIr),e(Be,r0),e(r0,nAe),e(nAe,AIr),e(r0,LIr),e(r0,noe),e(noe,yIr),e(r0,xIr),e(Be,$Ir),e(Be,t0),e(t0,sAe),e(sAe,kIr),e(t0,SIr),e(t0,soe),e(soe,RIr),e(t0,PIr),e(Be,BIr),e(Be,a0),e(a0,lAe),e(lAe,IIr),e(a0,NIr),e(a0,loe),e(loe,qIr),e(a0,jIr),e(Be,DIr),e(Be,n0),e(n0,iAe),e(iAe,GIr),e(n0,OIr),e(n0,ioe),e(ioe,VIr),e(n0,XIr),e(jr,zIr),M(s0,jr,null),v(f,JKe,_),v(f,Zc,_),e(Zc,l0),e(l0,dAe),M(jk,dAe,null),e(Zc,QIr),e(Zc,cAe),e(cAe,WIr),v(f,YKe,_),v(f,cr,_),M(Dk,cr,null),e(cr,UIr),e(cr,ef),e(ef,HIr),e(ef,doe),e(doe,JIr),e(ef,YIr),e(ef,coe),e(coe,KIr),e(ef,ZIr),e(cr,eNr),e(cr,Gk),e(Gk,oNr),e(Gk,fAe),e(fAe,rNr),e(Gk,tNr),e(cr,aNr),e(cr,Ut),M(Ok,Ut,null),e(Ut,nNr),e(Ut,mAe),e(mAe,sNr),e(Ut,lNr),e(Ut,of),e(of,iNr),e(of,gAe),e(gAe,dNr),e(of,cNr),e(of,foe),e(foe,fNr),e(of,mNr),e(Ut,gNr),M(i0,Ut,null),e(cr,hNr),e(cr,Dr),M(Vk,Dr,null),e(Dr,uNr),e(Dr,hAe),e(hAe,pNr),e(Dr,_Nr),e(Dr,yn),e(yn,vNr),e(yn,uAe),e(uAe,bNr),e(yn,FNr),e(yn,pAe),e(pAe,TNr),e(yn,MNr),e(yn,_Ae),e(_Ae,ENr),e(yn,CNr),e(Dr,wNr),e(Dr,rf),e(rf,d0),e(d0,vAe),e(vAe,ANr),e(d0,LNr),e(d0,moe),e(moe,yNr),e(d0,xNr),e(rf,$Nr),e(rf,c0),e(c0,bAe),e(bAe,kNr),e(c0,SNr),e(c0,goe),e(goe,RNr),e(c0,PNr),e(rf,BNr),e(rf,f0),e(f0,FAe),e(FAe,INr),e(f0,NNr),e(f0,hoe),e(hoe,qNr),e(f0,jNr),e(Dr,DNr),M(m0,Dr,null),v(f,KKe,_),v(f,tf,_),e(tf,g0),e(g0,TAe),M(Xk,TAe,null),e(tf,GNr),e(tf,MAe),e(MAe,ONr),v(f,ZKe,_),v(f,fr,_),M(zk,fr,null),e(fr,VNr),e(fr,af),e(af,XNr),e(af,uoe),e(uoe,zNr),e(af,QNr),e(af,poe),e(poe,WNr),e(af,UNr),e(fr,HNr),e(fr,Qk),e(Qk,JNr),e(Qk,EAe),e(EAe,YNr),e(Qk,KNr),e(fr,ZNr),e(fr,Ht),M(Wk,Ht,null),e(Ht,eqr),e(Ht,CAe),e(CAe,oqr),e(Ht,rqr),e(Ht,nf),e(nf,tqr),e(nf,wAe),e(wAe,aqr),e(nf,nqr),e(nf,_oe),e(_oe,sqr),e(nf,lqr),e(Ht,iqr),M(h0,Ht,null),e(fr,dqr),e(fr,Gr),M(Uk,Gr,null),e(Gr,cqr),e(Gr,AAe),e(AAe,fqr),e(Gr,mqr),e(Gr,xn),e(xn,gqr),e(xn,LAe),e(LAe,hqr),e(xn,uqr),e(xn,yAe),e(yAe,pqr),e(xn,_qr),e(xn,xAe),e(xAe,vqr),e(xn,bqr),e(Gr,Fqr),e(Gr,me),e(me,u0),e(u0,$Ae),e($Ae,Tqr),e(u0,Mqr),e(u0,voe),e(voe,Eqr),e(u0,Cqr),e(me,wqr),e(me,p0),e(p0,kAe),e(kAe,Aqr),e(p0,Lqr),e(p0,boe),e(boe,yqr),e(p0,xqr),e(me,$qr),e(me,_0),e(_0,SAe),e(SAe,kqr),e(_0,Sqr),e(_0,Foe),e(Foe,Rqr),e(_0,Pqr),e(me,Bqr),e(me,v0),e(v0,RAe),e(RAe,Iqr),e(v0,Nqr),e(v0,Toe),e(Toe,qqr),e(v0,jqr),e(me,Dqr),e(me,b0),e(b0,PAe),e(PAe,Gqr),e(b0,Oqr),e(b0,Moe),e(Moe,Vqr),e(b0,Xqr),e(me,zqr),e(me,F0),e(F0,BAe),e(BAe,Qqr),e(F0,Wqr),e(F0,Eoe),e(Eoe,Uqr),e(F0,Hqr),e(me,Jqr),e(me,T0),e(T0,IAe),e(IAe,Yqr),e(T0,Kqr),e(T0,Coe),e(Coe,Zqr),e(T0,ejr),e(me,ojr),e(me,M0),e(M0,NAe),e(NAe,rjr),e(M0,tjr),e(M0,woe),e(woe,ajr),e(M0,njr),e(me,sjr),e(me,E0),e(E0,qAe),e(qAe,ljr),e(E0,ijr),e(E0,Aoe),e(Aoe,djr),e(E0,cjr),e(me,fjr),e(me,C0),e(C0,jAe),e(jAe,mjr),e(C0,gjr),e(C0,Loe),e(Loe,hjr),e(C0,ujr),e(me,pjr),e(me,w0),e(w0,DAe),e(DAe,_jr),e(w0,vjr),e(w0,yoe),e(yoe,bjr),e(w0,Fjr),e(me,Tjr),e(me,A0),e(A0,GAe),e(GAe,Mjr),e(A0,Ejr),e(A0,xoe),e(xoe,Cjr),e(A0,wjr),e(me,Ajr),e(me,L0),e(L0,OAe),e(OAe,Ljr),e(L0,yjr),e(L0,$oe),e($oe,xjr),e(L0,$jr),e(me,kjr),e(me,y0),e(y0,VAe),e(VAe,Sjr),e(y0,Rjr),e(y0,koe),e(koe,Pjr),e(y0,Bjr),e(me,Ijr),e(me,x0),e(x0,XAe),e(XAe,Njr),e(x0,qjr),e(x0,Soe),e(Soe,jjr),e(x0,Djr),e(me,Gjr),e(me,$0),e($0,zAe),e(zAe,Ojr),e($0,Vjr),e($0,Roe),e(Roe,Xjr),e($0,zjr),e(me,Qjr),e(me,k0),e(k0,QAe),e(QAe,Wjr),e(k0,Ujr),e(k0,Poe),e(Poe,Hjr),e(k0,Jjr),e(me,Yjr),e(me,S0),e(S0,WAe),e(WAe,Kjr),e(S0,Zjr),e(S0,Boe),e(Boe,eDr),e(S0,oDr),e(me,rDr),e(me,R0),e(R0,UAe),e(UAe,tDr),e(R0,aDr),e(R0,Ioe),e(Ioe,nDr),e(R0,sDr),e(me,lDr),e(me,P0),e(P0,HAe),e(HAe,iDr),e(P0,dDr),e(P0,Noe),e(Noe,cDr),e(P0,fDr),e(Gr,mDr),M(B0,Gr,null),v(f,eZe,_),v(f,sf,_),e(sf,I0),e(I0,JAe),M(Hk,JAe,null),e(sf,gDr),e(sf,YAe),e(YAe,hDr),v(f,oZe,_),v(f,mr,_),M(Jk,mr,null),e(mr,uDr),e(mr,lf),e(lf,pDr),e(lf,qoe),e(qoe,_Dr),e(lf,vDr),e(lf,joe),e(joe,bDr),e(lf,FDr),e(mr,TDr),e(mr,Yk),e(Yk,MDr),e(Yk,KAe),e(KAe,EDr),e(Yk,CDr),e(mr,wDr),e(mr,Jt),M(Kk,Jt,null),e(Jt,ADr),e(Jt,ZAe),e(ZAe,LDr),e(Jt,yDr),e(Jt,df),e(df,xDr),e(df,e6e),e(e6e,$Dr),e(df,kDr),e(df,Doe),e(Doe,SDr),e(df,RDr),e(Jt,PDr),M(N0,Jt,null),e(mr,BDr),e(mr,Or),M(Zk,Or,null),e(Or,IDr),e(Or,o6e),e(o6e,NDr),e(Or,qDr),e(Or,$n),e($n,jDr),e($n,r6e),e(r6e,DDr),e($n,GDr),e($n,t6e),e(t6e,ODr),e($n,VDr),e($n,a6e),e(a6e,XDr),e($n,zDr),e(Or,QDr),e(Or,ye),e(ye,q0),e(q0,n6e),e(n6e,WDr),e(q0,UDr),e(q0,Goe),e(Goe,HDr),e(q0,JDr),e(ye,YDr),e(ye,j0),e(j0,s6e),e(s6e,KDr),e(j0,ZDr),e(j0,Ooe),e(Ooe,eGr),e(j0,oGr),e(ye,rGr),e(ye,D0),e(D0,l6e),e(l6e,tGr),e(D0,aGr),e(D0,Voe),e(Voe,nGr),e(D0,sGr),e(ye,lGr),e(ye,G0),e(G0,i6e),e(i6e,iGr),e(G0,dGr),e(G0,Xoe),e(Xoe,cGr),e(G0,fGr),e(ye,mGr),e(ye,O0),e(O0,d6e),e(d6e,gGr),e(O0,hGr),e(O0,zoe),e(zoe,uGr),e(O0,pGr),e(ye,_Gr),e(ye,V0),e(V0,c6e),e(c6e,vGr),e(V0,bGr),e(V0,Qoe),e(Qoe,FGr),e(V0,TGr),e(ye,MGr),e(ye,X0),e(X0,f6e),e(f6e,EGr),e(X0,CGr),e(X0,Woe),e(Woe,wGr),e(X0,AGr),e(ye,LGr),e(ye,z0),e(z0,m6e),e(m6e,yGr),e(z0,xGr),e(z0,Uoe),e(Uoe,$Gr),e(z0,kGr),e(ye,SGr),e(ye,Q0),e(Q0,g6e),e(g6e,RGr),e(Q0,PGr),e(Q0,Hoe),e(Hoe,BGr),e(Q0,IGr),e(ye,NGr),e(ye,W0),e(W0,h6e),e(h6e,qGr),e(W0,jGr),e(W0,Joe),e(Joe,DGr),e(W0,GGr),e(Or,OGr),M(U0,Or,null),v(f,rZe,_),v(f,cf,_),e(cf,H0),e(H0,u6e),M(eS,u6e,null),e(cf,VGr),e(cf,p6e),e(p6e,XGr),v(f,tZe,_),v(f,gr,_),M(oS,gr,null),e(gr,zGr),e(gr,ff),e(ff,QGr),e(ff,Yoe),e(Yoe,WGr),e(ff,UGr),e(ff,Koe),e(Koe,HGr),e(ff,JGr),e(gr,YGr),e(gr,rS),e(rS,KGr),e(rS,_6e),e(_6e,ZGr),e(rS,eOr),e(gr,oOr),e(gr,Yt),M(tS,Yt,null),e(Yt,rOr),e(Yt,v6e),e(v6e,tOr),e(Yt,aOr),e(Yt,mf),e(mf,nOr),e(mf,b6e),e(b6e,sOr),e(mf,lOr),e(mf,Zoe),e(Zoe,iOr),e(mf,dOr),e(Yt,cOr),M(J0,Yt,null),e(gr,fOr),e(gr,Vr),M(aS,Vr,null),e(Vr,mOr),e(Vr,F6e),e(F6e,gOr),e(Vr,hOr),e(Vr,kn),e(kn,uOr),e(kn,T6e),e(T6e,pOr),e(kn,_Or),e(kn,M6e),e(M6e,vOr),e(kn,bOr),e(kn,E6e),e(E6e,FOr),e(kn,TOr),e(Vr,MOr),e(Vr,re),e(re,Y0),e(Y0,C6e),e(C6e,EOr),e(Y0,COr),e(Y0,ere),e(ere,wOr),e(Y0,AOr),e(re,LOr),e(re,K0),e(K0,w6e),e(w6e,yOr),e(K0,xOr),e(K0,ore),e(ore,$Or),e(K0,kOr),e(re,SOr),e(re,Z0),e(Z0,A6e),e(A6e,ROr),e(Z0,POr),e(Z0,rre),e(rre,BOr),e(Z0,IOr),e(re,NOr),e(re,ew),e(ew,L6e),e(L6e,qOr),e(ew,jOr),e(ew,tre),e(tre,DOr),e(ew,GOr),e(re,OOr),e(re,ow),e(ow,y6e),e(y6e,VOr),e(ow,XOr),e(ow,are),e(are,zOr),e(ow,QOr),e(re,WOr),e(re,rw),e(rw,x6e),e(x6e,UOr),e(rw,HOr),e(rw,nre),e(nre,JOr),e(rw,YOr),e(re,KOr),e(re,tw),e(tw,$6e),e($6e,ZOr),e(tw,eVr),e(tw,sre),e(sre,oVr),e(tw,rVr),e(re,tVr),e(re,aw),e(aw,k6e),e(k6e,aVr),e(aw,nVr),e(aw,lre),e(lre,sVr),e(aw,lVr),e(re,iVr),e(re,nw),e(nw,S6e),e(S6e,dVr),e(nw,cVr),e(nw,ire),e(ire,fVr),e(nw,mVr),e(re,gVr),e(re,sw),e(sw,R6e),e(R6e,hVr),e(sw,uVr),e(sw,dre),e(dre,pVr),e(sw,_Vr),e(re,vVr),e(re,lw),e(lw,P6e),e(P6e,bVr),e(lw,FVr),e(lw,cre),e(cre,TVr),e(lw,MVr),e(re,EVr),e(re,iw),e(iw,B6e),e(B6e,CVr),e(iw,wVr),e(iw,fre),e(fre,AVr),e(iw,LVr),e(re,yVr),e(re,dw),e(dw,I6e),e(I6e,xVr),e(dw,$Vr),e(dw,mre),e(mre,kVr),e(dw,SVr),e(re,RVr),e(re,cw),e(cw,N6e),e(N6e,PVr),e(cw,BVr),e(cw,gre),e(gre,IVr),e(cw,NVr),e(re,qVr),e(re,fw),e(fw,q6e),e(q6e,jVr),e(fw,DVr),e(fw,hre),e(hre,GVr),e(fw,OVr),e(re,VVr),e(re,mw),e(mw,j6e),e(j6e,XVr),e(mw,zVr),e(mw,ure),e(ure,QVr),e(mw,WVr),e(re,UVr),e(re,gw),e(gw,D6e),e(D6e,HVr),e(gw,JVr),e(gw,pre),e(pre,YVr),e(gw,KVr),e(re,ZVr),e(re,hw),e(hw,G6e),e(G6e,eXr),e(hw,oXr),e(hw,_re),e(_re,rXr),e(hw,tXr),e(re,aXr),e(re,uw),e(uw,O6e),e(O6e,nXr),e(uw,sXr),e(uw,vre),e(vre,lXr),e(uw,iXr),e(re,dXr),e(re,pw),e(pw,V6e),e(V6e,cXr),e(pw,fXr),e(pw,bre),e(bre,mXr),e(pw,gXr),e(re,hXr),e(re,_w),e(_w,X6e),e(X6e,uXr),e(_w,pXr),e(_w,Fre),e(Fre,_Xr),e(_w,vXr),e(re,bXr),e(re,vw),e(vw,z6e),e(z6e,FXr),e(vw,TXr),e(vw,Tre),e(Tre,MXr),e(vw,EXr),e(re,CXr),e(re,bw),e(bw,Q6e),e(Q6e,wXr),e(bw,AXr),e(bw,Mre),e(Mre,LXr),e(bw,yXr),e(re,xXr),e(re,Fw),e(Fw,W6e),e(W6e,$Xr),e(Fw,kXr),e(Fw,Ere),e(Ere,SXr),e(Fw,RXr),e(re,PXr),e(re,Tw),e(Tw,U6e),e(U6e,BXr),e(Tw,IXr),e(Tw,Cre),e(Cre,NXr),e(Tw,qXr),e(re,jXr),e(re,Mw),e(Mw,H6e),e(H6e,DXr),e(Mw,GXr),e(Mw,wre),e(wre,OXr),e(Mw,VXr),e(re,XXr),e(re,Ew),e(Ew,J6e),e(J6e,zXr),e(Ew,QXr),e(Ew,Are),e(Are,WXr),e(Ew,UXr),e(Vr,HXr),M(Cw,Vr,null),v(f,aZe,_),v(f,gf,_),e(gf,ww),e(ww,Y6e),M(nS,Y6e,null),e(gf,JXr),e(gf,K6e),e(K6e,YXr),v(f,nZe,_),v(f,hr,_),M(sS,hr,null),e(hr,KXr),e(hr,hf),e(hf,ZXr),e(hf,Lre),e(Lre,ezr),e(hf,ozr),e(hf,yre),e(yre,rzr),e(hf,tzr),e(hr,azr),e(hr,lS),e(lS,nzr),e(lS,Z6e),e(Z6e,szr),e(lS,lzr),e(hr,izr),e(hr,Kt),M(iS,Kt,null),e(Kt,dzr),e(Kt,e7e),e(e7e,czr),e(Kt,fzr),e(Kt,uf),e(uf,mzr),e(uf,o7e),e(o7e,gzr),e(uf,hzr),e(uf,xre),e(xre,uzr),e(uf,pzr),e(Kt,_zr),M(Aw,Kt,null),e(hr,vzr),e(hr,Xr),M(dS,Xr,null),e(Xr,bzr),e(Xr,r7e),e(r7e,Fzr),e(Xr,Tzr),e(Xr,Sn),e(Sn,Mzr),e(Sn,t7e),e(t7e,Ezr),e(Sn,Czr),e(Sn,a7e),e(a7e,wzr),e(Sn,Azr),e(Sn,n7e),e(n7e,Lzr),e(Sn,yzr),e(Xr,xzr),e(Xr,be),e(be,Lw),e(Lw,s7e),e(s7e,$zr),e(Lw,kzr),e(Lw,$re),e($re,Szr),e(Lw,Rzr),e(be,Pzr),e(be,yw),e(yw,l7e),e(l7e,Bzr),e(yw,Izr),e(yw,kre),e(kre,Nzr),e(yw,qzr),e(be,jzr),e(be,xw),e(xw,i7e),e(i7e,Dzr),e(xw,Gzr),e(xw,Sre),e(Sre,Ozr),e(xw,Vzr),e(be,Xzr),e(be,$w),e($w,d7e),e(d7e,zzr),e($w,Qzr),e($w,Rre),e(Rre,Wzr),e($w,Uzr),e(be,Hzr),e(be,kw),e(kw,c7e),e(c7e,Jzr),e(kw,Yzr),e(kw,Pre),e(Pre,Kzr),e(kw,Zzr),e(be,eQr),e(be,Sw),e(Sw,f7e),e(f7e,oQr),e(Sw,rQr),e(Sw,Bre),e(Bre,tQr),e(Sw,aQr),e(be,nQr),e(be,Rw),e(Rw,m7e),e(m7e,sQr),e(Rw,lQr),e(Rw,Ire),e(Ire,iQr),e(Rw,dQr),e(be,cQr),e(be,Pw),e(Pw,g7e),e(g7e,fQr),e(Pw,mQr),e(Pw,Nre),e(Nre,gQr),e(Pw,hQr),e(be,uQr),e(be,Bw),e(Bw,h7e),e(h7e,pQr),e(Bw,_Qr),e(Bw,qre),e(qre,vQr),e(Bw,bQr),e(be,FQr),e(be,Iw),e(Iw,u7e),e(u7e,TQr),e(Iw,MQr),e(Iw,jre),e(jre,EQr),e(Iw,CQr),e(be,wQr),e(be,Nw),e(Nw,p7e),e(p7e,AQr),e(Nw,LQr),e(Nw,Dre),e(Dre,yQr),e(Nw,xQr),e(be,$Qr),e(be,qw),e(qw,_7e),e(_7e,kQr),e(qw,SQr),e(qw,Gre),e(Gre,RQr),e(qw,PQr),e(be,BQr),e(be,jw),e(jw,v7e),e(v7e,IQr),e(jw,NQr),e(jw,Ore),e(Ore,qQr),e(jw,jQr),e(be,DQr),e(be,Dw),e(Dw,b7e),e(b7e,GQr),e(Dw,OQr),e(Dw,Vre),e(Vre,VQr),e(Dw,XQr),e(be,zQr),e(be,Gw),e(Gw,F7e),e(F7e,QQr),e(Gw,WQr),e(Gw,Xre),e(Xre,UQr),e(Gw,HQr),e(be,JQr),e(be,Ow),e(Ow,T7e),e(T7e,YQr),e(Ow,KQr),e(Ow,zre),e(zre,ZQr),e(Ow,eWr),e(be,oWr),e(be,Vw),e(Vw,M7e),e(M7e,rWr),e(Vw,tWr),e(Vw,Qre),e(Qre,aWr),e(Vw,nWr),e(Xr,sWr),M(Xw,Xr,null),v(f,sZe,_),v(f,pf,_),e(pf,zw),e(zw,E7e),M(cS,E7e,null),e(pf,lWr),e(pf,C7e),e(C7e,iWr),v(f,lZe,_),v(f,ur,_),M(fS,ur,null),e(ur,dWr),e(ur,_f),e(_f,cWr),e(_f,Wre),e(Wre,fWr),e(_f,mWr),e(_f,Ure),e(Ure,gWr),e(_f,hWr),e(ur,uWr),e(ur,mS),e(mS,pWr),e(mS,w7e),e(w7e,_Wr),e(mS,vWr),e(ur,bWr),e(ur,Zt),M(gS,Zt,null),e(Zt,FWr),e(Zt,A7e),e(A7e,TWr),e(Zt,MWr),e(Zt,vf),e(vf,EWr),e(vf,L7e),e(L7e,CWr),e(vf,wWr),e(vf,Hre),e(Hre,AWr),e(vf,LWr),e(Zt,yWr),M(Qw,Zt,null),e(ur,xWr),e(ur,zr),M(hS,zr,null),e(zr,$Wr),e(zr,y7e),e(y7e,kWr),e(zr,SWr),e(zr,Rn),e(Rn,RWr),e(Rn,x7e),e(x7e,PWr),e(Rn,BWr),e(Rn,$7e),e($7e,IWr),e(Rn,NWr),e(Rn,k7e),e(k7e,qWr),e(Rn,jWr),e(zr,DWr),e(zr,uS),e(uS,Ww),e(Ww,S7e),e(S7e,GWr),e(Ww,OWr),e(Ww,Jre),e(Jre,VWr),e(Ww,XWr),e(uS,zWr),e(uS,Uw),e(Uw,R7e),e(R7e,QWr),e(Uw,WWr),e(Uw,Yre),e(Yre,UWr),e(Uw,HWr),e(zr,JWr),M(Hw,zr,null),v(f,iZe,_),v(f,bf,_),e(bf,Jw),e(Jw,P7e),M(pS,P7e,null),e(bf,YWr),e(bf,B7e),e(B7e,KWr),v(f,dZe,_),v(f,pr,_),M(_S,pr,null),e(pr,ZWr),e(pr,Ff),e(Ff,eUr),e(Ff,Kre),e(Kre,oUr),e(Ff,rUr),e(Ff,Zre),e(Zre,tUr),e(Ff,aUr),e(pr,nUr),e(pr,vS),e(vS,sUr),e(vS,I7e),e(I7e,lUr),e(vS,iUr),e(pr,dUr),e(pr,ea),M(bS,ea,null),e(ea,cUr),e(ea,N7e),e(N7e,fUr),e(ea,mUr),e(ea,Tf),e(Tf,gUr),e(Tf,q7e),e(q7e,hUr),e(Tf,uUr),e(Tf,ete),e(ete,pUr),e(Tf,_Ur),e(ea,vUr),M(Yw,ea,null),e(pr,bUr),e(pr,Qr),M(FS,Qr,null),e(Qr,FUr),e(Qr,j7e),e(j7e,TUr),e(Qr,MUr),e(Qr,Pn),e(Pn,EUr),e(Pn,D7e),e(D7e,CUr),e(Pn,wUr),e(Pn,G7e),e(G7e,AUr),e(Pn,LUr),e(Pn,O7e),e(O7e,yUr),e(Pn,xUr),e(Qr,$Ur),e(Qr,V7e),e(V7e,Kw),e(Kw,X7e),e(X7e,kUr),e(Kw,SUr),e(Kw,ote),e(ote,RUr),e(Kw,PUr),e(Qr,BUr),M(Zw,Qr,null),v(f,cZe,_),v(f,Mf,_),e(Mf,eA),e(eA,z7e),M(TS,z7e,null),e(Mf,IUr),e(Mf,Q7e),e(Q7e,NUr),v(f,fZe,_),v(f,_r,_),M(MS,_r,null),e(_r,qUr),e(_r,Ef),e(Ef,jUr),e(Ef,rte),e(rte,DUr),e(Ef,GUr),e(Ef,tte),e(tte,OUr),e(Ef,VUr),e(_r,XUr),e(_r,ES),e(ES,zUr),e(ES,W7e),e(W7e,QUr),e(ES,WUr),e(_r,UUr),e(_r,oa),M(CS,oa,null),e(oa,HUr),e(oa,U7e),e(U7e,JUr),e(oa,YUr),e(oa,Cf),e(Cf,KUr),e(Cf,H7e),e(H7e,ZUr),e(Cf,eHr),e(Cf,ate),e(ate,oHr),e(Cf,rHr),e(oa,tHr),M(oA,oa,null),e(_r,aHr),e(_r,Wr),M(wS,Wr,null),e(Wr,nHr),e(Wr,J7e),e(J7e,sHr),e(Wr,lHr),e(Wr,Bn),e(Bn,iHr),e(Bn,Y7e),e(Y7e,dHr),e(Bn,cHr),e(Bn,K7e),e(K7e,fHr),e(Bn,mHr),e(Bn,Z7e),e(Z7e,gHr),e(Bn,hHr),e(Wr,uHr),e(Wr,eLe),e(eLe,rA),e(rA,oLe),e(oLe,pHr),e(rA,_Hr),e(rA,nte),e(nte,vHr),e(rA,bHr),e(Wr,FHr),M(tA,Wr,null),v(f,mZe,_),v(f,wf,_),e(wf,aA),e(aA,rLe),M(AS,rLe,null),e(wf,THr),e(wf,tLe),e(tLe,MHr),v(f,gZe,_),v(f,vr,_),M(LS,vr,null),e(vr,EHr),e(vr,Af),e(Af,CHr),e(Af,ste),e(ste,wHr),e(Af,AHr),e(Af,lte),e(lte,LHr),e(Af,yHr),e(vr,xHr),e(vr,yS),e(yS,$Hr),e(yS,aLe),e(aLe,kHr),e(yS,SHr),e(vr,RHr),e(vr,ra),M(xS,ra,null),e(ra,PHr),e(ra,nLe),e(nLe,BHr),e(ra,IHr),e(ra,Lf),e(Lf,NHr),e(Lf,sLe),e(sLe,qHr),e(Lf,jHr),e(Lf,ite),e(ite,DHr),e(Lf,GHr),e(ra,OHr),M(nA,ra,null),e(vr,VHr),e(vr,Ur),M($S,Ur,null),e(Ur,XHr),e(Ur,lLe),e(lLe,zHr),e(Ur,QHr),e(Ur,In),e(In,WHr),e(In,iLe),e(iLe,UHr),e(In,HHr),e(In,dLe),e(dLe,JHr),e(In,YHr),e(In,cLe),e(cLe,KHr),e(In,ZHr),e(Ur,eJr),e(Ur,de),e(de,sA),e(sA,fLe),e(fLe,oJr),e(sA,rJr),e(sA,dte),e(dte,tJr),e(sA,aJr),e(de,nJr),e(de,lA),e(lA,mLe),e(mLe,sJr),e(lA,lJr),e(lA,cte),e(cte,iJr),e(lA,dJr),e(de,cJr),e(de,iA),e(iA,gLe),e(gLe,fJr),e(iA,mJr),e(iA,fte),e(fte,gJr),e(iA,hJr),e(de,uJr),e(de,dA),e(dA,hLe),e(hLe,pJr),e(dA,_Jr),e(dA,mte),e(mte,vJr),e(dA,bJr),e(de,FJr),e(de,cA),e(cA,uLe),e(uLe,TJr),e(cA,MJr),e(cA,gte),e(gte,EJr),e(cA,CJr),e(de,wJr),e(de,fA),e(fA,pLe),e(pLe,AJr),e(fA,LJr),e(fA,hte),e(hte,yJr),e(fA,xJr),e(de,$Jr),e(de,mA),e(mA,_Le),e(_Le,kJr),e(mA,SJr),e(mA,ute),e(ute,RJr),e(mA,PJr),e(de,BJr),e(de,gA),e(gA,vLe),e(vLe,IJr),e(gA,NJr),e(gA,pte),e(pte,qJr),e(gA,jJr),e(de,DJr),e(de,hA),e(hA,bLe),e(bLe,GJr),e(hA,OJr),e(hA,_te),e(_te,VJr),e(hA,XJr),e(de,zJr),e(de,uA),e(uA,FLe),e(FLe,QJr),e(uA,WJr),e(uA,vte),e(vte,UJr),e(uA,HJr),e(de,JJr),e(de,pA),e(pA,TLe),e(TLe,YJr),e(pA,KJr),e(pA,bte),e(bte,ZJr),e(pA,eYr),e(de,oYr),e(de,_A),e(_A,MLe),e(MLe,rYr),e(_A,tYr),e(_A,Fte),e(Fte,aYr),e(_A,nYr),e(de,sYr),e(de,vA),e(vA,ELe),e(ELe,lYr),e(vA,iYr),e(vA,Tte),e(Tte,dYr),e(vA,cYr),e(de,fYr),e(de,bA),e(bA,CLe),e(CLe,mYr),e(bA,gYr),e(bA,Mte),e(Mte,hYr),e(bA,uYr),e(de,pYr),e(de,FA),e(FA,wLe),e(wLe,_Yr),e(FA,vYr),e(FA,Ete),e(Ete,bYr),e(FA,FYr),e(de,TYr),e(de,TA),e(TA,ALe),e(ALe,MYr),e(TA,EYr),e(TA,Cte),e(Cte,CYr),e(TA,wYr),e(de,AYr),e(de,MA),e(MA,LLe),e(LLe,LYr),e(MA,yYr),e(MA,wte),e(wte,xYr),e(MA,$Yr),e(de,kYr),e(de,EA),e(EA,yLe),e(yLe,SYr),e(EA,RYr),e(EA,Ate),e(Ate,PYr),e(EA,BYr),e(de,IYr),e(de,CA),e(CA,xLe),e(xLe,NYr),e(CA,qYr),e(CA,Lte),e(Lte,jYr),e(CA,DYr),e(de,GYr),e(de,wA),e(wA,$Le),e($Le,OYr),e(wA,VYr),e(wA,yte),e(yte,XYr),e(wA,zYr),e(de,QYr),e(de,AA),e(AA,kLe),e(kLe,WYr),e(AA,UYr),e(AA,xte),e(xte,HYr),e(AA,JYr),e(Ur,YYr),M(LA,Ur,null),v(f,hZe,_),v(f,yf,_),e(yf,yA),e(yA,SLe),M(kS,SLe,null),e(yf,KYr),e(yf,RLe),e(RLe,ZYr),v(f,uZe,_),v(f,br,_),M(SS,br,null),e(br,eKr),e(br,xf),e(xf,oKr),e(xf,$te),e($te,rKr),e(xf,tKr),e(xf,kte),e(kte,aKr),e(xf,nKr),e(br,sKr),e(br,RS),e(RS,lKr),e(RS,PLe),e(PLe,iKr),e(RS,dKr),e(br,cKr),e(br,ta),M(PS,ta,null),e(ta,fKr),e(ta,BLe),e(BLe,mKr),e(ta,gKr),e(ta,$f),e($f,hKr),e($f,ILe),e(ILe,uKr),e($f,pKr),e($f,Ste),e(Ste,_Kr),e($f,vKr),e(ta,bKr),M(xA,ta,null),e(br,FKr),e(br,Hr),M(BS,Hr,null),e(Hr,TKr),e(Hr,NLe),e(NLe,MKr),e(Hr,EKr),e(Hr,Nn),e(Nn,CKr),e(Nn,qLe),e(qLe,wKr),e(Nn,AKr),e(Nn,jLe),e(jLe,LKr),e(Nn,yKr),e(Nn,DLe),e(DLe,xKr),e(Nn,$Kr),e(Hr,kKr),e(Hr,ce),e(ce,$A),e($A,GLe),e(GLe,SKr),e($A,RKr),e($A,Rte),e(Rte,PKr),e($A,BKr),e(ce,IKr),e(ce,kA),e(kA,OLe),e(OLe,NKr),e(kA,qKr),e(kA,Pte),e(Pte,jKr),e(kA,DKr),e(ce,GKr),e(ce,SA),e(SA,VLe),e(VLe,OKr),e(SA,VKr),e(SA,Bte),e(Bte,XKr),e(SA,zKr),e(ce,QKr),e(ce,RA),e(RA,XLe),e(XLe,WKr),e(RA,UKr),e(RA,Ite),e(Ite,HKr),e(RA,JKr),e(ce,YKr),e(ce,PA),e(PA,zLe),e(zLe,KKr),e(PA,ZKr),e(PA,Nte),e(Nte,eZr),e(PA,oZr),e(ce,rZr),e(ce,BA),e(BA,QLe),e(QLe,tZr),e(BA,aZr),e(BA,qte),e(qte,nZr),e(BA,sZr),e(ce,lZr),e(ce,IA),e(IA,WLe),e(WLe,iZr),e(IA,dZr),e(IA,jte),e(jte,cZr),e(IA,fZr),e(ce,mZr),e(ce,NA),e(NA,ULe),e(ULe,gZr),e(NA,hZr),e(NA,Dte),e(Dte,uZr),e(NA,pZr),e(ce,_Zr),e(ce,qA),e(qA,HLe),e(HLe,vZr),e(qA,bZr),e(qA,Gte),e(Gte,FZr),e(qA,TZr),e(ce,MZr),e(ce,jA),e(jA,JLe),e(JLe,EZr),e(jA,CZr),e(jA,Ote),e(Ote,wZr),e(jA,AZr),e(ce,LZr),e(ce,DA),e(DA,YLe),e(YLe,yZr),e(DA,xZr),e(DA,Vte),e(Vte,$Zr),e(DA,kZr),e(ce,SZr),e(ce,GA),e(GA,KLe),e(KLe,RZr),e(GA,PZr),e(GA,Xte),e(Xte,BZr),e(GA,IZr),e(ce,NZr),e(ce,OA),e(OA,ZLe),e(ZLe,qZr),e(OA,jZr),e(OA,zte),e(zte,DZr),e(OA,GZr),e(ce,OZr),e(ce,VA),e(VA,eye),e(eye,VZr),e(VA,XZr),e(VA,Qte),e(Qte,zZr),e(VA,QZr),e(ce,WZr),e(ce,XA),e(XA,oye),e(oye,UZr),e(XA,HZr),e(XA,Wte),e(Wte,JZr),e(XA,YZr),e(ce,KZr),e(ce,zA),e(zA,rye),e(rye,ZZr),e(zA,eet),e(zA,Ute),e(Ute,oet),e(zA,ret),e(ce,tet),e(ce,QA),e(QA,tye),e(tye,aet),e(QA,net),e(QA,Hte),e(Hte,set),e(QA,iet),e(ce,det),e(ce,WA),e(WA,aye),e(aye,cet),e(WA,fet),e(WA,Jte),e(Jte,met),e(WA,get),e(ce,het),e(ce,UA),e(UA,nye),e(nye,uet),e(UA,pet),e(UA,Yte),e(Yte,_et),e(UA,vet),e(ce,bet),e(ce,HA),e(HA,sye),e(sye,Fet),e(HA,Tet),e(HA,Kte),e(Kte,Met),e(HA,Eet),e(ce,Cet),e(ce,JA),e(JA,lye),e(lye,wet),e(JA,Aet),e(JA,Zte),e(Zte,Let),e(JA,yet),e(Hr,xet),M(YA,Hr,null),v(f,pZe,_),v(f,kf,_),e(kf,KA),e(KA,iye),M(IS,iye,null),e(kf,$et),e(kf,dye),e(dye,ket),v(f,_Ze,_),v(f,Fr,_),M(NS,Fr,null),e(Fr,Set),e(Fr,Sf),e(Sf,Ret),e(Sf,eae),e(eae,Pet),e(Sf,Bet),e(Sf,oae),e(oae,Iet),e(Sf,Net),e(Fr,qet),e(Fr,qS),e(qS,jet),e(qS,cye),e(cye,Det),e(qS,Get),e(Fr,Oet),e(Fr,aa),M(jS,aa,null),e(aa,Vet),e(aa,fye),e(fye,Xet),e(aa,zet),e(aa,Rf),e(Rf,Qet),e(Rf,mye),e(mye,Wet),e(Rf,Uet),e(Rf,rae),e(rae,Het),e(Rf,Jet),e(aa,Yet),M(ZA,aa,null),e(Fr,Ket),e(Fr,Jr),M(DS,Jr,null),e(Jr,Zet),e(Jr,gye),e(gye,eot),e(Jr,oot),e(Jr,qn),e(qn,rot),e(qn,hye),e(hye,tot),e(qn,aot),e(qn,uye),e(uye,not),e(qn,sot),e(qn,pye),e(pye,lot),e(qn,iot),e(Jr,dot),e(Jr,_ye),e(_ye,e6),e(e6,vye),e(vye,cot),e(e6,fot),e(e6,tae),e(tae,mot),e(e6,got),e(Jr,hot),M(o6,Jr,null),v(f,vZe,_),v(f,Pf,_),e(Pf,r6),e(r6,bye),M(GS,bye,null),e(Pf,uot),e(Pf,Fye),e(Fye,pot),v(f,bZe,_),v(f,Tr,_),M(OS,Tr,null),e(Tr,_ot),e(Tr,Bf),e(Bf,vot),e(Bf,aae),e(aae,bot),e(Bf,Fot),e(Bf,nae),e(nae,Tot),e(Bf,Mot),e(Tr,Eot),e(Tr,VS),e(VS,Cot),e(VS,Tye),e(Tye,wot),e(VS,Aot),e(Tr,Lot),e(Tr,na),M(XS,na,null),e(na,yot),e(na,Mye),e(Mye,xot),e(na,$ot),e(na,If),e(If,kot),e(If,Eye),e(Eye,Sot),e(If,Rot),e(If,sae),e(sae,Pot),e(If,Bot),e(na,Iot),M(t6,na,null),e(Tr,Not),e(Tr,Yr),M(zS,Yr,null),e(Yr,qot),e(Yr,Cye),e(Cye,jot),e(Yr,Dot),e(Yr,jn),e(jn,Got),e(jn,wye),e(wye,Oot),e(jn,Vot),e(jn,Aye),e(Aye,Xot),e(jn,zot),e(jn,Lye),e(Lye,Qot),e(jn,Wot),e(Yr,Uot),e(Yr,yye),e(yye,a6),e(a6,xye),e(xye,Hot),e(a6,Jot),e(a6,lae),e(lae,Yot),e(a6,Kot),e(Yr,Zot),M(n6,Yr,null),v(f,FZe,_),v(f,Nf,_),e(Nf,s6),e(s6,$ye),M(QS,$ye,null),e(Nf,ert),e(Nf,kye),e(kye,ort),v(f,TZe,_),v(f,Mr,_),M(WS,Mr,null),e(Mr,rrt),e(Mr,qf),e(qf,trt),e(qf,iae),e(iae,art),e(qf,nrt),e(qf,dae),e(dae,srt),e(qf,lrt),e(Mr,irt),e(Mr,US),e(US,drt),e(US,Sye),e(Sye,crt),e(US,frt),e(Mr,mrt),e(Mr,sa),M(HS,sa,null),e(sa,grt),e(sa,Rye),e(Rye,hrt),e(sa,urt),e(sa,jf),e(jf,prt),e(jf,Pye),e(Pye,_rt),e(jf,vrt),e(jf,cae),e(cae,brt),e(jf,Frt),e(sa,Trt),M(l6,sa,null),e(Mr,Mrt),e(Mr,Kr),M(JS,Kr,null),e(Kr,Ert),e(Kr,Bye),e(Bye,Crt),e(Kr,wrt),e(Kr,Dn),e(Dn,Art),e(Dn,Iye),e(Iye,Lrt),e(Dn,yrt),e(Dn,Nye),e(Nye,xrt),e(Dn,$rt),e(Dn,qye),e(qye,krt),e(Dn,Srt),e(Kr,Rrt),e(Kr,te),e(te,i6),e(i6,jye),e(jye,Prt),e(i6,Brt),e(i6,fae),e(fae,Irt),e(i6,Nrt),e(te,qrt),e(te,d6),e(d6,Dye),e(Dye,jrt),e(d6,Drt),e(d6,mae),e(mae,Grt),e(d6,Ort),e(te,Vrt),e(te,c6),e(c6,Gye),e(Gye,Xrt),e(c6,zrt),e(c6,gae),e(gae,Qrt),e(c6,Wrt),e(te,Urt),e(te,f6),e(f6,Oye),e(Oye,Hrt),e(f6,Jrt),e(f6,hae),e(hae,Yrt),e(f6,Krt),e(te,Zrt),e(te,m6),e(m6,Vye),e(Vye,ett),e(m6,ott),e(m6,uae),e(uae,rtt),e(m6,ttt),e(te,att),e(te,g6),e(g6,Xye),e(Xye,ntt),e(g6,stt),e(g6,pae),e(pae,ltt),e(g6,itt),e(te,dtt),e(te,h6),e(h6,zye),e(zye,ctt),e(h6,ftt),e(h6,_ae),e(_ae,mtt),e(h6,gtt),e(te,htt),e(te,u6),e(u6,Qye),e(Qye,utt),e(u6,ptt),e(u6,vae),e(vae,_tt),e(u6,vtt),e(te,btt),e(te,p6),e(p6,Wye),e(Wye,Ftt),e(p6,Ttt),e(p6,bae),e(bae,Mtt),e(p6,Ett),e(te,Ctt),e(te,_6),e(_6,Uye),e(Uye,wtt),e(_6,Att),e(_6,Fae),e(Fae,Ltt),e(_6,ytt),e(te,xtt),e(te,v6),e(v6,Hye),e(Hye,$tt),e(v6,ktt),e(v6,Tae),e(Tae,Stt),e(v6,Rtt),e(te,Ptt),e(te,b6),e(b6,Jye),e(Jye,Btt),e(b6,Itt),e(b6,Mae),e(Mae,Ntt),e(b6,qtt),e(te,jtt),e(te,F6),e(F6,Yye),e(Yye,Dtt),e(F6,Gtt),e(F6,Eae),e(Eae,Ott),e(F6,Vtt),e(te,Xtt),e(te,T6),e(T6,Kye),e(Kye,ztt),e(T6,Qtt),e(T6,Cae),e(Cae,Wtt),e(T6,Utt),e(te,Htt),e(te,M6),e(M6,Zye),e(Zye,Jtt),e(M6,Ytt),e(M6,wae),e(wae,Ktt),e(M6,Ztt),e(te,eat),e(te,E6),e(E6,e8e),e(e8e,oat),e(E6,rat),e(E6,Aae),e(Aae,tat),e(E6,aat),e(te,nat),e(te,C6),e(C6,o8e),e(o8e,sat),e(C6,lat),e(C6,Lae),e(Lae,iat),e(C6,dat),e(te,cat),e(te,w6),e(w6,r8e),e(r8e,fat),e(w6,mat),e(w6,yae),e(yae,gat),e(w6,hat),e(te,uat),e(te,A6),e(A6,t8e),e(t8e,pat),e(A6,_at),e(A6,xae),e(xae,vat),e(A6,bat),e(te,Fat),e(te,L6),e(L6,a8e),e(a8e,Tat),e(L6,Mat),e(L6,$ae),e($ae,Eat),e(L6,Cat),e(te,wat),e(te,y6),e(y6,n8e),e(n8e,Aat),e(y6,Lat),e(y6,kae),e(kae,yat),e(y6,xat),e(te,$at),e(te,x6),e(x6,s8e),e(s8e,kat),e(x6,Sat),e(x6,Sae),e(Sae,Rat),e(x6,Pat),e(te,Bat),e(te,$6),e($6,l8e),e(l8e,Iat),e($6,Nat),e($6,Rae),e(Rae,qat),e($6,jat),e(te,Dat),e(te,k6),e(k6,i8e),e(i8e,Gat),e(k6,Oat),e(k6,Pae),e(Pae,Vat),e(k6,Xat),e(te,zat),e(te,S6),e(S6,d8e),e(d8e,Qat),e(S6,Wat),e(S6,Bae),e(Bae,Uat),e(S6,Hat),e(te,Jat),e(te,R6),e(R6,c8e),e(c8e,Yat),e(R6,Kat),e(R6,Iae),e(Iae,Zat),e(R6,ent),e(te,ont),e(te,P6),e(P6,f8e),e(f8e,rnt),e(P6,tnt),e(P6,Nae),e(Nae,ant),e(P6,nnt),e(Kr,snt),M(B6,Kr,null),v(f,MZe,_),v(f,Df,_),e(Df,I6),e(I6,m8e),M(YS,m8e,null),e(Df,lnt),e(Df,g8e),e(g8e,int),v(f,EZe,_),v(f,Er,_),M(KS,Er,null),e(Er,dnt),e(Er,Gf),e(Gf,cnt),e(Gf,qae),e(qae,fnt),e(Gf,mnt),e(Gf,jae),e(jae,gnt),e(Gf,hnt),e(Er,unt),e(Er,ZS),e(ZS,pnt),e(ZS,h8e),e(h8e,_nt),e(ZS,vnt),e(Er,bnt),e(Er,la),M(eR,la,null),e(la,Fnt),e(la,u8e),e(u8e,Tnt),e(la,Mnt),e(la,Of),e(Of,Ent),e(Of,p8e),e(p8e,Cnt),e(Of,wnt),e(Of,Dae),e(Dae,Ant),e(Of,Lnt),e(la,ynt),M(N6,la,null),e(Er,xnt),e(Er,Zr),M(oR,Zr,null),e(Zr,$nt),e(Zr,_8e),e(_8e,knt),e(Zr,Snt),e(Zr,Gn),e(Gn,Rnt),e(Gn,v8e),e(v8e,Pnt),e(Gn,Bnt),e(Gn,b8e),e(b8e,Int),e(Gn,Nnt),e(Gn,F8e),e(F8e,qnt),e(Gn,jnt),e(Zr,Dnt),e(Zr,xe),e(xe,q6),e(q6,T8e),e(T8e,Gnt),e(q6,Ont),e(q6,Gae),e(Gae,Vnt),e(q6,Xnt),e(xe,znt),e(xe,j6),e(j6,M8e),e(M8e,Qnt),e(j6,Wnt),e(j6,Oae),e(Oae,Unt),e(j6,Hnt),e(xe,Jnt),e(xe,D6),e(D6,E8e),e(E8e,Ynt),e(D6,Knt),e(D6,Vae),e(Vae,Znt),e(D6,est),e(xe,ost),e(xe,G6),e(G6,C8e),e(C8e,rst),e(G6,tst),e(G6,Xae),e(Xae,ast),e(G6,nst),e(xe,sst),e(xe,O6),e(O6,w8e),e(w8e,lst),e(O6,ist),e(O6,zae),e(zae,dst),e(O6,cst),e(xe,fst),e(xe,V6),e(V6,A8e),e(A8e,mst),e(V6,gst),e(V6,Qae),e(Qae,hst),e(V6,ust),e(xe,pst),e(xe,X6),e(X6,L8e),e(L8e,_st),e(X6,vst),e(X6,Wae),e(Wae,bst),e(X6,Fst),e(xe,Tst),e(xe,z6),e(z6,y8e),e(y8e,Mst),e(z6,Est),e(z6,Uae),e(Uae,Cst),e(z6,wst),e(xe,Ast),e(xe,Q6),e(Q6,x8e),e(x8e,Lst),e(Q6,yst),e(Q6,Hae),e(Hae,xst),e(Q6,$st),e(xe,kst),e(xe,W6),e(W6,$8e),e($8e,Sst),e(W6,Rst),e(W6,Jae),e(Jae,Pst),e(W6,Bst),e(Zr,Ist),M(U6,Zr,null),v(f,CZe,_),v(f,Vf,_),e(Vf,H6),e(H6,k8e),M(rR,k8e,null),e(Vf,Nst),e(Vf,S8e),e(S8e,qst),v(f,wZe,_),v(f,Cr,_),M(tR,Cr,null),e(Cr,jst),e(Cr,Xf),e(Xf,Dst),e(Xf,Yae),e(Yae,Gst),e(Xf,Ost),e(Xf,Kae),e(Kae,Vst),e(Xf,Xst),e(Cr,zst),e(Cr,aR),e(aR,Qst),e(aR,R8e),e(R8e,Wst),e(aR,Ust),e(Cr,Hst),e(Cr,ia),M(nR,ia,null),e(ia,Jst),e(ia,P8e),e(P8e,Yst),e(ia,Kst),e(ia,zf),e(zf,Zst),e(zf,B8e),e(B8e,elt),e(zf,olt),e(zf,Zae),e(Zae,rlt),e(zf,tlt),e(ia,alt),M(J6,ia,null),e(Cr,nlt),e(Cr,et),M(sR,et,null),e(et,slt),e(et,I8e),e(I8e,llt),e(et,ilt),e(et,On),e(On,dlt),e(On,N8e),e(N8e,clt),e(On,flt),e(On,q8e),e(q8e,mlt),e(On,glt),e(On,j8e),e(j8e,hlt),e(On,ult),e(et,plt),e(et,Ee),e(Ee,Y6),e(Y6,D8e),e(D8e,_lt),e(Y6,vlt),e(Y6,ene),e(ene,blt),e(Y6,Flt),e(Ee,Tlt),e(Ee,K6),e(K6,G8e),e(G8e,Mlt),e(K6,Elt),e(K6,one),e(one,Clt),e(K6,wlt),e(Ee,Alt),e(Ee,Z6),e(Z6,O8e),e(O8e,Llt),e(Z6,ylt),e(Z6,rne),e(rne,xlt),e(Z6,$lt),e(Ee,klt),e(Ee,e7),e(e7,V8e),e(V8e,Slt),e(e7,Rlt),e(e7,tne),e(tne,Plt),e(e7,Blt),e(Ee,Ilt),e(Ee,o7),e(o7,X8e),e(X8e,Nlt),e(o7,qlt),e(o7,ane),e(ane,jlt),e(o7,Dlt),e(Ee,Glt),e(Ee,r7),e(r7,z8e),e(z8e,Olt),e(r7,Vlt),e(r7,nne),e(nne,Xlt),e(r7,zlt),e(Ee,Qlt),e(Ee,t7),e(t7,Q8e),e(Q8e,Wlt),e(t7,Ult),e(t7,sne),e(sne,Hlt),e(t7,Jlt),e(Ee,Ylt),e(Ee,a7),e(a7,W8e),e(W8e,Klt),e(a7,Zlt),e(a7,lne),e(lne,eit),e(a7,oit),e(Ee,rit),e(Ee,n7),e(n7,U8e),e(U8e,tit),e(n7,ait),e(n7,ine),e(ine,nit),e(n7,sit),e(Ee,lit),e(Ee,s7),e(s7,H8e),e(H8e,iit),e(s7,dit),e(s7,dne),e(dne,cit),e(s7,fit),e(Ee,mit),e(Ee,l7),e(l7,J8e),e(J8e,git),e(l7,hit),e(l7,cne),e(cne,uit),e(l7,pit),e(Ee,_it),e(Ee,i7),e(i7,Y8e),e(Y8e,vit),e(i7,bit),e(i7,fne),e(fne,Fit),e(i7,Tit),e(Ee,Mit),e(Ee,d7),e(d7,K8e),e(K8e,Eit),e(d7,Cit),e(d7,mne),e(mne,wit),e(d7,Ait),e(et,Lit),M(c7,et,null),v(f,AZe,_),v(f,Qf,_),e(Qf,f7),e(f7,Z8e),M(lR,Z8e,null),e(Qf,yit),e(Qf,e9e),e(e9e,xit),v(f,LZe,_),v(f,wr,_),M(iR,wr,null),e(wr,$it),e(wr,Wf),e(Wf,kit),e(Wf,gne),e(gne,Sit),e(Wf,Rit),e(Wf,hne),e(hne,Pit),e(Wf,Bit),e(wr,Iit),e(wr,dR),e(dR,Nit),e(dR,o9e),e(o9e,qit),e(dR,jit),e(wr,Dit),e(wr,da),M(cR,da,null),e(da,Git),e(da,r9e),e(r9e,Oit),e(da,Vit),e(da,Uf),e(Uf,Xit),e(Uf,t9e),e(t9e,zit),e(Uf,Qit),e(Uf,une),e(une,Wit),e(Uf,Uit),e(da,Hit),M(m7,da,null),e(wr,Jit),e(wr,ot),M(fR,ot,null),e(ot,Yit),e(ot,a9e),e(a9e,Kit),e(ot,Zit),e(ot,Vn),e(Vn,edt),e(Vn,n9e),e(n9e,odt),e(Vn,rdt),e(Vn,s9e),e(s9e,tdt),e(Vn,adt),e(Vn,l9e),e(l9e,ndt),e(Vn,sdt),e(ot,ldt),e(ot,$e),e($e,g7),e(g7,i9e),e(i9e,idt),e(g7,ddt),e(g7,pne),e(pne,cdt),e(g7,fdt),e($e,mdt),e($e,h7),e(h7,d9e),e(d9e,gdt),e(h7,hdt),e(h7,_ne),e(_ne,udt),e(h7,pdt),e($e,_dt),e($e,u7),e(u7,c9e),e(c9e,vdt),e(u7,bdt),e(u7,vne),e(vne,Fdt),e(u7,Tdt),e($e,Mdt),e($e,p7),e(p7,f9e),e(f9e,Edt),e(p7,Cdt),e(p7,bne),e(bne,wdt),e(p7,Adt),e($e,Ldt),e($e,_7),e(_7,m9e),e(m9e,ydt),e(_7,xdt),e(_7,Fne),e(Fne,$dt),e(_7,kdt),e($e,Sdt),e($e,v7),e(v7,g9e),e(g9e,Rdt),e(v7,Pdt),e(v7,Tne),e(Tne,Bdt),e(v7,Idt),e($e,Ndt),e($e,b7),e(b7,h9e),e(h9e,qdt),e(b7,jdt),e(b7,Mne),e(Mne,Ddt),e(b7,Gdt),e($e,Odt),e($e,F7),e(F7,u9e),e(u9e,Vdt),e(F7,Xdt),e(F7,Ene),e(Ene,zdt),e(F7,Qdt),e($e,Wdt),e($e,T7),e(T7,p9e),e(p9e,Udt),e(T7,Hdt),e(T7,Cne),e(Cne,Jdt),e(T7,Ydt),e($e,Kdt),e($e,M7),e(M7,_9e),e(_9e,Zdt),e(M7,ect),e(M7,wne),e(wne,oct),e(M7,rct),e(ot,tct),M(E7,ot,null),v(f,yZe,_),v(f,Hf,_),e(Hf,C7),e(C7,v9e),M(mR,v9e,null),e(Hf,act),e(Hf,b9e),e(b9e,nct),v(f,xZe,_),v(f,Ar,_),M(gR,Ar,null),e(Ar,sct),e(Ar,Jf),e(Jf,lct),e(Jf,Ane),e(Ane,ict),e(Jf,dct),e(Jf,Lne),e(Lne,cct),e(Jf,fct),e(Ar,mct),e(Ar,hR),e(hR,gct),e(hR,F9e),e(F9e,hct),e(hR,uct),e(Ar,pct),e(Ar,ca),M(uR,ca,null),e(ca,_ct),e(ca,T9e),e(T9e,vct),e(ca,bct),e(ca,Yf),e(Yf,Fct),e(Yf,M9e),e(M9e,Tct),e(Yf,Mct),e(Yf,yne),e(yne,Ect),e(Yf,Cct),e(ca,wct),M(w7,ca,null),e(Ar,Act),e(Ar,rt),M(pR,rt,null),e(rt,Lct),e(rt,E9e),e(E9e,yct),e(rt,xct),e(rt,Xn),e(Xn,$ct),e(Xn,C9e),e(C9e,kct),e(Xn,Sct),e(Xn,w9e),e(w9e,Rct),e(Xn,Pct),e(Xn,A9e),e(A9e,Bct),e(Xn,Ict),e(rt,Nct),e(rt,ke),e(ke,A7),e(A7,L9e),e(L9e,qct),e(A7,jct),e(A7,xne),e(xne,Dct),e(A7,Gct),e(ke,Oct),e(ke,L7),e(L7,y9e),e(y9e,Vct),e(L7,Xct),e(L7,$ne),e($ne,zct),e(L7,Qct),e(ke,Wct),e(ke,y7),e(y7,x9e),e(x9e,Uct),e(y7,Hct),e(y7,kne),e(kne,Jct),e(y7,Yct),e(ke,Kct),e(ke,x7),e(x7,$9e),e($9e,Zct),e(x7,eft),e(x7,Sne),e(Sne,oft),e(x7,rft),e(ke,tft),e(ke,$7),e($7,k9e),e(k9e,aft),e($7,nft),e($7,Rne),e(Rne,sft),e($7,lft),e(ke,ift),e(ke,k7),e(k7,S9e),e(S9e,dft),e(k7,cft),e(k7,Pne),e(Pne,fft),e(k7,mft),e(ke,gft),e(ke,S7),e(S7,R9e),e(R9e,hft),e(S7,uft),e(S7,Bne),e(Bne,pft),e(S7,_ft),e(ke,vft),e(ke,R7),e(R7,P9e),e(P9e,bft),e(R7,Fft),e(R7,Ine),e(Ine,Tft),e(R7,Mft),e(ke,Eft),e(ke,P7),e(P7,B9e),e(B9e,Cft),e(P7,wft),e(P7,Nne),e(Nne,Aft),e(P7,Lft),e(ke,yft),e(ke,B7),e(B7,I9e),e(I9e,xft),e(B7,$ft),e(B7,qne),e(qne,kft),e(B7,Sft),e(rt,Rft),M(I7,rt,null),v(f,$Ze,_),v(f,Kf,_),e(Kf,N7),e(N7,N9e),M(_R,N9e,null),e(Kf,Pft),e(Kf,q9e),e(q9e,Bft),v(f,kZe,_),v(f,Lr,_),M(vR,Lr,null),e(Lr,Ift),e(Lr,Zf),e(Zf,Nft),e(Zf,jne),e(jne,qft),e(Zf,jft),e(Zf,Dne),e(Dne,Dft),e(Zf,Gft),e(Lr,Oft),e(Lr,bR),e(bR,Vft),e(bR,j9e),e(j9e,Xft),e(bR,zft),e(Lr,Qft),e(Lr,fa),M(FR,fa,null),e(fa,Wft),e(fa,D9e),e(D9e,Uft),e(fa,Hft),e(fa,em),e(em,Jft),e(em,G9e),e(G9e,Yft),e(em,Kft),e(em,Gne),e(Gne,Zft),e(em,emt),e(fa,omt),M(q7,fa,null),e(Lr,rmt),e(Lr,tt),M(TR,tt,null),e(tt,tmt),e(tt,O9e),e(O9e,amt),e(tt,nmt),e(tt,zn),e(zn,smt),e(zn,V9e),e(V9e,lmt),e(zn,imt),e(zn,X9e),e(X9e,dmt),e(zn,cmt),e(zn,z9e),e(z9e,fmt),e(zn,mmt),e(tt,gmt),e(tt,Se),e(Se,j7),e(j7,Q9e),e(Q9e,hmt),e(j7,umt),e(j7,One),e(One,pmt),e(j7,_mt),e(Se,vmt),e(Se,D7),e(D7,W9e),e(W9e,bmt),e(D7,Fmt),e(D7,Vne),e(Vne,Tmt),e(D7,Mmt),e(Se,Emt),e(Se,G7),e(G7,U9e),e(U9e,Cmt),e(G7,wmt),e(G7,Xne),e(Xne,Amt),e(G7,Lmt),e(Se,ymt),e(Se,O7),e(O7,H9e),e(H9e,xmt),e(O7,$mt),e(O7,zne),e(zne,kmt),e(O7,Smt),e(Se,Rmt),e(Se,V7),e(V7,J9e),e(J9e,Pmt),e(V7,Bmt),e(V7,Qne),e(Qne,Imt),e(V7,Nmt),e(Se,qmt),e(Se,X7),e(X7,Y9e),e(Y9e,jmt),e(X7,Dmt),e(X7,Wne),e(Wne,Gmt),e(X7,Omt),e(Se,Vmt),e(Se,z7),e(z7,K9e),e(K9e,Xmt),e(z7,zmt),e(z7,Une),e(Une,Qmt),e(z7,Wmt),e(Se,Umt),e(Se,Q7),e(Q7,Z9e),e(Z9e,Hmt),e(Q7,Jmt),e(Q7,Hne),e(Hne,Ymt),e(Q7,Kmt),e(Se,Zmt),e(Se,W7),e(W7,exe),e(exe,egt),e(W7,ogt),e(W7,Jne),e(Jne,rgt),e(W7,tgt),e(Se,agt),e(Se,U7),e(U7,oxe),e(oxe,ngt),e(U7,sgt),e(U7,Yne),e(Yne,lgt),e(U7,igt),e(tt,dgt),M(H7,tt,null),v(f,SZe,_),v(f,om,_),e(om,J7),e(J7,rxe),M(MR,rxe,null),e(om,cgt),e(om,txe),e(txe,fgt),v(f,RZe,_),v(f,yr,_),M(ER,yr,null),e(yr,mgt),e(yr,rm),e(rm,ggt),e(rm,Kne),e(Kne,hgt),e(rm,ugt),e(rm,Zne),e(Zne,pgt),e(rm,_gt),e(yr,vgt),e(yr,CR),e(CR,bgt),e(CR,axe),e(axe,Fgt),e(CR,Tgt),e(yr,Mgt),e(yr,ma),M(wR,ma,null),e(ma,Egt),e(ma,nxe),e(nxe,Cgt),e(ma,wgt),e(ma,tm),e(tm,Agt),e(tm,sxe),e(sxe,Lgt),e(tm,ygt),e(tm,ese),e(ese,xgt),e(tm,$gt),e(ma,kgt),M(Y7,ma,null),e(yr,Sgt),e(yr,at),M(AR,at,null),e(at,Rgt),e(at,lxe),e(lxe,Pgt),e(at,Bgt),e(at,Qn),e(Qn,Igt),e(Qn,ixe),e(ixe,Ngt),e(Qn,qgt),e(Qn,dxe),e(dxe,jgt),e(Qn,Dgt),e(Qn,cxe),e(cxe,Ggt),e(Qn,Ogt),e(at,Vgt),e(at,Re),e(Re,K7),e(K7,fxe),e(fxe,Xgt),e(K7,zgt),e(K7,ose),e(ose,Qgt),e(K7,Wgt),e(Re,Ugt),e(Re,Z7),e(Z7,mxe),e(mxe,Hgt),e(Z7,Jgt),e(Z7,rse),e(rse,Ygt),e(Z7,Kgt),e(Re,Zgt),e(Re,eL),e(eL,gxe),e(gxe,eht),e(eL,oht),e(eL,tse),e(tse,rht),e(eL,tht),e(Re,aht),e(Re,oL),e(oL,hxe),e(hxe,nht),e(oL,sht),e(oL,ase),e(ase,lht),e(oL,iht),e(Re,dht),e(Re,rL),e(rL,uxe),e(uxe,cht),e(rL,fht),e(rL,nse),e(nse,mht),e(rL,ght),e(Re,hht),e(Re,tL),e(tL,pxe),e(pxe,uht),e(tL,pht),e(tL,sse),e(sse,_ht),e(tL,vht),e(Re,bht),e(Re,aL),e(aL,_xe),e(_xe,Fht),e(aL,Tht),e(aL,lse),e(lse,Mht),e(aL,Eht),e(Re,Cht),e(Re,nL),e(nL,vxe),e(vxe,wht),e(nL,Aht),e(nL,ise),e(ise,Lht),e(nL,yht),e(Re,xht),e(Re,sL),e(sL,bxe),e(bxe,$ht),e(sL,kht),e(sL,dse),e(dse,Sht),e(sL,Rht),e(Re,Pht),e(Re,lL),e(lL,Fxe),e(Fxe,Bht),e(lL,Iht),e(lL,cse),e(cse,Nht),e(lL,qht),e(at,jht),M(iL,at,null),v(f,PZe,_),v(f,am,_),e(am,dL),e(dL,Txe),M(LR,Txe,null),e(am,Dht),e(am,Mxe),e(Mxe,Ght),v(f,BZe,_),v(f,xr,_),M(yR,xr,null),e(xr,Oht),e(xr,nm),e(nm,Vht),e(nm,fse),e(fse,Xht),e(nm,zht),e(nm,mse),e(mse,Qht),e(nm,Wht),e(xr,Uht),e(xr,xR),e(xR,Hht),e(xR,Exe),e(Exe,Jht),e(xR,Yht),e(xr,Kht),e(xr,ga),M($R,ga,null),e(ga,Zht),e(ga,Cxe),e(Cxe,eut),e(ga,out),e(ga,sm),e(sm,rut),e(sm,wxe),e(wxe,tut),e(sm,aut),e(sm,gse),e(gse,nut),e(sm,sut),e(ga,lut),M(cL,ga,null),e(xr,iut),e(xr,nt),M(kR,nt,null),e(nt,dut),e(nt,Axe),e(Axe,cut),e(nt,fut),e(nt,Wn),e(Wn,mut),e(Wn,Lxe),e(Lxe,gut),e(Wn,hut),e(Wn,yxe),e(yxe,uut),e(Wn,put),e(Wn,xxe),e(xxe,_ut),e(Wn,vut),e(nt,but),e(nt,Xe),e(Xe,fL),e(fL,$xe),e($xe,Fut),e(fL,Tut),e(fL,hse),e(hse,Mut),e(fL,Eut),e(Xe,Cut),e(Xe,mL),e(mL,kxe),e(kxe,wut),e(mL,Aut),e(mL,use),e(use,Lut),e(mL,yut),e(Xe,xut),e(Xe,gL),e(gL,Sxe),e(Sxe,$ut),e(gL,kut),e(gL,pse),e(pse,Sut),e(gL,Rut),e(Xe,Put),e(Xe,hL),e(hL,Rxe),e(Rxe,But),e(hL,Iut),e(hL,_se),e(_se,Nut),e(hL,qut),e(Xe,jut),e(Xe,uL),e(uL,Pxe),e(Pxe,Dut),e(uL,Gut),e(uL,vse),e(vse,Out),e(uL,Vut),e(Xe,Xut),e(Xe,pL),e(pL,Bxe),e(Bxe,zut),e(pL,Qut),e(pL,bse),e(bse,Wut),e(pL,Uut),e(Xe,Hut),e(Xe,_L),e(_L,Ixe),e(Ixe,Jut),e(_L,Yut),e(_L,Fse),e(Fse,Kut),e(_L,Zut),e(Xe,ept),e(Xe,vL),e(vL,Nxe),e(Nxe,opt),e(vL,rpt),e(vL,Tse),e(Tse,tpt),e(vL,apt),e(nt,npt),M(bL,nt,null),v(f,IZe,_),v(f,lm,_),e(lm,FL),e(FL,qxe),M(SR,qxe,null),e(lm,spt),e(lm,jxe),e(jxe,lpt),v(f,NZe,_),v(f,$r,_),M(RR,$r,null),e($r,ipt),e($r,im),e(im,dpt),e(im,Mse),e(Mse,cpt),e(im,fpt),e(im,Ese),e(Ese,mpt),e(im,gpt),e($r,hpt),e($r,PR),e(PR,upt),e(PR,Dxe),e(Dxe,ppt),e(PR,_pt),e($r,vpt),e($r,ha),M(BR,ha,null),e(ha,bpt),e(ha,Gxe),e(Gxe,Fpt),e(ha,Tpt),e(ha,dm),e(dm,Mpt),e(dm,Oxe),e(Oxe,Ept),e(dm,Cpt),e(dm,Cse),e(Cse,wpt),e(dm,Apt),e(ha,Lpt),M(TL,ha,null),e($r,ypt),e($r,st),M(IR,st,null),e(st,xpt),e(st,Vxe),e(Vxe,$pt),e(st,kpt),e(st,Un),e(Un,Spt),e(Un,Xxe),e(Xxe,Rpt),e(Un,Ppt),e(Un,zxe),e(zxe,Bpt),e(Un,Ipt),e(Un,Qxe),e(Qxe,Npt),e(Un,qpt),e(st,jpt),e(st,ze),e(ze,ML),e(ML,Wxe),e(Wxe,Dpt),e(ML,Gpt),e(ML,wse),e(wse,Opt),e(ML,Vpt),e(ze,Xpt),e(ze,EL),e(EL,Uxe),e(Uxe,zpt),e(EL,Qpt),e(EL,Ase),e(Ase,Wpt),e(EL,Upt),e(ze,Hpt),e(ze,CL),e(CL,Hxe),e(Hxe,Jpt),e(CL,Ypt),e(CL,Lse),e(Lse,Kpt),e(CL,Zpt),e(ze,e_t),e(ze,wL),e(wL,Jxe),e(Jxe,o_t),e(wL,r_t),e(wL,yse),e(yse,t_t),e(wL,a_t),e(ze,n_t),e(ze,AL),e(AL,Yxe),e(Yxe,s_t),e(AL,l_t),e(AL,xse),e(xse,i_t),e(AL,d_t),e(ze,c_t),e(ze,LL),e(LL,Kxe),e(Kxe,f_t),e(LL,m_t),e(LL,$se),e($se,g_t),e(LL,h_t),e(ze,u_t),e(ze,yL),e(yL,Zxe),e(Zxe,p_t),e(yL,__t),e(yL,kse),e(kse,v_t),e(yL,b_t),e(ze,F_t),e(ze,xL),e(xL,e$e),e(e$e,T_t),e(xL,M_t),e(xL,Sse),e(Sse,E_t),e(xL,C_t),e(st,w_t),M($L,st,null),v(f,qZe,_),v(f,cm,_),e(cm,kL),e(kL,o$e),M(NR,o$e,null),e(cm,A_t),e(cm,r$e),e(r$e,L_t),v(f,jZe,_),v(f,kr,_),M(qR,kr,null),e(kr,y_t),e(kr,fm),e(fm,x_t),e(fm,Rse),e(Rse,$_t),e(fm,k_t),e(fm,Pse),e(Pse,S_t),e(fm,R_t),e(kr,P_t),e(kr,jR),e(jR,B_t),e(jR,t$e),e(t$e,I_t),e(jR,N_t),e(kr,q_t),e(kr,ua),M(DR,ua,null),e(ua,j_t),e(ua,a$e),e(a$e,D_t),e(ua,G_t),e(ua,mm),e(mm,O_t),e(mm,n$e),e(n$e,V_t),e(mm,X_t),e(mm,Bse),e(Bse,z_t),e(mm,Q_t),e(ua,W_t),M(SL,ua,null),e(kr,U_t),e(kr,lt),M(GR,lt,null),e(lt,H_t),e(lt,s$e),e(s$e,J_t),e(lt,Y_t),e(lt,Hn),e(Hn,K_t),e(Hn,l$e),e(l$e,Z_t),e(Hn,e2t),e(Hn,i$e),e(i$e,o2t),e(Hn,r2t),e(Hn,d$e),e(d$e,t2t),e(Hn,a2t),e(lt,n2t),e(lt,c$e),e(c$e,RL),e(RL,f$e),e(f$e,s2t),e(RL,l2t),e(RL,Ise),e(Ise,i2t),e(RL,d2t),e(lt,c2t),M(PL,lt,null),v(f,DZe,_),v(f,gm,_),e(gm,BL),e(BL,m$e),M(OR,m$e,null),e(gm,f2t),e(gm,g$e),e(g$e,m2t),v(f,GZe,_),v(f,Sr,_),M(VR,Sr,null),e(Sr,g2t),e(Sr,hm),e(hm,h2t),e(hm,Nse),e(Nse,u2t),e(hm,p2t),e(hm,qse),e(qse,_2t),e(hm,v2t),e(Sr,b2t),e(Sr,XR),e(XR,F2t),e(XR,h$e),e(h$e,T2t),e(XR,M2t),e(Sr,E2t),e(Sr,pa),M(zR,pa,null),e(pa,C2t),e(pa,u$e),e(u$e,w2t),e(pa,A2t),e(pa,um),e(um,L2t),e(um,p$e),e(p$e,y2t),e(um,x2t),e(um,jse),e(jse,$2t),e(um,k2t),e(pa,S2t),M(IL,pa,null),e(Sr,R2t),e(Sr,it),M(QR,it,null),e(it,P2t),e(it,_$e),e(_$e,B2t),e(it,I2t),e(it,Jn),e(Jn,N2t),e(Jn,v$e),e(v$e,q2t),e(Jn,j2t),e(Jn,b$e),e(b$e,D2t),e(Jn,G2t),e(Jn,F$e),e(F$e,O2t),e(Jn,V2t),e(it,X2t),e(it,WR),e(WR,NL),e(NL,T$e),e(T$e,z2t),e(NL,Q2t),e(NL,Dse),e(Dse,W2t),e(NL,U2t),e(WR,H2t),e(WR,qL),e(qL,M$e),e(M$e,J2t),e(qL,Y2t),e(qL,Gse),e(Gse,K2t),e(qL,Z2t),e(it,evt),M(jL,it,null),v(f,OZe,_),v(f,pm,_),e(pm,DL),e(DL,E$e),M(UR,E$e,null),e(pm,ovt),e(pm,C$e),e(C$e,rvt),v(f,VZe,_),v(f,Rr,_),M(HR,Rr,null),e(Rr,tvt),e(Rr,_m),e(_m,avt),e(_m,Ose),e(Ose,nvt),e(_m,svt),e(_m,Vse),e(Vse,lvt),e(_m,ivt),e(Rr,dvt),e(Rr,JR),e(JR,cvt),e(JR,w$e),e(w$e,fvt),e(JR,mvt),e(Rr,gvt),e(Rr,_a),M(YR,_a,null),e(_a,hvt),e(_a,A$e),e(A$e,uvt),e(_a,pvt),e(_a,vm),e(vm,_vt),e(vm,L$e),e(L$e,vvt),e(vm,bvt),e(vm,Xse),e(Xse,Fvt),e(vm,Tvt),e(_a,Mvt),M(GL,_a,null),e(Rr,Evt),e(Rr,dt),M(KR,dt,null),e(dt,Cvt),e(dt,y$e),e(y$e,wvt),e(dt,Avt),e(dt,Yn),e(Yn,Lvt),e(Yn,x$e),e(x$e,yvt),e(Yn,xvt),e(Yn,$$e),e($$e,$vt),e(Yn,kvt),e(Yn,k$e),e(k$e,Svt),e(Yn,Rvt),e(dt,Pvt),e(dt,S$e),e(S$e,OL),e(OL,R$e),e(R$e,Bvt),e(OL,Ivt),e(OL,zse),e(zse,Nvt),e(OL,qvt),e(dt,jvt),M(VL,dt,null),XZe=!0},p(f,[_]){const ZR={};_&2&&(ZR.$$scope={dirty:_,ctx:f}),Lm.$set(ZR);const P$e={};_&2&&(P$e.$$scope={dirty:_,ctx:f}),Qh.$set(P$e);const B$e={};_&2&&(B$e.$$scope={dirty:_,ctx:f}),yu.$set(B$e);const I$e={};_&2&&(I$e.$$scope={dirty:_,ctx:f}),pp.$set(I$e);const eP={};_&2&&(eP.$$scope={dirty:_,ctx:f}),_p.$set(eP);const N$e={};_&2&&(N$e.$$scope={dirty:_,ctx:f}),Gp.$set(N$e);const Kn={};_&2&&(Kn.$$scope={dirty:_,ctx:f}),Op.$set(Kn);const q$e={};_&2&&(q$e.$$scope={dirty:_,ctx:f}),zp.$set(q$e);const j$e={};_&2&&(j$e.$$scope={dirty:_,ctx:f}),tv.$set(j$e);const D$e={};_&2&&(D$e.$$scope={dirty:_,ctx:f}),nv.$set(D$e);const oP={};_&2&&(oP.$$scope={dirty:_,ctx:f}),o1.$set(oP);const G$e={};_&2&&(G$e.$$scope={dirty:_,ctx:f}),t1.$set(G$e);const rP={};_&2&&(rP.$$scope={dirty:_,ctx:f}),Q1.$set(rP);const O$e={};_&2&&(O$e.$$scope={dirty:_,ctx:f}),U1.$set(O$e);const tP={};_&2&&(tP.$$scope={dirty:_,ctx:f}),B4.$set(tP);const V$e={};_&2&&(V$e.$$scope={dirty:_,ctx:f}),N4.$set(V$e);const X$e={};_&2&&(X$e.$$scope={dirty:_,ctx:f}),nb.$set(X$e);const z$e={};_&2&&(z$e.$$scope={dirty:_,ctx:f}),lb.$set(z$e);const bm={};_&2&&(bm.$$scope={dirty:_,ctx:f}),iF.$set(bm);const Q$e={};_&2&&(Q$e.$$scope={dirty:_,ctx:f}),cF.$set(Q$e);const W$e={};_&2&&(W$e.$$scope={dirty:_,ctx:f}),XF.$set(W$e);const U$e={};_&2&&(U$e.$$scope={dirty:_,ctx:f}),QF.$set(U$e);const aP={};_&2&&(aP.$$scope={dirty:_,ctx:f}),oT.$set(aP);const H$e={};_&2&&(H$e.$$scope={dirty:_,ctx:f}),tT.$set(H$e);const J$e={};_&2&&(J$e.$$scope={dirty:_,ctx:f}),VT.$set(J$e);const Y$e={};_&2&&(Y$e.$$scope={dirty:_,ctx:f}),zT.$set(Y$e);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:f}),NM.$set(ht);const nP={};_&2&&(nP.$$scope={dirty:_,ctx:f}),jM.$set(nP);const K$e={};_&2&&(K$e.$$scope={dirty:_,ctx:f}),OM.$set(K$e);const sP={};_&2&&(sP.$$scope={dirty:_,ctx:f}),XM.$set(sP);const Z$e={};_&2&&(Z$e.$$scope={dirty:_,ctx:f}),HM.$set(Z$e);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:f}),YM.$set(ut);const eke={};_&2&&(eke.$$scope={dirty:_,ctx:f}),gE.$set(eke);const Fm={};_&2&&(Fm.$$scope={dirty:_,ctx:f}),uE.$set(Fm);const oke={};_&2&&(oke.$$scope={dirty:_,ctx:f}),vE.$set(oke);const rke={};_&2&&(rke.$$scope={dirty:_,ctx:f}),FE.$set(rke);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),EE.$set(L);const XL={};_&2&&(XL.$$scope={dirty:_,ctx:f}),wE.$set(XL);const tke={};_&2&&(tke.$$scope={dirty:_,ctx:f}),yE.$set(tke);const ake={};_&2&&(ake.$$scope={dirty:_,ctx:f}),$E.$set(ake);const zL={};_&2&&(zL.$$scope={dirty:_,ctx:f}),GE.$set(zL);const nke={};_&2&&(nke.$$scope={dirty:_,ctx:f}),VE.$set(nke);const ske={};_&2&&(ske.$$scope={dirty:_,ctx:f}),JE.$set(ske);const QL={};_&2&&(QL.$$scope={dirty:_,ctx:f}),KE.$set(QL);const lke={};_&2&&(lke.$$scope={dirty:_,ctx:f}),cC.$set(lke);const ike={};_&2&&(ike.$$scope={dirty:_,ctx:f}),mC.$set(ike);const WL={};_&2&&(WL.$$scope={dirty:_,ctx:f}),pC.$set(WL);const dke={};_&2&&(dke.$$scope={dirty:_,ctx:f}),vC.$set(dke);const cke={};_&2&&(cke.$$scope={dirty:_,ctx:f}),wC.$set(cke);const UL={};_&2&&(UL.$$scope={dirty:_,ctx:f}),LC.$set(UL);const fke={};_&2&&(fke.$$scope={dirty:_,ctx:f}),RC.$set(fke);const mke={};_&2&&(mke.$$scope={dirty:_,ctx:f}),BC.$set(mke);const HL={};_&2&&(HL.$$scope={dirty:_,ctx:f}),jC.$set(HL);const gke={};_&2&&(gke.$$scope={dirty:_,ctx:f}),GC.$set(gke);const hke={};_&2&&(hke.$$scope={dirty:_,ctx:f}),XC.$set(hke);const JL={};_&2&&(JL.$$scope={dirty:_,ctx:f}),QC.$set(JL);const uke={};_&2&&(uke.$$scope={dirty:_,ctx:f}),ZC.$set(uke);const pke={};_&2&&(pke.$$scope={dirty:_,ctx:f}),o3.$set(pke);const YL={};_&2&&(YL.$$scope={dirty:_,ctx:f}),a3.$set(YL);const _ke={};_&2&&(_ke.$$scope={dirty:_,ctx:f}),s3.$set(_ke);const vke={};_&2&&(vke.$$scope={dirty:_,ctx:f}),s5.$set(vke);const KL={};_&2&&(KL.$$scope={dirty:_,ctx:f}),i5.$set(KL);const bke={};_&2&&(bke.$$scope={dirty:_,ctx:f}),S5.$set(bke);const Fke={};_&2&&(Fke.$$scope={dirty:_,ctx:f}),P5.$set(Fke);const ZL={};_&2&&(ZL.$$scope={dirty:_,ctx:f}),H5.$set(ZL);const Tke={};_&2&&(Tke.$$scope={dirty:_,ctx:f}),Y5.$set(Tke);const Mke={};_&2&&(Mke.$$scope={dirty:_,ctx:f}),s0.$set(Mke);const ey={};_&2&&(ey.$$scope={dirty:_,ctx:f}),i0.$set(ey);const Eke={};_&2&&(Eke.$$scope={dirty:_,ctx:f}),m0.$set(Eke);const Cke={};_&2&&(Cke.$$scope={dirty:_,ctx:f}),h0.$set(Cke);const oy={};_&2&&(oy.$$scope={dirty:_,ctx:f}),B0.$set(oy);const wke={};_&2&&(wke.$$scope={dirty:_,ctx:f}),N0.$set(wke);const Ake={};_&2&&(Ake.$$scope={dirty:_,ctx:f}),U0.$set(Ake);const ry={};_&2&&(ry.$$scope={dirty:_,ctx:f}),J0.$set(ry);const Lke={};_&2&&(Lke.$$scope={dirty:_,ctx:f}),Cw.$set(Lke);const yke={};_&2&&(yke.$$scope={dirty:_,ctx:f}),Aw.$set(yke);const ty={};_&2&&(ty.$$scope={dirty:_,ctx:f}),Xw.$set(ty);const xke={};_&2&&(xke.$$scope={dirty:_,ctx:f}),Qw.$set(xke);const $ke={};_&2&&($ke.$$scope={dirty:_,ctx:f}),Hw.$set($ke);const ay={};_&2&&(ay.$$scope={dirty:_,ctx:f}),Yw.$set(ay);const kke={};_&2&&(kke.$$scope={dirty:_,ctx:f}),Zw.$set(kke);const Ske={};_&2&&(Ske.$$scope={dirty:_,ctx:f}),oA.$set(Ske);const ny={};_&2&&(ny.$$scope={dirty:_,ctx:f}),tA.$set(ny);const Rke={};_&2&&(Rke.$$scope={dirty:_,ctx:f}),nA.$set(Rke);const Pke={};_&2&&(Pke.$$scope={dirty:_,ctx:f}),LA.$set(Pke);const sy={};_&2&&(sy.$$scope={dirty:_,ctx:f}),xA.$set(sy);const Bke={};_&2&&(Bke.$$scope={dirty:_,ctx:f}),YA.$set(Bke);const Ike={};_&2&&(Ike.$$scope={dirty:_,ctx:f}),ZA.$set(Ike);const ly={};_&2&&(ly.$$scope={dirty:_,ctx:f}),o6.$set(ly);const Nke={};_&2&&(Nke.$$scope={dirty:_,ctx:f}),t6.$set(Nke);const qke={};_&2&&(qke.$$scope={dirty:_,ctx:f}),n6.$set(qke);const iy={};_&2&&(iy.$$scope={dirty:_,ctx:f}),l6.$set(iy);const jke={};_&2&&(jke.$$scope={dirty:_,ctx:f}),B6.$set(jke);const Dke={};_&2&&(Dke.$$scope={dirty:_,ctx:f}),N6.$set(Dke);const dy={};_&2&&(dy.$$scope={dirty:_,ctx:f}),U6.$set(dy);const Gke={};_&2&&(Gke.$$scope={dirty:_,ctx:f}),J6.$set(Gke);const Oke={};_&2&&(Oke.$$scope={dirty:_,ctx:f}),c7.$set(Oke);const cy={};_&2&&(cy.$$scope={dirty:_,ctx:f}),m7.$set(cy);const Vke={};_&2&&(Vke.$$scope={dirty:_,ctx:f}),E7.$set(Vke);const Xke={};_&2&&(Xke.$$scope={dirty:_,ctx:f}),w7.$set(Xke);const fy={};_&2&&(fy.$$scope={dirty:_,ctx:f}),I7.$set(fy);const zke={};_&2&&(zke.$$scope={dirty:_,ctx:f}),q7.$set(zke);const Qke={};_&2&&(Qke.$$scope={dirty:_,ctx:f}),H7.$set(Qke);const my={};_&2&&(my.$$scope={dirty:_,ctx:f}),Y7.$set(my);const Wke={};_&2&&(Wke.$$scope={dirty:_,ctx:f}),iL.$set(Wke);const Uke={};_&2&&(Uke.$$scope={dirty:_,ctx:f}),cL.$set(Uke);const gy={};_&2&&(gy.$$scope={dirty:_,ctx:f}),bL.$set(gy);const Hke={};_&2&&(Hke.$$scope={dirty:_,ctx:f}),TL.$set(Hke);const Jke={};_&2&&(Jke.$$scope={dirty:_,ctx:f}),$L.$set(Jke);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:f}),SL.$set(hy);const Yke={};_&2&&(Yke.$$scope={dirty:_,ctx:f}),PL.$set(Yke);const Kke={};_&2&&(Kke.$$scope={dirty:_,ctx:f}),IL.$set(Kke);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:f}),jL.$set(uy);const Zke={};_&2&&(Zke.$$scope={dirty:_,ctx:f}),GL.$set(Zke);const eSe={};_&2&&(eSe.$$scope={dirty:_,ctx:f}),VL.$set(eSe)},i(f){XZe||(E(d.$$.fragment,f),E(Qa.$$.fragment,f),E(E9.$$.fragment,f),E(C9.$$.fragment,f),E(Lm.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(x9.$$.fragment,f),E(Qh.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(S9.$$.fragment,f),E(B9.$$.fragment,f),E(yu.$$.fragment,f),E(I9.$$.fragment,f),E(N9.$$.fragment,f),E(q9.$$.fragment,f),E(G9.$$.fragment,f),E(pp.$$.fragment,f),E(_p.$$.fragment,f),E(O9.$$.fragment,f),E(V9.$$.fragment,f),E(X9.$$.fragment,f),E(W9.$$.fragment,f),E(Gp.$$.fragment,f),E(Op.$$.fragment,f),E(U9.$$.fragment,f),E(H9.$$.fragment,f),E(J9.$$.fragment,f),E(K9.$$.fragment,f),E(zp.$$.fragment,f),E(Z9.$$.fragment,f),E(tv.$$.fragment,f),E(ex.$$.fragment,f),E(ox.$$.fragment,f),E(tx.$$.fragment,f),E(nv.$$.fragment,f),E(ax.$$.fragment,f),E(o1.$$.fragment,f),E(nx.$$.fragment,f),E(sx.$$.fragment,f),E(ix.$$.fragment,f),E(t1.$$.fragment,f),E(dx.$$.fragment,f),E(Q1.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E(U1.$$.fragment,f),E(hx.$$.fragment,f),E(B4.$$.fragment,f),E(ux.$$.fragment,f),E(px.$$.fragment,f),E(vx.$$.fragment,f),E(N4.$$.fragment,f),E(bx.$$.fragment,f),E(nb.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(lb.$$.fragment,f),E(Cx.$$.fragment,f),E(iF.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(yx.$$.fragment,f),E(cF.$$.fragment,f),E(xx.$$.fragment,f),E(XF.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(QF.$$.fragment,f),E(Px.$$.fragment,f),E(oT.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(qx.$$.fragment,f),E(tT.$$.fragment,f),E(jx.$$.fragment,f),E(VT.$$.fragment,f),E(Dx.$$.fragment,f),E(Gx.$$.fragment,f),E(Vx.$$.fragment,f),E(zT.$$.fragment,f),E(Xx.$$.fragment,f),E(NM.$$.fragment,f),E(zx.$$.fragment,f),E(Qx.$$.fragment,f),E(Ux.$$.fragment,f),E(jM.$$.fragment,f),E(Hx.$$.fragment,f),E(OM.$$.fragment,f),E(Jx.$$.fragment,f),E(Yx.$$.fragment,f),E(Zx.$$.fragment,f),E(XM.$$.fragment,f),E(e$.$$.fragment,f),E(HM.$$.fragment,f),E(o$.$$.fragment,f),E(r$.$$.fragment,f),E(a$.$$.fragment,f),E(YM.$$.fragment,f),E(n$.$$.fragment,f),E(gE.$$.fragment,f),E(s$.$$.fragment,f),E(l$.$$.fragment,f),E(d$.$$.fragment,f),E(uE.$$.fragment,f),E(c$.$$.fragment,f),E(vE.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(h$.$$.fragment,f),E(FE.$$.fragment,f),E(u$.$$.fragment,f),E(EE.$$.fragment,f),E(p$.$$.fragment,f),E(_$.$$.fragment,f),E(b$.$$.fragment,f),E(wE.$$.fragment,f),E(F$.$$.fragment,f),E(yE.$$.fragment,f),E(T$.$$.fragment,f),E(M$.$$.fragment,f),E(C$.$$.fragment,f),E($E.$$.fragment,f),E(w$.$$.fragment,f),E(GE.$$.fragment,f),E(A$.$$.fragment,f),E(L$.$$.fragment,f),E(x$.$$.fragment,f),E(VE.$$.fragment,f),E($$.$$.fragment,f),E(JE.$$.fragment,f),E(k$.$$.fragment,f),E(S$.$$.fragment,f),E(P$.$$.fragment,f),E(KE.$$.fragment,f),E(B$.$$.fragment,f),E(cC.$$.fragment,f),E(I$.$$.fragment,f),E(N$.$$.fragment,f),E(j$.$$.fragment,f),E(mC.$$.fragment,f),E(D$.$$.fragment,f),E(pC.$$.fragment,f),E(O$.$$.fragment,f),E(V$.$$.fragment,f),E(z$.$$.fragment,f),E(vC.$$.fragment,f),E(Q$.$$.fragment,f),E(wC.$$.fragment,f),E(W$.$$.fragment,f),E(U$.$$.fragment,f),E(J$.$$.fragment,f),E(LC.$$.fragment,f),E(Y$.$$.fragment,f),E(RC.$$.fragment,f),E(K$.$$.fragment,f),E(Z$.$$.fragment,f),E(ok.$$.fragment,f),E(BC.$$.fragment,f),E(rk.$$.fragment,f),E(jC.$$.fragment,f),E(ak.$$.fragment,f),E(nk.$$.fragment,f),E(lk.$$.fragment,f),E(GC.$$.fragment,f),E(ik.$$.fragment,f),E(XC.$$.fragment,f),E(dk.$$.fragment,f),E(ck.$$.fragment,f),E(mk.$$.fragment,f),E(QC.$$.fragment,f),E(gk.$$.fragment,f),E(ZC.$$.fragment,f),E(hk.$$.fragment,f),E(uk.$$.fragment,f),E(_k.$$.fragment,f),E(o3.$$.fragment,f),E(vk.$$.fragment,f),E(a3.$$.fragment,f),E(bk.$$.fragment,f),E(Fk.$$.fragment,f),E(Mk.$$.fragment,f),E(s3.$$.fragment,f),E(Ek.$$.fragment,f),E(s5.$$.fragment,f),E(Ck.$$.fragment,f),E(wk.$$.fragment,f),E(Lk.$$.fragment,f),E(i5.$$.fragment,f),E(yk.$$.fragment,f),E(S5.$$.fragment,f),E(xk.$$.fragment,f),E($k.$$.fragment,f),E(Sk.$$.fragment,f),E(P5.$$.fragment,f),E(Rk.$$.fragment,f),E(H5.$$.fragment,f),E(Pk.$$.fragment,f),E(Bk.$$.fragment,f),E(Nk.$$.fragment,f),E(Y5.$$.fragment,f),E(qk.$$.fragment,f),E(s0.$$.fragment,f),E(jk.$$.fragment,f),E(Dk.$$.fragment,f),E(Ok.$$.fragment,f),E(i0.$$.fragment,f),E(Vk.$$.fragment,f),E(m0.$$.fragment,f),E(Xk.$$.fragment,f),E(zk.$$.fragment,f),E(Wk.$$.fragment,f),E(h0.$$.fragment,f),E(Uk.$$.fragment,f),E(B0.$$.fragment,f),E(Hk.$$.fragment,f),E(Jk.$$.fragment,f),E(Kk.$$.fragment,f),E(N0.$$.fragment,f),E(Zk.$$.fragment,f),E(U0.$$.fragment,f),E(eS.$$.fragment,f),E(oS.$$.fragment,f),E(tS.$$.fragment,f),E(J0.$$.fragment,f),E(aS.$$.fragment,f),E(Cw.$$.fragment,f),E(nS.$$.fragment,f),E(sS.$$.fragment,f),E(iS.$$.fragment,f),E(Aw.$$.fragment,f),E(dS.$$.fragment,f),E(Xw.$$.fragment,f),E(cS.$$.fragment,f),E(fS.$$.fragment,f),E(gS.$$.fragment,f),E(Qw.$$.fragment,f),E(hS.$$.fragment,f),E(Hw.$$.fragment,f),E(pS.$$.fragment,f),E(_S.$$.fragment,f),E(bS.$$.fragment,f),E(Yw.$$.fragment,f),E(FS.$$.fragment,f),E(Zw.$$.fragment,f),E(TS.$$.fragment,f),E(MS.$$.fragment,f),E(CS.$$.fragment,f),E(oA.$$.fragment,f),E(wS.$$.fragment,f),E(tA.$$.fragment,f),E(AS.$$.fragment,f),E(LS.$$.fragment,f),E(xS.$$.fragment,f),E(nA.$$.fragment,f),E($S.$$.fragment,f),E(LA.$$.fragment,f),E(kS.$$.fragment,f),E(SS.$$.fragment,f),E(PS.$$.fragment,f),E(xA.$$.fragment,f),E(BS.$$.fragment,f),E(YA.$$.fragment,f),E(IS.$$.fragment,f),E(NS.$$.fragment,f),E(jS.$$.fragment,f),E(ZA.$$.fragment,f),E(DS.$$.fragment,f),E(o6.$$.fragment,f),E(GS.$$.fragment,f),E(OS.$$.fragment,f),E(XS.$$.fragment,f),E(t6.$$.fragment,f),E(zS.$$.fragment,f),E(n6.$$.fragment,f),E(QS.$$.fragment,f),E(WS.$$.fragment,f),E(HS.$$.fragment,f),E(l6.$$.fragment,f),E(JS.$$.fragment,f),E(B6.$$.fragment,f),E(YS.$$.fragment,f),E(KS.$$.fragment,f),E(eR.$$.fragment,f),E(N6.$$.fragment,f),E(oR.$$.fragment,f),E(U6.$$.fragment,f),E(rR.$$.fragment,f),E(tR.$$.fragment,f),E(nR.$$.fragment,f),E(J6.$$.fragment,f),E(sR.$$.fragment,f),E(c7.$$.fragment,f),E(lR.$$.fragment,f),E(iR.$$.fragment,f),E(cR.$$.fragment,f),E(m7.$$.fragment,f),E(fR.$$.fragment,f),E(E7.$$.fragment,f),E(mR.$$.fragment,f),E(gR.$$.fragment,f),E(uR.$$.fragment,f),E(w7.$$.fragment,f),E(pR.$$.fragment,f),E(I7.$$.fragment,f),E(_R.$$.fragment,f),E(vR.$$.fragment,f),E(FR.$$.fragment,f),E(q7.$$.fragment,f),E(TR.$$.fragment,f),E(H7.$$.fragment,f),E(MR.$$.fragment,f),E(ER.$$.fragment,f),E(wR.$$.fragment,f),E(Y7.$$.fragment,f),E(AR.$$.fragment,f),E(iL.$$.fragment,f),E(LR.$$.fragment,f),E(yR.$$.fragment,f),E($R.$$.fragment,f),E(cL.$$.fragment,f),E(kR.$$.fragment,f),E(bL.$$.fragment,f),E(SR.$$.fragment,f),E(RR.$$.fragment,f),E(BR.$$.fragment,f),E(TL.$$.fragment,f),E(IR.$$.fragment,f),E($L.$$.fragment,f),E(NR.$$.fragment,f),E(qR.$$.fragment,f),E(DR.$$.fragment,f),E(SL.$$.fragment,f),E(GR.$$.fragment,f),E(PL.$$.fragment,f),E(OR.$$.fragment,f),E(VR.$$.fragment,f),E(zR.$$.fragment,f),E(IL.$$.fragment,f),E(QR.$$.fragment,f),E(jL.$$.fragment,f),E(UR.$$.fragment,f),E(HR.$$.fragment,f),E(YR.$$.fragment,f),E(GL.$$.fragment,f),E(KR.$$.fragment,f),E(VL.$$.fragment,f),XZe=!0)},o(f){C(d.$$.fragment,f),C(Qa.$$.fragment,f),C(E9.$$.fragment,f),C(C9.$$.fragment,f),C(Lm.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(x9.$$.fragment,f),C(Qh.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(S9.$$.fragment,f),C(B9.$$.fragment,f),C(yu.$$.fragment,f),C(I9.$$.fragment,f),C(N9.$$.fragment,f),C(q9.$$.fragment,f),C(G9.$$.fragment,f),C(pp.$$.fragment,f),C(_p.$$.fragment,f),C(O9.$$.fragment,f),C(V9.$$.fragment,f),C(X9.$$.fragment,f),C(W9.$$.fragment,f),C(Gp.$$.fragment,f),C(Op.$$.fragment,f),C(U9.$$.fragment,f),C(H9.$$.fragment,f),C(J9.$$.fragment,f),C(K9.$$.fragment,f),C(zp.$$.fragment,f),C(Z9.$$.fragment,f),C(tv.$$.fragment,f),C(ex.$$.fragment,f),C(ox.$$.fragment,f),C(tx.$$.fragment,f),C(nv.$$.fragment,f),C(ax.$$.fragment,f),C(o1.$$.fragment,f),C(nx.$$.fragment,f),C(sx.$$.fragment,f),C(ix.$$.fragment,f),C(t1.$$.fragment,f),C(dx.$$.fragment,f),C(Q1.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C(U1.$$.fragment,f),C(hx.$$.fragment,f),C(B4.$$.fragment,f),C(ux.$$.fragment,f),C(px.$$.fragment,f),C(vx.$$.fragment,f),C(N4.$$.fragment,f),C(bx.$$.fragment,f),C(nb.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(lb.$$.fragment,f),C(Cx.$$.fragment,f),C(iF.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(yx.$$.fragment,f),C(cF.$$.fragment,f),C(xx.$$.fragment,f),C(XF.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(QF.$$.fragment,f),C(Px.$$.fragment,f),C(oT.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(qx.$$.fragment,f),C(tT.$$.fragment,f),C(jx.$$.fragment,f),C(VT.$$.fragment,f),C(Dx.$$.fragment,f),C(Gx.$$.fragment,f),C(Vx.$$.fragment,f),C(zT.$$.fragment,f),C(Xx.$$.fragment,f),C(NM.$$.fragment,f),C(zx.$$.fragment,f),C(Qx.$$.fragment,f),C(Ux.$$.fragment,f),C(jM.$$.fragment,f),C(Hx.$$.fragment,f),C(OM.$$.fragment,f),C(Jx.$$.fragment,f),C(Yx.$$.fragment,f),C(Zx.$$.fragment,f),C(XM.$$.fragment,f),C(e$.$$.fragment,f),C(HM.$$.fragment,f),C(o$.$$.fragment,f),C(r$.$$.fragment,f),C(a$.$$.fragment,f),C(YM.$$.fragment,f),C(n$.$$.fragment,f),C(gE.$$.fragment,f),C(s$.$$.fragment,f),C(l$.$$.fragment,f),C(d$.$$.fragment,f),C(uE.$$.fragment,f),C(c$.$$.fragment,f),C(vE.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(h$.$$.fragment,f),C(FE.$$.fragment,f),C(u$.$$.fragment,f),C(EE.$$.fragment,f),C(p$.$$.fragment,f),C(_$.$$.fragment,f),C(b$.$$.fragment,f),C(wE.$$.fragment,f),C(F$.$$.fragment,f),C(yE.$$.fragment,f),C(T$.$$.fragment,f),C(M$.$$.fragment,f),C(C$.$$.fragment,f),C($E.$$.fragment,f),C(w$.$$.fragment,f),C(GE.$$.fragment,f),C(A$.$$.fragment,f),C(L$.$$.fragment,f),C(x$.$$.fragment,f),C(VE.$$.fragment,f),C($$.$$.fragment,f),C(JE.$$.fragment,f),C(k$.$$.fragment,f),C(S$.$$.fragment,f),C(P$.$$.fragment,f),C(KE.$$.fragment,f),C(B$.$$.fragment,f),C(cC.$$.fragment,f),C(I$.$$.fragment,f),C(N$.$$.fragment,f),C(j$.$$.fragment,f),C(mC.$$.fragment,f),C(D$.$$.fragment,f),C(pC.$$.fragment,f),C(O$.$$.fragment,f),C(V$.$$.fragment,f),C(z$.$$.fragment,f),C(vC.$$.fragment,f),C(Q$.$$.fragment,f),C(wC.$$.fragment,f),C(W$.$$.fragment,f),C(U$.$$.fragment,f),C(J$.$$.fragment,f),C(LC.$$.fragment,f),C(Y$.$$.fragment,f),C(RC.$$.fragment,f),C(K$.$$.fragment,f),C(Z$.$$.fragment,f),C(ok.$$.fragment,f),C(BC.$$.fragment,f),C(rk.$$.fragment,f),C(jC.$$.fragment,f),C(ak.$$.fragment,f),C(nk.$$.fragment,f),C(lk.$$.fragment,f),C(GC.$$.fragment,f),C(ik.$$.fragment,f),C(XC.$$.fragment,f),C(dk.$$.fragment,f),C(ck.$$.fragment,f),C(mk.$$.fragment,f),C(QC.$$.fragment,f),C(gk.$$.fragment,f),C(ZC.$$.fragment,f),C(hk.$$.fragment,f),C(uk.$$.fragment,f),C(_k.$$.fragment,f),C(o3.$$.fragment,f),C(vk.$$.fragment,f),C(a3.$$.fragment,f),C(bk.$$.fragment,f),C(Fk.$$.fragment,f),C(Mk.$$.fragment,f),C(s3.$$.fragment,f),C(Ek.$$.fragment,f),C(s5.$$.fragment,f),C(Ck.$$.fragment,f),C(wk.$$.fragment,f),C(Lk.$$.fragment,f),C(i5.$$.fragment,f),C(yk.$$.fragment,f),C(S5.$$.fragment,f),C(xk.$$.fragment,f),C($k.$$.fragment,f),C(Sk.$$.fragment,f),C(P5.$$.fragment,f),C(Rk.$$.fragment,f),C(H5.$$.fragment,f),C(Pk.$$.fragment,f),C(Bk.$$.fragment,f),C(Nk.$$.fragment,f),C(Y5.$$.fragment,f),C(qk.$$.fragment,f),C(s0.$$.fragment,f),C(jk.$$.fragment,f),C(Dk.$$.fragment,f),C(Ok.$$.fragment,f),C(i0.$$.fragment,f),C(Vk.$$.fragment,f),C(m0.$$.fragment,f),C(Xk.$$.fragment,f),C(zk.$$.fragment,f),C(Wk.$$.fragment,f),C(h0.$$.fragment,f),C(Uk.$$.fragment,f),C(B0.$$.fragment,f),C(Hk.$$.fragment,f),C(Jk.$$.fragment,f),C(Kk.$$.fragment,f),C(N0.$$.fragment,f),C(Zk.$$.fragment,f),C(U0.$$.fragment,f),C(eS.$$.fragment,f),C(oS.$$.fragment,f),C(tS.$$.fragment,f),C(J0.$$.fragment,f),C(aS.$$.fragment,f),C(Cw.$$.fragment,f),C(nS.$$.fragment,f),C(sS.$$.fragment,f),C(iS.$$.fragment,f),C(Aw.$$.fragment,f),C(dS.$$.fragment,f),C(Xw.$$.fragment,f),C(cS.$$.fragment,f),C(fS.$$.fragment,f),C(gS.$$.fragment,f),C(Qw.$$.fragment,f),C(hS.$$.fragment,f),C(Hw.$$.fragment,f),C(pS.$$.fragment,f),C(_S.$$.fragment,f),C(bS.$$.fragment,f),C(Yw.$$.fragment,f),C(FS.$$.fragment,f),C(Zw.$$.fragment,f),C(TS.$$.fragment,f),C(MS.$$.fragment,f),C(CS.$$.fragment,f),C(oA.$$.fragment,f),C(wS.$$.fragment,f),C(tA.$$.fragment,f),C(AS.$$.fragment,f),C(LS.$$.fragment,f),C(xS.$$.fragment,f),C(nA.$$.fragment,f),C($S.$$.fragment,f),C(LA.$$.fragment,f),C(kS.$$.fragment,f),C(SS.$$.fragment,f),C(PS.$$.fragment,f),C(xA.$$.fragment,f),C(BS.$$.fragment,f),C(YA.$$.fragment,f),C(IS.$$.fragment,f),C(NS.$$.fragment,f),C(jS.$$.fragment,f),C(ZA.$$.fragment,f),C(DS.$$.fragment,f),C(o6.$$.fragment,f),C(GS.$$.fragment,f),C(OS.$$.fragment,f),C(XS.$$.fragment,f),C(t6.$$.fragment,f),C(zS.$$.fragment,f),C(n6.$$.fragment,f),C(QS.$$.fragment,f),C(WS.$$.fragment,f),C(HS.$$.fragment,f),C(l6.$$.fragment,f),C(JS.$$.fragment,f),C(B6.$$.fragment,f),C(YS.$$.fragment,f),C(KS.$$.fragment,f),C(eR.$$.fragment,f),C(N6.$$.fragment,f),C(oR.$$.fragment,f),C(U6.$$.fragment,f),C(rR.$$.fragment,f),C(tR.$$.fragment,f),C(nR.$$.fragment,f),C(J6.$$.fragment,f),C(sR.$$.fragment,f),C(c7.$$.fragment,f),C(lR.$$.fragment,f),C(iR.$$.fragment,f),C(cR.$$.fragment,f),C(m7.$$.fragment,f),C(fR.$$.fragment,f),C(E7.$$.fragment,f),C(mR.$$.fragment,f),C(gR.$$.fragment,f),C(uR.$$.fragment,f),C(w7.$$.fragment,f),C(pR.$$.fragment,f),C(I7.$$.fragment,f),C(_R.$$.fragment,f),C(vR.$$.fragment,f),C(FR.$$.fragment,f),C(q7.$$.fragment,f),C(TR.$$.fragment,f),C(H7.$$.fragment,f),C(MR.$$.fragment,f),C(ER.$$.fragment,f),C(wR.$$.fragment,f),C(Y7.$$.fragment,f),C(AR.$$.fragment,f),C(iL.$$.fragment,f),C(LR.$$.fragment,f),C(yR.$$.fragment,f),C($R.$$.fragment,f),C(cL.$$.fragment,f),C(kR.$$.fragment,f),C(bL.$$.fragment,f),C(SR.$$.fragment,f),C(RR.$$.fragment,f),C(BR.$$.fragment,f),C(TL.$$.fragment,f),C(IR.$$.fragment,f),C($L.$$.fragment,f),C(NR.$$.fragment,f),C(qR.$$.fragment,f),C(DR.$$.fragment,f),C(SL.$$.fragment,f),C(GR.$$.fragment,f),C(PL.$$.fragment,f),C(OR.$$.fragment,f),C(VR.$$.fragment,f),C(zR.$$.fragment,f),C(IL.$$.fragment,f),C(QR.$$.fragment,f),C(jL.$$.fragment,f),C(UR.$$.fragment,f),C(HR.$$.fragment,f),C(YR.$$.fragment,f),C(GL.$$.fragment,f),C(KR.$$.fragment,f),C(VL.$$.fragment,f),XZe=!1},d(f){t(g),f&&t(b),f&&t(u),w(d),f&&t(Mm),f&&t(pt),f&&t(Ve),f&&t(He),f&&t(Cm),w(Qa,f),f&&t(Je),f&&t(Ae),f&&t(xo),f&&t(Wa),f&&t(kYe),f&&t(dd),w(E9),f&&t(SYe),f&&t(ts),f&&t(RYe),w(C9,f),f&&t(PYe),f&&t(xB),f&&t(BYe),w(Lm,f),f&&t(IYe),f&&t(cd),w(w9),f&&t(NYe),f&&t($o),w(A9),w(x9),w(Qh),w($9),f&&t(qYe),f&&t(md),w(k9),f&&t(jYe),f&&t(ko),w(S9),w(B9),w(yu),w(I9),f&&t(DYe),f&&t(gd),w(N9),f&&t(GYe),f&&t(So),w(q9),w(G9),w(pp),w(_p),w(O9),f&&t(OYe),f&&t(hd),w(V9),f&&t(VYe),f&&t(Ro),w(X9),w(W9),w(Gp),w(Op),w(U9),f&&t(XYe),f&&t(pd),w(H9),f&&t(zYe),f&&t(Po),w(J9),w(K9),w(zp),w(Z9),w(tv),f&&t(QYe),f&&t(bd),w(ex),f&&t(WYe),f&&t(Bo),w(ox),w(tx),w(nv),w(ax),w(o1),f&&t(UYe),f&&t(Md),w(nx),f&&t(HYe),f&&t(Io),w(sx),w(ix),w(t1),w(dx),w(Q1),f&&t(JYe),f&&t(wd),w(cx),f&&t(YYe),f&&t(No),w(fx),w(gx),w(U1),w(hx),w(B4),f&&t(KYe),f&&t(yd),w(ux),f&&t(ZYe),f&&t(qo),w(px),w(vx),w(N4),w(bx),w(nb),f&&t(eKe),f&&t(kd),w(Fx),f&&t(oKe),f&&t(jo),w(Tx),w(Ex),w(lb),w(Cx),w(iF),f&&t(rKe),f&&t(Pd),w(wx),f&&t(tKe),f&&t(Do),w(Ax),w(yx),w(cF),w(xx),w(XF),f&&t(aKe),f&&t(Nd),w($x),f&&t(nKe),f&&t(Go),w(kx),w(Rx),w(QF),w(Px),w(oT),f&&t(sKe),f&&t(Dd),w(Bx),f&&t(lKe),f&&t(Oo),w(Ix),w(qx),w(tT),w(jx),w(VT),f&&t(iKe),f&&t(Vd),w(Dx),f&&t(dKe),f&&t(Vo),w(Gx),w(Vx),w(zT),w(Xx),w(NM),f&&t(cKe),f&&t(Qd),w(zx),f&&t(fKe),f&&t(Xo),w(Qx),w(Ux),w(jM),w(Hx),w(OM),f&&t(mKe),f&&t(Hd),w(Jx),f&&t(gKe),f&&t(zo),w(Yx),w(Zx),w(XM),w(e$),w(HM),f&&t(hKe),f&&t(Zd),w(o$),f&&t(uKe),f&&t(Qo),w(r$),w(a$),w(YM),w(n$),w(gE),f&&t(pKe),f&&t(rc),w(s$),f&&t(_Ke),f&&t(Wo),w(l$),w(d$),w(uE),w(c$),w(vE),f&&t(vKe),f&&t(nc),w(f$),f&&t(bKe),f&&t(Uo),w(m$),w(h$),w(FE),w(u$),w(EE),f&&t(FKe),f&&t(ic),w(p$),f&&t(TKe),f&&t(Ho),w(_$),w(b$),w(wE),w(F$),w(yE),f&&t(MKe),f&&t(fc),w(T$),f&&t(EKe),f&&t(Jo),w(M$),w(C$),w($E),w(w$),w(GE),f&&t(CKe),f&&t(hc),w(A$),f&&t(wKe),f&&t(Yo),w(L$),w(x$),w(VE),w($$),w(JE),f&&t(AKe),f&&t(_c),w(k$),f&&t(LKe),f&&t(Ko),w(S$),w(P$),w(KE),w(B$),w(cC),f&&t(yKe),f&&t(Fc),w(I$),f&&t(xKe),f&&t(Zo),w(N$),w(j$),w(mC),w(D$),w(pC),f&&t($Ke),f&&t(Ec),w(O$),f&&t(kKe),f&&t(er),w(V$),w(z$),w(vC),w(Q$),w(wC),f&&t(SKe),f&&t(Ac),w(W$),f&&t(RKe),f&&t(or),w(U$),w(J$),w(LC),w(Y$),w(RC),f&&t(PKe),f&&t(xc),w(K$),f&&t(BKe),f&&t(rr),w(Z$),w(ok),w(BC),w(rk),w(jC),f&&t(IKe),f&&t(Sc),w(ak),f&&t(NKe),f&&t(tr),w(nk),w(lk),w(GC),w(ik),w(XC),f&&t(qKe),f&&t(Bc),w(dk),f&&t(jKe),f&&t(ar),w(ck),w(mk),w(QC),w(gk),w(ZC),f&&t(DKe),f&&t(qc),w(hk),f&&t(GKe),f&&t(nr),w(uk),w(_k),w(o3),w(vk),w(a3),f&&t(OKe),f&&t(Gc),w(bk),f&&t(VKe),f&&t(sr),w(Fk),w(Mk),w(s3),w(Ek),w(s5),f&&t(XKe),f&&t(Xc),w(Ck),f&&t(zKe),f&&t(lr),w(wk),w(Lk),w(i5),w(yk),w(S5),f&&t(QKe),f&&t(Wc),w(xk),f&&t(WKe),f&&t(ir),w($k),w(Sk),w(P5),w(Rk),w(H5),f&&t(UKe),f&&t(Jc),w(Pk),f&&t(HKe),f&&t(dr),w(Bk),w(Nk),w(Y5),w(qk),w(s0),f&&t(JKe),f&&t(Zc),w(jk),f&&t(YKe),f&&t(cr),w(Dk),w(Ok),w(i0),w(Vk),w(m0),f&&t(KKe),f&&t(tf),w(Xk),f&&t(ZKe),f&&t(fr),w(zk),w(Wk),w(h0),w(Uk),w(B0),f&&t(eZe),f&&t(sf),w(Hk),f&&t(oZe),f&&t(mr),w(Jk),w(Kk),w(N0),w(Zk),w(U0),f&&t(rZe),f&&t(cf),w(eS),f&&t(tZe),f&&t(gr),w(oS),w(tS),w(J0),w(aS),w(Cw),f&&t(aZe),f&&t(gf),w(nS),f&&t(nZe),f&&t(hr),w(sS),w(iS),w(Aw),w(dS),w(Xw),f&&t(sZe),f&&t(pf),w(cS),f&&t(lZe),f&&t(ur),w(fS),w(gS),w(Qw),w(hS),w(Hw),f&&t(iZe),f&&t(bf),w(pS),f&&t(dZe),f&&t(pr),w(_S),w(bS),w(Yw),w(FS),w(Zw),f&&t(cZe),f&&t(Mf),w(TS),f&&t(fZe),f&&t(_r),w(MS),w(CS),w(oA),w(wS),w(tA),f&&t(mZe),f&&t(wf),w(AS),f&&t(gZe),f&&t(vr),w(LS),w(xS),w(nA),w($S),w(LA),f&&t(hZe),f&&t(yf),w(kS),f&&t(uZe),f&&t(br),w(SS),w(PS),w(xA),w(BS),w(YA),f&&t(pZe),f&&t(kf),w(IS),f&&t(_Ze),f&&t(Fr),w(NS),w(jS),w(ZA),w(DS),w(o6),f&&t(vZe),f&&t(Pf),w(GS),f&&t(bZe),f&&t(Tr),w(OS),w(XS),w(t6),w(zS),w(n6),f&&t(FZe),f&&t(Nf),w(QS),f&&t(TZe),f&&t(Mr),w(WS),w(HS),w(l6),w(JS),w(B6),f&&t(MZe),f&&t(Df),w(YS),f&&t(EZe),f&&t(Er),w(KS),w(eR),w(N6),w(oR),w(U6),f&&t(CZe),f&&t(Vf),w(rR),f&&t(wZe),f&&t(Cr),w(tR),w(nR),w(J6),w(sR),w(c7),f&&t(AZe),f&&t(Qf),w(lR),f&&t(LZe),f&&t(wr),w(iR),w(cR),w(m7),w(fR),w(E7),f&&t(yZe),f&&t(Hf),w(mR),f&&t(xZe),f&&t(Ar),w(gR),w(uR),w(w7),w(pR),w(I7),f&&t($Ze),f&&t(Kf),w(_R),f&&t(kZe),f&&t(Lr),w(vR),w(FR),w(q7),w(TR),w(H7),f&&t(SZe),f&&t(om),w(MR),f&&t(RZe),f&&t(yr),w(ER),w(wR),w(Y7),w(AR),w(iL),f&&t(PZe),f&&t(am),w(LR),f&&t(BZe),f&&t(xr),w(yR),w($R),w(cL),w(kR),w(bL),f&&t(IZe),f&&t(lm),w(SR),f&&t(NZe),f&&t($r),w(RR),w(BR),w(TL),w(IR),w($L),f&&t(qZe),f&&t(cm),w(NR),f&&t(jZe),f&&t(kr),w(qR),w(DR),w(SL),w(GR),w(PL),f&&t(DZe),f&&t(gm),w(OR),f&&t(GZe),f&&t(Sr),w(VR),w(zR),w(IL),w(QR),w(jL),f&&t(OZe),f&&t(pm),w(UR),f&&t(VZe),f&&t(Rr),w(HR),w(YR),w(GL),w(KR),w(VL)}}}const Hha={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Jha($){return Dma(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tua extends Ima{constructor(g){super();Nma(this,g,Jha,Uha,qma,{})}}export{tua as default,Hha as metadata};
