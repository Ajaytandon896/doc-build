import{S as W0,i as B0,s as Q0,e as r,k as l,w as k,t,M as U0,c as a,d as n,m as d,a as i,x as F,h as o,b as c,F as e,g as h,y as b,q as y,o as w,B as $,v as R0}from"../../chunks/vendor-6b77c823.js";import{T as qe}from"../../chunks/Tip-39098574.js";import{D as X}from"../../chunks/Docstring-17b815d9.js";import{C as be}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as Ce}from"../../chunks/IconCopyLink-7a11ce68.js";function V0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function H0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function Y0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function K0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function G0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function Z0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function X0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function J0(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function e2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function n2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function t2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function o2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function s2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function r2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function a2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function i2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function l2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function d2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function c2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function p2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function u2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function h2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function f2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge;return{c(){u=r("p"),z=t("TF 2.0 models accepts two formats as inputs:"),g=l(),_=r("ul"),T=r("li"),v=t("having all inputs as keyword arguments (like PyTorch models), or"),m=l(),M=r("li"),ce=t("having all inputs as a list, tuple or dict in the first positional arguments."),K=l(),q=r("p"),J=t("This second option is useful when using "),A=r("code"),ne=t("tf.keras.Model.fit"),pe=t(` method which currently requires having all the
tensors in the first argument of the model call function: `),N=r("code"),ue=t("model(inputs)"),ie=t("."),Y=l(),L=r("p"),te=t(`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),G=l(),P=r("ul"),x=r("li"),oe=t("a single Tensor with "),B=r("code"),le=t("input_ids"),se=t(" only and nothing else: "),S=r("code"),he=t("model(inputs_ids)"),de=l(),C=r("li"),fe=t(`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=r("code"),ee=t("model([input_ids, attention_mask])"),ae=t(" or "),Q=r("code"),me=t("model([input_ids, attention_mask, token_type_ids])"),I=l(),O=r("li"),re=t(`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=r("code"),ge=t('model({"input_ids": input_ids, "token_type_ids": token_type_ids})')},l(p){u=a(p,"P",{});var E=i(u);z=o(E,"TF 2.0 models accepts two formats as inputs:"),E.forEach(n),g=d(p),_=a(p,"UL",{});var Z=i(_);T=a(Z,"LI",{});var ve=i(T);v=o(ve,"having all inputs as keyword arguments (like PyTorch models), or"),ve.forEach(n),m=d(Z),M=a(Z,"LI",{});var ye=i(M);ce=o(ye,"having all inputs as a list, tuple or dict in the first positional arguments."),ye.forEach(n),Z.forEach(n),K=d(p),q=a(p,"P",{});var D=i(q);J=o(D,"This second option is useful when using "),A=a(D,"CODE",{});var Te=i(A);ne=o(Te,"tf.keras.Model.fit"),Te.forEach(n),pe=o(D,` method which currently requires having all the
tensors in the first argument of the model call function: `),N=a(D,"CODE",{});var we=i(N);ue=o(we,"model(inputs)"),we.forEach(n),ie=o(D,"."),D.forEach(n),Y=d(p),L=a(p,"P",{});var $e=i(L);te=o($e,`If you choose this second option, there are three possibilities you can use to gather all the input Tensors in the
first positional argument :`),$e.forEach(n),G=d(p),P=a(p,"UL",{});var j=i(P);x=a(j,"LI",{});var R=i(x);oe=o(R,"a single Tensor with "),B=a(R,"CODE",{});var Ee=i(B);le=o(Ee,"input_ids"),Ee.forEach(n),se=o(R," only and nothing else: "),S=a(R,"CODE",{});var ke=i(S);he=o(ke,"model(inputs_ids)"),ke.forEach(n),R.forEach(n),de=d(j),C=a(j,"LI",{});var V=i(C);fe=o(V,`a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:
`),W=a(V,"CODE",{});var Me=i(W);ee=o(Me,"model([input_ids, attention_mask])"),Me.forEach(n),ae=o(V," or "),Q=a(V,"CODE",{});var Fe=i(Q);me=o(Fe,"model([input_ids, attention_mask, token_type_ids])"),Fe.forEach(n),V.forEach(n),I=d(j),O=a(j,"LI",{});var _e=i(O);re=o(_e,`a dictionary with one or several input Tensors associated to the input names given in the docstring:
`),U=a(_e,"CODE",{});var ze=i(U);ge=o(ze,'model({"input_ids": input_ids, "token_type_ids": token_type_ids})'),ze.forEach(n),_e.forEach(n),j.forEach(n)},m(p,E){h(p,u,E),e(u,z),h(p,g,E),h(p,_,E),e(_,T),e(T,v),e(_,m),e(_,M),e(M,ce),h(p,K,E),h(p,q,E),e(q,J),e(q,A),e(A,ne),e(q,pe),e(q,N),e(N,ue),e(q,ie),h(p,Y,E),h(p,L,E),e(L,te),h(p,G,E),h(p,P,E),e(P,x),e(x,oe),e(x,B),e(B,le),e(x,se),e(x,S),e(S,he),e(P,de),e(P,C),e(C,fe),e(C,W),e(W,ee),e(C,ae),e(C,Q),e(Q,me),e(P,I),e(P,O),e(O,re),e(O,U),e(U,ge)},d(p){p&&n(u),p&&n(g),p&&n(_),p&&n(K),p&&n(q),p&&n(Y),p&&n(L),p&&n(G),p&&n(P)}}}function m2(H){let u,z,g,_,T;return{c(){u=r("p"),z=t("Although the recipe for forward pass needs to be defined within this function, one should call the "),g=r("code"),_=t("Module"),T=t(`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`)},l(v){u=a(v,"P",{});var m=i(u);z=o(m,"Although the recipe for forward pass needs to be defined within this function, one should call the "),g=a(m,"CODE",{});var M=i(g);_=o(M,"Module"),M.forEach(n),T=o(m,`
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`),m.forEach(n)},m(v,m){h(v,u,m),e(u,z),e(u,g),e(g,_),e(u,T)},d(v){v&&n(u)}}}function g2(H){let u,z,g,_,T,v,m,M,ce,K,q,J,A,ne,pe,N,ue,ie,Y,L,te,G,P,x,oe,B,le,se,S,he,de,C,fe,W,ee,ae,Q,me,I,O,re,U,ge,p,E,Z,ve,ye,D,Te,we,$e,j,R,Ee,ke,V,Me,Fe,_e,ze,oi,Yu,Ku,Oc,In,Gu,No,Zu,Xu,So,Ju,eh,Dc,Zn,Wt,kl,Io,nh,Fl,th,Ac,Nn,Wo,oh,Sn,sh,si,rh,ah,ri,ih,lh,Bo,dh,ch,ph,Xn,uh,ai,hh,fh,ii,mh,gh,Nc,Jn,Bt,bl,Qo,_h,yl,vh,Sc,xe,Uo,Th,wl,kh,Fh,Qt,li,bh,yh,di,wh,$h,Eh,Ro,Mh,ci,zh,qh,Ph,Wn,Vo,Ch,$l,xh,jh,Ho,pi,Lh,El,Oh,Dh,ui,Ah,Ml,Nh,Sh,Ut,Yo,Ih,Ko,Wh,zl,Bh,Qh,Uh,bn,Go,Rh,ql,Vh,Hh,Zo,Yh,et,Kh,Pl,Gh,Zh,Cl,Xh,Jh,ef,hi,Xo,Ic,nt,Rt,xl,Jo,nf,jl,tf,Wc,sn,es,of,ns,sf,Ll,rf,af,lf,Vt,fi,df,cf,mi,pf,uf,hf,ts,ff,gi,mf,gf,_f,yn,os,vf,Ol,Tf,kf,ss,Ff,tt,bf,Dl,yf,wf,Al,$f,Ef,Bc,ot,Ht,Nl,rs,Mf,Sl,zf,Qc,st,as,qf,is,Pf,_i,Cf,xf,Uc,rt,ls,jf,ds,Lf,vi,Of,Df,Rc,at,Yt,Il,cs,Af,Wl,Nf,Vc,Qe,ps,Sf,Bl,If,Wf,us,Bf,hs,Qf,Uf,Rf,fs,Vf,Ti,Hf,Yf,Kf,ms,Gf,gs,Zf,Xf,Jf,rn,_s,em,it,nm,ki,tm,om,Ql,sm,rm,am,Kt,im,Ul,lm,dm,vs,Hc,lt,Gt,Rl,Ts,cm,Vl,pm,Yc,Ue,ks,um,Hl,hm,fm,Fs,mm,bs,gm,_m,vm,ys,Tm,Fi,km,Fm,bm,ws,ym,$s,wm,$m,Em,an,Es,Mm,dt,zm,bi,qm,Pm,Yl,Cm,xm,jm,Zt,Lm,Kl,Om,Dm,Ms,Kc,ct,Xt,Gl,zs,Am,Zl,Nm,Gc,pt,qs,Sm,ln,Ps,Im,ut,Wm,yi,Bm,Qm,Xl,Um,Rm,Vm,Jt,Hm,Jl,Ym,Km,Cs,Zc,ht,eo,ed,xs,Gm,nd,Zm,Xc,Re,js,Xm,Ls,Jm,td,eg,ng,tg,Os,og,Ds,sg,rg,ag,As,ig,wi,lg,dg,cg,Ns,pg,Ss,ug,hg,fg,Ge,Is,mg,ft,gg,$i,_g,vg,od,Tg,kg,Fg,no,bg,sd,yg,wg,Ws,$g,Bs,Jc,mt,to,rd,Qs,Eg,ad,Mg,ep,Ve,Us,zg,id,qg,Pg,Rs,Cg,Vs,xg,jg,Lg,Hs,Og,Ei,Dg,Ag,Ng,Ys,Sg,Ks,Ig,Wg,Bg,Pe,Gs,Qg,gt,Ug,Mi,Rg,Vg,ld,Hg,Yg,Kg,oo,Gg,dd,Zg,Xg,Zs,Jg,Xs,e_,cd,n_,t_,Js,o_,er,np,_t,so,pd,nr,s_,ud,r_,tp,He,tr,a_,hd,i_,l_,or,d_,sr,c_,p_,u_,rr,h_,zi,f_,m_,g_,ar,__,ir,v_,T_,k_,dn,lr,F_,vt,b_,qi,y_,w_,fd,$_,E_,M_,ro,z_,md,q_,P_,dr,op,Tt,ao,gd,cr,C_,_d,x_,sp,Ye,pr,j_,vd,L_,O_,ur,D_,hr,A_,N_,S_,fr,I_,Pi,W_,B_,Q_,mr,U_,gr,R_,V_,H_,Ze,_r,Y_,kt,K_,Ci,G_,Z_,Td,X_,J_,ev,io,nv,kd,tv,ov,vr,sv,Tr,rp,Ft,lo,Fd,kr,rv,bd,av,ap,Ke,Fr,iv,bt,lv,yd,dv,cv,wd,pv,uv,hv,br,fv,yr,mv,gv,_v,wr,vv,xi,Tv,kv,Fv,$r,bv,Er,yv,wv,$v,Xe,Mr,Ev,yt,Mv,ji,zv,qv,$d,Pv,Cv,xv,co,jv,Ed,Lv,Ov,zr,Dv,qr,ip,wt,po,Md,Pr,Av,zd,Nv,lp,Le,Cr,Sv,qd,Iv,Wv,xr,Bv,jr,Qv,Uv,Rv,Lr,Vv,Li,Hv,Yv,Kv,Or,Gv,Dr,Zv,Xv,Jv,uo,eT,cn,Ar,nT,$t,tT,Oi,oT,sT,Pd,rT,aT,iT,ho,lT,Cd,dT,cT,Nr,dp,Et,fo,xd,Sr,pT,jd,uT,cp,Oe,Ir,hT,Ld,fT,mT,Wr,gT,Br,_T,vT,TT,Qr,kT,Di,FT,bT,yT,Ur,wT,Rr,$T,ET,MT,mo,zT,pn,Vr,qT,Mt,PT,Ai,CT,xT,Od,jT,LT,OT,go,DT,Dd,AT,NT,Hr,pp,zt,_o,Ad,Yr,ST,Nd,IT,up,De,Kr,WT,Sd,BT,QT,Gr,UT,Zr,RT,VT,HT,Xr,YT,Ni,KT,GT,ZT,Jr,XT,ea,JT,ek,nk,vo,tk,un,na,ok,qt,sk,Si,rk,ak,Id,ik,lk,dk,To,ck,Wd,pk,uk,ta,hp,Pt,ko,Bd,oa,hk,Qd,fk,fp,Ae,sa,mk,ra,gk,Ud,_k,vk,Tk,aa,kk,ia,Fk,bk,yk,la,wk,Ii,$k,Ek,Mk,da,zk,ca,qk,Pk,Ck,Fo,xk,Je,pa,jk,Ct,Lk,Wi,Ok,Dk,Rd,Ak,Nk,Sk,bo,Ik,Vd,Wk,Bk,ua,Qk,ha,mp,xt,yo,Hd,fa,Uk,Yd,Rk,gp,Ne,ma,Vk,Kd,Hk,Yk,ga,Kk,_a,Gk,Zk,Xk,va,Jk,Bi,eF,nF,tF,Ta,oF,ka,sF,rF,aF,wo,iF,en,Fa,lF,jt,dF,Qi,cF,pF,Gd,uF,hF,fF,$o,mF,Zd,gF,_F,ba,vF,ya,_p,Lt,Eo,Xd,wa,TF,Jd,kF,vp,Se,$a,FF,ec,bF,yF,Ea,wF,Ma,$F,EF,MF,za,zF,Ui,qF,PF,CF,qa,xF,Pa,jF,LF,OF,Mo,DF,hn,Ca,AF,Ot,NF,Ri,SF,IF,nc,WF,BF,QF,zo,UF,tc,RF,VF,xa,Tp,Dt,qo,oc,ja,HF,sc,YF,kp,Ie,La,KF,rc,GF,ZF,Oa,XF,Da,JF,eb,nb,Aa,tb,Vi,ob,sb,rb,Na,ab,Sa,ib,lb,db,Po,cb,nn,Ia,pb,At,ub,Hi,hb,fb,ac,mb,gb,_b,Co,vb,ic,Tb,kb,Wa,Fb,Ba,Fp,Nt,xo,lc,Qa,bb,dc,yb,bp,We,Ua,wb,St,$b,cc,Eb,Mb,pc,zb,qb,Pb,Ra,Cb,Va,xb,jb,Lb,Ha,Ob,Yi,Db,Ab,Nb,Ya,Sb,Ka,Ib,Wb,Bb,jo,Qb,tn,Ga,Ub,It,Rb,Ki,Vb,Hb,uc,Yb,Kb,Gb,Lo,Zb,hc,Xb,Jb,Za,ey,Xa,yp;return v=new Ce({}),ne=new Ce({}),Io=new Ce({}),Wo=new X({props:{name:"class transformers.FunnelConfig",anchor:"transformers.FunnelConfig",parameters:[{name:"vocab_size",val:" = 30522"},{name:"block_sizes",val:" = [4, 4, 4]"},{name:"block_repeats",val:" = None"},{name:"num_decoder_layers",val:" = 2"},{name:"d_model",val:" = 768"},{name:"n_head",val:" = 12"},{name:"d_head",val:" = 64"},{name:"d_inner",val:" = 3072"},{name:"hidden_act",val:" = 'gelu_new'"},{name:"hidden_dropout",val:" = 0.1"},{name:"attention_dropout",val:" = 0.1"},{name:"activation_dropout",val:" = 0.0"},{name:"max_position_embeddings",val:" = 512"},{name:"type_vocab_size",val:" = 3"},{name:"initializer_range",val:" = 0.1"},{name:"initializer_std",val:" = None"},{name:"layer_norm_eps",val:" = 1e-09"},{name:"pooling_type",val:" = 'mean'"},{name:"attention_type",val:" = 'relative_shift'"},{name:"separate_cls",val:" = True"},{name:"truncate_seq",val:" = True"},{name:"pool_q_only",val:" = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FunnelConfig.vocab_size",description:`<strong>vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 30522) &#x2014;
Vocabulary size of the Funnel transformer. Defines the number of different tokens that can be represented
by the <code>inputs_ids</code> passed when calling <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a>.`,name:"vocab_size"},{anchor:"transformers.FunnelConfig.block_sizes",description:`<strong>block_sizes</strong> (<code>List[int]</code>, <em>optional</em>, defaults to <code>[4, 4, 4]</code>) &#x2014;
The sizes of the blocks used in the model.`,name:"block_sizes"},{anchor:"transformers.FunnelConfig.block_repeats",description:`<strong>block_repeats</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
If passed along, each layer of each block is repeated the number of times indicated.`,name:"block_repeats"},{anchor:"transformers.FunnelConfig.num_decoder_layers",description:`<strong>num_decoder_layers</strong> (<code>int</code>, <em>optional</em>, defaults to 2) &#x2014;
The number of layers in the decoder (when not using the base model).`,name:"num_decoder_layers"},{anchor:"transformers.FunnelConfig.d_model",description:`<strong>d_model</strong> (<code>int</code>, <em>optional</em>, defaults to 768) &#x2014;
Dimensionality of the model&#x2019;s hidden states.`,name:"d_model"},{anchor:"transformers.FunnelConfig.n_head",description:`<strong>n_head</strong> (<code>int</code>, <em>optional</em>, defaults to 12) &#x2014;
Number of attention heads for each attention layer in the Transformer encoder.`,name:"n_head"},{anchor:"transformers.FunnelConfig.d_head",description:`<strong>d_head</strong> (<code>int</code>, <em>optional</em>, defaults to 64) &#x2014;
Dimensionality of the model&#x2019;s heads.`,name:"d_head"},{anchor:"transformers.FunnelConfig.d_inner",description:`<strong>d_inner</strong> (<code>int</code>, <em>optional</em>, defaults to 3072) &#x2014;
Inner dimension in the feed-forward blocks.`,name:"d_inner"},{anchor:"transformers.FunnelConfig.hidden_act",description:`<strong>hidden_act</strong> (<code>str</code> or <code>callable</code>, <em>optional</em>, defaults to <code>&quot;gelu_new&quot;</code>) &#x2014;
The non-linear activation function (function or string) in the encoder and pooler. If string, <code>&quot;gelu&quot;</code>,
<code>&quot;relu&quot;</code>, <code>&quot;silu&quot;</code> and <code>&quot;gelu_new&quot;</code> are supported.`,name:"hidden_act"},{anchor:"transformers.FunnelConfig.hidden_dropout",description:`<strong>hidden_dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.`,name:"hidden_dropout"},{anchor:"transformers.FunnelConfig.attention_dropout",description:`<strong>attention_dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The dropout probability for the attention probabilities.`,name:"attention_dropout"},{anchor:"transformers.FunnelConfig.activation_dropout",description:`<strong>activation_dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.0) &#x2014;
The dropout probability used between the two layers of the feed-forward blocks.`,name:"activation_dropout"},{anchor:"transformers.FunnelConfig.max_position_embeddings",description:`<strong>max_position_embeddings</strong> (<code>int</code>, <em>optional</em>, defaults to 512) &#x2014;
The maximum sequence length that this model might ever be used with. Typically set this to something large
just in case (e.g., 512 or 1024 or 2048).`,name:"max_position_embeddings"},{anchor:"transformers.FunnelConfig.type_vocab_size",description:`<strong>type_vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 3) &#x2014;
The vocabulary size of the <code>token_type_ids</code> passed when calling <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a>.`,name:"type_vocab_size"},{anchor:"transformers.FunnelConfig.initializer_range",description:`<strong>initializer_range</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The upper bound of the <em>uniform initializer</em> for initializing all weight matrices in attention layers.`,name:"initializer_range"},{anchor:"transformers.FunnelConfig.initializer_std",description:`<strong>initializer_std</strong> (<code>float</code>, <em>optional</em>) &#x2014;
The standard deviation of the <em>normal initializer</em> for initializing the embedding matrix and the weight of
linear layers. Will default to 1 for the embedding matrix and the value given by Xavier initialization for
linear layers.`,name:"initializer_std"},{anchor:"transformers.FunnelConfig.layer_norm_eps",description:`<strong>layer_norm_eps</strong> (<code>float</code>, <em>optional</em>, defaults to 1e-9) &#x2014;
The epsilon used by the layer normalization layers.`,name:"layer_norm_eps"},{anchor:"transformers.FunnelConfig.pooling_type",description:`<strong>pooling_type</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
Possible values are <code>&quot;mean&quot;</code> or <code>&quot;max&quot;</code>. The way pooling is performed at the beginning of each block.`,name:"pooling_type"},{anchor:"transformers.FunnelConfig.attention_type",description:`<strong>attention_type</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;relative_shift&quot;</code>) &#x2014;
Possible values are <code>&quot;relative_shift&quot;</code> or <code>&quot;factorized&quot;</code>. The former is faster on CPU/GPU while the latter
is faster on TPU.`,name:"attention_type"},{anchor:"transformers.FunnelConfig.separate_cls",description:`<strong>separate_cls</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to separate the cls token when applying pooling.`,name:"separate_cls"},{anchor:"transformers.FunnelConfig.truncate_seq",description:`<strong>truncate_seq</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
When using <code>separate_cls</code>, whether or not to truncate the last token when pooling, to avoid getting a
sequence length that is not a multiple of 2.`,name:"truncate_seq"},{anchor:"transformers.FunnelConfig.pool_q_only",description:`<strong>pool_q_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to apply the pooling only to the query or to query, key and values for the attention layers.`,name:"pool_q_only"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/configuration_funnel.py#L37"}}),Qo=new Ce({}),Uo=new X({props:{name:"class transformers.FunnelTokenizer",anchor:"transformers.FunnelTokenizer",parameters:[{name:"vocab_file",val:""},{name:"do_lower_case",val:" = True"},{name:"do_basic_tokenize",val:" = True"},{name:"never_split",val:" = None"},{name:"unk_token",val:" = '<unk>'"},{name:"sep_token",val:" = '<sep>'"},{name:"pad_token",val:" = '<pad>'"},{name:"cls_token",val:" = '<cls>'"},{name:"mask_token",val:" = '<mask>'"},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"tokenize_chinese_chars",val:" = True"},{name:"strip_accents",val:" = None"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/tokenization_funnel.py#L58"}}),Vo=new X({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.FunnelTokenizer.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.FunnelTokenizer.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added.`,name:"token_ids_0"},{anchor:"transformers.FunnelTokenizer.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/bert/tokenization_bert.py#L248",returnDescription:`
<p>List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Yo=new X({props:{name:"get_special_tokens_mask",anchor:"transformers.FunnelTokenizer.get_special_tokens_mask",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"},{name:"already_has_special_tokens",val:": bool = False"}],parametersDescription:[{anchor:"transformers.FunnelTokenizer.get_special_tokens_mask.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.FunnelTokenizer.get_special_tokens_mask.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"},{anchor:"transformers.FunnelTokenizer.get_special_tokens_mask.already_has_special_tokens",description:`<strong>already_has_special_tokens</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the token list is already formatted with special tokens for the model.`,name:"already_has_special_tokens"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/bert/tokenization_bert.py#L273",returnDescription:`
<p>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Go=new X({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.FunnelTokenizer.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.FunnelTokenizer.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.FunnelTokenizer.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/tokenization_funnel.py#L108",returnDescription:`
<p>List of <a href="../glossary#token-type-ids">token type IDs</a> according to the given sequence(s).</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),Zo=new be({props:{code:`2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
| first sequence    | second sequence |`,highlighted:`2<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1 1
| first sequence    | second sequence |`}}),Xo=new X({props:{name:"save_vocabulary",anchor:"transformers.FunnelTokenizer.save_vocabulary",parameters:[{name:"save_directory",val:": str"},{name:"filename_prefix",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/bert/tokenization_bert.py#L330"}}),Jo=new Ce({}),es=new X({props:{name:"class transformers.FunnelTokenizerFast",anchor:"transformers.FunnelTokenizerFast",parameters:[{name:"vocab_file",val:" = None"},{name:"tokenizer_file",val:" = None"},{name:"do_lower_case",val:" = True"},{name:"unk_token",val:" = '<unk>'"},{name:"sep_token",val:" = '<sep>'"},{name:"pad_token",val:" = '<pad>'"},{name:"cls_token",val:" = '<cls>'"},{name:"mask_token",val:" = '<mask>'"},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"clean_text",val:" = True"},{name:"tokenize_chinese_chars",val:" = True"},{name:"strip_accents",val:" = None"},{name:"wordpieces_prefix",val:" = '##'"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/tokenization_funnel_fast.py#L71"}}),os=new X({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.FunnelTokenizerFast.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": typing.List[int]"},{name:"token_ids_1",val:": typing.Optional[typing.List[int]] = None"}],parametersDescription:[{anchor:"transformers.FunnelTokenizerFast.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.FunnelTokenizerFast.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/tokenization_funnel_fast.py#L124",returnDescription:`
<p>List of <a href="../glossary#token-type-ids">token type IDs</a> according to the given sequence(s).</p>
`,returnType:`
<p><code>List[int]</code></p>
`}}),ss=new be({props:{code:`2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
| first sequence    | second sequence |`,highlighted:`2<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1 1
| first sequence    | second sequence |`}}),rs=new Ce({}),as=new X({props:{name:"class transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput",anchor:"transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput",parameters:[{name:"loss",val:": typing.Optional[torch.FloatTensor] = None"},{name:"logits",val:": FloatTensor = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"}],parametersDescription:[{anchor:"transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput.loss",description:`<strong>loss</strong> (<em>optional</em>, returned when <code>labels</code> is provided, <code>torch.FloatTensor</code> of shape <code>(1,)</code>) &#x2014;
Total loss of the ELECTRA-style objective.`,name:"loss"},{anchor:"transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput.logits",description:`<strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Prediction scores of the head (scores for each token before SoftMax).`,name:"logits"},{anchor:"transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer) of
shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.`,name:"hidden_states"},{anchor:"transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.`,name:"attentions"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L834"}}),ls=new X({props:{name:"class transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput",anchor:"transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput",parameters:[{name:"logits",val:": Tensor = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[tensorflow.python.framework.ops.Tensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[tensorflow.python.framework.ops.Tensor]] = None"}],parametersDescription:[{anchor:"transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput.logits",description:`<strong>logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Prediction scores of the head (scores for each token before SoftMax).`,name:"logits"},{anchor:"transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.`,name:"hidden_states"},{anchor:"transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.`,name:"attentions"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L978"}}),cs=new Ce({}),ps=new X({props:{name:"class transformers.FunnelBaseModel",anchor:"transformers.FunnelBaseModel",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelBaseModel.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L927"}}),_s=new X({props:{name:"forward",anchor:"transformers.FunnelBaseModel.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"position_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"head_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelBaseModel.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelBaseModel.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelBaseModel.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelBaseModel.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelBaseModel.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelBaseModel.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelBaseModel.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L943",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput"
>transformers.modeling_outputs.BaseModelOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) \u2014 Sequence of hidden-states at the output of the last layer of the model.</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput"
>transformers.modeling_outputs.BaseModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),Kt=new qe({props:{$$slots:{default:[V0]},$$scope:{ctx:H}}}),vs=new be({props:{code:`from transformers import FunnelTokenizer, FunnelBaseModel
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = FunnelBaseModel.from_pretrained("funnel-transformer/small-base")

inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelBaseModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelBaseModel.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),Ts=new Ce({}),ks=new X({props:{name:"class transformers.FunnelModel",anchor:"transformers.FunnelModel",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelModel.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1004"}}),Es=new X({props:{name:"forward",anchor:"transformers.FunnelModel.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelModel.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelModel.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelModel.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelModel.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelModel.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelModel.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelModel.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1021",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput"
>transformers.modeling_outputs.BaseModelOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) \u2014 Sequence of hidden-states at the output of the last layer of the model.</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput"
>transformers.modeling_outputs.BaseModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),Zt=new qe({props:{$$slots:{default:[H0]},$$scope:{ctx:H}}}),Ms=new be({props:{code:`from transformers import FunnelTokenizer, FunnelModel
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = FunnelModel.from_pretrained("funnel-transformer/small")

inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelModel.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),zs=new Ce({}),qs=new X({props:{name:"class transformers.FunnelForPreTraining",anchor:"transformers.FunnelForPreTraining",parameters:[{name:"config",val:": FunnelConfig"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1112"}}),Ps=new X({props:{name:"forward",anchor:"transformers.FunnelForPreTraining.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"labels",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelForPreTraining.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelForPreTraining.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelForPreTraining.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelForPreTraining.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelForPreTraining.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelForPreTraining.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelForPreTraining.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"},{anchor:"transformers.FunnelForPreTraining.forward.labels",description:`<strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Labels for computing the ELECTRA-style loss. Input should be a sequence of tokens (see <code>input_ids</code>
docstring) Indices should be in <code>[0, 1]</code>:</p>
<ul>
<li>0 indicates the token is an original token,</li>
<li>1 indicates the token was replaced.</li>
</ul>`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1121",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput"
>transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<em>optional</em>, returned when <code>labels</code> is provided, <code>torch.FloatTensor</code> of shape <code>(1,)</code>) \u2014 Total loss of the ELECTRA-style objective.</p>
</li>
<li>
<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>) \u2014 Prediction scores of the head (scores for each token before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer) of
shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput"
>transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),Jt=new qe({props:{$$slots:{default:[Y0]},$$scope:{ctx:H}}}),Cs=new be({props:{code:`from transformers import FunnelTokenizer, FunnelForPreTraining
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = FunnelForPreTraining.from_pretrained("funnel-transformer/small")

inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
logits = model(**inputs).logits`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForPreTraining
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForPreTraining.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits`}}),xs=new Ce({}),js=new X({props:{name:"class transformers.FunnelForMaskedLM",anchor:"transformers.FunnelForMaskedLM",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelForMaskedLM.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1195"}}),Is=new X({props:{name:"forward",anchor:"transformers.FunnelForMaskedLM.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"labels",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelForMaskedLM.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelForMaskedLM.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelForMaskedLM.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelForMaskedLM.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelForMaskedLM.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelForMaskedLM.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelForMaskedLM.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"},{anchor:"transformers.FunnelForMaskedLM.forward.labels",description:`<strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Labels for computing the masked language modeling loss. Indices should be in <code>[-100, 0, ..., config.vocab_size]</code> (see <code>input_ids</code> docstring) Tokens with indices set to <code>-100</code> are ignored (masked), the
loss is only computed for the tokens with labels in <code>[0, ..., config.vocab_size]</code>`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1211",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput"
>transformers.modeling_outputs.MaskedLMOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) \u2014 Masked language modeling (MLM) loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, config.vocab_size)</code>) \u2014 Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.MaskedLMOutput"
>transformers.modeling_outputs.MaskedLMOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),no=new qe({props:{$$slots:{default:[K0]},$$scope:{ctx:H}}}),Ws=new be({props:{code:`from transformers import FunnelTokenizer, FunnelForMaskedLM
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = FunnelForMaskedLM.from_pretrained("funnel-transformer/small")

inputs = tokenizer("The capital of France is <mask>.", return_tensors="pt")

with torch.no_grad():
    logits = model(**inputs).logits

# retrieve index of <mask>
mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]

predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)
tokenizer.decode(predicted_token_id)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForMaskedLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;The capital of France is &lt;mask&gt;.&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># retrieve index of &lt;mask&gt;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[<span class="hljs-number">0</span>].nonzero(as_tuple=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_id = logits[<span class="hljs-number">0</span>, mask_token_index].argmax(axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predicted_token_id)
`}}),Bs=new be({props:{code:`labels = tokenizer("The capital of France is Paris.", return_tensors="pt")["input_ids"]
# mask labels of non-<mask> tokens
labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)

outputs = model(**inputs, labels=labels)
round(outputs.loss.item(), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = tokenizer(<span class="hljs-string">&quot;The capital of France is Paris.&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)[<span class="hljs-string">&quot;input_ids&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># mask labels of non-&lt;mask&gt; tokens</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -<span class="hljs-number">100</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs, labels=labels)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(outputs.loss.item(), <span class="hljs-number">2</span>)
`}}),Qs=new Ce({}),Us=new X({props:{name:"class transformers.FunnelForSequenceClassification",anchor:"transformers.FunnelForSequenceClassification",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelForSequenceClassification.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1275"}}),Gs=new X({props:{name:"forward",anchor:"transformers.FunnelForSequenceClassification.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"labels",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelForSequenceClassification.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelForSequenceClassification.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelForSequenceClassification.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelForSequenceClassification.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelForSequenceClassification.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelForSequenceClassification.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelForSequenceClassification.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"},{anchor:"transformers.FunnelForSequenceClassification.forward.labels",description:`<strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for computing the sequence classification/regression loss. Indices should be in <code>[0, ..., config.num_labels - 1]</code>. If <code>config.num_labels == 1</code> a regression loss is computed (Mean-Square loss), If
<code>config.num_labels &gt; 1</code> a classification loss is computed (Cross-Entropy).`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1286",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput"
>transformers.modeling_outputs.SequenceClassifierOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) \u2014 Classification (or regression if config.num_labels==1) loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.num_labels)</code>) \u2014 Classification (or regression if config.num_labels==1) scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput"
>transformers.modeling_outputs.SequenceClassifierOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),oo=new qe({props:{$$slots:{default:[G0]},$$scope:{ctx:H}}}),Zs=new be({props:{code:`import torch
from transformers import FunnelTokenizer, FunnelForSequenceClassification

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = FunnelForSequenceClassification.from_pretrained("funnel-transformer/small-base")

inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")

with torch.no_grad():
    logits = model(**inputs).logits

predicted_class_id = logits.argmax().item()
model.config.id2label[predicted_class_id]
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class_id = logits.argmax().item()
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.id2label[predicted_class_id]
`}}),Xs=new be({props:{code:`# To train a model on \`num_labels\` classes, you can pass \`num_labels=num_labels\` to \`.from_pretrained(...)\`
num_labels = len(model.config.id2label)
model = FunnelForSequenceClassification.from_pretrained("funnel-transformer/small-base", num_labels=num_labels)

labels = torch.tensor(1)
loss = model(**inputs, labels=labels).loss
round(loss.item(), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># To train a model on \`num_labels\` classes, you can pass \`num_labels=num_labels\` to \`.from_pretrained(...)\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_labels = <span class="hljs-built_in">len</span>(model.config.id2label)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>, num_labels=num_labels)

<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.tensor(<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = model(**inputs, labels=labels).loss
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(loss.item(), <span class="hljs-number">2</span>)
`}}),Js=new be({props:{code:`import torch
from transformers import FunnelTokenizer, FunnelForSequenceClassification

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = FunnelForSequenceClassification.from_pretrained("funnel-transformer/small-base", problem_type="multi_label_classification")

inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")

with torch.no_grad():
    logits = model(**inputs).logits

predicted_class_id = logits.argmax().item()
model.config.id2label[predicted_class_id]
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>, problem_type=<span class="hljs-string">&quot;multi_label_classification&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class_id = logits.argmax().item()
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.id2label[predicted_class_id]
`}}),er=new be({props:{code:`# To train a model on \`num_labels\` classes, you can pass \`num_labels=num_labels\` to \`.from_pretrained(...)\`
num_labels = len(model.config.id2label)
model = FunnelForSequenceClassification.from_pretrained("funnel-transformer/small-base", num_labels=num_labels)

num_labels = len(model.config.id2label)
labels = torch.nn.functional.one_hot(torch.tensor([predicted_class_id]), num_classes=num_labels).to(
    torch.float
)
loss = model(**inputs, labels=labels).loss
loss.backward()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># To train a model on \`num_labels\` classes, you can pass \`num_labels=num_labels\` to \`.from_pretrained(...)\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_labels = <span class="hljs-built_in">len</span>(model.config.id2label)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>, num_labels=num_labels)

<span class="hljs-meta">&gt;&gt;&gt; </span>num_labels = <span class="hljs-built_in">len</span>(model.config.id2label)
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.nn.functional.one_hot(torch.tensor([predicted_class_id]), num_classes=num_labels).to(
<span class="hljs-meta">... </span>    torch.<span class="hljs-built_in">float</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = model(**inputs, labels=labels).loss
<span class="hljs-meta">&gt;&gt;&gt; </span>loss.backward()`}}),nr=new Ce({}),tr=new X({props:{name:"class transformers.FunnelForMultipleChoice",anchor:"transformers.FunnelForMultipleChoice",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelForMultipleChoice.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1368"}}),lr=new X({props:{name:"forward",anchor:"transformers.FunnelForMultipleChoice.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"labels",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelForMultipleChoice.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelForMultipleChoice.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelForMultipleChoice.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelForMultipleChoice.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_choices, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelForMultipleChoice.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelForMultipleChoice.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelForMultipleChoice.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"},{anchor:"transformers.FunnelForMultipleChoice.forward.labels",description:`<strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for computing the multiple choice classification loss. Indices should be in <code>[0, ..., num_choices-1]</code> where <code>num_choices</code> is the size of the second dimension of the input tensors. (See
<code>input_ids</code> above)`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1377",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput"
>transformers.modeling_outputs.MultipleChoiceModelOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <em>(1,)</em>, <em>optional</em>, returned when <code>labels</code> is provided) \u2014 Classification loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_choices)</code>) \u2014 <em>num_choices</em> is the second dimension of the input tensors. (see <em>input_ids</em> above).</p>
<p>Classification scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.MultipleChoiceModelOutput"
>transformers.modeling_outputs.MultipleChoiceModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),ro=new qe({props:{$$slots:{default:[Z0]},$$scope:{ctx:H}}}),dr=new be({props:{code:`from transformers import FunnelTokenizer, FunnelForMultipleChoice
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = FunnelForMultipleChoice.from_pretrained("funnel-transformer/small-base")

prompt = "In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced."
choice0 = "It is eaten with a fork and a knife."
choice1 = "It is eaten while held in the hand."
labels = torch.tensor(0).unsqueeze(0)  # choice0 is correct (according to Wikipedia ;)), batch size 1

encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors="pt", padding=True)
outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()}, labels=labels)  # batch size is 1

# the linear classifier still needs to be trained
loss = outputs.loss
logits = outputs.logits`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>prompt = <span class="hljs-string">&quot;In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>choice0 = <span class="hljs-string">&quot;It is eaten with a fork and a knife.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>choice1 = <span class="hljs-string">&quot;It is eaten while held in the hand.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.tensor(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># choice0 is correct (according to Wikipedia ;)), batch size 1</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**{k: v.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> encoding.items()}, labels=labels)  <span class="hljs-comment"># batch size is 1</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># the linear classifier still needs to be trained</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = outputs.loss
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`}}),cr=new Ce({}),pr=new X({props:{name:"class transformers.FunnelForTokenClassification",anchor:"transformers.FunnelForTokenClassification",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelForTokenClassification.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1452"}}),_r=new X({props:{name:"forward",anchor:"transformers.FunnelForTokenClassification.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"labels",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelForTokenClassification.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelForTokenClassification.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelForTokenClassification.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelForTokenClassification.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelForTokenClassification.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelForTokenClassification.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelForTokenClassification.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"},{anchor:"transformers.FunnelForTokenClassification.forward.labels",description:`<strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Labels for computing the token classification loss. Indices should be in <code>[0, ..., config.num_labels - 1]</code>.`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1464",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput"
>transformers.modeling_outputs.TokenClassifierOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided)  \u2014 Classification loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, config.num_labels)</code>) \u2014 Classification scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.TokenClassifierOutput"
>transformers.modeling_outputs.TokenClassifierOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),io=new qe({props:{$$slots:{default:[X0]},$$scope:{ctx:H}}}),vr=new be({props:{code:`from transformers import FunnelTokenizer, FunnelForTokenClassification
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = FunnelForTokenClassification.from_pretrained("funnel-transformer/small")

inputs = tokenizer(
    "HuggingFace is a company based in Paris and New York", add_special_tokens=False, return_tensors="pt"
)

with torch.no_grad():
    logits = model(**inputs).logits

predicted_token_class_ids = logits.argmax(-1)

# Note that tokens are classified rather then input words which means that
# there might be more predicted token classes than words.
# Multiple token classes might account for the same word
predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]
predicted_tokens_classes
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForTokenClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;HuggingFace is a company based in Paris and New York&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class_ids = logits.argmax(-<span class="hljs-number">1</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Note that tokens are classified rather then input words which means that</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># there might be more predicted token classes than words.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Multiple token classes might account for the same word</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_tokens_classes = [model.config.id2label[t.item()] <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> predicted_token_class_ids[<span class="hljs-number">0</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_tokens_classes
`}}),Tr=new be({props:{code:`labels = predicted_token_class_ids
loss = model(**inputs, labels=labels).loss
round(loss.item(), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = predicted_token_class_ids
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = model(**inputs, labels=labels).loss
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(loss.item(), <span class="hljs-number">2</span>)
`}}),kr=new Ce({}),Fr=new X({props:{name:"class transformers.FunnelForQuestionAnswering",anchor:"transformers.FunnelForQuestionAnswering",parameters:[{name:"config",val:": FunnelConfig"}],parametersDescription:[{anchor:"transformers.FunnelForQuestionAnswering.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1526"}}),Mr=new X({props:{name:"forward",anchor:"transformers.FunnelForQuestionAnswering.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.Tensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"start_positions",val:": typing.Optional[torch.Tensor] = None"},{name:"end_positions",val:": typing.Optional[torch.Tensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.FunnelForQuestionAnswering.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FunnelForQuestionAnswering.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.FunnelForQuestionAnswering.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.FunnelForQuestionAnswering.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.FunnelForQuestionAnswering.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.FunnelForQuestionAnswering.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.FunnelForQuestionAnswering.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"},{anchor:"transformers.FunnelForQuestionAnswering.forward.start_positions",description:`<strong>start_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for position (index) of the start of the labelled span for computing the token classification loss.
Positions are clamped to the length of the sequence (<code>sequence_length</code>). Position outside of the sequence
are not taken into account for computing the loss.`,name:"start_positions"},{anchor:"transformers.FunnelForQuestionAnswering.forward.end_positions",description:`<strong>end_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for position (index) of the end of the labelled span for computing the token classification loss.
Positions are clamped to the length of the sequence (<code>sequence_length</code>). Position outside of the sequence
are not taken into account for computing the loss.`,name:"end_positions"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_funnel.py#L1537",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput"
>transformers.modeling_outputs.QuestionAnsweringModelOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) \u2014 Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.</p>
</li>
<li>
<p><strong>start_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>) \u2014 Span-start scores (before SoftMax).</p>
</li>
<li>
<p><strong>end_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>) \u2014 Span-end scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_outputs.QuestionAnsweringModelOutput"
>transformers.modeling_outputs.QuestionAnsweringModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),co=new qe({props:{$$slots:{default:[J0]},$$scope:{ctx:H}}}),zr=new be({props:{code:`from transformers import FunnelTokenizer, FunnelForQuestionAnswering
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = FunnelForQuestionAnswering.from_pretrained("funnel-transformer/small")

question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"

inputs = tokenizer(question, text, return_tensors="pt")
with torch.no_grad():
    outputs = model(**inputs)

answer_start_index = outputs.start_logits.argmax()
answer_end_index = outputs.end_logits.argmax()

predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
tokenizer.decode(predict_answer_tokens)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, FunnelForQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FunnelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>question, text = <span class="hljs-string">&quot;Who was Jim Henson?&quot;</span>, <span class="hljs-string">&quot;Jim Henson was a nice puppet&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(question, text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>answer_start_index = outputs.start_logits.argmax()
<span class="hljs-meta">&gt;&gt;&gt; </span>answer_end_index = outputs.end_logits.argmax()

<span class="hljs-meta">&gt;&gt;&gt; </span>predict_answer_tokens = inputs.input_ids[<span class="hljs-number">0</span>, answer_start_index : answer_end_index + <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predict_answer_tokens)
`}}),qr=new be({props:{code:`# target is "nice puppet"
target_start_index, target_end_index = torch.tensor([14]), torch.tensor([15])

outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)
loss = outputs.loss
round(loss.item(), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target is &quot;nice puppet&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>target_start_index, target_end_index = torch.tensor([<span class="hljs-number">14</span>]), torch.tensor([<span class="hljs-number">15</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = outputs.loss
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(loss.item(), <span class="hljs-number">2</span>)
`}}),Pr=new Ce({}),Cr=new X({props:{name:"class transformers.TFFunnelBaseModel",anchor:"transformers.TFFunnelBaseModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelBaseModel.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1095"}}),uo=new qe({props:{$$slots:{default:[e2]},$$scope:{ctx:H}}}),Ar=new X({props:{name:"call",anchor:"transformers.TFFunnelBaseModel.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelBaseModel.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelBaseModel.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelBaseModel.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelBaseModel.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelBaseModel.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelBaseModel.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelBaseModel.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelBaseModel.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1100",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput"
>transformers.modeling_tf_outputs.TFBaseModelOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>last_hidden_state</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) \u2014 Sequence of hidden-states at the output of the last layer of the model.</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput"
>transformers.modeling_tf_outputs.TFBaseModelOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),ho=new qe({props:{$$slots:{default:[n2]},$$scope:{ctx:H}}}),Nr=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelBaseModel
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = TFFunnelBaseModel.from_pretrained("funnel-transformer/small-base")

inputs = tokenizer("Hello, my dog is cute", return_tensors="tf")
outputs = model(inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelBaseModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelBaseModel.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),Sr=new Ce({}),Ir=new X({props:{name:"class transformers.TFFunnelModel",anchor:"transformers.TFFunnelModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelModel.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1142"}}),mo=new qe({props:{$$slots:{default:[t2]},$$scope:{ctx:H}}}),Vr=new X({props:{name:"call",anchor:"transformers.TFFunnelModel.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelModel.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelModel.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelModel.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelModel.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelModel.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelModel.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelModel.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelModel.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1147",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput"
>transformers.modeling_tf_outputs.TFBaseModelOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>last_hidden_state</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) \u2014 Sequence of hidden-states at the output of the last layer of the model.</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFBaseModelOutput"
>transformers.modeling_tf_outputs.TFBaseModelOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),go=new qe({props:{$$slots:{default:[o2]},$$scope:{ctx:H}}}),Hr=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelModel
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = TFFunnelModel.from_pretrained("funnel-transformer/small")

inputs = tokenizer("Hello, my dog is cute", return_tensors="tf")
outputs = model(inputs)

last_hidden_states = outputs.last_hidden_state`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelModel.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`}}),Yr=new Ce({}),Kr=new X({props:{name:"class transformers.TFFunnelForPreTraining",anchor:"transformers.TFFunnelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForPreTraining.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1192"}}),vo=new qe({props:{$$slots:{default:[s2]},$$scope:{ctx:H}}}),na=new X({props:{name:"call",anchor:"transformers.TFFunnelForPreTraining.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"training",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForPreTraining.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelForPreTraining.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelForPreTraining.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelForPreTraining.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelForPreTraining.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelForPreTraining.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelForPreTraining.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelForPreTraining.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1199",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput"
>transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) \u2014 Prediction scores of the head (scores for each token before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput"
>transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTrainingOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),To=new qe({props:{$$slots:{default:[r2]},$$scope:{ctx:H}}}),ta=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelForPreTraining
import torch

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = TFFunnelForPreTraining.from_pretrained("funnel-transformer/small")

inputs = tokenizer("Hello, my dog is cute", return_tensors="tf")
logits = model(inputs).logits`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelForPreTraining
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForPreTraining.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(inputs).logits`}}),oa=new Ce({}),sa=new X({props:{name:"class transformers.TFFunnelForMaskedLM",anchor:"transformers.TFFunnelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForMaskedLM.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1259"}}),Fo=new qe({props:{$$slots:{default:[a2]},$$scope:{ctx:H}}}),pa=new X({props:{name:"call",anchor:"transformers.TFFunnelForMaskedLM.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"labels",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelForMaskedLM.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelForMaskedLM.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelForMaskedLM.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelForMaskedLM.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelForMaskedLM.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelForMaskedLM.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelForMaskedLM.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelForMaskedLM.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"},{anchor:"transformers.TFFunnelForMaskedLM.call.labels",description:`<strong>labels</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Labels for computing the masked language modeling loss. Indices should be in <code>[-100, 0, ..., config.vocab_size]</code> (see <code>input_ids</code> docstring) Tokens with indices set to <code>-100</code> are ignored (masked), the
loss is only computed for the tokens with labels in <code>[0, ..., config.vocab_size]</code>`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1273",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFMaskedLMOutput"
>transformers.modeling_tf_outputs.TFMaskedLMOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>tf.Tensor</code> of shape <code>(n,)</code>, <em>optional</em>, where n is the number of non-masked labels, returned when <code>labels</code> is provided) \u2014 Masked language modeling (MLM) loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, config.vocab_size)</code>) \u2014 Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFMaskedLMOutput"
>transformers.modeling_tf_outputs.TFMaskedLMOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),bo=new qe({props:{$$slots:{default:[i2]},$$scope:{ctx:H}}}),ua=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelForMaskedLM
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = TFFunnelForMaskedLM.from_pretrained("funnel-transformer/small")

inputs = tokenizer("The capital of France is [MASK].", return_tensors="tf")
logits = model(**inputs).logits

# retrieve index of [MASK]
mask_token_index = tf.where(inputs.input_ids == tokenizer.mask_token_id)[0][1]

predicted_token_id = tf.math.argmax(logits[0, mask_token_index], axis=-1)
tokenizer.decode(predicted_token_id)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelForMaskedLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;The capital of France is [MASK].&quot;</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># retrieve index of [MASK]</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_token_index = tf.where(inputs.input_ids == tokenizer.mask_token_id)[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_id = tf.math.argmax(logits[<span class="hljs-number">0</span>, mask_token_index], axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predicted_token_id)
`}}),ha=new be({props:{code:`labels = tokenizer("The capital of France is Paris.", return_tensors="tf")["input_ids"]
# mask labels of non-[MASK] tokens
labels = tf.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)

outputs = model(**inputs, labels=labels)
round(float(outputs.loss), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = tokenizer(<span class="hljs-string">&quot;The capital of France is Paris.&quot;</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)[<span class="hljs-string">&quot;input_ids&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># mask labels of non-[MASK] tokens</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = tf.where(inputs.input_ids == tokenizer.mask_token_id, labels, -<span class="hljs-number">100</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs, labels=labels)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(<span class="hljs-built_in">float</span>(outputs.loss), <span class="hljs-number">2</span>)
`}}),fa=new Ce({}),ma=new X({props:{name:"class transformers.TFFunnelForSequenceClassification",anchor:"transformers.TFFunnelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForSequenceClassification.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1340"}}),wo=new qe({props:{$$slots:{default:[l2]},$$scope:{ctx:H}}}),Fa=new X({props:{name:"call",anchor:"transformers.TFFunnelForSequenceClassification.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"labels",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelForSequenceClassification.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelForSequenceClassification.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelForSequenceClassification.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelForSequenceClassification.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelForSequenceClassification.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelForSequenceClassification.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelForSequenceClassification.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelForSequenceClassification.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"},{anchor:"transformers.TFFunnelForSequenceClassification.call.labels",description:`<strong>labels</strong> (<code>tf.Tensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for computing the sequence classification/regression loss. Indices should be in <code>[0, ..., config.num_labels - 1]</code>. If <code>config.num_labels == 1</code> a regression loss is computed (Mean-Square loss), If
<code>config.num_labels &gt; 1</code> a classification loss is computed (Cross-Entropy).`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1348",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput"
>transformers.modeling_tf_outputs.TFSequenceClassifierOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, )</code>, <em>optional</em>, returned when <code>labels</code> is provided) \u2014 Classification (or regression if config.num_labels==1) loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, config.num_labels)</code>) \u2014 Classification (or regression if config.num_labels==1) scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFSequenceClassifierOutput"
>transformers.modeling_tf_outputs.TFSequenceClassifierOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),$o=new qe({props:{$$slots:{default:[d2]},$$scope:{ctx:H}}}),ba=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelForSequenceClassification
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = TFFunnelForSequenceClassification.from_pretrained("funnel-transformer/small-base")

inputs = tokenizer("Hello, my dog is cute", return_tensors="tf")

logits = model(**inputs).logits

predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
model.config.id2label[predicted_class_id]
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class_id = <span class="hljs-built_in">int</span>(tf.math.argmax(logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.id2label[predicted_class_id]
`}}),ya=new be({props:{code:`# To train a model on \`num_labels\` classes, you can pass \`num_labels=num_labels\` to \`.from_pretrained(...)\`
num_labels = len(model.config.id2label)
model = TFFunnelForSequenceClassification.from_pretrained("funnel-transformer/small-base", num_labels=num_labels)

labels = tf.constant(1)
loss = model(**inputs, labels=labels).loss
round(float(loss), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># To train a model on \`num_labels\` classes, you can pass \`num_labels=num_labels\` to \`.from_pretrained(...)\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_labels = <span class="hljs-built_in">len</span>(model.config.id2label)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>, num_labels=num_labels)

<span class="hljs-meta">&gt;&gt;&gt; </span>labels = tf.constant(<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = model(**inputs, labels=labels).loss
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(<span class="hljs-built_in">float</span>(loss), <span class="hljs-number">2</span>)
`}}),wa=new Ce({}),$a=new X({props:{name:"class transformers.TFFunnelForMultipleChoice",anchor:"transformers.TFFunnelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForMultipleChoice.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1416"}}),Mo=new qe({props:{$$slots:{default:[c2]},$$scope:{ctx:H}}}),Ca=new X({props:{name:"call",anchor:"transformers.TFFunnelForMultipleChoice.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"labels",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelForMultipleChoice.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelForMultipleChoice.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelForMultipleChoice.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelForMultipleChoice.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, num_choices, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelForMultipleChoice.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelForMultipleChoice.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelForMultipleChoice.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelForMultipleChoice.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"},{anchor:"transformers.TFFunnelForMultipleChoice.call.labels",description:`<strong>labels</strong> (<code>tf.Tensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for computing the multiple choice classification loss. Indices should be in <code>[0, ..., num_choices]</code>
where <code>num_choices</code> is the size of the second dimension of the input tensors. (See <code>input_ids</code> above)`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1433",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFMultipleChoiceModelOutput"
>transformers.modeling_tf_outputs.TFMultipleChoiceModelOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>tf.Tensor</code> of shape <em>(batch_size, )</em>, <em>optional</em>, returned when <code>labels</code> is provided) \u2014 Classification loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, num_choices)</code>) \u2014 <em>num_choices</em> is the second dimension of the input tensors. (see <em>input_ids</em> above).</p>
<p>Classification scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFMultipleChoiceModelOutput"
>transformers.modeling_tf_outputs.TFMultipleChoiceModelOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),zo=new qe({props:{$$slots:{default:[p2]},$$scope:{ctx:H}}}),xa=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelForMultipleChoice
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small-base")
model = TFFunnelForMultipleChoice.from_pretrained("funnel-transformer/small-base")

prompt = "In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced."
choice0 = "It is eaten with a fork and a knife."
choice1 = "It is eaten while held in the hand."

encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors="tf", padding=True)
inputs = {k: tf.expand_dims(v, 0) for k, v in encoding.items()}
outputs = model(inputs)  # batch size is 1

# the linear classifier still needs to be trained
logits = outputs.logits`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>prompt = <span class="hljs-string">&quot;In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>choice0 = <span class="hljs-string">&quot;It is eaten with a fork and a knife.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>choice1 = <span class="hljs-string">&quot;It is eaten while held in the hand.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=<span class="hljs-string">&quot;tf&quot;</span>, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = {k: tf.expand_dims(v, <span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> encoding.items()}
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(inputs)  <span class="hljs-comment"># batch size is 1</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># the linear classifier still needs to be trained</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`}}),ja=new Ce({}),La=new X({props:{name:"class transformers.TFFunnelForTokenClassification",anchor:"transformers.TFFunnelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForTokenClassification.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1532"}}),Po=new qe({props:{$$slots:{default:[u2]},$$scope:{ctx:H}}}),Ia=new X({props:{name:"call",anchor:"transformers.TFFunnelForTokenClassification.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"labels",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelForTokenClassification.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelForTokenClassification.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelForTokenClassification.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelForTokenClassification.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelForTokenClassification.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelForTokenClassification.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelForTokenClassification.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelForTokenClassification.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"},{anchor:"transformers.TFFunnelForTokenClassification.call.labels",description:`<strong>labels</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Labels for computing the token classification loss. Indices should be in <code>[0, ..., config.num_labels - 1]</code>.`,name:"labels"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1543",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput"
>transformers.modeling_tf_outputs.TFTokenClassifierOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>tf.Tensor</code> of shape <code>(n,)</code>, <em>optional</em>, where n is the number of unmasked labels, returned when <code>labels</code> is provided)  \u2014 Classification loss.</p>
</li>
<li>
<p><strong>logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, config.num_labels)</code>) \u2014 Classification scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFTokenClassifierOutput"
>transformers.modeling_tf_outputs.TFTokenClassifierOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),Co=new qe({props:{$$slots:{default:[h2]},$$scope:{ctx:H}}}),Wa=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelForTokenClassification
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = TFFunnelForTokenClassification.from_pretrained("funnel-transformer/small")

inputs = tokenizer(
    "HuggingFace is a company based in Paris and New York", add_special_tokens=False, return_tensors="tf"
)

logits = model(**inputs).logits
predicted_token_class_ids = tf.math.argmax(logits, axis=-1)

# Note that tokens are classified rather then input words which means that
# there might be more predicted token classes than words.
# Multiple token classes might account for the same word
predicted_tokens_classes = [model.config.id2label[t] for t in predicted_token_class_ids[0].numpy().tolist()]
predicted_tokens_classes
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelForTokenClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;HuggingFace is a company based in Paris and New York&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class_ids = tf.math.argmax(logits, axis=-<span class="hljs-number">1</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Note that tokens are classified rather then input words which means that</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># there might be more predicted token classes than words.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Multiple token classes might account for the same word</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_tokens_classes = [model.config.id2label[t] <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> predicted_token_class_ids[<span class="hljs-number">0</span>].numpy().tolist()]
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_tokens_classes
`}}),Ba=new be({props:{code:`labels = predicted_token_class_ids
loss = tf.math.reduce_mean(model(**inputs, labels=labels).loss)
round(float(loss), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = predicted_token_class_ids
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = tf.math.reduce_mean(model(**inputs, labels=labels).loss)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(<span class="hljs-built_in">float</span>(loss), <span class="hljs-number">2</span>)
`}}),Qa=new Ce({}),Ua=new X({props:{name:"class transformers.TFFunnelForQuestionAnswering",anchor:"transformers.TFFunnelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFFunnelForQuestionAnswering.config",description:`<strong>config</strong> (<code>XxxConfig</code>) &#x2014; Model configuration class with all the parameters of the model.
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1610"}}),jo=new qe({props:{$$slots:{default:[f2]},$$scope:{ctx:H}}}),Ga=new X({props:{name:"call",anchor:"transformers.TFFunnelForQuestionAnswering.call",parameters:[{name:"input_ids",val:": typing.Union[typing.List[tensorflow.python.framework.ops.Tensor], typing.List[numpy.ndarray], typing.List[tensorflow.python.keras.engine.keras_tensor.KerasTensor], typing.Dict[str, tensorflow.python.framework.ops.Tensor], typing.Dict[str, numpy.ndarray], typing.Dict[str, tensorflow.python.keras.engine.keras_tensor.KerasTensor], tensorflow.python.framework.ops.Tensor, numpy.ndarray, tensorflow.python.keras.engine.keras_tensor.KerasTensor, NoneType] = None"},{name:"attention_mask",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"token_type_ids",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"inputs_embeds",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"},{name:"start_positions",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"end_positions",val:": typing.Union[numpy.ndarray, tensorflow.python.framework.ops.Tensor, NoneType] = None"},{name:"training",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TFFunnelForQuestionAnswering.call.input_ids",description:`<strong>input_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer">FunnelTokenizer</a>. See <a href="/docs/transformers/v4.18.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.attention_mask",description:`<strong>attention_mask</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.token_type_ids",description:`<strong>token_type_ids</strong> (<code>Numpy array</code> or <code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the
config will be used instead.`,name:"output_attentions"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail. This argument can be used only in eager mode, in graph mode the value in the config will be
used instead.`,name:"output_hidden_states"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple. This argument can be used in
eager mode, in graph mode the value will always be set to True.`,name:"return_dict"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.training",description:`<strong>training</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use the model in training mode (some modules like dropout modules have different
behaviors between training and evaluation).`,name:"training"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.start_positions",description:`<strong>start_positions</strong> (<code>tf.Tensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for position (index) of the start of the labelled span for computing the token classification loss.
Positions are clamped to the length of the sequence (<code>sequence_length</code>). Position outside of the sequence
are not taken into account for computing the loss.`,name:"start_positions"},{anchor:"transformers.TFFunnelForQuestionAnswering.call.end_positions",description:`<strong>end_positions</strong> (<code>tf.Tensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for position (index) of the end of the labelled span for computing the token classification loss.
Positions are clamped to the length of the sequence (<code>sequence_length</code>). Position outside of the sequence
are not taken into account for computing the loss.`,name:"end_positions"}],source:"https://github.com/huggingface/transformers/blob/v4.18.0/src/transformers/models/funnel/modeling_tf_funnel.py#L1620",returnDescription:`
<p>A <a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput"
>transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput</a> or a tuple of <code>tf.Tensor</code> (if
<code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various elements depending on the
configuration (<a
  href="/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelConfig"
>FunnelConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, )</code>, <em>optional</em>, returned when <code>start_positions</code> and <code>end_positions</code> are provided) \u2014 Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.</p>
</li>
<li>
<p><strong>start_logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) \u2014 Span-start scores (before SoftMax).</p>
</li>
<li>
<p><strong>end_logits</strong> (<code>tf.Tensor</code> of shape <code>(batch_size, sequence_length)</code>) \u2014 Span-end scores (before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for the output of the embeddings + one for the output of each layer) of shape
<code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(tf.Tensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) \u2014 Tuple of <code>tf.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`
<p><a
  href="/docs/transformers/v4.18.0/en/main_classes/output#transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput"
>transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput</a> or <code>tuple(tf.Tensor)</code></p>
`}}),Lo=new qe({props:{$$slots:{default:[m2]},$$scope:{ctx:H}}}),Za=new be({props:{code:`from transformers import FunnelTokenizer, TFFunnelForQuestionAnswering
import tensorflow as tf

tokenizer = FunnelTokenizer.from_pretrained("funnel-transformer/small")
model = TFFunnelForQuestionAnswering.from_pretrained("funnel-transformer/small")

question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"

inputs = tokenizer(question, text, return_tensors="tf")
outputs = model(**inputs)

answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])
answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])

predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
tokenizer.decode(predict_answer_tokens)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> FunnelTokenizer, TFFunnelForQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = FunnelTokenizer.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFFunnelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;funnel-transformer/small&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>question, text = <span class="hljs-string">&quot;Who was Jim Henson?&quot;</span>, <span class="hljs-string">&quot;Jim Henson was a nice puppet&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(question, text, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>answer_start_index = <span class="hljs-built_in">int</span>(tf.math.argmax(outputs.start_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>answer_end_index = <span class="hljs-built_in">int</span>(tf.math.argmax(outputs.end_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>predict_answer_tokens = inputs.input_ids[<span class="hljs-number">0</span>, answer_start_index : answer_end_index + <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predict_answer_tokens)
`}}),Xa=new be({props:{code:`# target is "nice puppet"
target_start_index, target_end_index = tf.constant([14]), tf.constant([15])

outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)
loss = tf.math.reduce_mean(outputs.loss)
round(float(loss), 2)
`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target is &quot;nice puppet&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>target_start_index, target_end_index = tf.constant([<span class="hljs-number">14</span>]), tf.constant([<span class="hljs-number">15</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = tf.math.reduce_mean(outputs.loss)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">round</span>(<span class="hljs-built_in">float</span>(loss), <span class="hljs-number">2</span>)
`}}),{c(){u=r("meta"),z=l(),g=r("h1"),_=r("a"),T=r("span"),k(v.$$.fragment),m=l(),M=r("span"),ce=t("Funnel Transformer"),K=l(),q=r("h2"),J=r("a"),A=r("span"),k(ne.$$.fragment),pe=l(),N=r("span"),ue=t("Overview"),ie=l(),Y=r("p"),L=t("The Funnel Transformer model was proposed in the paper "),te=r("a"),G=t(`Funnel-Transformer: Filtering out Sequential Redundancy for
Efficient Language Processing`),P=t(`. It is a bidirectional transformer model, like
BERT, but with a pooling operation after each block of layers, a bit like in traditional convolutional neural networks
(CNN) in computer vision.`),x=l(),oe=r("p"),B=t("The abstract from the paper is the following:"),le=l(),se=r("p"),S=r("em"),he=t(`With the success of language pretraining, it is highly desirable to develop more efficient architectures of good
scalability that can exploit the abundant unlabeled data at a lower cost. To improve the efficiency, we examine the
much-overlooked redundancy in maintaining a full-length token-level presentation, especially for tasks that only
require a single-vector presentation of the sequence. With this intuition, we propose Funnel-Transformer which
gradually compresses the sequence of hidden states to a shorter one and hence reduces the computation cost. More
importantly, by re-investing the saved FLOPs from length reduction in constructing a deeper or wider model, we further
improve the model capacity. In addition, to perform token-level predictions as required by common pretraining
objectives, Funnel-Transformer is able to recover a deep representation for each token from the reduced hidden sequence
via a decoder. Empirically, with comparable or fewer FLOPs, Funnel-Transformer outperforms the standard Transformer on
a wide variety of sequence-level prediction tasks, including text classification, language understanding, and reading
comprehension.`),de=l(),C=r("p"),fe=t("Tips:"),W=l(),ee=r("ul"),ae=r("li"),Q=t(`Since Funnel Transformer uses pooling, the sequence length of the hidden states changes after each block of layers.
The base model therefore has a final sequence length that is a quarter of the original one. This model can be used
directly for tasks that just require a sentence summary (like sequence classification or multiple choice). For other
tasks, the full model is used; this full model has a decoder that upsamples the final hidden states to the same
sequence length as the input.`),me=l(),I=r("li"),O=t(`The Funnel Transformer checkpoints are all available with a full version and a base version. The first ones should be
used for `),re=r("a"),U=t("FunnelModel"),ge=t(", "),p=r("a"),E=t("FunnelForPreTraining"),Z=t(`,
`),ve=r("a"),ye=t("FunnelForMaskedLM"),D=t(", "),Te=r("a"),we=t("FunnelForTokenClassification"),$e=t(` and
class:`),j=r("em"),R=t("~transformers.FunnelForQuestionAnswering"),Ee=t(`. The second ones should be used for
`),ke=r("a"),V=t("FunnelBaseModel"),Me=t(", "),Fe=r("a"),_e=t("FunnelForSequenceClassification"),ze=t(` and
`),oi=r("a"),Yu=t("FunnelForMultipleChoice"),Ku=t("."),Oc=l(),In=r("p"),Gu=t("This model was contributed by "),No=r("a"),Zu=t("sgugger"),Xu=t(". The original code can be found "),So=r("a"),Ju=t("here"),eh=t("."),Dc=l(),Zn=r("h2"),Wt=r("a"),kl=r("span"),k(Io.$$.fragment),nh=l(),Fl=r("span"),th=t("FunnelConfig"),Ac=l(),Nn=r("div"),k(Wo.$$.fragment),oh=l(),Sn=r("p"),sh=t("This is the configuration class to store the configuration of a "),si=r("a"),rh=t("FunnelModel"),ah=t(" or a "),ri=r("a"),ih=t("TFBertModel"),lh=t(`. It is used to
instantiate a Funnel Transformer model according to the specified arguments, defining the model architecture.
Instantiating a configuration with the defaults will yield a similar configuration to that of the Funnel
Transformer `),Bo=r("a"),dh=t("funnel-transformer/small"),ch=t(" architecture."),ph=l(),Xn=r("p"),uh=t("Configuration objects inherit from "),ai=r("a"),hh=t("PretrainedConfig"),fh=t(` and can be used to control the model outputs. Read the
documentation from `),ii=r("a"),mh=t("PretrainedConfig"),gh=t(" for more information."),Nc=l(),Jn=r("h2"),Bt=r("a"),bl=r("span"),k(Qo.$$.fragment),_h=l(),yl=r("span"),vh=t("FunnelTokenizer"),Sc=l(),xe=r("div"),k(Uo.$$.fragment),Th=l(),wl=r("p"),kh=t("Construct a Funnel Transformer tokenizer."),Fh=l(),Qt=r("p"),li=r("a"),bh=t("FunnelTokenizer"),yh=t(" is identical to "),di=r("a"),wh=t("BertTokenizer"),$h=t(` and runs end-to-end tokenization: punctuation splitting and
wordpiece.`),Eh=l(),Ro=r("p"),Mh=t("Refer to superclass "),ci=r("a"),zh=t("BertTokenizer"),qh=t(" for usage examples and documentation concerning parameters."),Ph=l(),Wn=r("div"),k(Vo.$$.fragment),Ch=l(),$l=r("p"),xh=t(`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A BERT sequence has the following format:`),jh=l(),Ho=r("ul"),pi=r("li"),Lh=t("single sequence: "),El=r("code"),Oh=t("[CLS] X [SEP]"),Dh=l(),ui=r("li"),Ah=t("pair of sequences: "),Ml=r("code"),Nh=t("[CLS] A [SEP] B [SEP]"),Sh=l(),Ut=r("div"),k(Yo.$$.fragment),Ih=l(),Ko=r("p"),Wh=t(`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),zl=r("code"),Bh=t("prepare_for_model"),Qh=t(" method."),Uh=l(),bn=r("div"),k(Go.$$.fragment),Rh=l(),ql=r("p"),Vh=t(`Create a mask from the two sequences passed to be used in a sequence-pair classification task. A Funnel
Transformer sequence pair mask has the following format:`),Hh=l(),k(Zo.$$.fragment),Yh=l(),et=r("p"),Kh=t("If "),Pl=r("code"),Gh=t("token_ids_1"),Zh=t(" is "),Cl=r("code"),Xh=t("None"),Jh=t(", this method only returns the first portion of the mask (0s)."),ef=l(),hi=r("div"),k(Xo.$$.fragment),Ic=l(),nt=r("h2"),Rt=r("a"),xl=r("span"),k(Jo.$$.fragment),nf=l(),jl=r("span"),tf=t("FunnelTokenizerFast"),Wc=l(),sn=r("div"),k(es.$$.fragment),of=l(),ns=r("p"),sf=t("Construct a \u201Cfast\u201D Funnel Transformer tokenizer (backed by HuggingFace\u2019s "),Ll=r("em"),rf=t("tokenizers"),af=t(" library)."),lf=l(),Vt=r("p"),fi=r("a"),df=t("FunnelTokenizerFast"),cf=t(" is identical to "),mi=r("a"),pf=t("BertTokenizerFast"),uf=t(` and runs end-to-end tokenization: punctuation
splitting and wordpiece.`),hf=l(),ts=r("p"),ff=t("Refer to superclass "),gi=r("a"),mf=t("BertTokenizerFast"),gf=t(" for usage examples and documentation concerning parameters."),_f=l(),yn=r("div"),k(os.$$.fragment),vf=l(),Ol=r("p"),Tf=t(`Create a mask from the two sequences passed to be used in a sequence-pair classification task. A Funnel
Transformer sequence pair mask has the following format:`),kf=l(),k(ss.$$.fragment),Ff=l(),tt=r("p"),bf=t("If "),Dl=r("code"),yf=t("token_ids_1"),wf=t(" is "),Al=r("code"),$f=t("None"),Ef=t(", this method only returns the first portion of the mask (0s)."),Bc=l(),ot=r("h2"),Ht=r("a"),Nl=r("span"),k(rs.$$.fragment),Mf=l(),Sl=r("span"),zf=t("Funnel specific outputs"),Qc=l(),st=r("div"),k(as.$$.fragment),qf=l(),is=r("p"),Pf=t("Output type of "),_i=r("a"),Cf=t("FunnelForPreTraining"),xf=t("."),Uc=l(),rt=r("div"),k(ls.$$.fragment),jf=l(),ds=r("p"),Lf=t("Output type of "),vi=r("a"),Of=t("FunnelForPreTraining"),Df=t("."),Rc=l(),at=r("h2"),Yt=r("a"),Il=r("span"),k(cs.$$.fragment),Af=l(),Wl=r("span"),Nf=t("FunnelBaseModel"),Vc=l(),Qe=r("div"),k(ps.$$.fragment),Sf=l(),Bl=r("p"),If=t(`The base Funnel Transformer Model transformer outputting raw hidden-states without upsampling head (also called
decoder) or any task-specific head on top.`),Wf=l(),us=r("p"),Bf=t("The Funnel Transformer model was proposed in "),hs=r("a"),Qf=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Uf=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Rf=l(),fs=r("p"),Vf=t("This model inherits from "),Ti=r("a"),Hf=t("PreTrainedModel"),Yf=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Kf=l(),ms=r("p"),Gf=t("This model is also a PyTorch "),gs=r("a"),Zf=t("torch.nn.Module"),Xf=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Jf=l(),rn=r("div"),k(_s.$$.fragment),em=l(),it=r("p"),nm=t("The "),ki=r("a"),tm=t("FunnelBaseModel"),om=t(" forward method, overrides the "),Ql=r("code"),sm=t("__call__"),rm=t(" special method."),am=l(),k(Kt.$$.fragment),im=l(),Ul=r("p"),lm=t("Example:"),dm=l(),k(vs.$$.fragment),Hc=l(),lt=r("h2"),Gt=r("a"),Rl=r("span"),k(Ts.$$.fragment),cm=l(),Vl=r("span"),pm=t("FunnelModel"),Yc=l(),Ue=r("div"),k(ks.$$.fragment),um=l(),Hl=r("p"),hm=t("The bare Funnel Transformer Model transformer outputting raw hidden-states without any specific head on top."),fm=l(),Fs=r("p"),mm=t("The Funnel Transformer model was proposed in "),bs=r("a"),gm=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),_m=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),vm=l(),ys=r("p"),Tm=t("This model inherits from "),Fi=r("a"),km=t("PreTrainedModel"),Fm=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),bm=l(),ws=r("p"),ym=t("This model is also a PyTorch "),$s=r("a"),wm=t("torch.nn.Module"),$m=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Em=l(),an=r("div"),k(Es.$$.fragment),Mm=l(),dt=r("p"),zm=t("The "),bi=r("a"),qm=t("FunnelModel"),Pm=t(" forward method, overrides the "),Yl=r("code"),Cm=t("__call__"),xm=t(" special method."),jm=l(),k(Zt.$$.fragment),Lm=l(),Kl=r("p"),Om=t("Example:"),Dm=l(),k(Ms.$$.fragment),Kc=l(),ct=r("h2"),Xt=r("a"),Gl=r("span"),k(zs.$$.fragment),Am=l(),Zl=r("span"),Nm=t("FunnelModelForPreTraining"),Gc=l(),pt=r("div"),k(qs.$$.fragment),Sm=l(),ln=r("div"),k(Ps.$$.fragment),Im=l(),ut=r("p"),Wm=t("The "),yi=r("a"),Bm=t("FunnelForPreTraining"),Qm=t(" forward method, overrides the "),Xl=r("code"),Um=t("__call__"),Rm=t(" special method."),Vm=l(),k(Jt.$$.fragment),Hm=l(),Jl=r("p"),Ym=t("Examples:"),Km=l(),k(Cs.$$.fragment),Zc=l(),ht=r("h2"),eo=r("a"),ed=r("span"),k(xs.$$.fragment),Gm=l(),nd=r("span"),Zm=t("FunnelForMaskedLM"),Xc=l(),Re=r("div"),k(js.$$.fragment),Xm=l(),Ls=r("p"),Jm=t("Funnel Transformer Model with a "),td=r("code"),eg=t("language modeling"),ng=t(" head on top."),tg=l(),Os=r("p"),og=t("The Funnel Transformer model was proposed in "),Ds=r("a"),sg=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),rg=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),ag=l(),As=r("p"),ig=t("This model inherits from "),wi=r("a"),lg=t("PreTrainedModel"),dg=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),cg=l(),Ns=r("p"),pg=t("This model is also a PyTorch "),Ss=r("a"),ug=t("torch.nn.Module"),hg=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),fg=l(),Ge=r("div"),k(Is.$$.fragment),mg=l(),ft=r("p"),gg=t("The "),$i=r("a"),_g=t("FunnelForMaskedLM"),vg=t(" forward method, overrides the "),od=r("code"),Tg=t("__call__"),kg=t(" special method."),Fg=l(),k(no.$$.fragment),bg=l(),sd=r("p"),yg=t("Example:"),wg=l(),k(Ws.$$.fragment),$g=l(),k(Bs.$$.fragment),Jc=l(),mt=r("h2"),to=r("a"),rd=r("span"),k(Qs.$$.fragment),Eg=l(),ad=r("span"),Mg=t("FunnelForSequenceClassification"),ep=l(),Ve=r("div"),k(Us.$$.fragment),zg=l(),id=r("p"),qg=t(`Funnel Transformer Model with a sequence classification/regression head on top (two linear layer on top of the
first timestep of the last hidden state) e.g. for GLUE tasks.`),Pg=l(),Rs=r("p"),Cg=t("The Funnel Transformer model was proposed in "),Vs=r("a"),xg=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),jg=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Lg=l(),Hs=r("p"),Og=t("This model inherits from "),Ei=r("a"),Dg=t("PreTrainedModel"),Ag=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Ng=l(),Ys=r("p"),Sg=t("This model is also a PyTorch "),Ks=r("a"),Ig=t("torch.nn.Module"),Wg=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Bg=l(),Pe=r("div"),k(Gs.$$.fragment),Qg=l(),gt=r("p"),Ug=t("The "),Mi=r("a"),Rg=t("FunnelForSequenceClassification"),Vg=t(" forward method, overrides the "),ld=r("code"),Hg=t("__call__"),Yg=t(" special method."),Kg=l(),k(oo.$$.fragment),Gg=l(),dd=r("p"),Zg=t("Example of single-label classification:"),Xg=l(),k(Zs.$$.fragment),Jg=l(),k(Xs.$$.fragment),e_=l(),cd=r("p"),n_=t("Example of multi-label classification:"),t_=l(),k(Js.$$.fragment),o_=l(),k(er.$$.fragment),np=l(),_t=r("h2"),so=r("a"),pd=r("span"),k(nr.$$.fragment),s_=l(),ud=r("span"),r_=t("FunnelForMultipleChoice"),tp=l(),He=r("div"),k(tr.$$.fragment),a_=l(),hd=r("p"),i_=t(`Funnel Transformer Model with a multiple choice classification head on top (two linear layer on top of the first
timestep of the last hidden state, and a softmax) e.g. for RocStories/SWAG tasks.`),l_=l(),or=r("p"),d_=t("The Funnel Transformer model was proposed in "),sr=r("a"),c_=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),p_=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),u_=l(),rr=r("p"),h_=t("This model inherits from "),zi=r("a"),f_=t("PreTrainedModel"),m_=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),g_=l(),ar=r("p"),__=t("This model is also a PyTorch "),ir=r("a"),v_=t("torch.nn.Module"),T_=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),k_=l(),dn=r("div"),k(lr.$$.fragment),F_=l(),vt=r("p"),b_=t("The "),qi=r("a"),y_=t("FunnelForMultipleChoice"),w_=t(" forward method, overrides the "),fd=r("code"),$_=t("__call__"),E_=t(" special method."),M_=l(),k(ro.$$.fragment),z_=l(),md=r("p"),q_=t("Example:"),P_=l(),k(dr.$$.fragment),op=l(),Tt=r("h2"),ao=r("a"),gd=r("span"),k(cr.$$.fragment),C_=l(),_d=r("span"),x_=t("FunnelForTokenClassification"),sp=l(),Ye=r("div"),k(pr.$$.fragment),j_=l(),vd=r("p"),L_=t(`Funnel Transformer Model with a token classification head on top (a linear layer on top of the hidden-states
output) e.g. for Named-Entity-Recognition (NER) tasks.`),O_=l(),ur=r("p"),D_=t("The Funnel Transformer model was proposed in "),hr=r("a"),A_=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),N_=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),S_=l(),fr=r("p"),I_=t("This model inherits from "),Pi=r("a"),W_=t("PreTrainedModel"),B_=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Q_=l(),mr=r("p"),U_=t("This model is also a PyTorch "),gr=r("a"),R_=t("torch.nn.Module"),V_=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),H_=l(),Ze=r("div"),k(_r.$$.fragment),Y_=l(),kt=r("p"),K_=t("The "),Ci=r("a"),G_=t("FunnelForTokenClassification"),Z_=t(" forward method, overrides the "),Td=r("code"),X_=t("__call__"),J_=t(" special method."),ev=l(),k(io.$$.fragment),nv=l(),kd=r("p"),tv=t("Example:"),ov=l(),k(vr.$$.fragment),sv=l(),k(Tr.$$.fragment),rp=l(),Ft=r("h2"),lo=r("a"),Fd=r("span"),k(kr.$$.fragment),rv=l(),bd=r("span"),av=t("FunnelForQuestionAnswering"),ap=l(),Ke=r("div"),k(Fr.$$.fragment),iv=l(),bt=r("p"),lv=t(`Funnel Transformer Model with a span classification head on top for extractive question-answering tasks like SQuAD
(a linear layer on top of the hidden-states output to compute `),yd=r("code"),dv=t("span start logits"),cv=t(" and "),wd=r("code"),pv=t("span end logits"),uv=t(")."),hv=l(),br=r("p"),fv=t("The Funnel Transformer model was proposed in "),yr=r("a"),mv=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),gv=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),_v=l(),wr=r("p"),vv=t("This model inherits from "),xi=r("a"),Tv=t("PreTrainedModel"),kv=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Fv=l(),$r=r("p"),bv=t("This model is also a PyTorch "),Er=r("a"),yv=t("torch.nn.Module"),wv=t(` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),$v=l(),Xe=r("div"),k(Mr.$$.fragment),Ev=l(),yt=r("p"),Mv=t("The "),ji=r("a"),zv=t("FunnelForQuestionAnswering"),qv=t(" forward method, overrides the "),$d=r("code"),Pv=t("__call__"),Cv=t(" special method."),xv=l(),k(co.$$.fragment),jv=l(),Ed=r("p"),Lv=t("Example:"),Ov=l(),k(zr.$$.fragment),Dv=l(),k(qr.$$.fragment),ip=l(),wt=r("h2"),po=r("a"),Md=r("span"),k(Pr.$$.fragment),Av=l(),zd=r("span"),Nv=t("TFFunnelBaseModel"),lp=l(),Le=r("div"),k(Cr.$$.fragment),Sv=l(),qd=r("p"),Iv=t(`The base Funnel Transformer Model transformer outputting raw hidden-states without upsampling head (also called
decoder) or any task-specific head on top.`),Wv=l(),xr=r("p"),Bv=t("The Funnel Transformer model was proposed in "),jr=r("a"),Qv=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Uv=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Rv=l(),Lr=r("p"),Vv=t("This model inherits from "),Li=r("a"),Hv=t("TFPreTrainedModel"),Yv=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Kv=l(),Or=r("p"),Gv=t("This model is also a "),Dr=r("a"),Zv=t("tf.keras.Model"),Xv=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Jv=l(),k(uo.$$.fragment),eT=l(),cn=r("div"),k(Ar.$$.fragment),nT=l(),$t=r("p"),tT=t("The "),Oi=r("a"),oT=t("TFFunnelBaseModel"),sT=t(" forward method, overrides the "),Pd=r("code"),rT=t("__call__"),aT=t(" special method."),iT=l(),k(ho.$$.fragment),lT=l(),Cd=r("p"),dT=t("Example:"),cT=l(),k(Nr.$$.fragment),dp=l(),Et=r("h2"),fo=r("a"),xd=r("span"),k(Sr.$$.fragment),pT=l(),jd=r("span"),uT=t("TFFunnelModel"),cp=l(),Oe=r("div"),k(Ir.$$.fragment),hT=l(),Ld=r("p"),fT=t("The bare Funnel Transformer Model transformer outputting raw hidden-states without any specific head on top."),mT=l(),Wr=r("p"),gT=t("The Funnel Transformer model was proposed in "),Br=r("a"),_T=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),vT=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),TT=l(),Qr=r("p"),kT=t("This model inherits from "),Di=r("a"),FT=t("TFPreTrainedModel"),bT=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),yT=l(),Ur=r("p"),wT=t("This model is also a "),Rr=r("a"),$T=t("tf.keras.Model"),ET=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),MT=l(),k(mo.$$.fragment),zT=l(),pn=r("div"),k(Vr.$$.fragment),qT=l(),Mt=r("p"),PT=t("The "),Ai=r("a"),CT=t("TFFunnelModel"),xT=t(" forward method, overrides the "),Od=r("code"),jT=t("__call__"),LT=t(" special method."),OT=l(),k(go.$$.fragment),DT=l(),Dd=r("p"),AT=t("Example:"),NT=l(),k(Hr.$$.fragment),pp=l(),zt=r("h2"),_o=r("a"),Ad=r("span"),k(Yr.$$.fragment),ST=l(),Nd=r("span"),IT=t("TFFunnelModelForPreTraining"),up=l(),De=r("div"),k(Kr.$$.fragment),WT=l(),Sd=r("p"),BT=t("Funnel model with a binary classification head on top as used during pretraining for identifying generated tokens."),QT=l(),Gr=r("p"),UT=t("The Funnel Transformer model was proposed in "),Zr=r("a"),RT=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),VT=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),HT=l(),Xr=r("p"),YT=t("This model inherits from "),Ni=r("a"),KT=t("TFPreTrainedModel"),GT=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),ZT=l(),Jr=r("p"),XT=t("This model is also a "),ea=r("a"),JT=t("tf.keras.Model"),ek=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),nk=l(),k(vo.$$.fragment),tk=l(),un=r("div"),k(na.$$.fragment),ok=l(),qt=r("p"),sk=t("The "),Si=r("a"),rk=t("TFFunnelForPreTraining"),ak=t(" forward method, overrides the "),Id=r("code"),ik=t("__call__"),lk=t(" special method."),dk=l(),k(To.$$.fragment),ck=l(),Wd=r("p"),pk=t("Examples:"),uk=l(),k(ta.$$.fragment),hp=l(),Pt=r("h2"),ko=r("a"),Bd=r("span"),k(oa.$$.fragment),hk=l(),Qd=r("span"),fk=t("TFFunnelForMaskedLM"),fp=l(),Ae=r("div"),k(sa.$$.fragment),mk=l(),ra=r("p"),gk=t("Funnel Model with a "),Ud=r("code"),_k=t("language modeling"),vk=t(" head on top."),Tk=l(),aa=r("p"),kk=t("The Funnel Transformer model was proposed in "),ia=r("a"),Fk=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),bk=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),yk=l(),la=r("p"),wk=t("This model inherits from "),Ii=r("a"),$k=t("TFPreTrainedModel"),Ek=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Mk=l(),da=r("p"),zk=t("This model is also a "),ca=r("a"),qk=t("tf.keras.Model"),Pk=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Ck=l(),k(Fo.$$.fragment),xk=l(),Je=r("div"),k(pa.$$.fragment),jk=l(),Ct=r("p"),Lk=t("The "),Wi=r("a"),Ok=t("TFFunnelForMaskedLM"),Dk=t(" forward method, overrides the "),Rd=r("code"),Ak=t("__call__"),Nk=t(" special method."),Sk=l(),k(bo.$$.fragment),Ik=l(),Vd=r("p"),Wk=t("Example:"),Bk=l(),k(ua.$$.fragment),Qk=l(),k(ha.$$.fragment),mp=l(),xt=r("h2"),yo=r("a"),Hd=r("span"),k(fa.$$.fragment),Uk=l(),Yd=r("span"),Rk=t("TFFunnelForSequenceClassification"),gp=l(),Ne=r("div"),k(ma.$$.fragment),Vk=l(),Kd=r("p"),Hk=t(`Funnel Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled
output) e.g. for GLUE tasks.`),Yk=l(),ga=r("p"),Kk=t("The Funnel Transformer model was proposed in "),_a=r("a"),Gk=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Zk=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Xk=l(),va=r("p"),Jk=t("This model inherits from "),Bi=r("a"),eF=t("TFPreTrainedModel"),nF=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),tF=l(),Ta=r("p"),oF=t("This model is also a "),ka=r("a"),sF=t("tf.keras.Model"),rF=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),aF=l(),k(wo.$$.fragment),iF=l(),en=r("div"),k(Fa.$$.fragment),lF=l(),jt=r("p"),dF=t("The "),Qi=r("a"),cF=t("TFFunnelForSequenceClassification"),pF=t(" forward method, overrides the "),Gd=r("code"),uF=t("__call__"),hF=t(" special method."),fF=l(),k($o.$$.fragment),mF=l(),Zd=r("p"),gF=t("Example:"),_F=l(),k(ba.$$.fragment),vF=l(),k(ya.$$.fragment),_p=l(),Lt=r("h2"),Eo=r("a"),Xd=r("span"),k(wa.$$.fragment),TF=l(),Jd=r("span"),kF=t("TFFunnelForMultipleChoice"),vp=l(),Se=r("div"),k($a.$$.fragment),FF=l(),ec=r("p"),bF=t(`Funnel Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`),yF=l(),Ea=r("p"),wF=t("The Funnel Transformer model was proposed in "),Ma=r("a"),$F=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),EF=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),MF=l(),za=r("p"),zF=t("This model inherits from "),Ui=r("a"),qF=t("TFPreTrainedModel"),PF=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),CF=l(),qa=r("p"),xF=t("This model is also a "),Pa=r("a"),jF=t("tf.keras.Model"),LF=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),OF=l(),k(Mo.$$.fragment),DF=l(),hn=r("div"),k(Ca.$$.fragment),AF=l(),Ot=r("p"),NF=t("The "),Ri=r("a"),SF=t("TFFunnelForMultipleChoice"),IF=t(" forward method, overrides the "),nc=r("code"),WF=t("__call__"),BF=t(" special method."),QF=l(),k(zo.$$.fragment),UF=l(),tc=r("p"),RF=t("Example:"),VF=l(),k(xa.$$.fragment),Tp=l(),Dt=r("h2"),qo=r("a"),oc=r("span"),k(ja.$$.fragment),HF=l(),sc=r("span"),YF=t("TFFunnelForTokenClassification"),kp=l(),Ie=r("div"),k(La.$$.fragment),KF=l(),rc=r("p"),GF=t(`Funnel Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for
Named-Entity-Recognition (NER) tasks.`),ZF=l(),Oa=r("p"),XF=t("The Funnel Transformer model was proposed in "),Da=r("a"),JF=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),eb=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),nb=l(),Aa=r("p"),tb=t("This model inherits from "),Vi=r("a"),ob=t("TFPreTrainedModel"),sb=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),rb=l(),Na=r("p"),ab=t("This model is also a "),Sa=r("a"),ib=t("tf.keras.Model"),lb=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),db=l(),k(Po.$$.fragment),cb=l(),nn=r("div"),k(Ia.$$.fragment),pb=l(),At=r("p"),ub=t("The "),Hi=r("a"),hb=t("TFFunnelForTokenClassification"),fb=t(" forward method, overrides the "),ac=r("code"),mb=t("__call__"),gb=t(" special method."),_b=l(),k(Co.$$.fragment),vb=l(),ic=r("p"),Tb=t("Example:"),kb=l(),k(Wa.$$.fragment),Fb=l(),k(Ba.$$.fragment),Fp=l(),Nt=r("h2"),xo=r("a"),lc=r("span"),k(Qa.$$.fragment),bb=l(),dc=r("span"),yb=t("TFFunnelForQuestionAnswering"),bp=l(),We=r("div"),k(Ua.$$.fragment),wb=l(),St=r("p"),$b=t(`Funnel Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear
layers on top of the hidden-states output to compute `),cc=r("code"),Eb=t("span start logits"),Mb=t(" and "),pc=r("code"),zb=t("span end logits"),qb=t(")."),Pb=l(),Ra=r("p"),Cb=t("The Funnel Transformer model was proposed in "),Va=r("a"),xb=t(`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),jb=t(" by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Lb=l(),Ha=r("p"),Ob=t("This model inherits from "),Yi=r("a"),Db=t("TFPreTrainedModel"),Ab=t(`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Nb=l(),Ya=r("p"),Sb=t("This model is also a "),Ka=r("a"),Ib=t("tf.keras.Model"),Wb=t(` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Bb=l(),k(jo.$$.fragment),Qb=l(),tn=r("div"),k(Ga.$$.fragment),Ub=l(),It=r("p"),Rb=t("The "),Ki=r("a"),Vb=t("TFFunnelForQuestionAnswering"),Hb=t(" forward method, overrides the "),uc=r("code"),Yb=t("__call__"),Kb=t(" special method."),Gb=l(),k(Lo.$$.fragment),Zb=l(),hc=r("p"),Xb=t("Example:"),Jb=l(),k(Za.$$.fragment),ey=l(),k(Xa.$$.fragment),this.h()},l(s){const f=U0('[data-svelte="svelte-1phssyn"]',document.head);u=a(f,"META",{name:!0,content:!0}),f.forEach(n),z=d(s),g=a(s,"H1",{class:!0});var Ja=i(g);_=a(Ja,"A",{id:!0,class:!0,href:!0});var fc=i(_);T=a(fc,"SPAN",{});var mc=i(T);F(v.$$.fragment,mc),mc.forEach(n),fc.forEach(n),m=d(Ja),M=a(Ja,"SPAN",{});var gc=i(M);ce=o(gc,"Funnel Transformer"),gc.forEach(n),Ja.forEach(n),K=d(s),q=a(s,"H2",{class:!0});var ei=i(q);J=a(ei,"A",{id:!0,class:!0,href:!0});var _c=i(J);A=a(_c,"SPAN",{});var vc=i(A);F(ne.$$.fragment,vc),vc.forEach(n),_c.forEach(n),pe=d(ei),N=a(ei,"SPAN",{});var Tc=i(N);ue=o(Tc,"Overview"),Tc.forEach(n),ei.forEach(n),ie=d(s),Y=a(s,"P",{});var ni=i(Y);L=o(ni,"The Funnel Transformer model was proposed in the paper "),te=a(ni,"A",{href:!0,rel:!0});var kc=i(te);G=o(kc,`Funnel-Transformer: Filtering out Sequential Redundancy for
Efficient Language Processing`),kc.forEach(n),P=o(ni,`. It is a bidirectional transformer model, like
BERT, but with a pooling operation after each block of layers, a bit like in traditional convolutional neural networks
(CNN) in computer vision.`),ni.forEach(n),x=d(s),oe=a(s,"P",{});var Fc=i(oe);B=o(Fc,"The abstract from the paper is the following:"),Fc.forEach(n),le=d(s),se=a(s,"P",{});var bc=i(se);S=a(bc,"EM",{});var yc=i(S);he=o(yc,`With the success of language pretraining, it is highly desirable to develop more efficient architectures of good
scalability that can exploit the abundant unlabeled data at a lower cost. To improve the efficiency, we examine the
much-overlooked redundancy in maintaining a full-length token-level presentation, especially for tasks that only
require a single-vector presentation of the sequence. With this intuition, we propose Funnel-Transformer which
gradually compresses the sequence of hidden states to a shorter one and hence reduces the computation cost. More
importantly, by re-investing the saved FLOPs from length reduction in constructing a deeper or wider model, we further
improve the model capacity. In addition, to perform token-level predictions as required by common pretraining
objectives, Funnel-Transformer is able to recover a deep representation for each token from the reduced hidden sequence
via a decoder. Empirically, with comparable or fewer FLOPs, Funnel-Transformer outperforms the standard Transformer on
a wide variety of sequence-level prediction tasks, including text classification, language understanding, and reading
comprehension.`),yc.forEach(n),bc.forEach(n),de=d(s),C=a(s,"P",{});var wc=i(C);fe=o(wc,"Tips:"),wc.forEach(n),W=d(s),ee=a(s,"UL",{});var ti=i(ee);ae=a(ti,"LI",{});var $c=i(ae);Q=o($c,`Since Funnel Transformer uses pooling, the sequence length of the hidden states changes after each block of layers.
The base model therefore has a final sequence length that is a quarter of the original one. This model can be used
directly for tasks that just require a sentence summary (like sequence classification or multiple choice). For other
tasks, the full model is used; this full model has a decoder that upsamples the final hidden states to the same
sequence length as the input.`),$c.forEach(n),me=d(ti),I=a(ti,"LI",{});var je=i(I);O=o(je,`The Funnel Transformer checkpoints are all available with a full version and a base version. The first ones should be
used for `),re=a(je,"A",{href:!0});var Ec=i(re);U=o(Ec,"FunnelModel"),Ec.forEach(n),ge=o(je,", "),p=a(je,"A",{href:!0});var Mc=i(p);E=o(Mc,"FunnelForPreTraining"),Mc.forEach(n),Z=o(je,`,
`),ve=a(je,"A",{href:!0});var zc=i(ve);ye=o(zc,"FunnelForMaskedLM"),zc.forEach(n),D=o(je,", "),Te=a(je,"A",{href:!0});var qc=i(Te);we=o(qc,"FunnelForTokenClassification"),qc.forEach(n),$e=o(je,` and
class:`),j=a(je,"EM",{});var Pc=i(j);R=o(Pc,"~transformers.FunnelForQuestionAnswering"),Pc.forEach(n),Ee=o(je,`. The second ones should be used for
`),ke=a(je,"A",{href:!0});var Cc=i(ke);V=o(Cc,"FunnelBaseModel"),Cc.forEach(n),Me=o(je,", "),Fe=a(je,"A",{href:!0});var xc=i(Fe);_e=o(xc,"FunnelForSequenceClassification"),xc.forEach(n),ze=o(je,` and
`),oi=a(je,"A",{href:!0});var oy=i(oi);Yu=o(oy,"FunnelForMultipleChoice"),oy.forEach(n),Ku=o(je,"."),je.forEach(n),ti.forEach(n),Oc=d(s),In=a(s,"P",{});var Gi=i(In);Gu=o(Gi,"This model was contributed by "),No=a(Gi,"A",{href:!0,rel:!0});var sy=i(No);Zu=o(sy,"sgugger"),sy.forEach(n),Xu=o(Gi,". The original code can be found "),So=a(Gi,"A",{href:!0,rel:!0});var ry=i(So);Ju=o(ry,"here"),ry.forEach(n),eh=o(Gi,"."),Gi.forEach(n),Dc=d(s),Zn=a(s,"H2",{class:!0});var wp=i(Zn);Wt=a(wp,"A",{id:!0,class:!0,href:!0});var ay=i(Wt);kl=a(ay,"SPAN",{});var iy=i(kl);F(Io.$$.fragment,iy),iy.forEach(n),ay.forEach(n),nh=d(wp),Fl=a(wp,"SPAN",{});var ly=i(Fl);th=o(ly,"FunnelConfig"),ly.forEach(n),wp.forEach(n),Ac=d(s),Nn=a(s,"DIV",{class:!0});var Zi=i(Nn);F(Wo.$$.fragment,Zi),oh=d(Zi),Sn=a(Zi,"P",{});var Oo=i(Sn);sh=o(Oo,"This is the configuration class to store the configuration of a "),si=a(Oo,"A",{href:!0});var dy=i(si);rh=o(dy,"FunnelModel"),dy.forEach(n),ah=o(Oo," or a "),ri=a(Oo,"A",{href:!0});var cy=i(ri);ih=o(cy,"TFBertModel"),cy.forEach(n),lh=o(Oo,`. It is used to
instantiate a Funnel Transformer model according to the specified arguments, defining the model architecture.
Instantiating a configuration with the defaults will yield a similar configuration to that of the Funnel
Transformer `),Bo=a(Oo,"A",{href:!0,rel:!0});var py=i(Bo);dh=o(py,"funnel-transformer/small"),py.forEach(n),ch=o(Oo," architecture."),Oo.forEach(n),ph=d(Zi),Xn=a(Zi,"P",{});var Xi=i(Xn);uh=o(Xi,"Configuration objects inherit from "),ai=a(Xi,"A",{href:!0});var uy=i(ai);hh=o(uy,"PretrainedConfig"),uy.forEach(n),fh=o(Xi,` and can be used to control the model outputs. Read the
documentation from `),ii=a(Xi,"A",{href:!0});var hy=i(ii);mh=o(hy,"PretrainedConfig"),hy.forEach(n),gh=o(Xi," for more information."),Xi.forEach(n),Zi.forEach(n),Nc=d(s),Jn=a(s,"H2",{class:!0});var $p=i(Jn);Bt=a($p,"A",{id:!0,class:!0,href:!0});var fy=i(Bt);bl=a(fy,"SPAN",{});var my=i(bl);F(Qo.$$.fragment,my),my.forEach(n),fy.forEach(n),_h=d($p),yl=a($p,"SPAN",{});var gy=i(yl);vh=o(gy,"FunnelTokenizer"),gy.forEach(n),$p.forEach(n),Sc=d(s),xe=a(s,"DIV",{class:!0});var on=i(xe);F(Uo.$$.fragment,on),Th=d(on),wl=a(on,"P",{});var _y=i(wl);kh=o(_y,"Construct a Funnel Transformer tokenizer."),_y.forEach(n),Fh=d(on),Qt=a(on,"P",{});var jc=i(Qt);li=a(jc,"A",{href:!0});var vy=i(li);bh=o(vy,"FunnelTokenizer"),vy.forEach(n),yh=o(jc," is identical to "),di=a(jc,"A",{href:!0});var Ty=i(di);wh=o(Ty,"BertTokenizer"),Ty.forEach(n),$h=o(jc,` and runs end-to-end tokenization: punctuation splitting and
wordpiece.`),jc.forEach(n),Eh=d(on),Ro=a(on,"P",{});var Ep=i(Ro);Mh=o(Ep,"Refer to superclass "),ci=a(Ep,"A",{href:!0});var ky=i(ci);zh=o(ky,"BertTokenizer"),ky.forEach(n),qh=o(Ep," for usage examples and documentation concerning parameters."),Ep.forEach(n),Ph=d(on),Wn=a(on,"DIV",{class:!0});var Ji=i(Wn);F(Vo.$$.fragment,Ji),Ch=d(Ji),$l=a(Ji,"P",{});var Fy=i($l);xh=o(Fy,`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A BERT sequence has the following format:`),Fy.forEach(n),jh=d(Ji),Ho=a(Ji,"UL",{});var Mp=i(Ho);pi=a(Mp,"LI",{});var ny=i(pi);Lh=o(ny,"single sequence: "),El=a(ny,"CODE",{});var by=i(El);Oh=o(by,"[CLS] X [SEP]"),by.forEach(n),ny.forEach(n),Dh=d(Mp),ui=a(Mp,"LI",{});var ty=i(ui);Ah=o(ty,"pair of sequences: "),Ml=a(ty,"CODE",{});var yy=i(Ml);Nh=o(yy,"[CLS] A [SEP] B [SEP]"),yy.forEach(n),ty.forEach(n),Mp.forEach(n),Ji.forEach(n),Sh=d(on),Ut=a(on,"DIV",{class:!0});var zp=i(Ut);F(Yo.$$.fragment,zp),Ih=d(zp),Ko=a(zp,"P",{});var qp=i(Ko);Wh=o(qp,`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer `),zl=a(qp,"CODE",{});var wy=i(zl);Bh=o(wy,"prepare_for_model"),wy.forEach(n),Qh=o(qp," method."),qp.forEach(n),zp.forEach(n),Uh=d(on),bn=a(on,"DIV",{class:!0});var Do=i(bn);F(Go.$$.fragment,Do),Rh=d(Do),ql=a(Do,"P",{});var $y=i(ql);Vh=o($y,`Create a mask from the two sequences passed to be used in a sequence-pair classification task. A Funnel
Transformer sequence pair mask has the following format:`),$y.forEach(n),Hh=d(Do),F(Zo.$$.fragment,Do),Yh=d(Do),et=a(Do,"P",{});var el=i(et);Kh=o(el,"If "),Pl=a(el,"CODE",{});var Ey=i(Pl);Gh=o(Ey,"token_ids_1"),Ey.forEach(n),Zh=o(el," is "),Cl=a(el,"CODE",{});var My=i(Cl);Xh=o(My,"None"),My.forEach(n),Jh=o(el,", this method only returns the first portion of the mask (0s)."),el.forEach(n),Do.forEach(n),ef=d(on),hi=a(on,"DIV",{class:!0});var zy=i(hi);F(Xo.$$.fragment,zy),zy.forEach(n),on.forEach(n),Ic=d(s),nt=a(s,"H2",{class:!0});var Pp=i(nt);Rt=a(Pp,"A",{id:!0,class:!0,href:!0});var qy=i(Rt);xl=a(qy,"SPAN",{});var Py=i(xl);F(Jo.$$.fragment,Py),Py.forEach(n),qy.forEach(n),nf=d(Pp),jl=a(Pp,"SPAN",{});var Cy=i(jl);tf=o(Cy,"FunnelTokenizerFast"),Cy.forEach(n),Pp.forEach(n),Wc=d(s),sn=a(s,"DIV",{class:!0});var Bn=i(sn);F(es.$$.fragment,Bn),of=d(Bn),ns=a(Bn,"P",{});var Cp=i(ns);sf=o(Cp,"Construct a \u201Cfast\u201D Funnel Transformer tokenizer (backed by HuggingFace\u2019s "),Ll=a(Cp,"EM",{});var xy=i(Ll);rf=o(xy,"tokenizers"),xy.forEach(n),af=o(Cp," library)."),Cp.forEach(n),lf=d(Bn),Vt=a(Bn,"P",{});var Lc=i(Vt);fi=a(Lc,"A",{href:!0});var jy=i(fi);df=o(jy,"FunnelTokenizerFast"),jy.forEach(n),cf=o(Lc," is identical to "),mi=a(Lc,"A",{href:!0});var Ly=i(mi);pf=o(Ly,"BertTokenizerFast"),Ly.forEach(n),uf=o(Lc,` and runs end-to-end tokenization: punctuation
splitting and wordpiece.`),Lc.forEach(n),hf=d(Bn),ts=a(Bn,"P",{});var xp=i(ts);ff=o(xp,"Refer to superclass "),gi=a(xp,"A",{href:!0});var Oy=i(gi);mf=o(Oy,"BertTokenizerFast"),Oy.forEach(n),gf=o(xp," for usage examples and documentation concerning parameters."),xp.forEach(n),_f=d(Bn),yn=a(Bn,"DIV",{class:!0});var Ao=i(yn);F(os.$$.fragment,Ao),vf=d(Ao),Ol=a(Ao,"P",{});var Dy=i(Ol);Tf=o(Dy,`Create a mask from the two sequences passed to be used in a sequence-pair classification task. A Funnel
Transformer sequence pair mask has the following format:`),Dy.forEach(n),kf=d(Ao),F(ss.$$.fragment,Ao),Ff=d(Ao),tt=a(Ao,"P",{});var nl=i(tt);bf=o(nl,"If "),Dl=a(nl,"CODE",{});var Ay=i(Dl);yf=o(Ay,"token_ids_1"),Ay.forEach(n),wf=o(nl," is "),Al=a(nl,"CODE",{});var Ny=i(Al);$f=o(Ny,"None"),Ny.forEach(n),Ef=o(nl,", this method only returns the first portion of the mask (0s)."),nl.forEach(n),Ao.forEach(n),Bn.forEach(n),Bc=d(s),ot=a(s,"H2",{class:!0});var jp=i(ot);Ht=a(jp,"A",{id:!0,class:!0,href:!0});var Sy=i(Ht);Nl=a(Sy,"SPAN",{});var Iy=i(Nl);F(rs.$$.fragment,Iy),Iy.forEach(n),Sy.forEach(n),Mf=d(jp),Sl=a(jp,"SPAN",{});var Wy=i(Sl);zf=o(Wy,"Funnel specific outputs"),Wy.forEach(n),jp.forEach(n),Qc=d(s),st=a(s,"DIV",{class:!0});var Lp=i(st);F(as.$$.fragment,Lp),qf=d(Lp),is=a(Lp,"P",{});var Op=i(is);Pf=o(Op,"Output type of "),_i=a(Op,"A",{href:!0});var By=i(_i);Cf=o(By,"FunnelForPreTraining"),By.forEach(n),xf=o(Op,"."),Op.forEach(n),Lp.forEach(n),Uc=d(s),rt=a(s,"DIV",{class:!0});var Dp=i(rt);F(ls.$$.fragment,Dp),jf=d(Dp),ds=a(Dp,"P",{});var Ap=i(ds);Lf=o(Ap,"Output type of "),vi=a(Ap,"A",{href:!0});var Qy=i(vi);Of=o(Qy,"FunnelForPreTraining"),Qy.forEach(n),Df=o(Ap,"."),Ap.forEach(n),Dp.forEach(n),Rc=d(s),at=a(s,"H2",{class:!0});var Np=i(at);Yt=a(Np,"A",{id:!0,class:!0,href:!0});var Uy=i(Yt);Il=a(Uy,"SPAN",{});var Ry=i(Il);F(cs.$$.fragment,Ry),Ry.forEach(n),Uy.forEach(n),Af=d(Np),Wl=a(Np,"SPAN",{});var Vy=i(Wl);Nf=o(Vy,"FunnelBaseModel"),Vy.forEach(n),Np.forEach(n),Vc=d(s),Qe=a(s,"DIV",{class:!0});var wn=i(Qe);F(ps.$$.fragment,wn),Sf=d(wn),Bl=a(wn,"P",{});var Hy=i(Bl);If=o(Hy,`The base Funnel Transformer Model transformer outputting raw hidden-states without upsampling head (also called
decoder) or any task-specific head on top.`),Hy.forEach(n),Wf=d(wn),us=a(wn,"P",{});var Sp=i(us);Bf=o(Sp,"The Funnel Transformer model was proposed in "),hs=a(Sp,"A",{href:!0,rel:!0});var Yy=i(hs);Qf=o(Yy,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Yy.forEach(n),Uf=o(Sp," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Sp.forEach(n),Rf=d(wn),fs=a(wn,"P",{});var Ip=i(fs);Vf=o(Ip,"This model inherits from "),Ti=a(Ip,"A",{href:!0});var Ky=i(Ti);Hf=o(Ky,"PreTrainedModel"),Ky.forEach(n),Yf=o(Ip,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Ip.forEach(n),Kf=d(wn),ms=a(wn,"P",{});var Wp=i(ms);Gf=o(Wp,"This model is also a PyTorch "),gs=a(Wp,"A",{href:!0,rel:!0});var Gy=i(gs);Zf=o(Gy,"torch.nn.Module"),Gy.forEach(n),Xf=o(Wp,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Wp.forEach(n),Jf=d(wn),rn=a(wn,"DIV",{class:!0});var Qn=i(rn);F(_s.$$.fragment,Qn),em=d(Qn),it=a(Qn,"P",{});var tl=i(it);nm=o(tl,"The "),ki=a(tl,"A",{href:!0});var Zy=i(ki);tm=o(Zy,"FunnelBaseModel"),Zy.forEach(n),om=o(tl," forward method, overrides the "),Ql=a(tl,"CODE",{});var Xy=i(Ql);sm=o(Xy,"__call__"),Xy.forEach(n),rm=o(tl," special method."),tl.forEach(n),am=d(Qn),F(Kt.$$.fragment,Qn),im=d(Qn),Ul=a(Qn,"P",{});var Jy=i(Ul);lm=o(Jy,"Example:"),Jy.forEach(n),dm=d(Qn),F(vs.$$.fragment,Qn),Qn.forEach(n),wn.forEach(n),Hc=d(s),lt=a(s,"H2",{class:!0});var Bp=i(lt);Gt=a(Bp,"A",{id:!0,class:!0,href:!0});var e1=i(Gt);Rl=a(e1,"SPAN",{});var n1=i(Rl);F(Ts.$$.fragment,n1),n1.forEach(n),e1.forEach(n),cm=d(Bp),Vl=a(Bp,"SPAN",{});var t1=i(Vl);pm=o(t1,"FunnelModel"),t1.forEach(n),Bp.forEach(n),Yc=d(s),Ue=a(s,"DIV",{class:!0});var $n=i(Ue);F(ks.$$.fragment,$n),um=d($n),Hl=a($n,"P",{});var o1=i(Hl);hm=o(o1,"The bare Funnel Transformer Model transformer outputting raw hidden-states without any specific head on top."),o1.forEach(n),fm=d($n),Fs=a($n,"P",{});var Qp=i(Fs);mm=o(Qp,"The Funnel Transformer model was proposed in "),bs=a(Qp,"A",{href:!0,rel:!0});var s1=i(bs);gm=o(s1,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),s1.forEach(n),_m=o(Qp," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Qp.forEach(n),vm=d($n),ys=a($n,"P",{});var Up=i(ys);Tm=o(Up,"This model inherits from "),Fi=a(Up,"A",{href:!0});var r1=i(Fi);km=o(r1,"PreTrainedModel"),r1.forEach(n),Fm=o(Up,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Up.forEach(n),bm=d($n),ws=a($n,"P",{});var Rp=i(ws);ym=o(Rp,"This model is also a PyTorch "),$s=a(Rp,"A",{href:!0,rel:!0});var a1=i($s);wm=o(a1,"torch.nn.Module"),a1.forEach(n),$m=o(Rp,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Rp.forEach(n),Em=d($n),an=a($n,"DIV",{class:!0});var Un=i(an);F(Es.$$.fragment,Un),Mm=d(Un),dt=a(Un,"P",{});var ol=i(dt);zm=o(ol,"The "),bi=a(ol,"A",{href:!0});var i1=i(bi);qm=o(i1,"FunnelModel"),i1.forEach(n),Pm=o(ol," forward method, overrides the "),Yl=a(ol,"CODE",{});var l1=i(Yl);Cm=o(l1,"__call__"),l1.forEach(n),xm=o(ol," special method."),ol.forEach(n),jm=d(Un),F(Zt.$$.fragment,Un),Lm=d(Un),Kl=a(Un,"P",{});var d1=i(Kl);Om=o(d1,"Example:"),d1.forEach(n),Dm=d(Un),F(Ms.$$.fragment,Un),Un.forEach(n),$n.forEach(n),Kc=d(s),ct=a(s,"H2",{class:!0});var Vp=i(ct);Xt=a(Vp,"A",{id:!0,class:!0,href:!0});var c1=i(Xt);Gl=a(c1,"SPAN",{});var p1=i(Gl);F(zs.$$.fragment,p1),p1.forEach(n),c1.forEach(n),Am=d(Vp),Zl=a(Vp,"SPAN",{});var u1=i(Zl);Nm=o(u1,"FunnelModelForPreTraining"),u1.forEach(n),Vp.forEach(n),Gc=d(s),pt=a(s,"DIV",{class:!0});var Hp=i(pt);F(qs.$$.fragment,Hp),Sm=d(Hp),ln=a(Hp,"DIV",{class:!0});var Rn=i(ln);F(Ps.$$.fragment,Rn),Im=d(Rn),ut=a(Rn,"P",{});var sl=i(ut);Wm=o(sl,"The "),yi=a(sl,"A",{href:!0});var h1=i(yi);Bm=o(h1,"FunnelForPreTraining"),h1.forEach(n),Qm=o(sl," forward method, overrides the "),Xl=a(sl,"CODE",{});var f1=i(Xl);Um=o(f1,"__call__"),f1.forEach(n),Rm=o(sl," special method."),sl.forEach(n),Vm=d(Rn),F(Jt.$$.fragment,Rn),Hm=d(Rn),Jl=a(Rn,"P",{});var m1=i(Jl);Ym=o(m1,"Examples:"),m1.forEach(n),Km=d(Rn),F(Cs.$$.fragment,Rn),Rn.forEach(n),Hp.forEach(n),Zc=d(s),ht=a(s,"H2",{class:!0});var Yp=i(ht);eo=a(Yp,"A",{id:!0,class:!0,href:!0});var g1=i(eo);ed=a(g1,"SPAN",{});var _1=i(ed);F(xs.$$.fragment,_1),_1.forEach(n),g1.forEach(n),Gm=d(Yp),nd=a(Yp,"SPAN",{});var v1=i(nd);Zm=o(v1,"FunnelForMaskedLM"),v1.forEach(n),Yp.forEach(n),Xc=d(s),Re=a(s,"DIV",{class:!0});var En=i(Re);F(js.$$.fragment,En),Xm=d(En),Ls=a(En,"P",{});var Kp=i(Ls);Jm=o(Kp,"Funnel Transformer Model with a "),td=a(Kp,"CODE",{});var T1=i(td);eg=o(T1,"language modeling"),T1.forEach(n),ng=o(Kp," head on top."),Kp.forEach(n),tg=d(En),Os=a(En,"P",{});var Gp=i(Os);og=o(Gp,"The Funnel Transformer model was proposed in "),Ds=a(Gp,"A",{href:!0,rel:!0});var k1=i(Ds);sg=o(k1,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),k1.forEach(n),rg=o(Gp," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Gp.forEach(n),ag=d(En),As=a(En,"P",{});var Zp=i(As);ig=o(Zp,"This model inherits from "),wi=a(Zp,"A",{href:!0});var F1=i(wi);lg=o(F1,"PreTrainedModel"),F1.forEach(n),dg=o(Zp,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Zp.forEach(n),cg=d(En),Ns=a(En,"P",{});var Xp=i(Ns);pg=o(Xp,"This model is also a PyTorch "),Ss=a(Xp,"A",{href:!0,rel:!0});var b1=i(Ss);ug=o(b1,"torch.nn.Module"),b1.forEach(n),hg=o(Xp,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),Xp.forEach(n),fg=d(En),Ge=a(En,"DIV",{class:!0});var Mn=i(Ge);F(Is.$$.fragment,Mn),mg=d(Mn),ft=a(Mn,"P",{});var rl=i(ft);gg=o(rl,"The "),$i=a(rl,"A",{href:!0});var y1=i($i);_g=o(y1,"FunnelForMaskedLM"),y1.forEach(n),vg=o(rl," forward method, overrides the "),od=a(rl,"CODE",{});var w1=i(od);Tg=o(w1,"__call__"),w1.forEach(n),kg=o(rl," special method."),rl.forEach(n),Fg=d(Mn),F(no.$$.fragment,Mn),bg=d(Mn),sd=a(Mn,"P",{});var $1=i(sd);yg=o($1,"Example:"),$1.forEach(n),wg=d(Mn),F(Ws.$$.fragment,Mn),$g=d(Mn),F(Bs.$$.fragment,Mn),Mn.forEach(n),En.forEach(n),Jc=d(s),mt=a(s,"H2",{class:!0});var Jp=i(mt);to=a(Jp,"A",{id:!0,class:!0,href:!0});var E1=i(to);rd=a(E1,"SPAN",{});var M1=i(rd);F(Qs.$$.fragment,M1),M1.forEach(n),E1.forEach(n),Eg=d(Jp),ad=a(Jp,"SPAN",{});var z1=i(ad);Mg=o(z1,"FunnelForSequenceClassification"),z1.forEach(n),Jp.forEach(n),ep=d(s),Ve=a(s,"DIV",{class:!0});var zn=i(Ve);F(Us.$$.fragment,zn),zg=d(zn),id=a(zn,"P",{});var q1=i(id);qg=o(q1,`Funnel Transformer Model with a sequence classification/regression head on top (two linear layer on top of the
first timestep of the last hidden state) e.g. for GLUE tasks.`),q1.forEach(n),Pg=d(zn),Rs=a(zn,"P",{});var eu=i(Rs);Cg=o(eu,"The Funnel Transformer model was proposed in "),Vs=a(eu,"A",{href:!0,rel:!0});var P1=i(Vs);xg=o(P1,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),P1.forEach(n),jg=o(eu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),eu.forEach(n),Lg=d(zn),Hs=a(zn,"P",{});var nu=i(Hs);Og=o(nu,"This model inherits from "),Ei=a(nu,"A",{href:!0});var C1=i(Ei);Dg=o(C1,"PreTrainedModel"),C1.forEach(n),Ag=o(nu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),nu.forEach(n),Ng=d(zn),Ys=a(zn,"P",{});var tu=i(Ys);Sg=o(tu,"This model is also a PyTorch "),Ks=a(tu,"A",{href:!0,rel:!0});var x1=i(Ks);Ig=o(x1,"torch.nn.Module"),x1.forEach(n),Wg=o(tu,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),tu.forEach(n),Bg=d(zn),Pe=a(zn,"DIV",{class:!0});var Be=i(Pe);F(Gs.$$.fragment,Be),Qg=d(Be),gt=a(Be,"P",{});var al=i(gt);Ug=o(al,"The "),Mi=a(al,"A",{href:!0});var j1=i(Mi);Rg=o(j1,"FunnelForSequenceClassification"),j1.forEach(n),Vg=o(al," forward method, overrides the "),ld=a(al,"CODE",{});var L1=i(ld);Hg=o(L1,"__call__"),L1.forEach(n),Yg=o(al," special method."),al.forEach(n),Kg=d(Be),F(oo.$$.fragment,Be),Gg=d(Be),dd=a(Be,"P",{});var O1=i(dd);Zg=o(O1,"Example of single-label classification:"),O1.forEach(n),Xg=d(Be),F(Zs.$$.fragment,Be),Jg=d(Be),F(Xs.$$.fragment,Be),e_=d(Be),cd=a(Be,"P",{});var D1=i(cd);n_=o(D1,"Example of multi-label classification:"),D1.forEach(n),t_=d(Be),F(Js.$$.fragment,Be),o_=d(Be),F(er.$$.fragment,Be),Be.forEach(n),zn.forEach(n),np=d(s),_t=a(s,"H2",{class:!0});var ou=i(_t);so=a(ou,"A",{id:!0,class:!0,href:!0});var A1=i(so);pd=a(A1,"SPAN",{});var N1=i(pd);F(nr.$$.fragment,N1),N1.forEach(n),A1.forEach(n),s_=d(ou),ud=a(ou,"SPAN",{});var S1=i(ud);r_=o(S1,"FunnelForMultipleChoice"),S1.forEach(n),ou.forEach(n),tp=d(s),He=a(s,"DIV",{class:!0});var qn=i(He);F(tr.$$.fragment,qn),a_=d(qn),hd=a(qn,"P",{});var I1=i(hd);i_=o(I1,`Funnel Transformer Model with a multiple choice classification head on top (two linear layer on top of the first
timestep of the last hidden state, and a softmax) e.g. for RocStories/SWAG tasks.`),I1.forEach(n),l_=d(qn),or=a(qn,"P",{});var su=i(or);d_=o(su,"The Funnel Transformer model was proposed in "),sr=a(su,"A",{href:!0,rel:!0});var W1=i(sr);c_=o(W1,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),W1.forEach(n),p_=o(su," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),su.forEach(n),u_=d(qn),rr=a(qn,"P",{});var ru=i(rr);h_=o(ru,"This model inherits from "),zi=a(ru,"A",{href:!0});var B1=i(zi);f_=o(B1,"PreTrainedModel"),B1.forEach(n),m_=o(ru,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),ru.forEach(n),g_=d(qn),ar=a(qn,"P",{});var au=i(ar);__=o(au,"This model is also a PyTorch "),ir=a(au,"A",{href:!0,rel:!0});var Q1=i(ir);v_=o(Q1,"torch.nn.Module"),Q1.forEach(n),T_=o(au,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),au.forEach(n),k_=d(qn),dn=a(qn,"DIV",{class:!0});var Vn=i(dn);F(lr.$$.fragment,Vn),F_=d(Vn),vt=a(Vn,"P",{});var il=i(vt);b_=o(il,"The "),qi=a(il,"A",{href:!0});var U1=i(qi);y_=o(U1,"FunnelForMultipleChoice"),U1.forEach(n),w_=o(il," forward method, overrides the "),fd=a(il,"CODE",{});var R1=i(fd);$_=o(R1,"__call__"),R1.forEach(n),E_=o(il," special method."),il.forEach(n),M_=d(Vn),F(ro.$$.fragment,Vn),z_=d(Vn),md=a(Vn,"P",{});var V1=i(md);q_=o(V1,"Example:"),V1.forEach(n),P_=d(Vn),F(dr.$$.fragment,Vn),Vn.forEach(n),qn.forEach(n),op=d(s),Tt=a(s,"H2",{class:!0});var iu=i(Tt);ao=a(iu,"A",{id:!0,class:!0,href:!0});var H1=i(ao);gd=a(H1,"SPAN",{});var Y1=i(gd);F(cr.$$.fragment,Y1),Y1.forEach(n),H1.forEach(n),C_=d(iu),_d=a(iu,"SPAN",{});var K1=i(_d);x_=o(K1,"FunnelForTokenClassification"),K1.forEach(n),iu.forEach(n),sp=d(s),Ye=a(s,"DIV",{class:!0});var Pn=i(Ye);F(pr.$$.fragment,Pn),j_=d(Pn),vd=a(Pn,"P",{});var G1=i(vd);L_=o(G1,`Funnel Transformer Model with a token classification head on top (a linear layer on top of the hidden-states
output) e.g. for Named-Entity-Recognition (NER) tasks.`),G1.forEach(n),O_=d(Pn),ur=a(Pn,"P",{});var lu=i(ur);D_=o(lu,"The Funnel Transformer model was proposed in "),hr=a(lu,"A",{href:!0,rel:!0});var Z1=i(hr);A_=o(Z1,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Z1.forEach(n),N_=o(lu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),lu.forEach(n),S_=d(Pn),fr=a(Pn,"P",{});var du=i(fr);I_=o(du,"This model inherits from "),Pi=a(du,"A",{href:!0});var X1=i(Pi);W_=o(X1,"PreTrainedModel"),X1.forEach(n),B_=o(du,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),du.forEach(n),Q_=d(Pn),mr=a(Pn,"P",{});var cu=i(mr);U_=o(cu,"This model is also a PyTorch "),gr=a(cu,"A",{href:!0,rel:!0});var J1=i(gr);R_=o(J1,"torch.nn.Module"),J1.forEach(n),V_=o(cu,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),cu.forEach(n),H_=d(Pn),Ze=a(Pn,"DIV",{class:!0});var Cn=i(Ze);F(_r.$$.fragment,Cn),Y_=d(Cn),kt=a(Cn,"P",{});var ll=i(kt);K_=o(ll,"The "),Ci=a(ll,"A",{href:!0});var ew=i(Ci);G_=o(ew,"FunnelForTokenClassification"),ew.forEach(n),Z_=o(ll," forward method, overrides the "),Td=a(ll,"CODE",{});var nw=i(Td);X_=o(nw,"__call__"),nw.forEach(n),J_=o(ll," special method."),ll.forEach(n),ev=d(Cn),F(io.$$.fragment,Cn),nv=d(Cn),kd=a(Cn,"P",{});var tw=i(kd);tv=o(tw,"Example:"),tw.forEach(n),ov=d(Cn),F(vr.$$.fragment,Cn),sv=d(Cn),F(Tr.$$.fragment,Cn),Cn.forEach(n),Pn.forEach(n),rp=d(s),Ft=a(s,"H2",{class:!0});var pu=i(Ft);lo=a(pu,"A",{id:!0,class:!0,href:!0});var ow=i(lo);Fd=a(ow,"SPAN",{});var sw=i(Fd);F(kr.$$.fragment,sw),sw.forEach(n),ow.forEach(n),rv=d(pu),bd=a(pu,"SPAN",{});var rw=i(bd);av=o(rw,"FunnelForQuestionAnswering"),rw.forEach(n),pu.forEach(n),ap=d(s),Ke=a(s,"DIV",{class:!0});var xn=i(Ke);F(Fr.$$.fragment,xn),iv=d(xn),bt=a(xn,"P",{});var dl=i(bt);lv=o(dl,`Funnel Transformer Model with a span classification head on top for extractive question-answering tasks like SQuAD
(a linear layer on top of the hidden-states output to compute `),yd=a(dl,"CODE",{});var aw=i(yd);dv=o(aw,"span start logits"),aw.forEach(n),cv=o(dl," and "),wd=a(dl,"CODE",{});var iw=i(wd);pv=o(iw,"span end logits"),iw.forEach(n),uv=o(dl,")."),dl.forEach(n),hv=d(xn),br=a(xn,"P",{});var uu=i(br);fv=o(uu,"The Funnel Transformer model was proposed in "),yr=a(uu,"A",{href:!0,rel:!0});var lw=i(yr);mv=o(lw,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),lw.forEach(n),gv=o(uu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),uu.forEach(n),_v=d(xn),wr=a(xn,"P",{});var hu=i(wr);vv=o(hu,"This model inherits from "),xi=a(hu,"A",{href:!0});var dw=i(xi);Tv=o(dw,"PreTrainedModel"),dw.forEach(n),kv=o(hu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),hu.forEach(n),Fv=d(xn),$r=a(xn,"P",{});var fu=i($r);bv=o(fu,"This model is also a PyTorch "),Er=a(fu,"A",{href:!0,rel:!0});var cw=i(Er);yv=o(cw,"torch.nn.Module"),cw.forEach(n),wv=o(fu,` subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`),fu.forEach(n),$v=d(xn),Xe=a(xn,"DIV",{class:!0});var jn=i(Xe);F(Mr.$$.fragment,jn),Ev=d(jn),yt=a(jn,"P",{});var cl=i(yt);Mv=o(cl,"The "),ji=a(cl,"A",{href:!0});var pw=i(ji);zv=o(pw,"FunnelForQuestionAnswering"),pw.forEach(n),qv=o(cl," forward method, overrides the "),$d=a(cl,"CODE",{});var uw=i($d);Pv=o(uw,"__call__"),uw.forEach(n),Cv=o(cl," special method."),cl.forEach(n),xv=d(jn),F(co.$$.fragment,jn),jv=d(jn),Ed=a(jn,"P",{});var hw=i(Ed);Lv=o(hw,"Example:"),hw.forEach(n),Ov=d(jn),F(zr.$$.fragment,jn),Dv=d(jn),F(qr.$$.fragment,jn),jn.forEach(n),xn.forEach(n),ip=d(s),wt=a(s,"H2",{class:!0});var mu=i(wt);po=a(mu,"A",{id:!0,class:!0,href:!0});var fw=i(po);Md=a(fw,"SPAN",{});var mw=i(Md);F(Pr.$$.fragment,mw),mw.forEach(n),fw.forEach(n),Av=d(mu),zd=a(mu,"SPAN",{});var gw=i(zd);Nv=o(gw,"TFFunnelBaseModel"),gw.forEach(n),mu.forEach(n),lp=d(s),Le=a(s,"DIV",{class:!0});var fn=i(Le);F(Cr.$$.fragment,fn),Sv=d(fn),qd=a(fn,"P",{});var _w=i(qd);Iv=o(_w,`The base Funnel Transformer Model transformer outputting raw hidden-states without upsampling head (also called
decoder) or any task-specific head on top.`),_w.forEach(n),Wv=d(fn),xr=a(fn,"P",{});var gu=i(xr);Bv=o(gu,"The Funnel Transformer model was proposed in "),jr=a(gu,"A",{href:!0,rel:!0});var vw=i(jr);Qv=o(vw,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),vw.forEach(n),Uv=o(gu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),gu.forEach(n),Rv=d(fn),Lr=a(fn,"P",{});var _u=i(Lr);Vv=o(_u,"This model inherits from "),Li=a(_u,"A",{href:!0});var Tw=i(Li);Hv=o(Tw,"TFPreTrainedModel"),Tw.forEach(n),Yv=o(_u,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),_u.forEach(n),Kv=d(fn),Or=a(fn,"P",{});var vu=i(Or);Gv=o(vu,"This model is also a "),Dr=a(vu,"A",{href:!0,rel:!0});var kw=i(Dr);Zv=o(kw,"tf.keras.Model"),kw.forEach(n),Xv=o(vu,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),vu.forEach(n),Jv=d(fn),F(uo.$$.fragment,fn),eT=d(fn),cn=a(fn,"DIV",{class:!0});var Hn=i(cn);F(Ar.$$.fragment,Hn),nT=d(Hn),$t=a(Hn,"P",{});var pl=i($t);tT=o(pl,"The "),Oi=a(pl,"A",{href:!0});var Fw=i(Oi);oT=o(Fw,"TFFunnelBaseModel"),Fw.forEach(n),sT=o(pl," forward method, overrides the "),Pd=a(pl,"CODE",{});var bw=i(Pd);rT=o(bw,"__call__"),bw.forEach(n),aT=o(pl," special method."),pl.forEach(n),iT=d(Hn),F(ho.$$.fragment,Hn),lT=d(Hn),Cd=a(Hn,"P",{});var yw=i(Cd);dT=o(yw,"Example:"),yw.forEach(n),cT=d(Hn),F(Nr.$$.fragment,Hn),Hn.forEach(n),fn.forEach(n),dp=d(s),Et=a(s,"H2",{class:!0});var Tu=i(Et);fo=a(Tu,"A",{id:!0,class:!0,href:!0});var ww=i(fo);xd=a(ww,"SPAN",{});var $w=i(xd);F(Sr.$$.fragment,$w),$w.forEach(n),ww.forEach(n),pT=d(Tu),jd=a(Tu,"SPAN",{});var Ew=i(jd);uT=o(Ew,"TFFunnelModel"),Ew.forEach(n),Tu.forEach(n),cp=d(s),Oe=a(s,"DIV",{class:!0});var mn=i(Oe);F(Ir.$$.fragment,mn),hT=d(mn),Ld=a(mn,"P",{});var Mw=i(Ld);fT=o(Mw,"The bare Funnel Transformer Model transformer outputting raw hidden-states without any specific head on top."),Mw.forEach(n),mT=d(mn),Wr=a(mn,"P",{});var ku=i(Wr);gT=o(ku,"The Funnel Transformer model was proposed in "),Br=a(ku,"A",{href:!0,rel:!0});var zw=i(Br);_T=o(zw,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),zw.forEach(n),vT=o(ku," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),ku.forEach(n),TT=d(mn),Qr=a(mn,"P",{});var Fu=i(Qr);kT=o(Fu,"This model inherits from "),Di=a(Fu,"A",{href:!0});var qw=i(Di);FT=o(qw,"TFPreTrainedModel"),qw.forEach(n),bT=o(Fu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Fu.forEach(n),yT=d(mn),Ur=a(mn,"P",{});var bu=i(Ur);wT=o(bu,"This model is also a "),Rr=a(bu,"A",{href:!0,rel:!0});var Pw=i(Rr);$T=o(Pw,"tf.keras.Model"),Pw.forEach(n),ET=o(bu,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),bu.forEach(n),MT=d(mn),F(mo.$$.fragment,mn),zT=d(mn),pn=a(mn,"DIV",{class:!0});var Yn=i(pn);F(Vr.$$.fragment,Yn),qT=d(Yn),Mt=a(Yn,"P",{});var ul=i(Mt);PT=o(ul,"The "),Ai=a(ul,"A",{href:!0});var Cw=i(Ai);CT=o(Cw,"TFFunnelModel"),Cw.forEach(n),xT=o(ul," forward method, overrides the "),Od=a(ul,"CODE",{});var xw=i(Od);jT=o(xw,"__call__"),xw.forEach(n),LT=o(ul," special method."),ul.forEach(n),OT=d(Yn),F(go.$$.fragment,Yn),DT=d(Yn),Dd=a(Yn,"P",{});var jw=i(Dd);AT=o(jw,"Example:"),jw.forEach(n),NT=d(Yn),F(Hr.$$.fragment,Yn),Yn.forEach(n),mn.forEach(n),pp=d(s),zt=a(s,"H2",{class:!0});var yu=i(zt);_o=a(yu,"A",{id:!0,class:!0,href:!0});var Lw=i(_o);Ad=a(Lw,"SPAN",{});var Ow=i(Ad);F(Yr.$$.fragment,Ow),Ow.forEach(n),Lw.forEach(n),ST=d(yu),Nd=a(yu,"SPAN",{});var Dw=i(Nd);IT=o(Dw,"TFFunnelModelForPreTraining"),Dw.forEach(n),yu.forEach(n),up=d(s),De=a(s,"DIV",{class:!0});var gn=i(De);F(Kr.$$.fragment,gn),WT=d(gn),Sd=a(gn,"P",{});var Aw=i(Sd);BT=o(Aw,"Funnel model with a binary classification head on top as used during pretraining for identifying generated tokens."),Aw.forEach(n),QT=d(gn),Gr=a(gn,"P",{});var wu=i(Gr);UT=o(wu,"The Funnel Transformer model was proposed in "),Zr=a(wu,"A",{href:!0,rel:!0});var Nw=i(Zr);RT=o(Nw,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Nw.forEach(n),VT=o(wu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),wu.forEach(n),HT=d(gn),Xr=a(gn,"P",{});var $u=i(Xr);YT=o($u,"This model inherits from "),Ni=a($u,"A",{href:!0});var Sw=i(Ni);KT=o(Sw,"TFPreTrainedModel"),Sw.forEach(n),GT=o($u,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),$u.forEach(n),ZT=d(gn),Jr=a(gn,"P",{});var Eu=i(Jr);XT=o(Eu,"This model is also a "),ea=a(Eu,"A",{href:!0,rel:!0});var Iw=i(ea);JT=o(Iw,"tf.keras.Model"),Iw.forEach(n),ek=o(Eu,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Eu.forEach(n),nk=d(gn),F(vo.$$.fragment,gn),tk=d(gn),un=a(gn,"DIV",{class:!0});var Kn=i(un);F(na.$$.fragment,Kn),ok=d(Kn),qt=a(Kn,"P",{});var hl=i(qt);sk=o(hl,"The "),Si=a(hl,"A",{href:!0});var Ww=i(Si);rk=o(Ww,"TFFunnelForPreTraining"),Ww.forEach(n),ak=o(hl," forward method, overrides the "),Id=a(hl,"CODE",{});var Bw=i(Id);ik=o(Bw,"__call__"),Bw.forEach(n),lk=o(hl," special method."),hl.forEach(n),dk=d(Kn),F(To.$$.fragment,Kn),ck=d(Kn),Wd=a(Kn,"P",{});var Qw=i(Wd);pk=o(Qw,"Examples:"),Qw.forEach(n),uk=d(Kn),F(ta.$$.fragment,Kn),Kn.forEach(n),gn.forEach(n),hp=d(s),Pt=a(s,"H2",{class:!0});var Mu=i(Pt);ko=a(Mu,"A",{id:!0,class:!0,href:!0});var Uw=i(ko);Bd=a(Uw,"SPAN",{});var Rw=i(Bd);F(oa.$$.fragment,Rw),Rw.forEach(n),Uw.forEach(n),hk=d(Mu),Qd=a(Mu,"SPAN",{});var Vw=i(Qd);fk=o(Vw,"TFFunnelForMaskedLM"),Vw.forEach(n),Mu.forEach(n),fp=d(s),Ae=a(s,"DIV",{class:!0});var _n=i(Ae);F(sa.$$.fragment,_n),mk=d(_n),ra=a(_n,"P",{});var zu=i(ra);gk=o(zu,"Funnel Model with a "),Ud=a(zu,"CODE",{});var Hw=i(Ud);_k=o(Hw,"language modeling"),Hw.forEach(n),vk=o(zu," head on top."),zu.forEach(n),Tk=d(_n),aa=a(_n,"P",{});var qu=i(aa);kk=o(qu,"The Funnel Transformer model was proposed in "),ia=a(qu,"A",{href:!0,rel:!0});var Yw=i(ia);Fk=o(Yw,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),Yw.forEach(n),bk=o(qu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),qu.forEach(n),yk=d(_n),la=a(_n,"P",{});var Pu=i(la);wk=o(Pu,"This model inherits from "),Ii=a(Pu,"A",{href:!0});var Kw=i(Ii);$k=o(Kw,"TFPreTrainedModel"),Kw.forEach(n),Ek=o(Pu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Pu.forEach(n),Mk=d(_n),da=a(_n,"P",{});var Cu=i(da);zk=o(Cu,"This model is also a "),ca=a(Cu,"A",{href:!0,rel:!0});var Gw=i(ca);qk=o(Gw,"tf.keras.Model"),Gw.forEach(n),Pk=o(Cu,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Cu.forEach(n),Ck=d(_n),F(Fo.$$.fragment,_n),xk=d(_n),Je=a(_n,"DIV",{class:!0});var Ln=i(Je);F(pa.$$.fragment,Ln),jk=d(Ln),Ct=a(Ln,"P",{});var fl=i(Ct);Lk=o(fl,"The "),Wi=a(fl,"A",{href:!0});var Zw=i(Wi);Ok=o(Zw,"TFFunnelForMaskedLM"),Zw.forEach(n),Dk=o(fl," forward method, overrides the "),Rd=a(fl,"CODE",{});var Xw=i(Rd);Ak=o(Xw,"__call__"),Xw.forEach(n),Nk=o(fl," special method."),fl.forEach(n),Sk=d(Ln),F(bo.$$.fragment,Ln),Ik=d(Ln),Vd=a(Ln,"P",{});var Jw=i(Vd);Wk=o(Jw,"Example:"),Jw.forEach(n),Bk=d(Ln),F(ua.$$.fragment,Ln),Qk=d(Ln),F(ha.$$.fragment,Ln),Ln.forEach(n),_n.forEach(n),mp=d(s),xt=a(s,"H2",{class:!0});var xu=i(xt);yo=a(xu,"A",{id:!0,class:!0,href:!0});var e0=i(yo);Hd=a(e0,"SPAN",{});var n0=i(Hd);F(fa.$$.fragment,n0),n0.forEach(n),e0.forEach(n),Uk=d(xu),Yd=a(xu,"SPAN",{});var t0=i(Yd);Rk=o(t0,"TFFunnelForSequenceClassification"),t0.forEach(n),xu.forEach(n),gp=d(s),Ne=a(s,"DIV",{class:!0});var vn=i(Ne);F(ma.$$.fragment,vn),Vk=d(vn),Kd=a(vn,"P",{});var o0=i(Kd);Hk=o(o0,`Funnel Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled
output) e.g. for GLUE tasks.`),o0.forEach(n),Yk=d(vn),ga=a(vn,"P",{});var ju=i(ga);Kk=o(ju,"The Funnel Transformer model was proposed in "),_a=a(ju,"A",{href:!0,rel:!0});var s0=i(_a);Gk=o(s0,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),s0.forEach(n),Zk=o(ju," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),ju.forEach(n),Xk=d(vn),va=a(vn,"P",{});var Lu=i(va);Jk=o(Lu,"This model inherits from "),Bi=a(Lu,"A",{href:!0});var r0=i(Bi);eF=o(r0,"TFPreTrainedModel"),r0.forEach(n),nF=o(Lu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Lu.forEach(n),tF=d(vn),Ta=a(vn,"P",{});var Ou=i(Ta);oF=o(Ou,"This model is also a "),ka=a(Ou,"A",{href:!0,rel:!0});var a0=i(ka);sF=o(a0,"tf.keras.Model"),a0.forEach(n),rF=o(Ou,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Ou.forEach(n),aF=d(vn),F(wo.$$.fragment,vn),iF=d(vn),en=a(vn,"DIV",{class:!0});var On=i(en);F(Fa.$$.fragment,On),lF=d(On),jt=a(On,"P",{});var ml=i(jt);dF=o(ml,"The "),Qi=a(ml,"A",{href:!0});var i0=i(Qi);cF=o(i0,"TFFunnelForSequenceClassification"),i0.forEach(n),pF=o(ml," forward method, overrides the "),Gd=a(ml,"CODE",{});var l0=i(Gd);uF=o(l0,"__call__"),l0.forEach(n),hF=o(ml," special method."),ml.forEach(n),fF=d(On),F($o.$$.fragment,On),mF=d(On),Zd=a(On,"P",{});var d0=i(Zd);gF=o(d0,"Example:"),d0.forEach(n),_F=d(On),F(ba.$$.fragment,On),vF=d(On),F(ya.$$.fragment,On),On.forEach(n),vn.forEach(n),_p=d(s),Lt=a(s,"H2",{class:!0});var Du=i(Lt);Eo=a(Du,"A",{id:!0,class:!0,href:!0});var c0=i(Eo);Xd=a(c0,"SPAN",{});var p0=i(Xd);F(wa.$$.fragment,p0),p0.forEach(n),c0.forEach(n),TF=d(Du),Jd=a(Du,"SPAN",{});var u0=i(Jd);kF=o(u0,"TFFunnelForMultipleChoice"),u0.forEach(n),Du.forEach(n),vp=d(s),Se=a(s,"DIV",{class:!0});var Tn=i(Se);F($a.$$.fragment,Tn),FF=d(Tn),ec=a(Tn,"P",{});var h0=i(ec);bF=o(h0,`Funnel Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`),h0.forEach(n),yF=d(Tn),Ea=a(Tn,"P",{});var Au=i(Ea);wF=o(Au,"The Funnel Transformer model was proposed in "),Ma=a(Au,"A",{href:!0,rel:!0});var f0=i(Ma);$F=o(f0,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),f0.forEach(n),EF=o(Au," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Au.forEach(n),MF=d(Tn),za=a(Tn,"P",{});var Nu=i(za);zF=o(Nu,"This model inherits from "),Ui=a(Nu,"A",{href:!0});var m0=i(Ui);qF=o(m0,"TFPreTrainedModel"),m0.forEach(n),PF=o(Nu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Nu.forEach(n),CF=d(Tn),qa=a(Tn,"P",{});var Su=i(qa);xF=o(Su,"This model is also a "),Pa=a(Su,"A",{href:!0,rel:!0});var g0=i(Pa);jF=o(g0,"tf.keras.Model"),g0.forEach(n),LF=o(Su,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Su.forEach(n),OF=d(Tn),F(Mo.$$.fragment,Tn),DF=d(Tn),hn=a(Tn,"DIV",{class:!0});var Gn=i(hn);F(Ca.$$.fragment,Gn),AF=d(Gn),Ot=a(Gn,"P",{});var gl=i(Ot);NF=o(gl,"The "),Ri=a(gl,"A",{href:!0});var _0=i(Ri);SF=o(_0,"TFFunnelForMultipleChoice"),_0.forEach(n),IF=o(gl," forward method, overrides the "),nc=a(gl,"CODE",{});var v0=i(nc);WF=o(v0,"__call__"),v0.forEach(n),BF=o(gl," special method."),gl.forEach(n),QF=d(Gn),F(zo.$$.fragment,Gn),UF=d(Gn),tc=a(Gn,"P",{});var T0=i(tc);RF=o(T0,"Example:"),T0.forEach(n),VF=d(Gn),F(xa.$$.fragment,Gn),Gn.forEach(n),Tn.forEach(n),Tp=d(s),Dt=a(s,"H2",{class:!0});var Iu=i(Dt);qo=a(Iu,"A",{id:!0,class:!0,href:!0});var k0=i(qo);oc=a(k0,"SPAN",{});var F0=i(oc);F(ja.$$.fragment,F0),F0.forEach(n),k0.forEach(n),HF=d(Iu),sc=a(Iu,"SPAN",{});var b0=i(sc);YF=o(b0,"TFFunnelForTokenClassification"),b0.forEach(n),Iu.forEach(n),kp=d(s),Ie=a(s,"DIV",{class:!0});var kn=i(Ie);F(La.$$.fragment,kn),KF=d(kn),rc=a(kn,"P",{});var y0=i(rc);GF=o(y0,`Funnel Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for
Named-Entity-Recognition (NER) tasks.`),y0.forEach(n),ZF=d(kn),Oa=a(kn,"P",{});var Wu=i(Oa);XF=o(Wu,"The Funnel Transformer model was proposed in "),Da=a(Wu,"A",{href:!0,rel:!0});var w0=i(Da);JF=o(w0,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),w0.forEach(n),eb=o(Wu," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Wu.forEach(n),nb=d(kn),Aa=a(kn,"P",{});var Bu=i(Aa);tb=o(Bu,"This model inherits from "),Vi=a(Bu,"A",{href:!0});var $0=i(Vi);ob=o($0,"TFPreTrainedModel"),$0.forEach(n),sb=o(Bu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Bu.forEach(n),rb=d(kn),Na=a(kn,"P",{});var Qu=i(Na);ab=o(Qu,"This model is also a "),Sa=a(Qu,"A",{href:!0,rel:!0});var E0=i(Sa);ib=o(E0,"tf.keras.Model"),E0.forEach(n),lb=o(Qu,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Qu.forEach(n),db=d(kn),F(Po.$$.fragment,kn),cb=d(kn),nn=a(kn,"DIV",{class:!0});var Dn=i(nn);F(Ia.$$.fragment,Dn),pb=d(Dn),At=a(Dn,"P",{});var _l=i(At);ub=o(_l,"The "),Hi=a(_l,"A",{href:!0});var M0=i(Hi);hb=o(M0,"TFFunnelForTokenClassification"),M0.forEach(n),fb=o(_l," forward method, overrides the "),ac=a(_l,"CODE",{});var z0=i(ac);mb=o(z0,"__call__"),z0.forEach(n),gb=o(_l," special method."),_l.forEach(n),_b=d(Dn),F(Co.$$.fragment,Dn),vb=d(Dn),ic=a(Dn,"P",{});var q0=i(ic);Tb=o(q0,"Example:"),q0.forEach(n),kb=d(Dn),F(Wa.$$.fragment,Dn),Fb=d(Dn),F(Ba.$$.fragment,Dn),Dn.forEach(n),kn.forEach(n),Fp=d(s),Nt=a(s,"H2",{class:!0});var Uu=i(Nt);xo=a(Uu,"A",{id:!0,class:!0,href:!0});var P0=i(xo);lc=a(P0,"SPAN",{});var C0=i(lc);F(Qa.$$.fragment,C0),C0.forEach(n),P0.forEach(n),bb=d(Uu),dc=a(Uu,"SPAN",{});var x0=i(dc);yb=o(x0,"TFFunnelForQuestionAnswering"),x0.forEach(n),Uu.forEach(n),bp=d(s),We=a(s,"DIV",{class:!0});var Fn=i(We);F(Ua.$$.fragment,Fn),wb=d(Fn),St=a(Fn,"P",{});var vl=i(St);$b=o(vl,`Funnel Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear
layers on top of the hidden-states output to compute `),cc=a(vl,"CODE",{});var j0=i(cc);Eb=o(j0,"span start logits"),j0.forEach(n),Mb=o(vl," and "),pc=a(vl,"CODE",{});var L0=i(pc);zb=o(L0,"span end logits"),L0.forEach(n),qb=o(vl,")."),vl.forEach(n),Pb=d(Fn),Ra=a(Fn,"P",{});var Ru=i(Ra);Cb=o(Ru,"The Funnel Transformer model was proposed in "),Va=a(Ru,"A",{href:!0,rel:!0});var O0=i(Va);xb=o(O0,`Funnel-Transformer: Filtering out Sequential Redundancy for Efficient
Language Processing`),O0.forEach(n),jb=o(Ru," by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le."),Ru.forEach(n),Lb=d(Fn),Ha=a(Fn,"P",{});var Vu=i(Ha);Ob=o(Vu,"This model inherits from "),Yi=a(Vu,"A",{href:!0});var D0=i(Yi);Db=o(D0,"TFPreTrainedModel"),D0.forEach(n),Ab=o(Vu,`. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`),Vu.forEach(n),Nb=d(Fn),Ya=a(Fn,"P",{});var Hu=i(Ya);Sb=o(Hu,"This model is also a "),Ka=a(Hu,"A",{href:!0,rel:!0});var A0=i(Ka);Ib=o(A0,"tf.keras.Model"),A0.forEach(n),Wb=o(Hu,` subclass. Use it
as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and
behavior.`),Hu.forEach(n),Bb=d(Fn),F(jo.$$.fragment,Fn),Qb=d(Fn),tn=a(Fn,"DIV",{class:!0});var An=i(tn);F(Ga.$$.fragment,An),Ub=d(An),It=a(An,"P",{});var Tl=i(It);Rb=o(Tl,"The "),Ki=a(Tl,"A",{href:!0});var N0=i(Ki);Vb=o(N0,"TFFunnelForQuestionAnswering"),N0.forEach(n),Hb=o(Tl," forward method, overrides the "),uc=a(Tl,"CODE",{});var S0=i(uc);Yb=o(S0,"__call__"),S0.forEach(n),Kb=o(Tl," special method."),Tl.forEach(n),Gb=d(An),F(Lo.$$.fragment,An),Zb=d(An),hc=a(An,"P",{});var I0=i(hc);Xb=o(I0,"Example:"),I0.forEach(n),Jb=d(An),F(Za.$$.fragment,An),ey=d(An),F(Xa.$$.fragment,An),An.forEach(n),Fn.forEach(n),this.h()},h(){c(u,"name","hf:doc:metadata"),c(u,"content",JSON.stringify(_2)),c(_,"id","funnel-transformer"),c(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_,"href","#funnel-transformer"),c(g,"class","relative group"),c(J,"id","overview"),c(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J,"href","#overview"),c(q,"class","relative group"),c(te,"href","https://arxiv.org/abs/2006.03236"),c(te,"rel","nofollow"),c(re,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelModel"),c(p,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(ve,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(Te,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(ke,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelBaseModel"),c(Fe,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(oi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(No,"href","https://huggingface.co/sgugger"),c(No,"rel","nofollow"),c(So,"href","https://github.com/laiguokun/Funnel-Transformer"),c(So,"rel","nofollow"),c(Wt,"id","transformers.FunnelConfig"),c(Wt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wt,"href","#transformers.FunnelConfig"),c(Zn,"class","relative group"),c(si,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelModel"),c(ri,"href","/docs/transformers/v4.18.0/en/model_doc/bert#transformers.TFBertModel"),c(Bo,"href","https://huggingface.co/funnel-transformer/small"),c(Bo,"rel","nofollow"),c(ai,"href","/docs/transformers/v4.18.0/en/main_classes/configuration#transformers.PretrainedConfig"),c(ii,"href","/docs/transformers/v4.18.0/en/main_classes/configuration#transformers.PretrainedConfig"),c(Nn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bt,"id","transformers.FunnelTokenizer"),c(Bt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bt,"href","#transformers.FunnelTokenizer"),c(Jn,"class","relative group"),c(li,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizer"),c(di,"href","/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer"),c(ci,"href","/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizer"),c(Wn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hi,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rt,"id","transformers.FunnelTokenizerFast"),c(Rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Rt,"href","#transformers.FunnelTokenizerFast"),c(nt,"class","relative group"),c(fi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(mi,"href","/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(gi,"href","/docs/transformers/v4.18.0/en/model_doc/bert#transformers.BertTokenizerFast"),c(yn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ht,"id","transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput"),c(Ht,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ht,"href","#transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput"),c(ot,"class","relative group"),c(_i,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yt,"id","transformers.FunnelBaseModel"),c(Yt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yt,"href","#transformers.FunnelBaseModel"),c(at,"class","relative group"),c(hs,"href","https://arxiv.org/abs/2006.03236"),c(hs,"rel","nofollow"),c(Ti,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c(gs,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c(gs,"rel","nofollow"),c(ki,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelBaseModel"),c(rn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gt,"id","transformers.FunnelModel"),c(Gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gt,"href","#transformers.FunnelModel"),c(lt,"class","relative group"),c(bs,"href","https://arxiv.org/abs/2006.03236"),c(bs,"rel","nofollow"),c(Fi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c($s,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c($s,"rel","nofollow"),c(bi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelModel"),c(an,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xt,"id","transformers.FunnelForPreTraining"),c(Xt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xt,"href","#transformers.FunnelForPreTraining"),c(ct,"class","relative group"),c(yi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(ln,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eo,"id","transformers.FunnelForMaskedLM"),c(eo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eo,"href","#transformers.FunnelForMaskedLM"),c(ht,"class","relative group"),c(Ds,"href","https://arxiv.org/abs/2006.03236"),c(Ds,"rel","nofollow"),c(wi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c(Ss,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c(Ss,"rel","nofollow"),c($i,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(Ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(to,"id","transformers.FunnelForSequenceClassification"),c(to,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(to,"href","#transformers.FunnelForSequenceClassification"),c(mt,"class","relative group"),c(Vs,"href","https://arxiv.org/abs/2006.03236"),c(Vs,"rel","nofollow"),c(Ei,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c(Ks,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c(Ks,"rel","nofollow"),c(Mi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(Pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(so,"id","transformers.FunnelForMultipleChoice"),c(so,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(so,"href","#transformers.FunnelForMultipleChoice"),c(_t,"class","relative group"),c(sr,"href","https://arxiv.org/abs/2006.03236"),c(sr,"rel","nofollow"),c(zi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c(ir,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c(ir,"rel","nofollow"),c(qi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(dn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ao,"id","transformers.FunnelForTokenClassification"),c(ao,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ao,"href","#transformers.FunnelForTokenClassification"),c(Tt,"class","relative group"),c(hr,"href","https://arxiv.org/abs/2006.03236"),c(hr,"rel","nofollow"),c(Pi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c(gr,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c(gr,"rel","nofollow"),c(Ci,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lo,"id","transformers.FunnelForQuestionAnswering"),c(lo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lo,"href","#transformers.FunnelForQuestionAnswering"),c(Ft,"class","relative group"),c(yr,"href","https://arxiv.org/abs/2006.03236"),c(yr,"rel","nofollow"),c(xi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel"),c(Er,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),c(Er,"rel","nofollow"),c(ji,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(po,"id","transformers.TFFunnelBaseModel"),c(po,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(po,"href","#transformers.TFFunnelBaseModel"),c(wt,"class","relative group"),c(jr,"href","https://arxiv.org/abs/2006.03236"),c(jr,"rel","nofollow"),c(Li,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(Dr,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Dr,"rel","nofollow"),c(Oi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(cn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fo,"id","transformers.TFFunnelModel"),c(fo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fo,"href","#transformers.TFFunnelModel"),c(Et,"class","relative group"),c(Br,"href","https://arxiv.org/abs/2006.03236"),c(Br,"rel","nofollow"),c(Di,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(Rr,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Rr,"rel","nofollow"),c(Ai,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelModel"),c(pn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_o,"id","transformers.TFFunnelForPreTraining"),c(_o,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_o,"href","#transformers.TFFunnelForPreTraining"),c(zt,"class","relative group"),c(Zr,"href","https://arxiv.org/abs/2006.03236"),c(Zr,"rel","nofollow"),c(Ni,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(ea,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(ea,"rel","nofollow"),c(Si,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(un,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(De,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"id","transformers.TFFunnelForMaskedLM"),c(ko,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ko,"href","#transformers.TFFunnelForMaskedLM"),c(Pt,"class","relative group"),c(ia,"href","https://arxiv.org/abs/2006.03236"),c(ia,"rel","nofollow"),c(Ii,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(ca,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(ca,"rel","nofollow"),c(Wi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"id","transformers.TFFunnelForSequenceClassification"),c(yo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yo,"href","#transformers.TFFunnelForSequenceClassification"),c(xt,"class","relative group"),c(_a,"href","https://arxiv.org/abs/2006.03236"),c(_a,"rel","nofollow"),c(Bi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(ka,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(ka,"rel","nofollow"),c(Qi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(en,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eo,"id","transformers.TFFunnelForMultipleChoice"),c(Eo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Eo,"href","#transformers.TFFunnelForMultipleChoice"),c(Lt,"class","relative group"),c(Ma,"href","https://arxiv.org/abs/2006.03236"),c(Ma,"rel","nofollow"),c(Ui,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(Pa,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Pa,"rel","nofollow"),c(Ri,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(hn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Se,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"id","transformers.TFFunnelForTokenClassification"),c(qo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qo,"href","#transformers.TFFunnelForTokenClassification"),c(Dt,"class","relative group"),c(Da,"href","https://arxiv.org/abs/2006.03236"),c(Da,"rel","nofollow"),c(Vi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(Sa,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Sa,"rel","nofollow"),c(Hi,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(nn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"id","transformers.TFFunnelForQuestionAnswering"),c(xo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xo,"href","#transformers.TFFunnelForQuestionAnswering"),c(Nt,"class","relative group"),c(Va,"href","https://arxiv.org/abs/2006.03236"),c(Va,"rel","nofollow"),c(Yi,"href","/docs/transformers/v4.18.0/en/main_classes/model#transformers.TFPreTrainedModel"),c(Ka,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Ka,"rel","nofollow"),c(Ki,"href","/docs/transformers/v4.18.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(tn,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(s,f){e(document.head,u),h(s,z,f),h(s,g,f),e(g,_),e(_,T),b(v,T,null),e(g,m),e(g,M),e(M,ce),h(s,K,f),h(s,q,f),e(q,J),e(J,A),b(ne,A,null),e(q,pe),e(q,N),e(N,ue),h(s,ie,f),h(s,Y,f),e(Y,L),e(Y,te),e(te,G),e(Y,P),h(s,x,f),h(s,oe,f),e(oe,B),h(s,le,f),h(s,se,f),e(se,S),e(S,he),h(s,de,f),h(s,C,f),e(C,fe),h(s,W,f),h(s,ee,f),e(ee,ae),e(ae,Q),e(ee,me),e(ee,I),e(I,O),e(I,re),e(re,U),e(I,ge),e(I,p),e(p,E),e(I,Z),e(I,ve),e(ve,ye),e(I,D),e(I,Te),e(Te,we),e(I,$e),e(I,j),e(j,R),e(I,Ee),e(I,ke),e(ke,V),e(I,Me),e(I,Fe),e(Fe,_e),e(I,ze),e(I,oi),e(oi,Yu),e(I,Ku),h(s,Oc,f),h(s,In,f),e(In,Gu),e(In,No),e(No,Zu),e(In,Xu),e(In,So),e(So,Ju),e(In,eh),h(s,Dc,f),h(s,Zn,f),e(Zn,Wt),e(Wt,kl),b(Io,kl,null),e(Zn,nh),e(Zn,Fl),e(Fl,th),h(s,Ac,f),h(s,Nn,f),b(Wo,Nn,null),e(Nn,oh),e(Nn,Sn),e(Sn,sh),e(Sn,si),e(si,rh),e(Sn,ah),e(Sn,ri),e(ri,ih),e(Sn,lh),e(Sn,Bo),e(Bo,dh),e(Sn,ch),e(Nn,ph),e(Nn,Xn),e(Xn,uh),e(Xn,ai),e(ai,hh),e(Xn,fh),e(Xn,ii),e(ii,mh),e(Xn,gh),h(s,Nc,f),h(s,Jn,f),e(Jn,Bt),e(Bt,bl),b(Qo,bl,null),e(Jn,_h),e(Jn,yl),e(yl,vh),h(s,Sc,f),h(s,xe,f),b(Uo,xe,null),e(xe,Th),e(xe,wl),e(wl,kh),e(xe,Fh),e(xe,Qt),e(Qt,li),e(li,bh),e(Qt,yh),e(Qt,di),e(di,wh),e(Qt,$h),e(xe,Eh),e(xe,Ro),e(Ro,Mh),e(Ro,ci),e(ci,zh),e(Ro,qh),e(xe,Ph),e(xe,Wn),b(Vo,Wn,null),e(Wn,Ch),e(Wn,$l),e($l,xh),e(Wn,jh),e(Wn,Ho),e(Ho,pi),e(pi,Lh),e(pi,El),e(El,Oh),e(Ho,Dh),e(Ho,ui),e(ui,Ah),e(ui,Ml),e(Ml,Nh),e(xe,Sh),e(xe,Ut),b(Yo,Ut,null),e(Ut,Ih),e(Ut,Ko),e(Ko,Wh),e(Ko,zl),e(zl,Bh),e(Ko,Qh),e(xe,Uh),e(xe,bn),b(Go,bn,null),e(bn,Rh),e(bn,ql),e(ql,Vh),e(bn,Hh),b(Zo,bn,null),e(bn,Yh),e(bn,et),e(et,Kh),e(et,Pl),e(Pl,Gh),e(et,Zh),e(et,Cl),e(Cl,Xh),e(et,Jh),e(xe,ef),e(xe,hi),b(Xo,hi,null),h(s,Ic,f),h(s,nt,f),e(nt,Rt),e(Rt,xl),b(Jo,xl,null),e(nt,nf),e(nt,jl),e(jl,tf),h(s,Wc,f),h(s,sn,f),b(es,sn,null),e(sn,of),e(sn,ns),e(ns,sf),e(ns,Ll),e(Ll,rf),e(ns,af),e(sn,lf),e(sn,Vt),e(Vt,fi),e(fi,df),e(Vt,cf),e(Vt,mi),e(mi,pf),e(Vt,uf),e(sn,hf),e(sn,ts),e(ts,ff),e(ts,gi),e(gi,mf),e(ts,gf),e(sn,_f),e(sn,yn),b(os,yn,null),e(yn,vf),e(yn,Ol),e(Ol,Tf),e(yn,kf),b(ss,yn,null),e(yn,Ff),e(yn,tt),e(tt,bf),e(tt,Dl),e(Dl,yf),e(tt,wf),e(tt,Al),e(Al,$f),e(tt,Ef),h(s,Bc,f),h(s,ot,f),e(ot,Ht),e(Ht,Nl),b(rs,Nl,null),e(ot,Mf),e(ot,Sl),e(Sl,zf),h(s,Qc,f),h(s,st,f),b(as,st,null),e(st,qf),e(st,is),e(is,Pf),e(is,_i),e(_i,Cf),e(is,xf),h(s,Uc,f),h(s,rt,f),b(ls,rt,null),e(rt,jf),e(rt,ds),e(ds,Lf),e(ds,vi),e(vi,Of),e(ds,Df),h(s,Rc,f),h(s,at,f),e(at,Yt),e(Yt,Il),b(cs,Il,null),e(at,Af),e(at,Wl),e(Wl,Nf),h(s,Vc,f),h(s,Qe,f),b(ps,Qe,null),e(Qe,Sf),e(Qe,Bl),e(Bl,If),e(Qe,Wf),e(Qe,us),e(us,Bf),e(us,hs),e(hs,Qf),e(us,Uf),e(Qe,Rf),e(Qe,fs),e(fs,Vf),e(fs,Ti),e(Ti,Hf),e(fs,Yf),e(Qe,Kf),e(Qe,ms),e(ms,Gf),e(ms,gs),e(gs,Zf),e(ms,Xf),e(Qe,Jf),e(Qe,rn),b(_s,rn,null),e(rn,em),e(rn,it),e(it,nm),e(it,ki),e(ki,tm),e(it,om),e(it,Ql),e(Ql,sm),e(it,rm),e(rn,am),b(Kt,rn,null),e(rn,im),e(rn,Ul),e(Ul,lm),e(rn,dm),b(vs,rn,null),h(s,Hc,f),h(s,lt,f),e(lt,Gt),e(Gt,Rl),b(Ts,Rl,null),e(lt,cm),e(lt,Vl),e(Vl,pm),h(s,Yc,f),h(s,Ue,f),b(ks,Ue,null),e(Ue,um),e(Ue,Hl),e(Hl,hm),e(Ue,fm),e(Ue,Fs),e(Fs,mm),e(Fs,bs),e(bs,gm),e(Fs,_m),e(Ue,vm),e(Ue,ys),e(ys,Tm),e(ys,Fi),e(Fi,km),e(ys,Fm),e(Ue,bm),e(Ue,ws),e(ws,ym),e(ws,$s),e($s,wm),e(ws,$m),e(Ue,Em),e(Ue,an),b(Es,an,null),e(an,Mm),e(an,dt),e(dt,zm),e(dt,bi),e(bi,qm),e(dt,Pm),e(dt,Yl),e(Yl,Cm),e(dt,xm),e(an,jm),b(Zt,an,null),e(an,Lm),e(an,Kl),e(Kl,Om),e(an,Dm),b(Ms,an,null),h(s,Kc,f),h(s,ct,f),e(ct,Xt),e(Xt,Gl),b(zs,Gl,null),e(ct,Am),e(ct,Zl),e(Zl,Nm),h(s,Gc,f),h(s,pt,f),b(qs,pt,null),e(pt,Sm),e(pt,ln),b(Ps,ln,null),e(ln,Im),e(ln,ut),e(ut,Wm),e(ut,yi),e(yi,Bm),e(ut,Qm),e(ut,Xl),e(Xl,Um),e(ut,Rm),e(ln,Vm),b(Jt,ln,null),e(ln,Hm),e(ln,Jl),e(Jl,Ym),e(ln,Km),b(Cs,ln,null),h(s,Zc,f),h(s,ht,f),e(ht,eo),e(eo,ed),b(xs,ed,null),e(ht,Gm),e(ht,nd),e(nd,Zm),h(s,Xc,f),h(s,Re,f),b(js,Re,null),e(Re,Xm),e(Re,Ls),e(Ls,Jm),e(Ls,td),e(td,eg),e(Ls,ng),e(Re,tg),e(Re,Os),e(Os,og),e(Os,Ds),e(Ds,sg),e(Os,rg),e(Re,ag),e(Re,As),e(As,ig),e(As,wi),e(wi,lg),e(As,dg),e(Re,cg),e(Re,Ns),e(Ns,pg),e(Ns,Ss),e(Ss,ug),e(Ns,hg),e(Re,fg),e(Re,Ge),b(Is,Ge,null),e(Ge,mg),e(Ge,ft),e(ft,gg),e(ft,$i),e($i,_g),e(ft,vg),e(ft,od),e(od,Tg),e(ft,kg),e(Ge,Fg),b(no,Ge,null),e(Ge,bg),e(Ge,sd),e(sd,yg),e(Ge,wg),b(Ws,Ge,null),e(Ge,$g),b(Bs,Ge,null),h(s,Jc,f),h(s,mt,f),e(mt,to),e(to,rd),b(Qs,rd,null),e(mt,Eg),e(mt,ad),e(ad,Mg),h(s,ep,f),h(s,Ve,f),b(Us,Ve,null),e(Ve,zg),e(Ve,id),e(id,qg),e(Ve,Pg),e(Ve,Rs),e(Rs,Cg),e(Rs,Vs),e(Vs,xg),e(Rs,jg),e(Ve,Lg),e(Ve,Hs),e(Hs,Og),e(Hs,Ei),e(Ei,Dg),e(Hs,Ag),e(Ve,Ng),e(Ve,Ys),e(Ys,Sg),e(Ys,Ks),e(Ks,Ig),e(Ys,Wg),e(Ve,Bg),e(Ve,Pe),b(Gs,Pe,null),e(Pe,Qg),e(Pe,gt),e(gt,Ug),e(gt,Mi),e(Mi,Rg),e(gt,Vg),e(gt,ld),e(ld,Hg),e(gt,Yg),e(Pe,Kg),b(oo,Pe,null),e(Pe,Gg),e(Pe,dd),e(dd,Zg),e(Pe,Xg),b(Zs,Pe,null),e(Pe,Jg),b(Xs,Pe,null),e(Pe,e_),e(Pe,cd),e(cd,n_),e(Pe,t_),b(Js,Pe,null),e(Pe,o_),b(er,Pe,null),h(s,np,f),h(s,_t,f),e(_t,so),e(so,pd),b(nr,pd,null),e(_t,s_),e(_t,ud),e(ud,r_),h(s,tp,f),h(s,He,f),b(tr,He,null),e(He,a_),e(He,hd),e(hd,i_),e(He,l_),e(He,or),e(or,d_),e(or,sr),e(sr,c_),e(or,p_),e(He,u_),e(He,rr),e(rr,h_),e(rr,zi),e(zi,f_),e(rr,m_),e(He,g_),e(He,ar),e(ar,__),e(ar,ir),e(ir,v_),e(ar,T_),e(He,k_),e(He,dn),b(lr,dn,null),e(dn,F_),e(dn,vt),e(vt,b_),e(vt,qi),e(qi,y_),e(vt,w_),e(vt,fd),e(fd,$_),e(vt,E_),e(dn,M_),b(ro,dn,null),e(dn,z_),e(dn,md),e(md,q_),e(dn,P_),b(dr,dn,null),h(s,op,f),h(s,Tt,f),e(Tt,ao),e(ao,gd),b(cr,gd,null),e(Tt,C_),e(Tt,_d),e(_d,x_),h(s,sp,f),h(s,Ye,f),b(pr,Ye,null),e(Ye,j_),e(Ye,vd),e(vd,L_),e(Ye,O_),e(Ye,ur),e(ur,D_),e(ur,hr),e(hr,A_),e(ur,N_),e(Ye,S_),e(Ye,fr),e(fr,I_),e(fr,Pi),e(Pi,W_),e(fr,B_),e(Ye,Q_),e(Ye,mr),e(mr,U_),e(mr,gr),e(gr,R_),e(mr,V_),e(Ye,H_),e(Ye,Ze),b(_r,Ze,null),e(Ze,Y_),e(Ze,kt),e(kt,K_),e(kt,Ci),e(Ci,G_),e(kt,Z_),e(kt,Td),e(Td,X_),e(kt,J_),e(Ze,ev),b(io,Ze,null),e(Ze,nv),e(Ze,kd),e(kd,tv),e(Ze,ov),b(vr,Ze,null),e(Ze,sv),b(Tr,Ze,null),h(s,rp,f),h(s,Ft,f),e(Ft,lo),e(lo,Fd),b(kr,Fd,null),e(Ft,rv),e(Ft,bd),e(bd,av),h(s,ap,f),h(s,Ke,f),b(Fr,Ke,null),e(Ke,iv),e(Ke,bt),e(bt,lv),e(bt,yd),e(yd,dv),e(bt,cv),e(bt,wd),e(wd,pv),e(bt,uv),e(Ke,hv),e(Ke,br),e(br,fv),e(br,yr),e(yr,mv),e(br,gv),e(Ke,_v),e(Ke,wr),e(wr,vv),e(wr,xi),e(xi,Tv),e(wr,kv),e(Ke,Fv),e(Ke,$r),e($r,bv),e($r,Er),e(Er,yv),e($r,wv),e(Ke,$v),e(Ke,Xe),b(Mr,Xe,null),e(Xe,Ev),e(Xe,yt),e(yt,Mv),e(yt,ji),e(ji,zv),e(yt,qv),e(yt,$d),e($d,Pv),e(yt,Cv),e(Xe,xv),b(co,Xe,null),e(Xe,jv),e(Xe,Ed),e(Ed,Lv),e(Xe,Ov),b(zr,Xe,null),e(Xe,Dv),b(qr,Xe,null),h(s,ip,f),h(s,wt,f),e(wt,po),e(po,Md),b(Pr,Md,null),e(wt,Av),e(wt,zd),e(zd,Nv),h(s,lp,f),h(s,Le,f),b(Cr,Le,null),e(Le,Sv),e(Le,qd),e(qd,Iv),e(Le,Wv),e(Le,xr),e(xr,Bv),e(xr,jr),e(jr,Qv),e(xr,Uv),e(Le,Rv),e(Le,Lr),e(Lr,Vv),e(Lr,Li),e(Li,Hv),e(Lr,Yv),e(Le,Kv),e(Le,Or),e(Or,Gv),e(Or,Dr),e(Dr,Zv),e(Or,Xv),e(Le,Jv),b(uo,Le,null),e(Le,eT),e(Le,cn),b(Ar,cn,null),e(cn,nT),e(cn,$t),e($t,tT),e($t,Oi),e(Oi,oT),e($t,sT),e($t,Pd),e(Pd,rT),e($t,aT),e(cn,iT),b(ho,cn,null),e(cn,lT),e(cn,Cd),e(Cd,dT),e(cn,cT),b(Nr,cn,null),h(s,dp,f),h(s,Et,f),e(Et,fo),e(fo,xd),b(Sr,xd,null),e(Et,pT),e(Et,jd),e(jd,uT),h(s,cp,f),h(s,Oe,f),b(Ir,Oe,null),e(Oe,hT),e(Oe,Ld),e(Ld,fT),e(Oe,mT),e(Oe,Wr),e(Wr,gT),e(Wr,Br),e(Br,_T),e(Wr,vT),e(Oe,TT),e(Oe,Qr),e(Qr,kT),e(Qr,Di),e(Di,FT),e(Qr,bT),e(Oe,yT),e(Oe,Ur),e(Ur,wT),e(Ur,Rr),e(Rr,$T),e(Ur,ET),e(Oe,MT),b(mo,Oe,null),e(Oe,zT),e(Oe,pn),b(Vr,pn,null),e(pn,qT),e(pn,Mt),e(Mt,PT),e(Mt,Ai),e(Ai,CT),e(Mt,xT),e(Mt,Od),e(Od,jT),e(Mt,LT),e(pn,OT),b(go,pn,null),e(pn,DT),e(pn,Dd),e(Dd,AT),e(pn,NT),b(Hr,pn,null),h(s,pp,f),h(s,zt,f),e(zt,_o),e(_o,Ad),b(Yr,Ad,null),e(zt,ST),e(zt,Nd),e(Nd,IT),h(s,up,f),h(s,De,f),b(Kr,De,null),e(De,WT),e(De,Sd),e(Sd,BT),e(De,QT),e(De,Gr),e(Gr,UT),e(Gr,Zr),e(Zr,RT),e(Gr,VT),e(De,HT),e(De,Xr),e(Xr,YT),e(Xr,Ni),e(Ni,KT),e(Xr,GT),e(De,ZT),e(De,Jr),e(Jr,XT),e(Jr,ea),e(ea,JT),e(Jr,ek),e(De,nk),b(vo,De,null),e(De,tk),e(De,un),b(na,un,null),e(un,ok),e(un,qt),e(qt,sk),e(qt,Si),e(Si,rk),e(qt,ak),e(qt,Id),e(Id,ik),e(qt,lk),e(un,dk),b(To,un,null),e(un,ck),e(un,Wd),e(Wd,pk),e(un,uk),b(ta,un,null),h(s,hp,f),h(s,Pt,f),e(Pt,ko),e(ko,Bd),b(oa,Bd,null),e(Pt,hk),e(Pt,Qd),e(Qd,fk),h(s,fp,f),h(s,Ae,f),b(sa,Ae,null),e(Ae,mk),e(Ae,ra),e(ra,gk),e(ra,Ud),e(Ud,_k),e(ra,vk),e(Ae,Tk),e(Ae,aa),e(aa,kk),e(aa,ia),e(ia,Fk),e(aa,bk),e(Ae,yk),e(Ae,la),e(la,wk),e(la,Ii),e(Ii,$k),e(la,Ek),e(Ae,Mk),e(Ae,da),e(da,zk),e(da,ca),e(ca,qk),e(da,Pk),e(Ae,Ck),b(Fo,Ae,null),e(Ae,xk),e(Ae,Je),b(pa,Je,null),e(Je,jk),e(Je,Ct),e(Ct,Lk),e(Ct,Wi),e(Wi,Ok),e(Ct,Dk),e(Ct,Rd),e(Rd,Ak),e(Ct,Nk),e(Je,Sk),b(bo,Je,null),e(Je,Ik),e(Je,Vd),e(Vd,Wk),e(Je,Bk),b(ua,Je,null),e(Je,Qk),b(ha,Je,null),h(s,mp,f),h(s,xt,f),e(xt,yo),e(yo,Hd),b(fa,Hd,null),e(xt,Uk),e(xt,Yd),e(Yd,Rk),h(s,gp,f),h(s,Ne,f),b(ma,Ne,null),e(Ne,Vk),e(Ne,Kd),e(Kd,Hk),e(Ne,Yk),e(Ne,ga),e(ga,Kk),e(ga,_a),e(_a,Gk),e(ga,Zk),e(Ne,Xk),e(Ne,va),e(va,Jk),e(va,Bi),e(Bi,eF),e(va,nF),e(Ne,tF),e(Ne,Ta),e(Ta,oF),e(Ta,ka),e(ka,sF),e(Ta,rF),e(Ne,aF),b(wo,Ne,null),e(Ne,iF),e(Ne,en),b(Fa,en,null),e(en,lF),e(en,jt),e(jt,dF),e(jt,Qi),e(Qi,cF),e(jt,pF),e(jt,Gd),e(Gd,uF),e(jt,hF),e(en,fF),b($o,en,null),e(en,mF),e(en,Zd),e(Zd,gF),e(en,_F),b(ba,en,null),e(en,vF),b(ya,en,null),h(s,_p,f),h(s,Lt,f),e(Lt,Eo),e(Eo,Xd),b(wa,Xd,null),e(Lt,TF),e(Lt,Jd),e(Jd,kF),h(s,vp,f),h(s,Se,f),b($a,Se,null),e(Se,FF),e(Se,ec),e(ec,bF),e(Se,yF),e(Se,Ea),e(Ea,wF),e(Ea,Ma),e(Ma,$F),e(Ea,EF),e(Se,MF),e(Se,za),e(za,zF),e(za,Ui),e(Ui,qF),e(za,PF),e(Se,CF),e(Se,qa),e(qa,xF),e(qa,Pa),e(Pa,jF),e(qa,LF),e(Se,OF),b(Mo,Se,null),e(Se,DF),e(Se,hn),b(Ca,hn,null),e(hn,AF),e(hn,Ot),e(Ot,NF),e(Ot,Ri),e(Ri,SF),e(Ot,IF),e(Ot,nc),e(nc,WF),e(Ot,BF),e(hn,QF),b(zo,hn,null),e(hn,UF),e(hn,tc),e(tc,RF),e(hn,VF),b(xa,hn,null),h(s,Tp,f),h(s,Dt,f),e(Dt,qo),e(qo,oc),b(ja,oc,null),e(Dt,HF),e(Dt,sc),e(sc,YF),h(s,kp,f),h(s,Ie,f),b(La,Ie,null),e(Ie,KF),e(Ie,rc),e(rc,GF),e(Ie,ZF),e(Ie,Oa),e(Oa,XF),e(Oa,Da),e(Da,JF),e(Oa,eb),e(Ie,nb),e(Ie,Aa),e(Aa,tb),e(Aa,Vi),e(Vi,ob),e(Aa,sb),e(Ie,rb),e(Ie,Na),e(Na,ab),e(Na,Sa),e(Sa,ib),e(Na,lb),e(Ie,db),b(Po,Ie,null),e(Ie,cb),e(Ie,nn),b(Ia,nn,null),e(nn,pb),e(nn,At),e(At,ub),e(At,Hi),e(Hi,hb),e(At,fb),e(At,ac),e(ac,mb),e(At,gb),e(nn,_b),b(Co,nn,null),e(nn,vb),e(nn,ic),e(ic,Tb),e(nn,kb),b(Wa,nn,null),e(nn,Fb),b(Ba,nn,null),h(s,Fp,f),h(s,Nt,f),e(Nt,xo),e(xo,lc),b(Qa,lc,null),e(Nt,bb),e(Nt,dc),e(dc,yb),h(s,bp,f),h(s,We,f),b(Ua,We,null),e(We,wb),e(We,St),e(St,$b),e(St,cc),e(cc,Eb),e(St,Mb),e(St,pc),e(pc,zb),e(St,qb),e(We,Pb),e(We,Ra),e(Ra,Cb),e(Ra,Va),e(Va,xb),e(Ra,jb),e(We,Lb),e(We,Ha),e(Ha,Ob),e(Ha,Yi),e(Yi,Db),e(Ha,Ab),e(We,Nb),e(We,Ya),e(Ya,Sb),e(Ya,Ka),e(Ka,Ib),e(Ya,Wb),e(We,Bb),b(jo,We,null),e(We,Qb),e(We,tn),b(Ga,tn,null),e(tn,Ub),e(tn,It),e(It,Rb),e(It,Ki),e(Ki,Vb),e(It,Hb),e(It,uc),e(uc,Yb),e(It,Kb),e(tn,Gb),b(Lo,tn,null),e(tn,Zb),e(tn,hc),e(hc,Xb),e(tn,Jb),b(Za,tn,null),e(tn,ey),b(Xa,tn,null),yp=!0},p(s,[f]){const Ja={};f&2&&(Ja.$$scope={dirty:f,ctx:s}),Kt.$set(Ja);const fc={};f&2&&(fc.$$scope={dirty:f,ctx:s}),Zt.$set(fc);const mc={};f&2&&(mc.$$scope={dirty:f,ctx:s}),Jt.$set(mc);const gc={};f&2&&(gc.$$scope={dirty:f,ctx:s}),no.$set(gc);const ei={};f&2&&(ei.$$scope={dirty:f,ctx:s}),oo.$set(ei);const _c={};f&2&&(_c.$$scope={dirty:f,ctx:s}),ro.$set(_c);const vc={};f&2&&(vc.$$scope={dirty:f,ctx:s}),io.$set(vc);const Tc={};f&2&&(Tc.$$scope={dirty:f,ctx:s}),co.$set(Tc);const ni={};f&2&&(ni.$$scope={dirty:f,ctx:s}),uo.$set(ni);const kc={};f&2&&(kc.$$scope={dirty:f,ctx:s}),ho.$set(kc);const Fc={};f&2&&(Fc.$$scope={dirty:f,ctx:s}),mo.$set(Fc);const bc={};f&2&&(bc.$$scope={dirty:f,ctx:s}),go.$set(bc);const yc={};f&2&&(yc.$$scope={dirty:f,ctx:s}),vo.$set(yc);const wc={};f&2&&(wc.$$scope={dirty:f,ctx:s}),To.$set(wc);const ti={};f&2&&(ti.$$scope={dirty:f,ctx:s}),Fo.$set(ti);const $c={};f&2&&($c.$$scope={dirty:f,ctx:s}),bo.$set($c);const je={};f&2&&(je.$$scope={dirty:f,ctx:s}),wo.$set(je);const Ec={};f&2&&(Ec.$$scope={dirty:f,ctx:s}),$o.$set(Ec);const Mc={};f&2&&(Mc.$$scope={dirty:f,ctx:s}),Mo.$set(Mc);const zc={};f&2&&(zc.$$scope={dirty:f,ctx:s}),zo.$set(zc);const qc={};f&2&&(qc.$$scope={dirty:f,ctx:s}),Po.$set(qc);const Pc={};f&2&&(Pc.$$scope={dirty:f,ctx:s}),Co.$set(Pc);const Cc={};f&2&&(Cc.$$scope={dirty:f,ctx:s}),jo.$set(Cc);const xc={};f&2&&(xc.$$scope={dirty:f,ctx:s}),Lo.$set(xc)},i(s){yp||(y(v.$$.fragment,s),y(ne.$$.fragment,s),y(Io.$$.fragment,s),y(Wo.$$.fragment,s),y(Qo.$$.fragment,s),y(Uo.$$.fragment,s),y(Vo.$$.fragment,s),y(Yo.$$.fragment,s),y(Go.$$.fragment,s),y(Zo.$$.fragment,s),y(Xo.$$.fragment,s),y(Jo.$$.fragment,s),y(es.$$.fragment,s),y(os.$$.fragment,s),y(ss.$$.fragment,s),y(rs.$$.fragment,s),y(as.$$.fragment,s),y(ls.$$.fragment,s),y(cs.$$.fragment,s),y(ps.$$.fragment,s),y(_s.$$.fragment,s),y(Kt.$$.fragment,s),y(vs.$$.fragment,s),y(Ts.$$.fragment,s),y(ks.$$.fragment,s),y(Es.$$.fragment,s),y(Zt.$$.fragment,s),y(Ms.$$.fragment,s),y(zs.$$.fragment,s),y(qs.$$.fragment,s),y(Ps.$$.fragment,s),y(Jt.$$.fragment,s),y(Cs.$$.fragment,s),y(xs.$$.fragment,s),y(js.$$.fragment,s),y(Is.$$.fragment,s),y(no.$$.fragment,s),y(Ws.$$.fragment,s),y(Bs.$$.fragment,s),y(Qs.$$.fragment,s),y(Us.$$.fragment,s),y(Gs.$$.fragment,s),y(oo.$$.fragment,s),y(Zs.$$.fragment,s),y(Xs.$$.fragment,s),y(Js.$$.fragment,s),y(er.$$.fragment,s),y(nr.$$.fragment,s),y(tr.$$.fragment,s),y(lr.$$.fragment,s),y(ro.$$.fragment,s),y(dr.$$.fragment,s),y(cr.$$.fragment,s),y(pr.$$.fragment,s),y(_r.$$.fragment,s),y(io.$$.fragment,s),y(vr.$$.fragment,s),y(Tr.$$.fragment,s),y(kr.$$.fragment,s),y(Fr.$$.fragment,s),y(Mr.$$.fragment,s),y(co.$$.fragment,s),y(zr.$$.fragment,s),y(qr.$$.fragment,s),y(Pr.$$.fragment,s),y(Cr.$$.fragment,s),y(uo.$$.fragment,s),y(Ar.$$.fragment,s),y(ho.$$.fragment,s),y(Nr.$$.fragment,s),y(Sr.$$.fragment,s),y(Ir.$$.fragment,s),y(mo.$$.fragment,s),y(Vr.$$.fragment,s),y(go.$$.fragment,s),y(Hr.$$.fragment,s),y(Yr.$$.fragment,s),y(Kr.$$.fragment,s),y(vo.$$.fragment,s),y(na.$$.fragment,s),y(To.$$.fragment,s),y(ta.$$.fragment,s),y(oa.$$.fragment,s),y(sa.$$.fragment,s),y(Fo.$$.fragment,s),y(pa.$$.fragment,s),y(bo.$$.fragment,s),y(ua.$$.fragment,s),y(ha.$$.fragment,s),y(fa.$$.fragment,s),y(ma.$$.fragment,s),y(wo.$$.fragment,s),y(Fa.$$.fragment,s),y($o.$$.fragment,s),y(ba.$$.fragment,s),y(ya.$$.fragment,s),y(wa.$$.fragment,s),y($a.$$.fragment,s),y(Mo.$$.fragment,s),y(Ca.$$.fragment,s),y(zo.$$.fragment,s),y(xa.$$.fragment,s),y(ja.$$.fragment,s),y(La.$$.fragment,s),y(Po.$$.fragment,s),y(Ia.$$.fragment,s),y(Co.$$.fragment,s),y(Wa.$$.fragment,s),y(Ba.$$.fragment,s),y(Qa.$$.fragment,s),y(Ua.$$.fragment,s),y(jo.$$.fragment,s),y(Ga.$$.fragment,s),y(Lo.$$.fragment,s),y(Za.$$.fragment,s),y(Xa.$$.fragment,s),yp=!0)},o(s){w(v.$$.fragment,s),w(ne.$$.fragment,s),w(Io.$$.fragment,s),w(Wo.$$.fragment,s),w(Qo.$$.fragment,s),w(Uo.$$.fragment,s),w(Vo.$$.fragment,s),w(Yo.$$.fragment,s),w(Go.$$.fragment,s),w(Zo.$$.fragment,s),w(Xo.$$.fragment,s),w(Jo.$$.fragment,s),w(es.$$.fragment,s),w(os.$$.fragment,s),w(ss.$$.fragment,s),w(rs.$$.fragment,s),w(as.$$.fragment,s),w(ls.$$.fragment,s),w(cs.$$.fragment,s),w(ps.$$.fragment,s),w(_s.$$.fragment,s),w(Kt.$$.fragment,s),w(vs.$$.fragment,s),w(Ts.$$.fragment,s),w(ks.$$.fragment,s),w(Es.$$.fragment,s),w(Zt.$$.fragment,s),w(Ms.$$.fragment,s),w(zs.$$.fragment,s),w(qs.$$.fragment,s),w(Ps.$$.fragment,s),w(Jt.$$.fragment,s),w(Cs.$$.fragment,s),w(xs.$$.fragment,s),w(js.$$.fragment,s),w(Is.$$.fragment,s),w(no.$$.fragment,s),w(Ws.$$.fragment,s),w(Bs.$$.fragment,s),w(Qs.$$.fragment,s),w(Us.$$.fragment,s),w(Gs.$$.fragment,s),w(oo.$$.fragment,s),w(Zs.$$.fragment,s),w(Xs.$$.fragment,s),w(Js.$$.fragment,s),w(er.$$.fragment,s),w(nr.$$.fragment,s),w(tr.$$.fragment,s),w(lr.$$.fragment,s),w(ro.$$.fragment,s),w(dr.$$.fragment,s),w(cr.$$.fragment,s),w(pr.$$.fragment,s),w(_r.$$.fragment,s),w(io.$$.fragment,s),w(vr.$$.fragment,s),w(Tr.$$.fragment,s),w(kr.$$.fragment,s),w(Fr.$$.fragment,s),w(Mr.$$.fragment,s),w(co.$$.fragment,s),w(zr.$$.fragment,s),w(qr.$$.fragment,s),w(Pr.$$.fragment,s),w(Cr.$$.fragment,s),w(uo.$$.fragment,s),w(Ar.$$.fragment,s),w(ho.$$.fragment,s),w(Nr.$$.fragment,s),w(Sr.$$.fragment,s),w(Ir.$$.fragment,s),w(mo.$$.fragment,s),w(Vr.$$.fragment,s),w(go.$$.fragment,s),w(Hr.$$.fragment,s),w(Yr.$$.fragment,s),w(Kr.$$.fragment,s),w(vo.$$.fragment,s),w(na.$$.fragment,s),w(To.$$.fragment,s),w(ta.$$.fragment,s),w(oa.$$.fragment,s),w(sa.$$.fragment,s),w(Fo.$$.fragment,s),w(pa.$$.fragment,s),w(bo.$$.fragment,s),w(ua.$$.fragment,s),w(ha.$$.fragment,s),w(fa.$$.fragment,s),w(ma.$$.fragment,s),w(wo.$$.fragment,s),w(Fa.$$.fragment,s),w($o.$$.fragment,s),w(ba.$$.fragment,s),w(ya.$$.fragment,s),w(wa.$$.fragment,s),w($a.$$.fragment,s),w(Mo.$$.fragment,s),w(Ca.$$.fragment,s),w(zo.$$.fragment,s),w(xa.$$.fragment,s),w(ja.$$.fragment,s),w(La.$$.fragment,s),w(Po.$$.fragment,s),w(Ia.$$.fragment,s),w(Co.$$.fragment,s),w(Wa.$$.fragment,s),w(Ba.$$.fragment,s),w(Qa.$$.fragment,s),w(Ua.$$.fragment,s),w(jo.$$.fragment,s),w(Ga.$$.fragment,s),w(Lo.$$.fragment,s),w(Za.$$.fragment,s),w(Xa.$$.fragment,s),yp=!1},d(s){n(u),s&&n(z),s&&n(g),$(v),s&&n(K),s&&n(q),$(ne),s&&n(ie),s&&n(Y),s&&n(x),s&&n(oe),s&&n(le),s&&n(se),s&&n(de),s&&n(C),s&&n(W),s&&n(ee),s&&n(Oc),s&&n(In),s&&n(Dc),s&&n(Zn),$(Io),s&&n(Ac),s&&n(Nn),$(Wo),s&&n(Nc),s&&n(Jn),$(Qo),s&&n(Sc),s&&n(xe),$(Uo),$(Vo),$(Yo),$(Go),$(Zo),$(Xo),s&&n(Ic),s&&n(nt),$(Jo),s&&n(Wc),s&&n(sn),$(es),$(os),$(ss),s&&n(Bc),s&&n(ot),$(rs),s&&n(Qc),s&&n(st),$(as),s&&n(Uc),s&&n(rt),$(ls),s&&n(Rc),s&&n(at),$(cs),s&&n(Vc),s&&n(Qe),$(ps),$(_s),$(Kt),$(vs),s&&n(Hc),s&&n(lt),$(Ts),s&&n(Yc),s&&n(Ue),$(ks),$(Es),$(Zt),$(Ms),s&&n(Kc),s&&n(ct),$(zs),s&&n(Gc),s&&n(pt),$(qs),$(Ps),$(Jt),$(Cs),s&&n(Zc),s&&n(ht),$(xs),s&&n(Xc),s&&n(Re),$(js),$(Is),$(no),$(Ws),$(Bs),s&&n(Jc),s&&n(mt),$(Qs),s&&n(ep),s&&n(Ve),$(Us),$(Gs),$(oo),$(Zs),$(Xs),$(Js),$(er),s&&n(np),s&&n(_t),$(nr),s&&n(tp),s&&n(He),$(tr),$(lr),$(ro),$(dr),s&&n(op),s&&n(Tt),$(cr),s&&n(sp),s&&n(Ye),$(pr),$(_r),$(io),$(vr),$(Tr),s&&n(rp),s&&n(Ft),$(kr),s&&n(ap),s&&n(Ke),$(Fr),$(Mr),$(co),$(zr),$(qr),s&&n(ip),s&&n(wt),$(Pr),s&&n(lp),s&&n(Le),$(Cr),$(uo),$(Ar),$(ho),$(Nr),s&&n(dp),s&&n(Et),$(Sr),s&&n(cp),s&&n(Oe),$(Ir),$(mo),$(Vr),$(go),$(Hr),s&&n(pp),s&&n(zt),$(Yr),s&&n(up),s&&n(De),$(Kr),$(vo),$(na),$(To),$(ta),s&&n(hp),s&&n(Pt),$(oa),s&&n(fp),s&&n(Ae),$(sa),$(Fo),$(pa),$(bo),$(ua),$(ha),s&&n(mp),s&&n(xt),$(fa),s&&n(gp),s&&n(Ne),$(ma),$(wo),$(Fa),$($o),$(ba),$(ya),s&&n(_p),s&&n(Lt),$(wa),s&&n(vp),s&&n(Se),$($a),$(Mo),$(Ca),$(zo),$(xa),s&&n(Tp),s&&n(Dt),$(ja),s&&n(kp),s&&n(Ie),$(La),$(Po),$(Ia),$(Co),$(Wa),$(Ba),s&&n(Fp),s&&n(Nt),$(Qa),s&&n(bp),s&&n(We),$(Ua),$(jo),$(Ga),$(Lo),$(Za),$(Xa)}}}const _2={local:"funnel-transformer",sections:[{local:"overview",title:"Overview"},{local:"transformers.FunnelConfig",title:"FunnelConfig"},{local:"transformers.FunnelTokenizer",title:"FunnelTokenizer"},{local:"transformers.FunnelTokenizerFast",title:"FunnelTokenizerFast"},{local:"transformers.models.funnel.modeling_funnel.FunnelForPreTrainingOutput",title:"Funnel specific outputs"},{local:"transformers.FunnelBaseModel",title:"FunnelBaseModel"},{local:"transformers.FunnelModel",title:"FunnelModel"},{local:"transformers.FunnelForPreTraining",title:"FunnelModelForPreTraining"},{local:"transformers.FunnelForMaskedLM",title:"FunnelForMaskedLM"},{local:"transformers.FunnelForSequenceClassification",title:"FunnelForSequenceClassification"},{local:"transformers.FunnelForMultipleChoice",title:"FunnelForMultipleChoice"},{local:"transformers.FunnelForTokenClassification",title:"FunnelForTokenClassification"},{local:"transformers.FunnelForQuestionAnswering",title:"FunnelForQuestionAnswering"},{local:"transformers.TFFunnelBaseModel",title:"TFFunnelBaseModel"},{local:"transformers.TFFunnelModel",title:"TFFunnelModel"},{local:"transformers.TFFunnelForPreTraining",title:"TFFunnelModelForPreTraining"},{local:"transformers.TFFunnelForMaskedLM",title:"TFFunnelForMaskedLM"},{local:"transformers.TFFunnelForSequenceClassification",title:"TFFunnelForSequenceClassification"},{local:"transformers.TFFunnelForMultipleChoice",title:"TFFunnelForMultipleChoice"},{local:"transformers.TFFunnelForTokenClassification",title:"TFFunnelForTokenClassification"},{local:"transformers.TFFunnelForQuestionAnswering",title:"TFFunnelForQuestionAnswering"}],title:"Funnel Transformer"};function v2(H){return R0(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class w2 extends W0{constructor(u){super();B0(this,u,v2,g2,Q0,{})}}export{w2 as default,_2 as metadata};
