import{S as Oi,i as Ai,s as Ci,e as r,k as i,w as v,t as o,M as Li,c as s,d as t,m as c,a as n,x as _,h as l,b as p,F as e,g as m,y as b,L as Ii,q as w,o as $,B as y}from"../../chunks/vendor-ab4e3193.js";import{D as P}from"../../chunks/Docstring-b69c0bd4.js";import{C as Ta}from"../../chunks/CodeBlock-516df0c5.js";import{I as rt}from"../../chunks/IconCopyLink-d992940d.js";import"../../chunks/CopyButton-204b56db.js";function Ui(_r){let O,Ve,k,x,st,ne,br,nt,wr,xa,Y,$r,Me,yr,Er,ja,Re,Dr,Oa,L,W,ot,oe,Pr,lt,kr,Aa,I,le,Tr,it,xr,Ca,U,ie,jr,ct,Or,La,z,ce,Ar,D,Cr,dt,Lr,Ir,ht,Ur,zr,pt,Sr,Hr,ft,Nr,Gr,Ia,S,de,Vr,ut,Mr,Ua,H,J,mt,he,Rr,gt,Fr,za,N,pe,qr,vt,Br,Sa,G,Q,_t,fe,Kr,bt,Yr,Ha,f,ue,Wr,wt,Jr,Qr,$t,Xr,Zr,yt,Et,es,ts,Dt,as,rs,V,Fe,ss,Pt,ns,os,qe,ls,kt,is,cs,Be,ds,Tt,hs,ps,xt,fs,us,M,Ke,ms,jt,gs,vs,Ye,_s,Ot,bs,ws,We,$s,At,ys,Es,Ct,Ds,Ps,Lt,It,ks,Ts,Ut,xs,js,zt,St,Os,As,Ht,Cs,Ls,X,me,Is,ge,Us,Nt,zs,Ss,Hs,Z,ve,Ns,Gt,Gs,Na,R,ee,Vt,_e,Vs,Mt,Ms,Ga,E,be,Rs,we,Fs,Rt,qs,Bs,Ks,$e,Ys,Ft,Ws,Js,Qs,A,ye,Xs,qt,Zs,en,Ee,tn,Bt,an,rn,sn,te,De,nn,Pe,on,Kt,ln,cn,dn,ae,ke,hn,Te,pn,Yt,fn,un,Va,F,re,Wt,xe,mn,Jt,gn,Ma,d,je,vn,q,_n,Qt,bn,wn,Xt,$n,yn,En,Zt,Dn,Pn,Oe,ea,kn,Tn,ta,xn,jn,aa,On,An,ra,Cn,Ln,Ae,In,j,Un,sa,zn,Sn,na,Hn,Nn,oa,Gn,Vn,Mn,Ce,Le,Rn,la,Fn,qn,Bn,ia,Kn,Yn,Ie,Wn,ca,Jn,Qn,Xn,Ue,Zn,B,eo,da,to,ao,ha,ro,so,no,pa,oo,lo,ze,io,fa,co,ho,po,ua,fo,uo,Se,mo,ma,go,vo,ga,_o,bo,va,wo,$o,He,yo,_a,Eo,Do,Po,Ne,ko,ba,To,xo,wa,jo,Oo,$a,Ao,Co,ya,Lo,Io,Ge,Uo,Ea,zo,So,Je,Da,Ho,No,Go,K,Vo,Pa,Mo,Ro,ka,Fo,qo,Ra;return ne=new rt({}),oe=new rt({}),le=new P({props:{name:"class transformers.EvalPrediction",anchor:"transformers.EvalPrediction",parameters:[{name:"predictions",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"},{name:"label_ids",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_utils.py#L68",parametersDescription:[{anchor:"transformers.EvalPrediction.predictions",description:"<strong>predictions</strong> (<code>np.ndarray</code>) &#x2014; Predictions of the model.",name:"predictions"},{anchor:"transformers.EvalPrediction.label_ids",description:"<strong>label_ids</strong> (<code>np.ndarray</code>) &#x2014; Targets to be matched.",name:"label_ids"}]}}),ie=new P({props:{name:"class transformers.IntervalStrategy",anchor:"transformers.IntervalStrategy",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_utils.py#L116"}}),ce=new P({props:{name:"transformers.set_seed",anchor:"transformers.set_seed",parameters:[{name:"seed",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_utils.py#L50",parametersDescription:[{anchor:"transformers.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"}]}}),de=new P({props:{name:"transformers.torch_distributed_zero_first",anchor:"transformers.torch_distributed_zero_first",parameters:[{name:"local_rank",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_pt_utils.py#L212",parametersDescription:[{anchor:"transformers.torch_distributed_zero_first.local_rank",description:"<strong>local_rank</strong> (<code>int</code>) &#x2014; The rank of the local process.",name:"local_rank"}]}}),he=new rt({}),pe=new P({props:{name:"class transformers.trainer_callback.CallbackHandler",anchor:"transformers.trainer_callback.CallbackHandler",parameters:[{name:"callbacks",val:""},{name:"model",val:""},{name:"tokenizer",val:""},{name:"optimizer",val:""},{name:"lr_scheduler",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_callback.py#L283"}}),fe=new rt({}),ue=new P({props:{name:"class transformers.trainer_pt_utils.DistributedTensorGatherer",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer",parameters:[{name:"world_size",val:""},{name:"num_samples",val:""},{name:"make_multiple_of",val:" = None"},{name:"padding_index",val:" = -100"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_pt_utils.py#L338",parametersDescription:[{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.world_size",description:`<strong>world_size</strong> (<code>int</code>) &#x2014;
The number of processes used in the distributed training.`,name:"world_size"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.num_samples",description:`<strong>num_samples</strong> (<code>int</code>) &#x2014;
The number of samples in our dataset.`,name:"num_samples"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.make_multiple_of",description:`<strong>make_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If passed, the class assumes the datasets passed to each process are made to be a multiple of this argument
(by adding samples).`,name:"make_multiple_of"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.padding_index",description:`<strong>padding_index</strong> (<code>int</code>, <em>optional</em>, defaults to -100) &#x2014;
The padding index to use if the arrays don&#x2019;t all have the same sequence length.`,name:"padding_index"}]}}),me=new P({props:{name:"add_arrays",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.add_arrays",parameters:[{name:"arrays",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_pt_utils.py#L399"}}),ve=new P({props:{name:"finalize",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.finalize",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/trainer_pt_utils.py#L435"}}),_e=new rt({}),be=new P({props:{name:"class transformers.HfArgumentParser",anchor:"transformers.HfArgumentParser",parameters:[{name:"dataclass_types",val:": typing.Union[DataClassType, typing.Iterable[DataClassType]]"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/hf_argparser.py#L44"}}),ye=new P({props:{name:"parse_args_into_dataclasses",anchor:"transformers.HfArgumentParser.parse_args_into_dataclasses",parameters:[{name:"args",val:" = None"},{name:"return_remaining_strings",val:" = False"},{name:"look_for_args_file",val:" = True"},{name:"args_filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/hf_argparser.py#L160",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.abspath<ul>
<li>if applicable, an additional namespace for more (non-dataclass backed) arguments added to the parser
after initialization.</li>
<li>The potential list of remaining argument strings. (same as argparse.ArgumentParser.parse_known_args)</li>
</ul></li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),De=new P({props:{name:"parse_dict",anchor:"transformers.HfArgumentParser.parse_dict",parameters:[{name:"args",val:": dict"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/hf_argparser.py#L233"}}),ke=new P({props:{name:"parse_json_file",anchor:"transformers.HfArgumentParser.parse_json_file",parameters:[{name:"json_file",val:": str"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/hf_argparser.py#L219"}}),xe=new rt({}),je=new P({props:{name:"class transformers.debug_utils.DebugUnderflowOverflow",anchor:"transformers.debug_utils.DebugUnderflowOverflow",parameters:[{name:"model",val:""},{name:"max_frames_to_save",val:" = 21"},{name:"trace_batch_nums",val:" = []"},{name:"abort_after_batch_num",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/debug_utils.py#L28",parametersDescription:[{anchor:"transformers.debug_utils.DebugUnderflowOverflow.model",description:`<strong>model</strong> (<code>nn.Module</code>) &#x2014;
The model to debug.`,name:"model"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.max_frames_to_save",description:`<strong>max_frames_to_save</strong> (<code>int</code>, <em>optional</em>, defaults to 21) &#x2014;
How many frames back to record`,name:"max_frames_to_save"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.trace_batch_nums(List[int],",description:`<strong>trace_batch_nums(<code>List[int]</code>,</strong> <em>optional</em>, defaults to <code>[]</code>) &#x2014;
Which batch numbers to trace (turns detection off)`,name:"trace_batch_nums(List[int],"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.abort_after_batch_num",description:"<strong>abort_after_batch_num</strong>  (`int&#x201C;, <em>optional</em>) &#x2014;\nWhether to abort after a certain batch number has finished",name:"abort_after_batch_num"}]}}),Ae=new Ta({props:{code:"debug_overflow = DebugUnderflowOverflow(model),",highlighted:"debug_overflow = DebugUnderflowOverflow(model)"}}),Ue=new Ta({props:{code:`Detected inf/nan during batch_number=0
Last 21 forward frames:
abs min  abs max  metadata
[...]
                  encoder.block.2.layer.1.DenseReluDense.wi_0 Linear
2.17e-07 4.50e+00 weight
1.79e-06 4.65e+00 input[0]
2.68e-06 3.70e+01 output
                  encoder.block.2.layer.1.DenseReluDense.wi_1 Linear
8.08e-07 2.66e+01 weight
1.79e-06 4.65e+00 input[0]
1.27e-04 2.37e+02 output
                  encoder.block.2.layer.1.DenseReluDense.wo Linear
1.01e-06 6.44e+00 weight
0.00e+00 9.74e+03 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.DenseReluDense T5DenseGatedGeluDense
1.79e-06 4.65e+00 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.dropout Dropout
3.18e-04 6.27e+04 input[0]
0.00e+00      inf output,`,highlighted:`Detected inf/nan during batch_number=<span class="hljs-number">0</span>
Last <span class="hljs-number">21</span> forward frames:
<span class="hljs-built_in">abs</span> <span class="hljs-built_in">min</span>  <span class="hljs-built_in">abs</span> <span class="hljs-built_in">max</span>  metadata
[...]
                  encoder.block<span class="hljs-number">.2</span>.layer<span class="hljs-number">.1</span>.DenseReluDense.wi_0 Linear
<span class="hljs-number">2.17e-07</span> <span class="hljs-number">4.50e+00</span> weight
<span class="hljs-number">1.79e-06</span> <span class="hljs-number">4.65e+00</span> <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>]
<span class="hljs-number">2.68e-06</span> <span class="hljs-number">3.70e+01</span> output
                  encoder.block<span class="hljs-number">.2</span>.layer<span class="hljs-number">.1</span>.DenseReluDense.wi_1 Linear
<span class="hljs-number">8.08e-07</span> <span class="hljs-number">2.66e+01</span> weight
<span class="hljs-number">1.79e-06</span> <span class="hljs-number">4.65e+00</span> <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>]
<span class="hljs-number">1.27e-04</span> <span class="hljs-number">2.37e+02</span> output
                  encoder.block<span class="hljs-number">.2</span>.layer<span class="hljs-number">.1</span>.DenseReluDense.wo Linear
<span class="hljs-number">1.01e-06</span> <span class="hljs-number">6.44e+00</span> weight
<span class="hljs-number">0.00e+00</span> <span class="hljs-number">9.74e+03</span> <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>]
<span class="hljs-number">3.18e-04</span> <span class="hljs-number">6.27e+04</span> output
                  encoder.block<span class="hljs-number">.2</span>.layer<span class="hljs-number">.1</span>.DenseReluDense T5DenseGatedGeluDense
<span class="hljs-number">1.79e-06</span> <span class="hljs-number">4.65e+00</span> <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>]
<span class="hljs-number">3.18e-04</span> <span class="hljs-number">6.27e+04</span> output
                  encoder.block<span class="hljs-number">.2</span>.layer<span class="hljs-number">.1</span>.dropout Dropout
<span class="hljs-number">3.18e-04</span> <span class="hljs-number">6.27e+04</span> <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>]
<span class="hljs-number">0.00e+00</span>      inf output`}}),Se=new Ta({props:{code:"debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=100),",highlighted:'debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=<span class="hljs-number">100</span>)'}}),Ne=new Ta({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1,3]),",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>])'}}),Ge=new Ta({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1,3], abort_after_batch_num=3),",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>], abort_after_batch_num=<span class="hljs-number">3</span>)'}}),{c(){O=r("meta"),Ve=i(),k=r("h1"),x=r("a"),st=r("span"),v(ne.$$.fragment),br=i(),nt=r("span"),wr=o("Utilities for Trainer"),xa=i(),Y=r("p"),$r=o("This page lists all the utility functions used by "),Me=r("a"),yr=o("Trainer"),Er=o("."),ja=i(),Re=r("p"),Dr=o("Most of those are only useful if you are studying the code of the Trainer in the library."),Oa=i(),L=r("h2"),W=r("a"),ot=r("span"),v(oe.$$.fragment),Pr=i(),lt=r("span"),kr=o("Utilities"),Aa=i(),I=r("div"),v(le.$$.fragment),Tr=i(),it=r("p"),xr=o("Evaluation output (always contains labels), to be used to compute metrics."),Ca=i(),U=r("div"),v(ie.$$.fragment),jr=i(),ct=r("p"),Or=o("An enumeration."),La=i(),z=r("div"),v(ce.$$.fragment),Ar=i(),D=r("p"),Cr=o("Helper function for reproducible behavior to set the seed in "),dt=r("code"),Lr=o("random"),Ir=o(", "),ht=r("code"),Ur=o("numpy"),zr=o(", "),pt=r("code"),Sr=o("torch"),Hr=o(" and/or "),ft=r("code"),Nr=o("tf"),Gr=o(` (if
installed).`),Ia=i(),S=r("div"),v(de.$$.fragment),Vr=i(),ut=r("p"),Mr=o("Decorator to make all processes in distributed training wait for each local_master to do something."),Ua=i(),H=r("h2"),J=r("a"),mt=r("span"),v(he.$$.fragment),Rr=i(),gt=r("span"),Fr=o("Callbacks internals"),za=i(),N=r("div"),v(pe.$$.fragment),qr=i(),vt=r("p"),Br=o("Internal class that just calls the list of callbacks in order."),Sa=i(),G=r("h2"),Q=r("a"),_t=r("span"),v(fe.$$.fragment),Kr=i(),bt=r("span"),Yr=o("Distributed Evaluation"),Ha=i(),f=r("div"),v(ue.$$.fragment),Wr=i(),wt=r("p"),Jr=o("A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),Qr=i(),$t=r("p"),Xr=o(`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),Zr=i(),yt=r("p"),Et=r("code"),es=o("[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),ts=i(),Dt=r("p"),as=o(`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),rs=i(),V=r("ul"),Fe=r("li"),ss=o("P0: "),Pt=r("code"),ns=o("[0, 1, 2, 3, 4, 5]"),os=i(),qe=r("li"),ls=o("P1: "),kt=r("code"),is=o("[6, 7, 8, 9, 10, 11]"),cs=i(),Be=r("li"),ds=o("P2: "),Tt=r("code"),hs=o("[12, 13, 14, 15, 0, 1]"),ps=i(),xt=r("p"),fs=o("The first batch treated on each process will be"),us=i(),M=r("ul"),Ke=r("li"),ms=o("P0: "),jt=r("code"),gs=o("[0, 1]"),vs=i(),Ye=r("li"),_s=o("P1: "),Ot=r("code"),bs=o("[6, 7]"),ws=i(),We=r("li"),$s=o("P2: "),At=r("code"),ys=o("[12, 13]"),Es=i(),Ct=r("p"),Ds=o(`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),Ps=i(),Lt=r("p"),It=r("code"),ks=o("[0, 1, 6, 7, 12, 13]"),Ts=i(),Ut=r("p"),xs=o(`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),js=i(),zt=r("p"),St=r("code"),Os=o("[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),As=i(),Ht=r("p"),Cs=o("For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),Ls=i(),X=r("div"),v(me.$$.fragment),Is=i(),ge=r("p"),Us=o("Add "),Nt=r("code"),zs=o("arrays"),Ss=o(` to the internal storage, Will initialize the storage to the full size at the first arrays
passed so that if we\u2019re bound to get an OOM, it happens at the beginning.`),Hs=i(),Z=r("div"),v(ve.$$.fragment),Ns=i(),Gt=r("p"),Gs=o(`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),Na=i(),R=r("h2"),ee=r("a"),Vt=r("span"),v(_e.$$.fragment),Vs=i(),Mt=r("span"),Ms=o("Distributed Evaluation"),Ga=i(),E=r("div"),v(be.$$.fragment),Rs=i(),we=r("p"),Fs=o("This subclass of "),Rt=r("code"),qs=o("argparse.ArgumentParser"),Bs=o(" uses type hints on dataclasses to generate arguments."),Ks=i(),$e=r("p"),Ys=o(`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),Ft=r("code"),Ws=o("_argument_group_name"),Js=o(" attribute in the dataclass."),Qs=i(),A=r("div"),v(ye.$$.fragment),Xs=i(),qt=r("p"),Zs=o("Parse command-line args into instances of the specified dataclass types."),en=i(),Ee=r("p"),tn=o("This relies on argparse\u2019s "),Bt=r("code"),an=o("ArgumentParser.parse_known_args"),rn=o(`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),sn=i(),te=r("div"),v(De.$$.fragment),nn=i(),Pe=r("p"),on=o("Alternative helper method that does not use "),Kt=r("code"),ln=o("argparse"),cn=o(` at all, instead uses a dict and populating the dataclass
types.`),dn=i(),ae=r("div"),v(ke.$$.fragment),hn=i(),Te=r("p"),pn=o("Alternative helper method that does not use "),Yt=r("code"),fn=o("argparse"),un=o(` at all, instead loading a json file and populating the
dataclass types.`),Va=i(),F=r("h2"),re=r("a"),Wt=r("span"),v(xe.$$.fragment),mn=i(),Jt=r("span"),gn=o("Debug Utilities"),Ma=i(),d=r("div"),v(je.$$.fragment),vn=i(),q=r("p"),_n=o(`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),Qt=r("code"),bn=o("nan"),wn=o(" or "),Xt=r("code"),$n=o("inf"),yn=o(" weight and activation elements."),En=i(),Zt=r("p"),Dn=o("There are 2 working modes:"),Pn=i(),Oe=r("ol"),ea=r("li"),kn=o("Underflow/overflow detection (default)"),Tn=i(),ta=r("li"),xn=o("Specific batch absolute min/max tracing without detection"),jn=i(),aa=r("p"),On=o("Mode 1: Underflow/overflow detection"),An=i(),ra=r("p"),Cn=o("To activate the underflow/overflow detection, initialize the object with the model :"),Ln=i(),v(Ae.$$.fragment),In=i(),j=r("p"),Un=o("then run the training as normal and if "),sa=r("code"),zn=o("nan"),Sn=o(" or "),na=r("code"),Hn=o("inf"),Nn=o(` gets detected in at least one of the weight, input or
output elements this module will throw an exception and will print `),oa=r("code"),Gn=o("max_frames_to_save"),Vn=o(` frames that lead to this
event, each frame reporting`),Mn=i(),Ce=r("ol"),Le=r("li"),Rn=o("the fully qualified module name plus the class name whose "),la=r("code"),Fn=o("forward"),qn=o(" was run"),Bn=i(),ia=r("li"),Kn=o("the absolute min and max value of all elements for each module weights, and the inputs and output"),Yn=i(),Ie=r("p"),Wn=o("For example, here is the header and the last few frames in detection report for "),ca=r("code"),Jn=o("google/mt5-small"),Qn=o(" run in fp16 mixed precision :"),Xn=i(),v(Ue.$$.fragment),Zn=i(),B=r("p"),eo=o("You can see here, that "),da=r("code"),to=o("T5DenseGatedGeluDense.forward"),ao=o(` resulted in output activations, whose absolute max value
was around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),ha=r("code"),ro=o("Dropout"),so=o(` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),no=i(),pa=r("p"),oo=o(`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),lo=i(),ze=r("p"),io=o("The tracking is done in a forward hook, which gets invoked immediately after "),fa=r("code"),co=o("forward"),ho=o(" has completed."),po=i(),ua=r("p"),fo=o("By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),uo=i(),v(Se.$$.fragment),mo=i(),ma=r("p"),go=o(`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that may
take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in the next
section.`),vo=i(),ga=r("p"),_o=o("Mode 2. Specific batch absolute min/max tracing without detection"),bo=i(),va=r("p"),wo=o("The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),$o=i(),He=r("p"),yo=o("Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),_a=r("code"),Eo=o("forward"),Do=o(` call of a
given batch, and only do that for batches 1 and 3. Then you instantiate this class as :`),Po=i(),v(Ne.$$.fragment),ko=i(),ba=r("p"),To=o("And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),xo=i(),wa=r("p"),jo=o(`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),Oo=i(),$a=r("p"),Ao=o("Early stopping:"),Co=i(),ya=r("p"),Lo=o("You can also specify the batch number after which to stop the training, with :"),Io=i(),v(Ge.$$.fragment),Uo=i(),Ea=r("p"),zo=o("This feature is mainly useful in the tracing mode, but you can use it for any mode."),So=i(),Je=r("p"),Da=r("strong"),Ho=o("Performance"),No=o(":"),Go=i(),K=r("p"),Vo=o("As this module measures absolute "),Pa=r("code"),Mo=o("min"),Ro=o("/`"),ka=r("code"),Fo=o("max"),qo=o(` of each weight of the model on every forward it\u2019ll slow the
training down. Therefore remember to turn it off once the debugging needs have been met.`),this.h()},l(a){const u=Li('[data-svelte="svelte-1phssyn"]',document.head);O=s(u,"META",{name:!0,content:!0}),u.forEach(t),Ve=c(a),k=s(a,"H1",{class:!0});var Fa=n(k);x=s(Fa,"A",{id:!0,class:!0,href:!0});var Zo=n(x);st=s(Zo,"SPAN",{});var el=n(st);_(ne.$$.fragment,el),el.forEach(t),Zo.forEach(t),br=c(Fa),nt=s(Fa,"SPAN",{});var tl=n(nt);wr=l(tl,"Utilities for Trainer"),tl.forEach(t),Fa.forEach(t),xa=c(a),Y=s(a,"P",{});var qa=n(Y);$r=l(qa,"This page lists all the utility functions used by "),Me=s(qa,"A",{href:!0});var al=n(Me);yr=l(al,"Trainer"),al.forEach(t),Er=l(qa,"."),qa.forEach(t),ja=c(a),Re=s(a,"P",{});var rl=n(Re);Dr=l(rl,"Most of those are only useful if you are studying the code of the Trainer in the library."),rl.forEach(t),Oa=c(a),L=s(a,"H2",{class:!0});var Ba=n(L);W=s(Ba,"A",{id:!0,class:!0,href:!0});var sl=n(W);ot=s(sl,"SPAN",{});var nl=n(ot);_(oe.$$.fragment,nl),nl.forEach(t),sl.forEach(t),Pr=c(Ba),lt=s(Ba,"SPAN",{});var ol=n(lt);kr=l(ol,"Utilities"),ol.forEach(t),Ba.forEach(t),Aa=c(a),I=s(a,"DIV",{class:!0});var Ka=n(I);_(le.$$.fragment,Ka),Tr=c(Ka),it=s(Ka,"P",{});var ll=n(it);xr=l(ll,"Evaluation output (always contains labels), to be used to compute metrics."),ll.forEach(t),Ka.forEach(t),Ca=c(a),U=s(a,"DIV",{class:!0});var Ya=n(U);_(ie.$$.fragment,Ya),jr=c(Ya),ct=s(Ya,"P",{});var il=n(ct);Or=l(il,"An enumeration."),il.forEach(t),Ya.forEach(t),La=c(a),z=s(a,"DIV",{class:!0});var Wa=n(z);_(ce.$$.fragment,Wa),Ar=c(Wa),D=s(Wa,"P",{});var C=n(D);Cr=l(C,"Helper function for reproducible behavior to set the seed in "),dt=s(C,"CODE",{});var cl=n(dt);Lr=l(cl,"random"),cl.forEach(t),Ir=l(C,", "),ht=s(C,"CODE",{});var dl=n(ht);Ur=l(dl,"numpy"),dl.forEach(t),zr=l(C,", "),pt=s(C,"CODE",{});var hl=n(pt);Sr=l(hl,"torch"),hl.forEach(t),Hr=l(C," and/or "),ft=s(C,"CODE",{});var pl=n(ft);Nr=l(pl,"tf"),pl.forEach(t),Gr=l(C,` (if
installed).`),C.forEach(t),Wa.forEach(t),Ia=c(a),S=s(a,"DIV",{class:!0});var Ja=n(S);_(de.$$.fragment,Ja),Vr=c(Ja),ut=s(Ja,"P",{});var fl=n(ut);Mr=l(fl,"Decorator to make all processes in distributed training wait for each local_master to do something."),fl.forEach(t),Ja.forEach(t),Ua=c(a),H=s(a,"H2",{class:!0});var Qa=n(H);J=s(Qa,"A",{id:!0,class:!0,href:!0});var ul=n(J);mt=s(ul,"SPAN",{});var ml=n(mt);_(he.$$.fragment,ml),ml.forEach(t),ul.forEach(t),Rr=c(Qa),gt=s(Qa,"SPAN",{});var gl=n(gt);Fr=l(gl,"Callbacks internals"),gl.forEach(t),Qa.forEach(t),za=c(a),N=s(a,"DIV",{class:!0});var Xa=n(N);_(pe.$$.fragment,Xa),qr=c(Xa),vt=s(Xa,"P",{});var vl=n(vt);Br=l(vl,"Internal class that just calls the list of callbacks in order."),vl.forEach(t),Xa.forEach(t),Sa=c(a),G=s(a,"H2",{class:!0});var Za=n(G);Q=s(Za,"A",{id:!0,class:!0,href:!0});var _l=n(Q);_t=s(_l,"SPAN",{});var bl=n(_t);_(fe.$$.fragment,bl),bl.forEach(t),_l.forEach(t),Kr=c(Za),bt=s(Za,"SPAN",{});var wl=n(bt);Yr=l(wl,"Distributed Evaluation"),wl.forEach(t),Za.forEach(t),Ha=c(a),f=s(a,"DIV",{class:!0});var g=n(f);_(ue.$$.fragment,g),Wr=c(g),wt=s(g,"P",{});var $l=n(wt);Jr=l($l,"A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),$l.forEach(t),Qr=c(g),$t=s(g,"P",{});var yl=n($t);Xr=l(yl,`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),yl.forEach(t),Zr=c(g),yt=s(g,"P",{});var El=n(yt);Et=s(El,"CODE",{});var Dl=n(Et);es=l(Dl,"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),Dl.forEach(t),El.forEach(t),ts=c(g),Dt=s(g,"P",{});var Pl=n(Dt);as=l(Pl,`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),Pl.forEach(t),rs=c(g),V=s(g,"UL",{});var Qe=n(V);Fe=s(Qe,"LI",{});var Bo=n(Fe);ss=l(Bo,"P0: "),Pt=s(Bo,"CODE",{});var kl=n(Pt);ns=l(kl,"[0, 1, 2, 3, 4, 5]"),kl.forEach(t),Bo.forEach(t),os=c(Qe),qe=s(Qe,"LI",{});var Ko=n(qe);ls=l(Ko,"P1: "),kt=s(Ko,"CODE",{});var Tl=n(kt);is=l(Tl,"[6, 7, 8, 9, 10, 11]"),Tl.forEach(t),Ko.forEach(t),cs=c(Qe),Be=s(Qe,"LI",{});var Yo=n(Be);ds=l(Yo,"P2: "),Tt=s(Yo,"CODE",{});var xl=n(Tt);hs=l(xl,"[12, 13, 14, 15, 0, 1]"),xl.forEach(t),Yo.forEach(t),Qe.forEach(t),ps=c(g),xt=s(g,"P",{});var jl=n(xt);fs=l(jl,"The first batch treated on each process will be"),jl.forEach(t),us=c(g),M=s(g,"UL",{});var Xe=n(M);Ke=s(Xe,"LI",{});var Wo=n(Ke);ms=l(Wo,"P0: "),jt=s(Wo,"CODE",{});var Ol=n(jt);gs=l(Ol,"[0, 1]"),Ol.forEach(t),Wo.forEach(t),vs=c(Xe),Ye=s(Xe,"LI",{});var Jo=n(Ye);_s=l(Jo,"P1: "),Ot=s(Jo,"CODE",{});var Al=n(Ot);bs=l(Al,"[6, 7]"),Al.forEach(t),Jo.forEach(t),ws=c(Xe),We=s(Xe,"LI",{});var Qo=n(We);$s=l(Qo,"P2: "),At=s(Qo,"CODE",{});var Cl=n(At);ys=l(Cl,"[12, 13]"),Cl.forEach(t),Qo.forEach(t),Xe.forEach(t),Es=c(g),Ct=s(g,"P",{});var Ll=n(Ct);Ds=l(Ll,`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),Ll.forEach(t),Ps=c(g),Lt=s(g,"P",{});var Il=n(Lt);It=s(Il,"CODE",{});var Ul=n(It);ks=l(Ul,"[0, 1, 6, 7, 12, 13]"),Ul.forEach(t),Il.forEach(t),Ts=c(g),Ut=s(g,"P",{});var zl=n(Ut);xs=l(zl,`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),zl.forEach(t),js=c(g),zt=s(g,"P",{});var Sl=n(zt);St=s(Sl,"CODE",{});var Hl=n(St);Os=l(Hl,"[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),Hl.forEach(t),Sl.forEach(t),As=c(g),Ht=s(g,"P",{});var Nl=n(Ht);Cs=l(Nl,"For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),Nl.forEach(t),Ls=c(g),X=s(g,"DIV",{class:!0});var er=n(X);_(me.$$.fragment,er),Is=c(er),ge=s(er,"P",{});var tr=n(ge);Us=l(tr,"Add "),Nt=s(tr,"CODE",{});var Gl=n(Nt);zs=l(Gl,"arrays"),Gl.forEach(t),Ss=l(tr,` to the internal storage, Will initialize the storage to the full size at the first arrays
passed so that if we\u2019re bound to get an OOM, it happens at the beginning.`),tr.forEach(t),er.forEach(t),Hs=c(g),Z=s(g,"DIV",{class:!0});var ar=n(Z);_(ve.$$.fragment,ar),Ns=c(ar),Gt=s(ar,"P",{});var Vl=n(Gt);Gs=l(Vl,`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),Vl.forEach(t),ar.forEach(t),g.forEach(t),Na=c(a),R=s(a,"H2",{class:!0});var rr=n(R);ee=s(rr,"A",{id:!0,class:!0,href:!0});var Ml=n(ee);Vt=s(Ml,"SPAN",{});var Rl=n(Vt);_(_e.$$.fragment,Rl),Rl.forEach(t),Ml.forEach(t),Vs=c(rr),Mt=s(rr,"SPAN",{});var Fl=n(Mt);Ms=l(Fl,"Distributed Evaluation"),Fl.forEach(t),rr.forEach(t),Ga=c(a),E=s(a,"DIV",{class:!0});var T=n(E);_(be.$$.fragment,T),Rs=c(T),we=s(T,"P",{});var sr=n(we);Fs=l(sr,"This subclass of "),Rt=s(sr,"CODE",{});var ql=n(Rt);qs=l(ql,"argparse.ArgumentParser"),ql.forEach(t),Bs=l(sr," uses type hints on dataclasses to generate arguments."),sr.forEach(t),Ks=c(T),$e=s(T,"P",{});var nr=n($e);Ys=l(nr,`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),Ft=s(nr,"CODE",{});var Bl=n(Ft);Ws=l(Bl,"_argument_group_name"),Bl.forEach(t),Js=l(nr," attribute in the dataclass."),nr.forEach(t),Qs=c(T),A=s(T,"DIV",{class:!0});var Ze=n(A);_(ye.$$.fragment,Ze),Xs=c(Ze),qt=s(Ze,"P",{});var Kl=n(qt);Zs=l(Kl,"Parse command-line args into instances of the specified dataclass types."),Kl.forEach(t),en=c(Ze),Ee=s(Ze,"P",{});var or=n(Ee);tn=l(or,"This relies on argparse\u2019s "),Bt=s(or,"CODE",{});var Yl=n(Bt);an=l(Yl,"ArgumentParser.parse_known_args"),Yl.forEach(t),rn=l(or,`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),or.forEach(t),Ze.forEach(t),sn=c(T),te=s(T,"DIV",{class:!0});var lr=n(te);_(De.$$.fragment,lr),nn=c(lr),Pe=s(lr,"P",{});var ir=n(Pe);on=l(ir,"Alternative helper method that does not use "),Kt=s(ir,"CODE",{});var Wl=n(Kt);ln=l(Wl,"argparse"),Wl.forEach(t),cn=l(ir,` at all, instead uses a dict and populating the dataclass
types.`),ir.forEach(t),lr.forEach(t),dn=c(T),ae=s(T,"DIV",{class:!0});var cr=n(ae);_(ke.$$.fragment,cr),hn=c(cr),Te=s(cr,"P",{});var dr=n(Te);pn=l(dr,"Alternative helper method that does not use "),Yt=s(dr,"CODE",{});var Jl=n(Yt);fn=l(Jl,"argparse"),Jl.forEach(t),un=l(dr,` at all, instead loading a json file and populating the
dataclass types.`),dr.forEach(t),cr.forEach(t),T.forEach(t),Va=c(a),F=s(a,"H2",{class:!0});var hr=n(F);re=s(hr,"A",{id:!0,class:!0,href:!0});var Ql=n(re);Wt=s(Ql,"SPAN",{});var Xl=n(Wt);_(xe.$$.fragment,Xl),Xl.forEach(t),Ql.forEach(t),mn=c(hr),Jt=s(hr,"SPAN",{});var Zl=n(Jt);gn=l(Zl,"Debug Utilities"),Zl.forEach(t),hr.forEach(t),Ma=c(a),d=s(a,"DIV",{class:!0});var h=n(d);_(je.$$.fragment,h),vn=c(h),q=s(h,"P",{});var et=n(q);_n=l(et,`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),Qt=s(et,"CODE",{});var ei=n(Qt);bn=l(ei,"nan"),ei.forEach(t),wn=l(et," or "),Xt=s(et,"CODE",{});var ti=n(Xt);$n=l(ti,"inf"),ti.forEach(t),yn=l(et," weight and activation elements."),et.forEach(t),En=c(h),Zt=s(h,"P",{});var ai=n(Zt);Dn=l(ai,"There are 2 working modes:"),ai.forEach(t),Pn=c(h),Oe=s(h,"OL",{});var pr=n(Oe);ea=s(pr,"LI",{});var ri=n(ea);kn=l(ri,"Underflow/overflow detection (default)"),ri.forEach(t),Tn=c(pr),ta=s(pr,"LI",{});var si=n(ta);xn=l(si,"Specific batch absolute min/max tracing without detection"),si.forEach(t),pr.forEach(t),jn=c(h),aa=s(h,"P",{});var ni=n(aa);On=l(ni,"Mode 1: Underflow/overflow detection"),ni.forEach(t),An=c(h),ra=s(h,"P",{});var oi=n(ra);Cn=l(oi,"To activate the underflow/overflow detection, initialize the object with the model :"),oi.forEach(t),Ln=c(h),_(Ae.$$.fragment,h),In=c(h),j=s(h,"P",{});var se=n(j);Un=l(se,"then run the training as normal and if "),sa=s(se,"CODE",{});var li=n(sa);zn=l(li,"nan"),li.forEach(t),Sn=l(se," or "),na=s(se,"CODE",{});var ii=n(na);Hn=l(ii,"inf"),ii.forEach(t),Nn=l(se,` gets detected in at least one of the weight, input or
output elements this module will throw an exception and will print `),oa=s(se,"CODE",{});var ci=n(oa);Gn=l(ci,"max_frames_to_save"),ci.forEach(t),Vn=l(se,` frames that lead to this
event, each frame reporting`),se.forEach(t),Mn=c(h),Ce=s(h,"OL",{});var fr=n(Ce);Le=s(fr,"LI",{});var ur=n(Le);Rn=l(ur,"the fully qualified module name plus the class name whose "),la=s(ur,"CODE",{});var di=n(la);Fn=l(di,"forward"),di.forEach(t),qn=l(ur," was run"),ur.forEach(t),Bn=c(fr),ia=s(fr,"LI",{});var hi=n(ia);Kn=l(hi,"the absolute min and max value of all elements for each module weights, and the inputs and output"),hi.forEach(t),fr.forEach(t),Yn=c(h),Ie=s(h,"P",{});var mr=n(Ie);Wn=l(mr,"For example, here is the header and the last few frames in detection report for "),ca=s(mr,"CODE",{});var pi=n(ca);Jn=l(pi,"google/mt5-small"),pi.forEach(t),Qn=l(mr," run in fp16 mixed precision :"),mr.forEach(t),Xn=c(h),_(Ue.$$.fragment,h),Zn=c(h),B=s(h,"P",{});var tt=n(B);eo=l(tt,"You can see here, that "),da=s(tt,"CODE",{});var fi=n(da);to=l(fi,"T5DenseGatedGeluDense.forward"),fi.forEach(t),ao=l(tt,` resulted in output activations, whose absolute max value
was around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),ha=s(tt,"CODE",{});var ui=n(ha);ro=l(ui,"Dropout"),ui.forEach(t),so=l(tt,` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),tt.forEach(t),no=c(h),pa=s(h,"P",{});var mi=n(pa);oo=l(mi,`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),mi.forEach(t),lo=c(h),ze=s(h,"P",{});var gr=n(ze);io=l(gr,"The tracking is done in a forward hook, which gets invoked immediately after "),fa=s(gr,"CODE",{});var gi=n(fa);co=l(gi,"forward"),gi.forEach(t),ho=l(gr," has completed."),gr.forEach(t),po=c(h),ua=s(h,"P",{});var vi=n(ua);fo=l(vi,"By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),vi.forEach(t),uo=c(h),_(Se.$$.fragment,h),mo=c(h),ma=s(h,"P",{});var _i=n(ma);go=l(_i,`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that may
take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in the next
section.`),_i.forEach(t),vo=c(h),ga=s(h,"P",{});var bi=n(ga);_o=l(bi,"Mode 2. Specific batch absolute min/max tracing without detection"),bi.forEach(t),bo=c(h),va=s(h,"P",{});var wi=n(va);wo=l(wi,"The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),wi.forEach(t),$o=c(h),He=s(h,"P",{});var vr=n(He);yo=l(vr,"Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),_a=s(vr,"CODE",{});var $i=n(_a);Eo=l($i,"forward"),$i.forEach(t),Do=l(vr,` call of a
given batch, and only do that for batches 1 and 3. Then you instantiate this class as :`),vr.forEach(t),Po=c(h),_(Ne.$$.fragment,h),ko=c(h),ba=s(h,"P",{});var yi=n(ba);To=l(yi,"And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),yi.forEach(t),xo=c(h),wa=s(h,"P",{});var Ei=n(wa);jo=l(Ei,`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),Ei.forEach(t),Oo=c(h),$a=s(h,"P",{});var Di=n($a);Ao=l(Di,"Early stopping:"),Di.forEach(t),Co=c(h),ya=s(h,"P",{});var Pi=n(ya);Lo=l(Pi,"You can also specify the batch number after which to stop the training, with :"),Pi.forEach(t),Io=c(h),_(Ge.$$.fragment,h),Uo=c(h),Ea=s(h,"P",{});var ki=n(Ea);zo=l(ki,"This feature is mainly useful in the tracing mode, but you can use it for any mode."),ki.forEach(t),So=c(h),Je=s(h,"P",{});var Xo=n(Je);Da=s(Xo,"STRONG",{});var Ti=n(Da);Ho=l(Ti,"Performance"),Ti.forEach(t),No=l(Xo,":"),Xo.forEach(t),Go=c(h),K=s(h,"P",{});var at=n(K);Vo=l(at,"As this module measures absolute "),Pa=s(at,"CODE",{});var xi=n(Pa);Mo=l(xi,"min"),xi.forEach(t),Ro=l(at,"/`"),ka=s(at,"CODE",{});var ji=n(ka);Fo=l(ji,"max"),ji.forEach(t),qo=l(at,` of each weight of the model on every forward it\u2019ll slow the
training down. Therefore remember to turn it off once the debugging needs have been met.`),at.forEach(t),h.forEach(t),this.h()},h(){p(O,"name","hf:doc:metadata"),p(O,"content",JSON.stringify(zi)),p(x,"id","utilities-for-trainer"),p(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(x,"href","#utilities-for-trainer"),p(k,"class","relative group"),p(Me,"href","/docs/transformers/v4.14.1/en/main_classes/trainer#transformers.Trainer"),p(W,"id","transformers.EvalPrediction"),p(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(W,"href","#transformers.EvalPrediction"),p(L,"class","relative group"),p(I,"class","docstring"),p(U,"class","docstring"),p(z,"class","docstring"),p(S,"class","docstring"),p(J,"id","transformers.trainer_callback.CallbackHandler"),p(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(J,"href","#transformers.trainer_callback.CallbackHandler"),p(H,"class","relative group"),p(N,"class","docstring"),p(Q,"id","transformers.trainer_pt_utils.DistributedTensorGatherer"),p(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Q,"href","#transformers.trainer_pt_utils.DistributedTensorGatherer"),p(G,"class","relative group"),p(X,"class","docstring"),p(Z,"class","docstring"),p(f,"class","docstring"),p(ee,"id","transformers.HfArgumentParser"),p(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ee,"href","#transformers.HfArgumentParser"),p(R,"class","relative group"),p(A,"class","docstring"),p(te,"class","docstring"),p(ae,"class","docstring"),p(E,"class","docstring"),p(re,"id","transformers.debug_utils.DebugUnderflowOverflow"),p(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(re,"href","#transformers.debug_utils.DebugUnderflowOverflow"),p(F,"class","relative group"),p(d,"class","docstring")},m(a,u){e(document.head,O),m(a,Ve,u),m(a,k,u),e(k,x),e(x,st),b(ne,st,null),e(k,br),e(k,nt),e(nt,wr),m(a,xa,u),m(a,Y,u),e(Y,$r),e(Y,Me),e(Me,yr),e(Y,Er),m(a,ja,u),m(a,Re,u),e(Re,Dr),m(a,Oa,u),m(a,L,u),e(L,W),e(W,ot),b(oe,ot,null),e(L,Pr),e(L,lt),e(lt,kr),m(a,Aa,u),m(a,I,u),b(le,I,null),e(I,Tr),e(I,it),e(it,xr),m(a,Ca,u),m(a,U,u),b(ie,U,null),e(U,jr),e(U,ct),e(ct,Or),m(a,La,u),m(a,z,u),b(ce,z,null),e(z,Ar),e(z,D),e(D,Cr),e(D,dt),e(dt,Lr),e(D,Ir),e(D,ht),e(ht,Ur),e(D,zr),e(D,pt),e(pt,Sr),e(D,Hr),e(D,ft),e(ft,Nr),e(D,Gr),m(a,Ia,u),m(a,S,u),b(de,S,null),e(S,Vr),e(S,ut),e(ut,Mr),m(a,Ua,u),m(a,H,u),e(H,J),e(J,mt),b(he,mt,null),e(H,Rr),e(H,gt),e(gt,Fr),m(a,za,u),m(a,N,u),b(pe,N,null),e(N,qr),e(N,vt),e(vt,Br),m(a,Sa,u),m(a,G,u),e(G,Q),e(Q,_t),b(fe,_t,null),e(G,Kr),e(G,bt),e(bt,Yr),m(a,Ha,u),m(a,f,u),b(ue,f,null),e(f,Wr),e(f,wt),e(wt,Jr),e(f,Qr),e(f,$t),e($t,Xr),e(f,Zr),e(f,yt),e(yt,Et),e(Et,es),e(f,ts),e(f,Dt),e(Dt,as),e(f,rs),e(f,V),e(V,Fe),e(Fe,ss),e(Fe,Pt),e(Pt,ns),e(V,os),e(V,qe),e(qe,ls),e(qe,kt),e(kt,is),e(V,cs),e(V,Be),e(Be,ds),e(Be,Tt),e(Tt,hs),e(f,ps),e(f,xt),e(xt,fs),e(f,us),e(f,M),e(M,Ke),e(Ke,ms),e(Ke,jt),e(jt,gs),e(M,vs),e(M,Ye),e(Ye,_s),e(Ye,Ot),e(Ot,bs),e(M,ws),e(M,We),e(We,$s),e(We,At),e(At,ys),e(f,Es),e(f,Ct),e(Ct,Ds),e(f,Ps),e(f,Lt),e(Lt,It),e(It,ks),e(f,Ts),e(f,Ut),e(Ut,xs),e(f,js),e(f,zt),e(zt,St),e(St,Os),e(f,As),e(f,Ht),e(Ht,Cs),e(f,Ls),e(f,X),b(me,X,null),e(X,Is),e(X,ge),e(ge,Us),e(ge,Nt),e(Nt,zs),e(ge,Ss),e(f,Hs),e(f,Z),b(ve,Z,null),e(Z,Ns),e(Z,Gt),e(Gt,Gs),m(a,Na,u),m(a,R,u),e(R,ee),e(ee,Vt),b(_e,Vt,null),e(R,Vs),e(R,Mt),e(Mt,Ms),m(a,Ga,u),m(a,E,u),b(be,E,null),e(E,Rs),e(E,we),e(we,Fs),e(we,Rt),e(Rt,qs),e(we,Bs),e(E,Ks),e(E,$e),e($e,Ys),e($e,Ft),e(Ft,Ws),e($e,Js),e(E,Qs),e(E,A),b(ye,A,null),e(A,Xs),e(A,qt),e(qt,Zs),e(A,en),e(A,Ee),e(Ee,tn),e(Ee,Bt),e(Bt,an),e(Ee,rn),e(E,sn),e(E,te),b(De,te,null),e(te,nn),e(te,Pe),e(Pe,on),e(Pe,Kt),e(Kt,ln),e(Pe,cn),e(E,dn),e(E,ae),b(ke,ae,null),e(ae,hn),e(ae,Te),e(Te,pn),e(Te,Yt),e(Yt,fn),e(Te,un),m(a,Va,u),m(a,F,u),e(F,re),e(re,Wt),b(xe,Wt,null),e(F,mn),e(F,Jt),e(Jt,gn),m(a,Ma,u),m(a,d,u),b(je,d,null),e(d,vn),e(d,q),e(q,_n),e(q,Qt),e(Qt,bn),e(q,wn),e(q,Xt),e(Xt,$n),e(q,yn),e(d,En),e(d,Zt),e(Zt,Dn),e(d,Pn),e(d,Oe),e(Oe,ea),e(ea,kn),e(Oe,Tn),e(Oe,ta),e(ta,xn),e(d,jn),e(d,aa),e(aa,On),e(d,An),e(d,ra),e(ra,Cn),e(d,Ln),b(Ae,d,null),e(d,In),e(d,j),e(j,Un),e(j,sa),e(sa,zn),e(j,Sn),e(j,na),e(na,Hn),e(j,Nn),e(j,oa),e(oa,Gn),e(j,Vn),e(d,Mn),e(d,Ce),e(Ce,Le),e(Le,Rn),e(Le,la),e(la,Fn),e(Le,qn),e(Ce,Bn),e(Ce,ia),e(ia,Kn),e(d,Yn),e(d,Ie),e(Ie,Wn),e(Ie,ca),e(ca,Jn),e(Ie,Qn),e(d,Xn),b(Ue,d,null),e(d,Zn),e(d,B),e(B,eo),e(B,da),e(da,to),e(B,ao),e(B,ha),e(ha,ro),e(B,so),e(d,no),e(d,pa),e(pa,oo),e(d,lo),e(d,ze),e(ze,io),e(ze,fa),e(fa,co),e(ze,ho),e(d,po),e(d,ua),e(ua,fo),e(d,uo),b(Se,d,null),e(d,mo),e(d,ma),e(ma,go),e(d,vo),e(d,ga),e(ga,_o),e(d,bo),e(d,va),e(va,wo),e(d,$o),e(d,He),e(He,yo),e(He,_a),e(_a,Eo),e(He,Do),e(d,Po),b(Ne,d,null),e(d,ko),e(d,ba),e(ba,To),e(d,xo),e(d,wa),e(wa,jo),e(d,Oo),e(d,$a),e($a,Ao),e(d,Co),e(d,ya),e(ya,Lo),e(d,Io),b(Ge,d,null),e(d,Uo),e(d,Ea),e(Ea,zo),e(d,So),e(d,Je),e(Je,Da),e(Da,Ho),e(Je,No),e(d,Go),e(d,K),e(K,Vo),e(K,Pa),e(Pa,Mo),e(K,Ro),e(K,ka),e(ka,Fo),e(K,qo),Ra=!0},p:Ii,i(a){Ra||(w(ne.$$.fragment,a),w(oe.$$.fragment,a),w(le.$$.fragment,a),w(ie.$$.fragment,a),w(ce.$$.fragment,a),w(de.$$.fragment,a),w(he.$$.fragment,a),w(pe.$$.fragment,a),w(fe.$$.fragment,a),w(ue.$$.fragment,a),w(me.$$.fragment,a),w(ve.$$.fragment,a),w(_e.$$.fragment,a),w(be.$$.fragment,a),w(ye.$$.fragment,a),w(De.$$.fragment,a),w(ke.$$.fragment,a),w(xe.$$.fragment,a),w(je.$$.fragment,a),w(Ae.$$.fragment,a),w(Ue.$$.fragment,a),w(Se.$$.fragment,a),w(Ne.$$.fragment,a),w(Ge.$$.fragment,a),Ra=!0)},o(a){$(ne.$$.fragment,a),$(oe.$$.fragment,a),$(le.$$.fragment,a),$(ie.$$.fragment,a),$(ce.$$.fragment,a),$(de.$$.fragment,a),$(he.$$.fragment,a),$(pe.$$.fragment,a),$(fe.$$.fragment,a),$(ue.$$.fragment,a),$(me.$$.fragment,a),$(ve.$$.fragment,a),$(_e.$$.fragment,a),$(be.$$.fragment,a),$(ye.$$.fragment,a),$(De.$$.fragment,a),$(ke.$$.fragment,a),$(xe.$$.fragment,a),$(je.$$.fragment,a),$(Ae.$$.fragment,a),$(Ue.$$.fragment,a),$(Se.$$.fragment,a),$(Ne.$$.fragment,a),$(Ge.$$.fragment,a),Ra=!1},d(a){t(O),a&&t(Ve),a&&t(k),y(ne),a&&t(xa),a&&t(Y),a&&t(ja),a&&t(Re),a&&t(Oa),a&&t(L),y(oe),a&&t(Aa),a&&t(I),y(le),a&&t(Ca),a&&t(U),y(ie),a&&t(La),a&&t(z),y(ce),a&&t(Ia),a&&t(S),y(de),a&&t(Ua),a&&t(H),y(he),a&&t(za),a&&t(N),y(pe),a&&t(Sa),a&&t(G),y(fe),a&&t(Ha),a&&t(f),y(ue),y(me),y(ve),a&&t(Na),a&&t(R),y(_e),a&&t(Ga),a&&t(E),y(be),y(ye),y(De),y(ke),a&&t(Va),a&&t(F),y(xe),a&&t(Ma),a&&t(d),y(je),y(Ae),y(Ue),y(Se),y(Ne),y(Ge)}}}const zi={local:"utilities-for-trainer",sections:[{local:"transformers.EvalPrediction",title:"Utilities"},{local:"transformers.trainer_callback.CallbackHandler",title:"Callbacks internals"},{local:"transformers.trainer_pt_utils.DistributedTensorGatherer",title:"Distributed Evaluation"},{local:"transformers.HfArgumentParser",title:"Distributed Evaluation"},{local:"transformers.debug_utils.DebugUnderflowOverflow",title:"Debug Utilities"}],title:"Utilities for Trainer"};function Si(_r,O,Ve){let{fw:k}=O;return _r.$$set=x=>{"fw"in x&&Ve(0,k=x.fw)},[k]}class Ri extends Oi{constructor(O){super();Ai(this,O,Si,Ui,Ci,{fw:0})}}export{Ri as default,zi as metadata};
