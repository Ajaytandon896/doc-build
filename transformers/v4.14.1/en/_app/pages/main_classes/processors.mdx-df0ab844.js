import{S as Li,i as Di,s as ki,e as a,k as i,w as m,t as l,M as Ni,c as r,d as s,m as p,a as o,x as u,h as n,b as c,F as t,g as h,y as d,L as Ti,q as v,o as _,B as g}from"../../chunks/vendor-ab4e3193.js";import{D as P}from"../../chunks/Docstring-b69c0bd4.js";import{C as Gl}from"../../chunks/CodeBlock-516df0c5.js";import{I as ve}from"../../chunks/IconCopyLink-d992940d.js";import"../../chunks/CopyButton-204b56db.js";function ji(Ka){let k,nt,q,I,Lt,_e,Ya,Dt,Za,Ts,it,er,js,j,F,kt,ge,tr,Nt,sr,Vs,y,ar,pt,rr,or,ft,lr,nr,ct,ir,pr,ht,fr,cr,Cs,$,Ee,hr,Tt,mr,ur,R,$e,dr,we,vr,mt,_r,gr,Er,X,xe,$r,jt,wr,xr,z,be,br,Vt,Pr,yr,H,Pe,qr,ye,Sr,ut,Ir,Ar,Lr,B,qe,Dr,Se,kr,dt,Nr,Tr,jr,J,Ie,Vr,Ct,Cr,Qs,A,Ae,Qr,Qt,Or,Mr,W,Le,Gr,Ot,Ur,Os,L,De,Fr,Mt,Rr,Xr,K,ke,zr,Gt,Hr,Ms,V,Y,Ut,Ne,Br,Ft,Jr,Gs,Z,Te,Wr,Kr,je,Yr,Us,vt,Zr,Fs,_t,eo,Rs,E,Rt,Xt,to,so,zt,Ht,ao,ro,Bt,Jt,oo,lo,Wt,Kt,no,io,Yt,Zt,po,fo,es,ts,co,ho,ss,as,mo,uo,rs,os,vo,_o,ls,ns,go,Xs,ee,Eo,gt,$o,wo,zs,Et,xo,Hs,C,te,is,Ve,bo,ps,Po,Bs,se,yo,Ce,qo,So,Js,Q,ae,fs,Qe,Io,cs,Ao,Ws,O,Oe,Lo,Do,$t,ko,Me,No,To,Ks,Ge,jo,Ue,Vo,Ys,wt,Co,Zs,xt,hs,ms,Qo,ea,bt,Oo,ta,re,Mo,Fe,Go,Uo,sa,M,oe,us,Re,Fo,ds,Ro,aa,D,Xe,Xo,zo,ze,Ho,Bo,He,Jo,Wo,ra,Pt,Ko,oa,G,le,vs,Be,Yo,_s,Zo,la,yt,el,na,ne,gs,Es,tl,sl,$s,ws,al,ia,Je,rl,xs,ol,pa,b,We,ll,bs,nl,il,ie,Ke,pl,Ps,fl,cl,S,Ye,hl,Ze,ml,ys,ul,dl,vl,qs,_l,gl,et,El,pe,tt,$l,Ss,wl,fa,fe,xl,Is,bl,Pl,ca,qt,yl,ha,ce,ql,As,Sl,Il,ma,U,he,Ls,st,Al,Ds,Ll,ua,St,Dl,da,at,va,me,kl,ks,Nl,Tl,_a,rt,ga,ue,jl,ot,Vl,Cl,Ea;return _e=new ve({}),ge=new ve({}),Ee=new P({props:{name:"class transformers.DataProcessor",anchor:"transformers.DataProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L81"}}),$e=new P({props:{name:"get_dev_examples",anchor:"transformers.DataProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L98"}}),xe=new P({props:{name:"get_example_from_tensor_dict",anchor:"transformers.DataProcessor.get_example_from_tensor_dict",parameters:[{name:"tensor_dict",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L84"}}),be=new P({props:{name:"get_labels",anchor:"transformers.DataProcessor.get_labels",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L106"}}),Pe=new P({props:{name:"get_test_examples",anchor:"transformers.DataProcessor.get_test_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L102"}}),qe=new P({props:{name:"get_train_examples",anchor:"transformers.DataProcessor.get_train_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L94"}}),Ie=new P({props:{name:"tfds_map",anchor:"transformers.DataProcessor.tfds_map",parameters:[{name:"example",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L110"}}),Ae=new P({props:{name:"class transformers.InputExample",anchor:"transformers.InputExample",parameters:[{name:"guid",val:": str"},{name:"text_a",val:": str"},{name:"text_b",val:": typing.Optional[str] = None"},{name:"label",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L31"}}),Le=new P({props:{name:"to_json_string",anchor:"transformers.InputExample.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L50"}}),De=new P({props:{name:"class transformers.InputFeatures",anchor:"transformers.InputFeatures",parameters:[{name:"input_ids",val:": typing.List[int]"},{name:"attention_mask",val:": typing.Optional[typing.List[int]] = None"},{name:"token_type_ids",val:": typing.Optional[typing.List[int]] = None"},{name:"label",val:": typing.Union[int, float, NoneType] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L56"}}),ke=new P({props:{name:"to_json_string",anchor:"transformers.InputFeatures.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/utils.py#L76"}}),Ne=new ve({}),Ve=new ve({}),Qe=new ve({}),Re=new ve({}),Be=new ve({}),We=new P({props:{name:"class transformers.data.processors.squad.SquadProcessor",anchor:"transformers.data.processors.squad.SquadProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/squad.py#L542"}}),Ke=new P({props:{name:"get_dev_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/squad.py#L628"}}),Ye=new P({props:{name:"get_examples_from_dataset",anchor:"transformers.data.processors.squad.SquadProcessor.get_examples_from_dataset",parameters:[{name:"dataset",val:""},{name:"evaluate",val:" = False"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/squad.py#L575",returnDescription:`
<p>List of SquadExample</p>
`}}),et=new Gl({props:{code:`import tensorflow_datasets as tfds
dataset = tfds.load("squad")

training_examples = get_examples_from_dataset(dataset, evaluate=False)
evaluation_examples = get_examples_from_dataset(dataset, evaluate=True),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>training_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">True</span>)`}}),tt=new P({props:{name:"get_train_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_train_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.14.1/src/transformers/data/processors/squad.py#L606"}}),st=new ve({}),at=new Gl({props:{code:`# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features( 
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># Loading a V2 processor</span>
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

<span class="hljs-comment"># Loading a V1 processor</span>
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features( 
    <span class="hljs-attribute">examples</span>=examples,
    <span class="hljs-attribute">tokenizer</span>=tokenizer,
    <span class="hljs-attribute">max_seq_length</span>=max_seq_length,
    <span class="hljs-attribute">doc_stride</span>=args.doc_stride,
    <span class="hljs-attribute">max_query_length</span>=max_query_length,
    <span class="hljs-attribute">is_training</span>=not evaluate,
)`}}),rt=new Gl({props:{code:`# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features( 
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># tensorflow_datasets only handle Squad V1.</span>
tfds_examples = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, <span class="hljs-attribute">evaluate</span>=evaluate)

features = squad_convert_examples_to_features( 
    <span class="hljs-attribute">examples</span>=examples,
    <span class="hljs-attribute">tokenizer</span>=tokenizer,
    <span class="hljs-attribute">max_seq_length</span>=max_seq_length,
    <span class="hljs-attribute">doc_stride</span>=args.doc_stride,
    <span class="hljs-attribute">max_query_length</span>=max_query_length,
    <span class="hljs-attribute">is_training</span>=not evaluate,
)`}}),{c(){k=a("meta"),nt=i(),q=a("h1"),I=a("a"),Lt=a("span"),m(_e.$$.fragment),Ya=i(),Dt=a("span"),Za=l("Processors"),Ts=i(),it=a("p"),er=l(`This library includes processors for several traditional tasks. These processors can be used to process a dataset into
examples that can be fed to a model.`),js=i(),j=a("h2"),F=a("a"),kt=a("span"),m(ge.$$.fragment),tr=i(),Nt=a("span"),sr=l("Processors"),Vs=i(),y=a("p"),ar=l(`All processors follow the same architecture which is that of the
`),pt=a("a"),rr=l("DataProcessor"),or=l(`. The processor returns a list of
`),ft=a("a"),lr=l("InputExample"),nr=l(`. These
`),ct=a("a"),ir=l("InputExample"),pr=l(` can be converted to
`),ht=a("a"),fr=l("InputFeatures"),cr=l(" in order to be fed to the model."),Cs=i(),$=a("div"),m(Ee.$$.fragment),hr=i(),Tt=a("p"),mr=l("Base class for data converters for sequence classification data sets."),ur=i(),R=a("div"),m($e.$$.fragment),dr=i(),we=a("p"),vr=l("Gets a collection of "),mt=a("a"),_r=l("InputExample"),gr=l(" for the dev set."),Er=i(),X=a("div"),m(xe.$$.fragment),$r=i(),jt=a("p"),wr=l("Gets an example from a dict with tensorflow tensors."),xr=i(),z=a("div"),m(be.$$.fragment),br=i(),Vt=a("p"),Pr=l("Gets the list of labels for this data set."),yr=i(),H=a("div"),m(Pe.$$.fragment),qr=i(),ye=a("p"),Sr=l("Gets a collection of "),ut=a("a"),Ir=l("InputExample"),Ar=l(" for the test set."),Lr=i(),B=a("div"),m(qe.$$.fragment),Dr=i(),Se=a("p"),kr=l("Gets a collection of "),dt=a("a"),Nr=l("InputExample"),Tr=l(" for the train set."),jr=i(),J=a("div"),m(Ie.$$.fragment),Vr=i(),Ct=a("p"),Cr=l(`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),Qs=i(),A=a("div"),m(Ae.$$.fragment),Qr=i(),Qt=a("p"),Or=l("A single training/test example for simple sequence classification."),Mr=i(),W=a("div"),m(Le.$$.fragment),Gr=i(),Ot=a("p"),Ur=l("Serializes this instance to a JSON string."),Os=i(),L=a("div"),m(De.$$.fragment),Fr=i(),Mt=a("p"),Rr=l("A single set of features of data. Property names are the same names as the corresponding inputs to a model."),Xr=i(),K=a("div"),m(ke.$$.fragment),zr=i(),Gt=a("p"),Hr=l("Serializes this instance to a JSON string."),Ms=i(),V=a("h2"),Y=a("a"),Ut=a("span"),m(Ne.$$.fragment),Br=i(),Ft=a("span"),Jr=l("GLUE"),Gs=i(),Z=a("p"),Te=a("a"),Wr=l("General Language Understanding Evaluation (GLUE)"),Kr=l(` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),je=a("a"),Yr=l(`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),Us=i(),vt=a("p"),Zr=l(`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),Fs=i(),_t=a("p"),eo=l("Those processors are:"),Rs=i(),E=a("ul"),Rt=a("li"),Xt=a("code"),to=l("MrpcProcessor"),so=i(),zt=a("li"),Ht=a("code"),ao=l("MnliProcessor"),ro=i(),Bt=a("li"),Jt=a("code"),oo=l("MnliMismatchedProcessor"),lo=i(),Wt=a("li"),Kt=a("code"),no=l("Sst2Processor"),io=i(),Yt=a("li"),Zt=a("code"),po=l("StsbProcessor"),fo=i(),es=a("li"),ts=a("code"),co=l("QqpProcessor"),ho=i(),ss=a("li"),as=a("code"),mo=l("QnliProcessor"),uo=i(),rs=a("li"),os=a("code"),vo=l("RteProcessor"),_o=i(),ls=a("li"),ns=a("code"),go=l("WnliProcessor"),Xs=i(),ee=a("p"),Eo=l(`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),gt=a("a"),$o=l("InputExample"),wo=l("."),zs=i(),Et=a("p"),xo=l("automethod,transformers.data.processors.glue.glue_convert_examples_to_features"),Hs=i(),C=a("h3"),te=a("a"),is=a("span"),m(Ve.$$.fragment),bo=i(),ps=a("span"),Po=l("Example usage"),Bs=i(),se=a("p"),yo=l("An example using these processors is given in the "),Ce=a("a"),qo=l("run_glue.py"),So=l(" script."),Js=i(),Q=a("h2"),ae=a("a"),fs=a("span"),m(Qe.$$.fragment),Io=i(),cs=a("span"),Ao=l("XNLI"),Ws=i(),O=a("p"),Oe=a("a"),Lo=l("The Cross-Lingual NLI Corpus (XNLI)"),Do=l(` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),$t=a("em"),ko=l(`MultiNLI
<`),Me=a("a"),No=l("http://www.nyu.edu/projects/bowman/multinli/>"),To=l(`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ks=i(),Ge=a("p"),jo=l("It was released together with the paper "),Ue=a("a"),Vo=l("XNLI: Evaluating Cross-lingual Sentence Representations"),Ys=i(),wt=a("p"),Co=l("This library hosts the processor to load the XNLI data:"),Zs=i(),xt=a("ul"),hs=a("li"),ms=a("code"),Qo=l("XnliProcessor"),ea=i(),bt=a("p"),Oo=l("Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),ta=i(),re=a("p"),Mo=l("An example using these processors is given in the "),Fe=a("a"),Go=l("run_xnli.py"),Uo=l(" script."),sa=i(),M=a("h2"),oe=a("a"),us=a("span"),m(Re.$$.fragment),Fo=i(),ds=a("span"),Ro=l("SQuAD"),aa=i(),D=a("p"),Xe=a("a"),Xo=l("The Stanford Question Answering Dataset (SQuAD)"),zo=l(` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),ze=a("a"),Ho=l("SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Bo=l(". The second version (v2.0) was released alongside the paper "),He=a("a"),Jo=l(`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Wo=l("."),ra=i(),Pt=a("p"),Ko=l("This library hosts a processor for each of the two versions:"),oa=i(),G=a("h3"),le=a("a"),vs=a("span"),m(Be.$$.fragment),Yo=i(),_s=a("span"),Zo=l("Processors"),la=i(),yt=a("p"),el=l("Those processors are:"),na=i(),ne=a("ul"),gs=a("li"),Es=a("code"),tl=l("SquadV1Processor"),sl=i(),$s=a("li"),ws=a("code"),al=l("SquadV2Processor"),ia=i(),Je=a("p"),rl=l("They both inherit from the abstract class "),xs=a("code"),ol=l("SquadProcessor"),pa=i(),b=a("div"),m(We.$$.fragment),ll=i(),bs=a("p"),nl=l(`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),il=i(),ie=a("div"),m(Ke.$$.fragment),pl=i(),Ps=a("p"),fl=l("Returns the evaluation example from the data directory."),cl=i(),S=a("div"),m(Ye.$$.fragment),hl=i(),Ze=a("p"),ml=l("Creates a list of "),ys=a("code"),ul=l("SquadExample"),dl=l(" using a TFDS dataset."),vl=i(),qs=a("p"),_l=l("Examples:"),gl=i(),m(et.$$.fragment),El=i(),pe=a("div"),m(tt.$$.fragment),$l=i(),Ss=a("p"),wl=l("Returns the training examples from the data directory."),fa=i(),fe=a("p"),xl=l(`Additionally, the following method can be used to convert SQuAD examples into
`),Is=a("code"),bl=l("SquadFeatures"),Pl=l(" that can be used as model inputs."),ca=i(),qt=a("p"),yl=l("automethod,transformers.data.processors.squad.squad_convert_examples_to_features"),ha=i(),ce=a("p"),ql=l(`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),As=a("em"),Sl=l("tensorflow_datasets"),Il=l(" package. Examples are given below."),ma=i(),U=a("h3"),he=a("a"),Ls=a("span"),m(st.$$.fragment),Al=i(),Ds=a("span"),Ll=l("Example usage"),ua=i(),St=a("p"),Dl=l("Here is an example using the processors as well as the conversion method using data files:"),da=i(),m(at.$$.fragment),va=i(),me=a("p"),kl=l("Using "),ks=a("em"),Nl=l("tensorflow_datasets"),Tl=l(" is as easy as using a data file:"),_a=i(),m(rt.$$.fragment),ga=i(),ue=a("p"),jl=l("Another example using these processors is given in the "),ot=a("a"),Vl=l("run_squad.py"),Cl=l(" script."),this.h()},l(e){const f=Ni('[data-svelte="svelte-1phssyn"]',document.head);k=r(f,"META",{name:!0,content:!0}),f.forEach(s),nt=p(e),q=r(e,"H1",{class:!0});var $a=o(q);I=r($a,"A",{id:!0,class:!0,href:!0});var Ul=o(I);Lt=r(Ul,"SPAN",{});var Fl=o(Lt);u(_e.$$.fragment,Fl),Fl.forEach(s),Ul.forEach(s),Ya=p($a),Dt=r($a,"SPAN",{});var Rl=o(Dt);Za=n(Rl,"Processors"),Rl.forEach(s),$a.forEach(s),Ts=p(e),it=r(e,"P",{});var Xl=o(it);er=n(Xl,`This library includes processors for several traditional tasks. These processors can be used to process a dataset into
examples that can be fed to a model.`),Xl.forEach(s),js=p(e),j=r(e,"H2",{class:!0});var wa=o(j);F=r(wa,"A",{id:!0,class:!0,href:!0});var zl=o(F);kt=r(zl,"SPAN",{});var Hl=o(kt);u(ge.$$.fragment,Hl),Hl.forEach(s),zl.forEach(s),tr=p(wa),Nt=r(wa,"SPAN",{});var Bl=o(Nt);sr=n(Bl,"Processors"),Bl.forEach(s),wa.forEach(s),Vs=p(e),y=r(e,"P",{});var N=o(y);ar=n(N,`All processors follow the same architecture which is that of the
`),pt=r(N,"A",{href:!0});var Jl=o(pt);rr=n(Jl,"DataProcessor"),Jl.forEach(s),or=n(N,`. The processor returns a list of
`),ft=r(N,"A",{href:!0});var Wl=o(ft);lr=n(Wl,"InputExample"),Wl.forEach(s),nr=n(N,`. These
`),ct=r(N,"A",{href:!0});var Kl=o(ct);ir=n(Kl,"InputExample"),Kl.forEach(s),pr=n(N,` can be converted to
`),ht=r(N,"A",{href:!0});var Yl=o(ht);fr=n(Yl,"InputFeatures"),Yl.forEach(s),cr=n(N," in order to be fed to the model."),N.forEach(s),Cs=p(e),$=r(e,"DIV",{class:!0});var x=o($);u(Ee.$$.fragment,x),hr=p(x),Tt=r(x,"P",{});var Zl=o(Tt);mr=n(Zl,"Base class for data converters for sequence classification data sets."),Zl.forEach(s),ur=p(x),R=r(x,"DIV",{class:!0});var xa=o(R);u($e.$$.fragment,xa),dr=p(xa),we=r(xa,"P",{});var ba=o(we);vr=n(ba,"Gets a collection of "),mt=r(ba,"A",{href:!0});var en=o(mt);_r=n(en,"InputExample"),en.forEach(s),gr=n(ba," for the dev set."),ba.forEach(s),xa.forEach(s),Er=p(x),X=r(x,"DIV",{class:!0});var Pa=o(X);u(xe.$$.fragment,Pa),$r=p(Pa),jt=r(Pa,"P",{});var tn=o(jt);wr=n(tn,"Gets an example from a dict with tensorflow tensors."),tn.forEach(s),Pa.forEach(s),xr=p(x),z=r(x,"DIV",{class:!0});var ya=o(z);u(be.$$.fragment,ya),br=p(ya),Vt=r(ya,"P",{});var sn=o(Vt);Pr=n(sn,"Gets the list of labels for this data set."),sn.forEach(s),ya.forEach(s),yr=p(x),H=r(x,"DIV",{class:!0});var qa=o(H);u(Pe.$$.fragment,qa),qr=p(qa),ye=r(qa,"P",{});var Sa=o(ye);Sr=n(Sa,"Gets a collection of "),ut=r(Sa,"A",{href:!0});var an=o(ut);Ir=n(an,"InputExample"),an.forEach(s),Ar=n(Sa," for the test set."),Sa.forEach(s),qa.forEach(s),Lr=p(x),B=r(x,"DIV",{class:!0});var Ia=o(B);u(qe.$$.fragment,Ia),Dr=p(Ia),Se=r(Ia,"P",{});var Aa=o(Se);kr=n(Aa,"Gets a collection of "),dt=r(Aa,"A",{href:!0});var rn=o(dt);Nr=n(rn,"InputExample"),rn.forEach(s),Tr=n(Aa," for the train set."),Aa.forEach(s),Ia.forEach(s),jr=p(x),J=r(x,"DIV",{class:!0});var La=o(J);u(Ie.$$.fragment,La),Vr=p(La),Ct=r(La,"P",{});var on=o(Ct);Cr=n(on,`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),on.forEach(s),La.forEach(s),x.forEach(s),Qs=p(e),A=r(e,"DIV",{class:!0});var It=o(A);u(Ae.$$.fragment,It),Qr=p(It),Qt=r(It,"P",{});var ln=o(Qt);Or=n(ln,"A single training/test example for simple sequence classification."),ln.forEach(s),Mr=p(It),W=r(It,"DIV",{class:!0});var Da=o(W);u(Le.$$.fragment,Da),Gr=p(Da),Ot=r(Da,"P",{});var nn=o(Ot);Ur=n(nn,"Serializes this instance to a JSON string."),nn.forEach(s),Da.forEach(s),It.forEach(s),Os=p(e),L=r(e,"DIV",{class:!0});var At=o(L);u(De.$$.fragment,At),Fr=p(At),Mt=r(At,"P",{});var pn=o(Mt);Rr=n(pn,"A single set of features of data. Property names are the same names as the corresponding inputs to a model."),pn.forEach(s),Xr=p(At),K=r(At,"DIV",{class:!0});var ka=o(K);u(ke.$$.fragment,ka),zr=p(ka),Gt=r(ka,"P",{});var fn=o(Gt);Hr=n(fn,"Serializes this instance to a JSON string."),fn.forEach(s),ka.forEach(s),At.forEach(s),Ms=p(e),V=r(e,"H2",{class:!0});var Na=o(V);Y=r(Na,"A",{id:!0,class:!0,href:!0});var cn=o(Y);Ut=r(cn,"SPAN",{});var hn=o(Ut);u(Ne.$$.fragment,hn),hn.forEach(s),cn.forEach(s),Br=p(Na),Ft=r(Na,"SPAN",{});var mn=o(Ft);Jr=n(mn,"GLUE"),mn.forEach(s),Na.forEach(s),Gs=p(e),Z=r(e,"P",{});var Ta=o(Z);Te=r(Ta,"A",{href:!0,rel:!0});var un=o(Te);Wr=n(un,"General Language Understanding Evaluation (GLUE)"),un.forEach(s),Kr=n(Ta,` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),je=r(Ta,"A",{href:!0,rel:!0});var dn=o(je);Yr=n(dn,`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),dn.forEach(s),Ta.forEach(s),Us=p(e),vt=r(e,"P",{});var vn=o(vt);Zr=n(vn,`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),vn.forEach(s),Fs=p(e),_t=r(e,"P",{});var _n=o(_t);eo=n(_n,"Those processors are:"),_n.forEach(s),Rs=p(e),E=r(e,"UL",{});var w=o(E);Rt=r(w,"LI",{});var gn=o(Rt);Xt=r(gn,"CODE",{});var En=o(Xt);to=n(En,"MrpcProcessor"),En.forEach(s),gn.forEach(s),so=p(w),zt=r(w,"LI",{});var $n=o(zt);Ht=r($n,"CODE",{});var wn=o(Ht);ao=n(wn,"MnliProcessor"),wn.forEach(s),$n.forEach(s),ro=p(w),Bt=r(w,"LI",{});var xn=o(Bt);Jt=r(xn,"CODE",{});var bn=o(Jt);oo=n(bn,"MnliMismatchedProcessor"),bn.forEach(s),xn.forEach(s),lo=p(w),Wt=r(w,"LI",{});var Pn=o(Wt);Kt=r(Pn,"CODE",{});var yn=o(Kt);no=n(yn,"Sst2Processor"),yn.forEach(s),Pn.forEach(s),io=p(w),Yt=r(w,"LI",{});var qn=o(Yt);Zt=r(qn,"CODE",{});var Sn=o(Zt);po=n(Sn,"StsbProcessor"),Sn.forEach(s),qn.forEach(s),fo=p(w),es=r(w,"LI",{});var In=o(es);ts=r(In,"CODE",{});var An=o(ts);co=n(An,"QqpProcessor"),An.forEach(s),In.forEach(s),ho=p(w),ss=r(w,"LI",{});var Ln=o(ss);as=r(Ln,"CODE",{});var Dn=o(as);mo=n(Dn,"QnliProcessor"),Dn.forEach(s),Ln.forEach(s),uo=p(w),rs=r(w,"LI",{});var kn=o(rs);os=r(kn,"CODE",{});var Nn=o(os);vo=n(Nn,"RteProcessor"),Nn.forEach(s),kn.forEach(s),_o=p(w),ls=r(w,"LI",{});var Tn=o(ls);ns=r(Tn,"CODE",{});var jn=o(ns);go=n(jn,"WnliProcessor"),jn.forEach(s),Tn.forEach(s),w.forEach(s),Xs=p(e),ee=r(e,"P",{});var ja=o(ee);Eo=n(ja,`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),gt=r(ja,"A",{href:!0});var Vn=o(gt);$o=n(Vn,"InputExample"),Vn.forEach(s),wo=n(ja,"."),ja.forEach(s),zs=p(e),Et=r(e,"P",{});var Cn=o(Et);xo=n(Cn,"automethod,transformers.data.processors.glue.glue_convert_examples_to_features"),Cn.forEach(s),Hs=p(e),C=r(e,"H3",{class:!0});var Va=o(C);te=r(Va,"A",{id:!0,class:!0,href:!0});var Qn=o(te);is=r(Qn,"SPAN",{});var On=o(is);u(Ve.$$.fragment,On),On.forEach(s),Qn.forEach(s),bo=p(Va),ps=r(Va,"SPAN",{});var Mn=o(ps);Po=n(Mn,"Example usage"),Mn.forEach(s),Va.forEach(s),Bs=p(e),se=r(e,"P",{});var Ca=o(se);yo=n(Ca,"An example using these processors is given in the "),Ce=r(Ca,"A",{href:!0,rel:!0});var Gn=o(Ce);qo=n(Gn,"run_glue.py"),Gn.forEach(s),So=n(Ca," script."),Ca.forEach(s),Js=p(e),Q=r(e,"H2",{class:!0});var Qa=o(Q);ae=r(Qa,"A",{id:!0,class:!0,href:!0});var Un=o(ae);fs=r(Un,"SPAN",{});var Fn=o(fs);u(Qe.$$.fragment,Fn),Fn.forEach(s),Un.forEach(s),Io=p(Qa),cs=r(Qa,"SPAN",{});var Rn=o(cs);Ao=n(Rn,"XNLI"),Rn.forEach(s),Qa.forEach(s),Ws=p(e),O=r(e,"P",{});var Ns=o(O);Oe=r(Ns,"A",{href:!0,rel:!0});var Xn=o(Oe);Lo=n(Xn,"The Cross-Lingual NLI Corpus (XNLI)"),Xn.forEach(s),Do=n(Ns,` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),$t=r(Ns,"EM",{});var Ql=o($t);ko=n(Ql,`MultiNLI
<`),Me=r(Ql,"A",{href:!0,rel:!0});var zn=o(Me);No=n(zn,"http://www.nyu.edu/projects/bowman/multinli/>"),zn.forEach(s),Ql.forEach(s),To=n(Ns,`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ns.forEach(s),Ks=p(e),Ge=r(e,"P",{});var Ol=o(Ge);jo=n(Ol,"It was released together with the paper "),Ue=r(Ol,"A",{href:!0,rel:!0});var Hn=o(Ue);Vo=n(Hn,"XNLI: Evaluating Cross-lingual Sentence Representations"),Hn.forEach(s),Ol.forEach(s),Ys=p(e),wt=r(e,"P",{});var Bn=o(wt);Co=n(Bn,"This library hosts the processor to load the XNLI data:"),Bn.forEach(s),Zs=p(e),xt=r(e,"UL",{});var Jn=o(xt);hs=r(Jn,"LI",{});var Wn=o(hs);ms=r(Wn,"CODE",{});var Kn=o(ms);Qo=n(Kn,"XnliProcessor"),Kn.forEach(s),Wn.forEach(s),Jn.forEach(s),ea=p(e),bt=r(e,"P",{});var Yn=o(bt);Oo=n(Yn,"Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),Yn.forEach(s),ta=p(e),re=r(e,"P",{});var Oa=o(re);Mo=n(Oa,"An example using these processors is given in the "),Fe=r(Oa,"A",{href:!0,rel:!0});var Zn=o(Fe);Go=n(Zn,"run_xnli.py"),Zn.forEach(s),Uo=n(Oa," script."),Oa.forEach(s),sa=p(e),M=r(e,"H2",{class:!0});var Ma=o(M);oe=r(Ma,"A",{id:!0,class:!0,href:!0});var ei=o(oe);us=r(ei,"SPAN",{});var ti=o(us);u(Re.$$.fragment,ti),ti.forEach(s),ei.forEach(s),Fo=p(Ma),ds=r(Ma,"SPAN",{});var si=o(ds);Ro=n(si,"SQuAD"),si.forEach(s),Ma.forEach(s),aa=p(e),D=r(e,"P",{});var lt=o(D);Xe=r(lt,"A",{href:!0,rel:!0});var ai=o(Xe);Xo=n(ai,"The Stanford Question Answering Dataset (SQuAD)"),ai.forEach(s),zo=n(lt,` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),ze=r(lt,"A",{href:!0,rel:!0});var ri=o(ze);Ho=n(ri,"SQuAD: 100,000+ Questions for Machine Comprehension of Text"),ri.forEach(s),Bo=n(lt,". The second version (v2.0) was released alongside the paper "),He=r(lt,"A",{href:!0,rel:!0});var oi=o(He);Jo=n(oi,`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),oi.forEach(s),Wo=n(lt,"."),lt.forEach(s),ra=p(e),Pt=r(e,"P",{});var li=o(Pt);Ko=n(li,"This library hosts a processor for each of the two versions:"),li.forEach(s),oa=p(e),G=r(e,"H3",{class:!0});var Ga=o(G);le=r(Ga,"A",{id:!0,class:!0,href:!0});var ni=o(le);vs=r(ni,"SPAN",{});var ii=o(vs);u(Be.$$.fragment,ii),ii.forEach(s),ni.forEach(s),Yo=p(Ga),_s=r(Ga,"SPAN",{});var pi=o(_s);Zo=n(pi,"Processors"),pi.forEach(s),Ga.forEach(s),la=p(e),yt=r(e,"P",{});var fi=o(yt);el=n(fi,"Those processors are:"),fi.forEach(s),na=p(e),ne=r(e,"UL",{});var Ua=o(ne);gs=r(Ua,"LI",{});var ci=o(gs);Es=r(ci,"CODE",{});var hi=o(Es);tl=n(hi,"SquadV1Processor"),hi.forEach(s),ci.forEach(s),sl=p(Ua),$s=r(Ua,"LI",{});var mi=o($s);ws=r(mi,"CODE",{});var ui=o(ws);al=n(ui,"SquadV2Processor"),ui.forEach(s),mi.forEach(s),Ua.forEach(s),ia=p(e),Je=r(e,"P",{});var Ml=o(Je);rl=n(Ml,"They both inherit from the abstract class "),xs=r(Ml,"CODE",{});var di=o(xs);ol=n(di,"SquadProcessor"),di.forEach(s),Ml.forEach(s),pa=p(e),b=r(e,"DIV",{class:!0});var T=o(b);u(We.$$.fragment,T),ll=p(T),bs=r(T,"P",{});var vi=o(bs);nl=n(vi,`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),vi.forEach(s),il=p(T),ie=r(T,"DIV",{class:!0});var Fa=o(ie);u(Ke.$$.fragment,Fa),pl=p(Fa),Ps=r(Fa,"P",{});var _i=o(Ps);fl=n(_i,"Returns the evaluation example from the data directory."),_i.forEach(s),Fa.forEach(s),cl=p(T),S=r(T,"DIV",{class:!0});var de=o(S);u(Ye.$$.fragment,de),hl=p(de),Ze=r(de,"P",{});var Ra=o(Ze);ml=n(Ra,"Creates a list of "),ys=r(Ra,"CODE",{});var gi=o(ys);ul=n(gi,"SquadExample"),gi.forEach(s),dl=n(Ra," using a TFDS dataset."),Ra.forEach(s),vl=p(de),qs=r(de,"P",{});var Ei=o(qs);_l=n(Ei,"Examples:"),Ei.forEach(s),gl=p(de),u(et.$$.fragment,de),de.forEach(s),El=p(T),pe=r(T,"DIV",{class:!0});var Xa=o(pe);u(tt.$$.fragment,Xa),$l=p(Xa),Ss=r(Xa,"P",{});var $i=o(Ss);wl=n($i,"Returns the training examples from the data directory."),$i.forEach(s),Xa.forEach(s),T.forEach(s),fa=p(e),fe=r(e,"P",{});var za=o(fe);xl=n(za,`Additionally, the following method can be used to convert SQuAD examples into
`),Is=r(za,"CODE",{});var wi=o(Is);bl=n(wi,"SquadFeatures"),wi.forEach(s),Pl=n(za," that can be used as model inputs."),za.forEach(s),ca=p(e),qt=r(e,"P",{});var xi=o(qt);yl=n(xi,"automethod,transformers.data.processors.squad.squad_convert_examples_to_features"),xi.forEach(s),ha=p(e),ce=r(e,"P",{});var Ha=o(ce);ql=n(Ha,`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),As=r(Ha,"EM",{});var bi=o(As);Sl=n(bi,"tensorflow_datasets"),bi.forEach(s),Il=n(Ha," package. Examples are given below."),Ha.forEach(s),ma=p(e),U=r(e,"H3",{class:!0});var Ba=o(U);he=r(Ba,"A",{id:!0,class:!0,href:!0});var Pi=o(he);Ls=r(Pi,"SPAN",{});var yi=o(Ls);u(st.$$.fragment,yi),yi.forEach(s),Pi.forEach(s),Al=p(Ba),Ds=r(Ba,"SPAN",{});var qi=o(Ds);Ll=n(qi,"Example usage"),qi.forEach(s),Ba.forEach(s),ua=p(e),St=r(e,"P",{});var Si=o(St);Dl=n(Si,"Here is an example using the processors as well as the conversion method using data files:"),Si.forEach(s),da=p(e),u(at.$$.fragment,e),va=p(e),me=r(e,"P",{});var Ja=o(me);kl=n(Ja,"Using "),ks=r(Ja,"EM",{});var Ii=o(ks);Nl=n(Ii,"tensorflow_datasets"),Ii.forEach(s),Tl=n(Ja," is as easy as using a data file:"),Ja.forEach(s),_a=p(e),u(rt.$$.fragment,e),ga=p(e),ue=r(e,"P",{});var Wa=o(ue);jl=n(Wa,"Another example using these processors is given in the "),ot=r(Wa,"A",{href:!0,rel:!0});var Ai=o(ot);Vl=n(Ai,"run_squad.py"),Ai.forEach(s),Cl=n(Wa," script."),Wa.forEach(s),this.h()},h(){c(k,"name","hf:doc:metadata"),c(k,"content",JSON.stringify(Vi)),c(I,"id","processors"),c(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I,"href","#processors"),c(q,"class","relative group"),c(F,"id","transformers.DataProcessor"),c(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F,"href","#transformers.DataProcessor"),c(j,"class","relative group"),c(pt,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.DataProcessor"),c(ft,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputExample"),c(ct,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputExample"),c(ht,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputFeatures"),c(mt,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputExample"),c(R,"class","docstring"),c(X,"class","docstring"),c(z,"class","docstring"),c(ut,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputExample"),c(H,"class","docstring"),c(dt,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputExample"),c(B,"class","docstring"),c(J,"class","docstring"),c($,"class","docstring"),c(W,"class","docstring"),c(A,"class","docstring"),c(K,"class","docstring"),c(L,"class","docstring"),c(Y,"id","glue"),c(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y,"href","#glue"),c(V,"class","relative group"),c(Te,"href","https://gluebenchmark.com/"),c(Te,"rel","nofollow"),c(je,"href","https://openreview.net/pdf?id=rJ4km2R5t7"),c(je,"rel","nofollow"),c(gt,"href","/docs/transformers/v4.14.1/en/main_classes/processors#transformers.InputExample"),c(te,"id","example-usage"),c(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(te,"href","#example-usage"),c(C,"class","relative group"),c(Ce,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_glue.py"),c(Ce,"rel","nofollow"),c(ae,"id","xnli"),c(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ae,"href","#xnli"),c(Q,"class","relative group"),c(Oe,"href","https://www.nyu.edu/projects/bowman/xnli/"),c(Oe,"rel","nofollow"),c(Me,"href","http://www.nyu.edu/projects/bowman/multinli/%3E"),c(Me,"rel","nofollow"),c(Ue,"href","https://arxiv.org/abs/1809.05053"),c(Ue,"rel","nofollow"),c(Fe,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_xnli.py"),c(Fe,"rel","nofollow"),c(oe,"id","squad"),c(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oe,"href","#squad"),c(M,"class","relative group"),c(Xe,"href","https://rajpurkar.github.io/SQuAD-explorer//"),c(Xe,"rel","nofollow"),c(ze,"href","https://arxiv.org/abs/1606.05250"),c(ze,"rel","nofollow"),c(He,"href","https://arxiv.org/abs/1806.03822"),c(He,"rel","nofollow"),c(le,"id","transformers.data.processors.squad.SquadProcessor"),c(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(le,"href","#transformers.data.processors.squad.SquadProcessor"),c(G,"class","relative group"),c(ie,"class","docstring"),c(S,"class","docstring"),c(pe,"class","docstring"),c(b,"class","docstring"),c(he,"id","example-usage"),c(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(he,"href","#example-usage"),c(U,"class","relative group"),c(ot,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/question-answering/run_squad.py"),c(ot,"rel","nofollow")},m(e,f){t(document.head,k),h(e,nt,f),h(e,q,f),t(q,I),t(I,Lt),d(_e,Lt,null),t(q,Ya),t(q,Dt),t(Dt,Za),h(e,Ts,f),h(e,it,f),t(it,er),h(e,js,f),h(e,j,f),t(j,F),t(F,kt),d(ge,kt,null),t(j,tr),t(j,Nt),t(Nt,sr),h(e,Vs,f),h(e,y,f),t(y,ar),t(y,pt),t(pt,rr),t(y,or),t(y,ft),t(ft,lr),t(y,nr),t(y,ct),t(ct,ir),t(y,pr),t(y,ht),t(ht,fr),t(y,cr),h(e,Cs,f),h(e,$,f),d(Ee,$,null),t($,hr),t($,Tt),t(Tt,mr),t($,ur),t($,R),d($e,R,null),t(R,dr),t(R,we),t(we,vr),t(we,mt),t(mt,_r),t(we,gr),t($,Er),t($,X),d(xe,X,null),t(X,$r),t(X,jt),t(jt,wr),t($,xr),t($,z),d(be,z,null),t(z,br),t(z,Vt),t(Vt,Pr),t($,yr),t($,H),d(Pe,H,null),t(H,qr),t(H,ye),t(ye,Sr),t(ye,ut),t(ut,Ir),t(ye,Ar),t($,Lr),t($,B),d(qe,B,null),t(B,Dr),t(B,Se),t(Se,kr),t(Se,dt),t(dt,Nr),t(Se,Tr),t($,jr),t($,J),d(Ie,J,null),t(J,Vr),t(J,Ct),t(Ct,Cr),h(e,Qs,f),h(e,A,f),d(Ae,A,null),t(A,Qr),t(A,Qt),t(Qt,Or),t(A,Mr),t(A,W),d(Le,W,null),t(W,Gr),t(W,Ot),t(Ot,Ur),h(e,Os,f),h(e,L,f),d(De,L,null),t(L,Fr),t(L,Mt),t(Mt,Rr),t(L,Xr),t(L,K),d(ke,K,null),t(K,zr),t(K,Gt),t(Gt,Hr),h(e,Ms,f),h(e,V,f),t(V,Y),t(Y,Ut),d(Ne,Ut,null),t(V,Br),t(V,Ft),t(Ft,Jr),h(e,Gs,f),h(e,Z,f),t(Z,Te),t(Te,Wr),t(Z,Kr),t(Z,je),t(je,Yr),h(e,Us,f),h(e,vt,f),t(vt,Zr),h(e,Fs,f),h(e,_t,f),t(_t,eo),h(e,Rs,f),h(e,E,f),t(E,Rt),t(Rt,Xt),t(Xt,to),t(E,so),t(E,zt),t(zt,Ht),t(Ht,ao),t(E,ro),t(E,Bt),t(Bt,Jt),t(Jt,oo),t(E,lo),t(E,Wt),t(Wt,Kt),t(Kt,no),t(E,io),t(E,Yt),t(Yt,Zt),t(Zt,po),t(E,fo),t(E,es),t(es,ts),t(ts,co),t(E,ho),t(E,ss),t(ss,as),t(as,mo),t(E,uo),t(E,rs),t(rs,os),t(os,vo),t(E,_o),t(E,ls),t(ls,ns),t(ns,go),h(e,Xs,f),h(e,ee,f),t(ee,Eo),t(ee,gt),t(gt,$o),t(ee,wo),h(e,zs,f),h(e,Et,f),t(Et,xo),h(e,Hs,f),h(e,C,f),t(C,te),t(te,is),d(Ve,is,null),t(C,bo),t(C,ps),t(ps,Po),h(e,Bs,f),h(e,se,f),t(se,yo),t(se,Ce),t(Ce,qo),t(se,So),h(e,Js,f),h(e,Q,f),t(Q,ae),t(ae,fs),d(Qe,fs,null),t(Q,Io),t(Q,cs),t(cs,Ao),h(e,Ws,f),h(e,O,f),t(O,Oe),t(Oe,Lo),t(O,Do),t(O,$t),t($t,ko),t($t,Me),t(Me,No),t(O,To),h(e,Ks,f),h(e,Ge,f),t(Ge,jo),t(Ge,Ue),t(Ue,Vo),h(e,Ys,f),h(e,wt,f),t(wt,Co),h(e,Zs,f),h(e,xt,f),t(xt,hs),t(hs,ms),t(ms,Qo),h(e,ea,f),h(e,bt,f),t(bt,Oo),h(e,ta,f),h(e,re,f),t(re,Mo),t(re,Fe),t(Fe,Go),t(re,Uo),h(e,sa,f),h(e,M,f),t(M,oe),t(oe,us),d(Re,us,null),t(M,Fo),t(M,ds),t(ds,Ro),h(e,aa,f),h(e,D,f),t(D,Xe),t(Xe,Xo),t(D,zo),t(D,ze),t(ze,Ho),t(D,Bo),t(D,He),t(He,Jo),t(D,Wo),h(e,ra,f),h(e,Pt,f),t(Pt,Ko),h(e,oa,f),h(e,G,f),t(G,le),t(le,vs),d(Be,vs,null),t(G,Yo),t(G,_s),t(_s,Zo),h(e,la,f),h(e,yt,f),t(yt,el),h(e,na,f),h(e,ne,f),t(ne,gs),t(gs,Es),t(Es,tl),t(ne,sl),t(ne,$s),t($s,ws),t(ws,al),h(e,ia,f),h(e,Je,f),t(Je,rl),t(Je,xs),t(xs,ol),h(e,pa,f),h(e,b,f),d(We,b,null),t(b,ll),t(b,bs),t(bs,nl),t(b,il),t(b,ie),d(Ke,ie,null),t(ie,pl),t(ie,Ps),t(Ps,fl),t(b,cl),t(b,S),d(Ye,S,null),t(S,hl),t(S,Ze),t(Ze,ml),t(Ze,ys),t(ys,ul),t(Ze,dl),t(S,vl),t(S,qs),t(qs,_l),t(S,gl),d(et,S,null),t(b,El),t(b,pe),d(tt,pe,null),t(pe,$l),t(pe,Ss),t(Ss,wl),h(e,fa,f),h(e,fe,f),t(fe,xl),t(fe,Is),t(Is,bl),t(fe,Pl),h(e,ca,f),h(e,qt,f),t(qt,yl),h(e,ha,f),h(e,ce,f),t(ce,ql),t(ce,As),t(As,Sl),t(ce,Il),h(e,ma,f),h(e,U,f),t(U,he),t(he,Ls),d(st,Ls,null),t(U,Al),t(U,Ds),t(Ds,Ll),h(e,ua,f),h(e,St,f),t(St,Dl),h(e,da,f),d(at,e,f),h(e,va,f),h(e,me,f),t(me,kl),t(me,ks),t(ks,Nl),t(me,Tl),h(e,_a,f),d(rt,e,f),h(e,ga,f),h(e,ue,f),t(ue,jl),t(ue,ot),t(ot,Vl),t(ue,Cl),Ea=!0},p:Ti,i(e){Ea||(v(_e.$$.fragment,e),v(ge.$$.fragment,e),v(Ee.$$.fragment,e),v($e.$$.fragment,e),v(xe.$$.fragment,e),v(be.$$.fragment,e),v(Pe.$$.fragment,e),v(qe.$$.fragment,e),v(Ie.$$.fragment,e),v(Ae.$$.fragment,e),v(Le.$$.fragment,e),v(De.$$.fragment,e),v(ke.$$.fragment,e),v(Ne.$$.fragment,e),v(Ve.$$.fragment,e),v(Qe.$$.fragment,e),v(Re.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(Ke.$$.fragment,e),v(Ye.$$.fragment,e),v(et.$$.fragment,e),v(tt.$$.fragment,e),v(st.$$.fragment,e),v(at.$$.fragment,e),v(rt.$$.fragment,e),Ea=!0)},o(e){_(_e.$$.fragment,e),_(ge.$$.fragment,e),_(Ee.$$.fragment,e),_($e.$$.fragment,e),_(xe.$$.fragment,e),_(be.$$.fragment,e),_(Pe.$$.fragment,e),_(qe.$$.fragment,e),_(Ie.$$.fragment,e),_(Ae.$$.fragment,e),_(Le.$$.fragment,e),_(De.$$.fragment,e),_(ke.$$.fragment,e),_(Ne.$$.fragment,e),_(Ve.$$.fragment,e),_(Qe.$$.fragment,e),_(Re.$$.fragment,e),_(Be.$$.fragment,e),_(We.$$.fragment,e),_(Ke.$$.fragment,e),_(Ye.$$.fragment,e),_(et.$$.fragment,e),_(tt.$$.fragment,e),_(st.$$.fragment,e),_(at.$$.fragment,e),_(rt.$$.fragment,e),Ea=!1},d(e){s(k),e&&s(nt),e&&s(q),g(_e),e&&s(Ts),e&&s(it),e&&s(js),e&&s(j),g(ge),e&&s(Vs),e&&s(y),e&&s(Cs),e&&s($),g(Ee),g($e),g(xe),g(be),g(Pe),g(qe),g(Ie),e&&s(Qs),e&&s(A),g(Ae),g(Le),e&&s(Os),e&&s(L),g(De),g(ke),e&&s(Ms),e&&s(V),g(Ne),e&&s(Gs),e&&s(Z),e&&s(Us),e&&s(vt),e&&s(Fs),e&&s(_t),e&&s(Rs),e&&s(E),e&&s(Xs),e&&s(ee),e&&s(zs),e&&s(Et),e&&s(Hs),e&&s(C),g(Ve),e&&s(Bs),e&&s(se),e&&s(Js),e&&s(Q),g(Qe),e&&s(Ws),e&&s(O),e&&s(Ks),e&&s(Ge),e&&s(Ys),e&&s(wt),e&&s(Zs),e&&s(xt),e&&s(ea),e&&s(bt),e&&s(ta),e&&s(re),e&&s(sa),e&&s(M),g(Re),e&&s(aa),e&&s(D),e&&s(ra),e&&s(Pt),e&&s(oa),e&&s(G),g(Be),e&&s(la),e&&s(yt),e&&s(na),e&&s(ne),e&&s(ia),e&&s(Je),e&&s(pa),e&&s(b),g(We),g(Ke),g(Ye),g(et),g(tt),e&&s(fa),e&&s(fe),e&&s(ca),e&&s(qt),e&&s(ha),e&&s(ce),e&&s(ma),e&&s(U),g(st),e&&s(ua),e&&s(St),e&&s(da),g(at,e),e&&s(va),e&&s(me),e&&s(_a),g(rt,e),e&&s(ga),e&&s(ue)}}}const Vi={local:"processors",sections:[{local:"transformers.DataProcessor",title:"Processors"},{local:"glue",sections:[{local:"example-usage",title:"Example usage"}],title:"GLUE"},{local:"xnli",title:"XNLI"},{local:"squad",sections:[{local:"transformers.data.processors.squad.SquadProcessor",title:"Processors"},{local:"example-usage",title:"Example usage"}],title:"SQuAD"}],title:"Processors"};function Ci(Ka,k,nt){let{fw:q}=k;return Ka.$$set=I=>{"fw"in I&&nt(0,q=I.fw)},[q]}class Fi extends Li{constructor(k){super();Di(this,k,Ci,ji,ki,{fw:0})}}export{Fi as default,Vi as metadata};
