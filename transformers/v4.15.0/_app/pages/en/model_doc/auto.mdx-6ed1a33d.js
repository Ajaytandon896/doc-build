import{S as NVt,i as DVt,s as GVt,e as a,k as l,w as f,t as o,L as OVt,c as n,d as r,m as i,a as s,x as c,h as t,b as m,J as e,g as v,y as g,q as h,o as u,B as p}from"../../../chunks/vendor-b1433968.js";import{T as Qct}from"../../../chunks/Tip-c3840994.js";import{D as C}from"../../../chunks/Docstring-ff504c58.js";import{C as w}from"../../../chunks/CodeBlock-a320dbd7.js";import{I as X}from"../../../chunks/IconCopyLink-7029626d.js";import"../../../chunks/CopyButton-f65cb278.js";function qVt(Wl){let J,ye,se,de,Ue,ie,ue,Bo,Vl,km,zr,Ql,Hl,RF,Rm,Fe,Ze,Ul,gn,SF,hn,un,PF,Jl,pn,$F,Kl,Sm,ba;return{c(){J=a("p"),ye=o("If your "),se=a("code"),de=o("NewModelConfig"),Ue=o(" is a subclass of "),ie=a("code"),ue=o("PretrainedConfig"),Bo=o(`, make sure its
`),Vl=a("code"),km=o("model_type"),zr=o(" attribute is set to the same key you use when registering the config (here "),Ql=a("code"),Hl=o('"new-model"'),RF=o(")."),Rm=l(),Fe=a("p"),Ze=o("Likewise, if your "),Ul=a("code"),gn=o("NewModel"),SF=o(" is a subclass of "),hn=a("a"),un=o("PreTrainedModel"),PF=o(`, make sure its
`),Jl=a("code"),pn=o("config_class"),$F=o(` attribute is set to the same class you use when registering the model (here
`),Kl=a("code"),Sm=o("NewModelConfig"),ba=o(")."),this.h()},l(eo){J=n(eo,"P",{});var me=s(J);ye=t(me,"If your "),se=n(me,"CODE",{});var IA=s(se);de=t(IA,"NewModelConfig"),IA.forEach(r),Ue=t(me," is a subclass of "),ie=n(me,"CODE",{});var Yl=s(ie);ue=t(Yl,"PretrainedConfig"),Yl.forEach(r),Bo=t(me,`, make sure its
`),Vl=n(me,"CODE",{});var jA=s(Vl);km=t(jA,"model_type"),jA.forEach(r),zr=t(me," attribute is set to the same key you use when registering the config (here "),Ql=n(me,"CODE",{});var NA=s(Ql);Hl=t(NA,'"new-model"'),NA.forEach(r),RF=t(me,")."),me.forEach(r),Rm=i(eo),Fe=n(eo,"P",{});var ko=s(Fe);Ze=t(ko,"Likewise, if your "),Ul=n(ko,"CODE",{});var Ta=s(Ul);gn=t(Ta,"NewModel"),Ta.forEach(r),SF=t(ko," is a subclass of "),hn=n(ko,"A",{href:!0});var DA=s(hn);un=t(DA,"PreTrainedModel"),DA.forEach(r),PF=t(ko,`, make sure its
`),Jl=n(ko,"CODE",{});var Pm=s(Jl);pn=t(Pm,"config_class"),Pm.forEach(r),$F=t(ko,` attribute is set to the same class you use when registering the model (here
`),Kl=n(ko,"CODE",{});var GA=s(Kl);Sm=t(GA,"NewModelConfig"),GA.forEach(r),ba=t(ko,")."),ko.forEach(r),this.h()},h(){m(hn,"href","/docs/transformers/v4.15.0/en/main_classes/model#transformers.PreTrainedModel")},m(eo,me){v(eo,J,me),e(J,ye),e(J,se),e(se,de),e(J,Ue),e(J,ie),e(ie,ue),e(J,Bo),e(J,Vl),e(Vl,km),e(J,zr),e(J,Ql),e(Ql,Hl),e(J,RF),v(eo,Rm,me),v(eo,Fe,me),e(Fe,Ze),e(Fe,Ul),e(Ul,gn),e(Fe,SF),e(Fe,hn),e(hn,un),e(Fe,PF),e(Fe,Jl),e(Jl,pn),e(Fe,$F),e(Fe,Kl),e(Kl,Sm),e(Fe,ba)},d(eo){eo&&r(J),eo&&r(Rm),eo&&r(Fe)}}}function zVt(Wl){let J,ye,se,de,Ue;return{c(){J=a("p"),ye=o("Passing "),se=a("em"),de=o("use_auth_token=True"),Ue=o(" is required when you want to use a private model.")},l(ie){J=n(ie,"P",{});var ue=s(J);ye=t(ue,"Passing "),se=n(ue,"EM",{});var Bo=s(se);de=t(Bo,"use_auth_token=True"),Bo.forEach(r),Ue=t(ue," is required when you want to use a private model."),ue.forEach(r)},m(ie,ue){v(ie,J,ue),e(J,ye),e(J,se),e(se,de),e(J,Ue)},d(ie){ie&&r(J)}}}function XVt(Wl){let J,ye,se,de,Ue;return{c(){J=a("p"),ye=o("Passing "),se=a("em"),de=o("use_auth_token=True"),Ue=o(" is required when you want to use a private model.")},l(ie){J=n(ie,"P",{});var ue=s(J);ye=t(ue,"Passing "),se=n(ue,"EM",{});var Bo=s(se);de=t(Bo,"use_auth_token=True"),Bo.forEach(r),Ue=t(ue," is required when you want to use a private model."),ue.forEach(r)},m(ie,ue){v(ie,J,ue),e(J,ye),e(J,se),e(se,de),e(J,Ue)},d(ie){ie&&r(J)}}}function WVt(Wl){let J,ye,se,de,Ue,ie,ue,Bo,Vl,km,zr,Ql,Hl,RF,Rm,Fe,Ze,Ul,gn,SF,hn,un,PF,Jl,pn,$F,Kl,Sm,ba,eo,me,IA,Yl,jA,NA,ko,Ta,DA,Pm,GA,dwe,bEe,Zl,$m,YG,IF,mwe,ZG,fwe,TEe,_n,cwe,eO,gwe,hwe,oO,uwe,pwe,FEe,jF,MEe,OA,_we,EEe,Im,CEe,ei,jm,tO,NF,vwe,rO,bwe,yEe,Ro,DF,Twe,GF,Fwe,qA,Mwe,Ewe,Cwe,OF,ywe,aO,wwe,Awe,xwe,oo,qF,Lwe,nO,Bwe,kwe,oi,Rwe,sO,Swe,Pwe,lO,$we,Iwe,jwe,b,Nm,iO,Nwe,Dwe,zA,Gwe,Owe,qwe,Dm,dO,zwe,Xwe,XA,Wwe,Vwe,Qwe,Gm,mO,Hwe,Uwe,WA,Jwe,Kwe,Ywe,Om,fO,Zwe,eAe,VA,oAe,tAe,rAe,qm,cO,aAe,nAe,QA,sAe,lAe,iAe,zm,gO,dAe,mAe,HA,fAe,cAe,gAe,Xm,hO,hAe,uAe,UA,pAe,_Ae,vAe,Wm,uO,bAe,TAe,JA,FAe,MAe,EAe,Vm,pO,CAe,yAe,KA,wAe,AAe,xAe,Qm,_O,LAe,BAe,YA,kAe,RAe,SAe,Hm,vO,PAe,$Ae,ZA,IAe,jAe,NAe,Um,bO,DAe,GAe,e7,OAe,qAe,zAe,Jm,TO,XAe,WAe,o7,VAe,QAe,HAe,Km,FO,UAe,JAe,t7,KAe,YAe,ZAe,Ym,MO,e7e,o7e,r7,t7e,r7e,a7e,Zm,EO,n7e,s7e,a7,l7e,i7e,d7e,ef,CO,m7e,f7e,n7,c7e,g7e,h7e,of,yO,u7e,p7e,s7,_7e,v7e,b7e,tf,wO,T7e,F7e,l7,M7e,E7e,C7e,rf,AO,y7e,w7e,i7,A7e,x7e,L7e,af,xO,B7e,k7e,d7,R7e,S7e,P7e,nf,LO,$7e,I7e,m7,j7e,N7e,D7e,sf,BO,G7e,O7e,f7,q7e,z7e,X7e,lf,kO,W7e,V7e,c7,Q7e,H7e,U7e,df,RO,J7e,K7e,g7,Y7e,Z7e,exe,mf,SO,oxe,txe,h7,rxe,axe,nxe,ff,PO,sxe,lxe,u7,ixe,dxe,mxe,cf,$O,fxe,cxe,p7,gxe,hxe,uxe,gf,IO,pxe,_xe,_7,vxe,bxe,Txe,hf,jO,Fxe,Mxe,v7,Exe,Cxe,yxe,uf,NO,wxe,Axe,b7,xxe,Lxe,Bxe,pf,DO,kxe,Rxe,T7,Sxe,Pxe,$xe,_f,GO,Ixe,jxe,F7,Nxe,Dxe,Gxe,vf,OO,Oxe,qxe,M7,zxe,Xxe,Wxe,bf,qO,Vxe,Qxe,E7,Hxe,Uxe,Jxe,Tf,zO,Kxe,Yxe,C7,Zxe,e6e,o6e,Ff,XO,t6e,r6e,y7,a6e,n6e,s6e,Mf,WO,l6e,i6e,w7,d6e,m6e,f6e,Ef,VO,c6e,g6e,A7,h6e,u6e,p6e,Cf,QO,_6e,v6e,x7,b6e,T6e,F6e,yf,HO,M6e,E6e,L7,C6e,y6e,w6e,wf,UO,A6e,x6e,B7,L6e,B6e,k6e,Af,JO,R6e,S6e,k7,P6e,$6e,I6e,xf,KO,j6e,N6e,R7,D6e,G6e,O6e,Lf,YO,q6e,z6e,S7,X6e,W6e,V6e,Bf,ZO,Q6e,H6e,P7,U6e,J6e,K6e,kf,eq,Y6e,Z6e,$7,e8e,o8e,t8e,Rf,oq,r8e,a8e,I7,n8e,s8e,l8e,Sf,tq,i8e,d8e,j7,m8e,f8e,c8e,Pf,rq,g8e,h8e,N7,u8e,p8e,_8e,$f,aq,v8e,b8e,D7,T8e,F8e,M8e,If,nq,E8e,C8e,G7,y8e,w8e,A8e,jf,sq,x8e,L8e,O7,B8e,k8e,R8e,Nf,lq,S8e,P8e,q7,$8e,I8e,j8e,Df,iq,N8e,D8e,z7,G8e,O8e,q8e,Gf,dq,z8e,X8e,X7,W8e,V8e,Q8e,Of,mq,H8e,U8e,W7,J8e,K8e,Y8e,qf,fq,Z8e,eLe,V7,oLe,tLe,rLe,zf,cq,aLe,nLe,Q7,sLe,lLe,iLe,Xf,gq,dLe,mLe,H7,fLe,cLe,gLe,Wf,hq,hLe,uLe,U7,pLe,_Le,vLe,Vf,uq,bLe,TLe,J7,FLe,MLe,ELe,Qf,pq,CLe,yLe,K7,wLe,ALe,xLe,Hf,_q,LLe,BLe,Y7,kLe,RLe,SLe,Uf,vq,PLe,$Le,Z7,ILe,jLe,NLe,Jf,bq,DLe,GLe,ex,OLe,qLe,zLe,Kf,Tq,XLe,WLe,ox,VLe,QLe,HLe,Yf,Fq,ULe,JLe,tx,KLe,YLe,ZLe,Zf,Mq,eBe,oBe,rx,tBe,rBe,aBe,ec,Eq,nBe,sBe,ax,lBe,iBe,dBe,oc,Cq,mBe,fBe,nx,cBe,gBe,hBe,tc,yq,uBe,pBe,sx,_Be,vBe,bBe,rc,wq,TBe,FBe,lx,MBe,EBe,CBe,ac,Aq,yBe,wBe,ix,ABe,xBe,LBe,nc,xq,BBe,kBe,dx,RBe,SBe,PBe,sc,Lq,$Be,IBe,mx,jBe,NBe,DBe,lc,Bq,GBe,OBe,fx,qBe,zBe,XBe,ic,kq,WBe,VBe,cx,QBe,HBe,UBe,dc,Rq,JBe,KBe,gx,YBe,ZBe,e9e,mc,Sq,o9e,t9e,hx,r9e,a9e,n9e,Pq,s9e,l9e,zF,i9e,fc,XF,d9e,$q,m9e,wEe,ti,cc,Iq,WF,f9e,jq,c9e,AEe,So,VF,g9e,QF,h9e,ux,u9e,p9e,_9e,HF,v9e,Nq,b9e,T9e,F9e,to,UF,M9e,Dq,E9e,C9e,Fa,y9e,Gq,w9e,A9e,Oq,x9e,L9e,qq,B9e,k9e,R9e,E,vn,zq,S9e,P9e,px,$9e,I9e,_x,j9e,N9e,D9e,bn,Xq,G9e,O9e,vx,q9e,z9e,bx,X9e,W9e,V9e,Tn,Wq,Q9e,H9e,Tx,U9e,J9e,Fx,K9e,Y9e,Z9e,gc,Vq,eke,oke,Mx,tke,rke,ake,Fn,Qq,nke,ske,Ex,lke,ike,Cx,dke,mke,fke,hc,Hq,cke,gke,yx,hke,uke,pke,uc,Uq,_ke,vke,wx,bke,Tke,Fke,pc,Jq,Mke,Eke,Ax,Cke,yke,wke,Mn,Kq,Ake,xke,xx,Lke,Bke,Lx,kke,Rke,Ske,En,Yq,Pke,$ke,Bx,Ike,jke,kx,Nke,Dke,Gke,Cn,Zq,Oke,qke,Rx,zke,Xke,Sx,Wke,Vke,Qke,_c,ez,Hke,Uke,Px,Jke,Kke,Yke,vc,oz,Zke,eRe,$x,oRe,tRe,rRe,yn,tz,aRe,nRe,Ix,sRe,lRe,jx,iRe,dRe,mRe,bc,rz,fRe,cRe,Nx,gRe,hRe,uRe,wn,az,pRe,_Re,Dx,vRe,bRe,Gx,TRe,FRe,MRe,An,nz,ERe,CRe,Ox,yRe,wRe,qx,ARe,xRe,LRe,xn,sz,BRe,kRe,zx,RRe,SRe,lz,PRe,$Re,IRe,Tc,iz,jRe,NRe,Xx,DRe,GRe,ORe,Ln,dz,qRe,zRe,Wx,XRe,WRe,Vx,VRe,QRe,HRe,Fc,mz,URe,JRe,Qx,KRe,YRe,ZRe,Bn,fz,eSe,oSe,Hx,tSe,rSe,Ux,aSe,nSe,sSe,kn,cz,lSe,iSe,Jx,dSe,mSe,Kx,fSe,cSe,gSe,Rn,gz,hSe,uSe,Yx,pSe,_Se,Zx,vSe,bSe,TSe,Mc,hz,FSe,MSe,e6,ESe,CSe,ySe,Sn,uz,wSe,ASe,o6,xSe,LSe,t6,BSe,kSe,RSe,Ec,pz,SSe,PSe,r6,$Se,ISe,jSe,Pn,_z,NSe,DSe,a6,GSe,OSe,n6,qSe,zSe,XSe,$n,vz,WSe,VSe,s6,QSe,HSe,l6,USe,JSe,KSe,In,bz,YSe,ZSe,i6,ePe,oPe,d6,tPe,rPe,aPe,Cc,Tz,nPe,sPe,m6,lPe,iPe,dPe,jn,Fz,mPe,fPe,f6,cPe,gPe,c6,hPe,uPe,pPe,Nn,Mz,_Pe,vPe,g6,bPe,TPe,h6,FPe,MPe,EPe,Dn,Ez,CPe,yPe,u6,wPe,APe,p6,xPe,LPe,BPe,Gn,Cz,kPe,RPe,_6,SPe,PPe,v6,$Pe,IPe,jPe,On,yz,NPe,DPe,b6,GPe,OPe,T6,qPe,zPe,XPe,yc,wz,WPe,VPe,F6,QPe,HPe,UPe,qn,Az,JPe,KPe,M6,YPe,ZPe,E6,e$e,o$e,t$e,wc,xz,r$e,a$e,C6,n$e,s$e,l$e,Ac,Lz,i$e,d$e,y6,m$e,f$e,c$e,zn,Bz,g$e,h$e,w6,u$e,p$e,A6,_$e,v$e,b$e,Xn,kz,T$e,F$e,x6,M$e,E$e,L6,C$e,y$e,w$e,Wn,Rz,A$e,x$e,B6,L$e,B$e,k6,k$e,R$e,S$e,Vn,Sz,P$e,$$e,R6,I$e,j$e,S6,N$e,D$e,G$e,Qn,Pz,O$e,q$e,P6,z$e,X$e,$6,W$e,V$e,Q$e,Hn,$z,H$e,U$e,I6,J$e,K$e,j6,Y$e,Z$e,eIe,Un,Iz,oIe,tIe,N6,rIe,aIe,D6,nIe,sIe,lIe,xc,jz,iIe,dIe,G6,mIe,fIe,cIe,Lc,Nz,gIe,hIe,O6,uIe,pIe,_Ie,Bc,Dz,vIe,bIe,q6,TIe,FIe,MIe,Jn,Gz,EIe,CIe,z6,yIe,wIe,X6,AIe,xIe,LIe,kc,Oz,BIe,kIe,W6,RIe,SIe,PIe,Kn,qz,$Ie,IIe,V6,jIe,NIe,Q6,DIe,GIe,OIe,Yn,zz,qIe,zIe,H6,XIe,WIe,U6,VIe,QIe,HIe,Zn,Xz,UIe,JIe,J6,KIe,YIe,K6,ZIe,eje,oje,es,Wz,tje,rje,Y6,aje,nje,Z6,sje,lje,ije,os,Vz,dje,mje,e8,fje,cje,o8,gje,hje,uje,Rc,Qz,pje,_je,t8,vje,bje,Tje,Sc,Hz,Fje,Mje,r8,Eje,Cje,yje,ts,Uz,wje,Aje,a8,xje,Lje,n8,Bje,kje,Rje,rs,Jz,Sje,Pje,s8,$je,Ije,l8,jje,Nje,Dje,as,Kz,Gje,Oje,i8,qje,zje,d8,Xje,Wje,Vje,Pc,Yz,Qje,Hje,m8,Uje,Jje,Kje,$c,Zz,Yje,Zje,f8,eNe,oNe,tNe,Ic,eX,rNe,aNe,c8,nNe,sNe,lNe,jc,oX,iNe,dNe,g8,mNe,fNe,cNe,Nc,tX,gNe,hNe,h8,uNe,pNe,_Ne,ns,rX,vNe,bNe,u8,TNe,FNe,p8,MNe,ENe,CNe,ss,aX,yNe,wNe,_8,ANe,xNe,v8,LNe,BNe,kNe,nX,RNe,SNe,JF,PNe,Dc,KF,$Ne,sX,INe,xEe,ri,Gc,lX,YF,jNe,iX,NNe,LEe,Gr,ZF,DNe,eM,GNe,b8,ONe,qNe,zNe,oM,XNe,dX,WNe,VNe,QNe,we,tM,HNe,mX,UNe,JNe,Ma,KNe,fX,YNe,ZNe,cX,eDe,oDe,gX,tDe,rDe,aDe,fe,Oc,hX,nDe,sDe,T8,lDe,iDe,dDe,qc,uX,mDe,fDe,F8,cDe,gDe,hDe,zc,pX,uDe,pDe,M8,_De,vDe,bDe,Xc,_X,TDe,FDe,E8,MDe,EDe,CDe,Wc,vX,yDe,wDe,C8,ADe,xDe,LDe,Vc,bX,BDe,kDe,y8,RDe,SDe,PDe,Qc,TX,$De,IDe,w8,jDe,NDe,DDe,Hc,FX,GDe,ODe,A8,qDe,zDe,XDe,Uc,MX,WDe,VDe,x8,QDe,HDe,UDe,Jc,EX,JDe,KDe,L8,YDe,ZDe,eGe,Kc,oGe,CX,tGe,rGe,rM,BEe,ai,Yc,yX,aM,aGe,wX,nGe,kEe,Or,nM,sGe,sM,lGe,B8,iGe,dGe,mGe,lM,fGe,AX,cGe,gGe,hGe,Ae,iM,uGe,xX,pGe,_Ge,ni,vGe,LX,bGe,TGe,BX,FGe,MGe,EGe,Je,Zc,kX,CGe,yGe,k8,wGe,AGe,xGe,eg,RX,LGe,BGe,R8,kGe,RGe,SGe,og,SX,PGe,$Ge,S8,IGe,jGe,NGe,tg,PX,DGe,GGe,P8,OGe,qGe,zGe,rg,$X,XGe,WGe,$8,VGe,QGe,HGe,ag,IX,UGe,JGe,I8,KGe,YGe,ZGe,ng,jX,eOe,oOe,j8,tOe,rOe,aOe,sg,nOe,NX,sOe,lOe,dM,REe,si,lg,DX,mM,iOe,GX,dOe,SEe,Po,fM,mOe,li,fOe,OX,cOe,gOe,qX,hOe,uOe,pOe,cM,_Oe,zX,vOe,bOe,TOe,wt,gM,FOe,XX,MOe,EOe,ii,COe,WX,yOe,wOe,VX,AOe,xOe,LOe,QX,BOe,kOe,hM,ROe,xe,uM,SOe,HX,POe,$Oe,Ea,IOe,UX,jOe,NOe,JX,DOe,GOe,KX,OOe,qOe,zOe,F,ig,YX,XOe,WOe,N8,VOe,QOe,HOe,dg,ZX,UOe,JOe,D8,KOe,YOe,ZOe,mg,eW,eqe,oqe,G8,tqe,rqe,aqe,fg,oW,nqe,sqe,O8,lqe,iqe,dqe,cg,tW,mqe,fqe,q8,cqe,gqe,hqe,gg,rW,uqe,pqe,z8,_qe,vqe,bqe,hg,aW,Tqe,Fqe,X8,Mqe,Eqe,Cqe,ug,nW,yqe,wqe,W8,Aqe,xqe,Lqe,pg,sW,Bqe,kqe,V8,Rqe,Sqe,Pqe,_g,lW,$qe,Iqe,Q8,jqe,Nqe,Dqe,vg,iW,Gqe,Oqe,H8,qqe,zqe,Xqe,bg,dW,Wqe,Vqe,U8,Qqe,Hqe,Uqe,Tg,mW,Jqe,Kqe,J8,Yqe,Zqe,eze,Fg,fW,oze,tze,K8,rze,aze,nze,Mg,cW,sze,lze,Y8,ize,dze,mze,Eg,gW,fze,cze,Z8,gze,hze,uze,Cg,hW,pze,_ze,eL,vze,bze,Tze,yg,uW,Fze,Mze,oL,Eze,Cze,yze,wg,pW,wze,Aze,tL,xze,Lze,Bze,Ag,_W,kze,Rze,rL,Sze,Pze,$ze,xg,vW,Ize,jze,aL,Nze,Dze,Gze,Lg,bW,Oze,qze,nL,zze,Xze,Wze,Bg,TW,Vze,Qze,sL,Hze,Uze,Jze,kg,FW,Kze,Yze,lL,Zze,eXe,oXe,ls,MW,tXe,rXe,iL,aXe,nXe,dL,sXe,lXe,iXe,Rg,EW,dXe,mXe,mL,fXe,cXe,gXe,Sg,CW,hXe,uXe,fL,pXe,_Xe,vXe,Pg,yW,bXe,TXe,cL,FXe,MXe,EXe,$g,wW,CXe,yXe,gL,wXe,AXe,xXe,Ig,AW,LXe,BXe,hL,kXe,RXe,SXe,jg,xW,PXe,$Xe,uL,IXe,jXe,NXe,Ng,LW,DXe,GXe,pL,OXe,qXe,zXe,Dg,BW,XXe,WXe,_L,VXe,QXe,HXe,Gg,kW,UXe,JXe,vL,KXe,YXe,ZXe,Og,RW,eWe,oWe,bL,tWe,rWe,aWe,qg,SW,nWe,sWe,TL,lWe,iWe,dWe,zg,PW,mWe,fWe,FL,cWe,gWe,hWe,Xg,$W,uWe,pWe,ML,_We,vWe,bWe,Wg,IW,TWe,FWe,EL,MWe,EWe,CWe,Vg,jW,yWe,wWe,CL,AWe,xWe,LWe,Qg,NW,BWe,kWe,yL,RWe,SWe,PWe,Hg,DW,$We,IWe,wL,jWe,NWe,DWe,Ug,GW,GWe,OWe,AL,qWe,zWe,XWe,Jg,OW,WWe,VWe,xL,QWe,HWe,UWe,Kg,qW,JWe,KWe,LL,YWe,ZWe,eVe,Yg,zW,oVe,tVe,BL,rVe,aVe,nVe,Zg,XW,sVe,lVe,kL,iVe,dVe,mVe,eh,WW,fVe,cVe,RL,gVe,hVe,uVe,oh,VW,pVe,_Ve,SL,vVe,bVe,TVe,th,QW,FVe,MVe,PL,EVe,CVe,yVe,rh,HW,wVe,AVe,$L,xVe,LVe,BVe,ah,UW,kVe,RVe,IL,SVe,PVe,$Ve,nh,JW,IVe,jVe,jL,NVe,DVe,GVe,sh,KW,OVe,qVe,NL,zVe,XVe,WVe,lh,YW,VVe,QVe,DL,HVe,UVe,JVe,ih,ZW,KVe,YVe,GL,ZVe,eQe,oQe,dh,eV,tQe,rQe,OL,aQe,nQe,sQe,mh,oV,lQe,iQe,qL,dQe,mQe,fQe,fh,tV,cQe,gQe,zL,hQe,uQe,pQe,ch,rV,_Qe,vQe,XL,bQe,TQe,FQe,gh,aV,MQe,EQe,WL,CQe,yQe,wQe,hh,nV,AQe,xQe,VL,LQe,BQe,kQe,uh,sV,RQe,SQe,QL,PQe,$Qe,IQe,ph,lV,jQe,NQe,HL,DQe,GQe,OQe,_h,iV,qQe,zQe,UL,XQe,WQe,VQe,vh,dV,QQe,HQe,JL,UQe,JQe,KQe,bh,mV,YQe,ZQe,KL,eHe,oHe,tHe,Th,fV,rHe,aHe,YL,nHe,sHe,lHe,Fh,cV,iHe,dHe,ZL,mHe,fHe,cHe,Mh,gV,gHe,hHe,eB,uHe,pHe,_He,Eh,hV,vHe,bHe,oB,THe,FHe,MHe,Ch,uV,EHe,CHe,tB,yHe,wHe,AHe,yh,pV,xHe,LHe,rB,BHe,kHe,RHe,wh,_V,SHe,PHe,aB,$He,IHe,jHe,Ah,NHe,vV,DHe,GHe,bV,OHe,qHe,TV,zHe,XHe,pM,PEe,di,xh,FV,_M,WHe,MV,VHe,$Ee,$o,vM,QHe,mi,HHe,EV,UHe,JHe,CV,KHe,YHe,ZHe,bM,eUe,yV,oUe,tUe,rUe,At,TM,aUe,wV,nUe,sUe,fi,lUe,AV,iUe,dUe,xV,mUe,fUe,cUe,LV,gUe,hUe,FM,uUe,Le,MM,pUe,BV,_Ue,vUe,Ca,bUe,kV,TUe,FUe,RV,MUe,EUe,SV,CUe,yUe,wUe,k,Lh,PV,AUe,xUe,nB,LUe,BUe,kUe,Bh,$V,RUe,SUe,sB,PUe,$Ue,IUe,kh,IV,jUe,NUe,lB,DUe,GUe,OUe,Rh,jV,qUe,zUe,iB,XUe,WUe,VUe,Sh,NV,QUe,HUe,dB,UUe,JUe,KUe,Ph,DV,YUe,ZUe,mB,eJe,oJe,tJe,$h,GV,rJe,aJe,fB,nJe,sJe,lJe,Ih,OV,iJe,dJe,cB,mJe,fJe,cJe,jh,qV,gJe,hJe,gB,uJe,pJe,_Je,Nh,zV,vJe,bJe,hB,TJe,FJe,MJe,Dh,XV,EJe,CJe,uB,yJe,wJe,AJe,Gh,WV,xJe,LJe,pB,BJe,kJe,RJe,Oh,VV,SJe,PJe,_B,$Je,IJe,jJe,qh,QV,NJe,DJe,vB,GJe,OJe,qJe,zh,HV,zJe,XJe,bB,WJe,VJe,QJe,Xh,UV,HJe,UJe,TB,JJe,KJe,YJe,Wh,JV,ZJe,eKe,FB,oKe,tKe,rKe,Vh,KV,aKe,nKe,MB,sKe,lKe,iKe,Qh,YV,dKe,mKe,EB,fKe,cKe,gKe,Hh,ZV,hKe,uKe,CB,pKe,_Ke,vKe,Uh,eQ,bKe,TKe,yB,FKe,MKe,EKe,Jh,oQ,CKe,yKe,wB,wKe,AKe,xKe,Kh,tQ,LKe,BKe,AB,kKe,RKe,SKe,Yh,rQ,PKe,$Ke,xB,IKe,jKe,NKe,Zh,aQ,DKe,GKe,LB,OKe,qKe,zKe,eu,nQ,XKe,WKe,BB,VKe,QKe,HKe,ou,sQ,UKe,JKe,kB,KKe,YKe,ZKe,tu,lQ,eYe,oYe,RB,tYe,rYe,aYe,ru,iQ,nYe,sYe,SB,lYe,iYe,dYe,au,dQ,mYe,fYe,PB,cYe,gYe,hYe,nu,mQ,uYe,pYe,$B,_Ye,vYe,bYe,su,fQ,TYe,FYe,IB,MYe,EYe,CYe,lu,cQ,yYe,wYe,jB,AYe,xYe,LYe,iu,gQ,BYe,kYe,NB,RYe,SYe,PYe,du,hQ,$Ye,IYe,DB,jYe,NYe,DYe,mu,uQ,GYe,OYe,GB,qYe,zYe,XYe,fu,WYe,pQ,VYe,QYe,_Q,HYe,UYe,vQ,JYe,KYe,EM,IEe,ci,cu,bQ,CM,YYe,TQ,ZYe,jEe,Io,yM,eZe,gi,oZe,FQ,tZe,rZe,MQ,aZe,nZe,sZe,wM,lZe,EQ,iZe,dZe,mZe,xt,AM,fZe,CQ,cZe,gZe,hi,hZe,yQ,uZe,pZe,wQ,_Ze,vZe,bZe,AQ,TZe,FZe,xM,MZe,Be,LM,EZe,xQ,CZe,yZe,ya,wZe,LQ,AZe,xZe,BQ,LZe,BZe,kQ,kZe,RZe,SZe,I,gu,RQ,PZe,$Ze,OB,IZe,jZe,NZe,hu,SQ,DZe,GZe,qB,OZe,qZe,zZe,uu,PQ,XZe,WZe,zB,VZe,QZe,HZe,pu,$Q,UZe,JZe,XB,KZe,YZe,ZZe,_u,IQ,eeo,oeo,WB,teo,reo,aeo,vu,jQ,neo,seo,VB,leo,ieo,deo,bu,NQ,meo,feo,QB,ceo,geo,heo,Tu,DQ,ueo,peo,HB,_eo,veo,beo,Fu,GQ,Teo,Feo,UB,Meo,Eeo,Ceo,Mu,OQ,yeo,weo,JB,Aeo,xeo,Leo,Eu,qQ,Beo,keo,KB,Reo,Seo,Peo,Cu,zQ,$eo,Ieo,YB,jeo,Neo,Deo,yu,XQ,Geo,Oeo,ZB,qeo,zeo,Xeo,wu,WQ,Weo,Veo,e9,Qeo,Heo,Ueo,Au,VQ,Jeo,Keo,o9,Yeo,Zeo,eoo,xu,QQ,ooo,too,t9,roo,aoo,noo,Lu,HQ,soo,loo,r9,ioo,doo,moo,Bu,UQ,foo,coo,a9,goo,hoo,uoo,ku,JQ,poo,_oo,n9,voo,boo,Too,Ru,KQ,Foo,Moo,s9,Eoo,Coo,yoo,Su,YQ,woo,Aoo,l9,xoo,Loo,Boo,Pu,ZQ,koo,Roo,i9,Soo,Poo,$oo,$u,eH,Ioo,joo,d9,Noo,Doo,Goo,Iu,oH,Ooo,qoo,m9,zoo,Xoo,Woo,ju,tH,Voo,Qoo,f9,Hoo,Uoo,Joo,Nu,rH,Koo,Yoo,c9,Zoo,eto,oto,Du,aH,tto,rto,g9,ato,nto,sto,Gu,nH,lto,ito,h9,dto,mto,fto,Ou,sH,cto,gto,u9,hto,uto,pto,qu,lH,_to,vto,p9,bto,Tto,Fto,zu,Mto,iH,Eto,Cto,dH,yto,wto,mH,Ato,xto,BM,NEe,ui,Xu,fH,kM,Lto,cH,Bto,DEe,jo,RM,kto,pi,Rto,gH,Sto,Pto,hH,$to,Ito,jto,SM,Nto,uH,Dto,Gto,Oto,Lt,PM,qto,pH,zto,Xto,_i,Wto,_H,Vto,Qto,vH,Hto,Uto,Jto,bH,Kto,Yto,$M,Zto,ke,IM,ero,TH,oro,tro,wa,rro,FH,aro,nro,MH,sro,lro,EH,iro,dro,mro,$,Wu,CH,fro,cro,_9,gro,hro,uro,Vu,yH,pro,_ro,v9,vro,bro,Tro,Qu,wH,Fro,Mro,b9,Ero,Cro,yro,Hu,AH,wro,Aro,T9,xro,Lro,Bro,Uu,xH,kro,Rro,F9,Sro,Pro,$ro,Ju,LH,Iro,jro,M9,Nro,Dro,Gro,Ku,BH,Oro,qro,E9,zro,Xro,Wro,Yu,kH,Vro,Qro,C9,Hro,Uro,Jro,Zu,RH,Kro,Yro,y9,Zro,eao,oao,ep,SH,tao,rao,w9,aao,nao,sao,op,PH,lao,iao,A9,dao,mao,fao,tp,$H,cao,gao,x9,hao,uao,pao,rp,IH,_ao,vao,L9,bao,Tao,Fao,ap,jH,Mao,Eao,B9,Cao,yao,wao,np,NH,Aao,xao,k9,Lao,Bao,kao,sp,DH,Rao,Sao,R9,Pao,$ao,Iao,lp,GH,jao,Nao,S9,Dao,Gao,Oao,ip,OH,qao,zao,P9,Xao,Wao,Vao,dp,qH,Qao,Hao,$9,Uao,Jao,Kao,mp,zH,Yao,Zao,I9,eno,ono,tno,fp,XH,rno,ano,j9,nno,sno,lno,cp,WH,ino,dno,N9,mno,fno,cno,gp,VH,gno,hno,D9,uno,pno,_no,hp,QH,vno,bno,G9,Tno,Fno,Mno,up,HH,Eno,Cno,O9,yno,wno,Ano,pp,UH,xno,Lno,q9,Bno,kno,Rno,_p,JH,Sno,Pno,z9,$no,Ino,jno,vp,KH,Nno,Dno,X9,Gno,Ono,qno,bp,YH,zno,Xno,ZH,Wno,Vno,Qno,Tp,eU,Hno,Uno,W9,Jno,Kno,Yno,Fp,oU,Zno,eso,V9,oso,tso,rso,Mp,aso,tU,nso,sso,rU,lso,iso,aU,dso,mso,jM,GEe,vi,Ep,nU,NM,fso,sU,cso,OEe,No,DM,gso,bi,hso,lU,uso,pso,iU,_so,vso,bso,GM,Tso,dU,Fso,Mso,Eso,Bt,OM,Cso,mU,yso,wso,Ti,Aso,fU,xso,Lso,cU,Bso,kso,Rso,gU,Sso,Pso,qM,$so,Re,zM,Iso,hU,jso,Nso,Aa,Dso,uU,Gso,Oso,pU,qso,zso,_U,Xso,Wso,Vso,ne,Cp,vU,Qso,Hso,Q9,Uso,Jso,Kso,yp,bU,Yso,Zso,H9,elo,olo,tlo,wp,TU,rlo,alo,U9,nlo,slo,llo,Ap,FU,ilo,dlo,J9,mlo,flo,clo,xp,MU,glo,hlo,K9,ulo,plo,_lo,Lp,EU,vlo,blo,Y9,Tlo,Flo,Mlo,Bp,CU,Elo,Clo,Z9,ylo,wlo,Alo,kp,yU,xlo,Llo,ek,Blo,klo,Rlo,Rp,wU,Slo,Plo,ok,$lo,Ilo,jlo,Sp,AU,Nlo,Dlo,tk,Glo,Olo,qlo,Pp,xU,zlo,Xlo,rk,Wlo,Vlo,Qlo,$p,LU,Hlo,Ulo,ak,Jlo,Klo,Ylo,Ip,BU,Zlo,eio,nk,oio,tio,rio,jp,kU,aio,nio,sk,sio,lio,iio,Np,RU,dio,mio,lk,fio,cio,gio,Dp,hio,SU,uio,pio,PU,_io,vio,$U,bio,Tio,XM,qEe,Fi,Gp,IU,WM,Fio,jU,Mio,zEe,Do,VM,Eio,Mi,Cio,NU,yio,wio,DU,Aio,xio,Lio,QM,Bio,GU,kio,Rio,Sio,kt,HM,Pio,OU,$io,Iio,Ei,jio,qU,Nio,Dio,zU,Gio,Oio,qio,XU,zio,Xio,UM,Wio,Se,JM,Vio,WU,Qio,Hio,xa,Uio,VU,Jio,Kio,QU,Yio,Zio,HU,edo,odo,tdo,A,Op,UU,rdo,ado,ik,ndo,sdo,ldo,qp,JU,ido,ddo,dk,mdo,fdo,cdo,zp,KU,gdo,hdo,mk,udo,pdo,_do,Xp,YU,vdo,bdo,fk,Tdo,Fdo,Mdo,Wp,ZU,Edo,Cdo,ck,ydo,wdo,Ado,Vp,eJ,xdo,Ldo,gk,Bdo,kdo,Rdo,Qp,oJ,Sdo,Pdo,hk,$do,Ido,jdo,Hp,tJ,Ndo,Ddo,uk,Gdo,Odo,qdo,Up,rJ,zdo,Xdo,pk,Wdo,Vdo,Qdo,Jp,aJ,Hdo,Udo,_k,Jdo,Kdo,Ydo,Kp,nJ,Zdo,emo,vk,omo,tmo,rmo,Yp,sJ,amo,nmo,bk,smo,lmo,imo,Zp,lJ,dmo,mmo,Tk,fmo,cmo,gmo,e_,iJ,hmo,umo,Fk,pmo,_mo,vmo,o_,dJ,bmo,Tmo,Mk,Fmo,Mmo,Emo,t_,mJ,Cmo,ymo,Ek,wmo,Amo,xmo,r_,fJ,Lmo,Bmo,Ck,kmo,Rmo,Smo,a_,cJ,Pmo,$mo,yk,Imo,jmo,Nmo,n_,gJ,Dmo,Gmo,wk,Omo,qmo,zmo,s_,hJ,Xmo,Wmo,Ak,Vmo,Qmo,Hmo,l_,uJ,Umo,Jmo,xk,Kmo,Ymo,Zmo,i_,pJ,efo,ofo,Lk,tfo,rfo,afo,d_,_J,nfo,sfo,Bk,lfo,ifo,dfo,m_,vJ,mfo,ffo,kk,cfo,gfo,hfo,f_,bJ,ufo,pfo,Rk,_fo,vfo,bfo,c_,TJ,Tfo,Ffo,Sk,Mfo,Efo,Cfo,g_,FJ,yfo,wfo,Pk,Afo,xfo,Lfo,h_,MJ,Bfo,kfo,$k,Rfo,Sfo,Pfo,u_,EJ,$fo,Ifo,Ik,jfo,Nfo,Dfo,p_,CJ,Gfo,Ofo,jk,qfo,zfo,Xfo,__,yJ,Wfo,Vfo,Nk,Qfo,Hfo,Ufo,v_,wJ,Jfo,Kfo,Dk,Yfo,Zfo,eco,b_,AJ,oco,tco,Gk,rco,aco,nco,T_,xJ,sco,lco,Ok,ico,dco,mco,F_,LJ,fco,cco,qk,gco,hco,uco,M_,BJ,pco,_co,zk,vco,bco,Tco,E_,kJ,Fco,Mco,Xk,Eco,Cco,yco,C_,RJ,wco,Aco,Wk,xco,Lco,Bco,y_,SJ,kco,Rco,Vk,Sco,Pco,$co,w_,PJ,Ico,jco,Qk,Nco,Dco,Gco,A_,$J,Oco,qco,Hk,zco,Xco,Wco,x_,Vco,IJ,Qco,Hco,jJ,Uco,Jco,NJ,Kco,Yco,KM,XEe,Ci,L_,DJ,YM,Zco,GJ,ego,WEe,Go,ZM,ogo,yi,tgo,OJ,rgo,ago,qJ,ngo,sgo,lgo,eE,igo,zJ,dgo,mgo,fgo,Rt,oE,cgo,XJ,ggo,hgo,wi,ugo,WJ,pgo,_go,VJ,vgo,bgo,Tgo,QJ,Fgo,Mgo,tE,Ego,Pe,rE,Cgo,HJ,ygo,wgo,La,Ago,UJ,xgo,Lgo,JJ,Bgo,kgo,KJ,Rgo,Sgo,Pgo,q,B_,YJ,$go,Igo,Uk,jgo,Ngo,Dgo,k_,ZJ,Ggo,Ogo,Jk,qgo,zgo,Xgo,R_,eK,Wgo,Vgo,Kk,Qgo,Hgo,Ugo,S_,oK,Jgo,Kgo,Yk,Ygo,Zgo,eho,P_,tK,oho,tho,Zk,rho,aho,nho,$_,rK,sho,lho,eR,iho,dho,mho,I_,aK,fho,cho,oR,gho,hho,uho,j_,nK,pho,_ho,tR,vho,bho,Tho,N_,sK,Fho,Mho,rR,Eho,Cho,yho,D_,lK,who,Aho,aR,xho,Lho,Bho,G_,iK,kho,Rho,nR,Sho,Pho,$ho,O_,dK,Iho,jho,sR,Nho,Dho,Gho,q_,mK,Oho,qho,lR,zho,Xho,Who,z_,fK,Vho,Qho,iR,Hho,Uho,Jho,X_,cK,Kho,Yho,dR,Zho,euo,ouo,W_,gK,tuo,ruo,mR,auo,nuo,suo,V_,hK,luo,iuo,fR,duo,muo,fuo,Q_,uK,cuo,guo,cR,huo,uuo,puo,H_,pK,_uo,vuo,gR,buo,Tuo,Fuo,U_,_K,Muo,Euo,hR,Cuo,yuo,wuo,J_,vK,Auo,xuo,uR,Luo,Buo,kuo,K_,bK,Ruo,Suo,pR,Puo,$uo,Iuo,Y_,TK,juo,Nuo,_R,Duo,Guo,Ouo,Z_,FK,quo,zuo,vR,Xuo,Wuo,Vuo,ev,Quo,MK,Huo,Uuo,EK,Juo,Kuo,CK,Yuo,Zuo,aE,VEe,Ai,ov,yK,nE,epo,wK,opo,QEe,Oo,sE,tpo,xi,rpo,AK,apo,npo,xK,spo,lpo,ipo,lE,dpo,LK,mpo,fpo,cpo,St,iE,gpo,BK,hpo,upo,Li,ppo,kK,_po,vpo,RK,bpo,Tpo,Fpo,SK,Mpo,Epo,dE,Cpo,$e,mE,ypo,PK,wpo,Apo,Ba,xpo,$K,Lpo,Bpo,IK,kpo,Rpo,jK,Spo,Ppo,$po,qr,tv,NK,Ipo,jpo,bR,Npo,Dpo,Gpo,rv,DK,Opo,qpo,TR,zpo,Xpo,Wpo,av,GK,Vpo,Qpo,FR,Hpo,Upo,Jpo,nv,OK,Kpo,Ypo,MR,Zpo,e_o,o_o,sv,qK,t_o,r_o,ER,a_o,n_o,s_o,lv,l_o,zK,i_o,d_o,XK,m_o,f_o,WK,c_o,g_o,fE,HEe,Bi,iv,VK,cE,h_o,QK,u_o,UEe,qo,gE,p_o,ki,__o,HK,v_o,b_o,UK,T_o,F_o,M_o,hE,E_o,JK,C_o,y_o,w_o,Pt,uE,A_o,KK,x_o,L_o,Ri,B_o,YK,k_o,R_o,ZK,S_o,P_o,$_o,eY,I_o,j_o,pE,N_o,Ie,_E,D_o,oY,G_o,O_o,ka,q_o,tY,z_o,X_o,rY,W_o,V_o,aY,Q_o,H_o,U_o,N,dv,nY,J_o,K_o,CR,Y_o,Z_o,evo,mv,sY,ovo,tvo,yR,rvo,avo,nvo,fv,lY,svo,lvo,wR,ivo,dvo,mvo,cv,iY,fvo,cvo,AR,gvo,hvo,uvo,gv,dY,pvo,_vo,xR,vvo,bvo,Tvo,hv,mY,Fvo,Mvo,LR,Evo,Cvo,yvo,uv,fY,wvo,Avo,BR,xvo,Lvo,Bvo,pv,cY,kvo,Rvo,kR,Svo,Pvo,$vo,_v,gY,Ivo,jvo,RR,Nvo,Dvo,Gvo,vv,hY,Ovo,qvo,SR,zvo,Xvo,Wvo,bv,uY,Vvo,Qvo,PR,Hvo,Uvo,Jvo,Tv,pY,Kvo,Yvo,$R,Zvo,e1o,o1o,Fv,_Y,t1o,r1o,IR,a1o,n1o,s1o,Mv,vY,l1o,i1o,jR,d1o,m1o,f1o,Ev,bY,c1o,g1o,NR,h1o,u1o,p1o,Cv,TY,_1o,v1o,DR,b1o,T1o,F1o,yv,FY,M1o,E1o,GR,C1o,y1o,w1o,wv,MY,A1o,x1o,OR,L1o,B1o,k1o,Av,EY,R1o,S1o,qR,P1o,$1o,I1o,xv,CY,j1o,N1o,zR,D1o,G1o,O1o,Lv,yY,q1o,z1o,XR,X1o,W1o,V1o,Bv,wY,Q1o,H1o,WR,U1o,J1o,K1o,kv,AY,Y1o,Z1o,VR,e2o,o2o,t2o,Rv,xY,r2o,a2o,QR,n2o,s2o,l2o,Sv,LY,i2o,d2o,HR,m2o,f2o,c2o,Pv,BY,g2o,h2o,UR,u2o,p2o,_2o,$v,kY,v2o,b2o,JR,T2o,F2o,M2o,Iv,RY,E2o,C2o,KR,y2o,w2o,A2o,jv,SY,x2o,L2o,YR,B2o,k2o,R2o,Nv,S2o,PY,P2o,$2o,$Y,I2o,j2o,IY,N2o,D2o,vE,JEe,Si,Dv,jY,bE,G2o,NY,O2o,KEe,zo,TE,q2o,Pi,z2o,DY,X2o,W2o,GY,V2o,Q2o,H2o,FE,U2o,OY,J2o,K2o,Y2o,$t,ME,Z2o,qY,ebo,obo,$i,tbo,zY,rbo,abo,XY,nbo,sbo,lbo,WY,ibo,dbo,EE,mbo,je,CE,fbo,VY,cbo,gbo,Ra,hbo,QY,ubo,pbo,HY,_bo,vbo,UY,bbo,Tbo,Fbo,R,Gv,JY,Mbo,Ebo,ZR,Cbo,ybo,wbo,Ov,KY,Abo,xbo,eS,Lbo,Bbo,kbo,qv,YY,Rbo,Sbo,oS,Pbo,$bo,Ibo,zv,ZY,jbo,Nbo,tS,Dbo,Gbo,Obo,Xv,eZ,qbo,zbo,rS,Xbo,Wbo,Vbo,Wv,oZ,Qbo,Hbo,aS,Ubo,Jbo,Kbo,Vv,tZ,Ybo,Zbo,nS,e4o,o4o,t4o,Qv,rZ,r4o,a4o,sS,n4o,s4o,l4o,Hv,aZ,i4o,d4o,lS,m4o,f4o,c4o,Uv,nZ,g4o,h4o,iS,u4o,p4o,_4o,Jv,sZ,v4o,b4o,dS,T4o,F4o,M4o,Kv,lZ,E4o,C4o,mS,y4o,w4o,A4o,Yv,iZ,x4o,L4o,fS,B4o,k4o,R4o,Zv,dZ,S4o,P4o,cS,$4o,I4o,j4o,e1,mZ,N4o,D4o,gS,G4o,O4o,q4o,o1,fZ,z4o,X4o,hS,W4o,V4o,Q4o,t1,cZ,H4o,U4o,uS,J4o,K4o,Y4o,r1,gZ,Z4o,e5o,pS,o5o,t5o,r5o,a1,hZ,a5o,n5o,_S,s5o,l5o,i5o,n1,uZ,d5o,m5o,vS,f5o,c5o,g5o,s1,pZ,h5o,u5o,bS,p5o,_5o,v5o,l1,_Z,b5o,T5o,TS,F5o,M5o,E5o,i1,vZ,C5o,y5o,FS,w5o,A5o,x5o,d1,bZ,L5o,B5o,MS,k5o,R5o,S5o,m1,TZ,P5o,$5o,ES,I5o,j5o,N5o,f1,FZ,D5o,G5o,CS,O5o,q5o,z5o,c1,MZ,X5o,W5o,yS,V5o,Q5o,H5o,g1,EZ,U5o,J5o,wS,K5o,Y5o,Z5o,h1,CZ,e0o,o0o,AS,t0o,r0o,a0o,u1,yZ,n0o,s0o,xS,l0o,i0o,d0o,p1,wZ,m0o,f0o,LS,c0o,g0o,h0o,_1,AZ,u0o,p0o,BS,_0o,v0o,b0o,v1,xZ,T0o,F0o,kS,M0o,E0o,C0o,b1,LZ,y0o,w0o,RS,A0o,x0o,L0o,T1,BZ,B0o,k0o,SS,R0o,S0o,P0o,F1,$0o,kZ,I0o,j0o,RZ,N0o,D0o,SZ,G0o,O0o,yE,YEe,Ii,M1,PZ,wE,q0o,$Z,z0o,ZEe,Xo,AE,X0o,ji,W0o,IZ,V0o,Q0o,jZ,H0o,U0o,J0o,xE,K0o,NZ,Y0o,Z0o,eTo,It,LE,oTo,DZ,tTo,rTo,Ni,aTo,GZ,nTo,sTo,OZ,lTo,iTo,dTo,qZ,mTo,fTo,BE,cTo,Ne,kE,gTo,zZ,hTo,uTo,Sa,pTo,XZ,_To,vTo,WZ,bTo,TTo,VZ,FTo,MTo,ETo,QZ,E1,HZ,CTo,yTo,PS,wTo,ATo,xTo,C1,LTo,UZ,BTo,kTo,JZ,RTo,STo,KZ,PTo,$To,RE,eCe,Di,y1,YZ,SE,ITo,ZZ,jTo,oCe,Wo,PE,NTo,Gi,DTo,eee,GTo,OTo,oee,qTo,zTo,XTo,$E,WTo,tee,VTo,QTo,HTo,jt,IE,UTo,ree,JTo,KTo,Oi,YTo,aee,ZTo,eFo,nee,oFo,tFo,rFo,see,aFo,nFo,jE,sFo,De,NE,lFo,lee,iFo,dFo,Pa,mFo,iee,fFo,cFo,dee,gFo,hFo,mee,uFo,pFo,_Fo,Vo,w1,fee,vFo,bFo,$S,TFo,FFo,MFo,is,cee,EFo,CFo,IS,yFo,wFo,jS,AFo,xFo,LFo,A1,gee,BFo,kFo,NS,RFo,SFo,PFo,Xr,hee,$Fo,IFo,DS,jFo,NFo,GS,DFo,GFo,OS,OFo,qFo,zFo,x1,uee,XFo,WFo,qS,VFo,QFo,HFo,L1,pee,UFo,JFo,zS,KFo,YFo,ZFo,B1,eMo,_ee,oMo,tMo,vee,rMo,aMo,bee,nMo,sMo,DE,tCe,qi,k1,Tee,GE,lMo,Fee,iMo,rCe,Qo,OE,dMo,zi,mMo,Mee,fMo,cMo,Eee,gMo,hMo,uMo,qE,pMo,Cee,_Mo,vMo,bMo,Nt,zE,TMo,yee,FMo,MMo,Xi,EMo,wee,CMo,yMo,Aee,wMo,AMo,xMo,xee,LMo,BMo,XE,kMo,Ge,WE,RMo,Lee,SMo,PMo,$a,$Mo,Bee,IMo,jMo,kee,NMo,DMo,Ree,GMo,OMo,qMo,See,R1,Pee,zMo,XMo,XS,WMo,VMo,QMo,S1,HMo,$ee,UMo,JMo,Iee,KMo,YMo,jee,ZMo,eEo,VE,aCe,Wi,P1,Nee,QE,oEo,Dee,tEo,nCe,Ho,HE,rEo,Vi,aEo,Gee,nEo,sEo,Oee,lEo,iEo,dEo,UE,mEo,qee,fEo,cEo,gEo,Dt,JE,hEo,zee,uEo,pEo,Qi,_Eo,Xee,vEo,bEo,Wee,TEo,FEo,MEo,Vee,EEo,CEo,KE,yEo,Oe,YE,wEo,Qee,AEo,xEo,Ia,LEo,Hee,BEo,kEo,Uee,REo,SEo,Jee,PEo,$Eo,IEo,Ke,$1,Kee,jEo,NEo,WS,DEo,GEo,OEo,I1,Yee,qEo,zEo,VS,XEo,WEo,VEo,j1,Zee,QEo,HEo,QS,UEo,JEo,KEo,N1,eoe,YEo,ZEo,HS,eCo,oCo,tCo,D1,ooe,rCo,aCo,US,nCo,sCo,lCo,G1,toe,iCo,dCo,JS,mCo,fCo,cCo,O1,roe,gCo,hCo,KS,uCo,pCo,_Co,q1,vCo,aoe,bCo,TCo,noe,FCo,MCo,soe,ECo,CCo,ZE,sCe,Hi,z1,loe,eC,yCo,ioe,wCo,lCe,Uo,oC,ACo,Ui,xCo,doe,LCo,BCo,moe,kCo,RCo,SCo,tC,PCo,foe,$Co,ICo,jCo,Gt,rC,NCo,coe,DCo,GCo,Ji,OCo,goe,qCo,zCo,hoe,XCo,WCo,VCo,uoe,QCo,HCo,aC,UCo,qe,nC,JCo,poe,KCo,YCo,ja,ZCo,_oe,e3o,o3o,voe,t3o,r3o,boe,a3o,n3o,s3o,Ki,X1,Toe,l3o,i3o,YS,d3o,m3o,f3o,W1,Foe,c3o,g3o,ZS,h3o,u3o,p3o,V1,Moe,_3o,v3o,eP,b3o,T3o,F3o,Q1,M3o,Eoe,E3o,C3o,Coe,y3o,w3o,yoe,A3o,x3o,sC,iCe,Yi,H1,woe,lC,L3o,Aoe,B3o,dCe,Jo,iC,k3o,Zi,R3o,xoe,S3o,P3o,Loe,$3o,I3o,j3o,dC,N3o,Boe,D3o,G3o,O3o,Ot,mC,q3o,koe,z3o,X3o,ed,W3o,Roe,V3o,Q3o,Soe,H3o,U3o,J3o,Poe,K3o,Y3o,fC,Z3o,ze,cC,eyo,$oe,oyo,tyo,Na,ryo,Ioe,ayo,nyo,joe,syo,lyo,Noe,iyo,dyo,myo,Ye,U1,Doe,fyo,cyo,oP,gyo,hyo,uyo,J1,Goe,pyo,_yo,tP,vyo,byo,Tyo,K1,Ooe,Fyo,Myo,rP,Eyo,Cyo,yyo,Y1,qoe,wyo,Ayo,aP,xyo,Lyo,Byo,Z1,zoe,kyo,Ryo,nP,Syo,Pyo,$yo,e2,Xoe,Iyo,jyo,sP,Nyo,Dyo,Gyo,o2,Woe,Oyo,qyo,lP,zyo,Xyo,Wyo,t2,Vyo,Voe,Qyo,Hyo,Qoe,Uyo,Jyo,Hoe,Kyo,Yyo,gC,mCe,od,r2,Uoe,hC,Zyo,Joe,ewo,fCe,Ko,uC,owo,td,two,Koe,rwo,awo,Yoe,nwo,swo,lwo,pC,iwo,Zoe,dwo,mwo,fwo,qt,_C,cwo,ete,gwo,hwo,rd,uwo,ote,pwo,_wo,tte,vwo,bwo,Two,rte,Fwo,Mwo,vC,Ewo,Xe,bC,Cwo,ate,ywo,wwo,Da,Awo,nte,xwo,Lwo,ste,Bwo,kwo,lte,Rwo,Swo,Pwo,TC,a2,ite,$wo,Iwo,iP,jwo,Nwo,Dwo,n2,dte,Gwo,Owo,dP,qwo,zwo,Xwo,s2,Wwo,mte,Vwo,Qwo,fte,Hwo,Uwo,cte,Jwo,Kwo,FC,cCe,ad,l2,gte,MC,Ywo,hte,Zwo,gCe,Yo,EC,eAo,nd,oAo,ute,tAo,rAo,pte,aAo,nAo,sAo,CC,lAo,_te,iAo,dAo,mAo,zt,yC,fAo,vte,cAo,gAo,sd,hAo,bte,uAo,pAo,Tte,_Ao,vAo,bAo,Fte,TAo,FAo,wC,MAo,We,AC,EAo,Mte,CAo,yAo,Ga,wAo,Ete,AAo,xAo,Cte,LAo,BAo,yte,kAo,RAo,SAo,ld,i2,wte,PAo,$Ao,mP,IAo,jAo,NAo,d2,Ate,DAo,GAo,fP,OAo,qAo,zAo,m2,xte,XAo,WAo,cP,VAo,QAo,HAo,f2,UAo,Lte,JAo,KAo,Bte,YAo,ZAo,kte,e7o,o7o,xC,hCe,id,c2,Rte,LC,t7o,Ste,r7o,uCe,Zo,BC,a7o,dd,n7o,Pte,s7o,l7o,$te,i7o,d7o,m7o,kC,f7o,Ite,c7o,g7o,h7o,Xt,RC,u7o,jte,p7o,_7o,md,v7o,Nte,b7o,T7o,Dte,F7o,M7o,E7o,Gte,C7o,y7o,SC,w7o,Ve,PC,A7o,Ote,x7o,L7o,Oa,B7o,qte,k7o,R7o,zte,S7o,P7o,Xte,$7o,I7o,j7o,Wte,g2,Vte,N7o,D7o,gP,G7o,O7o,q7o,h2,z7o,Qte,X7o,W7o,Hte,V7o,Q7o,Ute,H7o,U7o,$C,pCe,fd,u2,Jte,IC,J7o,Kte,K7o,_Ce,et,jC,Y7o,cd,Z7o,Yte,exo,oxo,Zte,txo,rxo,axo,NC,nxo,ere,sxo,lxo,ixo,Wt,DC,dxo,ore,mxo,fxo,gd,cxo,tre,gxo,hxo,rre,uxo,pxo,_xo,are,vxo,bxo,GC,Txo,Qe,OC,Fxo,nre,Mxo,Exo,qa,Cxo,sre,yxo,wxo,lre,Axo,xxo,ire,Lxo,Bxo,kxo,dre,p2,mre,Rxo,Sxo,hP,Pxo,$xo,Ixo,_2,jxo,fre,Nxo,Dxo,cre,Gxo,Oxo,gre,qxo,zxo,qC,vCe,hd,v2,hre,zC,Xxo,ure,Wxo,bCe,ot,XC,Vxo,ud,Qxo,pre,Hxo,Uxo,_re,Jxo,Kxo,Yxo,WC,Zxo,vre,e6o,o6o,t6o,Vt,VC,r6o,bre,a6o,n6o,pd,s6o,Tre,l6o,i6o,Fre,d6o,m6o,f6o,Mre,c6o,g6o,QC,h6o,ro,HC,u6o,Ere,p6o,_6o,za,v6o,Cre,b6o,T6o,yre,F6o,M6o,wre,E6o,C6o,y6o,L,b2,Are,w6o,A6o,uP,x6o,L6o,B6o,T2,xre,k6o,R6o,pP,S6o,P6o,$6o,F2,Lre,I6o,j6o,_P,N6o,D6o,G6o,M2,Bre,O6o,q6o,vP,z6o,X6o,W6o,E2,kre,V6o,Q6o,bP,H6o,U6o,J6o,C2,Rre,K6o,Y6o,TP,Z6o,e8o,o8o,y2,Sre,t8o,r8o,FP,a8o,n8o,s8o,w2,Pre,l8o,i8o,MP,d8o,m8o,f8o,A2,$re,c8o,g8o,EP,h8o,u8o,p8o,x2,Ire,_8o,v8o,CP,b8o,T8o,F8o,L2,jre,M8o,E8o,yP,C8o,y8o,w8o,B2,Nre,A8o,x8o,wP,L8o,B8o,k8o,k2,Dre,R8o,S8o,AP,P8o,$8o,I8o,R2,Gre,j8o,N8o,xP,D8o,G8o,O8o,ds,Ore,q8o,z8o,LP,X8o,W8o,BP,V8o,Q8o,H8o,S2,qre,U8o,J8o,kP,K8o,Y8o,Z8o,P2,zre,eLo,oLo,RP,tLo,rLo,aLo,$2,Xre,nLo,sLo,SP,lLo,iLo,dLo,I2,Wre,mLo,fLo,PP,cLo,gLo,hLo,j2,Vre,uLo,pLo,$P,_Lo,vLo,bLo,N2,Qre,TLo,FLo,IP,MLo,ELo,CLo,D2,Hre,yLo,wLo,jP,ALo,xLo,LLo,G2,Ure,BLo,kLo,NP,RLo,SLo,PLo,O2,Jre,$Lo,ILo,DP,jLo,NLo,DLo,q2,Kre,GLo,OLo,GP,qLo,zLo,XLo,z2,Yre,WLo,VLo,OP,QLo,HLo,ULo,X2,Zre,JLo,KLo,qP,YLo,ZLo,eBo,W2,eae,oBo,tBo,zP,rBo,aBo,nBo,V2,oae,sBo,lBo,XP,iBo,dBo,mBo,Q2,tae,fBo,cBo,WP,gBo,hBo,uBo,H2,rae,pBo,_Bo,VP,vBo,bBo,TBo,U2,aae,FBo,MBo,QP,EBo,CBo,yBo,J2,nae,wBo,ABo,HP,xBo,LBo,BBo,K2,sae,kBo,RBo,UP,SBo,PBo,$Bo,Y2,lae,IBo,jBo,JP,NBo,DBo,GBo,Z2,iae,OBo,qBo,KP,zBo,XBo,WBo,eb,dae,VBo,QBo,YP,HBo,UBo,JBo,ob,mae,KBo,YBo,ZP,ZBo,e9o,o9o,tb,fae,t9o,r9o,e$,a9o,n9o,s9o,cae,l9o,i9o,UC,TCe,_d,rb,gae,JC,d9o,hae,m9o,FCe,tt,KC,f9o,vd,c9o,uae,g9o,h9o,pae,u9o,p9o,_9o,YC,v9o,_ae,b9o,T9o,F9o,Qt,ZC,M9o,vae,E9o,C9o,bd,y9o,bae,w9o,A9o,Tae,x9o,L9o,B9o,Fae,k9o,R9o,e3,S9o,ao,o3,P9o,Mae,$9o,I9o,Xa,j9o,Eae,N9o,D9o,Cae,G9o,O9o,yae,q9o,z9o,X9o,V,ab,wae,W9o,V9o,o$,Q9o,H9o,U9o,nb,Aae,J9o,K9o,t$,Y9o,Z9o,eko,sb,xae,oko,tko,r$,rko,ako,nko,lb,Lae,sko,lko,a$,iko,dko,mko,ib,Bae,fko,cko,n$,gko,hko,uko,db,kae,pko,_ko,s$,vko,bko,Tko,mb,Rae,Fko,Mko,l$,Eko,Cko,yko,fb,Sae,wko,Ako,i$,xko,Lko,Bko,cb,Pae,kko,Rko,d$,Sko,Pko,$ko,gb,$ae,Iko,jko,m$,Nko,Dko,Gko,hb,Iae,Oko,qko,f$,zko,Xko,Wko,ub,jae,Vko,Qko,c$,Hko,Uko,Jko,pb,Nae,Kko,Yko,g$,Zko,eRo,oRo,_b,Dae,tRo,rRo,h$,aRo,nRo,sRo,vb,Gae,lRo,iRo,u$,dRo,mRo,fRo,bb,Oae,cRo,gRo,p$,hRo,uRo,pRo,Tb,qae,_Ro,vRo,_$,bRo,TRo,FRo,Fb,zae,MRo,ERo,v$,CRo,yRo,wRo,Mb,Xae,ARo,xRo,b$,LRo,BRo,kRo,Eb,Wae,RRo,SRo,T$,PRo,$Ro,IRo,Cb,Vae,jRo,NRo,F$,DRo,GRo,ORo,yb,Qae,qRo,zRo,M$,XRo,WRo,VRo,Hae,QRo,HRo,t3,MCe,Td,wb,Uae,r3,URo,Jae,JRo,ECe,rt,a3,KRo,Fd,YRo,Kae,ZRo,eSo,Yae,oSo,tSo,rSo,n3,aSo,Zae,nSo,sSo,lSo,Ht,s3,iSo,ene,dSo,mSo,Md,fSo,one,cSo,gSo,tne,hSo,uSo,pSo,rne,_So,vSo,l3,bSo,no,i3,TSo,ane,FSo,MSo,Wa,ESo,nne,CSo,ySo,sne,wSo,ASo,lne,xSo,LSo,BSo,ce,Ab,ine,kSo,RSo,E$,SSo,PSo,$So,xb,dne,ISo,jSo,C$,NSo,DSo,GSo,Lb,mne,OSo,qSo,y$,zSo,XSo,WSo,Bb,fne,VSo,QSo,w$,HSo,USo,JSo,kb,cne,KSo,YSo,A$,ZSo,ePo,oPo,Rb,gne,tPo,rPo,x$,aPo,nPo,sPo,Sb,hne,lPo,iPo,L$,dPo,mPo,fPo,Pb,une,cPo,gPo,B$,hPo,uPo,pPo,$b,pne,_Po,vPo,k$,bPo,TPo,FPo,Ib,_ne,MPo,EPo,R$,CPo,yPo,wPo,vne,APo,xPo,d3,CCe,Ed,jb,bne,m3,LPo,Tne,BPo,yCe,at,f3,kPo,Cd,RPo,Fne,SPo,PPo,Mne,$Po,IPo,jPo,c3,NPo,Ene,DPo,GPo,OPo,Ut,g3,qPo,Cne,zPo,XPo,yd,WPo,yne,VPo,QPo,wne,HPo,UPo,JPo,Ane,KPo,YPo,h3,ZPo,so,u3,e$o,xne,o$o,t$o,Va,r$o,Lne,a$o,n$o,Bne,s$o,l$o,kne,i$o,d$o,m$o,Rne,Nb,Sne,f$o,c$o,S$,g$o,h$o,u$o,Pne,p$o,_$o,p3,wCe,wd,Db,$ne,_3,v$o,Ine,b$o,ACe,nt,v3,T$o,Ad,F$o,jne,M$o,E$o,Nne,C$o,y$o,w$o,b3,A$o,Dne,x$o,L$o,B$o,Jt,T3,k$o,Gne,R$o,S$o,xd,P$o,One,$$o,I$o,qne,j$o,N$o,D$o,zne,G$o,O$o,F3,q$o,lo,M3,z$o,Xne,X$o,W$o,Qa,V$o,Wne,Q$o,H$o,Vne,U$o,J$o,Qne,K$o,Y$o,Z$o,K,Gb,Hne,eIo,oIo,P$,tIo,rIo,aIo,Ob,Une,nIo,sIo,$$,lIo,iIo,dIo,qb,Jne,mIo,fIo,I$,cIo,gIo,hIo,zb,Kne,uIo,pIo,j$,_Io,vIo,bIo,Xb,Yne,TIo,FIo,N$,MIo,EIo,CIo,Wb,Zne,yIo,wIo,D$,AIo,xIo,LIo,Vb,ese,BIo,kIo,G$,RIo,SIo,PIo,Qb,ose,$Io,IIo,O$,jIo,NIo,DIo,Hb,tse,GIo,OIo,q$,qIo,zIo,XIo,Ub,rse,WIo,VIo,z$,QIo,HIo,UIo,Jb,ase,JIo,KIo,X$,YIo,ZIo,ejo,Kb,nse,ojo,tjo,W$,rjo,ajo,njo,Yb,sse,sjo,ljo,V$,ijo,djo,mjo,Zb,lse,fjo,cjo,Q$,gjo,hjo,ujo,e4,ise,pjo,_jo,H$,vjo,bjo,Tjo,o4,dse,Fjo,Mjo,U$,Ejo,Cjo,yjo,t4,mse,wjo,Ajo,J$,xjo,Ljo,Bjo,r4,fse,kjo,Rjo,K$,Sjo,Pjo,$jo,a4,cse,Ijo,jjo,Y$,Njo,Djo,Gjo,n4,gse,Ojo,qjo,Z$,zjo,Xjo,Wjo,hse,Vjo,Qjo,E3,xCe,Ld,s4,use,C3,Hjo,pse,Ujo,LCe,st,y3,Jjo,Bd,Kjo,_se,Yjo,Zjo,vse,eNo,oNo,tNo,w3,rNo,bse,aNo,nNo,sNo,Kt,A3,lNo,Tse,iNo,dNo,kd,mNo,Fse,fNo,cNo,Mse,gNo,hNo,uNo,Ese,pNo,_No,x3,vNo,io,L3,bNo,Cse,TNo,FNo,Ha,MNo,yse,ENo,CNo,wse,yNo,wNo,Ase,ANo,xNo,LNo,ge,l4,xse,BNo,kNo,eI,RNo,SNo,PNo,i4,Lse,$No,INo,oI,jNo,NNo,DNo,d4,Bse,GNo,ONo,tI,qNo,zNo,XNo,m4,kse,WNo,VNo,rI,QNo,HNo,UNo,f4,Rse,JNo,KNo,aI,YNo,ZNo,eDo,c4,Sse,oDo,tDo,nI,rDo,aDo,nDo,g4,Pse,sDo,lDo,sI,iDo,dDo,mDo,h4,$se,fDo,cDo,lI,gDo,hDo,uDo,u4,Ise,pDo,_Do,iI,vDo,bDo,TDo,p4,jse,FDo,MDo,dI,EDo,CDo,yDo,Nse,wDo,ADo,B3,BCe,Rd,_4,Dse,k3,xDo,Gse,LDo,kCe,lt,R3,BDo,Sd,kDo,Ose,RDo,SDo,qse,PDo,$Do,IDo,S3,jDo,zse,NDo,DDo,GDo,Yt,P3,ODo,Xse,qDo,zDo,Pd,XDo,Wse,WDo,VDo,Vse,QDo,HDo,UDo,Qse,JDo,KDo,$3,YDo,mo,I3,ZDo,Hse,eGo,oGo,Ua,tGo,Use,rGo,aGo,Jse,nGo,sGo,Kse,lGo,iGo,dGo,O,v4,Yse,mGo,fGo,mI,cGo,gGo,hGo,b4,Zse,uGo,pGo,fI,_Go,vGo,bGo,T4,ele,TGo,FGo,cI,MGo,EGo,CGo,F4,ole,yGo,wGo,gI,AGo,xGo,LGo,M4,tle,BGo,kGo,hI,RGo,SGo,PGo,E4,rle,$Go,IGo,uI,jGo,NGo,DGo,C4,ale,GGo,OGo,pI,qGo,zGo,XGo,y4,nle,WGo,VGo,_I,QGo,HGo,UGo,w4,sle,JGo,KGo,vI,YGo,ZGo,eOo,A4,lle,oOo,tOo,bI,rOo,aOo,nOo,x4,ile,sOo,lOo,TI,iOo,dOo,mOo,L4,dle,fOo,cOo,FI,gOo,hOo,uOo,B4,mle,pOo,_Oo,MI,vOo,bOo,TOo,k4,fle,FOo,MOo,EI,EOo,COo,yOo,R4,cle,wOo,AOo,CI,xOo,LOo,BOo,S4,gle,kOo,ROo,yI,SOo,POo,$Oo,P4,hle,IOo,jOo,wI,NOo,DOo,GOo,$4,ule,OOo,qOo,AI,zOo,XOo,WOo,I4,ple,VOo,QOo,xI,HOo,UOo,JOo,j4,_le,KOo,YOo,LI,ZOo,eqo,oqo,N4,vle,tqo,rqo,BI,aqo,nqo,sqo,D4,ble,lqo,iqo,kI,dqo,mqo,fqo,G4,Tle,cqo,gqo,RI,hqo,uqo,pqo,O4,Fle,_qo,vqo,SI,bqo,Tqo,Fqo,q4,Mle,Mqo,Eqo,PI,Cqo,yqo,wqo,Ele,Aqo,xqo,j3,RCe,$d,z4,Cle,N3,Lqo,yle,Bqo,SCe,it,D3,kqo,Id,Rqo,wle,Sqo,Pqo,Ale,$qo,Iqo,jqo,G3,Nqo,xle,Dqo,Gqo,Oqo,Zt,O3,qqo,Lle,zqo,Xqo,jd,Wqo,Ble,Vqo,Qqo,kle,Hqo,Uqo,Jqo,Rle,Kqo,Yqo,q3,Zqo,fo,z3,ezo,Sle,ozo,tzo,Ja,rzo,Ple,azo,nzo,$le,szo,lzo,Ile,izo,dzo,mzo,re,X4,jle,fzo,czo,$I,gzo,hzo,uzo,W4,Nle,pzo,_zo,II,vzo,bzo,Tzo,V4,Dle,Fzo,Mzo,jI,Ezo,Czo,yzo,Q4,Gle,wzo,Azo,NI,xzo,Lzo,Bzo,H4,Ole,kzo,Rzo,DI,Szo,Pzo,$zo,U4,qle,Izo,jzo,GI,Nzo,Dzo,Gzo,J4,zle,Ozo,qzo,OI,zzo,Xzo,Wzo,K4,Xle,Vzo,Qzo,qI,Hzo,Uzo,Jzo,Y4,Wle,Kzo,Yzo,zI,Zzo,eXo,oXo,Z4,Vle,tXo,rXo,XI,aXo,nXo,sXo,e5,Qle,lXo,iXo,WI,dXo,mXo,fXo,o5,Hle,cXo,gXo,VI,hXo,uXo,pXo,t5,Ule,_Xo,vXo,QI,bXo,TXo,FXo,r5,Jle,MXo,EXo,HI,CXo,yXo,wXo,a5,Kle,AXo,xXo,UI,LXo,BXo,kXo,n5,Yle,RXo,SXo,JI,PXo,$Xo,IXo,s5,Zle,jXo,NXo,KI,DXo,GXo,OXo,eie,qXo,zXo,X3,PCe,Nd,l5,oie,W3,XXo,tie,WXo,$Ce,dt,V3,VXo,Dd,QXo,rie,HXo,UXo,aie,JXo,KXo,YXo,Q3,ZXo,nie,eWo,oWo,tWo,er,H3,rWo,sie,aWo,nWo,Gd,sWo,lie,lWo,iWo,iie,dWo,mWo,fWo,die,cWo,gWo,U3,hWo,co,J3,uWo,mie,pWo,_Wo,Ka,vWo,fie,bWo,TWo,cie,FWo,MWo,gie,EWo,CWo,yWo,hie,i5,uie,wWo,AWo,YI,xWo,LWo,BWo,pie,kWo,RWo,K3,ICe,Od,d5,_ie,Y3,SWo,vie,PWo,jCe,mt,Z3,$Wo,qd,IWo,bie,jWo,NWo,Tie,DWo,GWo,OWo,ey,qWo,Fie,zWo,XWo,WWo,or,oy,VWo,Mie,QWo,HWo,zd,UWo,Eie,JWo,KWo,Cie,YWo,ZWo,eVo,yie,oVo,tVo,ty,rVo,go,ry,aVo,wie,nVo,sVo,Ya,lVo,Aie,iVo,dVo,xie,mVo,fVo,Lie,cVo,gVo,hVo,Y,m5,Bie,uVo,pVo,ZI,_Vo,vVo,bVo,f5,kie,TVo,FVo,ej,MVo,EVo,CVo,c5,Rie,yVo,wVo,oj,AVo,xVo,LVo,g5,Sie,BVo,kVo,tj,RVo,SVo,PVo,h5,Pie,$Vo,IVo,rj,jVo,NVo,DVo,u5,$ie,GVo,OVo,aj,qVo,zVo,XVo,p5,Iie,WVo,VVo,nj,QVo,HVo,UVo,_5,jie,JVo,KVo,sj,YVo,ZVo,eQo,v5,Nie,oQo,tQo,lj,rQo,aQo,nQo,b5,Die,sQo,lQo,ij,iQo,dQo,mQo,T5,Gie,fQo,cQo,dj,gQo,hQo,uQo,F5,Oie,pQo,_Qo,mj,vQo,bQo,TQo,M5,qie,FQo,MQo,fj,EQo,CQo,yQo,E5,zie,wQo,AQo,cj,xQo,LQo,BQo,C5,Xie,kQo,RQo,gj,SQo,PQo,$Qo,y5,Wie,IQo,jQo,hj,NQo,DQo,GQo,w5,Vie,OQo,qQo,uj,zQo,XQo,WQo,A5,Qie,VQo,QQo,pj,HQo,UQo,JQo,x5,Hie,KQo,YQo,_j,ZQo,eHo,oHo,L5,Uie,tHo,rHo,vj,aHo,nHo,sHo,Jie,lHo,iHo,ay,NCe,Xd,B5,Kie,ny,dHo,Yie,mHo,DCe,ft,sy,fHo,Wd,cHo,Zie,gHo,hHo,ede,uHo,pHo,_Ho,ly,vHo,ode,bHo,THo,FHo,tr,iy,MHo,tde,EHo,CHo,Vd,yHo,rde,wHo,AHo,ade,xHo,LHo,BHo,nde,kHo,RHo,dy,SHo,ho,my,PHo,sde,$Ho,IHo,Za,jHo,lde,NHo,DHo,ide,GHo,OHo,dde,qHo,zHo,XHo,Z,k5,mde,WHo,VHo,bj,QHo,HHo,UHo,R5,fde,JHo,KHo,Tj,YHo,ZHo,eUo,S5,cde,oUo,tUo,Fj,rUo,aUo,nUo,P5,gde,sUo,lUo,Mj,iUo,dUo,mUo,$5,hde,fUo,cUo,Ej,gUo,hUo,uUo,I5,ude,pUo,_Uo,Cj,vUo,bUo,TUo,j5,pde,FUo,MUo,yj,EUo,CUo,yUo,N5,_de,wUo,AUo,wj,xUo,LUo,BUo,D5,vde,kUo,RUo,Aj,SUo,PUo,$Uo,G5,bde,IUo,jUo,xj,NUo,DUo,GUo,O5,Tde,OUo,qUo,Lj,zUo,XUo,WUo,q5,Fde,VUo,QUo,Bj,HUo,UUo,JUo,z5,Mde,KUo,YUo,kj,ZUo,eJo,oJo,X5,Ede,tJo,rJo,Rj,aJo,nJo,sJo,W5,Cde,lJo,iJo,Sj,dJo,mJo,fJo,V5,yde,cJo,gJo,Pj,hJo,uJo,pJo,Q5,wde,_Jo,vJo,$j,bJo,TJo,FJo,H5,Ade,MJo,EJo,Ij,CJo,yJo,wJo,U5,xde,AJo,xJo,jj,LJo,BJo,kJo,Lde,RJo,SJo,fy,GCe,Qd,J5,Bde,cy,PJo,kde,$Jo,OCe,ct,gy,IJo,Hd,jJo,Rde,NJo,DJo,Sde,GJo,OJo,qJo,hy,zJo,Pde,XJo,WJo,VJo,rr,uy,QJo,$de,HJo,UJo,Ud,JJo,Ide,KJo,YJo,jde,ZJo,eKo,oKo,Nde,tKo,rKo,py,aKo,uo,_y,nKo,Dde,sKo,lKo,en,iKo,Gde,dKo,mKo,Ode,fKo,cKo,qde,gKo,hKo,uKo,Q,K5,zde,pKo,_Ko,Nj,vKo,bKo,TKo,Y5,Xde,FKo,MKo,Dj,EKo,CKo,yKo,Z5,Wde,wKo,AKo,Gj,xKo,LKo,BKo,e0,Vde,kKo,RKo,Oj,SKo,PKo,$Ko,o0,Qde,IKo,jKo,qj,NKo,DKo,GKo,t0,Hde,OKo,qKo,zj,zKo,XKo,WKo,r0,Ude,VKo,QKo,Xj,HKo,UKo,JKo,a0,Jde,KKo,YKo,Wj,ZKo,eYo,oYo,n0,Kde,tYo,rYo,Vj,aYo,nYo,sYo,s0,Yde,lYo,iYo,Qj,dYo,mYo,fYo,l0,Zde,cYo,gYo,Hj,hYo,uYo,pYo,i0,eme,_Yo,vYo,Uj,bYo,TYo,FYo,d0,ome,MYo,EYo,Jj,CYo,yYo,wYo,m0,tme,AYo,xYo,Kj,LYo,BYo,kYo,f0,rme,RYo,SYo,Yj,PYo,$Yo,IYo,c0,ame,jYo,NYo,Zj,DYo,GYo,OYo,g0,nme,qYo,zYo,eN,XYo,WYo,VYo,h0,sme,QYo,HYo,oN,UYo,JYo,KYo,u0,lme,YYo,ZYo,tN,eZo,oZo,tZo,p0,ime,rZo,aZo,rN,nZo,sZo,lZo,_0,dme,iZo,dZo,aN,mZo,fZo,cZo,v0,mme,gZo,hZo,nN,uZo,pZo,_Zo,fme,vZo,bZo,vy,qCe,Jd,b0,cme,by,TZo,gme,FZo,zCe,gt,Ty,MZo,Kd,EZo,hme,CZo,yZo,ume,wZo,AZo,xZo,Fy,LZo,pme,BZo,kZo,RZo,ar,My,SZo,_me,PZo,$Zo,Yd,IZo,vme,jZo,NZo,bme,DZo,GZo,OZo,Tme,qZo,zZo,Ey,XZo,po,Cy,WZo,Fme,VZo,QZo,on,HZo,Mme,UZo,JZo,Eme,KZo,YZo,Cme,ZZo,eet,oet,Zd,T0,yme,tet,ret,sN,aet,net,set,F0,wme,iet,det,lN,met,fet,cet,M0,Ame,get,het,iN,uet,pet,_et,xme,vet,bet,yy,XCe,em,E0,Lme,wy,Tet,Bme,Fet,WCe,ht,Ay,Met,om,Eet,kme,Cet,yet,Rme,wet,Aet,xet,xy,Let,Sme,Bet,ket,Ret,nr,Ly,Set,Pme,Pet,$et,tm,Iet,$me,jet,Net,Ime,Det,Get,Oet,jme,qet,zet,By,Xet,_o,ky,Wet,Nme,Vet,Qet,tn,Het,Dme,Uet,Jet,Gme,Ket,Yet,Ome,Zet,eot,oot,he,C0,qme,tot,rot,dN,aot,not,sot,y0,zme,lot,iot,mN,dot,mot,fot,w0,Xme,cot,got,fN,hot,uot,pot,A0,Wme,_ot,vot,cN,bot,Tot,Fot,x0,Vme,Mot,Eot,gN,Cot,yot,wot,L0,Qme,Aot,xot,hN,Lot,Bot,kot,B0,Hme,Rot,Sot,uN,Pot,$ot,Iot,k0,Ume,jot,Not,pN,Dot,Got,Oot,R0,Jme,qot,zot,_N,Xot,Wot,Vot,S0,Kme,Qot,Hot,vN,Uot,Jot,Kot,Yme,Yot,Zot,Ry,VCe,rm,P0,Zme,Sy,ett,efe,ott,QCe,ut,Py,ttt,am,rtt,ofe,att,ntt,tfe,stt,ltt,itt,$y,dtt,rfe,mtt,ftt,ctt,sr,Iy,gtt,afe,htt,utt,nm,ptt,nfe,_tt,vtt,sfe,btt,Ttt,Ftt,lfe,Mtt,Ett,jy,Ctt,vo,Ny,ytt,ife,wtt,Att,rn,xtt,dfe,Ltt,Btt,mfe,ktt,Rtt,ffe,Stt,Ptt,$tt,Me,$0,cfe,Itt,jtt,bN,Ntt,Dtt,Gtt,I0,gfe,Ott,qtt,TN,ztt,Xtt,Wtt,j0,hfe,Vtt,Qtt,FN,Htt,Utt,Jtt,N0,ufe,Ktt,Ytt,MN,Ztt,ert,ort,D0,pfe,trt,rrt,EN,art,nrt,srt,G0,_fe,lrt,irt,CN,drt,mrt,frt,O0,vfe,crt,grt,yN,hrt,urt,prt,q0,bfe,_rt,vrt,wN,brt,Trt,Frt,Tfe,Mrt,Ert,Dy,HCe,sm,z0,Ffe,Gy,Crt,Mfe,yrt,UCe,pt,Oy,wrt,lm,Art,Efe,xrt,Lrt,Cfe,Brt,krt,Rrt,qy,Srt,yfe,Prt,$rt,Irt,lr,zy,jrt,wfe,Nrt,Drt,im,Grt,Afe,Ort,qrt,xfe,zrt,Xrt,Wrt,Lfe,Vrt,Qrt,Xy,Hrt,bo,Wy,Urt,Bfe,Jrt,Krt,an,Yrt,kfe,Zrt,eat,Rfe,oat,tat,Sfe,rat,aat,nat,pe,X0,Pfe,sat,lat,AN,iat,dat,mat,W0,$fe,fat,cat,xN,gat,hat,uat,V0,Ife,pat,_at,LN,vat,bat,Tat,Q0,jfe,Fat,Mat,BN,Eat,Cat,yat,H0,Nfe,wat,Aat,kN,xat,Lat,Bat,U0,Dfe,kat,Rat,RN,Sat,Pat,$at,J0,Gfe,Iat,jat,SN,Nat,Dat,Gat,K0,Ofe,Oat,qat,PN,zat,Xat,Wat,Y0,qfe,Vat,Qat,$N,Hat,Uat,Jat,zfe,Kat,Yat,Vy,JCe,dm,Z0,Xfe,Qy,Zat,Wfe,ent,KCe,_t,Hy,ont,mm,tnt,Vfe,rnt,ant,Qfe,nnt,snt,lnt,Uy,int,Hfe,dnt,mnt,fnt,ir,Jy,cnt,Ufe,gnt,hnt,fm,unt,Jfe,pnt,_nt,Kfe,vnt,bnt,Tnt,Yfe,Fnt,Mnt,Ky,Ent,To,Yy,Cnt,Zfe,ynt,wnt,nn,Ant,ece,xnt,Lnt,oce,Bnt,knt,tce,Rnt,Snt,Pnt,Ee,eT,rce,$nt,Int,IN,jnt,Nnt,Dnt,oT,ace,Gnt,Ont,jN,qnt,znt,Xnt,tT,nce,Wnt,Vnt,NN,Qnt,Hnt,Unt,rT,sce,Jnt,Knt,DN,Ynt,Znt,est,aT,lce,ost,tst,GN,rst,ast,nst,nT,ice,sst,lst,ON,ist,dst,mst,sT,dce,fst,cst,qN,gst,hst,ust,lT,mce,pst,_st,zN,vst,bst,Tst,fce,Fst,Mst,Zy,YCe,cm,iT,cce,ew,Est,gce,Cst,ZCe,vt,ow,yst,gm,wst,hce,Ast,xst,uce,Lst,Bst,kst,tw,Rst,pce,Sst,Pst,$st,dr,rw,Ist,_ce,jst,Nst,hm,Dst,vce,Gst,Ost,bce,qst,zst,Xst,Tce,Wst,Vst,aw,Qst,Fo,nw,Hst,Fce,Ust,Jst,sn,Kst,Mce,Yst,Zst,Ece,elt,olt,Cce,tlt,rlt,alt,Ce,dT,yce,nlt,slt,XN,llt,ilt,dlt,mT,wce,mlt,flt,WN,clt,glt,hlt,fT,Ace,ult,plt,VN,_lt,vlt,blt,cT,xce,Tlt,Flt,QN,Mlt,Elt,Clt,gT,Lce,ylt,wlt,HN,Alt,xlt,Llt,hT,Bce,Blt,klt,UN,Rlt,Slt,Plt,uT,kce,$lt,Ilt,JN,jlt,Nlt,Dlt,pT,Rce,Glt,Olt,KN,qlt,zlt,Xlt,Sce,Wlt,Vlt,sw,e3e,um,_T,Pce,lw,Qlt,$ce,Hlt,o3e,bt,iw,Ult,pm,Jlt,Ice,Klt,Ylt,jce,Zlt,eit,oit,dw,tit,Nce,rit,ait,nit,mr,mw,sit,Dce,lit,iit,_m,dit,Gce,mit,fit,Oce,cit,git,hit,qce,uit,pit,fw,_it,Mo,cw,vit,zce,bit,Tit,ln,Fit,Xce,Mit,Eit,Wce,Cit,yit,Vce,wit,Ait,xit,Tt,vT,Qce,Lit,Bit,YN,kit,Rit,Sit,bT,Hce,Pit,$it,ZN,Iit,jit,Nit,TT,Uce,Dit,Git,eD,Oit,qit,zit,FT,Jce,Xit,Wit,oD,Vit,Qit,Hit,MT,Kce,Uit,Jit,tD,Kit,Yit,Zit,ET,Yce,edt,odt,rD,tdt,rdt,adt,Zce,ndt,sdt,gw,t3e,vm,CT,ege,hw,ldt,oge,idt,r3e,Ft,uw,ddt,bm,mdt,tge,fdt,cdt,rge,gdt,hdt,udt,pw,pdt,age,_dt,vdt,bdt,fr,_w,Tdt,nge,Fdt,Mdt,Tm,Edt,sge,Cdt,ydt,lge,wdt,Adt,xdt,ige,Ldt,Bdt,vw,kdt,Eo,bw,Rdt,dge,Sdt,Pdt,dn,$dt,mge,Idt,jdt,fge,Ndt,Ddt,cge,Gdt,Odt,qdt,Mt,yT,gge,zdt,Xdt,aD,Wdt,Vdt,Qdt,wT,hge,Hdt,Udt,nD,Jdt,Kdt,Ydt,AT,uge,Zdt,emt,sD,omt,tmt,rmt,xT,pge,amt,nmt,lD,smt,lmt,imt,LT,_ge,dmt,mmt,iD,fmt,cmt,gmt,BT,vge,hmt,umt,dD,pmt,_mt,vmt,bge,bmt,Tmt,Tw,a3e,Fm,kT,Tge,Fw,Fmt,Fge,Mmt,n3e,Et,Mw,Emt,Mm,Cmt,Mge,ymt,wmt,Ege,Amt,xmt,Lmt,Ew,Bmt,Cge,kmt,Rmt,Smt,cr,Cw,Pmt,yge,$mt,Imt,Em,jmt,wge,Nmt,Dmt,Age,Gmt,Omt,qmt,xge,zmt,Xmt,yw,Wmt,Co,ww,Vmt,Lge,Qmt,Hmt,mn,Umt,Bge,Jmt,Kmt,kge,Ymt,Zmt,Rge,eft,oft,tft,Sge,RT,Pge,rft,aft,mD,nft,sft,lft,$ge,ift,dft,Aw,s3e,Cm,ST,Ige,xw,mft,jge,fft,l3e,Ct,Lw,cft,ym,gft,Nge,hft,uft,Dge,pft,_ft,vft,Bw,bft,Gge,Tft,Fft,Mft,gr,kw,Eft,Oge,Cft,yft,wm,wft,qge,Aft,xft,zge,Lft,Bft,kft,Xge,Rft,Sft,Rw,Pft,yo,Sw,$ft,Wge,Ift,jft,fn,Nft,Vge,Dft,Gft,Qge,Oft,qft,Hge,zft,Xft,Wft,Pw,PT,Uge,Vft,Qft,fD,Hft,Uft,Jft,$T,Jge,Kft,Yft,cD,Zft,ect,oct,Kge,tct,rct,$w,i3e,Am,IT,Yge,Iw,act,Zge,nct,d3e,yt,jw,sct,xm,lct,ehe,ict,dct,ohe,mct,fct,cct,Nw,gct,the,hct,uct,pct,hr,Dw,_ct,rhe,vct,bct,Lm,Tct,ahe,Fct,Mct,nhe,Ect,Cct,yct,she,wct,Act,Gw,xct,wo,Ow,Lct,lhe,Bct,kct,cn,Rct,ihe,Sct,Pct,dhe,$ct,Ict,mhe,jct,Nct,Dct,fhe,jT,che,Gct,Oct,gD,qct,zct,Xct,ghe,Wct,Vct,qw,m3e;return ie=new X({}),ba=new w({props:{code:"model = AutoModel.from_pretrained('bert-base-cased'),",highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)'}}),IF=new X({}),jF=new w({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel),`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Im=new Qct({props:{warning:!0,$$slots:{default:[qVt]},$$scope:{ctx:Wl}}}),NF=new X({}),DF=new C({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/configuration_auto.py#L475"}}),qF=new C({props:{name:"from\\_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/configuration_auto.py#L498",parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or
namespaced under a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
[<em>~PretrainedConfig.save_pretrained</em>] method, or the
[<em>~PreTrainedModel.save_pretrained</em>] method, e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<em>./my_model_directory/configuration.json</em>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
If <em>False</em>, then this function returns just the final configuration object.</p>
<p>If <em>True</em>, then this functions returns a <em>Tuple(config, unused_kwargs)</em> where <em>unused_kwargs</em>
is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e.,
the part of <em>kwargs</em> which has not been used to update <em>config</em> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <em>return_unused_kwargs</em> keyword parameter.`,name:"kwargs(additional"}]}}),zF=new w({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-uncased')

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained('dbmdz/bert-base-german-cased')

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained('./test/bert_saved_model/')

# Load a specific configuration file.
config = AutoConfig.from_pretrained('./test/bert_saved_model/my_configuration.json')

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained('bert-base-uncased', output_attentions=True, foo=False)
config.output_attentions
config, unused_kwargs = AutoConfig.from_pretrained('bert-base-uncased', output_attentions=True, foo=False, return_unused_kwargs=True)
config.output_attentions
config.unused_kwargs,`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-uncased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;dbmdz/bert-base-german-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./test/bert_saved_model/&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./test/bert_saved_model/my_configuration.json&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-uncased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-uncased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),XF=new C({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/configuration_auto.py#L616",parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/v4.15.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}]}}),WF=new X({}),VF=new C({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/tokenization_auto.py#L361"}}),UF=new C({props:{name:"from\\_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/tokenization_auto.py#L375",parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the [<em>~PreTrainedTokenizer.save_pretrained</em>] method, e.g.,
<em>./my_model_directory/</em>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <em>./my_model_directory/vocab.txt</em>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <em><strong>init</strong>()</em> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<em>str</em>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>True</em>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <em><strong>init</strong>()</em> method. Can be used to set special tokens like
<em>bos_token</em>, <em>eos_token</em>, <em>unk_token</em>, <em>sep_token</em>, <em>pad_token</em>, <em>cls_token</em>,
<em>mask_token</em>, <em>additional_special_tokens</em>. See parameters in the <em><strong>init</strong>()</em> for more details.`,name:"kwargs"}]}}),JF=new w({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained('dbmdz/bert-base-german-cased')

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained('./test/bert_saved_model/'),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;bert-base-uncased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;dbmdz/bert-base-german-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;./test/bert_saved_model/&#x27;</span>)`}}),KF=new C({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/tokenization_auto.py#L565",parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/v4.15.0/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}]}}),YF=new X({}),ZF=new C({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/feature_extraction_auto.py#L65"}}),tM=new C({props:{name:"from\\_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/feature_extraction_auto.py#L79",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or
namespaced under a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
[<em>~feature_extraction_utils.FeatureExtractionMixin.save_pretrained</em>] method, e.g.,
<em>./my_model_directory/</em>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<em>./my_model_directory/preprocessor_config.json</em>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}.</em> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<em>str</em> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <em>True</em>, will use the token
generated when running <em>transformers-cli login</em> (stored in <em>~/.huggingface</em>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
If <em>False</em>, then this function returns just the final feature extractor object. If <em>True</em>,
then this functions returns a <em>Tuple(feature_extractor, unused_kwargs)</em> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the
part of <em>kwargs</em> which has not been used to update <em>feature_extractor</em> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<em>Dict[str, Any]</em>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <em>return_unused_kwargs</em> keyword parameter.`,name:"kwargs"}]}}),Kc=new Qct({props:{$$slots:{default:[zVt]},$$scope:{ctx:Wl}}}),rM=new w({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/wav2vec2-base-960h')

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained('./test/saved_model/'),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&#x27;facebook/wav2vec2-base-960h&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&#x27;./test/saved_model/&#x27;</span>)`}}),aM=new X({}),nM=new C({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/processing_auto.py#L62"}}),iM=new C({props:{name:"from\\_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/processing_auto.py#L76",parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or
namespaced under a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <em>save_pretrained()</em> method,
e.g., <em>./my_model_directory/</em>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}.</em> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<em>str</em> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <em>True</em>, will use the token
generated when running <em>transformers-cli login</em> (stored in <em>~/.huggingface</em>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<em>str</em>, <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
If <em>False</em>, then this function returns just the final feature extractor object. If <em>True</em>,
then this functions returns a <em>Tuple(feature_extractor, unused_kwargs)</em> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the
part of <em>kwargs</em> which has not been used to update <em>feature_extractor</em> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<em>Dict[str, Any]</em>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <em>return_unused_kwargs</em> keyword parameter.`,name:"kwargs"}]}}),sg=new Qct({props:{$$slots:{default:[XVt]},$$scope:{ctx:Wl}}}),dM=new w({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained('facebook/wav2vec2-base-960h')

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained('./test/saved_model/'),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&#x27;facebook/wav2vec2-base-960h&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&#x27;./test/saved_model/&#x27;</span>)`}}),mM=new X({}),fM=new C({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L608"}}),gM=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),hM=new w({props:{code:`from transformers import AutoConfig, AutoModel
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModel.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),uM=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),pM=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModel.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModel.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),_M=new X({}),vM=new C({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L615"}}),TM=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),FM=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForPreTraining.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),MM=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),EM=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForPreTraining.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),CM=new X({}),yM=new C({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L630"}}),AM=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),xM=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForCausalLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),LM=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),BM=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForCausalLM.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),kM=new X({}),RM=new C({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L637"}}),PM=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),$M=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForMaskedLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),IM=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),jM=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForMaskedLM.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),NM=new X({}),DM=new C({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L644"}}),OM=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}]}}),qM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('t5-base')
model = AutoModelForSeq2SeqLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),zM=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),XM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained('t5-base', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/t5_tf_model_config.json')
model = AutoModelForSeq2SeqLM.from_pretrained('./tf_model/t5_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/t5_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;./tf_model/t5_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),WM=new X({}),VM=new C({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L653"}}),HM=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),UM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForSequenceClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),JM=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),KM=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForSequenceClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),YM=new X({}),ZM=new C({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L687"}}),oE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),tE=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForMultipleChoice.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),rE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),aE=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForMultipleChoice.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),nE=new X({}),sE=new C({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L694"}}),iE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}]}}),dE=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForNextSentencePrediction.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),mE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),fE=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForNextSentencePrediction.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),cE=new X({}),gE=new C({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L680"}}),uE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),pE=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForTokenClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),_E=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),vE=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForTokenClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),bE=new X({}),TE=new C({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L662"}}),ME=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),EE=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),CE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),yE=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForQuestionAnswering.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),wE=new X({}),AE=new C({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L669"}}),LE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),BE=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('google/tapas-base-finetuned-wtq')
model = AutoModelForTableQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;google/tapas-base-finetuned-wtq&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),kE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),RE=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained('google/tapas-base-finetuned-wtq')

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained('google/tapas-base-finetuned-wtq', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/tapas_tf_model_config.json')
model = AutoModelForTableQuestionAnswering.from_pretrained('./tf_model/tapas_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;google/tapas-base-finetuned-wtq&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;google/tapas-base-finetuned-wtq&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/tapas_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;./tf_model/tapas_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),SE=new X({}),PE=new C({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L703"}}),IE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),jE=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForImageClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),NE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),DE=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForImageClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),GE=new X({}),OE=new C({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L724"}}),zE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),XE=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForVision2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),WE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),VE=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForVision2Seq.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),QE=new X({}),HE=new C({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L731"}}),JE=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),KE=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForAudioClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),YE=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),ZE=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForAudioClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),eC=new X({}),oC=new C({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L754"}}),rC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),aC=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForAudioFrameClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),nC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),sC=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForAudioFrameClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),lC=new X({}),iC=new C({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L738"}}),mC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),fC=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForCTC.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),cC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),gC=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForCTC.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForCTC.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),hC=new X({}),uC=new C({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L745"}}),_C=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/speechencoderdecoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/speechencoderdecoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}]}}),vC=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForSpeechSeq2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),bC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),FC=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForSpeechSeq2Seq.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),MC=new X({}),EC=new C({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L763"}}),yC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),wC=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForAudioXVector.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),AC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),xC=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForAudioXVector.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),LC=new X({}),BC=new C({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L717"}}),RC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
</ul>`,name:"config"}]}}),SC=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForObjectDetection.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),PC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),$C=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForObjectDetection.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),IC=new X({}),jC=new C({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_auto.py#L710"}}),DC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}]}}),GC=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = AutoModelForImageSegmentation.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),OC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <em>./tf_model/model.ckpt.index</em>). In
this case, <em>from_tf</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the TensorFlow checkpoint in
a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using
[<em>~PreTrainedModel.save_pretrained</em>] and
[<em>~PreTrainedModel.from_pretrained</em>] is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),qC=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained('bert-base-cased')

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained('./tf_model/bert_tf_model_config.json')
model = AutoModelForImageSegmentation.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&#x27;./tf_model/bert_tf_checkpoint.ckpt.index&#x27;</span>, from_tf=<span class="hljs-literal">True</span>, config=config)`}}),zC=new X({}),XC=new C({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L353"}}),VC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),QC=new w({props:{code:`from transformers import AutoConfig, TFAutoModel
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModel.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),HC=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),UC=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModel.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModel.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),JC=new X({}),KC=new C({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L360"}}),ZC=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),e3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForPreTraining.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),o3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),t3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForPreTraining.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),r3=new X({}),a3=new C({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L375"}}),s3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),l3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForCausalLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),i3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),d3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForCausalLM.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),m3=new X({}),f3=new C({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L382"}}),g3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),h3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForImageClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),u3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),p3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForImageClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),_3=new X({}),v3=new C({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L389"}}),T3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),F3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForMaskedLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),M3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),E3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForMaskedLM.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),C3=new X({}),y3=new C({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L396"}}),A3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),x3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('t5-base')
model = TFAutoModelForSeq2SeqLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),L3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),B3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained('t5-base')

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained('t5-base', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/t5_pt_model_config.json')
model = TFAutoModelForSeq2SeqLM.from_pretrained('./pt_model/t5_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/t5_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;./pt_model/t5_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),k3=new X({}),R3=new C({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L405"}}),P3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),$3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForSequenceClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),I3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),j3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForSequenceClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),N3=new X({}),D3=new C({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),O3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),q3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForMultipleChoice.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),z3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),X3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForMultipleChoice.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),W3=new X({}),V3=new C({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L421"}}),H3=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),U3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('google/tapas-base-finetuned-wtq')
model = TFAutoModelForTableQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;google/tapas-base-finetuned-wtq&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),J3=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),K3=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained('google/tapas-base-finetuned-wtq')

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained('google/tapas-base-finetuned-wtq', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/tapas_pt_model_config.json')
model = TFAutoModelForTableQuestionAnswering.from_pretrained('./pt_model/tapas_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;google/tapas-base-finetuned-wtq&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;google/tapas-base-finetuned-wtq&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/tapas_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;./pt_model/tapas_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),Y3=new X({}),Z3=new C({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),oy=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),ty=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForTokenClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),ry=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),ay=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForTokenClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),ny=new X({}),sy=new C({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_tf_auto.py#L414"}}),iy=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),dy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = TFAutoModelForQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),my=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),fy=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained('bert-base-cased')

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = TFAutoModelForQuestionAnswering.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),cy=new X({}),gy=new C({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L211"}}),uy=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
</ul>`,name:"config"}]}}),py=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModel.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),_y=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),vy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModel.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModel.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),by=new X({}),Ty=new C({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L225"}}),My=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
</ul>`,name:"config"}]}}),Ey=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForCausalLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),Cy=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),yy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForCausalLM.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),wy=new X({}),Ay=new C({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L218"}}),Ly=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
</ul>`,name:"config"}]}}),By=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForPreTraining.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),ky=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),Ry=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForPreTraining.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),Sy=new X({}),Py=new C({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L232"}}),Iy=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),jy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForMaskedLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),Ny=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),Dy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForMaskedLM.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),Gy=new X({}),Oy=new C({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L239"}}),zy=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),Xy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('t5-base')
model = FlaxAutoModelForSeq2SeqLM.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),Wy=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),Vy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained('t5-base')

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained('t5-base', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/t5_pt_model_config.json')
model = FlaxAutoModelForSeq2SeqLM.from_pretrained('./pt_model/t5_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-base&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/t5_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;./pt_model/t5_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),Qy=new X({}),Hy=new C({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),Jy=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),Ky=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForSequenceClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),Yy=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),Zy=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForSequenceClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),ew=new X({}),ow=new C({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L257"}}),rw=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),aw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForQuestionAnswering.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),nw=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),sw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForQuestionAnswering.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),lw=new X({}),iw=new C({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),mw=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),fw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForTokenClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),cw=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),gw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForTokenClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),hw=new X({}),uw=new C({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L273"}}),_w=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
</ul>`,name:"config"}]}}),vw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForMultipleChoice.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),bw=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),Tw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForMultipleChoice.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),Fw=new X({}),Mw=new C({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L280"}}),Cw=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}]}}),yw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForNextSentencePrediction.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),ww=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),Aw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForNextSentencePrediction.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),xw=new X({}),Lw=new C({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L289"}}),kw=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),Rw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForImageClassification.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),Sw=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),$w=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForImageClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),Iw=new X({}),jw=new C({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/modeling_flax_auto.py#L298"}}),Dw=new C({props:{name:"from\\_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L384",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>]) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),Gw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq
# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained('bert-base-cased')
model = FlaxAutoModelForVision2Seq.from_config(config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),Ow=new C({props:{name:"from\\_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/auto/auto_factory.py#L412",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<em>str</em> or <em>os.PathLike</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <em>bert-base-uncased</em>, or namespaced under
a user or organization name, like <em>dbmdz/bert-base-german-cased</em>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
[<em>~PreTrainedModel.save_pretrained</em>], e.g., <em>./my_model_directory/</em>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <em>./pt_model/pytorch_model.bin</em>). In
this case, <em>from_pt</em> should be set to <em>True</em> and a configuration object should be provided
as <em>config</em> argument. This loading path is slower than converting the PyTorch model in a
TensorFlow model using the provided conversion scripts and loading the TensorFlow model
afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <em><strong>init</strong>()</em> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> ([<em>PretrainedConfig</em>], <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using [<em>~PreTrainedModel.save_pretrained</em>] and is reloaded
by supplying the save directory.</li>
<li>The model is loaded by supplying a local directory as <em>pretrained_model_name_or_path</em> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em> or <em>os.PathLike</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<em>pretrained_model_name_or_path</em> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<em>Dict[str, str]</em>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <em>{&#x2018;http&#x2019;: &#x2018;foo.bar:3128&#x2019;, &#x2018;http://hostname&#x2019;: &#x2018;foo.bar:4012&#x2019;}</em>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<em>bool</em>,</strong> <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>, defaults to <em>&#x201C;main&#x201D;</em>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <em>revision</em> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <em>True</em> for repositories you trust and in which you have read the code, as it
will execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<em>output_attentions=True</em>). Behaves differently depending on whether a <em>config</em> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <em>config</em>, <em>**kwargs</em> will be directly passed to the
underlying model&#x2019;s <em><strong>init</strong></em> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <em>kwargs</em> will be first passed to the configuration class
initialization function ([<em>~PretrainedConfig.from_pretrained</em>]). Each key of
<em>kwargs</em> that corresponds to a configuration attribute will be used to override said attribute
with the supplied <em>kwargs</em> value. Remaining keys that do not correspond to any configuration
attribute will be passed to the underlying model&#x2019;s <em><strong>init</strong></em> function.</li>
</ul>`,name:"kwargs"}]}}),qw=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained('bert-base-cased')

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained('bert-base-cased', output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained('./pt_model/bert_pt_model_config.json')
model = FlaxAutoModelForVision2Seq.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&#x27;bert-base-cased&#x27;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pt_model_config.json&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&#x27;./pt_model/bert_pytorch_model.bin&#x27;</span>, from_pt=<span class="hljs-literal">True</span>, config=config)`}}),{c(){J=a("meta"),ye=l(),se=a("h1"),de=a("a"),Ue=a("span"),f(ie.$$.fragment),ue=l(),Bo=a("span"),Vl=o("Auto Classes"),km=l(),zr=a("p"),Ql=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Hl=a("code"),RF=o("from_pretrained()"),Rm=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Fe=l(),Ze=a("p"),Ul=o("Instantiating one of "),gn=a("a"),SF=o("AutoConfig"),hn=o(", "),un=a("a"),PF=o("AutoModel"),Jl=o(`, and
`),pn=a("a"),$F=o("AutoTokenizer"),Kl=o(" will directly create a class of the relevant architecture. For instance"),Sm=l(),f(ba.$$.fragment),eo=l(),me=a("p"),IA=o("will create a model that is an instance of "),Yl=a("a"),jA=o("BertModel"),NA=o("."),ko=l(),Ta=a("p"),DA=o("There is one class of "),Pm=a("code"),GA=o("AutoModel"),dwe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),bEe=l(),Zl=a("h2"),$m=a("a"),YG=a("span"),f(IF.$$.fragment),mwe=l(),ZG=a("span"),fwe=o("Extending the Auto Classes"),TEe=l(),_n=a("p"),cwe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),eO=a("code"),gwe=o("NewModel"),hwe=o(", make sure you have a "),oO=a("code"),uwe=o("NewModelConfig"),pwe=o(` then you can add those to the auto
classes like this:`),FEe=l(),f(jF.$$.fragment),MEe=l(),OA=a("p"),_we=o("You will then be able to use the auto classes like you would usually do!"),EEe=l(),f(Im.$$.fragment),CEe=l(),ei=a("h2"),jm=a("a"),tO=a("span"),f(NF.$$.fragment),vwe=l(),rO=a("span"),bwe=o("AutoConfig"),yEe=l(),Ro=a("div"),f(DF.$$.fragment),Twe=l(),GF=a("p"),Fwe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),qA=a("a"),Mwe=o("from_pretrained()"),Ewe=o(" class method."),Cwe=l(),OF=a("p"),ywe=o("This class cannot be instantiated directly using "),aO=a("code"),wwe=o("__init__()"),Awe=o(" (throws an error)."),xwe=l(),oo=a("div"),f(qF.$$.fragment),Lwe=l(),nO=a("p"),Bwe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),kwe=l(),oi=a("p"),Rwe=o("The configuration class to instantiate is selected based on the "),sO=a("em"),Swe=o("model_type"),Pwe=o(` property of the config object
that is loaded, or when it\u2019s missing, by falling back to using pattern matching on
`),lO=a("em"),$we=o("pretrained_model_name_or_path"),Iwe=o(":"),jwe=l(),b=a("ul"),Nm=a("li"),iO=a("strong"),Nwe=o("albert"),Dwe=o(" \u2014 "),zA=a("a"),Gwe=o("AlbertConfig"),Owe=o(" (ALBERT model)"),qwe=l(),Dm=a("li"),dO=a("strong"),zwe=o("bart"),Xwe=o(" \u2014 "),XA=a("a"),Wwe=o("BartConfig"),Vwe=o(" (BART model)"),Qwe=l(),Gm=a("li"),mO=a("strong"),Hwe=o("beit"),Uwe=o(" \u2014 "),WA=a("a"),Jwe=o("BeitConfig"),Kwe=o(" (BEiT model)"),Ywe=l(),Om=a("li"),fO=a("strong"),Zwe=o("bert"),eAe=o(" \u2014 "),VA=a("a"),oAe=o("BertConfig"),tAe=o(" (BERT model)"),rAe=l(),qm=a("li"),cO=a("strong"),aAe=o("bert-generation"),nAe=o(" \u2014 "),QA=a("a"),sAe=o("BertGenerationConfig"),lAe=o(" (Bert Generation model)"),iAe=l(),zm=a("li"),gO=a("strong"),dAe=o("big_bird"),mAe=o(" \u2014 "),HA=a("a"),fAe=o("BigBirdConfig"),cAe=o(" (BigBird model)"),gAe=l(),Xm=a("li"),hO=a("strong"),hAe=o("bigbird_pegasus"),uAe=o(" \u2014 "),UA=a("a"),pAe=o("BigBirdPegasusConfig"),_Ae=o(" (BigBirdPegasus model)"),vAe=l(),Wm=a("li"),uO=a("strong"),bAe=o("blenderbot"),TAe=o(" \u2014 "),JA=a("a"),FAe=o("BlenderbotConfig"),MAe=o(" (Blenderbot model)"),EAe=l(),Vm=a("li"),pO=a("strong"),CAe=o("blenderbot-small"),yAe=o(" \u2014 "),KA=a("a"),wAe=o("BlenderbotSmallConfig"),AAe=o(" (BlenderbotSmall model)"),xAe=l(),Qm=a("li"),_O=a("strong"),LAe=o("camembert"),BAe=o(" \u2014 "),YA=a("a"),kAe=o("CamembertConfig"),RAe=o(" (CamemBERT model)"),SAe=l(),Hm=a("li"),vO=a("strong"),PAe=o("canine"),$Ae=o(" \u2014 "),ZA=a("a"),IAe=o("CanineConfig"),jAe=o(" (Canine model)"),NAe=l(),Um=a("li"),bO=a("strong"),DAe=o("clip"),GAe=o(" \u2014 "),e7=a("a"),OAe=o("CLIPConfig"),qAe=o(" (CLIP model)"),zAe=l(),Jm=a("li"),TO=a("strong"),XAe=o("convbert"),WAe=o(" \u2014 "),o7=a("a"),VAe=o("ConvBertConfig"),QAe=o(" (ConvBERT model)"),HAe=l(),Km=a("li"),FO=a("strong"),UAe=o("ctrl"),JAe=o(" \u2014 "),t7=a("a"),KAe=o("CTRLConfig"),YAe=o(" (CTRL model)"),ZAe=l(),Ym=a("li"),MO=a("strong"),e7e=o("deberta"),o7e=o(" \u2014 "),r7=a("a"),t7e=o("DebertaConfig"),r7e=o(" (DeBERTa model)"),a7e=l(),Zm=a("li"),EO=a("strong"),n7e=o("deberta-v2"),s7e=o(" \u2014 "),a7=a("a"),l7e=o("DebertaV2Config"),i7e=o(" (DeBERTa-v2 model)"),d7e=l(),ef=a("li"),CO=a("strong"),m7e=o("deit"),f7e=o(" \u2014 "),n7=a("a"),c7e=o("DeiTConfig"),g7e=o(" (DeiT model)"),h7e=l(),of=a("li"),yO=a("strong"),u7e=o("detr"),p7e=o(" \u2014 "),s7=a("a"),_7e=o("DetrConfig"),v7e=o(" (DETR model)"),b7e=l(),tf=a("li"),wO=a("strong"),T7e=o("distilbert"),F7e=o(" \u2014 "),l7=a("a"),M7e=o("DistilBertConfig"),E7e=o(" (DistilBERT model)"),C7e=l(),rf=a("li"),AO=a("strong"),y7e=o("dpr"),w7e=o(" \u2014 "),i7=a("a"),A7e=o("DPRConfig"),x7e=o(" (DPR model)"),L7e=l(),af=a("li"),xO=a("strong"),B7e=o("electra"),k7e=o(" \u2014 "),d7=a("a"),R7e=o("ElectraConfig"),S7e=o(" (ELECTRA model)"),P7e=l(),nf=a("li"),LO=a("strong"),$7e=o("encoder-decoder"),I7e=o(" \u2014 "),m7=a("a"),j7e=o("EncoderDecoderConfig"),N7e=o(" (Encoder decoder model)"),D7e=l(),sf=a("li"),BO=a("strong"),G7e=o("flaubert"),O7e=o(" \u2014 "),f7=a("a"),q7e=o("FlaubertConfig"),z7e=o(" (FlauBERT model)"),X7e=l(),lf=a("li"),kO=a("strong"),W7e=o("fnet"),V7e=o(" \u2014 "),c7=a("a"),Q7e=o("FNetConfig"),H7e=o(" (FNet model)"),U7e=l(),df=a("li"),RO=a("strong"),J7e=o("fsmt"),K7e=o(" \u2014 "),g7=a("a"),Y7e=o("FSMTConfig"),Z7e=o(" (FairSeq Machine-Translation model)"),exe=l(),mf=a("li"),SO=a("strong"),oxe=o("funnel"),txe=o(" \u2014 "),h7=a("a"),rxe=o("FunnelConfig"),axe=o(" (Funnel Transformer model)"),nxe=l(),ff=a("li"),PO=a("strong"),sxe=o("gpt2"),lxe=o(" \u2014 "),u7=a("a"),ixe=o("GPT2Config"),dxe=o(" (OpenAI GPT-2 model)"),mxe=l(),cf=a("li"),$O=a("strong"),fxe=o("gpt_neo"),cxe=o(" \u2014 "),p7=a("a"),gxe=o("GPTNeoConfig"),hxe=o(" (GPT Neo model)"),uxe=l(),gf=a("li"),IO=a("strong"),pxe=o("gptj"),_xe=o(" \u2014 "),_7=a("a"),vxe=o("GPTJConfig"),bxe=o(" (GPT-J model)"),Txe=l(),hf=a("li"),jO=a("strong"),Fxe=o("hubert"),Mxe=o(" \u2014 "),v7=a("a"),Exe=o("HubertConfig"),Cxe=o(" (Hubert model)"),yxe=l(),uf=a("li"),NO=a("strong"),wxe=o("ibert"),Axe=o(" \u2014 "),b7=a("a"),xxe=o("IBertConfig"),Lxe=o(" (I-BERT model)"),Bxe=l(),pf=a("li"),DO=a("strong"),kxe=o("imagegpt"),Rxe=o(" \u2014 "),T7=a("a"),Sxe=o("ImageGPTConfig"),Pxe=o(" (ImageGPT model)"),$xe=l(),_f=a("li"),GO=a("strong"),Ixe=o("layoutlm"),jxe=o(" \u2014 "),F7=a("a"),Nxe=o("LayoutLMConfig"),Dxe=o(" (LayoutLM model)"),Gxe=l(),vf=a("li"),OO=a("strong"),Oxe=o("layoutlmv2"),qxe=o(" \u2014 "),M7=a("a"),zxe=o("LayoutLMv2Config"),Xxe=o(" (LayoutLMv2 model)"),Wxe=l(),bf=a("li"),qO=a("strong"),Vxe=o("led"),Qxe=o(" \u2014 "),E7=a("a"),Hxe=o("LEDConfig"),Uxe=o(" (LED model)"),Jxe=l(),Tf=a("li"),zO=a("strong"),Kxe=o("longformer"),Yxe=o(" \u2014 "),C7=a("a"),Zxe=o("LongformerConfig"),e6e=o(" (Longformer model)"),o6e=l(),Ff=a("li"),XO=a("strong"),t6e=o("luke"),r6e=o(" \u2014 "),y7=a("a"),a6e=o("LukeConfig"),n6e=o(" (LUKE model)"),s6e=l(),Mf=a("li"),WO=a("strong"),l6e=o("lxmert"),i6e=o(" \u2014 "),w7=a("a"),d6e=o("LxmertConfig"),m6e=o(" (LXMERT model)"),f6e=l(),Ef=a("li"),VO=a("strong"),c6e=o("m2m_100"),g6e=o(" \u2014 "),A7=a("a"),h6e=o("M2M100Config"),u6e=o(" (M2M100 model)"),p6e=l(),Cf=a("li"),QO=a("strong"),_6e=o("marian"),v6e=o(" \u2014 "),x7=a("a"),b6e=o("MarianConfig"),T6e=o(" (Marian model)"),F6e=l(),yf=a("li"),HO=a("strong"),M6e=o("mbart"),E6e=o(" \u2014 "),L7=a("a"),C6e=o("MBartConfig"),y6e=o(" (mBART model)"),w6e=l(),wf=a("li"),UO=a("strong"),A6e=o("megatron-bert"),x6e=o(" \u2014 "),B7=a("a"),L6e=o("MegatronBertConfig"),B6e=o(" (MegatronBert model)"),k6e=l(),Af=a("li"),JO=a("strong"),R6e=o("mobilebert"),S6e=o(" \u2014 "),k7=a("a"),P6e=o("MobileBertConfig"),$6e=o(" (MobileBERT model)"),I6e=l(),xf=a("li"),KO=a("strong"),j6e=o("mpnet"),N6e=o(" \u2014 "),R7=a("a"),D6e=o("MPNetConfig"),G6e=o(" (MPNet model)"),O6e=l(),Lf=a("li"),YO=a("strong"),q6e=o("mt5"),z6e=o(" \u2014 "),S7=a("a"),X6e=o("MT5Config"),W6e=o(" (mT5 model)"),V6e=l(),Bf=a("li"),ZO=a("strong"),Q6e=o("openai-gpt"),H6e=o(" \u2014 "),P7=a("a"),U6e=o("OpenAIGPTConfig"),J6e=o(" (OpenAI GPT model)"),K6e=l(),kf=a("li"),eq=a("strong"),Y6e=o("pegasus"),Z6e=o(" \u2014 "),$7=a("a"),e8e=o("PegasusConfig"),o8e=o(" (Pegasus model)"),t8e=l(),Rf=a("li"),oq=a("strong"),r8e=o("perceiver"),a8e=o(" \u2014 "),I7=a("a"),n8e=o("PerceiverConfig"),s8e=o(" (Perceiver model)"),l8e=l(),Sf=a("li"),tq=a("strong"),i8e=o("prophetnet"),d8e=o(" \u2014 "),j7=a("a"),m8e=o("ProphetNetConfig"),f8e=o(" (ProphetNet model)"),c8e=l(),Pf=a("li"),rq=a("strong"),g8e=o("qdqbert"),h8e=o(" \u2014 "),N7=a("a"),u8e=o("QDQBertConfig"),p8e=o(" (QDQBert model)"),_8e=l(),$f=a("li"),aq=a("strong"),v8e=o("rag"),b8e=o(" \u2014 "),D7=a("a"),T8e=o("RagConfig"),F8e=o(" (RAG model)"),M8e=l(),If=a("li"),nq=a("strong"),E8e=o("reformer"),C8e=o(" \u2014 "),G7=a("a"),y8e=o("ReformerConfig"),w8e=o(" (Reformer model)"),A8e=l(),jf=a("li"),sq=a("strong"),x8e=o("rembert"),L8e=o(" \u2014 "),O7=a("a"),B8e=o("RemBertConfig"),k8e=o(" (RemBERT model)"),R8e=l(),Nf=a("li"),lq=a("strong"),S8e=o("retribert"),P8e=o(" \u2014 "),q7=a("a"),$8e=o("RetriBertConfig"),I8e=o(" (RetriBERT model)"),j8e=l(),Df=a("li"),iq=a("strong"),N8e=o("roberta"),D8e=o(" \u2014 "),z7=a("a"),G8e=o("RobertaConfig"),O8e=o(" (RoBERTa model)"),q8e=l(),Gf=a("li"),dq=a("strong"),z8e=o("roformer"),X8e=o(" \u2014 "),X7=a("a"),W8e=o("RoFormerConfig"),V8e=o(" (RoFormer model)"),Q8e=l(),Of=a("li"),mq=a("strong"),H8e=o("segformer"),U8e=o(" \u2014 "),W7=a("a"),J8e=o("SegformerConfig"),K8e=o(" (SegFormer model)"),Y8e=l(),qf=a("li"),fq=a("strong"),Z8e=o("sew"),eLe=o(" \u2014 "),V7=a("a"),oLe=o("SEWConfig"),tLe=o(" (SEW model)"),rLe=l(),zf=a("li"),cq=a("strong"),aLe=o("sew-d"),nLe=o(" \u2014 "),Q7=a("a"),sLe=o("SEWDConfig"),lLe=o(" (SEW-D model)"),iLe=l(),Xf=a("li"),gq=a("strong"),dLe=o("speech-encoder-decoder"),mLe=o(" \u2014 "),H7=a("a"),fLe=o("SpeechEncoderDecoderConfig"),cLe=o(" (Speech Encoder decoder model)"),gLe=l(),Wf=a("li"),hq=a("strong"),hLe=o("speech_to_text"),uLe=o(" \u2014 "),U7=a("a"),pLe=o("Speech2TextConfig"),_Le=o(" (Speech2Text model)"),vLe=l(),Vf=a("li"),uq=a("strong"),bLe=o("speech_to_text_2"),TLe=o(" \u2014 "),J7=a("a"),FLe=o("Speech2Text2Config"),MLe=o(" (Speech2Text2 model)"),ELe=l(),Qf=a("li"),pq=a("strong"),CLe=o("splinter"),yLe=o(" \u2014 "),K7=a("a"),wLe=o("SplinterConfig"),ALe=o(" (Splinter model)"),xLe=l(),Hf=a("li"),_q=a("strong"),LLe=o("squeezebert"),BLe=o(" \u2014 "),Y7=a("a"),kLe=o("SqueezeBertConfig"),RLe=o(" (SqueezeBERT model)"),SLe=l(),Uf=a("li"),vq=a("strong"),PLe=o("t5"),$Le=o(" \u2014 "),Z7=a("a"),ILe=o("T5Config"),jLe=o(" (T5 model)"),NLe=l(),Jf=a("li"),bq=a("strong"),DLe=o("tapas"),GLe=o(" \u2014 "),ex=a("a"),OLe=o("TapasConfig"),qLe=o(" (TAPAS model)"),zLe=l(),Kf=a("li"),Tq=a("strong"),XLe=o("transfo-xl"),WLe=o(" \u2014 "),ox=a("a"),VLe=o("TransfoXLConfig"),QLe=o(" (Transformer-XL model)"),HLe=l(),Yf=a("li"),Fq=a("strong"),ULe=o("trocr"),JLe=o(" \u2014 "),tx=a("a"),KLe=o("TrOCRConfig"),YLe=o(" (TrOCR model)"),ZLe=l(),Zf=a("li"),Mq=a("strong"),eBe=o("unispeech"),oBe=o(" \u2014 "),rx=a("a"),tBe=o("UniSpeechConfig"),rBe=o(" (UniSpeech model)"),aBe=l(),ec=a("li"),Eq=a("strong"),nBe=o("unispeech-sat"),sBe=o(" \u2014 "),ax=a("a"),lBe=o("UniSpeechSatConfig"),iBe=o(" (UniSpeechSat model)"),dBe=l(),oc=a("li"),Cq=a("strong"),mBe=o("vision-encoder-decoder"),fBe=o(" \u2014 "),nx=a("a"),cBe=o("VisionEncoderDecoderConfig"),gBe=o(" (Vision Encoder decoder model)"),hBe=l(),tc=a("li"),yq=a("strong"),uBe=o("vision-text-dual-encoder"),pBe=o(" \u2014 "),sx=a("a"),_Be=o("VisionTextDualEncoderConfig"),vBe=o(" (VisionTextDualEncoder model)"),bBe=l(),rc=a("li"),wq=a("strong"),TBe=o("visual_bert"),FBe=o(" \u2014 "),lx=a("a"),MBe=o("VisualBertConfig"),EBe=o(" (VisualBert model)"),CBe=l(),ac=a("li"),Aq=a("strong"),yBe=o("vit"),wBe=o(" \u2014 "),ix=a("a"),ABe=o("ViTConfig"),xBe=o(" (ViT model)"),LBe=l(),nc=a("li"),xq=a("strong"),BBe=o("wav2vec2"),kBe=o(" \u2014 "),dx=a("a"),RBe=o("Wav2Vec2Config"),SBe=o(" (Wav2Vec2 model)"),PBe=l(),sc=a("li"),Lq=a("strong"),$Be=o("wavlm"),IBe=o(" \u2014 "),mx=a("a"),jBe=o("WavLMConfig"),NBe=o(" (WavLM model)"),DBe=l(),lc=a("li"),Bq=a("strong"),GBe=o("xlm"),OBe=o(" \u2014 "),fx=a("a"),qBe=o("XLMConfig"),zBe=o(" (XLM model)"),XBe=l(),ic=a("li"),kq=a("strong"),WBe=o("xlm-prophetnet"),VBe=o(" \u2014 "),cx=a("a"),QBe=o("XLMProphetNetConfig"),HBe=o(" (XLMProphetNet model)"),UBe=l(),dc=a("li"),Rq=a("strong"),JBe=o("xlm-roberta"),KBe=o(" \u2014 "),gx=a("a"),YBe=o("XLMRobertaConfig"),ZBe=o(" (XLM-RoBERTa model)"),e9e=l(),mc=a("li"),Sq=a("strong"),o9e=o("xlnet"),t9e=o(" \u2014 "),hx=a("a"),r9e=o("XLNetConfig"),a9e=o(" (XLNet model)"),n9e=l(),Pq=a("p"),s9e=o("Examples:"),l9e=l(),f(zF.$$.fragment),i9e=l(),fc=a("div"),f(XF.$$.fragment),d9e=l(),$q=a("p"),m9e=o("Register a new configuration for this class."),wEe=l(),ti=a("h2"),cc=a("a"),Iq=a("span"),f(WF.$$.fragment),f9e=l(),jq=a("span"),c9e=o("AutoTokenizer"),AEe=l(),So=a("div"),f(VF.$$.fragment),g9e=l(),QF=a("p"),h9e=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ux=a("a"),u9e=o("AutoTokenizer.from_pretrained()"),p9e=o(" class method."),_9e=l(),HF=a("p"),v9e=o("This class cannot be instantiated directly using "),Nq=a("code"),b9e=o("__init__()"),T9e=o(" (throws an error)."),F9e=l(),to=a("div"),f(UF.$$.fragment),M9e=l(),Dq=a("p"),E9e=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),C9e=l(),Fa=a("p"),y9e=o("The tokenizer class to instantiate is selected based on the "),Gq=a("em"),w9e=o("model_type"),A9e=o(` property of the config object
(either passed as an argument or loaded from `),Oq=a("em"),x9e=o("pretrained_model_name_or_path"),L9e=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),qq=a("em"),B9e=o("pretrained_model_name_or_path"),k9e=o(":"),R9e=l(),E=a("ul"),vn=a("li"),zq=a("strong"),S9e=o("albert"),P9e=o(" \u2014 "),px=a("a"),$9e=o("AlbertTokenizer"),I9e=o(" or "),_x=a("a"),j9e=o("AlbertTokenizerFast"),N9e=o(" (ALBERT model)"),D9e=l(),bn=a("li"),Xq=a("strong"),G9e=o("bart"),O9e=o(" \u2014 "),vx=a("a"),q9e=o("BartTokenizer"),z9e=o(" or "),bx=a("a"),X9e=o("BartTokenizerFast"),W9e=o(" (BART model)"),V9e=l(),Tn=a("li"),Wq=a("strong"),Q9e=o("barthez"),H9e=o(" \u2014 "),Tx=a("a"),U9e=o("BarthezTokenizer"),J9e=o(" or "),Fx=a("a"),K9e=o("BarthezTokenizerFast"),Y9e=o(" (BARThez model)"),Z9e=l(),gc=a("li"),Vq=a("strong"),eke=o("bartpho"),oke=o(" \u2014 "),Mx=a("a"),tke=o("BartphoTokenizer"),rke=o(" (BARTpho model)"),ake=l(),Fn=a("li"),Qq=a("strong"),nke=o("bert"),ske=o(" \u2014 "),Ex=a("a"),lke=o("BertTokenizer"),ike=o(" or "),Cx=a("a"),dke=o("BertTokenizerFast"),mke=o(" (BERT model)"),fke=l(),hc=a("li"),Hq=a("strong"),cke=o("bert-generation"),gke=o(" \u2014 "),yx=a("a"),hke=o("BertGenerationTokenizer"),uke=o(" (Bert Generation model)"),pke=l(),uc=a("li"),Uq=a("strong"),_ke=o("bert-japanese"),vke=o(" \u2014 "),wx=a("a"),bke=o("BertJapaneseTokenizer"),Tke=o(" (BertJapanese model)"),Fke=l(),pc=a("li"),Jq=a("strong"),Mke=o("bertweet"),Eke=o(" \u2014 "),Ax=a("a"),Cke=o("BertweetTokenizer"),yke=o(" (Bertweet model)"),wke=l(),Mn=a("li"),Kq=a("strong"),Ake=o("big_bird"),xke=o(" \u2014 "),xx=a("a"),Lke=o("BigBirdTokenizer"),Bke=o(" or "),Lx=a("a"),kke=o("BigBirdTokenizerFast"),Rke=o(" (BigBird model)"),Ske=l(),En=a("li"),Yq=a("strong"),Pke=o("bigbird_pegasus"),$ke=o(" \u2014 "),Bx=a("a"),Ike=o("PegasusTokenizer"),jke=o(" or "),kx=a("a"),Nke=o("PegasusTokenizerFast"),Dke=o(" (BigBirdPegasus model)"),Gke=l(),Cn=a("li"),Zq=a("strong"),Oke=o("blenderbot"),qke=o(" \u2014 "),Rx=a("a"),zke=o("BlenderbotTokenizer"),Xke=o(" or "),Sx=a("a"),Wke=o("BlenderbotTokenizerFast"),Vke=o(" (Blenderbot model)"),Qke=l(),_c=a("li"),ez=a("strong"),Hke=o("blenderbot-small"),Uke=o(" \u2014 "),Px=a("a"),Jke=o("BlenderbotSmallTokenizer"),Kke=o(" (BlenderbotSmall model)"),Yke=l(),vc=a("li"),oz=a("strong"),Zke=o("byt5"),eRe=o(" \u2014 "),$x=a("a"),oRe=o("ByT5Tokenizer"),tRe=o(" (ByT5 model)"),rRe=l(),yn=a("li"),tz=a("strong"),aRe=o("camembert"),nRe=o(" \u2014 "),Ix=a("a"),sRe=o("CamembertTokenizer"),lRe=o(" or "),jx=a("a"),iRe=o("CamembertTokenizerFast"),dRe=o(" (CamemBERT model)"),mRe=l(),bc=a("li"),rz=a("strong"),fRe=o("canine"),cRe=o(" \u2014 "),Nx=a("a"),gRe=o("CanineTokenizer"),hRe=o(" (Canine model)"),uRe=l(),wn=a("li"),az=a("strong"),pRe=o("clip"),_Re=o(" \u2014 "),Dx=a("a"),vRe=o("CLIPTokenizer"),bRe=o(" or "),Gx=a("a"),TRe=o("CLIPTokenizerFast"),FRe=o(" (CLIP model)"),MRe=l(),An=a("li"),nz=a("strong"),ERe=o("convbert"),CRe=o(" \u2014 "),Ox=a("a"),yRe=o("ConvBertTokenizer"),wRe=o(" or "),qx=a("a"),ARe=o("ConvBertTokenizerFast"),xRe=o(" (ConvBERT model)"),LRe=l(),xn=a("li"),sz=a("strong"),BRe=o("cpm"),kRe=o(" \u2014 "),zx=a("a"),RRe=o("CpmTokenizer"),SRe=o(" or "),lz=a("code"),PRe=o("CpmTokenizerFast"),$Re=o(" (CPM model)"),IRe=l(),Tc=a("li"),iz=a("strong"),jRe=o("ctrl"),NRe=o(" \u2014 "),Xx=a("a"),DRe=o("CTRLTokenizer"),GRe=o(" (CTRL model)"),ORe=l(),Ln=a("li"),dz=a("strong"),qRe=o("deberta"),zRe=o(" \u2014 "),Wx=a("a"),XRe=o("DebertaTokenizer"),WRe=o(" or "),Vx=a("a"),VRe=o("DebertaTokenizerFast"),QRe=o(" (DeBERTa model)"),HRe=l(),Fc=a("li"),mz=a("strong"),URe=o("deberta-v2"),JRe=o(" \u2014 "),Qx=a("a"),KRe=o("DebertaV2Tokenizer"),YRe=o(" (DeBERTa-v2 model)"),ZRe=l(),Bn=a("li"),fz=a("strong"),eSe=o("distilbert"),oSe=o(" \u2014 "),Hx=a("a"),tSe=o("DistilBertTokenizer"),rSe=o(" or "),Ux=a("a"),aSe=o("DistilBertTokenizerFast"),nSe=o(" (DistilBERT model)"),sSe=l(),kn=a("li"),cz=a("strong"),lSe=o("dpr"),iSe=o(" \u2014 "),Jx=a("a"),dSe=o("DPRQuestionEncoderTokenizer"),mSe=o(" or "),Kx=a("a"),fSe=o("DPRQuestionEncoderTokenizerFast"),cSe=o(" (DPR model)"),gSe=l(),Rn=a("li"),gz=a("strong"),hSe=o("electra"),uSe=o(" \u2014 "),Yx=a("a"),pSe=o("ElectraTokenizer"),_Se=o(" or "),Zx=a("a"),vSe=o("ElectraTokenizerFast"),bSe=o(" (ELECTRA model)"),TSe=l(),Mc=a("li"),hz=a("strong"),FSe=o("flaubert"),MSe=o(" \u2014 "),e6=a("a"),ESe=o("FlaubertTokenizer"),CSe=o(" (FlauBERT model)"),ySe=l(),Sn=a("li"),uz=a("strong"),wSe=o("fnet"),ASe=o(" \u2014 "),o6=a("a"),xSe=o("FNetTokenizer"),LSe=o(" or "),t6=a("a"),BSe=o("FNetTokenizerFast"),kSe=o(" (FNet model)"),RSe=l(),Ec=a("li"),pz=a("strong"),SSe=o("fsmt"),PSe=o(" \u2014 "),r6=a("a"),$Se=o("FSMTTokenizer"),ISe=o(" (FairSeq Machine-Translation model)"),jSe=l(),Pn=a("li"),_z=a("strong"),NSe=o("funnel"),DSe=o(" \u2014 "),a6=a("a"),GSe=o("FunnelTokenizer"),OSe=o(" or "),n6=a("a"),qSe=o("FunnelTokenizerFast"),zSe=o(" (Funnel Transformer model)"),XSe=l(),$n=a("li"),vz=a("strong"),WSe=o("gpt2"),VSe=o(" \u2014 "),s6=a("a"),QSe=o("GPT2Tokenizer"),HSe=o(" or "),l6=a("a"),USe=o("GPT2TokenizerFast"),JSe=o(" (OpenAI GPT-2 model)"),KSe=l(),In=a("li"),bz=a("strong"),YSe=o("gpt_neo"),ZSe=o(" \u2014 "),i6=a("a"),ePe=o("GPT2Tokenizer"),oPe=o(" or "),d6=a("a"),tPe=o("GPT2TokenizerFast"),rPe=o(" (GPT Neo model)"),aPe=l(),Cc=a("li"),Tz=a("strong"),nPe=o("hubert"),sPe=o(" \u2014 "),m6=a("a"),lPe=o("Wav2Vec2CTCTokenizer"),iPe=o(" (Hubert model)"),dPe=l(),jn=a("li"),Fz=a("strong"),mPe=o("ibert"),fPe=o(" \u2014 "),f6=a("a"),cPe=o("RobertaTokenizer"),gPe=o(" or "),c6=a("a"),hPe=o("RobertaTokenizerFast"),uPe=o(" (I-BERT model)"),pPe=l(),Nn=a("li"),Mz=a("strong"),_Pe=o("layoutlm"),vPe=o(" \u2014 "),g6=a("a"),bPe=o("LayoutLMTokenizer"),TPe=o(" or "),h6=a("a"),FPe=o("LayoutLMTokenizerFast"),MPe=o(" (LayoutLM model)"),EPe=l(),Dn=a("li"),Ez=a("strong"),CPe=o("layoutlmv2"),yPe=o(" \u2014 "),u6=a("a"),wPe=o("LayoutLMv2Tokenizer"),APe=o(" or "),p6=a("a"),xPe=o("LayoutLMv2TokenizerFast"),LPe=o(" (LayoutLMv2 model)"),BPe=l(),Gn=a("li"),Cz=a("strong"),kPe=o("led"),RPe=o(" \u2014 "),_6=a("a"),SPe=o("LEDTokenizer"),PPe=o(" or "),v6=a("a"),$Pe=o("LEDTokenizerFast"),IPe=o(" (LED model)"),jPe=l(),On=a("li"),yz=a("strong"),NPe=o("longformer"),DPe=o(" \u2014 "),b6=a("a"),GPe=o("LongformerTokenizer"),OPe=o(" or "),T6=a("a"),qPe=o("LongformerTokenizerFast"),zPe=o(" (Longformer model)"),XPe=l(),yc=a("li"),wz=a("strong"),WPe=o("luke"),VPe=o(" \u2014 "),F6=a("a"),QPe=o("LukeTokenizer"),HPe=o(" (LUKE model)"),UPe=l(),qn=a("li"),Az=a("strong"),JPe=o("lxmert"),KPe=o(" \u2014 "),M6=a("a"),YPe=o("LxmertTokenizer"),ZPe=o(" or "),E6=a("a"),e$e=o("LxmertTokenizerFast"),o$e=o(" (LXMERT model)"),t$e=l(),wc=a("li"),xz=a("strong"),r$e=o("m2m_100"),a$e=o(" \u2014 "),C6=a("a"),n$e=o("M2M100Tokenizer"),s$e=o(" (M2M100 model)"),l$e=l(),Ac=a("li"),Lz=a("strong"),i$e=o("marian"),d$e=o(" \u2014 "),y6=a("a"),m$e=o("MarianTokenizer"),f$e=o(" (Marian model)"),c$e=l(),zn=a("li"),Bz=a("strong"),g$e=o("mbart"),h$e=o(" \u2014 "),w6=a("a"),u$e=o("MBartTokenizer"),p$e=o(" or "),A6=a("a"),_$e=o("MBartTokenizerFast"),v$e=o(" (mBART model)"),b$e=l(),Xn=a("li"),kz=a("strong"),T$e=o("mbart50"),F$e=o(" \u2014 "),x6=a("a"),M$e=o("MBart50Tokenizer"),E$e=o(" or "),L6=a("a"),C$e=o("MBart50TokenizerFast"),y$e=o(" (mBART-50 model)"),w$e=l(),Wn=a("li"),Rz=a("strong"),A$e=o("mobilebert"),x$e=o(" \u2014 "),B6=a("a"),L$e=o("MobileBertTokenizer"),B$e=o(" or "),k6=a("a"),k$e=o("MobileBertTokenizerFast"),R$e=o(" (MobileBERT model)"),S$e=l(),Vn=a("li"),Sz=a("strong"),P$e=o("mpnet"),$$e=o(" \u2014 "),R6=a("a"),I$e=o("MPNetTokenizer"),j$e=o(" or "),S6=a("a"),N$e=o("MPNetTokenizerFast"),D$e=o(" (MPNet model)"),G$e=l(),Qn=a("li"),Pz=a("strong"),O$e=o("mt5"),q$e=o(" \u2014 "),P6=a("a"),z$e=o("MT5Tokenizer"),X$e=o(" or "),$6=a("a"),W$e=o("MT5TokenizerFast"),V$e=o(" (mT5 model)"),Q$e=l(),Hn=a("li"),$z=a("strong"),H$e=o("openai-gpt"),U$e=o(" \u2014 "),I6=a("a"),J$e=o("OpenAIGPTTokenizer"),K$e=o(" or "),j6=a("a"),Y$e=o("OpenAIGPTTokenizerFast"),Z$e=o(" (OpenAI GPT model)"),eIe=l(),Un=a("li"),Iz=a("strong"),oIe=o("pegasus"),tIe=o(" \u2014 "),N6=a("a"),rIe=o("PegasusTokenizer"),aIe=o(" or "),D6=a("a"),nIe=o("PegasusTokenizerFast"),sIe=o(" (Pegasus model)"),lIe=l(),xc=a("li"),jz=a("strong"),iIe=o("perceiver"),dIe=o(" \u2014 "),G6=a("a"),mIe=o("PerceiverTokenizer"),fIe=o(" (Perceiver model)"),cIe=l(),Lc=a("li"),Nz=a("strong"),gIe=o("phobert"),hIe=o(" \u2014 "),O6=a("a"),uIe=o("PhobertTokenizer"),pIe=o(" (PhoBERT model)"),_Ie=l(),Bc=a("li"),Dz=a("strong"),vIe=o("prophetnet"),bIe=o(" \u2014 "),q6=a("a"),TIe=o("ProphetNetTokenizer"),FIe=o(" (ProphetNet model)"),MIe=l(),Jn=a("li"),Gz=a("strong"),EIe=o("qdqbert"),CIe=o(" \u2014 "),z6=a("a"),yIe=o("BertTokenizer"),wIe=o(" or "),X6=a("a"),AIe=o("BertTokenizerFast"),xIe=o(" (QDQBert model)"),LIe=l(),kc=a("li"),Oz=a("strong"),BIe=o("rag"),kIe=o(" \u2014 "),W6=a("a"),RIe=o("RagTokenizer"),SIe=o(" (RAG model)"),PIe=l(),Kn=a("li"),qz=a("strong"),$Ie=o("reformer"),IIe=o(" \u2014 "),V6=a("a"),jIe=o("ReformerTokenizer"),NIe=o(" or "),Q6=a("a"),DIe=o("ReformerTokenizerFast"),GIe=o(" (Reformer model)"),OIe=l(),Yn=a("li"),zz=a("strong"),qIe=o("rembert"),zIe=o(" \u2014 "),H6=a("a"),XIe=o("RemBertTokenizer"),WIe=o(" or "),U6=a("a"),VIe=o("RemBertTokenizerFast"),QIe=o(" (RemBERT model)"),HIe=l(),Zn=a("li"),Xz=a("strong"),UIe=o("retribert"),JIe=o(" \u2014 "),J6=a("a"),KIe=o("RetriBertTokenizer"),YIe=o(" or "),K6=a("a"),ZIe=o("RetriBertTokenizerFast"),eje=o(" (RetriBERT model)"),oje=l(),es=a("li"),Wz=a("strong"),tje=o("roberta"),rje=o(" \u2014 "),Y6=a("a"),aje=o("RobertaTokenizer"),nje=o(" or "),Z6=a("a"),sje=o("RobertaTokenizerFast"),lje=o(" (RoBERTa model)"),ije=l(),os=a("li"),Vz=a("strong"),dje=o("roformer"),mje=o(" \u2014 "),e8=a("a"),fje=o("RoFormerTokenizer"),cje=o(" or "),o8=a("a"),gje=o("RoFormerTokenizerFast"),hje=o(" (RoFormer model)"),uje=l(),Rc=a("li"),Qz=a("strong"),pje=o("speech_to_text"),_je=o(" \u2014 "),t8=a("a"),vje=o("Speech2TextTokenizer"),bje=o(" (Speech2Text model)"),Tje=l(),Sc=a("li"),Hz=a("strong"),Fje=o("speech_to_text_2"),Mje=o(" \u2014 "),r8=a("a"),Eje=o("Speech2Text2Tokenizer"),Cje=o(" (Speech2Text2 model)"),yje=l(),ts=a("li"),Uz=a("strong"),wje=o("splinter"),Aje=o(" \u2014 "),a8=a("a"),xje=o("SplinterTokenizer"),Lje=o(" or "),n8=a("a"),Bje=o("SplinterTokenizerFast"),kje=o(" (Splinter model)"),Rje=l(),rs=a("li"),Jz=a("strong"),Sje=o("squeezebert"),Pje=o(" \u2014 "),s8=a("a"),$je=o("SqueezeBertTokenizer"),Ije=o(" or "),l8=a("a"),jje=o("SqueezeBertTokenizerFast"),Nje=o(" (SqueezeBERT model)"),Dje=l(),as=a("li"),Kz=a("strong"),Gje=o("t5"),Oje=o(" \u2014 "),i8=a("a"),qje=o("T5Tokenizer"),zje=o(" or "),d8=a("a"),Xje=o("T5TokenizerFast"),Wje=o(" (T5 model)"),Vje=l(),Pc=a("li"),Yz=a("strong"),Qje=o("tapas"),Hje=o(" \u2014 "),m8=a("a"),Uje=o("TapasTokenizer"),Jje=o(" (TAPAS model)"),Kje=l(),$c=a("li"),Zz=a("strong"),Yje=o("transfo-xl"),Zje=o(" \u2014 "),f8=a("a"),eNe=o("TransfoXLTokenizer"),oNe=o(" (Transformer-XL model)"),tNe=l(),Ic=a("li"),eX=a("strong"),rNe=o("wav2vec2"),aNe=o(" \u2014 "),c8=a("a"),nNe=o("Wav2Vec2CTCTokenizer"),sNe=o(" (Wav2Vec2 model)"),lNe=l(),jc=a("li"),oX=a("strong"),iNe=o("xlm"),dNe=o(" \u2014 "),g8=a("a"),mNe=o("XLMTokenizer"),fNe=o(" (XLM model)"),cNe=l(),Nc=a("li"),tX=a("strong"),gNe=o("xlm-prophetnet"),hNe=o(" \u2014 "),h8=a("a"),uNe=o("XLMProphetNetTokenizer"),pNe=o(" (XLMProphetNet model)"),_Ne=l(),ns=a("li"),rX=a("strong"),vNe=o("xlm-roberta"),bNe=o(" \u2014 "),u8=a("a"),TNe=o("XLMRobertaTokenizer"),FNe=o(" or "),p8=a("a"),MNe=o("XLMRobertaTokenizerFast"),ENe=o(" (XLM-RoBERTa model)"),CNe=l(),ss=a("li"),aX=a("strong"),yNe=o("xlnet"),wNe=o(" \u2014 "),_8=a("a"),ANe=o("XLNetTokenizer"),xNe=o(" or "),v8=a("a"),LNe=o("XLNetTokenizerFast"),BNe=o(" (XLNet model)"),kNe=l(),nX=a("p"),RNe=o("Examples:"),SNe=l(),f(JF.$$.fragment),PNe=l(),Dc=a("div"),f(KF.$$.fragment),$Ne=l(),sX=a("p"),INe=o("Register a new tokenizer in this mapping."),xEe=l(),ri=a("h2"),Gc=a("a"),lX=a("span"),f(YF.$$.fragment),jNe=l(),iX=a("span"),NNe=o("AutoFeatureExtractor"),LEe=l(),Gr=a("div"),f(ZF.$$.fragment),DNe=l(),eM=a("p"),GNe=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),b8=a("a"),ONe=o("AutoFeatureExtractor.from_pretrained()"),qNe=o(" class method."),zNe=l(),oM=a("p"),XNe=o("This class cannot be instantiated directly using "),dX=a("code"),WNe=o("__init__()"),VNe=o(" (throws an error)."),QNe=l(),we=a("div"),f(tM.$$.fragment),HNe=l(),mX=a("p"),UNe=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),JNe=l(),Ma=a("p"),KNe=o("The feature extractor class to instantiate is selected based on the "),fX=a("em"),YNe=o("model_type"),ZNe=o(` property of the config
object (either passed as an argument or loaded from `),cX=a("em"),eDe=o("pretrained_model_name_or_path"),oDe=o(` if possible), or when
it\u2019s missing, by falling back to using pattern matching on `),gX=a("em"),tDe=o("pretrained_model_name_or_path"),rDe=o(":"),aDe=l(),fe=a("ul"),Oc=a("li"),hX=a("strong"),nDe=o("beit"),sDe=o(" \u2014 "),T8=a("a"),lDe=o("BeitFeatureExtractor"),iDe=o(" (BEiT model)"),dDe=l(),qc=a("li"),uX=a("strong"),mDe=o("clip"),fDe=o(" \u2014 "),F8=a("a"),cDe=o("CLIPFeatureExtractor"),gDe=o(" (CLIP model)"),hDe=l(),zc=a("li"),pX=a("strong"),uDe=o("deit"),pDe=o(" \u2014 "),M8=a("a"),_De=o("DeiTFeatureExtractor"),vDe=o(" (DeiT model)"),bDe=l(),Xc=a("li"),_X=a("strong"),TDe=o("detr"),FDe=o(" \u2014 "),E8=a("a"),MDe=o("DetrFeatureExtractor"),EDe=o(" (DETR model)"),CDe=l(),Wc=a("li"),vX=a("strong"),yDe=o("hubert"),wDe=o(" \u2014 "),C8=a("a"),ADe=o("Wav2Vec2FeatureExtractor"),xDe=o(" (Hubert model)"),LDe=l(),Vc=a("li"),bX=a("strong"),BDe=o("layoutlmv2"),kDe=o(" \u2014 "),y8=a("a"),RDe=o("LayoutLMv2FeatureExtractor"),SDe=o(" (LayoutLMv2 model)"),PDe=l(),Qc=a("li"),TX=a("strong"),$De=o("perceiver"),IDe=o(" \u2014 "),w8=a("a"),jDe=o("PerceiverFeatureExtractor"),NDe=o(" (Perceiver model)"),DDe=l(),Hc=a("li"),FX=a("strong"),GDe=o("speech_to_text"),ODe=o(" \u2014 "),A8=a("a"),qDe=o("Speech2TextFeatureExtractor"),zDe=o(" (Speech2Text model)"),XDe=l(),Uc=a("li"),MX=a("strong"),WDe=o("vit"),VDe=o(" \u2014 "),x8=a("a"),QDe=o("ViTFeatureExtractor"),HDe=o(" (ViT model)"),UDe=l(),Jc=a("li"),EX=a("strong"),JDe=o("wav2vec2"),KDe=o(" \u2014 "),L8=a("a"),YDe=o("Wav2Vec2FeatureExtractor"),ZDe=o(" (Wav2Vec2 model)"),eGe=l(),f(Kc.$$.fragment),oGe=l(),CX=a("p"),tGe=o("Examples:"),rGe=l(),f(rM.$$.fragment),BEe=l(),ai=a("h2"),Yc=a("a"),yX=a("span"),f(aM.$$.fragment),aGe=l(),wX=a("span"),nGe=o("AutoProcessor"),kEe=l(),Or=a("div"),f(nM.$$.fragment),sGe=l(),sM=a("p"),lGe=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),B8=a("a"),iGe=o("AutoProcessor.from_pretrained()"),dGe=o(" class method."),mGe=l(),lM=a("p"),fGe=o("This class cannot be instantiated directly using "),AX=a("code"),cGe=o("__init__()"),gGe=o(" (throws an error)."),hGe=l(),Ae=a("div"),f(iM.$$.fragment),uGe=l(),xX=a("p"),pGe=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),_Ge=l(),ni=a("p"),vGe=o("The processor class to instantiate is selected based on the "),LX=a("em"),bGe=o("model_type"),TGe=o(` property of the config object
(either passed as an argument or loaded from `),BX=a("em"),FGe=o("pretrained_model_name_or_path"),MGe=o(" if possible):"),EGe=l(),Je=a("ul"),Zc=a("li"),kX=a("strong"),CGe=o("clip"),yGe=o(" \u2014 "),k8=a("a"),wGe=o("CLIPProcessor"),AGe=o(" (CLIP model)"),xGe=l(),eg=a("li"),RX=a("strong"),LGe=o("layoutlmv2"),BGe=o(" \u2014 "),R8=a("a"),kGe=o("LayoutLMv2Processor"),RGe=o(" (LayoutLMv2 model)"),SGe=l(),og=a("li"),SX=a("strong"),PGe=o("speech_to_text"),$Ge=o(" \u2014 "),S8=a("a"),IGe=o("Speech2TextProcessor"),jGe=o(" (Speech2Text model)"),NGe=l(),tg=a("li"),PX=a("strong"),DGe=o("speech_to_text_2"),GGe=o(" \u2014 "),P8=a("a"),OGe=o("Speech2Text2Processor"),qGe=o(" (Speech2Text2 model)"),zGe=l(),rg=a("li"),$X=a("strong"),XGe=o("trocr"),WGe=o(" \u2014 "),$8=a("a"),VGe=o("TrOCRProcessor"),QGe=o(" (TrOCR model)"),HGe=l(),ag=a("li"),IX=a("strong"),UGe=o("vision-text-dual-encoder"),JGe=o(" \u2014 "),I8=a("a"),KGe=o("VisionTextDualEncoderProcessor"),YGe=o(" (VisionTextDualEncoder model)"),ZGe=l(),ng=a("li"),jX=a("strong"),eOe=o("wav2vec2"),oOe=o(" \u2014 "),j8=a("a"),tOe=o("Wav2Vec2Processor"),rOe=o(" (Wav2Vec2 model)"),aOe=l(),f(sg.$$.fragment),nOe=l(),NX=a("p"),sOe=o("Examples:"),lOe=l(),f(dM.$$.fragment),REe=l(),si=a("h2"),lg=a("a"),DX=a("span"),f(mM.$$.fragment),iOe=l(),GX=a("span"),dOe=o("AutoModel"),SEe=l(),Po=a("div"),f(fM.$$.fragment),mOe=l(),li=a("p"),fOe=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),OX=a("code"),cOe=o("from_pretrained()"),gOe=o(` class method or the
`),qX=a("code"),hOe=o("from_config()"),uOe=o(" class method."),pOe=l(),cM=a("p"),_Oe=o("This class cannot be instantiated directly using "),zX=a("code"),vOe=o("__init__()"),bOe=o(" (throws an error)."),TOe=l(),wt=a("div"),f(gM.$$.fragment),FOe=l(),XX=a("p"),MOe=o("Instantiates one of the base model classes of the library from a configuration."),EOe=l(),ii=a("p"),COe=o(`Note:
Loading a model from its configuration file does `),WX=a("strong"),yOe=o("not"),wOe=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),VX=a("em"),AOe=o("~AutoModel.from_pretrained"),xOe=o(`] to load the model
weights.`),LOe=l(),QX=a("p"),BOe=o("Examples:"),kOe=l(),f(hM.$$.fragment),ROe=l(),xe=a("div"),f(uM.$$.fragment),SOe=l(),HX=a("p"),POe=o("Instantiate one of the base model classes of the library from a pretrained model."),$Oe=l(),Ea=a("p"),IOe=o("The model class to instantiate is selected based on the "),UX=a("em"),jOe=o("model_type"),NOe=o(` property of the config object (either
passed as an argument or loaded from `),JX=a("em"),DOe=o("pretrained_model_name_or_path"),GOe=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),KX=a("em"),OOe=o("pretrained_model_name_or_path"),qOe=o(":"),zOe=l(),F=a("ul"),ig=a("li"),YX=a("strong"),XOe=o("albert"),WOe=o(" \u2014 "),N8=a("a"),VOe=o("AlbertModel"),QOe=o(" (ALBERT model)"),HOe=l(),dg=a("li"),ZX=a("strong"),UOe=o("bart"),JOe=o(" \u2014 "),D8=a("a"),KOe=o("BartModel"),YOe=o(" (BART model)"),ZOe=l(),mg=a("li"),eW=a("strong"),eqe=o("beit"),oqe=o(" \u2014 "),G8=a("a"),tqe=o("BeitModel"),rqe=o(" (BEiT model)"),aqe=l(),fg=a("li"),oW=a("strong"),nqe=o("bert"),sqe=o(" \u2014 "),O8=a("a"),lqe=o("BertModel"),iqe=o(" (BERT model)"),dqe=l(),cg=a("li"),tW=a("strong"),mqe=o("bert-generation"),fqe=o(" \u2014 "),q8=a("a"),cqe=o("BertGenerationEncoder"),gqe=o(" (Bert Generation model)"),hqe=l(),gg=a("li"),rW=a("strong"),uqe=o("big_bird"),pqe=o(" \u2014 "),z8=a("a"),_qe=o("BigBirdModel"),vqe=o(" (BigBird model)"),bqe=l(),hg=a("li"),aW=a("strong"),Tqe=o("bigbird_pegasus"),Fqe=o(" \u2014 "),X8=a("a"),Mqe=o("BigBirdPegasusModel"),Eqe=o(" (BigBirdPegasus model)"),Cqe=l(),ug=a("li"),nW=a("strong"),yqe=o("blenderbot"),wqe=o(" \u2014 "),W8=a("a"),Aqe=o("BlenderbotModel"),xqe=o(" (Blenderbot model)"),Lqe=l(),pg=a("li"),sW=a("strong"),Bqe=o("blenderbot-small"),kqe=o(" \u2014 "),V8=a("a"),Rqe=o("BlenderbotSmallModel"),Sqe=o(" (BlenderbotSmall model)"),Pqe=l(),_g=a("li"),lW=a("strong"),$qe=o("camembert"),Iqe=o(" \u2014 "),Q8=a("a"),jqe=o("CamembertModel"),Nqe=o(" (CamemBERT model)"),Dqe=l(),vg=a("li"),iW=a("strong"),Gqe=o("canine"),Oqe=o(" \u2014 "),H8=a("a"),qqe=o("CanineModel"),zqe=o(" (Canine model)"),Xqe=l(),bg=a("li"),dW=a("strong"),Wqe=o("clip"),Vqe=o(" \u2014 "),U8=a("a"),Qqe=o("CLIPModel"),Hqe=o(" (CLIP model)"),Uqe=l(),Tg=a("li"),mW=a("strong"),Jqe=o("convbert"),Kqe=o(" \u2014 "),J8=a("a"),Yqe=o("ConvBertModel"),Zqe=o(" (ConvBERT model)"),eze=l(),Fg=a("li"),fW=a("strong"),oze=o("ctrl"),tze=o(" \u2014 "),K8=a("a"),rze=o("CTRLModel"),aze=o(" (CTRL model)"),nze=l(),Mg=a("li"),cW=a("strong"),sze=o("deberta"),lze=o(" \u2014 "),Y8=a("a"),ize=o("DebertaModel"),dze=o(" (DeBERTa model)"),mze=l(),Eg=a("li"),gW=a("strong"),fze=o("deberta-v2"),cze=o(" \u2014 "),Z8=a("a"),gze=o("DebertaV2Model"),hze=o(" (DeBERTa-v2 model)"),uze=l(),Cg=a("li"),hW=a("strong"),pze=o("deit"),_ze=o(" \u2014 "),eL=a("a"),vze=o("DeiTModel"),bze=o(" (DeiT model)"),Tze=l(),yg=a("li"),uW=a("strong"),Fze=o("detr"),Mze=o(" \u2014 "),oL=a("a"),Eze=o("DetrModel"),Cze=o(" (DETR model)"),yze=l(),wg=a("li"),pW=a("strong"),wze=o("distilbert"),Aze=o(" \u2014 "),tL=a("a"),xze=o("DistilBertModel"),Lze=o(" (DistilBERT model)"),Bze=l(),Ag=a("li"),_W=a("strong"),kze=o("dpr"),Rze=o(" \u2014 "),rL=a("a"),Sze=o("DPRQuestionEncoder"),Pze=o(" (DPR model)"),$ze=l(),xg=a("li"),vW=a("strong"),Ize=o("electra"),jze=o(" \u2014 "),aL=a("a"),Nze=o("ElectraModel"),Dze=o(" (ELECTRA model)"),Gze=l(),Lg=a("li"),bW=a("strong"),Oze=o("flaubert"),qze=o(" \u2014 "),nL=a("a"),zze=o("FlaubertModel"),Xze=o(" (FlauBERT model)"),Wze=l(),Bg=a("li"),TW=a("strong"),Vze=o("fnet"),Qze=o(" \u2014 "),sL=a("a"),Hze=o("FNetModel"),Uze=o(" (FNet model)"),Jze=l(),kg=a("li"),FW=a("strong"),Kze=o("fsmt"),Yze=o(" \u2014 "),lL=a("a"),Zze=o("FSMTModel"),eXe=o(" (FairSeq Machine-Translation model)"),oXe=l(),ls=a("li"),MW=a("strong"),tXe=o("funnel"),rXe=o(" \u2014 "),iL=a("a"),aXe=o("FunnelModel"),nXe=o(" or "),dL=a("a"),sXe=o("FunnelBaseModel"),lXe=o(" (Funnel Transformer model)"),iXe=l(),Rg=a("li"),EW=a("strong"),dXe=o("gpt2"),mXe=o(" \u2014 "),mL=a("a"),fXe=o("GPT2Model"),cXe=o(" (OpenAI GPT-2 model)"),gXe=l(),Sg=a("li"),CW=a("strong"),hXe=o("gpt_neo"),uXe=o(" \u2014 "),fL=a("a"),pXe=o("GPTNeoModel"),_Xe=o(" (GPT Neo model)"),vXe=l(),Pg=a("li"),yW=a("strong"),bXe=o("gptj"),TXe=o(" \u2014 "),cL=a("a"),FXe=o("GPTJModel"),MXe=o(" (GPT-J model)"),EXe=l(),$g=a("li"),wW=a("strong"),CXe=o("hubert"),yXe=o(" \u2014 "),gL=a("a"),wXe=o("HubertModel"),AXe=o(" (Hubert model)"),xXe=l(),Ig=a("li"),AW=a("strong"),LXe=o("ibert"),BXe=o(" \u2014 "),hL=a("a"),kXe=o("IBertModel"),RXe=o(" (I-BERT model)"),SXe=l(),jg=a("li"),xW=a("strong"),PXe=o("imagegpt"),$Xe=o(" \u2014 "),uL=a("a"),IXe=o("ImageGPTModel"),jXe=o(" (ImageGPT model)"),NXe=l(),Ng=a("li"),LW=a("strong"),DXe=o("layoutlm"),GXe=o(" \u2014 "),pL=a("a"),OXe=o("LayoutLMModel"),qXe=o(" (LayoutLM model)"),zXe=l(),Dg=a("li"),BW=a("strong"),XXe=o("layoutlmv2"),WXe=o(" \u2014 "),_L=a("a"),VXe=o("LayoutLMv2Model"),QXe=o(" (LayoutLMv2 model)"),HXe=l(),Gg=a("li"),kW=a("strong"),UXe=o("led"),JXe=o(" \u2014 "),vL=a("a"),KXe=o("LEDModel"),YXe=o(" (LED model)"),ZXe=l(),Og=a("li"),RW=a("strong"),eWe=o("longformer"),oWe=o(" \u2014 "),bL=a("a"),tWe=o("LongformerModel"),rWe=o(" (Longformer model)"),aWe=l(),qg=a("li"),SW=a("strong"),nWe=o("luke"),sWe=o(" \u2014 "),TL=a("a"),lWe=o("LukeModel"),iWe=o(" (LUKE model)"),dWe=l(),zg=a("li"),PW=a("strong"),mWe=o("lxmert"),fWe=o(" \u2014 "),FL=a("a"),cWe=o("LxmertModel"),gWe=o(" (LXMERT model)"),hWe=l(),Xg=a("li"),$W=a("strong"),uWe=o("m2m_100"),pWe=o(" \u2014 "),ML=a("a"),_We=o("M2M100Model"),vWe=o(" (M2M100 model)"),bWe=l(),Wg=a("li"),IW=a("strong"),TWe=o("marian"),FWe=o(" \u2014 "),EL=a("a"),MWe=o("MarianModel"),EWe=o(" (Marian model)"),CWe=l(),Vg=a("li"),jW=a("strong"),yWe=o("mbart"),wWe=o(" \u2014 "),CL=a("a"),AWe=o("MBartModel"),xWe=o(" (mBART model)"),LWe=l(),Qg=a("li"),NW=a("strong"),BWe=o("megatron-bert"),kWe=o(" \u2014 "),yL=a("a"),RWe=o("MegatronBertModel"),SWe=o(" (MegatronBert model)"),PWe=l(),Hg=a("li"),DW=a("strong"),$We=o("mobilebert"),IWe=o(" \u2014 "),wL=a("a"),jWe=o("MobileBertModel"),NWe=o(" (MobileBERT model)"),DWe=l(),Ug=a("li"),GW=a("strong"),GWe=o("mpnet"),OWe=o(" \u2014 "),AL=a("a"),qWe=o("MPNetModel"),zWe=o(" (MPNet model)"),XWe=l(),Jg=a("li"),OW=a("strong"),WWe=o("mt5"),VWe=o(" \u2014 "),xL=a("a"),QWe=o("MT5Model"),HWe=o(" (mT5 model)"),UWe=l(),Kg=a("li"),qW=a("strong"),JWe=o("openai-gpt"),KWe=o(" \u2014 "),LL=a("a"),YWe=o("OpenAIGPTModel"),ZWe=o(" (OpenAI GPT model)"),eVe=l(),Yg=a("li"),zW=a("strong"),oVe=o("pegasus"),tVe=o(" \u2014 "),BL=a("a"),rVe=o("PegasusModel"),aVe=o(" (Pegasus model)"),nVe=l(),Zg=a("li"),XW=a("strong"),sVe=o("perceiver"),lVe=o(" \u2014 "),kL=a("a"),iVe=o("PerceiverModel"),dVe=o(" (Perceiver model)"),mVe=l(),eh=a("li"),WW=a("strong"),fVe=o("prophetnet"),cVe=o(" \u2014 "),RL=a("a"),gVe=o("ProphetNetModel"),hVe=o(" (ProphetNet model)"),uVe=l(),oh=a("li"),VW=a("strong"),pVe=o("qdqbert"),_Ve=o(" \u2014 "),SL=a("a"),vVe=o("QDQBertModel"),bVe=o(" (QDQBert model)"),TVe=l(),th=a("li"),QW=a("strong"),FVe=o("reformer"),MVe=o(" \u2014 "),PL=a("a"),EVe=o("ReformerModel"),CVe=o(" (Reformer model)"),yVe=l(),rh=a("li"),HW=a("strong"),wVe=o("rembert"),AVe=o(" \u2014 "),$L=a("a"),xVe=o("RemBertModel"),LVe=o(" (RemBERT model)"),BVe=l(),ah=a("li"),UW=a("strong"),kVe=o("retribert"),RVe=o(" \u2014 "),IL=a("a"),SVe=o("RetriBertModel"),PVe=o(" (RetriBERT model)"),$Ve=l(),nh=a("li"),JW=a("strong"),IVe=o("roberta"),jVe=o(" \u2014 "),jL=a("a"),NVe=o("RobertaModel"),DVe=o(" (RoBERTa model)"),GVe=l(),sh=a("li"),KW=a("strong"),OVe=o("roformer"),qVe=o(" \u2014 "),NL=a("a"),zVe=o("RoFormerModel"),XVe=o(" (RoFormer model)"),WVe=l(),lh=a("li"),YW=a("strong"),VVe=o("segformer"),QVe=o(" \u2014 "),DL=a("a"),HVe=o("SegformerModel"),UVe=o(" (SegFormer model)"),JVe=l(),ih=a("li"),ZW=a("strong"),KVe=o("sew"),YVe=o(" \u2014 "),GL=a("a"),ZVe=o("SEWModel"),eQe=o(" (SEW model)"),oQe=l(),dh=a("li"),eV=a("strong"),tQe=o("sew-d"),rQe=o(" \u2014 "),OL=a("a"),aQe=o("SEWDModel"),nQe=o(" (SEW-D model)"),sQe=l(),mh=a("li"),oV=a("strong"),lQe=o("speech_to_text"),iQe=o(" \u2014 "),qL=a("a"),dQe=o("Speech2TextModel"),mQe=o(" (Speech2Text model)"),fQe=l(),fh=a("li"),tV=a("strong"),cQe=o("splinter"),gQe=o(" \u2014 "),zL=a("a"),hQe=o("SplinterModel"),uQe=o(" (Splinter model)"),pQe=l(),ch=a("li"),rV=a("strong"),_Qe=o("squeezebert"),vQe=o(" \u2014 "),XL=a("a"),bQe=o("SqueezeBertModel"),TQe=o(" (SqueezeBERT model)"),FQe=l(),gh=a("li"),aV=a("strong"),MQe=o("t5"),EQe=o(" \u2014 "),WL=a("a"),CQe=o("T5Model"),yQe=o(" (T5 model)"),wQe=l(),hh=a("li"),nV=a("strong"),AQe=o("tapas"),xQe=o(" \u2014 "),VL=a("a"),LQe=o("TapasModel"),BQe=o(" (TAPAS model)"),kQe=l(),uh=a("li"),sV=a("strong"),RQe=o("transfo-xl"),SQe=o(" \u2014 "),QL=a("a"),PQe=o("TransfoXLModel"),$Qe=o(" (Transformer-XL model)"),IQe=l(),ph=a("li"),lV=a("strong"),jQe=o("unispeech"),NQe=o(" \u2014 "),HL=a("a"),DQe=o("UniSpeechModel"),GQe=o(" (UniSpeech model)"),OQe=l(),_h=a("li"),iV=a("strong"),qQe=o("unispeech-sat"),zQe=o(" \u2014 "),UL=a("a"),XQe=o("UniSpeechSatModel"),WQe=o(" (UniSpeechSat model)"),VQe=l(),vh=a("li"),dV=a("strong"),QQe=o("vision-text-dual-encoder"),HQe=o(" \u2014 "),JL=a("a"),UQe=o("VisionTextDualEncoderModel"),JQe=o(" (VisionTextDualEncoder model)"),KQe=l(),bh=a("li"),mV=a("strong"),YQe=o("visual_bert"),ZQe=o(" \u2014 "),KL=a("a"),eHe=o("VisualBertModel"),oHe=o(" (VisualBert model)"),tHe=l(),Th=a("li"),fV=a("strong"),rHe=o("vit"),aHe=o(" \u2014 "),YL=a("a"),nHe=o("ViTModel"),sHe=o(" (ViT model)"),lHe=l(),Fh=a("li"),cV=a("strong"),iHe=o("wav2vec2"),dHe=o(" \u2014 "),ZL=a("a"),mHe=o("Wav2Vec2Model"),fHe=o(" (Wav2Vec2 model)"),cHe=l(),Mh=a("li"),gV=a("strong"),gHe=o("wavlm"),hHe=o(" \u2014 "),eB=a("a"),uHe=o("WavLMModel"),pHe=o(" (WavLM model)"),_He=l(),Eh=a("li"),hV=a("strong"),vHe=o("xlm"),bHe=o(" \u2014 "),oB=a("a"),THe=o("XLMModel"),FHe=o(" (XLM model)"),MHe=l(),Ch=a("li"),uV=a("strong"),EHe=o("xlm-prophetnet"),CHe=o(" \u2014 "),tB=a("a"),yHe=o("XLMProphetNetModel"),wHe=o(" (XLMProphetNet model)"),AHe=l(),yh=a("li"),pV=a("strong"),xHe=o("xlm-roberta"),LHe=o(" \u2014 "),rB=a("a"),BHe=o("XLMRobertaModel"),kHe=o(" (XLM-RoBERTa model)"),RHe=l(),wh=a("li"),_V=a("strong"),SHe=o("xlnet"),PHe=o(" \u2014 "),aB=a("a"),$He=o("XLNetModel"),IHe=o(" (XLNet model)"),jHe=l(),Ah=a("p"),NHe=o("The model is set in evaluation mode by default using "),vV=a("em"),DHe=o("model.eval()"),GHe=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bV=a("em"),OHe=o("model.train()"),qHe=l(),TV=a("p"),zHe=o("Examples:"),XHe=l(),f(pM.$$.fragment),PEe=l(),di=a("h2"),xh=a("a"),FV=a("span"),f(_M.$$.fragment),WHe=l(),MV=a("span"),VHe=o("AutoModelForPreTraining"),$Ee=l(),$o=a("div"),f(vM.$$.fragment),QHe=l(),mi=a("p"),HHe=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EV=a("code"),UHe=o("from_pretrained()"),JHe=o(` class method or the
`),CV=a("code"),KHe=o("from_config()"),YHe=o(" class method."),ZHe=l(),bM=a("p"),eUe=o("This class cannot be instantiated directly using "),yV=a("code"),oUe=o("__init__()"),tUe=o(" (throws an error)."),rUe=l(),At=a("div"),f(TM.$$.fragment),aUe=l(),wV=a("p"),nUe=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),sUe=l(),fi=a("p"),lUe=o(`Note:
Loading a model from its configuration file does `),AV=a("strong"),iUe=o("not"),dUe=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),xV=a("em"),mUe=o("~AutoModelForPreTraining.from_pretrained"),fUe=o(`] to load the model
weights.`),cUe=l(),LV=a("p"),gUe=o("Examples:"),hUe=l(),f(FM.$$.fragment),uUe=l(),Le=a("div"),f(MM.$$.fragment),pUe=l(),BV=a("p"),_Ue=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),vUe=l(),Ca=a("p"),bUe=o("The model class to instantiate is selected based on the "),kV=a("em"),TUe=o("model_type"),FUe=o(` property of the config object (either
passed as an argument or loaded from `),RV=a("em"),MUe=o("pretrained_model_name_or_path"),EUe=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),SV=a("em"),CUe=o("pretrained_model_name_or_path"),yUe=o(":"),wUe=l(),k=a("ul"),Lh=a("li"),PV=a("strong"),AUe=o("albert"),xUe=o(" \u2014 "),nB=a("a"),LUe=o("AlbertForPreTraining"),BUe=o(" (ALBERT model)"),kUe=l(),Bh=a("li"),$V=a("strong"),RUe=o("bart"),SUe=o(" \u2014 "),sB=a("a"),PUe=o("BartForConditionalGeneration"),$Ue=o(" (BART model)"),IUe=l(),kh=a("li"),IV=a("strong"),jUe=o("bert"),NUe=o(" \u2014 "),lB=a("a"),DUe=o("BertForPreTraining"),GUe=o(" (BERT model)"),OUe=l(),Rh=a("li"),jV=a("strong"),qUe=o("big_bird"),zUe=o(" \u2014 "),iB=a("a"),XUe=o("BigBirdForPreTraining"),WUe=o(" (BigBird model)"),VUe=l(),Sh=a("li"),NV=a("strong"),QUe=o("camembert"),HUe=o(" \u2014 "),dB=a("a"),UUe=o("CamembertForMaskedLM"),JUe=o(" (CamemBERT model)"),KUe=l(),Ph=a("li"),DV=a("strong"),YUe=o("ctrl"),ZUe=o(" \u2014 "),mB=a("a"),eJe=o("CTRLLMHeadModel"),oJe=o(" (CTRL model)"),tJe=l(),$h=a("li"),GV=a("strong"),rJe=o("deberta"),aJe=o(" \u2014 "),fB=a("a"),nJe=o("DebertaForMaskedLM"),sJe=o(" (DeBERTa model)"),lJe=l(),Ih=a("li"),OV=a("strong"),iJe=o("deberta-v2"),dJe=o(" \u2014 "),cB=a("a"),mJe=o("DebertaV2ForMaskedLM"),fJe=o(" (DeBERTa-v2 model)"),cJe=l(),jh=a("li"),qV=a("strong"),gJe=o("distilbert"),hJe=o(" \u2014 "),gB=a("a"),uJe=o("DistilBertForMaskedLM"),pJe=o(" (DistilBERT model)"),_Je=l(),Nh=a("li"),zV=a("strong"),vJe=o("electra"),bJe=o(" \u2014 "),hB=a("a"),TJe=o("ElectraForPreTraining"),FJe=o(" (ELECTRA model)"),MJe=l(),Dh=a("li"),XV=a("strong"),EJe=o("flaubert"),CJe=o(" \u2014 "),uB=a("a"),yJe=o("FlaubertWithLMHeadModel"),wJe=o(" (FlauBERT model)"),AJe=l(),Gh=a("li"),WV=a("strong"),xJe=o("fnet"),LJe=o(" \u2014 "),pB=a("a"),BJe=o("FNetForPreTraining"),kJe=o(" (FNet model)"),RJe=l(),Oh=a("li"),VV=a("strong"),SJe=o("fsmt"),PJe=o(" \u2014 "),_B=a("a"),$Je=o("FSMTForConditionalGeneration"),IJe=o(" (FairSeq Machine-Translation model)"),jJe=l(),qh=a("li"),QV=a("strong"),NJe=o("funnel"),DJe=o(" \u2014 "),vB=a("a"),GJe=o("FunnelForPreTraining"),OJe=o(" (Funnel Transformer model)"),qJe=l(),zh=a("li"),HV=a("strong"),zJe=o("gpt2"),XJe=o(" \u2014 "),bB=a("a"),WJe=o("GPT2LMHeadModel"),VJe=o(" (OpenAI GPT-2 model)"),QJe=l(),Xh=a("li"),UV=a("strong"),HJe=o("ibert"),UJe=o(" \u2014 "),TB=a("a"),JJe=o("IBertForMaskedLM"),KJe=o(" (I-BERT model)"),YJe=l(),Wh=a("li"),JV=a("strong"),ZJe=o("layoutlm"),eKe=o(" \u2014 "),FB=a("a"),oKe=o("LayoutLMForMaskedLM"),tKe=o(" (LayoutLM model)"),rKe=l(),Vh=a("li"),KV=a("strong"),aKe=o("longformer"),nKe=o(" \u2014 "),MB=a("a"),sKe=o("LongformerForMaskedLM"),lKe=o(" (Longformer model)"),iKe=l(),Qh=a("li"),YV=a("strong"),dKe=o("lxmert"),mKe=o(" \u2014 "),EB=a("a"),fKe=o("LxmertForPreTraining"),cKe=o(" (LXMERT model)"),gKe=l(),Hh=a("li"),ZV=a("strong"),hKe=o("megatron-bert"),uKe=o(" \u2014 "),CB=a("a"),pKe=o("MegatronBertForPreTraining"),_Ke=o(" (MegatronBert model)"),vKe=l(),Uh=a("li"),eQ=a("strong"),bKe=o("mobilebert"),TKe=o(" \u2014 "),yB=a("a"),FKe=o("MobileBertForPreTraining"),MKe=o(" (MobileBERT model)"),EKe=l(),Jh=a("li"),oQ=a("strong"),CKe=o("mpnet"),yKe=o(" \u2014 "),wB=a("a"),wKe=o("MPNetForMaskedLM"),AKe=o(" (MPNet model)"),xKe=l(),Kh=a("li"),tQ=a("strong"),LKe=o("openai-gpt"),BKe=o(" \u2014 "),AB=a("a"),kKe=o("OpenAIGPTLMHeadModel"),RKe=o(" (OpenAI GPT model)"),SKe=l(),Yh=a("li"),rQ=a("strong"),PKe=o("retribert"),$Ke=o(" \u2014 "),xB=a("a"),IKe=o("RetriBertModel"),jKe=o(" (RetriBERT model)"),NKe=l(),Zh=a("li"),aQ=a("strong"),DKe=o("roberta"),GKe=o(" \u2014 "),LB=a("a"),OKe=o("RobertaForMaskedLM"),qKe=o(" (RoBERTa model)"),zKe=l(),eu=a("li"),nQ=a("strong"),XKe=o("squeezebert"),WKe=o(" \u2014 "),BB=a("a"),VKe=o("SqueezeBertForMaskedLM"),QKe=o(" (SqueezeBERT model)"),HKe=l(),ou=a("li"),sQ=a("strong"),UKe=o("t5"),JKe=o(" \u2014 "),kB=a("a"),KKe=o("T5ForConditionalGeneration"),YKe=o(" (T5 model)"),ZKe=l(),tu=a("li"),lQ=a("strong"),eYe=o("tapas"),oYe=o(" \u2014 "),RB=a("a"),tYe=o("TapasForMaskedLM"),rYe=o(" (TAPAS model)"),aYe=l(),ru=a("li"),iQ=a("strong"),nYe=o("transfo-xl"),sYe=o(" \u2014 "),SB=a("a"),lYe=o("TransfoXLLMHeadModel"),iYe=o(" (Transformer-XL model)"),dYe=l(),au=a("li"),dQ=a("strong"),mYe=o("unispeech"),fYe=o(" \u2014 "),PB=a("a"),cYe=o("UniSpeechForPreTraining"),gYe=o(" (UniSpeech model)"),hYe=l(),nu=a("li"),mQ=a("strong"),uYe=o("unispeech-sat"),pYe=o(" \u2014 "),$B=a("a"),_Ye=o("UniSpeechSatForPreTraining"),vYe=o(" (UniSpeechSat model)"),bYe=l(),su=a("li"),fQ=a("strong"),TYe=o("visual_bert"),FYe=o(" \u2014 "),IB=a("a"),MYe=o("VisualBertForPreTraining"),EYe=o(" (VisualBert model)"),CYe=l(),lu=a("li"),cQ=a("strong"),yYe=o("wav2vec2"),wYe=o(" \u2014 "),jB=a("a"),AYe=o("Wav2Vec2ForPreTraining"),xYe=o(" (Wav2Vec2 model)"),LYe=l(),iu=a("li"),gQ=a("strong"),BYe=o("xlm"),kYe=o(" \u2014 "),NB=a("a"),RYe=o("XLMWithLMHeadModel"),SYe=o(" (XLM model)"),PYe=l(),du=a("li"),hQ=a("strong"),$Ye=o("xlm-roberta"),IYe=o(" \u2014 "),DB=a("a"),jYe=o("XLMRobertaForMaskedLM"),NYe=o(" (XLM-RoBERTa model)"),DYe=l(),mu=a("li"),uQ=a("strong"),GYe=o("xlnet"),OYe=o(" \u2014 "),GB=a("a"),qYe=o("XLNetLMHeadModel"),zYe=o(" (XLNet model)"),XYe=l(),fu=a("p"),WYe=o("The model is set in evaluation mode by default using "),pQ=a("em"),VYe=o("model.eval()"),QYe=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Q=a("em"),HYe=o("model.train()"),UYe=l(),vQ=a("p"),JYe=o("Examples:"),KYe=l(),f(EM.$$.fragment),IEe=l(),ci=a("h2"),cu=a("a"),bQ=a("span"),f(CM.$$.fragment),YYe=l(),TQ=a("span"),ZYe=o("AutoModelForCausalLM"),jEe=l(),Io=a("div"),f(yM.$$.fragment),eZe=l(),gi=a("p"),oZe=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),FQ=a("code"),tZe=o("from_pretrained()"),rZe=o(` class method or the
`),MQ=a("code"),aZe=o("from_config()"),nZe=o(" class method."),sZe=l(),wM=a("p"),lZe=o("This class cannot be instantiated directly using "),EQ=a("code"),iZe=o("__init__()"),dZe=o(" (throws an error)."),mZe=l(),xt=a("div"),f(AM.$$.fragment),fZe=l(),CQ=a("p"),cZe=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gZe=l(),hi=a("p"),hZe=o(`Note:
Loading a model from its configuration file does `),yQ=a("strong"),uZe=o("not"),pZe=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),wQ=a("em"),_Ze=o("~AutoModelForCausalLM.from_pretrained"),vZe=o(`] to load the model
weights.`),bZe=l(),AQ=a("p"),TZe=o("Examples:"),FZe=l(),f(xM.$$.fragment),MZe=l(),Be=a("div"),f(LM.$$.fragment),EZe=l(),xQ=a("p"),CZe=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),yZe=l(),ya=a("p"),wZe=o("The model class to instantiate is selected based on the "),LQ=a("em"),AZe=o("model_type"),xZe=o(` property of the config object (either
passed as an argument or loaded from `),BQ=a("em"),LZe=o("pretrained_model_name_or_path"),BZe=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),kQ=a("em"),kZe=o("pretrained_model_name_or_path"),RZe=o(":"),SZe=l(),I=a("ul"),gu=a("li"),RQ=a("strong"),PZe=o("bart"),$Ze=o(" \u2014 "),OB=a("a"),IZe=o("BartForCausalLM"),jZe=o(" (BART model)"),NZe=l(),hu=a("li"),SQ=a("strong"),DZe=o("bert"),GZe=o(" \u2014 "),qB=a("a"),OZe=o("BertLMHeadModel"),qZe=o(" (BERT model)"),zZe=l(),uu=a("li"),PQ=a("strong"),XZe=o("bert-generation"),WZe=o(" \u2014 "),zB=a("a"),VZe=o("BertGenerationDecoder"),QZe=o(" (Bert Generation model)"),HZe=l(),pu=a("li"),$Q=a("strong"),UZe=o("big_bird"),JZe=o(" \u2014 "),XB=a("a"),KZe=o("BigBirdForCausalLM"),YZe=o(" (BigBird model)"),ZZe=l(),_u=a("li"),IQ=a("strong"),eeo=o("bigbird_pegasus"),oeo=o(" \u2014 "),WB=a("a"),teo=o("BigBirdPegasusForCausalLM"),reo=o(" (BigBirdPegasus model)"),aeo=l(),vu=a("li"),jQ=a("strong"),neo=o("blenderbot"),seo=o(" \u2014 "),VB=a("a"),leo=o("BlenderbotForCausalLM"),ieo=o(" (Blenderbot model)"),deo=l(),bu=a("li"),NQ=a("strong"),meo=o("blenderbot-small"),feo=o(" \u2014 "),QB=a("a"),ceo=o("BlenderbotSmallForCausalLM"),geo=o(" (BlenderbotSmall model)"),heo=l(),Tu=a("li"),DQ=a("strong"),ueo=o("camembert"),peo=o(" \u2014 "),HB=a("a"),_eo=o("CamembertForCausalLM"),veo=o(" (CamemBERT model)"),beo=l(),Fu=a("li"),GQ=a("strong"),Teo=o("ctrl"),Feo=o(" \u2014 "),UB=a("a"),Meo=o("CTRLLMHeadModel"),Eeo=o(" (CTRL model)"),Ceo=l(),Mu=a("li"),OQ=a("strong"),yeo=o("gpt2"),weo=o(" \u2014 "),JB=a("a"),Aeo=o("GPT2LMHeadModel"),xeo=o(" (OpenAI GPT-2 model)"),Leo=l(),Eu=a("li"),qQ=a("strong"),Beo=o("gpt_neo"),keo=o(" \u2014 "),KB=a("a"),Reo=o("GPTNeoForCausalLM"),Seo=o(" (GPT Neo model)"),Peo=l(),Cu=a("li"),zQ=a("strong"),$eo=o("gptj"),Ieo=o(" \u2014 "),YB=a("a"),jeo=o("GPTJForCausalLM"),Neo=o(" (GPT-J model)"),Deo=l(),yu=a("li"),XQ=a("strong"),Geo=o("marian"),Oeo=o(" \u2014 "),ZB=a("a"),qeo=o("MarianForCausalLM"),zeo=o(" (Marian model)"),Xeo=l(),wu=a("li"),WQ=a("strong"),Weo=o("mbart"),Veo=o(" \u2014 "),e9=a("a"),Qeo=o("MBartForCausalLM"),Heo=o(" (mBART model)"),Ueo=l(),Au=a("li"),VQ=a("strong"),Jeo=o("megatron-bert"),Keo=o(" \u2014 "),o9=a("a"),Yeo=o("MegatronBertForCausalLM"),Zeo=o(" (MegatronBert model)"),eoo=l(),xu=a("li"),QQ=a("strong"),ooo=o("openai-gpt"),too=o(" \u2014 "),t9=a("a"),roo=o("OpenAIGPTLMHeadModel"),aoo=o(" (OpenAI GPT model)"),noo=l(),Lu=a("li"),HQ=a("strong"),soo=o("pegasus"),loo=o(" \u2014 "),r9=a("a"),ioo=o("PegasusForCausalLM"),doo=o(" (Pegasus model)"),moo=l(),Bu=a("li"),UQ=a("strong"),foo=o("prophetnet"),coo=o(" \u2014 "),a9=a("a"),goo=o("ProphetNetForCausalLM"),hoo=o(" (ProphetNet model)"),uoo=l(),ku=a("li"),JQ=a("strong"),poo=o("qdqbert"),_oo=o(" \u2014 "),n9=a("a"),voo=o("QDQBertLMHeadModel"),boo=o(" (QDQBert model)"),Too=l(),Ru=a("li"),KQ=a("strong"),Foo=o("reformer"),Moo=o(" \u2014 "),s9=a("a"),Eoo=o("ReformerModelWithLMHead"),Coo=o(" (Reformer model)"),yoo=l(),Su=a("li"),YQ=a("strong"),woo=o("rembert"),Aoo=o(" \u2014 "),l9=a("a"),xoo=o("RemBertForCausalLM"),Loo=o(" (RemBERT model)"),Boo=l(),Pu=a("li"),ZQ=a("strong"),koo=o("roberta"),Roo=o(" \u2014 "),i9=a("a"),Soo=o("RobertaForCausalLM"),Poo=o(" (RoBERTa model)"),$oo=l(),$u=a("li"),eH=a("strong"),Ioo=o("roformer"),joo=o(" \u2014 "),d9=a("a"),Noo=o("RoFormerForCausalLM"),Doo=o(" (RoFormer model)"),Goo=l(),Iu=a("li"),oH=a("strong"),Ooo=o("speech_to_text_2"),qoo=o(" \u2014 "),m9=a("a"),zoo=o("Speech2Text2ForCausalLM"),Xoo=o(" (Speech2Text2 model)"),Woo=l(),ju=a("li"),tH=a("strong"),Voo=o("transfo-xl"),Qoo=o(" \u2014 "),f9=a("a"),Hoo=o("TransfoXLLMHeadModel"),Uoo=o(" (Transformer-XL model)"),Joo=l(),Nu=a("li"),rH=a("strong"),Koo=o("trocr"),Yoo=o(" \u2014 "),c9=a("a"),Zoo=o("TrOCRForCausalLM"),eto=o(" (TrOCR model)"),oto=l(),Du=a("li"),aH=a("strong"),tto=o("xlm"),rto=o(" \u2014 "),g9=a("a"),ato=o("XLMWithLMHeadModel"),nto=o(" (XLM model)"),sto=l(),Gu=a("li"),nH=a("strong"),lto=o("xlm-prophetnet"),ito=o(" \u2014 "),h9=a("a"),dto=o("XLMProphetNetForCausalLM"),mto=o(" (XLMProphetNet model)"),fto=l(),Ou=a("li"),sH=a("strong"),cto=o("xlm-roberta"),gto=o(" \u2014 "),u9=a("a"),hto=o("XLMRobertaForCausalLM"),uto=o(" (XLM-RoBERTa model)"),pto=l(),qu=a("li"),lH=a("strong"),_to=o("xlnet"),vto=o(" \u2014 "),p9=a("a"),bto=o("XLNetLMHeadModel"),Tto=o(" (XLNet model)"),Fto=l(),zu=a("p"),Mto=o("The model is set in evaluation mode by default using "),iH=a("em"),Eto=o("model.eval()"),Cto=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dH=a("em"),yto=o("model.train()"),wto=l(),mH=a("p"),Ato=o("Examples:"),xto=l(),f(BM.$$.fragment),NEe=l(),ui=a("h2"),Xu=a("a"),fH=a("span"),f(kM.$$.fragment),Lto=l(),cH=a("span"),Bto=o("AutoModelForMaskedLM"),DEe=l(),jo=a("div"),f(RM.$$.fragment),kto=l(),pi=a("p"),Rto=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gH=a("code"),Sto=o("from_pretrained()"),Pto=o(` class method or the
`),hH=a("code"),$to=o("from_config()"),Ito=o(" class method."),jto=l(),SM=a("p"),Nto=o("This class cannot be instantiated directly using "),uH=a("code"),Dto=o("__init__()"),Gto=o(" (throws an error)."),Oto=l(),Lt=a("div"),f(PM.$$.fragment),qto=l(),pH=a("p"),zto=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Xto=l(),_i=a("p"),Wto=o(`Note:
Loading a model from its configuration file does `),_H=a("strong"),Vto=o("not"),Qto=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),vH=a("em"),Hto=o("~AutoModelForMaskedLM.from_pretrained"),Uto=o(`] to load the model
weights.`),Jto=l(),bH=a("p"),Kto=o("Examples:"),Yto=l(),f($M.$$.fragment),Zto=l(),ke=a("div"),f(IM.$$.fragment),ero=l(),TH=a("p"),oro=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),tro=l(),wa=a("p"),rro=o("The model class to instantiate is selected based on the "),FH=a("em"),aro=o("model_type"),nro=o(` property of the config object (either
passed as an argument or loaded from `),MH=a("em"),sro=o("pretrained_model_name_or_path"),lro=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),EH=a("em"),iro=o("pretrained_model_name_or_path"),dro=o(":"),mro=l(),$=a("ul"),Wu=a("li"),CH=a("strong"),fro=o("albert"),cro=o(" \u2014 "),_9=a("a"),gro=o("AlbertForMaskedLM"),hro=o(" (ALBERT model)"),uro=l(),Vu=a("li"),yH=a("strong"),pro=o("bart"),_ro=o(" \u2014 "),v9=a("a"),vro=o("BartForConditionalGeneration"),bro=o(" (BART model)"),Tro=l(),Qu=a("li"),wH=a("strong"),Fro=o("bert"),Mro=o(" \u2014 "),b9=a("a"),Ero=o("BertForMaskedLM"),Cro=o(" (BERT model)"),yro=l(),Hu=a("li"),AH=a("strong"),wro=o("big_bird"),Aro=o(" \u2014 "),T9=a("a"),xro=o("BigBirdForMaskedLM"),Lro=o(" (BigBird model)"),Bro=l(),Uu=a("li"),xH=a("strong"),kro=o("camembert"),Rro=o(" \u2014 "),F9=a("a"),Sro=o("CamembertForMaskedLM"),Pro=o(" (CamemBERT model)"),$ro=l(),Ju=a("li"),LH=a("strong"),Iro=o("convbert"),jro=o(" \u2014 "),M9=a("a"),Nro=o("ConvBertForMaskedLM"),Dro=o(" (ConvBERT model)"),Gro=l(),Ku=a("li"),BH=a("strong"),Oro=o("deberta"),qro=o(" \u2014 "),E9=a("a"),zro=o("DebertaForMaskedLM"),Xro=o(" (DeBERTa model)"),Wro=l(),Yu=a("li"),kH=a("strong"),Vro=o("deberta-v2"),Qro=o(" \u2014 "),C9=a("a"),Hro=o("DebertaV2ForMaskedLM"),Uro=o(" (DeBERTa-v2 model)"),Jro=l(),Zu=a("li"),RH=a("strong"),Kro=o("distilbert"),Yro=o(" \u2014 "),y9=a("a"),Zro=o("DistilBertForMaskedLM"),eao=o(" (DistilBERT model)"),oao=l(),ep=a("li"),SH=a("strong"),tao=o("electra"),rao=o(" \u2014 "),w9=a("a"),aao=o("ElectraForMaskedLM"),nao=o(" (ELECTRA model)"),sao=l(),op=a("li"),PH=a("strong"),lao=o("flaubert"),iao=o(" \u2014 "),A9=a("a"),dao=o("FlaubertWithLMHeadModel"),mao=o(" (FlauBERT model)"),fao=l(),tp=a("li"),$H=a("strong"),cao=o("fnet"),gao=o(" \u2014 "),x9=a("a"),hao=o("FNetForMaskedLM"),uao=o(" (FNet model)"),pao=l(),rp=a("li"),IH=a("strong"),_ao=o("funnel"),vao=o(" \u2014 "),L9=a("a"),bao=o("FunnelForMaskedLM"),Tao=o(" (Funnel Transformer model)"),Fao=l(),ap=a("li"),jH=a("strong"),Mao=o("ibert"),Eao=o(" \u2014 "),B9=a("a"),Cao=o("IBertForMaskedLM"),yao=o(" (I-BERT model)"),wao=l(),np=a("li"),NH=a("strong"),Aao=o("layoutlm"),xao=o(" \u2014 "),k9=a("a"),Lao=o("LayoutLMForMaskedLM"),Bao=o(" (LayoutLM model)"),kao=l(),sp=a("li"),DH=a("strong"),Rao=o("longformer"),Sao=o(" \u2014 "),R9=a("a"),Pao=o("LongformerForMaskedLM"),$ao=o(" (Longformer model)"),Iao=l(),lp=a("li"),GH=a("strong"),jao=o("mbart"),Nao=o(" \u2014 "),S9=a("a"),Dao=o("MBartForConditionalGeneration"),Gao=o(" (mBART model)"),Oao=l(),ip=a("li"),OH=a("strong"),qao=o("megatron-bert"),zao=o(" \u2014 "),P9=a("a"),Xao=o("MegatronBertForMaskedLM"),Wao=o(" (MegatronBert model)"),Vao=l(),dp=a("li"),qH=a("strong"),Qao=o("mobilebert"),Hao=o(" \u2014 "),$9=a("a"),Uao=o("MobileBertForMaskedLM"),Jao=o(" (MobileBERT model)"),Kao=l(),mp=a("li"),zH=a("strong"),Yao=o("mpnet"),Zao=o(" \u2014 "),I9=a("a"),eno=o("MPNetForMaskedLM"),ono=o(" (MPNet model)"),tno=l(),fp=a("li"),XH=a("strong"),rno=o("perceiver"),ano=o(" \u2014 "),j9=a("a"),nno=o("PerceiverForMaskedLM"),sno=o(" (Perceiver model)"),lno=l(),cp=a("li"),WH=a("strong"),ino=o("qdqbert"),dno=o(" \u2014 "),N9=a("a"),mno=o("QDQBertForMaskedLM"),fno=o(" (QDQBert model)"),cno=l(),gp=a("li"),VH=a("strong"),gno=o("reformer"),hno=o(" \u2014 "),D9=a("a"),uno=o("ReformerForMaskedLM"),pno=o(" (Reformer model)"),_no=l(),hp=a("li"),QH=a("strong"),vno=o("rembert"),bno=o(" \u2014 "),G9=a("a"),Tno=o("RemBertForMaskedLM"),Fno=o(" (RemBERT model)"),Mno=l(),up=a("li"),HH=a("strong"),Eno=o("roberta"),Cno=o(" \u2014 "),O9=a("a"),yno=o("RobertaForMaskedLM"),wno=o(" (RoBERTa model)"),Ano=l(),pp=a("li"),UH=a("strong"),xno=o("roformer"),Lno=o(" \u2014 "),q9=a("a"),Bno=o("RoFormerForMaskedLM"),kno=o(" (RoFormer model)"),Rno=l(),_p=a("li"),JH=a("strong"),Sno=o("squeezebert"),Pno=o(" \u2014 "),z9=a("a"),$no=o("SqueezeBertForMaskedLM"),Ino=o(" (SqueezeBERT model)"),jno=l(),vp=a("li"),KH=a("strong"),Nno=o("tapas"),Dno=o(" \u2014 "),X9=a("a"),Gno=o("TapasForMaskedLM"),Ono=o(" (TAPAS model)"),qno=l(),bp=a("li"),YH=a("strong"),zno=o("wav2vec2"),Xno=o(" \u2014 "),ZH=a("code"),Wno=o("Wav2Vec2ForMaskedLM"),Vno=o(" (Wav2Vec2 model)"),Qno=l(),Tp=a("li"),eU=a("strong"),Hno=o("xlm"),Uno=o(" \u2014 "),W9=a("a"),Jno=o("XLMWithLMHeadModel"),Kno=o(" (XLM model)"),Yno=l(),Fp=a("li"),oU=a("strong"),Zno=o("xlm-roberta"),eso=o(" \u2014 "),V9=a("a"),oso=o("XLMRobertaForMaskedLM"),tso=o(" (XLM-RoBERTa model)"),rso=l(),Mp=a("p"),aso=o("The model is set in evaluation mode by default using "),tU=a("em"),nso=o("model.eval()"),sso=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rU=a("em"),lso=o("model.train()"),iso=l(),aU=a("p"),dso=o("Examples:"),mso=l(),f(jM.$$.fragment),GEe=l(),vi=a("h2"),Ep=a("a"),nU=a("span"),f(NM.$$.fragment),fso=l(),sU=a("span"),cso=o("AutoModelForSeq2SeqLM"),OEe=l(),No=a("div"),f(DM.$$.fragment),gso=l(),bi=a("p"),hso=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),lU=a("code"),uso=o("from_pretrained()"),pso=o(` class method or the
`),iU=a("code"),_so=o("from_config()"),vso=o(" class method."),bso=l(),GM=a("p"),Tso=o("This class cannot be instantiated directly using "),dU=a("code"),Fso=o("__init__()"),Mso=o(" (throws an error)."),Eso=l(),Bt=a("div"),f(OM.$$.fragment),Cso=l(),mU=a("p"),yso=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),wso=l(),Ti=a("p"),Aso=o(`Note:
Loading a model from its configuration file does `),fU=a("strong"),xso=o("not"),Lso=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),cU=a("em"),Bso=o("~AutoModelForSeq2SeqLM.from_pretrained"),kso=o(`] to load the model
weights.`),Rso=l(),gU=a("p"),Sso=o("Examples:"),Pso=l(),f(qM.$$.fragment),$so=l(),Re=a("div"),f(zM.$$.fragment),Iso=l(),hU=a("p"),jso=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Nso=l(),Aa=a("p"),Dso=o("The model class to instantiate is selected based on the "),uU=a("em"),Gso=o("model_type"),Oso=o(` property of the config object (either
passed as an argument or loaded from `),pU=a("em"),qso=o("pretrained_model_name_or_path"),zso=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),_U=a("em"),Xso=o("pretrained_model_name_or_path"),Wso=o(":"),Vso=l(),ne=a("ul"),Cp=a("li"),vU=a("strong"),Qso=o("bart"),Hso=o(" \u2014 "),Q9=a("a"),Uso=o("BartForConditionalGeneration"),Jso=o(" (BART model)"),Kso=l(),yp=a("li"),bU=a("strong"),Yso=o("bigbird_pegasus"),Zso=o(" \u2014 "),H9=a("a"),elo=o("BigBirdPegasusForConditionalGeneration"),olo=o(" (BigBirdPegasus model)"),tlo=l(),wp=a("li"),TU=a("strong"),rlo=o("blenderbot"),alo=o(" \u2014 "),U9=a("a"),nlo=o("BlenderbotForConditionalGeneration"),slo=o(" (Blenderbot model)"),llo=l(),Ap=a("li"),FU=a("strong"),ilo=o("blenderbot-small"),dlo=o(" \u2014 "),J9=a("a"),mlo=o("BlenderbotSmallForConditionalGeneration"),flo=o(" (BlenderbotSmall model)"),clo=l(),xp=a("li"),MU=a("strong"),glo=o("encoder-decoder"),hlo=o(" \u2014 "),K9=a("a"),ulo=o("EncoderDecoderModel"),plo=o(" (Encoder decoder model)"),_lo=l(),Lp=a("li"),EU=a("strong"),vlo=o("fsmt"),blo=o(" \u2014 "),Y9=a("a"),Tlo=o("FSMTForConditionalGeneration"),Flo=o(" (FairSeq Machine-Translation model)"),Mlo=l(),Bp=a("li"),CU=a("strong"),Elo=o("led"),Clo=o(" \u2014 "),Z9=a("a"),ylo=o("LEDForConditionalGeneration"),wlo=o(" (LED model)"),Alo=l(),kp=a("li"),yU=a("strong"),xlo=o("m2m_100"),Llo=o(" \u2014 "),ek=a("a"),Blo=o("M2M100ForConditionalGeneration"),klo=o(" (M2M100 model)"),Rlo=l(),Rp=a("li"),wU=a("strong"),Slo=o("marian"),Plo=o(" \u2014 "),ok=a("a"),$lo=o("MarianMTModel"),Ilo=o(" (Marian model)"),jlo=l(),Sp=a("li"),AU=a("strong"),Nlo=o("mbart"),Dlo=o(" \u2014 "),tk=a("a"),Glo=o("MBartForConditionalGeneration"),Olo=o(" (mBART model)"),qlo=l(),Pp=a("li"),xU=a("strong"),zlo=o("mt5"),Xlo=o(" \u2014 "),rk=a("a"),Wlo=o("MT5ForConditionalGeneration"),Vlo=o(" (mT5 model)"),Qlo=l(),$p=a("li"),LU=a("strong"),Hlo=o("pegasus"),Ulo=o(" \u2014 "),ak=a("a"),Jlo=o("PegasusForConditionalGeneration"),Klo=o(" (Pegasus model)"),Ylo=l(),Ip=a("li"),BU=a("strong"),Zlo=o("prophetnet"),eio=o(" \u2014 "),nk=a("a"),oio=o("ProphetNetForConditionalGeneration"),tio=o(" (ProphetNet model)"),rio=l(),jp=a("li"),kU=a("strong"),aio=o("t5"),nio=o(" \u2014 "),sk=a("a"),sio=o("T5ForConditionalGeneration"),lio=o(" (T5 model)"),iio=l(),Np=a("li"),RU=a("strong"),dio=o("xlm-prophetnet"),mio=o(" \u2014 "),lk=a("a"),fio=o("XLMProphetNetForConditionalGeneration"),cio=o(" (XLMProphetNet model)"),gio=l(),Dp=a("p"),hio=o("The model is set in evaluation mode by default using "),SU=a("em"),uio=o("model.eval()"),pio=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PU=a("em"),_io=o("model.train()"),vio=l(),$U=a("p"),bio=o("Examples:"),Tio=l(),f(XM.$$.fragment),qEe=l(),Fi=a("h2"),Gp=a("a"),IU=a("span"),f(WM.$$.fragment),Fio=l(),jU=a("span"),Mio=o("AutoModelForSequenceClassification"),zEe=l(),Do=a("div"),f(VM.$$.fragment),Eio=l(),Mi=a("p"),Cio=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),NU=a("code"),yio=o("from_pretrained()"),wio=o(` class method or the
`),DU=a("code"),Aio=o("from_config()"),xio=o(" class method."),Lio=l(),QM=a("p"),Bio=o("This class cannot be instantiated directly using "),GU=a("code"),kio=o("__init__()"),Rio=o(" (throws an error)."),Sio=l(),kt=a("div"),f(HM.$$.fragment),Pio=l(),OU=a("p"),$io=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Iio=l(),Ei=a("p"),jio=o(`Note:
Loading a model from its configuration file does `),qU=a("strong"),Nio=o("not"),Dio=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),zU=a("em"),Gio=o("~AutoModelForSequenceClassification.from_pretrained"),Oio=o(`] to load the model
weights.`),qio=l(),XU=a("p"),zio=o("Examples:"),Xio=l(),f(UM.$$.fragment),Wio=l(),Se=a("div"),f(JM.$$.fragment),Vio=l(),WU=a("p"),Qio=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Hio=l(),xa=a("p"),Uio=o("The model class to instantiate is selected based on the "),VU=a("em"),Jio=o("model_type"),Kio=o(` property of the config object (either
passed as an argument or loaded from `),QU=a("em"),Yio=o("pretrained_model_name_or_path"),Zio=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),HU=a("em"),edo=o("pretrained_model_name_or_path"),odo=o(":"),tdo=l(),A=a("ul"),Op=a("li"),UU=a("strong"),rdo=o("albert"),ado=o(" \u2014 "),ik=a("a"),ndo=o("AlbertForSequenceClassification"),sdo=o(" (ALBERT model)"),ldo=l(),qp=a("li"),JU=a("strong"),ido=o("bart"),ddo=o(" \u2014 "),dk=a("a"),mdo=o("BartForSequenceClassification"),fdo=o(" (BART model)"),cdo=l(),zp=a("li"),KU=a("strong"),gdo=o("bert"),hdo=o(" \u2014 "),mk=a("a"),udo=o("BertForSequenceClassification"),pdo=o(" (BERT model)"),_do=l(),Xp=a("li"),YU=a("strong"),vdo=o("big_bird"),bdo=o(" \u2014 "),fk=a("a"),Tdo=o("BigBirdForSequenceClassification"),Fdo=o(" (BigBird model)"),Mdo=l(),Wp=a("li"),ZU=a("strong"),Edo=o("bigbird_pegasus"),Cdo=o(" \u2014 "),ck=a("a"),ydo=o("BigBirdPegasusForSequenceClassification"),wdo=o(" (BigBirdPegasus model)"),Ado=l(),Vp=a("li"),eJ=a("strong"),xdo=o("camembert"),Ldo=o(" \u2014 "),gk=a("a"),Bdo=o("CamembertForSequenceClassification"),kdo=o(" (CamemBERT model)"),Rdo=l(),Qp=a("li"),oJ=a("strong"),Sdo=o("canine"),Pdo=o(" \u2014 "),hk=a("a"),$do=o("CanineForSequenceClassification"),Ido=o(" (Canine model)"),jdo=l(),Hp=a("li"),tJ=a("strong"),Ndo=o("convbert"),Ddo=o(" \u2014 "),uk=a("a"),Gdo=o("ConvBertForSequenceClassification"),Odo=o(" (ConvBERT model)"),qdo=l(),Up=a("li"),rJ=a("strong"),zdo=o("ctrl"),Xdo=o(" \u2014 "),pk=a("a"),Wdo=o("CTRLForSequenceClassification"),Vdo=o(" (CTRL model)"),Qdo=l(),Jp=a("li"),aJ=a("strong"),Hdo=o("deberta"),Udo=o(" \u2014 "),_k=a("a"),Jdo=o("DebertaForSequenceClassification"),Kdo=o(" (DeBERTa model)"),Ydo=l(),Kp=a("li"),nJ=a("strong"),Zdo=o("deberta-v2"),emo=o(" \u2014 "),vk=a("a"),omo=o("DebertaV2ForSequenceClassification"),tmo=o(" (DeBERTa-v2 model)"),rmo=l(),Yp=a("li"),sJ=a("strong"),amo=o("distilbert"),nmo=o(" \u2014 "),bk=a("a"),smo=o("DistilBertForSequenceClassification"),lmo=o(" (DistilBERT model)"),imo=l(),Zp=a("li"),lJ=a("strong"),dmo=o("electra"),mmo=o(" \u2014 "),Tk=a("a"),fmo=o("ElectraForSequenceClassification"),cmo=o(" (ELECTRA model)"),gmo=l(),e_=a("li"),iJ=a("strong"),hmo=o("flaubert"),umo=o(" \u2014 "),Fk=a("a"),pmo=o("FlaubertForSequenceClassification"),_mo=o(" (FlauBERT model)"),vmo=l(),o_=a("li"),dJ=a("strong"),bmo=o("fnet"),Tmo=o(" \u2014 "),Mk=a("a"),Fmo=o("FNetForSequenceClassification"),Mmo=o(" (FNet model)"),Emo=l(),t_=a("li"),mJ=a("strong"),Cmo=o("funnel"),ymo=o(" \u2014 "),Ek=a("a"),wmo=o("FunnelForSequenceClassification"),Amo=o(" (Funnel Transformer model)"),xmo=l(),r_=a("li"),fJ=a("strong"),Lmo=o("gpt2"),Bmo=o(" \u2014 "),Ck=a("a"),kmo=o("GPT2ForSequenceClassification"),Rmo=o(" (OpenAI GPT-2 model)"),Smo=l(),a_=a("li"),cJ=a("strong"),Pmo=o("gpt_neo"),$mo=o(" \u2014 "),yk=a("a"),Imo=o("GPTNeoForSequenceClassification"),jmo=o(" (GPT Neo model)"),Nmo=l(),n_=a("li"),gJ=a("strong"),Dmo=o("gptj"),Gmo=o(" \u2014 "),wk=a("a"),Omo=o("GPTJForSequenceClassification"),qmo=o(" (GPT-J model)"),zmo=l(),s_=a("li"),hJ=a("strong"),Xmo=o("ibert"),Wmo=o(" \u2014 "),Ak=a("a"),Vmo=o("IBertForSequenceClassification"),Qmo=o(" (I-BERT model)"),Hmo=l(),l_=a("li"),uJ=a("strong"),Umo=o("layoutlm"),Jmo=o(" \u2014 "),xk=a("a"),Kmo=o("LayoutLMForSequenceClassification"),Ymo=o(" (LayoutLM model)"),Zmo=l(),i_=a("li"),pJ=a("strong"),efo=o("layoutlmv2"),ofo=o(" \u2014 "),Lk=a("a"),tfo=o("LayoutLMv2ForSequenceClassification"),rfo=o(" (LayoutLMv2 model)"),afo=l(),d_=a("li"),_J=a("strong"),nfo=o("led"),sfo=o(" \u2014 "),Bk=a("a"),lfo=o("LEDForSequenceClassification"),ifo=o(" (LED model)"),dfo=l(),m_=a("li"),vJ=a("strong"),mfo=o("longformer"),ffo=o(" \u2014 "),kk=a("a"),cfo=o("LongformerForSequenceClassification"),gfo=o(" (Longformer model)"),hfo=l(),f_=a("li"),bJ=a("strong"),ufo=o("mbart"),pfo=o(" \u2014 "),Rk=a("a"),_fo=o("MBartForSequenceClassification"),vfo=o(" (mBART model)"),bfo=l(),c_=a("li"),TJ=a("strong"),Tfo=o("megatron-bert"),Ffo=o(" \u2014 "),Sk=a("a"),Mfo=o("MegatronBertForSequenceClassification"),Efo=o(" (MegatronBert model)"),Cfo=l(),g_=a("li"),FJ=a("strong"),yfo=o("mobilebert"),wfo=o(" \u2014 "),Pk=a("a"),Afo=o("MobileBertForSequenceClassification"),xfo=o(" (MobileBERT model)"),Lfo=l(),h_=a("li"),MJ=a("strong"),Bfo=o("mpnet"),kfo=o(" \u2014 "),$k=a("a"),Rfo=o("MPNetForSequenceClassification"),Sfo=o(" (MPNet model)"),Pfo=l(),u_=a("li"),EJ=a("strong"),$fo=o("openai-gpt"),Ifo=o(" \u2014 "),Ik=a("a"),jfo=o("OpenAIGPTForSequenceClassification"),Nfo=o(" (OpenAI GPT model)"),Dfo=l(),p_=a("li"),CJ=a("strong"),Gfo=o("perceiver"),Ofo=o(" \u2014 "),jk=a("a"),qfo=o("PerceiverForSequenceClassification"),zfo=o(" (Perceiver model)"),Xfo=l(),__=a("li"),yJ=a("strong"),Wfo=o("qdqbert"),Vfo=o(" \u2014 "),Nk=a("a"),Qfo=o("QDQBertForSequenceClassification"),Hfo=o(" (QDQBert model)"),Ufo=l(),v_=a("li"),wJ=a("strong"),Jfo=o("reformer"),Kfo=o(" \u2014 "),Dk=a("a"),Yfo=o("ReformerForSequenceClassification"),Zfo=o(" (Reformer model)"),eco=l(),b_=a("li"),AJ=a("strong"),oco=o("rembert"),tco=o(" \u2014 "),Gk=a("a"),rco=o("RemBertForSequenceClassification"),aco=o(" (RemBERT model)"),nco=l(),T_=a("li"),xJ=a("strong"),sco=o("roberta"),lco=o(" \u2014 "),Ok=a("a"),ico=o("RobertaForSequenceClassification"),dco=o(" (RoBERTa model)"),mco=l(),F_=a("li"),LJ=a("strong"),fco=o("roformer"),cco=o(" \u2014 "),qk=a("a"),gco=o("RoFormerForSequenceClassification"),hco=o(" (RoFormer model)"),uco=l(),M_=a("li"),BJ=a("strong"),pco=o("squeezebert"),_co=o(" \u2014 "),zk=a("a"),vco=o("SqueezeBertForSequenceClassification"),bco=o(" (SqueezeBERT model)"),Tco=l(),E_=a("li"),kJ=a("strong"),Fco=o("tapas"),Mco=o(" \u2014 "),Xk=a("a"),Eco=o("TapasForSequenceClassification"),Cco=o(" (TAPAS model)"),yco=l(),C_=a("li"),RJ=a("strong"),wco=o("transfo-xl"),Aco=o(" \u2014 "),Wk=a("a"),xco=o("TransfoXLForSequenceClassification"),Lco=o(" (Transformer-XL model)"),Bco=l(),y_=a("li"),SJ=a("strong"),kco=o("xlm"),Rco=o(" \u2014 "),Vk=a("a"),Sco=o("XLMForSequenceClassification"),Pco=o(" (XLM model)"),$co=l(),w_=a("li"),PJ=a("strong"),Ico=o("xlm-roberta"),jco=o(" \u2014 "),Qk=a("a"),Nco=o("XLMRobertaForSequenceClassification"),Dco=o(" (XLM-RoBERTa model)"),Gco=l(),A_=a("li"),$J=a("strong"),Oco=o("xlnet"),qco=o(" \u2014 "),Hk=a("a"),zco=o("XLNetForSequenceClassification"),Xco=o(" (XLNet model)"),Wco=l(),x_=a("p"),Vco=o("The model is set in evaluation mode by default using "),IJ=a("em"),Qco=o("model.eval()"),Hco=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jJ=a("em"),Uco=o("model.train()"),Jco=l(),NJ=a("p"),Kco=o("Examples:"),Yco=l(),f(KM.$$.fragment),XEe=l(),Ci=a("h2"),L_=a("a"),DJ=a("span"),f(YM.$$.fragment),Zco=l(),GJ=a("span"),ego=o("AutoModelForMultipleChoice"),WEe=l(),Go=a("div"),f(ZM.$$.fragment),ogo=l(),yi=a("p"),tgo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),OJ=a("code"),rgo=o("from_pretrained()"),ago=o(` class method or the
`),qJ=a("code"),ngo=o("from_config()"),sgo=o(" class method."),lgo=l(),eE=a("p"),igo=o("This class cannot be instantiated directly using "),zJ=a("code"),dgo=o("__init__()"),mgo=o(" (throws an error)."),fgo=l(),Rt=a("div"),f(oE.$$.fragment),cgo=l(),XJ=a("p"),ggo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),hgo=l(),wi=a("p"),ugo=o(`Note:
Loading a model from its configuration file does `),WJ=a("strong"),pgo=o("not"),_go=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),VJ=a("em"),vgo=o("~AutoModelForMultipleChoice.from_pretrained"),bgo=o(`] to load the model
weights.`),Tgo=l(),QJ=a("p"),Fgo=o("Examples:"),Mgo=l(),f(tE.$$.fragment),Ego=l(),Pe=a("div"),f(rE.$$.fragment),Cgo=l(),HJ=a("p"),ygo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),wgo=l(),La=a("p"),Ago=o("The model class to instantiate is selected based on the "),UJ=a("em"),xgo=o("model_type"),Lgo=o(` property of the config object (either
passed as an argument or loaded from `),JJ=a("em"),Bgo=o("pretrained_model_name_or_path"),kgo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),KJ=a("em"),Rgo=o("pretrained_model_name_or_path"),Sgo=o(":"),Pgo=l(),q=a("ul"),B_=a("li"),YJ=a("strong"),$go=o("albert"),Igo=o(" \u2014 "),Uk=a("a"),jgo=o("AlbertForMultipleChoice"),Ngo=o(" (ALBERT model)"),Dgo=l(),k_=a("li"),ZJ=a("strong"),Ggo=o("bert"),Ogo=o(" \u2014 "),Jk=a("a"),qgo=o("BertForMultipleChoice"),zgo=o(" (BERT model)"),Xgo=l(),R_=a("li"),eK=a("strong"),Wgo=o("big_bird"),Vgo=o(" \u2014 "),Kk=a("a"),Qgo=o("BigBirdForMultipleChoice"),Hgo=o(" (BigBird model)"),Ugo=l(),S_=a("li"),oK=a("strong"),Jgo=o("camembert"),Kgo=o(" \u2014 "),Yk=a("a"),Ygo=o("CamembertForMultipleChoice"),Zgo=o(" (CamemBERT model)"),eho=l(),P_=a("li"),tK=a("strong"),oho=o("canine"),tho=o(" \u2014 "),Zk=a("a"),rho=o("CanineForMultipleChoice"),aho=o(" (Canine model)"),nho=l(),$_=a("li"),rK=a("strong"),sho=o("convbert"),lho=o(" \u2014 "),eR=a("a"),iho=o("ConvBertForMultipleChoice"),dho=o(" (ConvBERT model)"),mho=l(),I_=a("li"),aK=a("strong"),fho=o("distilbert"),cho=o(" \u2014 "),oR=a("a"),gho=o("DistilBertForMultipleChoice"),hho=o(" (DistilBERT model)"),uho=l(),j_=a("li"),nK=a("strong"),pho=o("electra"),_ho=o(" \u2014 "),tR=a("a"),vho=o("ElectraForMultipleChoice"),bho=o(" (ELECTRA model)"),Tho=l(),N_=a("li"),sK=a("strong"),Fho=o("flaubert"),Mho=o(" \u2014 "),rR=a("a"),Eho=o("FlaubertForMultipleChoice"),Cho=o(" (FlauBERT model)"),yho=l(),D_=a("li"),lK=a("strong"),who=o("fnet"),Aho=o(" \u2014 "),aR=a("a"),xho=o("FNetForMultipleChoice"),Lho=o(" (FNet model)"),Bho=l(),G_=a("li"),iK=a("strong"),kho=o("funnel"),Rho=o(" \u2014 "),nR=a("a"),Sho=o("FunnelForMultipleChoice"),Pho=o(" (Funnel Transformer model)"),$ho=l(),O_=a("li"),dK=a("strong"),Iho=o("ibert"),jho=o(" \u2014 "),sR=a("a"),Nho=o("IBertForMultipleChoice"),Dho=o(" (I-BERT model)"),Gho=l(),q_=a("li"),mK=a("strong"),Oho=o("longformer"),qho=o(" \u2014 "),lR=a("a"),zho=o("LongformerForMultipleChoice"),Xho=o(" (Longformer model)"),Who=l(),z_=a("li"),fK=a("strong"),Vho=o("megatron-bert"),Qho=o(" \u2014 "),iR=a("a"),Hho=o("MegatronBertForMultipleChoice"),Uho=o(" (MegatronBert model)"),Jho=l(),X_=a("li"),cK=a("strong"),Kho=o("mobilebert"),Yho=o(" \u2014 "),dR=a("a"),Zho=o("MobileBertForMultipleChoice"),euo=o(" (MobileBERT model)"),ouo=l(),W_=a("li"),gK=a("strong"),tuo=o("mpnet"),ruo=o(" \u2014 "),mR=a("a"),auo=o("MPNetForMultipleChoice"),nuo=o(" (MPNet model)"),suo=l(),V_=a("li"),hK=a("strong"),luo=o("qdqbert"),iuo=o(" \u2014 "),fR=a("a"),duo=o("QDQBertForMultipleChoice"),muo=o(" (QDQBert model)"),fuo=l(),Q_=a("li"),uK=a("strong"),cuo=o("rembert"),guo=o(" \u2014 "),cR=a("a"),huo=o("RemBertForMultipleChoice"),uuo=o(" (RemBERT model)"),puo=l(),H_=a("li"),pK=a("strong"),_uo=o("roberta"),vuo=o(" \u2014 "),gR=a("a"),buo=o("RobertaForMultipleChoice"),Tuo=o(" (RoBERTa model)"),Fuo=l(),U_=a("li"),_K=a("strong"),Muo=o("roformer"),Euo=o(" \u2014 "),hR=a("a"),Cuo=o("RoFormerForMultipleChoice"),yuo=o(" (RoFormer model)"),wuo=l(),J_=a("li"),vK=a("strong"),Auo=o("squeezebert"),xuo=o(" \u2014 "),uR=a("a"),Luo=o("SqueezeBertForMultipleChoice"),Buo=o(" (SqueezeBERT model)"),kuo=l(),K_=a("li"),bK=a("strong"),Ruo=o("xlm"),Suo=o(" \u2014 "),pR=a("a"),Puo=o("XLMForMultipleChoice"),$uo=o(" (XLM model)"),Iuo=l(),Y_=a("li"),TK=a("strong"),juo=o("xlm-roberta"),Nuo=o(" \u2014 "),_R=a("a"),Duo=o("XLMRobertaForMultipleChoice"),Guo=o(" (XLM-RoBERTa model)"),Ouo=l(),Z_=a("li"),FK=a("strong"),quo=o("xlnet"),zuo=o(" \u2014 "),vR=a("a"),Xuo=o("XLNetForMultipleChoice"),Wuo=o(" (XLNet model)"),Vuo=l(),ev=a("p"),Quo=o("The model is set in evaluation mode by default using "),MK=a("em"),Huo=o("model.eval()"),Uuo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EK=a("em"),Juo=o("model.train()"),Kuo=l(),CK=a("p"),Yuo=o("Examples:"),Zuo=l(),f(aE.$$.fragment),VEe=l(),Ai=a("h2"),ov=a("a"),yK=a("span"),f(nE.$$.fragment),epo=l(),wK=a("span"),opo=o("AutoModelForNextSentencePrediction"),QEe=l(),Oo=a("div"),f(sE.$$.fragment),tpo=l(),xi=a("p"),rpo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),AK=a("code"),apo=o("from_pretrained()"),npo=o(` class method or the
`),xK=a("code"),spo=o("from_config()"),lpo=o(" class method."),ipo=l(),lE=a("p"),dpo=o("This class cannot be instantiated directly using "),LK=a("code"),mpo=o("__init__()"),fpo=o(" (throws an error)."),cpo=l(),St=a("div"),f(iE.$$.fragment),gpo=l(),BK=a("p"),hpo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),upo=l(),Li=a("p"),ppo=o(`Note:
Loading a model from its configuration file does `),kK=a("strong"),_po=o("not"),vpo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),RK=a("em"),bpo=o("~AutoModelForNextSentencePrediction.from_pretrained"),Tpo=o(`] to load the model
weights.`),Fpo=l(),SK=a("p"),Mpo=o("Examples:"),Epo=l(),f(dE.$$.fragment),Cpo=l(),$e=a("div"),f(mE.$$.fragment),ypo=l(),PK=a("p"),wpo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Apo=l(),Ba=a("p"),xpo=o("The model class to instantiate is selected based on the "),$K=a("em"),Lpo=o("model_type"),Bpo=o(` property of the config object (either
passed as an argument or loaded from `),IK=a("em"),kpo=o("pretrained_model_name_or_path"),Rpo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),jK=a("em"),Spo=o("pretrained_model_name_or_path"),Ppo=o(":"),$po=l(),qr=a("ul"),tv=a("li"),NK=a("strong"),Ipo=o("bert"),jpo=o(" \u2014 "),bR=a("a"),Npo=o("BertForNextSentencePrediction"),Dpo=o(" (BERT model)"),Gpo=l(),rv=a("li"),DK=a("strong"),Opo=o("fnet"),qpo=o(" \u2014 "),TR=a("a"),zpo=o("FNetForNextSentencePrediction"),Xpo=o(" (FNet model)"),Wpo=l(),av=a("li"),GK=a("strong"),Vpo=o("megatron-bert"),Qpo=o(" \u2014 "),FR=a("a"),Hpo=o("MegatronBertForNextSentencePrediction"),Upo=o(" (MegatronBert model)"),Jpo=l(),nv=a("li"),OK=a("strong"),Kpo=o("mobilebert"),Ypo=o(" \u2014 "),MR=a("a"),Zpo=o("MobileBertForNextSentencePrediction"),e_o=o(" (MobileBERT model)"),o_o=l(),sv=a("li"),qK=a("strong"),t_o=o("qdqbert"),r_o=o(" \u2014 "),ER=a("a"),a_o=o("QDQBertForNextSentencePrediction"),n_o=o(" (QDQBert model)"),s_o=l(),lv=a("p"),l_o=o("The model is set in evaluation mode by default using "),zK=a("em"),i_o=o("model.eval()"),d_o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XK=a("em"),m_o=o("model.train()"),f_o=l(),WK=a("p"),c_o=o("Examples:"),g_o=l(),f(fE.$$.fragment),HEe=l(),Bi=a("h2"),iv=a("a"),VK=a("span"),f(cE.$$.fragment),h_o=l(),QK=a("span"),u_o=o("AutoModelForTokenClassification"),UEe=l(),qo=a("div"),f(gE.$$.fragment),p_o=l(),ki=a("p"),__o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HK=a("code"),v_o=o("from_pretrained()"),b_o=o(` class method or the
`),UK=a("code"),T_o=o("from_config()"),F_o=o(" class method."),M_o=l(),hE=a("p"),E_o=o("This class cannot be instantiated directly using "),JK=a("code"),C_o=o("__init__()"),y_o=o(" (throws an error)."),w_o=l(),Pt=a("div"),f(uE.$$.fragment),A_o=l(),KK=a("p"),x_o=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),L_o=l(),Ri=a("p"),B_o=o(`Note:
Loading a model from its configuration file does `),YK=a("strong"),k_o=o("not"),R_o=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),ZK=a("em"),S_o=o("~AutoModelForTokenClassification.from_pretrained"),P_o=o(`] to load the model
weights.`),$_o=l(),eY=a("p"),I_o=o("Examples:"),j_o=l(),f(pE.$$.fragment),N_o=l(),Ie=a("div"),f(_E.$$.fragment),D_o=l(),oY=a("p"),G_o=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),O_o=l(),ka=a("p"),q_o=o("The model class to instantiate is selected based on the "),tY=a("em"),z_o=o("model_type"),X_o=o(` property of the config object (either
passed as an argument or loaded from `),rY=a("em"),W_o=o("pretrained_model_name_or_path"),V_o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),aY=a("em"),Q_o=o("pretrained_model_name_or_path"),H_o=o(":"),U_o=l(),N=a("ul"),dv=a("li"),nY=a("strong"),J_o=o("albert"),K_o=o(" \u2014 "),CR=a("a"),Y_o=o("AlbertForTokenClassification"),Z_o=o(" (ALBERT model)"),evo=l(),mv=a("li"),sY=a("strong"),ovo=o("bert"),tvo=o(" \u2014 "),yR=a("a"),rvo=o("BertForTokenClassification"),avo=o(" (BERT model)"),nvo=l(),fv=a("li"),lY=a("strong"),svo=o("big_bird"),lvo=o(" \u2014 "),wR=a("a"),ivo=o("BigBirdForTokenClassification"),dvo=o(" (BigBird model)"),mvo=l(),cv=a("li"),iY=a("strong"),fvo=o("camembert"),cvo=o(" \u2014 "),AR=a("a"),gvo=o("CamembertForTokenClassification"),hvo=o(" (CamemBERT model)"),uvo=l(),gv=a("li"),dY=a("strong"),pvo=o("canine"),_vo=o(" \u2014 "),xR=a("a"),vvo=o("CanineForTokenClassification"),bvo=o(" (Canine model)"),Tvo=l(),hv=a("li"),mY=a("strong"),Fvo=o("convbert"),Mvo=o(" \u2014 "),LR=a("a"),Evo=o("ConvBertForTokenClassification"),Cvo=o(" (ConvBERT model)"),yvo=l(),uv=a("li"),fY=a("strong"),wvo=o("deberta"),Avo=o(" \u2014 "),BR=a("a"),xvo=o("DebertaForTokenClassification"),Lvo=o(" (DeBERTa model)"),Bvo=l(),pv=a("li"),cY=a("strong"),kvo=o("deberta-v2"),Rvo=o(" \u2014 "),kR=a("a"),Svo=o("DebertaV2ForTokenClassification"),Pvo=o(" (DeBERTa-v2 model)"),$vo=l(),_v=a("li"),gY=a("strong"),Ivo=o("distilbert"),jvo=o(" \u2014 "),RR=a("a"),Nvo=o("DistilBertForTokenClassification"),Dvo=o(" (DistilBERT model)"),Gvo=l(),vv=a("li"),hY=a("strong"),Ovo=o("electra"),qvo=o(" \u2014 "),SR=a("a"),zvo=o("ElectraForTokenClassification"),Xvo=o(" (ELECTRA model)"),Wvo=l(),bv=a("li"),uY=a("strong"),Vvo=o("flaubert"),Qvo=o(" \u2014 "),PR=a("a"),Hvo=o("FlaubertForTokenClassification"),Uvo=o(" (FlauBERT model)"),Jvo=l(),Tv=a("li"),pY=a("strong"),Kvo=o("fnet"),Yvo=o(" \u2014 "),$R=a("a"),Zvo=o("FNetForTokenClassification"),e1o=o(" (FNet model)"),o1o=l(),Fv=a("li"),_Y=a("strong"),t1o=o("funnel"),r1o=o(" \u2014 "),IR=a("a"),a1o=o("FunnelForTokenClassification"),n1o=o(" (Funnel Transformer model)"),s1o=l(),Mv=a("li"),vY=a("strong"),l1o=o("gpt2"),i1o=o(" \u2014 "),jR=a("a"),d1o=o("GPT2ForTokenClassification"),m1o=o(" (OpenAI GPT-2 model)"),f1o=l(),Ev=a("li"),bY=a("strong"),c1o=o("ibert"),g1o=o(" \u2014 "),NR=a("a"),h1o=o("IBertForTokenClassification"),u1o=o(" (I-BERT model)"),p1o=l(),Cv=a("li"),TY=a("strong"),_1o=o("layoutlm"),v1o=o(" \u2014 "),DR=a("a"),b1o=o("LayoutLMForTokenClassification"),T1o=o(" (LayoutLM model)"),F1o=l(),yv=a("li"),FY=a("strong"),M1o=o("layoutlmv2"),E1o=o(" \u2014 "),GR=a("a"),C1o=o("LayoutLMv2ForTokenClassification"),y1o=o(" (LayoutLMv2 model)"),w1o=l(),wv=a("li"),MY=a("strong"),A1o=o("longformer"),x1o=o(" \u2014 "),OR=a("a"),L1o=o("LongformerForTokenClassification"),B1o=o(" (Longformer model)"),k1o=l(),Av=a("li"),EY=a("strong"),R1o=o("megatron-bert"),S1o=o(" \u2014 "),qR=a("a"),P1o=o("MegatronBertForTokenClassification"),$1o=o(" (MegatronBert model)"),I1o=l(),xv=a("li"),CY=a("strong"),j1o=o("mobilebert"),N1o=o(" \u2014 "),zR=a("a"),D1o=o("MobileBertForTokenClassification"),G1o=o(" (MobileBERT model)"),O1o=l(),Lv=a("li"),yY=a("strong"),q1o=o("mpnet"),z1o=o(" \u2014 "),XR=a("a"),X1o=o("MPNetForTokenClassification"),W1o=o(" (MPNet model)"),V1o=l(),Bv=a("li"),wY=a("strong"),Q1o=o("qdqbert"),H1o=o(" \u2014 "),WR=a("a"),U1o=o("QDQBertForTokenClassification"),J1o=o(" (QDQBert model)"),K1o=l(),kv=a("li"),AY=a("strong"),Y1o=o("rembert"),Z1o=o(" \u2014 "),VR=a("a"),e2o=o("RemBertForTokenClassification"),o2o=o(" (RemBERT model)"),t2o=l(),Rv=a("li"),xY=a("strong"),r2o=o("roberta"),a2o=o(" \u2014 "),QR=a("a"),n2o=o("RobertaForTokenClassification"),s2o=o(" (RoBERTa model)"),l2o=l(),Sv=a("li"),LY=a("strong"),i2o=o("roformer"),d2o=o(" \u2014 "),HR=a("a"),m2o=o("RoFormerForTokenClassification"),f2o=o(" (RoFormer model)"),c2o=l(),Pv=a("li"),BY=a("strong"),g2o=o("squeezebert"),h2o=o(" \u2014 "),UR=a("a"),u2o=o("SqueezeBertForTokenClassification"),p2o=o(" (SqueezeBERT model)"),_2o=l(),$v=a("li"),kY=a("strong"),v2o=o("xlm"),b2o=o(" \u2014 "),JR=a("a"),T2o=o("XLMForTokenClassification"),F2o=o(" (XLM model)"),M2o=l(),Iv=a("li"),RY=a("strong"),E2o=o("xlm-roberta"),C2o=o(" \u2014 "),KR=a("a"),y2o=o("XLMRobertaForTokenClassification"),w2o=o(" (XLM-RoBERTa model)"),A2o=l(),jv=a("li"),SY=a("strong"),x2o=o("xlnet"),L2o=o(" \u2014 "),YR=a("a"),B2o=o("XLNetForTokenClassification"),k2o=o(" (XLNet model)"),R2o=l(),Nv=a("p"),S2o=o("The model is set in evaluation mode by default using "),PY=a("em"),P2o=o("model.eval()"),$2o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Y=a("em"),I2o=o("model.train()"),j2o=l(),IY=a("p"),N2o=o("Examples:"),D2o=l(),f(vE.$$.fragment),JEe=l(),Si=a("h2"),Dv=a("a"),jY=a("span"),f(bE.$$.fragment),G2o=l(),NY=a("span"),O2o=o("AutoModelForQuestionAnswering"),KEe=l(),zo=a("div"),f(TE.$$.fragment),q2o=l(),Pi=a("p"),z2o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DY=a("code"),X2o=o("from_pretrained()"),W2o=o(` class method or the
`),GY=a("code"),V2o=o("from_config()"),Q2o=o(" class method."),H2o=l(),FE=a("p"),U2o=o("This class cannot be instantiated directly using "),OY=a("code"),J2o=o("__init__()"),K2o=o(" (throws an error)."),Y2o=l(),$t=a("div"),f(ME.$$.fragment),Z2o=l(),qY=a("p"),ebo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),obo=l(),$i=a("p"),tbo=o(`Note:
Loading a model from its configuration file does `),zY=a("strong"),rbo=o("not"),abo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),XY=a("em"),nbo=o("~AutoModelForQuestionAnswering.from_pretrained"),sbo=o(`] to load the model
weights.`),lbo=l(),WY=a("p"),ibo=o("Examples:"),dbo=l(),f(EE.$$.fragment),mbo=l(),je=a("div"),f(CE.$$.fragment),fbo=l(),VY=a("p"),cbo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),gbo=l(),Ra=a("p"),hbo=o("The model class to instantiate is selected based on the "),QY=a("em"),ubo=o("model_type"),pbo=o(` property of the config object (either
passed as an argument or loaded from `),HY=a("em"),_bo=o("pretrained_model_name_or_path"),vbo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),UY=a("em"),bbo=o("pretrained_model_name_or_path"),Tbo=o(":"),Fbo=l(),R=a("ul"),Gv=a("li"),JY=a("strong"),Mbo=o("albert"),Ebo=o(" \u2014 "),ZR=a("a"),Cbo=o("AlbertForQuestionAnswering"),ybo=o(" (ALBERT model)"),wbo=l(),Ov=a("li"),KY=a("strong"),Abo=o("bart"),xbo=o(" \u2014 "),eS=a("a"),Lbo=o("BartForQuestionAnswering"),Bbo=o(" (BART model)"),kbo=l(),qv=a("li"),YY=a("strong"),Rbo=o("bert"),Sbo=o(" \u2014 "),oS=a("a"),Pbo=o("BertForQuestionAnswering"),$bo=o(" (BERT model)"),Ibo=l(),zv=a("li"),ZY=a("strong"),jbo=o("big_bird"),Nbo=o(" \u2014 "),tS=a("a"),Dbo=o("BigBirdForQuestionAnswering"),Gbo=o(" (BigBird model)"),Obo=l(),Xv=a("li"),eZ=a("strong"),qbo=o("bigbird_pegasus"),zbo=o(" \u2014 "),rS=a("a"),Xbo=o("BigBirdPegasusForQuestionAnswering"),Wbo=o(" (BigBirdPegasus model)"),Vbo=l(),Wv=a("li"),oZ=a("strong"),Qbo=o("camembert"),Hbo=o(" \u2014 "),aS=a("a"),Ubo=o("CamembertForQuestionAnswering"),Jbo=o(" (CamemBERT model)"),Kbo=l(),Vv=a("li"),tZ=a("strong"),Ybo=o("canine"),Zbo=o(" \u2014 "),nS=a("a"),e4o=o("CanineForQuestionAnswering"),o4o=o(" (Canine model)"),t4o=l(),Qv=a("li"),rZ=a("strong"),r4o=o("convbert"),a4o=o(" \u2014 "),sS=a("a"),n4o=o("ConvBertForQuestionAnswering"),s4o=o(" (ConvBERT model)"),l4o=l(),Hv=a("li"),aZ=a("strong"),i4o=o("deberta"),d4o=o(" \u2014 "),lS=a("a"),m4o=o("DebertaForQuestionAnswering"),f4o=o(" (DeBERTa model)"),c4o=l(),Uv=a("li"),nZ=a("strong"),g4o=o("deberta-v2"),h4o=o(" \u2014 "),iS=a("a"),u4o=o("DebertaV2ForQuestionAnswering"),p4o=o(" (DeBERTa-v2 model)"),_4o=l(),Jv=a("li"),sZ=a("strong"),v4o=o("distilbert"),b4o=o(" \u2014 "),dS=a("a"),T4o=o("DistilBertForQuestionAnswering"),F4o=o(" (DistilBERT model)"),M4o=l(),Kv=a("li"),lZ=a("strong"),E4o=o("electra"),C4o=o(" \u2014 "),mS=a("a"),y4o=o("ElectraForQuestionAnswering"),w4o=o(" (ELECTRA model)"),A4o=l(),Yv=a("li"),iZ=a("strong"),x4o=o("flaubert"),L4o=o(" \u2014 "),fS=a("a"),B4o=o("FlaubertForQuestionAnsweringSimple"),k4o=o(" (FlauBERT model)"),R4o=l(),Zv=a("li"),dZ=a("strong"),S4o=o("fnet"),P4o=o(" \u2014 "),cS=a("a"),$4o=o("FNetForQuestionAnswering"),I4o=o(" (FNet model)"),j4o=l(),e1=a("li"),mZ=a("strong"),N4o=o("funnel"),D4o=o(" \u2014 "),gS=a("a"),G4o=o("FunnelForQuestionAnswering"),O4o=o(" (Funnel Transformer model)"),q4o=l(),o1=a("li"),fZ=a("strong"),z4o=o("gptj"),X4o=o(" \u2014 "),hS=a("a"),W4o=o("GPTJForQuestionAnswering"),V4o=o(" (GPT-J model)"),Q4o=l(),t1=a("li"),cZ=a("strong"),H4o=o("ibert"),U4o=o(" \u2014 "),uS=a("a"),J4o=o("IBertForQuestionAnswering"),K4o=o(" (I-BERT model)"),Y4o=l(),r1=a("li"),gZ=a("strong"),Z4o=o("layoutlmv2"),e5o=o(" \u2014 "),pS=a("a"),o5o=o("LayoutLMv2ForQuestionAnswering"),t5o=o(" (LayoutLMv2 model)"),r5o=l(),a1=a("li"),hZ=a("strong"),a5o=o("led"),n5o=o(" \u2014 "),_S=a("a"),s5o=o("LEDForQuestionAnswering"),l5o=o(" (LED model)"),i5o=l(),n1=a("li"),uZ=a("strong"),d5o=o("longformer"),m5o=o(" \u2014 "),vS=a("a"),f5o=o("LongformerForQuestionAnswering"),c5o=o(" (Longformer model)"),g5o=l(),s1=a("li"),pZ=a("strong"),h5o=o("lxmert"),u5o=o(" \u2014 "),bS=a("a"),p5o=o("LxmertForQuestionAnswering"),_5o=o(" (LXMERT model)"),v5o=l(),l1=a("li"),_Z=a("strong"),b5o=o("mbart"),T5o=o(" \u2014 "),TS=a("a"),F5o=o("MBartForQuestionAnswering"),M5o=o(" (mBART model)"),E5o=l(),i1=a("li"),vZ=a("strong"),C5o=o("megatron-bert"),y5o=o(" \u2014 "),FS=a("a"),w5o=o("MegatronBertForQuestionAnswering"),A5o=o(" (MegatronBert model)"),x5o=l(),d1=a("li"),bZ=a("strong"),L5o=o("mobilebert"),B5o=o(" \u2014 "),MS=a("a"),k5o=o("MobileBertForQuestionAnswering"),R5o=o(" (MobileBERT model)"),S5o=l(),m1=a("li"),TZ=a("strong"),P5o=o("mpnet"),$5o=o(" \u2014 "),ES=a("a"),I5o=o("MPNetForQuestionAnswering"),j5o=o(" (MPNet model)"),N5o=l(),f1=a("li"),FZ=a("strong"),D5o=o("qdqbert"),G5o=o(" \u2014 "),CS=a("a"),O5o=o("QDQBertForQuestionAnswering"),q5o=o(" (QDQBert model)"),z5o=l(),c1=a("li"),MZ=a("strong"),X5o=o("reformer"),W5o=o(" \u2014 "),yS=a("a"),V5o=o("ReformerForQuestionAnswering"),Q5o=o(" (Reformer model)"),H5o=l(),g1=a("li"),EZ=a("strong"),U5o=o("rembert"),J5o=o(" \u2014 "),wS=a("a"),K5o=o("RemBertForQuestionAnswering"),Y5o=o(" (RemBERT model)"),Z5o=l(),h1=a("li"),CZ=a("strong"),e0o=o("roberta"),o0o=o(" \u2014 "),AS=a("a"),t0o=o("RobertaForQuestionAnswering"),r0o=o(" (RoBERTa model)"),a0o=l(),u1=a("li"),yZ=a("strong"),n0o=o("roformer"),s0o=o(" \u2014 "),xS=a("a"),l0o=o("RoFormerForQuestionAnswering"),i0o=o(" (RoFormer model)"),d0o=l(),p1=a("li"),wZ=a("strong"),m0o=o("splinter"),f0o=o(" \u2014 "),LS=a("a"),c0o=o("SplinterForQuestionAnswering"),g0o=o(" (Splinter model)"),h0o=l(),_1=a("li"),AZ=a("strong"),u0o=o("squeezebert"),p0o=o(" \u2014 "),BS=a("a"),_0o=o("SqueezeBertForQuestionAnswering"),v0o=o(" (SqueezeBERT model)"),b0o=l(),v1=a("li"),xZ=a("strong"),T0o=o("xlm"),F0o=o(" \u2014 "),kS=a("a"),M0o=o("XLMForQuestionAnsweringSimple"),E0o=o(" (XLM model)"),C0o=l(),b1=a("li"),LZ=a("strong"),y0o=o("xlm-roberta"),w0o=o(" \u2014 "),RS=a("a"),A0o=o("XLMRobertaForQuestionAnswering"),x0o=o(" (XLM-RoBERTa model)"),L0o=l(),T1=a("li"),BZ=a("strong"),B0o=o("xlnet"),k0o=o(" \u2014 "),SS=a("a"),R0o=o("XLNetForQuestionAnsweringSimple"),S0o=o(" (XLNet model)"),P0o=l(),F1=a("p"),$0o=o("The model is set in evaluation mode by default using "),kZ=a("em"),I0o=o("model.eval()"),j0o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),RZ=a("em"),N0o=o("model.train()"),D0o=l(),SZ=a("p"),G0o=o("Examples:"),O0o=l(),f(yE.$$.fragment),YEe=l(),Ii=a("h2"),M1=a("a"),PZ=a("span"),f(wE.$$.fragment),q0o=l(),$Z=a("span"),z0o=o("AutoModelForTableQuestionAnswering"),ZEe=l(),Xo=a("div"),f(AE.$$.fragment),X0o=l(),ji=a("p"),W0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),IZ=a("code"),V0o=o("from_pretrained()"),Q0o=o(` class method or the
`),jZ=a("code"),H0o=o("from_config()"),U0o=o(" class method."),J0o=l(),xE=a("p"),K0o=o("This class cannot be instantiated directly using "),NZ=a("code"),Y0o=o("__init__()"),Z0o=o(" (throws an error)."),eTo=l(),It=a("div"),f(LE.$$.fragment),oTo=l(),DZ=a("p"),tTo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),rTo=l(),Ni=a("p"),aTo=o(`Note:
Loading a model from its configuration file does `),GZ=a("strong"),nTo=o("not"),sTo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),OZ=a("em"),lTo=o("~AutoModelForTableQuestionAnswering.from_pretrained"),iTo=o(`] to load the model
weights.`),dTo=l(),qZ=a("p"),mTo=o("Examples:"),fTo=l(),f(BE.$$.fragment),cTo=l(),Ne=a("div"),f(kE.$$.fragment),gTo=l(),zZ=a("p"),hTo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),uTo=l(),Sa=a("p"),pTo=o("The model class to instantiate is selected based on the "),XZ=a("em"),_To=o("model_type"),vTo=o(` property of the config object (either
passed as an argument or loaded from `),WZ=a("em"),bTo=o("pretrained_model_name_or_path"),TTo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),VZ=a("em"),FTo=o("pretrained_model_name_or_path"),MTo=o(":"),ETo=l(),QZ=a("ul"),E1=a("li"),HZ=a("strong"),CTo=o("tapas"),yTo=o(" \u2014 "),PS=a("a"),wTo=o("TapasForQuestionAnswering"),ATo=o(" (TAPAS model)"),xTo=l(),C1=a("p"),LTo=o("The model is set in evaluation mode by default using "),UZ=a("em"),BTo=o("model.eval()"),kTo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JZ=a("em"),RTo=o("model.train()"),STo=l(),KZ=a("p"),PTo=o("Examples:"),$To=l(),f(RE.$$.fragment),eCe=l(),Di=a("h2"),y1=a("a"),YZ=a("span"),f(SE.$$.fragment),ITo=l(),ZZ=a("span"),jTo=o("AutoModelForImageClassification"),oCe=l(),Wo=a("div"),f(PE.$$.fragment),NTo=l(),Gi=a("p"),DTo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eee=a("code"),GTo=o("from_pretrained()"),OTo=o(` class method or the
`),oee=a("code"),qTo=o("from_config()"),zTo=o(" class method."),XTo=l(),$E=a("p"),WTo=o("This class cannot be instantiated directly using "),tee=a("code"),VTo=o("__init__()"),QTo=o(" (throws an error)."),HTo=l(),jt=a("div"),f(IE.$$.fragment),UTo=l(),ree=a("p"),JTo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),KTo=l(),Oi=a("p"),YTo=o(`Note:
Loading a model from its configuration file does `),aee=a("strong"),ZTo=o("not"),eFo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),nee=a("em"),oFo=o("~AutoModelForImageClassification.from_pretrained"),tFo=o(`] to load the model
weights.`),rFo=l(),see=a("p"),aFo=o("Examples:"),nFo=l(),f(jE.$$.fragment),sFo=l(),De=a("div"),f(NE.$$.fragment),lFo=l(),lee=a("p"),iFo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dFo=l(),Pa=a("p"),mFo=o("The model class to instantiate is selected based on the "),iee=a("em"),fFo=o("model_type"),cFo=o(` property of the config object (either
passed as an argument or loaded from `),dee=a("em"),gFo=o("pretrained_model_name_or_path"),hFo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),mee=a("em"),uFo=o("pretrained_model_name_or_path"),pFo=o(":"),_Fo=l(),Vo=a("ul"),w1=a("li"),fee=a("strong"),vFo=o("beit"),bFo=o(" \u2014 "),$S=a("a"),TFo=o("BeitForImageClassification"),FFo=o(" (BEiT model)"),MFo=l(),is=a("li"),cee=a("strong"),EFo=o("deit"),CFo=o(" \u2014 "),IS=a("a"),yFo=o("DeiTForImageClassification"),wFo=o(" or "),jS=a("a"),AFo=o("DeiTForImageClassificationWithTeacher"),xFo=o(" (DeiT model)"),LFo=l(),A1=a("li"),gee=a("strong"),BFo=o("imagegpt"),kFo=o(" \u2014 "),NS=a("a"),RFo=o("ImageGPTForImageClassification"),SFo=o(" (ImageGPT model)"),PFo=l(),Xr=a("li"),hee=a("strong"),$Fo=o("perceiver"),IFo=o(" \u2014 "),DS=a("a"),jFo=o("PerceiverForImageClassificationLearned"),NFo=o(" or "),GS=a("a"),DFo=o("PerceiverForImageClassificationFourier"),GFo=o(" or "),OS=a("a"),OFo=o("PerceiverForImageClassificationConvProcessing"),qFo=o(" (Perceiver model)"),zFo=l(),x1=a("li"),uee=a("strong"),XFo=o("segformer"),WFo=o(" \u2014 "),qS=a("a"),VFo=o("SegformerForImageClassification"),QFo=o(" (SegFormer model)"),HFo=l(),L1=a("li"),pee=a("strong"),UFo=o("vit"),JFo=o(" \u2014 "),zS=a("a"),KFo=o("ViTForImageClassification"),YFo=o(" (ViT model)"),ZFo=l(),B1=a("p"),eMo=o("The model is set in evaluation mode by default using "),_ee=a("em"),oMo=o("model.eval()"),tMo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vee=a("em"),rMo=o("model.train()"),aMo=l(),bee=a("p"),nMo=o("Examples:"),sMo=l(),f(DE.$$.fragment),tCe=l(),qi=a("h2"),k1=a("a"),Tee=a("span"),f(GE.$$.fragment),lMo=l(),Fee=a("span"),iMo=o("AutoModelForVision2Seq"),rCe=l(),Qo=a("div"),f(OE.$$.fragment),dMo=l(),zi=a("p"),mMo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Mee=a("code"),fMo=o("from_pretrained()"),cMo=o(` class method or the
`),Eee=a("code"),gMo=o("from_config()"),hMo=o(" class method."),uMo=l(),qE=a("p"),pMo=o("This class cannot be instantiated directly using "),Cee=a("code"),_Mo=o("__init__()"),vMo=o(" (throws an error)."),bMo=l(),Nt=a("div"),f(zE.$$.fragment),TMo=l(),yee=a("p"),FMo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),MMo=l(),Xi=a("p"),EMo=o(`Note:
Loading a model from its configuration file does `),wee=a("strong"),CMo=o("not"),yMo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Aee=a("em"),wMo=o("~AutoModelForVision2Seq.from_pretrained"),AMo=o(`] to load the model
weights.`),xMo=l(),xee=a("p"),LMo=o("Examples:"),BMo=l(),f(XE.$$.fragment),kMo=l(),Ge=a("div"),f(WE.$$.fragment),RMo=l(),Lee=a("p"),SMo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),PMo=l(),$a=a("p"),$Mo=o("The model class to instantiate is selected based on the "),Bee=a("em"),IMo=o("model_type"),jMo=o(` property of the config object (either
passed as an argument or loaded from `),kee=a("em"),NMo=o("pretrained_model_name_or_path"),DMo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ree=a("em"),GMo=o("pretrained_model_name_or_path"),OMo=o(":"),qMo=l(),See=a("ul"),R1=a("li"),Pee=a("strong"),zMo=o("vision-encoder-decoder"),XMo=o(" \u2014 "),XS=a("a"),WMo=o("VisionEncoderDecoderModel"),VMo=o(" (Vision Encoder decoder model)"),QMo=l(),S1=a("p"),HMo=o("The model is set in evaluation mode by default using "),$ee=a("em"),UMo=o("model.eval()"),JMo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Iee=a("em"),KMo=o("model.train()"),YMo=l(),jee=a("p"),ZMo=o("Examples:"),eEo=l(),f(VE.$$.fragment),aCe=l(),Wi=a("h2"),P1=a("a"),Nee=a("span"),f(QE.$$.fragment),oEo=l(),Dee=a("span"),tEo=o("AutoModelForAudioClassification"),nCe=l(),Ho=a("div"),f(HE.$$.fragment),rEo=l(),Vi=a("p"),aEo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Gee=a("code"),nEo=o("from_pretrained()"),sEo=o(` class method or the
`),Oee=a("code"),lEo=o("from_config()"),iEo=o(" class method."),dEo=l(),UE=a("p"),mEo=o("This class cannot be instantiated directly using "),qee=a("code"),fEo=o("__init__()"),cEo=o(" (throws an error)."),gEo=l(),Dt=a("div"),f(JE.$$.fragment),hEo=l(),zee=a("p"),uEo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),pEo=l(),Qi=a("p"),_Eo=o(`Note:
Loading a model from its configuration file does `),Xee=a("strong"),vEo=o("not"),bEo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Wee=a("em"),TEo=o("~AutoModelForAudioClassification.from_pretrained"),FEo=o(`] to load the model
weights.`),MEo=l(),Vee=a("p"),EEo=o("Examples:"),CEo=l(),f(KE.$$.fragment),yEo=l(),Oe=a("div"),f(YE.$$.fragment),wEo=l(),Qee=a("p"),AEo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),xEo=l(),Ia=a("p"),LEo=o("The model class to instantiate is selected based on the "),Hee=a("em"),BEo=o("model_type"),kEo=o(` property of the config object (either
passed as an argument or loaded from `),Uee=a("em"),REo=o("pretrained_model_name_or_path"),SEo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Jee=a("em"),PEo=o("pretrained_model_name_or_path"),$Eo=o(":"),IEo=l(),Ke=a("ul"),$1=a("li"),Kee=a("strong"),jEo=o("hubert"),NEo=o(" \u2014 "),WS=a("a"),DEo=o("HubertForSequenceClassification"),GEo=o(" (Hubert model)"),OEo=l(),I1=a("li"),Yee=a("strong"),qEo=o("sew"),zEo=o(" \u2014 "),VS=a("a"),XEo=o("SEWForSequenceClassification"),WEo=o(" (SEW model)"),VEo=l(),j1=a("li"),Zee=a("strong"),QEo=o("sew-d"),HEo=o(" \u2014 "),QS=a("a"),UEo=o("SEWDForSequenceClassification"),JEo=o(" (SEW-D model)"),KEo=l(),N1=a("li"),eoe=a("strong"),YEo=o("unispeech"),ZEo=o(" \u2014 "),HS=a("a"),eCo=o("UniSpeechForSequenceClassification"),oCo=o(" (UniSpeech model)"),tCo=l(),D1=a("li"),ooe=a("strong"),rCo=o("unispeech-sat"),aCo=o(" \u2014 "),US=a("a"),nCo=o("UniSpeechSatForSequenceClassification"),sCo=o(" (UniSpeechSat model)"),lCo=l(),G1=a("li"),toe=a("strong"),iCo=o("wav2vec2"),dCo=o(" \u2014 "),JS=a("a"),mCo=o("Wav2Vec2ForSequenceClassification"),fCo=o(" (Wav2Vec2 model)"),cCo=l(),O1=a("li"),roe=a("strong"),gCo=o("wavlm"),hCo=o(" \u2014 "),KS=a("a"),uCo=o("WavLMForSequenceClassification"),pCo=o(" (WavLM model)"),_Co=l(),q1=a("p"),vCo=o("The model is set in evaluation mode by default using "),aoe=a("em"),bCo=o("model.eval()"),TCo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),noe=a("em"),FCo=o("model.train()"),MCo=l(),soe=a("p"),ECo=o("Examples:"),CCo=l(),f(ZE.$$.fragment),sCe=l(),Hi=a("h2"),z1=a("a"),loe=a("span"),f(eC.$$.fragment),yCo=l(),ioe=a("span"),wCo=o("AutoModelForAudioFrameClassification"),lCe=l(),Uo=a("div"),f(oC.$$.fragment),ACo=l(),Ui=a("p"),xCo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),doe=a("code"),LCo=o("from_pretrained()"),BCo=o(` class method or the
`),moe=a("code"),kCo=o("from_config()"),RCo=o(" class method."),SCo=l(),tC=a("p"),PCo=o("This class cannot be instantiated directly using "),foe=a("code"),$Co=o("__init__()"),ICo=o(" (throws an error)."),jCo=l(),Gt=a("div"),f(rC.$$.fragment),NCo=l(),coe=a("p"),DCo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),GCo=l(),Ji=a("p"),OCo=o(`Note:
Loading a model from its configuration file does `),goe=a("strong"),qCo=o("not"),zCo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),hoe=a("em"),XCo=o("~AutoModelForAudioFrameClassification.from_pretrained"),WCo=o(`] to load the model
weights.`),VCo=l(),uoe=a("p"),QCo=o("Examples:"),HCo=l(),f(aC.$$.fragment),UCo=l(),qe=a("div"),f(nC.$$.fragment),JCo=l(),poe=a("p"),KCo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),YCo=l(),ja=a("p"),ZCo=o("The model class to instantiate is selected based on the "),_oe=a("em"),e3o=o("model_type"),o3o=o(` property of the config object (either
passed as an argument or loaded from `),voe=a("em"),t3o=o("pretrained_model_name_or_path"),r3o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),boe=a("em"),a3o=o("pretrained_model_name_or_path"),n3o=o(":"),s3o=l(),Ki=a("ul"),X1=a("li"),Toe=a("strong"),l3o=o("unispeech-sat"),i3o=o(" \u2014 "),YS=a("a"),d3o=o("UniSpeechSatForAudioFrameClassification"),m3o=o(" (UniSpeechSat model)"),f3o=l(),W1=a("li"),Foe=a("strong"),c3o=o("wav2vec2"),g3o=o(" \u2014 "),ZS=a("a"),h3o=o("Wav2Vec2ForAudioFrameClassification"),u3o=o(" (Wav2Vec2 model)"),p3o=l(),V1=a("li"),Moe=a("strong"),_3o=o("wavlm"),v3o=o(" \u2014 "),eP=a("a"),b3o=o("WavLMForAudioFrameClassification"),T3o=o(" (WavLM model)"),F3o=l(),Q1=a("p"),M3o=o("The model is set in evaluation mode by default using "),Eoe=a("em"),E3o=o("model.eval()"),C3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Coe=a("em"),y3o=o("model.train()"),w3o=l(),yoe=a("p"),A3o=o("Examples:"),x3o=l(),f(sC.$$.fragment),iCe=l(),Yi=a("h2"),H1=a("a"),woe=a("span"),f(lC.$$.fragment),L3o=l(),Aoe=a("span"),B3o=o("AutoModelForCTC"),dCe=l(),Jo=a("div"),f(iC.$$.fragment),k3o=l(),Zi=a("p"),R3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),xoe=a("code"),S3o=o("from_pretrained()"),P3o=o(` class method or the
`),Loe=a("code"),$3o=o("from_config()"),I3o=o(" class method."),j3o=l(),dC=a("p"),N3o=o("This class cannot be instantiated directly using "),Boe=a("code"),D3o=o("__init__()"),G3o=o(" (throws an error)."),O3o=l(),Ot=a("div"),f(mC.$$.fragment),q3o=l(),koe=a("p"),z3o=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),X3o=l(),ed=a("p"),W3o=o(`Note:
Loading a model from its configuration file does `),Roe=a("strong"),V3o=o("not"),Q3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Soe=a("em"),H3o=o("~AutoModelForCTC.from_pretrained"),U3o=o(`] to load the model
weights.`),J3o=l(),Poe=a("p"),K3o=o("Examples:"),Y3o=l(),f(fC.$$.fragment),Z3o=l(),ze=a("div"),f(cC.$$.fragment),eyo=l(),$oe=a("p"),oyo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),tyo=l(),Na=a("p"),ryo=o("The model class to instantiate is selected based on the "),Ioe=a("em"),ayo=o("model_type"),nyo=o(` property of the config object (either
passed as an argument or loaded from `),joe=a("em"),syo=o("pretrained_model_name_or_path"),lyo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Noe=a("em"),iyo=o("pretrained_model_name_or_path"),dyo=o(":"),myo=l(),Ye=a("ul"),U1=a("li"),Doe=a("strong"),fyo=o("hubert"),cyo=o(" \u2014 "),oP=a("a"),gyo=o("HubertForCTC"),hyo=o(" (Hubert model)"),uyo=l(),J1=a("li"),Goe=a("strong"),pyo=o("sew"),_yo=o(" \u2014 "),tP=a("a"),vyo=o("SEWForCTC"),byo=o(" (SEW model)"),Tyo=l(),K1=a("li"),Ooe=a("strong"),Fyo=o("sew-d"),Myo=o(" \u2014 "),rP=a("a"),Eyo=o("SEWDForCTC"),Cyo=o(" (SEW-D model)"),yyo=l(),Y1=a("li"),qoe=a("strong"),wyo=o("unispeech"),Ayo=o(" \u2014 "),aP=a("a"),xyo=o("UniSpeechForCTC"),Lyo=o(" (UniSpeech model)"),Byo=l(),Z1=a("li"),zoe=a("strong"),kyo=o("unispeech-sat"),Ryo=o(" \u2014 "),nP=a("a"),Syo=o("UniSpeechSatForCTC"),Pyo=o(" (UniSpeechSat model)"),$yo=l(),e2=a("li"),Xoe=a("strong"),Iyo=o("wav2vec2"),jyo=o(" \u2014 "),sP=a("a"),Nyo=o("Wav2Vec2ForCTC"),Dyo=o(" (Wav2Vec2 model)"),Gyo=l(),o2=a("li"),Woe=a("strong"),Oyo=o("wavlm"),qyo=o(" \u2014 "),lP=a("a"),zyo=o("WavLMForCTC"),Xyo=o(" (WavLM model)"),Wyo=l(),t2=a("p"),Vyo=o("The model is set in evaluation mode by default using "),Voe=a("em"),Qyo=o("model.eval()"),Hyo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qoe=a("em"),Uyo=o("model.train()"),Jyo=l(),Hoe=a("p"),Kyo=o("Examples:"),Yyo=l(),f(gC.$$.fragment),mCe=l(),od=a("h2"),r2=a("a"),Uoe=a("span"),f(hC.$$.fragment),Zyo=l(),Joe=a("span"),ewo=o("AutoModelForSpeechSeq2Seq"),fCe=l(),Ko=a("div"),f(uC.$$.fragment),owo=l(),td=a("p"),two=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) when created
with the `),Koe=a("code"),rwo=o("from_pretrained()"),awo=o(` class method or the
`),Yoe=a("code"),nwo=o("from_config()"),swo=o(" class method."),lwo=l(),pC=a("p"),iwo=o("This class cannot be instantiated directly using "),Zoe=a("code"),dwo=o("__init__()"),mwo=o(" (throws an error)."),fwo=l(),qt=a("div"),f(_C.$$.fragment),cwo=l(),ete=a("p"),gwo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a configuration."),hwo=l(),rd=a("p"),uwo=o(`Note:
Loading a model from its configuration file does `),ote=a("strong"),pwo=o("not"),_wo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),tte=a("em"),vwo=o("~AutoModelForSpeechSeq2Seq.from_pretrained"),bwo=o(`] to load the model
weights.`),Two=l(),rte=a("p"),Fwo=o("Examples:"),Mwo=l(),f(vC.$$.fragment),Ewo=l(),Xe=a("div"),f(bC.$$.fragment),Cwo=l(),ate=a("p"),ywo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a pretrained model."),wwo=l(),Da=a("p"),Awo=o("The model class to instantiate is selected based on the "),nte=a("em"),xwo=o("model_type"),Lwo=o(` property of the config object (either
passed as an argument or loaded from `),ste=a("em"),Bwo=o("pretrained_model_name_or_path"),kwo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),lte=a("em"),Rwo=o("pretrained_model_name_or_path"),Swo=o(":"),Pwo=l(),TC=a("ul"),a2=a("li"),ite=a("strong"),$wo=o("speech-encoder-decoder"),Iwo=o(" \u2014 "),iP=a("a"),jwo=o("SpeechEncoderDecoderModel"),Nwo=o(" (Speech Encoder decoder model)"),Dwo=l(),n2=a("li"),dte=a("strong"),Gwo=o("speech_to_text"),Owo=o(" \u2014 "),dP=a("a"),qwo=o("Speech2TextForConditionalGeneration"),zwo=o(" (Speech2Text model)"),Xwo=l(),s2=a("p"),Wwo=o("The model is set in evaluation mode by default using "),mte=a("em"),Vwo=o("model.eval()"),Qwo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fte=a("em"),Hwo=o("model.train()"),Uwo=l(),cte=a("p"),Jwo=o("Examples:"),Kwo=l(),f(FC.$$.fragment),cCe=l(),ad=a("h2"),l2=a("a"),gte=a("span"),f(MC.$$.fragment),Ywo=l(),hte=a("span"),Zwo=o("AutoModelForAudioXVector"),gCe=l(),Yo=a("div"),f(EC.$$.fragment),eAo=l(),nd=a("p"),oAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),ute=a("code"),tAo=o("from_pretrained()"),rAo=o(` class method or the
`),pte=a("code"),aAo=o("from_config()"),nAo=o(" class method."),sAo=l(),CC=a("p"),lAo=o("This class cannot be instantiated directly using "),_te=a("code"),iAo=o("__init__()"),dAo=o(" (throws an error)."),mAo=l(),zt=a("div"),f(yC.$$.fragment),fAo=l(),vte=a("p"),cAo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),gAo=l(),sd=a("p"),hAo=o(`Note:
Loading a model from its configuration file does `),bte=a("strong"),uAo=o("not"),pAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Tte=a("em"),_Ao=o("~AutoModelForAudioXVector.from_pretrained"),vAo=o(`] to load the model
weights.`),bAo=l(),Fte=a("p"),TAo=o("Examples:"),FAo=l(),f(wC.$$.fragment),MAo=l(),We=a("div"),f(AC.$$.fragment),EAo=l(),Mte=a("p"),CAo=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),yAo=l(),Ga=a("p"),wAo=o("The model class to instantiate is selected based on the "),Ete=a("em"),AAo=o("model_type"),xAo=o(` property of the config object (either
passed as an argument or loaded from `),Cte=a("em"),LAo=o("pretrained_model_name_or_path"),BAo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),yte=a("em"),kAo=o("pretrained_model_name_or_path"),RAo=o(":"),SAo=l(),ld=a("ul"),i2=a("li"),wte=a("strong"),PAo=o("unispeech-sat"),$Ao=o(" \u2014 "),mP=a("a"),IAo=o("UniSpeechSatForXVector"),jAo=o(" (UniSpeechSat model)"),NAo=l(),d2=a("li"),Ate=a("strong"),DAo=o("wav2vec2"),GAo=o(" \u2014 "),fP=a("a"),OAo=o("Wav2Vec2ForXVector"),qAo=o(" (Wav2Vec2 model)"),zAo=l(),m2=a("li"),xte=a("strong"),XAo=o("wavlm"),WAo=o(" \u2014 "),cP=a("a"),VAo=o("WavLMForXVector"),QAo=o(" (WavLM model)"),HAo=l(),f2=a("p"),UAo=o("The model is set in evaluation mode by default using "),Lte=a("em"),JAo=o("model.eval()"),KAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bte=a("em"),YAo=o("model.train()"),ZAo=l(),kte=a("p"),e7o=o("Examples:"),o7o=l(),f(xC.$$.fragment),hCe=l(),id=a("h2"),c2=a("a"),Rte=a("span"),f(LC.$$.fragment),t7o=l(),Ste=a("span"),r7o=o("AutoModelForObjectDetection"),uCe=l(),Zo=a("div"),f(BC.$$.fragment),a7o=l(),dd=a("p"),n7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Pte=a("code"),s7o=o("from_pretrained()"),l7o=o(` class method or the
`),$te=a("code"),i7o=o("from_config()"),d7o=o(" class method."),m7o=l(),kC=a("p"),f7o=o("This class cannot be instantiated directly using "),Ite=a("code"),c7o=o("__init__()"),g7o=o(" (throws an error)."),h7o=l(),Xt=a("div"),f(RC.$$.fragment),u7o=l(),jte=a("p"),p7o=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),_7o=l(),md=a("p"),v7o=o(`Note:
Loading a model from its configuration file does `),Nte=a("strong"),b7o=o("not"),T7o=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Dte=a("em"),F7o=o("~AutoModelForObjectDetection.from_pretrained"),M7o=o(`] to load the model
weights.`),E7o=l(),Gte=a("p"),C7o=o("Examples:"),y7o=l(),f(SC.$$.fragment),w7o=l(),Ve=a("div"),f(PC.$$.fragment),A7o=l(),Ote=a("p"),x7o=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),L7o=l(),Oa=a("p"),B7o=o("The model class to instantiate is selected based on the "),qte=a("em"),k7o=o("model_type"),R7o=o(` property of the config object (either
passed as an argument or loaded from `),zte=a("em"),S7o=o("pretrained_model_name_or_path"),P7o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Xte=a("em"),$7o=o("pretrained_model_name_or_path"),I7o=o(":"),j7o=l(),Wte=a("ul"),g2=a("li"),Vte=a("strong"),N7o=o("detr"),D7o=o(" \u2014 "),gP=a("a"),G7o=o("DetrForObjectDetection"),O7o=o(" (DETR model)"),q7o=l(),h2=a("p"),z7o=o("The model is set in evaluation mode by default using "),Qte=a("em"),X7o=o("model.eval()"),W7o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hte=a("em"),V7o=o("model.train()"),Q7o=l(),Ute=a("p"),H7o=o("Examples:"),U7o=l(),f($C.$$.fragment),pCe=l(),fd=a("h2"),u2=a("a"),Jte=a("span"),f(IC.$$.fragment),J7o=l(),Kte=a("span"),K7o=o("AutoModelForImageSegmentation"),_Ce=l(),et=a("div"),f(jC.$$.fragment),Y7o=l(),cd=a("p"),Z7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Yte=a("code"),exo=o("from_pretrained()"),oxo=o(` class method or the
`),Zte=a("code"),txo=o("from_config()"),rxo=o(" class method."),axo=l(),NC=a("p"),nxo=o("This class cannot be instantiated directly using "),ere=a("code"),sxo=o("__init__()"),lxo=o(" (throws an error)."),ixo=l(),Wt=a("div"),f(DC.$$.fragment),dxo=l(),ore=a("p"),mxo=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),fxo=l(),gd=a("p"),cxo=o(`Note:
Loading a model from its configuration file does `),tre=a("strong"),gxo=o("not"),hxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),rre=a("em"),uxo=o("~AutoModelForImageSegmentation.from_pretrained"),pxo=o(`] to load the model
weights.`),_xo=l(),are=a("p"),vxo=o("Examples:"),bxo=l(),f(GC.$$.fragment),Txo=l(),Qe=a("div"),f(OC.$$.fragment),Fxo=l(),nre=a("p"),Mxo=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Exo=l(),qa=a("p"),Cxo=o("The model class to instantiate is selected based on the "),sre=a("em"),yxo=o("model_type"),wxo=o(` property of the config object (either
passed as an argument or loaded from `),lre=a("em"),Axo=o("pretrained_model_name_or_path"),xxo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),ire=a("em"),Lxo=o("pretrained_model_name_or_path"),Bxo=o(":"),kxo=l(),dre=a("ul"),p2=a("li"),mre=a("strong"),Rxo=o("detr"),Sxo=o(" \u2014 "),hP=a("a"),Pxo=o("DetrForSegmentation"),$xo=o(" (DETR model)"),Ixo=l(),_2=a("p"),jxo=o("The model is set in evaluation mode by default using "),fre=a("em"),Nxo=o("model.eval()"),Dxo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cre=a("em"),Gxo=o("model.train()"),Oxo=l(),gre=a("p"),qxo=o("Examples:"),zxo=l(),f(qC.$$.fragment),vCe=l(),hd=a("h2"),v2=a("a"),hre=a("span"),f(zC.$$.fragment),Xxo=l(),ure=a("span"),Wxo=o("TFAutoModel"),bCe=l(),ot=a("div"),f(XC.$$.fragment),Vxo=l(),ud=a("p"),Qxo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pre=a("code"),Hxo=o("from_pretrained()"),Uxo=o(` class method or the
`),_re=a("code"),Jxo=o("from_config()"),Kxo=o(" class method."),Yxo=l(),WC=a("p"),Zxo=o("This class cannot be instantiated directly using "),vre=a("code"),e6o=o("__init__()"),o6o=o(" (throws an error)."),t6o=l(),Vt=a("div"),f(VC.$$.fragment),r6o=l(),bre=a("p"),a6o=o("Instantiates one of the base model classes of the library from a configuration."),n6o=l(),pd=a("p"),s6o=o(`Note:
Loading a model from its configuration file does `),Tre=a("strong"),l6o=o("not"),i6o=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Fre=a("em"),d6o=o("~TFAutoModel.from_pretrained"),m6o=o(`] to load the model
weights.`),f6o=l(),Mre=a("p"),c6o=o("Examples:"),g6o=l(),f(QC.$$.fragment),h6o=l(),ro=a("div"),f(HC.$$.fragment),u6o=l(),Ere=a("p"),p6o=o("Instantiate one of the base model classes of the library from a pretrained model."),_6o=l(),za=a("p"),v6o=o("The model class to instantiate is selected based on the "),Cre=a("em"),b6o=o("model_type"),T6o=o(` property of the config object (either
passed as an argument or loaded from `),yre=a("em"),F6o=o("pretrained_model_name_or_path"),M6o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),wre=a("em"),E6o=o("pretrained_model_name_or_path"),C6o=o(":"),y6o=l(),L=a("ul"),b2=a("li"),Are=a("strong"),w6o=o("albert"),A6o=o(" \u2014 "),uP=a("a"),x6o=o("TFAlbertModel"),L6o=o(" (ALBERT model)"),B6o=l(),T2=a("li"),xre=a("strong"),k6o=o("bart"),R6o=o(" \u2014 "),pP=a("a"),S6o=o("TFBartModel"),P6o=o(" (BART model)"),$6o=l(),F2=a("li"),Lre=a("strong"),I6o=o("bert"),j6o=o(" \u2014 "),_P=a("a"),N6o=o("TFBertModel"),D6o=o(" (BERT model)"),G6o=l(),M2=a("li"),Bre=a("strong"),O6o=o("blenderbot"),q6o=o(" \u2014 "),vP=a("a"),z6o=o("TFBlenderbotModel"),X6o=o(" (Blenderbot model)"),W6o=l(),E2=a("li"),kre=a("strong"),V6o=o("blenderbot-small"),Q6o=o(" \u2014 "),bP=a("a"),H6o=o("TFBlenderbotSmallModel"),U6o=o(" (BlenderbotSmall model)"),J6o=l(),C2=a("li"),Rre=a("strong"),K6o=o("camembert"),Y6o=o(" \u2014 "),TP=a("a"),Z6o=o("TFCamembertModel"),e8o=o(" (CamemBERT model)"),o8o=l(),y2=a("li"),Sre=a("strong"),t8o=o("convbert"),r8o=o(" \u2014 "),FP=a("a"),a8o=o("TFConvBertModel"),n8o=o(" (ConvBERT model)"),s8o=l(),w2=a("li"),Pre=a("strong"),l8o=o("ctrl"),i8o=o(" \u2014 "),MP=a("a"),d8o=o("TFCTRLModel"),m8o=o(" (CTRL model)"),f8o=l(),A2=a("li"),$re=a("strong"),c8o=o("deberta"),g8o=o(" \u2014 "),EP=a("a"),h8o=o("TFDebertaModel"),u8o=o(" (DeBERTa model)"),p8o=l(),x2=a("li"),Ire=a("strong"),_8o=o("deberta-v2"),v8o=o(" \u2014 "),CP=a("a"),b8o=o("TFDebertaV2Model"),T8o=o(" (DeBERTa-v2 model)"),F8o=l(),L2=a("li"),jre=a("strong"),M8o=o("distilbert"),E8o=o(" \u2014 "),yP=a("a"),C8o=o("TFDistilBertModel"),y8o=o(" (DistilBERT model)"),w8o=l(),B2=a("li"),Nre=a("strong"),A8o=o("dpr"),x8o=o(" \u2014 "),wP=a("a"),L8o=o("TFDPRQuestionEncoder"),B8o=o(" (DPR model)"),k8o=l(),k2=a("li"),Dre=a("strong"),R8o=o("electra"),S8o=o(" \u2014 "),AP=a("a"),P8o=o("TFElectraModel"),$8o=o(" (ELECTRA model)"),I8o=l(),R2=a("li"),Gre=a("strong"),j8o=o("flaubert"),N8o=o(" \u2014 "),xP=a("a"),D8o=o("TFFlaubertModel"),G8o=o(" (FlauBERT model)"),O8o=l(),ds=a("li"),Ore=a("strong"),q8o=o("funnel"),z8o=o(" \u2014 "),LP=a("a"),X8o=o("TFFunnelModel"),W8o=o(" or "),BP=a("a"),V8o=o("TFFunnelBaseModel"),Q8o=o(" (Funnel Transformer model)"),H8o=l(),S2=a("li"),qre=a("strong"),U8o=o("gpt2"),J8o=o(" \u2014 "),kP=a("a"),K8o=o("TFGPT2Model"),Y8o=o(" (OpenAI GPT-2 model)"),Z8o=l(),P2=a("li"),zre=a("strong"),eLo=o("hubert"),oLo=o(" \u2014 "),RP=a("a"),tLo=o("TFHubertModel"),rLo=o(" (Hubert model)"),aLo=l(),$2=a("li"),Xre=a("strong"),nLo=o("layoutlm"),sLo=o(" \u2014 "),SP=a("a"),lLo=o("TFLayoutLMModel"),iLo=o(" (LayoutLM model)"),dLo=l(),I2=a("li"),Wre=a("strong"),mLo=o("led"),fLo=o(" \u2014 "),PP=a("a"),cLo=o("TFLEDModel"),gLo=o(" (LED model)"),hLo=l(),j2=a("li"),Vre=a("strong"),uLo=o("longformer"),pLo=o(" \u2014 "),$P=a("a"),_Lo=o("TFLongformerModel"),vLo=o(" (Longformer model)"),bLo=l(),N2=a("li"),Qre=a("strong"),TLo=o("lxmert"),FLo=o(" \u2014 "),IP=a("a"),MLo=o("TFLxmertModel"),ELo=o(" (LXMERT model)"),CLo=l(),D2=a("li"),Hre=a("strong"),yLo=o("marian"),wLo=o(" \u2014 "),jP=a("a"),ALo=o("TFMarianModel"),xLo=o(" (Marian model)"),LLo=l(),G2=a("li"),Ure=a("strong"),BLo=o("mbart"),kLo=o(" \u2014 "),NP=a("a"),RLo=o("TFMBartModel"),SLo=o(" (mBART model)"),PLo=l(),O2=a("li"),Jre=a("strong"),$Lo=o("mobilebert"),ILo=o(" \u2014 "),DP=a("a"),jLo=o("TFMobileBertModel"),NLo=o(" (MobileBERT model)"),DLo=l(),q2=a("li"),Kre=a("strong"),GLo=o("mpnet"),OLo=o(" \u2014 "),GP=a("a"),qLo=o("TFMPNetModel"),zLo=o(" (MPNet model)"),XLo=l(),z2=a("li"),Yre=a("strong"),WLo=o("mt5"),VLo=o(" \u2014 "),OP=a("a"),QLo=o("TFMT5Model"),HLo=o(" (mT5 model)"),ULo=l(),X2=a("li"),Zre=a("strong"),JLo=o("openai-gpt"),KLo=o(" \u2014 "),qP=a("a"),YLo=o("TFOpenAIGPTModel"),ZLo=o(" (OpenAI GPT model)"),eBo=l(),W2=a("li"),eae=a("strong"),oBo=o("pegasus"),tBo=o(" \u2014 "),zP=a("a"),rBo=o("TFPegasusModel"),aBo=o(" (Pegasus model)"),nBo=l(),V2=a("li"),oae=a("strong"),sBo=o("rembert"),lBo=o(" \u2014 "),XP=a("a"),iBo=o("TFRemBertModel"),dBo=o(" (RemBERT model)"),mBo=l(),Q2=a("li"),tae=a("strong"),fBo=o("roberta"),cBo=o(" \u2014 "),WP=a("a"),gBo=o("TFRobertaModel"),hBo=o(" (RoBERTa model)"),uBo=l(),H2=a("li"),rae=a("strong"),pBo=o("roformer"),_Bo=o(" \u2014 "),VP=a("a"),vBo=o("TFRoFormerModel"),bBo=o(" (RoFormer model)"),TBo=l(),U2=a("li"),aae=a("strong"),FBo=o("t5"),MBo=o(" \u2014 "),QP=a("a"),EBo=o("TFT5Model"),CBo=o(" (T5 model)"),yBo=l(),J2=a("li"),nae=a("strong"),wBo=o("tapas"),ABo=o(" \u2014 "),HP=a("a"),xBo=o("TFTapasModel"),LBo=o(" (TAPAS model)"),BBo=l(),K2=a("li"),sae=a("strong"),kBo=o("transfo-xl"),RBo=o(" \u2014 "),UP=a("a"),SBo=o("TFTransfoXLModel"),PBo=o(" (Transformer-XL model)"),$Bo=l(),Y2=a("li"),lae=a("strong"),IBo=o("vit"),jBo=o(" \u2014 "),JP=a("a"),NBo=o("TFViTModel"),DBo=o(" (ViT model)"),GBo=l(),Z2=a("li"),iae=a("strong"),OBo=o("wav2vec2"),qBo=o(" \u2014 "),KP=a("a"),zBo=o("TFWav2Vec2Model"),XBo=o(" (Wav2Vec2 model)"),WBo=l(),eb=a("li"),dae=a("strong"),VBo=o("xlm"),QBo=o(" \u2014 "),YP=a("a"),HBo=o("TFXLMModel"),UBo=o(" (XLM model)"),JBo=l(),ob=a("li"),mae=a("strong"),KBo=o("xlm-roberta"),YBo=o(" \u2014 "),ZP=a("a"),ZBo=o("TFXLMRobertaModel"),e9o=o(" (XLM-RoBERTa model)"),o9o=l(),tb=a("li"),fae=a("strong"),t9o=o("xlnet"),r9o=o(" \u2014 "),e$=a("a"),a9o=o("TFXLNetModel"),n9o=o(" (XLNet model)"),s9o=l(),cae=a("p"),l9o=o("Examples:"),i9o=l(),f(UC.$$.fragment),TCe=l(),_d=a("h2"),rb=a("a"),gae=a("span"),f(JC.$$.fragment),d9o=l(),hae=a("span"),m9o=o("TFAutoModelForPreTraining"),FCe=l(),tt=a("div"),f(KC.$$.fragment),f9o=l(),vd=a("p"),c9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),uae=a("code"),g9o=o("from_pretrained()"),h9o=o(` class method or the
`),pae=a("code"),u9o=o("from_config()"),p9o=o(" class method."),_9o=l(),YC=a("p"),v9o=o("This class cannot be instantiated directly using "),_ae=a("code"),b9o=o("__init__()"),T9o=o(" (throws an error)."),F9o=l(),Qt=a("div"),f(ZC.$$.fragment),M9o=l(),vae=a("p"),E9o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),C9o=l(),bd=a("p"),y9o=o(`Note:
Loading a model from its configuration file does `),bae=a("strong"),w9o=o("not"),A9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Tae=a("em"),x9o=o("~TFAutoModelForPreTraining.from_pretrained"),L9o=o(`] to load the model
weights.`),B9o=l(),Fae=a("p"),k9o=o("Examples:"),R9o=l(),f(e3.$$.fragment),S9o=l(),ao=a("div"),f(o3.$$.fragment),P9o=l(),Mae=a("p"),$9o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),I9o=l(),Xa=a("p"),j9o=o("The model class to instantiate is selected based on the "),Eae=a("em"),N9o=o("model_type"),D9o=o(` property of the config object (either
passed as an argument or loaded from `),Cae=a("em"),G9o=o("pretrained_model_name_or_path"),O9o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),yae=a("em"),q9o=o("pretrained_model_name_or_path"),z9o=o(":"),X9o=l(),V=a("ul"),ab=a("li"),wae=a("strong"),W9o=o("albert"),V9o=o(" \u2014 "),o$=a("a"),Q9o=o("TFAlbertForPreTraining"),H9o=o(" (ALBERT model)"),U9o=l(),nb=a("li"),Aae=a("strong"),J9o=o("bart"),K9o=o(" \u2014 "),t$=a("a"),Y9o=o("TFBartForConditionalGeneration"),Z9o=o(" (BART model)"),eko=l(),sb=a("li"),xae=a("strong"),oko=o("bert"),tko=o(" \u2014 "),r$=a("a"),rko=o("TFBertForPreTraining"),ako=o(" (BERT model)"),nko=l(),lb=a("li"),Lae=a("strong"),sko=o("camembert"),lko=o(" \u2014 "),a$=a("a"),iko=o("TFCamembertForMaskedLM"),dko=o(" (CamemBERT model)"),mko=l(),ib=a("li"),Bae=a("strong"),fko=o("ctrl"),cko=o(" \u2014 "),n$=a("a"),gko=o("TFCTRLLMHeadModel"),hko=o(" (CTRL model)"),uko=l(),db=a("li"),kae=a("strong"),pko=o("distilbert"),_ko=o(" \u2014 "),s$=a("a"),vko=o("TFDistilBertForMaskedLM"),bko=o(" (DistilBERT model)"),Tko=l(),mb=a("li"),Rae=a("strong"),Fko=o("electra"),Mko=o(" \u2014 "),l$=a("a"),Eko=o("TFElectraForPreTraining"),Cko=o(" (ELECTRA model)"),yko=l(),fb=a("li"),Sae=a("strong"),wko=o("flaubert"),Ako=o(" \u2014 "),i$=a("a"),xko=o("TFFlaubertWithLMHeadModel"),Lko=o(" (FlauBERT model)"),Bko=l(),cb=a("li"),Pae=a("strong"),kko=o("funnel"),Rko=o(" \u2014 "),d$=a("a"),Sko=o("TFFunnelForPreTraining"),Pko=o(" (Funnel Transformer model)"),$ko=l(),gb=a("li"),$ae=a("strong"),Iko=o("gpt2"),jko=o(" \u2014 "),m$=a("a"),Nko=o("TFGPT2LMHeadModel"),Dko=o(" (OpenAI GPT-2 model)"),Gko=l(),hb=a("li"),Iae=a("strong"),Oko=o("layoutlm"),qko=o(" \u2014 "),f$=a("a"),zko=o("TFLayoutLMForMaskedLM"),Xko=o(" (LayoutLM model)"),Wko=l(),ub=a("li"),jae=a("strong"),Vko=o("lxmert"),Qko=o(" \u2014 "),c$=a("a"),Hko=o("TFLxmertForPreTraining"),Uko=o(" (LXMERT model)"),Jko=l(),pb=a("li"),Nae=a("strong"),Kko=o("mobilebert"),Yko=o(" \u2014 "),g$=a("a"),Zko=o("TFMobileBertForPreTraining"),eRo=o(" (MobileBERT model)"),oRo=l(),_b=a("li"),Dae=a("strong"),tRo=o("mpnet"),rRo=o(" \u2014 "),h$=a("a"),aRo=o("TFMPNetForMaskedLM"),nRo=o(" (MPNet model)"),sRo=l(),vb=a("li"),Gae=a("strong"),lRo=o("openai-gpt"),iRo=o(" \u2014 "),u$=a("a"),dRo=o("TFOpenAIGPTLMHeadModel"),mRo=o(" (OpenAI GPT model)"),fRo=l(),bb=a("li"),Oae=a("strong"),cRo=o("roberta"),gRo=o(" \u2014 "),p$=a("a"),hRo=o("TFRobertaForMaskedLM"),uRo=o(" (RoBERTa model)"),pRo=l(),Tb=a("li"),qae=a("strong"),_Ro=o("t5"),vRo=o(" \u2014 "),_$=a("a"),bRo=o("TFT5ForConditionalGeneration"),TRo=o(" (T5 model)"),FRo=l(),Fb=a("li"),zae=a("strong"),MRo=o("tapas"),ERo=o(" \u2014 "),v$=a("a"),CRo=o("TFTapasForMaskedLM"),yRo=o(" (TAPAS model)"),wRo=l(),Mb=a("li"),Xae=a("strong"),ARo=o("transfo-xl"),xRo=o(" \u2014 "),b$=a("a"),LRo=o("TFTransfoXLLMHeadModel"),BRo=o(" (Transformer-XL model)"),kRo=l(),Eb=a("li"),Wae=a("strong"),RRo=o("xlm"),SRo=o(" \u2014 "),T$=a("a"),PRo=o("TFXLMWithLMHeadModel"),$Ro=o(" (XLM model)"),IRo=l(),Cb=a("li"),Vae=a("strong"),jRo=o("xlm-roberta"),NRo=o(" \u2014 "),F$=a("a"),DRo=o("TFXLMRobertaForMaskedLM"),GRo=o(" (XLM-RoBERTa model)"),ORo=l(),yb=a("li"),Qae=a("strong"),qRo=o("xlnet"),zRo=o(" \u2014 "),M$=a("a"),XRo=o("TFXLNetLMHeadModel"),WRo=o(" (XLNet model)"),VRo=l(),Hae=a("p"),QRo=o("Examples:"),HRo=l(),f(t3.$$.fragment),MCe=l(),Td=a("h2"),wb=a("a"),Uae=a("span"),f(r3.$$.fragment),URo=l(),Jae=a("span"),JRo=o("TFAutoModelForCausalLM"),ECe=l(),rt=a("div"),f(a3.$$.fragment),KRo=l(),Fd=a("p"),YRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Kae=a("code"),ZRo=o("from_pretrained()"),eSo=o(` class method or the
`),Yae=a("code"),oSo=o("from_config()"),tSo=o(" class method."),rSo=l(),n3=a("p"),aSo=o("This class cannot be instantiated directly using "),Zae=a("code"),nSo=o("__init__()"),sSo=o(" (throws an error)."),lSo=l(),Ht=a("div"),f(s3.$$.fragment),iSo=l(),ene=a("p"),dSo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),mSo=l(),Md=a("p"),fSo=o(`Note:
Loading a model from its configuration file does `),one=a("strong"),cSo=o("not"),gSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),tne=a("em"),hSo=o("~TFAutoModelForCausalLM.from_pretrained"),uSo=o(`] to load the model
weights.`),pSo=l(),rne=a("p"),_So=o("Examples:"),vSo=l(),f(l3.$$.fragment),bSo=l(),no=a("div"),f(i3.$$.fragment),TSo=l(),ane=a("p"),FSo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),MSo=l(),Wa=a("p"),ESo=o("The model class to instantiate is selected based on the "),nne=a("em"),CSo=o("model_type"),ySo=o(` property of the config object (either
passed as an argument or loaded from `),sne=a("em"),wSo=o("pretrained_model_name_or_path"),ASo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),lne=a("em"),xSo=o("pretrained_model_name_or_path"),LSo=o(":"),BSo=l(),ce=a("ul"),Ab=a("li"),ine=a("strong"),kSo=o("bert"),RSo=o(" \u2014 "),E$=a("a"),SSo=o("TFBertLMHeadModel"),PSo=o(" (BERT model)"),$So=l(),xb=a("li"),dne=a("strong"),ISo=o("ctrl"),jSo=o(" \u2014 "),C$=a("a"),NSo=o("TFCTRLLMHeadModel"),DSo=o(" (CTRL model)"),GSo=l(),Lb=a("li"),mne=a("strong"),OSo=o("gpt2"),qSo=o(" \u2014 "),y$=a("a"),zSo=o("TFGPT2LMHeadModel"),XSo=o(" (OpenAI GPT-2 model)"),WSo=l(),Bb=a("li"),fne=a("strong"),VSo=o("openai-gpt"),QSo=o(" \u2014 "),w$=a("a"),HSo=o("TFOpenAIGPTLMHeadModel"),USo=o(" (OpenAI GPT model)"),JSo=l(),kb=a("li"),cne=a("strong"),KSo=o("rembert"),YSo=o(" \u2014 "),A$=a("a"),ZSo=o("TFRemBertForCausalLM"),ePo=o(" (RemBERT model)"),oPo=l(),Rb=a("li"),gne=a("strong"),tPo=o("roberta"),rPo=o(" \u2014 "),x$=a("a"),aPo=o("TFRobertaForCausalLM"),nPo=o(" (RoBERTa model)"),sPo=l(),Sb=a("li"),hne=a("strong"),lPo=o("roformer"),iPo=o(" \u2014 "),L$=a("a"),dPo=o("TFRoFormerForCausalLM"),mPo=o(" (RoFormer model)"),fPo=l(),Pb=a("li"),une=a("strong"),cPo=o("transfo-xl"),gPo=o(" \u2014 "),B$=a("a"),hPo=o("TFTransfoXLLMHeadModel"),uPo=o(" (Transformer-XL model)"),pPo=l(),$b=a("li"),pne=a("strong"),_Po=o("xlm"),vPo=o(" \u2014 "),k$=a("a"),bPo=o("TFXLMWithLMHeadModel"),TPo=o(" (XLM model)"),FPo=l(),Ib=a("li"),_ne=a("strong"),MPo=o("xlnet"),EPo=o(" \u2014 "),R$=a("a"),CPo=o("TFXLNetLMHeadModel"),yPo=o(" (XLNet model)"),wPo=l(),vne=a("p"),APo=o("Examples:"),xPo=l(),f(d3.$$.fragment),CCe=l(),Ed=a("h2"),jb=a("a"),bne=a("span"),f(m3.$$.fragment),LPo=l(),Tne=a("span"),BPo=o("TFAutoModelForImageClassification"),yCe=l(),at=a("div"),f(f3.$$.fragment),kPo=l(),Cd=a("p"),RPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Fne=a("code"),SPo=o("from_pretrained()"),PPo=o(` class method or the
`),Mne=a("code"),$Po=o("from_config()"),IPo=o(" class method."),jPo=l(),c3=a("p"),NPo=o("This class cannot be instantiated directly using "),Ene=a("code"),DPo=o("__init__()"),GPo=o(" (throws an error)."),OPo=l(),Ut=a("div"),f(g3.$$.fragment),qPo=l(),Cne=a("p"),zPo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),XPo=l(),yd=a("p"),WPo=o(`Note:
Loading a model from its configuration file does `),yne=a("strong"),VPo=o("not"),QPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),wne=a("em"),HPo=o("~TFAutoModelForImageClassification.from_pretrained"),UPo=o(`] to load the model
weights.`),JPo=l(),Ane=a("p"),KPo=o("Examples:"),YPo=l(),f(h3.$$.fragment),ZPo=l(),so=a("div"),f(u3.$$.fragment),e$o=l(),xne=a("p"),o$o=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),t$o=l(),Va=a("p"),r$o=o("The model class to instantiate is selected based on the "),Lne=a("em"),a$o=o("model_type"),n$o=o(` property of the config object (either
passed as an argument or loaded from `),Bne=a("em"),s$o=o("pretrained_model_name_or_path"),l$o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),kne=a("em"),i$o=o("pretrained_model_name_or_path"),d$o=o(":"),m$o=l(),Rne=a("ul"),Nb=a("li"),Sne=a("strong"),f$o=o("vit"),c$o=o(" \u2014 "),S$=a("a"),g$o=o("TFViTForImageClassification"),h$o=o(" (ViT model)"),u$o=l(),Pne=a("p"),p$o=o("Examples:"),_$o=l(),f(p3.$$.fragment),wCe=l(),wd=a("h2"),Db=a("a"),$ne=a("span"),f(_3.$$.fragment),v$o=l(),Ine=a("span"),b$o=o("TFAutoModelForMaskedLM"),ACe=l(),nt=a("div"),f(v3.$$.fragment),T$o=l(),Ad=a("p"),F$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jne=a("code"),M$o=o("from_pretrained()"),E$o=o(` class method or the
`),Nne=a("code"),C$o=o("from_config()"),y$o=o(" class method."),w$o=l(),b3=a("p"),A$o=o("This class cannot be instantiated directly using "),Dne=a("code"),x$o=o("__init__()"),L$o=o(" (throws an error)."),B$o=l(),Jt=a("div"),f(T3.$$.fragment),k$o=l(),Gne=a("p"),R$o=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),S$o=l(),xd=a("p"),P$o=o(`Note:
Loading a model from its configuration file does `),One=a("strong"),$$o=o("not"),I$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),qne=a("em"),j$o=o("~TFAutoModelForMaskedLM.from_pretrained"),N$o=o(`] to load the model
weights.`),D$o=l(),zne=a("p"),G$o=o("Examples:"),O$o=l(),f(F3.$$.fragment),q$o=l(),lo=a("div"),f(M3.$$.fragment),z$o=l(),Xne=a("p"),X$o=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),W$o=l(),Qa=a("p"),V$o=o("The model class to instantiate is selected based on the "),Wne=a("em"),Q$o=o("model_type"),H$o=o(` property of the config object (either
passed as an argument or loaded from `),Vne=a("em"),U$o=o("pretrained_model_name_or_path"),J$o=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Qne=a("em"),K$o=o("pretrained_model_name_or_path"),Y$o=o(":"),Z$o=l(),K=a("ul"),Gb=a("li"),Hne=a("strong"),eIo=o("albert"),oIo=o(" \u2014 "),P$=a("a"),tIo=o("TFAlbertForMaskedLM"),rIo=o(" (ALBERT model)"),aIo=l(),Ob=a("li"),Une=a("strong"),nIo=o("bert"),sIo=o(" \u2014 "),$$=a("a"),lIo=o("TFBertForMaskedLM"),iIo=o(" (BERT model)"),dIo=l(),qb=a("li"),Jne=a("strong"),mIo=o("camembert"),fIo=o(" \u2014 "),I$=a("a"),cIo=o("TFCamembertForMaskedLM"),gIo=o(" (CamemBERT model)"),hIo=l(),zb=a("li"),Kne=a("strong"),uIo=o("convbert"),pIo=o(" \u2014 "),j$=a("a"),_Io=o("TFConvBertForMaskedLM"),vIo=o(" (ConvBERT model)"),bIo=l(),Xb=a("li"),Yne=a("strong"),TIo=o("deberta"),FIo=o(" \u2014 "),N$=a("a"),MIo=o("TFDebertaForMaskedLM"),EIo=o(" (DeBERTa model)"),CIo=l(),Wb=a("li"),Zne=a("strong"),yIo=o("deberta-v2"),wIo=o(" \u2014 "),D$=a("a"),AIo=o("TFDebertaV2ForMaskedLM"),xIo=o(" (DeBERTa-v2 model)"),LIo=l(),Vb=a("li"),ese=a("strong"),BIo=o("distilbert"),kIo=o(" \u2014 "),G$=a("a"),RIo=o("TFDistilBertForMaskedLM"),SIo=o(" (DistilBERT model)"),PIo=l(),Qb=a("li"),ose=a("strong"),$Io=o("electra"),IIo=o(" \u2014 "),O$=a("a"),jIo=o("TFElectraForMaskedLM"),NIo=o(" (ELECTRA model)"),DIo=l(),Hb=a("li"),tse=a("strong"),GIo=o("flaubert"),OIo=o(" \u2014 "),q$=a("a"),qIo=o("TFFlaubertWithLMHeadModel"),zIo=o(" (FlauBERT model)"),XIo=l(),Ub=a("li"),rse=a("strong"),WIo=o("funnel"),VIo=o(" \u2014 "),z$=a("a"),QIo=o("TFFunnelForMaskedLM"),HIo=o(" (Funnel Transformer model)"),UIo=l(),Jb=a("li"),ase=a("strong"),JIo=o("layoutlm"),KIo=o(" \u2014 "),X$=a("a"),YIo=o("TFLayoutLMForMaskedLM"),ZIo=o(" (LayoutLM model)"),ejo=l(),Kb=a("li"),nse=a("strong"),ojo=o("longformer"),tjo=o(" \u2014 "),W$=a("a"),rjo=o("TFLongformerForMaskedLM"),ajo=o(" (Longformer model)"),njo=l(),Yb=a("li"),sse=a("strong"),sjo=o("mobilebert"),ljo=o(" \u2014 "),V$=a("a"),ijo=o("TFMobileBertForMaskedLM"),djo=o(" (MobileBERT model)"),mjo=l(),Zb=a("li"),lse=a("strong"),fjo=o("mpnet"),cjo=o(" \u2014 "),Q$=a("a"),gjo=o("TFMPNetForMaskedLM"),hjo=o(" (MPNet model)"),ujo=l(),e4=a("li"),ise=a("strong"),pjo=o("rembert"),_jo=o(" \u2014 "),H$=a("a"),vjo=o("TFRemBertForMaskedLM"),bjo=o(" (RemBERT model)"),Tjo=l(),o4=a("li"),dse=a("strong"),Fjo=o("roberta"),Mjo=o(" \u2014 "),U$=a("a"),Ejo=o("TFRobertaForMaskedLM"),Cjo=o(" (RoBERTa model)"),yjo=l(),t4=a("li"),mse=a("strong"),wjo=o("roformer"),Ajo=o(" \u2014 "),J$=a("a"),xjo=o("TFRoFormerForMaskedLM"),Ljo=o(" (RoFormer model)"),Bjo=l(),r4=a("li"),fse=a("strong"),kjo=o("tapas"),Rjo=o(" \u2014 "),K$=a("a"),Sjo=o("TFTapasForMaskedLM"),Pjo=o(" (TAPAS model)"),$jo=l(),a4=a("li"),cse=a("strong"),Ijo=o("xlm"),jjo=o(" \u2014 "),Y$=a("a"),Njo=o("TFXLMWithLMHeadModel"),Djo=o(" (XLM model)"),Gjo=l(),n4=a("li"),gse=a("strong"),Ojo=o("xlm-roberta"),qjo=o(" \u2014 "),Z$=a("a"),zjo=o("TFXLMRobertaForMaskedLM"),Xjo=o(" (XLM-RoBERTa model)"),Wjo=l(),hse=a("p"),Vjo=o("Examples:"),Qjo=l(),f(E3.$$.fragment),xCe=l(),Ld=a("h2"),s4=a("a"),use=a("span"),f(C3.$$.fragment),Hjo=l(),pse=a("span"),Ujo=o("TFAutoModelForSeq2SeqLM"),LCe=l(),st=a("div"),f(y3.$$.fragment),Jjo=l(),Bd=a("p"),Kjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_se=a("code"),Yjo=o("from_pretrained()"),Zjo=o(` class method or the
`),vse=a("code"),eNo=o("from_config()"),oNo=o(" class method."),tNo=l(),w3=a("p"),rNo=o("This class cannot be instantiated directly using "),bse=a("code"),aNo=o("__init__()"),nNo=o(" (throws an error)."),sNo=l(),Kt=a("div"),f(A3.$$.fragment),lNo=l(),Tse=a("p"),iNo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),dNo=l(),kd=a("p"),mNo=o(`Note:
Loading a model from its configuration file does `),Fse=a("strong"),fNo=o("not"),cNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Mse=a("em"),gNo=o("~TFAutoModelForSeq2SeqLM.from_pretrained"),hNo=o(`] to load the model
weights.`),uNo=l(),Ese=a("p"),pNo=o("Examples:"),_No=l(),f(x3.$$.fragment),vNo=l(),io=a("div"),f(L3.$$.fragment),bNo=l(),Cse=a("p"),TNo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),FNo=l(),Ha=a("p"),MNo=o("The model class to instantiate is selected based on the "),yse=a("em"),ENo=o("model_type"),CNo=o(` property of the config object (either
passed as an argument or loaded from `),wse=a("em"),yNo=o("pretrained_model_name_or_path"),wNo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ase=a("em"),ANo=o("pretrained_model_name_or_path"),xNo=o(":"),LNo=l(),ge=a("ul"),l4=a("li"),xse=a("strong"),BNo=o("bart"),kNo=o(" \u2014 "),eI=a("a"),RNo=o("TFBartForConditionalGeneration"),SNo=o(" (BART model)"),PNo=l(),i4=a("li"),Lse=a("strong"),$No=o("blenderbot"),INo=o(" \u2014 "),oI=a("a"),jNo=o("TFBlenderbotForConditionalGeneration"),NNo=o(" (Blenderbot model)"),DNo=l(),d4=a("li"),Bse=a("strong"),GNo=o("blenderbot-small"),ONo=o(" \u2014 "),tI=a("a"),qNo=o("TFBlenderbotSmallForConditionalGeneration"),zNo=o(" (BlenderbotSmall model)"),XNo=l(),m4=a("li"),kse=a("strong"),WNo=o("encoder-decoder"),VNo=o(" \u2014 "),rI=a("a"),QNo=o("TFEncoderDecoderModel"),HNo=o(" (Encoder decoder model)"),UNo=l(),f4=a("li"),Rse=a("strong"),JNo=o("led"),KNo=o(" \u2014 "),aI=a("a"),YNo=o("TFLEDForConditionalGeneration"),ZNo=o(" (LED model)"),eDo=l(),c4=a("li"),Sse=a("strong"),oDo=o("marian"),tDo=o(" \u2014 "),nI=a("a"),rDo=o("TFMarianMTModel"),aDo=o(" (Marian model)"),nDo=l(),g4=a("li"),Pse=a("strong"),sDo=o("mbart"),lDo=o(" \u2014 "),sI=a("a"),iDo=o("TFMBartForConditionalGeneration"),dDo=o(" (mBART model)"),mDo=l(),h4=a("li"),$se=a("strong"),fDo=o("mt5"),cDo=o(" \u2014 "),lI=a("a"),gDo=o("TFMT5ForConditionalGeneration"),hDo=o(" (mT5 model)"),uDo=l(),u4=a("li"),Ise=a("strong"),pDo=o("pegasus"),_Do=o(" \u2014 "),iI=a("a"),vDo=o("TFPegasusForConditionalGeneration"),bDo=o(" (Pegasus model)"),TDo=l(),p4=a("li"),jse=a("strong"),FDo=o("t5"),MDo=o(" \u2014 "),dI=a("a"),EDo=o("TFT5ForConditionalGeneration"),CDo=o(" (T5 model)"),yDo=l(),Nse=a("p"),wDo=o("Examples:"),ADo=l(),f(B3.$$.fragment),BCe=l(),Rd=a("h2"),_4=a("a"),Dse=a("span"),f(k3.$$.fragment),xDo=l(),Gse=a("span"),LDo=o("TFAutoModelForSequenceClassification"),kCe=l(),lt=a("div"),f(R3.$$.fragment),BDo=l(),Sd=a("p"),kDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Ose=a("code"),RDo=o("from_pretrained()"),SDo=o(` class method or the
`),qse=a("code"),PDo=o("from_config()"),$Do=o(" class method."),IDo=l(),S3=a("p"),jDo=o("This class cannot be instantiated directly using "),zse=a("code"),NDo=o("__init__()"),DDo=o(" (throws an error)."),GDo=l(),Yt=a("div"),f(P3.$$.fragment),ODo=l(),Xse=a("p"),qDo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zDo=l(),Pd=a("p"),XDo=o(`Note:
Loading a model from its configuration file does `),Wse=a("strong"),WDo=o("not"),VDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Vse=a("em"),QDo=o("~TFAutoModelForSequenceClassification.from_pretrained"),HDo=o(`] to load the model
weights.`),UDo=l(),Qse=a("p"),JDo=o("Examples:"),KDo=l(),f($3.$$.fragment),YDo=l(),mo=a("div"),f(I3.$$.fragment),ZDo=l(),Hse=a("p"),eGo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oGo=l(),Ua=a("p"),tGo=o("The model class to instantiate is selected based on the "),Use=a("em"),rGo=o("model_type"),aGo=o(` property of the config object (either
passed as an argument or loaded from `),Jse=a("em"),nGo=o("pretrained_model_name_or_path"),sGo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Kse=a("em"),lGo=o("pretrained_model_name_or_path"),iGo=o(":"),dGo=l(),O=a("ul"),v4=a("li"),Yse=a("strong"),mGo=o("albert"),fGo=o(" \u2014 "),mI=a("a"),cGo=o("TFAlbertForSequenceClassification"),gGo=o(" (ALBERT model)"),hGo=l(),b4=a("li"),Zse=a("strong"),uGo=o("bert"),pGo=o(" \u2014 "),fI=a("a"),_Go=o("TFBertForSequenceClassification"),vGo=o(" (BERT model)"),bGo=l(),T4=a("li"),ele=a("strong"),TGo=o("camembert"),FGo=o(" \u2014 "),cI=a("a"),MGo=o("TFCamembertForSequenceClassification"),EGo=o(" (CamemBERT model)"),CGo=l(),F4=a("li"),ole=a("strong"),yGo=o("convbert"),wGo=o(" \u2014 "),gI=a("a"),AGo=o("TFConvBertForSequenceClassification"),xGo=o(" (ConvBERT model)"),LGo=l(),M4=a("li"),tle=a("strong"),BGo=o("ctrl"),kGo=o(" \u2014 "),hI=a("a"),RGo=o("TFCTRLForSequenceClassification"),SGo=o(" (CTRL model)"),PGo=l(),E4=a("li"),rle=a("strong"),$Go=o("deberta"),IGo=o(" \u2014 "),uI=a("a"),jGo=o("TFDebertaForSequenceClassification"),NGo=o(" (DeBERTa model)"),DGo=l(),C4=a("li"),ale=a("strong"),GGo=o("deberta-v2"),OGo=o(" \u2014 "),pI=a("a"),qGo=o("TFDebertaV2ForSequenceClassification"),zGo=o(" (DeBERTa-v2 model)"),XGo=l(),y4=a("li"),nle=a("strong"),WGo=o("distilbert"),VGo=o(" \u2014 "),_I=a("a"),QGo=o("TFDistilBertForSequenceClassification"),HGo=o(" (DistilBERT model)"),UGo=l(),w4=a("li"),sle=a("strong"),JGo=o("electra"),KGo=o(" \u2014 "),vI=a("a"),YGo=o("TFElectraForSequenceClassification"),ZGo=o(" (ELECTRA model)"),eOo=l(),A4=a("li"),lle=a("strong"),oOo=o("flaubert"),tOo=o(" \u2014 "),bI=a("a"),rOo=o("TFFlaubertForSequenceClassification"),aOo=o(" (FlauBERT model)"),nOo=l(),x4=a("li"),ile=a("strong"),sOo=o("funnel"),lOo=o(" \u2014 "),TI=a("a"),iOo=o("TFFunnelForSequenceClassification"),dOo=o(" (Funnel Transformer model)"),mOo=l(),L4=a("li"),dle=a("strong"),fOo=o("gpt2"),cOo=o(" \u2014 "),FI=a("a"),gOo=o("TFGPT2ForSequenceClassification"),hOo=o(" (OpenAI GPT-2 model)"),uOo=l(),B4=a("li"),mle=a("strong"),pOo=o("layoutlm"),_Oo=o(" \u2014 "),MI=a("a"),vOo=o("TFLayoutLMForSequenceClassification"),bOo=o(" (LayoutLM model)"),TOo=l(),k4=a("li"),fle=a("strong"),FOo=o("longformer"),MOo=o(" \u2014 "),EI=a("a"),EOo=o("TFLongformerForSequenceClassification"),COo=o(" (Longformer model)"),yOo=l(),R4=a("li"),cle=a("strong"),wOo=o("mobilebert"),AOo=o(" \u2014 "),CI=a("a"),xOo=o("TFMobileBertForSequenceClassification"),LOo=o(" (MobileBERT model)"),BOo=l(),S4=a("li"),gle=a("strong"),kOo=o("mpnet"),ROo=o(" \u2014 "),yI=a("a"),SOo=o("TFMPNetForSequenceClassification"),POo=o(" (MPNet model)"),$Oo=l(),P4=a("li"),hle=a("strong"),IOo=o("openai-gpt"),jOo=o(" \u2014 "),wI=a("a"),NOo=o("TFOpenAIGPTForSequenceClassification"),DOo=o(" (OpenAI GPT model)"),GOo=l(),$4=a("li"),ule=a("strong"),OOo=o("rembert"),qOo=o(" \u2014 "),AI=a("a"),zOo=o("TFRemBertForSequenceClassification"),XOo=o(" (RemBERT model)"),WOo=l(),I4=a("li"),ple=a("strong"),VOo=o("roberta"),QOo=o(" \u2014 "),xI=a("a"),HOo=o("TFRobertaForSequenceClassification"),UOo=o(" (RoBERTa model)"),JOo=l(),j4=a("li"),_le=a("strong"),KOo=o("roformer"),YOo=o(" \u2014 "),LI=a("a"),ZOo=o("TFRoFormerForSequenceClassification"),eqo=o(" (RoFormer model)"),oqo=l(),N4=a("li"),vle=a("strong"),tqo=o("tapas"),rqo=o(" \u2014 "),BI=a("a"),aqo=o("TFTapasForSequenceClassification"),nqo=o(" (TAPAS model)"),sqo=l(),D4=a("li"),ble=a("strong"),lqo=o("transfo-xl"),iqo=o(" \u2014 "),kI=a("a"),dqo=o("TFTransfoXLForSequenceClassification"),mqo=o(" (Transformer-XL model)"),fqo=l(),G4=a("li"),Tle=a("strong"),cqo=o("xlm"),gqo=o(" \u2014 "),RI=a("a"),hqo=o("TFXLMForSequenceClassification"),uqo=o(" (XLM model)"),pqo=l(),O4=a("li"),Fle=a("strong"),_qo=o("xlm-roberta"),vqo=o(" \u2014 "),SI=a("a"),bqo=o("TFXLMRobertaForSequenceClassification"),Tqo=o(" (XLM-RoBERTa model)"),Fqo=l(),q4=a("li"),Mle=a("strong"),Mqo=o("xlnet"),Eqo=o(" \u2014 "),PI=a("a"),Cqo=o("TFXLNetForSequenceClassification"),yqo=o(" (XLNet model)"),wqo=l(),Ele=a("p"),Aqo=o("Examples:"),xqo=l(),f(j3.$$.fragment),RCe=l(),$d=a("h2"),z4=a("a"),Cle=a("span"),f(N3.$$.fragment),Lqo=l(),yle=a("span"),Bqo=o("TFAutoModelForMultipleChoice"),SCe=l(),it=a("div"),f(D3.$$.fragment),kqo=l(),Id=a("p"),Rqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),wle=a("code"),Sqo=o("from_pretrained()"),Pqo=o(` class method or the
`),Ale=a("code"),$qo=o("from_config()"),Iqo=o(" class method."),jqo=l(),G3=a("p"),Nqo=o("This class cannot be instantiated directly using "),xle=a("code"),Dqo=o("__init__()"),Gqo=o(" (throws an error)."),Oqo=l(),Zt=a("div"),f(O3.$$.fragment),qqo=l(),Lle=a("p"),zqo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Xqo=l(),jd=a("p"),Wqo=o(`Note:
Loading a model from its configuration file does `),Ble=a("strong"),Vqo=o("not"),Qqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),kle=a("em"),Hqo=o("~TFAutoModelForMultipleChoice.from_pretrained"),Uqo=o(`] to load the model
weights.`),Jqo=l(),Rle=a("p"),Kqo=o("Examples:"),Yqo=l(),f(q3.$$.fragment),Zqo=l(),fo=a("div"),f(z3.$$.fragment),ezo=l(),Sle=a("p"),ozo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),tzo=l(),Ja=a("p"),rzo=o("The model class to instantiate is selected based on the "),Ple=a("em"),azo=o("model_type"),nzo=o(` property of the config object (either
passed as an argument or loaded from `),$le=a("em"),szo=o("pretrained_model_name_or_path"),lzo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ile=a("em"),izo=o("pretrained_model_name_or_path"),dzo=o(":"),mzo=l(),re=a("ul"),X4=a("li"),jle=a("strong"),fzo=o("albert"),czo=o(" \u2014 "),$I=a("a"),gzo=o("TFAlbertForMultipleChoice"),hzo=o(" (ALBERT model)"),uzo=l(),W4=a("li"),Nle=a("strong"),pzo=o("bert"),_zo=o(" \u2014 "),II=a("a"),vzo=o("TFBertForMultipleChoice"),bzo=o(" (BERT model)"),Tzo=l(),V4=a("li"),Dle=a("strong"),Fzo=o("camembert"),Mzo=o(" \u2014 "),jI=a("a"),Ezo=o("TFCamembertForMultipleChoice"),Czo=o(" (CamemBERT model)"),yzo=l(),Q4=a("li"),Gle=a("strong"),wzo=o("convbert"),Azo=o(" \u2014 "),NI=a("a"),xzo=o("TFConvBertForMultipleChoice"),Lzo=o(" (ConvBERT model)"),Bzo=l(),H4=a("li"),Ole=a("strong"),kzo=o("distilbert"),Rzo=o(" \u2014 "),DI=a("a"),Szo=o("TFDistilBertForMultipleChoice"),Pzo=o(" (DistilBERT model)"),$zo=l(),U4=a("li"),qle=a("strong"),Izo=o("electra"),jzo=o(" \u2014 "),GI=a("a"),Nzo=o("TFElectraForMultipleChoice"),Dzo=o(" (ELECTRA model)"),Gzo=l(),J4=a("li"),zle=a("strong"),Ozo=o("flaubert"),qzo=o(" \u2014 "),OI=a("a"),zzo=o("TFFlaubertForMultipleChoice"),Xzo=o(" (FlauBERT model)"),Wzo=l(),K4=a("li"),Xle=a("strong"),Vzo=o("funnel"),Qzo=o(" \u2014 "),qI=a("a"),Hzo=o("TFFunnelForMultipleChoice"),Uzo=o(" (Funnel Transformer model)"),Jzo=l(),Y4=a("li"),Wle=a("strong"),Kzo=o("longformer"),Yzo=o(" \u2014 "),zI=a("a"),Zzo=o("TFLongformerForMultipleChoice"),eXo=o(" (Longformer model)"),oXo=l(),Z4=a("li"),Vle=a("strong"),tXo=o("mobilebert"),rXo=o(" \u2014 "),XI=a("a"),aXo=o("TFMobileBertForMultipleChoice"),nXo=o(" (MobileBERT model)"),sXo=l(),e5=a("li"),Qle=a("strong"),lXo=o("mpnet"),iXo=o(" \u2014 "),WI=a("a"),dXo=o("TFMPNetForMultipleChoice"),mXo=o(" (MPNet model)"),fXo=l(),o5=a("li"),Hle=a("strong"),cXo=o("rembert"),gXo=o(" \u2014 "),VI=a("a"),hXo=o("TFRemBertForMultipleChoice"),uXo=o(" (RemBERT model)"),pXo=l(),t5=a("li"),Ule=a("strong"),_Xo=o("roberta"),vXo=o(" \u2014 "),QI=a("a"),bXo=o("TFRobertaForMultipleChoice"),TXo=o(" (RoBERTa model)"),FXo=l(),r5=a("li"),Jle=a("strong"),MXo=o("roformer"),EXo=o(" \u2014 "),HI=a("a"),CXo=o("TFRoFormerForMultipleChoice"),yXo=o(" (RoFormer model)"),wXo=l(),a5=a("li"),Kle=a("strong"),AXo=o("xlm"),xXo=o(" \u2014 "),UI=a("a"),LXo=o("TFXLMForMultipleChoice"),BXo=o(" (XLM model)"),kXo=l(),n5=a("li"),Yle=a("strong"),RXo=o("xlm-roberta"),SXo=o(" \u2014 "),JI=a("a"),PXo=o("TFXLMRobertaForMultipleChoice"),$Xo=o(" (XLM-RoBERTa model)"),IXo=l(),s5=a("li"),Zle=a("strong"),jXo=o("xlnet"),NXo=o(" \u2014 "),KI=a("a"),DXo=o("TFXLNetForMultipleChoice"),GXo=o(" (XLNet model)"),OXo=l(),eie=a("p"),qXo=o("Examples:"),zXo=l(),f(X3.$$.fragment),PCe=l(),Nd=a("h2"),l5=a("a"),oie=a("span"),f(W3.$$.fragment),XXo=l(),tie=a("span"),WXo=o("TFAutoModelForTableQuestionAnswering"),$Ce=l(),dt=a("div"),f(V3.$$.fragment),VXo=l(),Dd=a("p"),QXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),rie=a("code"),HXo=o("from_pretrained()"),UXo=o(` class method or the
`),aie=a("code"),JXo=o("from_config()"),KXo=o(" class method."),YXo=l(),Q3=a("p"),ZXo=o("This class cannot be instantiated directly using "),nie=a("code"),eWo=o("__init__()"),oWo=o(" (throws an error)."),tWo=l(),er=a("div"),f(H3.$$.fragment),rWo=l(),sie=a("p"),aWo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),nWo=l(),Gd=a("p"),sWo=o(`Note:
Loading a model from its configuration file does `),lie=a("strong"),lWo=o("not"),iWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),iie=a("em"),dWo=o("~TFAutoModelForTableQuestionAnswering.from_pretrained"),mWo=o(`] to load the model
weights.`),fWo=l(),die=a("p"),cWo=o("Examples:"),gWo=l(),f(U3.$$.fragment),hWo=l(),co=a("div"),f(J3.$$.fragment),uWo=l(),mie=a("p"),pWo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_Wo=l(),Ka=a("p"),vWo=o("The model class to instantiate is selected based on the "),fie=a("em"),bWo=o("model_type"),TWo=o(` property of the config object (either
passed as an argument or loaded from `),cie=a("em"),FWo=o("pretrained_model_name_or_path"),MWo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),gie=a("em"),EWo=o("pretrained_model_name_or_path"),CWo=o(":"),yWo=l(),hie=a("ul"),i5=a("li"),uie=a("strong"),wWo=o("tapas"),AWo=o(" \u2014 "),YI=a("a"),xWo=o("TFTapasForQuestionAnswering"),LWo=o(" (TAPAS model)"),BWo=l(),pie=a("p"),kWo=o("Examples:"),RWo=l(),f(K3.$$.fragment),ICe=l(),Od=a("h2"),d5=a("a"),_ie=a("span"),f(Y3.$$.fragment),SWo=l(),vie=a("span"),PWo=o("TFAutoModelForTokenClassification"),jCe=l(),mt=a("div"),f(Z3.$$.fragment),$Wo=l(),qd=a("p"),IWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bie=a("code"),jWo=o("from_pretrained()"),NWo=o(` class method or the
`),Tie=a("code"),DWo=o("from_config()"),GWo=o(" class method."),OWo=l(),ey=a("p"),qWo=o("This class cannot be instantiated directly using "),Fie=a("code"),zWo=o("__init__()"),XWo=o(" (throws an error)."),WWo=l(),or=a("div"),f(oy.$$.fragment),VWo=l(),Mie=a("p"),QWo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),HWo=l(),zd=a("p"),UWo=o(`Note:
Loading a model from its configuration file does `),Eie=a("strong"),JWo=o("not"),KWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Cie=a("em"),YWo=o("~TFAutoModelForTokenClassification.from_pretrained"),ZWo=o(`] to load the model
weights.`),eVo=l(),yie=a("p"),oVo=o("Examples:"),tVo=l(),f(ty.$$.fragment),rVo=l(),go=a("div"),f(ry.$$.fragment),aVo=l(),wie=a("p"),nVo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),sVo=l(),Ya=a("p"),lVo=o("The model class to instantiate is selected based on the "),Aie=a("em"),iVo=o("model_type"),dVo=o(` property of the config object (either
passed as an argument or loaded from `),xie=a("em"),mVo=o("pretrained_model_name_or_path"),fVo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Lie=a("em"),cVo=o("pretrained_model_name_or_path"),gVo=o(":"),hVo=l(),Y=a("ul"),m5=a("li"),Bie=a("strong"),uVo=o("albert"),pVo=o(" \u2014 "),ZI=a("a"),_Vo=o("TFAlbertForTokenClassification"),vVo=o(" (ALBERT model)"),bVo=l(),f5=a("li"),kie=a("strong"),TVo=o("bert"),FVo=o(" \u2014 "),ej=a("a"),MVo=o("TFBertForTokenClassification"),EVo=o(" (BERT model)"),CVo=l(),c5=a("li"),Rie=a("strong"),yVo=o("camembert"),wVo=o(" \u2014 "),oj=a("a"),AVo=o("TFCamembertForTokenClassification"),xVo=o(" (CamemBERT model)"),LVo=l(),g5=a("li"),Sie=a("strong"),BVo=o("convbert"),kVo=o(" \u2014 "),tj=a("a"),RVo=o("TFConvBertForTokenClassification"),SVo=o(" (ConvBERT model)"),PVo=l(),h5=a("li"),Pie=a("strong"),$Vo=o("deberta"),IVo=o(" \u2014 "),rj=a("a"),jVo=o("TFDebertaForTokenClassification"),NVo=o(" (DeBERTa model)"),DVo=l(),u5=a("li"),$ie=a("strong"),GVo=o("deberta-v2"),OVo=o(" \u2014 "),aj=a("a"),qVo=o("TFDebertaV2ForTokenClassification"),zVo=o(" (DeBERTa-v2 model)"),XVo=l(),p5=a("li"),Iie=a("strong"),WVo=o("distilbert"),VVo=o(" \u2014 "),nj=a("a"),QVo=o("TFDistilBertForTokenClassification"),HVo=o(" (DistilBERT model)"),UVo=l(),_5=a("li"),jie=a("strong"),JVo=o("electra"),KVo=o(" \u2014 "),sj=a("a"),YVo=o("TFElectraForTokenClassification"),ZVo=o(" (ELECTRA model)"),eQo=l(),v5=a("li"),Nie=a("strong"),oQo=o("flaubert"),tQo=o(" \u2014 "),lj=a("a"),rQo=o("TFFlaubertForTokenClassification"),aQo=o(" (FlauBERT model)"),nQo=l(),b5=a("li"),Die=a("strong"),sQo=o("funnel"),lQo=o(" \u2014 "),ij=a("a"),iQo=o("TFFunnelForTokenClassification"),dQo=o(" (Funnel Transformer model)"),mQo=l(),T5=a("li"),Gie=a("strong"),fQo=o("layoutlm"),cQo=o(" \u2014 "),dj=a("a"),gQo=o("TFLayoutLMForTokenClassification"),hQo=o(" (LayoutLM model)"),uQo=l(),F5=a("li"),Oie=a("strong"),pQo=o("longformer"),_Qo=o(" \u2014 "),mj=a("a"),vQo=o("TFLongformerForTokenClassification"),bQo=o(" (Longformer model)"),TQo=l(),M5=a("li"),qie=a("strong"),FQo=o("mobilebert"),MQo=o(" \u2014 "),fj=a("a"),EQo=o("TFMobileBertForTokenClassification"),CQo=o(" (MobileBERT model)"),yQo=l(),E5=a("li"),zie=a("strong"),wQo=o("mpnet"),AQo=o(" \u2014 "),cj=a("a"),xQo=o("TFMPNetForTokenClassification"),LQo=o(" (MPNet model)"),BQo=l(),C5=a("li"),Xie=a("strong"),kQo=o("rembert"),RQo=o(" \u2014 "),gj=a("a"),SQo=o("TFRemBertForTokenClassification"),PQo=o(" (RemBERT model)"),$Qo=l(),y5=a("li"),Wie=a("strong"),IQo=o("roberta"),jQo=o(" \u2014 "),hj=a("a"),NQo=o("TFRobertaForTokenClassification"),DQo=o(" (RoBERTa model)"),GQo=l(),w5=a("li"),Vie=a("strong"),OQo=o("roformer"),qQo=o(" \u2014 "),uj=a("a"),zQo=o("TFRoFormerForTokenClassification"),XQo=o(" (RoFormer model)"),WQo=l(),A5=a("li"),Qie=a("strong"),VQo=o("xlm"),QQo=o(" \u2014 "),pj=a("a"),HQo=o("TFXLMForTokenClassification"),UQo=o(" (XLM model)"),JQo=l(),x5=a("li"),Hie=a("strong"),KQo=o("xlm-roberta"),YQo=o(" \u2014 "),_j=a("a"),ZQo=o("TFXLMRobertaForTokenClassification"),eHo=o(" (XLM-RoBERTa model)"),oHo=l(),L5=a("li"),Uie=a("strong"),tHo=o("xlnet"),rHo=o(" \u2014 "),vj=a("a"),aHo=o("TFXLNetForTokenClassification"),nHo=o(" (XLNet model)"),sHo=l(),Jie=a("p"),lHo=o("Examples:"),iHo=l(),f(ay.$$.fragment),NCe=l(),Xd=a("h2"),B5=a("a"),Kie=a("span"),f(ny.$$.fragment),dHo=l(),Yie=a("span"),mHo=o("TFAutoModelForQuestionAnswering"),DCe=l(),ft=a("div"),f(sy.$$.fragment),fHo=l(),Wd=a("p"),cHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Zie=a("code"),gHo=o("from_pretrained()"),hHo=o(` class method or the
`),ede=a("code"),uHo=o("from_config()"),pHo=o(" class method."),_Ho=l(),ly=a("p"),vHo=o("This class cannot be instantiated directly using "),ode=a("code"),bHo=o("__init__()"),THo=o(" (throws an error)."),FHo=l(),tr=a("div"),f(iy.$$.fragment),MHo=l(),tde=a("p"),EHo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),CHo=l(),Vd=a("p"),yHo=o(`Note:
Loading a model from its configuration file does `),rde=a("strong"),wHo=o("not"),AHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),ade=a("em"),xHo=o("~TFAutoModelForQuestionAnswering.from_pretrained"),LHo=o(`] to load the model
weights.`),BHo=l(),nde=a("p"),kHo=o("Examples:"),RHo=l(),f(dy.$$.fragment),SHo=l(),ho=a("div"),f(my.$$.fragment),PHo=l(),sde=a("p"),$Ho=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),IHo=l(),Za=a("p"),jHo=o("The model class to instantiate is selected based on the "),lde=a("em"),NHo=o("model_type"),DHo=o(` property of the config object (either
passed as an argument or loaded from `),ide=a("em"),GHo=o("pretrained_model_name_or_path"),OHo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),dde=a("em"),qHo=o("pretrained_model_name_or_path"),zHo=o(":"),XHo=l(),Z=a("ul"),k5=a("li"),mde=a("strong"),WHo=o("albert"),VHo=o(" \u2014 "),bj=a("a"),QHo=o("TFAlbertForQuestionAnswering"),HHo=o(" (ALBERT model)"),UHo=l(),R5=a("li"),fde=a("strong"),JHo=o("bert"),KHo=o(" \u2014 "),Tj=a("a"),YHo=o("TFBertForQuestionAnswering"),ZHo=o(" (BERT model)"),eUo=l(),S5=a("li"),cde=a("strong"),oUo=o("camembert"),tUo=o(" \u2014 "),Fj=a("a"),rUo=o("TFCamembertForQuestionAnswering"),aUo=o(" (CamemBERT model)"),nUo=l(),P5=a("li"),gde=a("strong"),sUo=o("convbert"),lUo=o(" \u2014 "),Mj=a("a"),iUo=o("TFConvBertForQuestionAnswering"),dUo=o(" (ConvBERT model)"),mUo=l(),$5=a("li"),hde=a("strong"),fUo=o("deberta"),cUo=o(" \u2014 "),Ej=a("a"),gUo=o("TFDebertaForQuestionAnswering"),hUo=o(" (DeBERTa model)"),uUo=l(),I5=a("li"),ude=a("strong"),pUo=o("deberta-v2"),_Uo=o(" \u2014 "),Cj=a("a"),vUo=o("TFDebertaV2ForQuestionAnswering"),bUo=o(" (DeBERTa-v2 model)"),TUo=l(),j5=a("li"),pde=a("strong"),FUo=o("distilbert"),MUo=o(" \u2014 "),yj=a("a"),EUo=o("TFDistilBertForQuestionAnswering"),CUo=o(" (DistilBERT model)"),yUo=l(),N5=a("li"),_de=a("strong"),wUo=o("electra"),AUo=o(" \u2014 "),wj=a("a"),xUo=o("TFElectraForQuestionAnswering"),LUo=o(" (ELECTRA model)"),BUo=l(),D5=a("li"),vde=a("strong"),kUo=o("flaubert"),RUo=o(" \u2014 "),Aj=a("a"),SUo=o("TFFlaubertForQuestionAnsweringSimple"),PUo=o(" (FlauBERT model)"),$Uo=l(),G5=a("li"),bde=a("strong"),IUo=o("funnel"),jUo=o(" \u2014 "),xj=a("a"),NUo=o("TFFunnelForQuestionAnswering"),DUo=o(" (Funnel Transformer model)"),GUo=l(),O5=a("li"),Tde=a("strong"),OUo=o("longformer"),qUo=o(" \u2014 "),Lj=a("a"),zUo=o("TFLongformerForQuestionAnswering"),XUo=o(" (Longformer model)"),WUo=l(),q5=a("li"),Fde=a("strong"),VUo=o("mobilebert"),QUo=o(" \u2014 "),Bj=a("a"),HUo=o("TFMobileBertForQuestionAnswering"),UUo=o(" (MobileBERT model)"),JUo=l(),z5=a("li"),Mde=a("strong"),KUo=o("mpnet"),YUo=o(" \u2014 "),kj=a("a"),ZUo=o("TFMPNetForQuestionAnswering"),eJo=o(" (MPNet model)"),oJo=l(),X5=a("li"),Ede=a("strong"),tJo=o("rembert"),rJo=o(" \u2014 "),Rj=a("a"),aJo=o("TFRemBertForQuestionAnswering"),nJo=o(" (RemBERT model)"),sJo=l(),W5=a("li"),Cde=a("strong"),lJo=o("roberta"),iJo=o(" \u2014 "),Sj=a("a"),dJo=o("TFRobertaForQuestionAnswering"),mJo=o(" (RoBERTa model)"),fJo=l(),V5=a("li"),yde=a("strong"),cJo=o("roformer"),gJo=o(" \u2014 "),Pj=a("a"),hJo=o("TFRoFormerForQuestionAnswering"),uJo=o(" (RoFormer model)"),pJo=l(),Q5=a("li"),wde=a("strong"),_Jo=o("xlm"),vJo=o(" \u2014 "),$j=a("a"),bJo=o("TFXLMForQuestionAnsweringSimple"),TJo=o(" (XLM model)"),FJo=l(),H5=a("li"),Ade=a("strong"),MJo=o("xlm-roberta"),EJo=o(" \u2014 "),Ij=a("a"),CJo=o("TFXLMRobertaForQuestionAnswering"),yJo=o(" (XLM-RoBERTa model)"),wJo=l(),U5=a("li"),xde=a("strong"),AJo=o("xlnet"),xJo=o(" \u2014 "),jj=a("a"),LJo=o("TFXLNetForQuestionAnsweringSimple"),BJo=o(" (XLNet model)"),kJo=l(),Lde=a("p"),RJo=o("Examples:"),SJo=l(),f(fy.$$.fragment),GCe=l(),Qd=a("h2"),J5=a("a"),Bde=a("span"),f(cy.$$.fragment),PJo=l(),kde=a("span"),$Jo=o("FlaxAutoModel"),OCe=l(),ct=a("div"),f(gy.$$.fragment),IJo=l(),Hd=a("p"),jJo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Rde=a("code"),NJo=o("from_pretrained()"),DJo=o(` class method or the
`),Sde=a("code"),GJo=o("from_config()"),OJo=o(" class method."),qJo=l(),hy=a("p"),zJo=o("This class cannot be instantiated directly using "),Pde=a("code"),XJo=o("__init__()"),WJo=o(" (throws an error)."),VJo=l(),rr=a("div"),f(uy.$$.fragment),QJo=l(),$de=a("p"),HJo=o("Instantiates one of the base model classes of the library from a configuration."),UJo=l(),Ud=a("p"),JJo=o(`Note:
Loading a model from its configuration file does `),Ide=a("strong"),KJo=o("not"),YJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),jde=a("em"),ZJo=o("~FlaxAutoModel.from_pretrained"),eKo=o(`] to load the model
weights.`),oKo=l(),Nde=a("p"),tKo=o("Examples:"),rKo=l(),f(py.$$.fragment),aKo=l(),uo=a("div"),f(_y.$$.fragment),nKo=l(),Dde=a("p"),sKo=o("Instantiate one of the base model classes of the library from a pretrained model."),lKo=l(),en=a("p"),iKo=o("The model class to instantiate is selected based on the "),Gde=a("em"),dKo=o("model_type"),mKo=o(` property of the config object (either
passed as an argument or loaded from `),Ode=a("em"),fKo=o("pretrained_model_name_or_path"),cKo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),qde=a("em"),gKo=o("pretrained_model_name_or_path"),hKo=o(":"),uKo=l(),Q=a("ul"),K5=a("li"),zde=a("strong"),pKo=o("albert"),_Ko=o(" \u2014 "),Nj=a("a"),vKo=o("FlaxAlbertModel"),bKo=o(" (ALBERT model)"),TKo=l(),Y5=a("li"),Xde=a("strong"),FKo=o("bart"),MKo=o(" \u2014 "),Dj=a("a"),EKo=o("FlaxBartModel"),CKo=o(" (BART model)"),yKo=l(),Z5=a("li"),Wde=a("strong"),wKo=o("beit"),AKo=o(" \u2014 "),Gj=a("a"),xKo=o("FlaxBeitModel"),LKo=o(" (BEiT model)"),BKo=l(),e0=a("li"),Vde=a("strong"),kKo=o("bert"),RKo=o(" \u2014 "),Oj=a("a"),SKo=o("FlaxBertModel"),PKo=o(" (BERT model)"),$Ko=l(),o0=a("li"),Qde=a("strong"),IKo=o("big_bird"),jKo=o(" \u2014 "),qj=a("a"),NKo=o("FlaxBigBirdModel"),DKo=o(" (BigBird model)"),GKo=l(),t0=a("li"),Hde=a("strong"),OKo=o("blenderbot"),qKo=o(" \u2014 "),zj=a("a"),zKo=o("FlaxBlenderbotModel"),XKo=o(" (Blenderbot model)"),WKo=l(),r0=a("li"),Ude=a("strong"),VKo=o("blenderbot-small"),QKo=o(" \u2014 "),Xj=a("a"),HKo=o("FlaxBlenderbotSmallModel"),UKo=o(" (BlenderbotSmall model)"),JKo=l(),a0=a("li"),Jde=a("strong"),KKo=o("clip"),YKo=o(" \u2014 "),Wj=a("a"),ZKo=o("FlaxCLIPModel"),eYo=o(" (CLIP model)"),oYo=l(),n0=a("li"),Kde=a("strong"),tYo=o("distilbert"),rYo=o(" \u2014 "),Vj=a("a"),aYo=o("FlaxDistilBertModel"),nYo=o(" (DistilBERT model)"),sYo=l(),s0=a("li"),Yde=a("strong"),lYo=o("electra"),iYo=o(" \u2014 "),Qj=a("a"),dYo=o("FlaxElectraModel"),mYo=o(" (ELECTRA model)"),fYo=l(),l0=a("li"),Zde=a("strong"),cYo=o("gpt2"),gYo=o(" \u2014 "),Hj=a("a"),hYo=o("FlaxGPT2Model"),uYo=o(" (OpenAI GPT-2 model)"),pYo=l(),i0=a("li"),eme=a("strong"),_Yo=o("gpt_neo"),vYo=o(" \u2014 "),Uj=a("a"),bYo=o("FlaxGPTNeoModel"),TYo=o(" (GPT Neo model)"),FYo=l(),d0=a("li"),ome=a("strong"),MYo=o("gptj"),EYo=o(" \u2014 "),Jj=a("a"),CYo=o("FlaxGPTJModel"),yYo=o(" (GPT-J model)"),wYo=l(),m0=a("li"),tme=a("strong"),AYo=o("marian"),xYo=o(" \u2014 "),Kj=a("a"),LYo=o("FlaxMarianModel"),BYo=o(" (Marian model)"),kYo=l(),f0=a("li"),rme=a("strong"),RYo=o("mbart"),SYo=o(" \u2014 "),Yj=a("a"),PYo=o("FlaxMBartModel"),$Yo=o(" (mBART model)"),IYo=l(),c0=a("li"),ame=a("strong"),jYo=o("mt5"),NYo=o(" \u2014 "),Zj=a("a"),DYo=o("FlaxMT5Model"),GYo=o(" (mT5 model)"),OYo=l(),g0=a("li"),nme=a("strong"),qYo=o("pegasus"),zYo=o(" \u2014 "),eN=a("a"),XYo=o("FlaxPegasusModel"),WYo=o(" (Pegasus model)"),VYo=l(),h0=a("li"),sme=a("strong"),QYo=o("roberta"),HYo=o(" \u2014 "),oN=a("a"),UYo=o("FlaxRobertaModel"),JYo=o(" (RoBERTa model)"),KYo=l(),u0=a("li"),lme=a("strong"),YYo=o("t5"),ZYo=o(" \u2014 "),tN=a("a"),eZo=o("FlaxT5Model"),oZo=o(" (T5 model)"),tZo=l(),p0=a("li"),ime=a("strong"),rZo=o("vision-text-dual-encoder"),aZo=o(" \u2014 "),rN=a("a"),nZo=o("FlaxVisionTextDualEncoderModel"),sZo=o(" (VisionTextDualEncoder model)"),lZo=l(),_0=a("li"),dme=a("strong"),iZo=o("vit"),dZo=o(" \u2014 "),aN=a("a"),mZo=o("FlaxViTModel"),fZo=o(" (ViT model)"),cZo=l(),v0=a("li"),mme=a("strong"),gZo=o("wav2vec2"),hZo=o(" \u2014 "),nN=a("a"),uZo=o("FlaxWav2Vec2Model"),pZo=o(" (Wav2Vec2 model)"),_Zo=l(),fme=a("p"),vZo=o("Examples:"),bZo=l(),f(vy.$$.fragment),qCe=l(),Jd=a("h2"),b0=a("a"),cme=a("span"),f(by.$$.fragment),TZo=l(),gme=a("span"),FZo=o("FlaxAutoModelForCausalLM"),zCe=l(),gt=a("div"),f(Ty.$$.fragment),MZo=l(),Kd=a("p"),EZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hme=a("code"),CZo=o("from_pretrained()"),yZo=o(` class method or the
`),ume=a("code"),wZo=o("from_config()"),AZo=o(" class method."),xZo=l(),Fy=a("p"),LZo=o("This class cannot be instantiated directly using "),pme=a("code"),BZo=o("__init__()"),kZo=o(" (throws an error)."),RZo=l(),ar=a("div"),f(My.$$.fragment),SZo=l(),_me=a("p"),PZo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$Zo=l(),Yd=a("p"),IZo=o(`Note:
Loading a model from its configuration file does `),vme=a("strong"),jZo=o("not"),NZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),bme=a("em"),DZo=o("~FlaxAutoModelForCausalLM.from_pretrained"),GZo=o(`] to load the model
weights.`),OZo=l(),Tme=a("p"),qZo=o("Examples:"),zZo=l(),f(Ey.$$.fragment),XZo=l(),po=a("div"),f(Cy.$$.fragment),WZo=l(),Fme=a("p"),VZo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),QZo=l(),on=a("p"),HZo=o("The model class to instantiate is selected based on the "),Mme=a("em"),UZo=o("model_type"),JZo=o(` property of the config object (either
passed as an argument or loaded from `),Eme=a("em"),KZo=o("pretrained_model_name_or_path"),YZo=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Cme=a("em"),ZZo=o("pretrained_model_name_or_path"),eet=o(":"),oet=l(),Zd=a("ul"),T0=a("li"),yme=a("strong"),tet=o("gpt2"),ret=o(" \u2014 "),sN=a("a"),aet=o("FlaxGPT2LMHeadModel"),net=o(" (OpenAI GPT-2 model)"),set=l(),F0=a("li"),wme=a("strong"),iet=o("gpt_neo"),det=o(" \u2014 "),lN=a("a"),met=o("FlaxGPTNeoForCausalLM"),fet=o(" (GPT Neo model)"),cet=l(),M0=a("li"),Ame=a("strong"),get=o("gptj"),het=o(" \u2014 "),iN=a("a"),uet=o("FlaxGPTJForCausalLM"),pet=o(" (GPT-J model)"),_et=l(),xme=a("p"),vet=o("Examples:"),bet=l(),f(yy.$$.fragment),XCe=l(),em=a("h2"),E0=a("a"),Lme=a("span"),f(wy.$$.fragment),Tet=l(),Bme=a("span"),Fet=o("FlaxAutoModelForPreTraining"),WCe=l(),ht=a("div"),f(Ay.$$.fragment),Met=l(),om=a("p"),Eet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kme=a("code"),Cet=o("from_pretrained()"),yet=o(` class method or the
`),Rme=a("code"),wet=o("from_config()"),Aet=o(" class method."),xet=l(),xy=a("p"),Let=o("This class cannot be instantiated directly using "),Sme=a("code"),Bet=o("__init__()"),ket=o(" (throws an error)."),Ret=l(),nr=a("div"),f(Ly.$$.fragment),Set=l(),Pme=a("p"),Pet=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$et=l(),tm=a("p"),Iet=o(`Note:
Loading a model from its configuration file does `),$me=a("strong"),jet=o("not"),Net=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Ime=a("em"),Det=o("~FlaxAutoModelForPreTraining.from_pretrained"),Get=o(`] to load the model
weights.`),Oet=l(),jme=a("p"),qet=o("Examples:"),zet=l(),f(By.$$.fragment),Xet=l(),_o=a("div"),f(ky.$$.fragment),Wet=l(),Nme=a("p"),Vet=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Qet=l(),tn=a("p"),Het=o("The model class to instantiate is selected based on the "),Dme=a("em"),Uet=o("model_type"),Jet=o(` property of the config object (either
passed as an argument or loaded from `),Gme=a("em"),Ket=o("pretrained_model_name_or_path"),Yet=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ome=a("em"),Zet=o("pretrained_model_name_or_path"),eot=o(":"),oot=l(),he=a("ul"),C0=a("li"),qme=a("strong"),tot=o("albert"),rot=o(" \u2014 "),dN=a("a"),aot=o("FlaxAlbertForPreTraining"),not=o(" (ALBERT model)"),sot=l(),y0=a("li"),zme=a("strong"),lot=o("bart"),iot=o(" \u2014 "),mN=a("a"),dot=o("FlaxBartForConditionalGeneration"),mot=o(" (BART model)"),fot=l(),w0=a("li"),Xme=a("strong"),cot=o("bert"),got=o(" \u2014 "),fN=a("a"),hot=o("FlaxBertForPreTraining"),uot=o(" (BERT model)"),pot=l(),A0=a("li"),Wme=a("strong"),_ot=o("big_bird"),vot=o(" \u2014 "),cN=a("a"),bot=o("FlaxBigBirdForPreTraining"),Tot=o(" (BigBird model)"),Fot=l(),x0=a("li"),Vme=a("strong"),Mot=o("electra"),Eot=o(" \u2014 "),gN=a("a"),Cot=o("FlaxElectraForPreTraining"),yot=o(" (ELECTRA model)"),wot=l(),L0=a("li"),Qme=a("strong"),Aot=o("mbart"),xot=o(" \u2014 "),hN=a("a"),Lot=o("FlaxMBartForConditionalGeneration"),Bot=o(" (mBART model)"),kot=l(),B0=a("li"),Hme=a("strong"),Rot=o("mt5"),Sot=o(" \u2014 "),uN=a("a"),Pot=o("FlaxMT5ForConditionalGeneration"),$ot=o(" (mT5 model)"),Iot=l(),k0=a("li"),Ume=a("strong"),jot=o("roberta"),Not=o(" \u2014 "),pN=a("a"),Dot=o("FlaxRobertaForMaskedLM"),Got=o(" (RoBERTa model)"),Oot=l(),R0=a("li"),Jme=a("strong"),qot=o("t5"),zot=o(" \u2014 "),_N=a("a"),Xot=o("FlaxT5ForConditionalGeneration"),Wot=o(" (T5 model)"),Vot=l(),S0=a("li"),Kme=a("strong"),Qot=o("wav2vec2"),Hot=o(" \u2014 "),vN=a("a"),Uot=o("FlaxWav2Vec2ForPreTraining"),Jot=o(" (Wav2Vec2 model)"),Kot=l(),Yme=a("p"),Yot=o("Examples:"),Zot=l(),f(Ry.$$.fragment),VCe=l(),rm=a("h2"),P0=a("a"),Zme=a("span"),f(Sy.$$.fragment),ett=l(),efe=a("span"),ott=o("FlaxAutoModelForMaskedLM"),QCe=l(),ut=a("div"),f(Py.$$.fragment),ttt=l(),am=a("p"),rtt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ofe=a("code"),att=o("from_pretrained()"),ntt=o(` class method or the
`),tfe=a("code"),stt=o("from_config()"),ltt=o(" class method."),itt=l(),$y=a("p"),dtt=o("This class cannot be instantiated directly using "),rfe=a("code"),mtt=o("__init__()"),ftt=o(" (throws an error)."),ctt=l(),sr=a("div"),f(Iy.$$.fragment),gtt=l(),afe=a("p"),htt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),utt=l(),nm=a("p"),ptt=o(`Note:
Loading a model from its configuration file does `),nfe=a("strong"),_tt=o("not"),vtt=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),sfe=a("em"),btt=o("~FlaxAutoModelForMaskedLM.from_pretrained"),Ttt=o(`] to load the model
weights.`),Ftt=l(),lfe=a("p"),Mtt=o("Examples:"),Ett=l(),f(jy.$$.fragment),Ctt=l(),vo=a("div"),f(Ny.$$.fragment),ytt=l(),ife=a("p"),wtt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Att=l(),rn=a("p"),xtt=o("The model class to instantiate is selected based on the "),dfe=a("em"),Ltt=o("model_type"),Btt=o(` property of the config object (either
passed as an argument or loaded from `),mfe=a("em"),ktt=o("pretrained_model_name_or_path"),Rtt=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),ffe=a("em"),Stt=o("pretrained_model_name_or_path"),Ptt=o(":"),$tt=l(),Me=a("ul"),$0=a("li"),cfe=a("strong"),Itt=o("albert"),jtt=o(" \u2014 "),bN=a("a"),Ntt=o("FlaxAlbertForMaskedLM"),Dtt=o(" (ALBERT model)"),Gtt=l(),I0=a("li"),gfe=a("strong"),Ott=o("bart"),qtt=o(" \u2014 "),TN=a("a"),ztt=o("FlaxBartForConditionalGeneration"),Xtt=o(" (BART model)"),Wtt=l(),j0=a("li"),hfe=a("strong"),Vtt=o("bert"),Qtt=o(" \u2014 "),FN=a("a"),Htt=o("FlaxBertForMaskedLM"),Utt=o(" (BERT model)"),Jtt=l(),N0=a("li"),ufe=a("strong"),Ktt=o("big_bird"),Ytt=o(" \u2014 "),MN=a("a"),Ztt=o("FlaxBigBirdForMaskedLM"),ert=o(" (BigBird model)"),ort=l(),D0=a("li"),pfe=a("strong"),trt=o("distilbert"),rrt=o(" \u2014 "),EN=a("a"),art=o("FlaxDistilBertForMaskedLM"),nrt=o(" (DistilBERT model)"),srt=l(),G0=a("li"),_fe=a("strong"),lrt=o("electra"),irt=o(" \u2014 "),CN=a("a"),drt=o("FlaxElectraForMaskedLM"),mrt=o(" (ELECTRA model)"),frt=l(),O0=a("li"),vfe=a("strong"),crt=o("mbart"),grt=o(" \u2014 "),yN=a("a"),hrt=o("FlaxMBartForConditionalGeneration"),urt=o(" (mBART model)"),prt=l(),q0=a("li"),bfe=a("strong"),_rt=o("roberta"),vrt=o(" \u2014 "),wN=a("a"),brt=o("FlaxRobertaForMaskedLM"),Trt=o(" (RoBERTa model)"),Frt=l(),Tfe=a("p"),Mrt=o("Examples:"),Ert=l(),f(Dy.$$.fragment),HCe=l(),sm=a("h2"),z0=a("a"),Ffe=a("span"),f(Gy.$$.fragment),Crt=l(),Mfe=a("span"),yrt=o("FlaxAutoModelForSeq2SeqLM"),UCe=l(),pt=a("div"),f(Oy.$$.fragment),wrt=l(),lm=a("p"),Art=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Efe=a("code"),xrt=o("from_pretrained()"),Lrt=o(` class method or the
`),Cfe=a("code"),Brt=o("from_config()"),krt=o(" class method."),Rrt=l(),qy=a("p"),Srt=o("This class cannot be instantiated directly using "),yfe=a("code"),Prt=o("__init__()"),$rt=o(" (throws an error)."),Irt=l(),lr=a("div"),f(zy.$$.fragment),jrt=l(),wfe=a("p"),Nrt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Drt=l(),im=a("p"),Grt=o(`Note:
Loading a model from its configuration file does `),Afe=a("strong"),Ort=o("not"),qrt=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),xfe=a("em"),zrt=o("~FlaxAutoModelForSeq2SeqLM.from_pretrained"),Xrt=o(`] to load the model
weights.`),Wrt=l(),Lfe=a("p"),Vrt=o("Examples:"),Qrt=l(),f(Xy.$$.fragment),Hrt=l(),bo=a("div"),f(Wy.$$.fragment),Urt=l(),Bfe=a("p"),Jrt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Krt=l(),an=a("p"),Yrt=o("The model class to instantiate is selected based on the "),kfe=a("em"),Zrt=o("model_type"),eat=o(` property of the config object (either
passed as an argument or loaded from `),Rfe=a("em"),oat=o("pretrained_model_name_or_path"),tat=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Sfe=a("em"),rat=o("pretrained_model_name_or_path"),aat=o(":"),nat=l(),pe=a("ul"),X0=a("li"),Pfe=a("strong"),sat=o("bart"),lat=o(" \u2014 "),AN=a("a"),iat=o("FlaxBartForConditionalGeneration"),dat=o(" (BART model)"),mat=l(),W0=a("li"),$fe=a("strong"),fat=o("blenderbot"),cat=o(" \u2014 "),xN=a("a"),gat=o("FlaxBlenderbotForConditionalGeneration"),hat=o(" (Blenderbot model)"),uat=l(),V0=a("li"),Ife=a("strong"),pat=o("blenderbot-small"),_at=o(" \u2014 "),LN=a("a"),vat=o("FlaxBlenderbotSmallForConditionalGeneration"),bat=o(" (BlenderbotSmall model)"),Tat=l(),Q0=a("li"),jfe=a("strong"),Fat=o("encoder-decoder"),Mat=o(" \u2014 "),BN=a("a"),Eat=o("FlaxEncoderDecoderModel"),Cat=o(" (Encoder decoder model)"),yat=l(),H0=a("li"),Nfe=a("strong"),wat=o("marian"),Aat=o(" \u2014 "),kN=a("a"),xat=o("FlaxMarianMTModel"),Lat=o(" (Marian model)"),Bat=l(),U0=a("li"),Dfe=a("strong"),kat=o("mbart"),Rat=o(" \u2014 "),RN=a("a"),Sat=o("FlaxMBartForConditionalGeneration"),Pat=o(" (mBART model)"),$at=l(),J0=a("li"),Gfe=a("strong"),Iat=o("mt5"),jat=o(" \u2014 "),SN=a("a"),Nat=o("FlaxMT5ForConditionalGeneration"),Dat=o(" (mT5 model)"),Gat=l(),K0=a("li"),Ofe=a("strong"),Oat=o("pegasus"),qat=o(" \u2014 "),PN=a("a"),zat=o("FlaxPegasusForConditionalGeneration"),Xat=o(" (Pegasus model)"),Wat=l(),Y0=a("li"),qfe=a("strong"),Vat=o("t5"),Qat=o(" \u2014 "),$N=a("a"),Hat=o("FlaxT5ForConditionalGeneration"),Uat=o(" (T5 model)"),Jat=l(),zfe=a("p"),Kat=o("Examples:"),Yat=l(),f(Vy.$$.fragment),JCe=l(),dm=a("h2"),Z0=a("a"),Xfe=a("span"),f(Qy.$$.fragment),Zat=l(),Wfe=a("span"),ent=o("FlaxAutoModelForSequenceClassification"),KCe=l(),_t=a("div"),f(Hy.$$.fragment),ont=l(),mm=a("p"),tnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Vfe=a("code"),rnt=o("from_pretrained()"),ant=o(` class method or the
`),Qfe=a("code"),nnt=o("from_config()"),snt=o(" class method."),lnt=l(),Uy=a("p"),int=o("This class cannot be instantiated directly using "),Hfe=a("code"),dnt=o("__init__()"),mnt=o(" (throws an error)."),fnt=l(),ir=a("div"),f(Jy.$$.fragment),cnt=l(),Ufe=a("p"),gnt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hnt=l(),fm=a("p"),unt=o(`Note:
Loading a model from its configuration file does `),Jfe=a("strong"),pnt=o("not"),_nt=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Kfe=a("em"),vnt=o("~FlaxAutoModelForSequenceClassification.from_pretrained"),bnt=o(`] to load the model
weights.`),Tnt=l(),Yfe=a("p"),Fnt=o("Examples:"),Mnt=l(),f(Ky.$$.fragment),Ent=l(),To=a("div"),f(Yy.$$.fragment),Cnt=l(),Zfe=a("p"),ynt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),wnt=l(),nn=a("p"),Ant=o("The model class to instantiate is selected based on the "),ece=a("em"),xnt=o("model_type"),Lnt=o(` property of the config object (either
passed as an argument or loaded from `),oce=a("em"),Bnt=o("pretrained_model_name_or_path"),knt=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),tce=a("em"),Rnt=o("pretrained_model_name_or_path"),Snt=o(":"),Pnt=l(),Ee=a("ul"),eT=a("li"),rce=a("strong"),$nt=o("albert"),Int=o(" \u2014 "),IN=a("a"),jnt=o("FlaxAlbertForSequenceClassification"),Nnt=o(" (ALBERT model)"),Dnt=l(),oT=a("li"),ace=a("strong"),Gnt=o("bart"),Ont=o(" \u2014 "),jN=a("a"),qnt=o("FlaxBartForSequenceClassification"),znt=o(" (BART model)"),Xnt=l(),tT=a("li"),nce=a("strong"),Wnt=o("bert"),Vnt=o(" \u2014 "),NN=a("a"),Qnt=o("FlaxBertForSequenceClassification"),Hnt=o(" (BERT model)"),Unt=l(),rT=a("li"),sce=a("strong"),Jnt=o("big_bird"),Knt=o(" \u2014 "),DN=a("a"),Ynt=o("FlaxBigBirdForSequenceClassification"),Znt=o(" (BigBird model)"),est=l(),aT=a("li"),lce=a("strong"),ost=o("distilbert"),tst=o(" \u2014 "),GN=a("a"),rst=o("FlaxDistilBertForSequenceClassification"),ast=o(" (DistilBERT model)"),nst=l(),nT=a("li"),ice=a("strong"),sst=o("electra"),lst=o(" \u2014 "),ON=a("a"),ist=o("FlaxElectraForSequenceClassification"),dst=o(" (ELECTRA model)"),mst=l(),sT=a("li"),dce=a("strong"),fst=o("mbart"),cst=o(" \u2014 "),qN=a("a"),gst=o("FlaxMBartForSequenceClassification"),hst=o(" (mBART model)"),ust=l(),lT=a("li"),mce=a("strong"),pst=o("roberta"),_st=o(" \u2014 "),zN=a("a"),vst=o("FlaxRobertaForSequenceClassification"),bst=o(" (RoBERTa model)"),Tst=l(),fce=a("p"),Fst=o("Examples:"),Mst=l(),f(Zy.$$.fragment),YCe=l(),cm=a("h2"),iT=a("a"),cce=a("span"),f(ew.$$.fragment),Est=l(),gce=a("span"),Cst=o("FlaxAutoModelForQuestionAnswering"),ZCe=l(),vt=a("div"),f(ow.$$.fragment),yst=l(),gm=a("p"),wst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hce=a("code"),Ast=o("from_pretrained()"),xst=o(` class method or the
`),uce=a("code"),Lst=o("from_config()"),Bst=o(" class method."),kst=l(),tw=a("p"),Rst=o("This class cannot be instantiated directly using "),pce=a("code"),Sst=o("__init__()"),Pst=o(" (throws an error)."),$st=l(),dr=a("div"),f(rw.$$.fragment),Ist=l(),_ce=a("p"),jst=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Nst=l(),hm=a("p"),Dst=o(`Note:
Loading a model from its configuration file does `),vce=a("strong"),Gst=o("not"),Ost=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),bce=a("em"),qst=o("~FlaxAutoModelForQuestionAnswering.from_pretrained"),zst=o(`] to load the model
weights.`),Xst=l(),Tce=a("p"),Wst=o("Examples:"),Vst=l(),f(aw.$$.fragment),Qst=l(),Fo=a("div"),f(nw.$$.fragment),Hst=l(),Fce=a("p"),Ust=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Jst=l(),sn=a("p"),Kst=o("The model class to instantiate is selected based on the "),Mce=a("em"),Yst=o("model_type"),Zst=o(` property of the config object (either
passed as an argument or loaded from `),Ece=a("em"),elt=o("pretrained_model_name_or_path"),olt=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Cce=a("em"),tlt=o("pretrained_model_name_or_path"),rlt=o(":"),alt=l(),Ce=a("ul"),dT=a("li"),yce=a("strong"),nlt=o("albert"),slt=o(" \u2014 "),XN=a("a"),llt=o("FlaxAlbertForQuestionAnswering"),ilt=o(" (ALBERT model)"),dlt=l(),mT=a("li"),wce=a("strong"),mlt=o("bart"),flt=o(" \u2014 "),WN=a("a"),clt=o("FlaxBartForQuestionAnswering"),glt=o(" (BART model)"),hlt=l(),fT=a("li"),Ace=a("strong"),ult=o("bert"),plt=o(" \u2014 "),VN=a("a"),_lt=o("FlaxBertForQuestionAnswering"),vlt=o(" (BERT model)"),blt=l(),cT=a("li"),xce=a("strong"),Tlt=o("big_bird"),Flt=o(" \u2014 "),QN=a("a"),Mlt=o("FlaxBigBirdForQuestionAnswering"),Elt=o(" (BigBird model)"),Clt=l(),gT=a("li"),Lce=a("strong"),ylt=o("distilbert"),wlt=o(" \u2014 "),HN=a("a"),Alt=o("FlaxDistilBertForQuestionAnswering"),xlt=o(" (DistilBERT model)"),Llt=l(),hT=a("li"),Bce=a("strong"),Blt=o("electra"),klt=o(" \u2014 "),UN=a("a"),Rlt=o("FlaxElectraForQuestionAnswering"),Slt=o(" (ELECTRA model)"),Plt=l(),uT=a("li"),kce=a("strong"),$lt=o("mbart"),Ilt=o(" \u2014 "),JN=a("a"),jlt=o("FlaxMBartForQuestionAnswering"),Nlt=o(" (mBART model)"),Dlt=l(),pT=a("li"),Rce=a("strong"),Glt=o("roberta"),Olt=o(" \u2014 "),KN=a("a"),qlt=o("FlaxRobertaForQuestionAnswering"),zlt=o(" (RoBERTa model)"),Xlt=l(),Sce=a("p"),Wlt=o("Examples:"),Vlt=l(),f(sw.$$.fragment),e3e=l(),um=a("h2"),_T=a("a"),Pce=a("span"),f(lw.$$.fragment),Qlt=l(),$ce=a("span"),Hlt=o("FlaxAutoModelForTokenClassification"),o3e=l(),bt=a("div"),f(iw.$$.fragment),Ult=l(),pm=a("p"),Jlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Ice=a("code"),Klt=o("from_pretrained()"),Ylt=o(` class method or the
`),jce=a("code"),Zlt=o("from_config()"),eit=o(" class method."),oit=l(),dw=a("p"),tit=o("This class cannot be instantiated directly using "),Nce=a("code"),rit=o("__init__()"),ait=o(" (throws an error)."),nit=l(),mr=a("div"),f(mw.$$.fragment),sit=l(),Dce=a("p"),lit=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),iit=l(),_m=a("p"),dit=o(`Note:
Loading a model from its configuration file does `),Gce=a("strong"),mit=o("not"),fit=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Oce=a("em"),cit=o("~FlaxAutoModelForTokenClassification.from_pretrained"),git=o(`] to load the model
weights.`),hit=l(),qce=a("p"),uit=o("Examples:"),pit=l(),f(fw.$$.fragment),_it=l(),Mo=a("div"),f(cw.$$.fragment),vit=l(),zce=a("p"),bit=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Tit=l(),ln=a("p"),Fit=o("The model class to instantiate is selected based on the "),Xce=a("em"),Mit=o("model_type"),Eit=o(` property of the config object (either
passed as an argument or loaded from `),Wce=a("em"),Cit=o("pretrained_model_name_or_path"),yit=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Vce=a("em"),wit=o("pretrained_model_name_or_path"),Ait=o(":"),xit=l(),Tt=a("ul"),vT=a("li"),Qce=a("strong"),Lit=o("albert"),Bit=o(" \u2014 "),YN=a("a"),kit=o("FlaxAlbertForTokenClassification"),Rit=o(" (ALBERT model)"),Sit=l(),bT=a("li"),Hce=a("strong"),Pit=o("bert"),$it=o(" \u2014 "),ZN=a("a"),Iit=o("FlaxBertForTokenClassification"),jit=o(" (BERT model)"),Nit=l(),TT=a("li"),Uce=a("strong"),Dit=o("big_bird"),Git=o(" \u2014 "),eD=a("a"),Oit=o("FlaxBigBirdForTokenClassification"),qit=o(" (BigBird model)"),zit=l(),FT=a("li"),Jce=a("strong"),Xit=o("distilbert"),Wit=o(" \u2014 "),oD=a("a"),Vit=o("FlaxDistilBertForTokenClassification"),Qit=o(" (DistilBERT model)"),Hit=l(),MT=a("li"),Kce=a("strong"),Uit=o("electra"),Jit=o(" \u2014 "),tD=a("a"),Kit=o("FlaxElectraForTokenClassification"),Yit=o(" (ELECTRA model)"),Zit=l(),ET=a("li"),Yce=a("strong"),edt=o("roberta"),odt=o(" \u2014 "),rD=a("a"),tdt=o("FlaxRobertaForTokenClassification"),rdt=o(" (RoBERTa model)"),adt=l(),Zce=a("p"),ndt=o("Examples:"),sdt=l(),f(gw.$$.fragment),t3e=l(),vm=a("h2"),CT=a("a"),ege=a("span"),f(hw.$$.fragment),ldt=l(),oge=a("span"),idt=o("FlaxAutoModelForMultipleChoice"),r3e=l(),Ft=a("div"),f(uw.$$.fragment),ddt=l(),bm=a("p"),mdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),tge=a("code"),fdt=o("from_pretrained()"),cdt=o(` class method or the
`),rge=a("code"),gdt=o("from_config()"),hdt=o(" class method."),udt=l(),pw=a("p"),pdt=o("This class cannot be instantiated directly using "),age=a("code"),_dt=o("__init__()"),vdt=o(" (throws an error)."),bdt=l(),fr=a("div"),f(_w.$$.fragment),Tdt=l(),nge=a("p"),Fdt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Mdt=l(),Tm=a("p"),Edt=o(`Note:
Loading a model from its configuration file does `),sge=a("strong"),Cdt=o("not"),ydt=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),lge=a("em"),wdt=o("~FlaxAutoModelForMultipleChoice.from_pretrained"),Adt=o(`] to load the model
weights.`),xdt=l(),ige=a("p"),Ldt=o("Examples:"),Bdt=l(),f(vw.$$.fragment),kdt=l(),Eo=a("div"),f(bw.$$.fragment),Rdt=l(),dge=a("p"),Sdt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Pdt=l(),dn=a("p"),$dt=o("The model class to instantiate is selected based on the "),mge=a("em"),Idt=o("model_type"),jdt=o(` property of the config object (either
passed as an argument or loaded from `),fge=a("em"),Ndt=o("pretrained_model_name_or_path"),Ddt=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),cge=a("em"),Gdt=o("pretrained_model_name_or_path"),Odt=o(":"),qdt=l(),Mt=a("ul"),yT=a("li"),gge=a("strong"),zdt=o("albert"),Xdt=o(" \u2014 "),aD=a("a"),Wdt=o("FlaxAlbertForMultipleChoice"),Vdt=o(" (ALBERT model)"),Qdt=l(),wT=a("li"),hge=a("strong"),Hdt=o("bert"),Udt=o(" \u2014 "),nD=a("a"),Jdt=o("FlaxBertForMultipleChoice"),Kdt=o(" (BERT model)"),Ydt=l(),AT=a("li"),uge=a("strong"),Zdt=o("big_bird"),emt=o(" \u2014 "),sD=a("a"),omt=o("FlaxBigBirdForMultipleChoice"),tmt=o(" (BigBird model)"),rmt=l(),xT=a("li"),pge=a("strong"),amt=o("distilbert"),nmt=o(" \u2014 "),lD=a("a"),smt=o("FlaxDistilBertForMultipleChoice"),lmt=o(" (DistilBERT model)"),imt=l(),LT=a("li"),_ge=a("strong"),dmt=o("electra"),mmt=o(" \u2014 "),iD=a("a"),fmt=o("FlaxElectraForMultipleChoice"),cmt=o(" (ELECTRA model)"),gmt=l(),BT=a("li"),vge=a("strong"),hmt=o("roberta"),umt=o(" \u2014 "),dD=a("a"),pmt=o("FlaxRobertaForMultipleChoice"),_mt=o(" (RoBERTa model)"),vmt=l(),bge=a("p"),bmt=o("Examples:"),Tmt=l(),f(Tw.$$.fragment),a3e=l(),Fm=a("h2"),kT=a("a"),Tge=a("span"),f(Fw.$$.fragment),Fmt=l(),Fge=a("span"),Mmt=o("FlaxAutoModelForNextSentencePrediction"),n3e=l(),Et=a("div"),f(Mw.$$.fragment),Emt=l(),Mm=a("p"),Cmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Mge=a("code"),ymt=o("from_pretrained()"),wmt=o(` class method or the
`),Ege=a("code"),Amt=o("from_config()"),xmt=o(" class method."),Lmt=l(),Ew=a("p"),Bmt=o("This class cannot be instantiated directly using "),Cge=a("code"),kmt=o("__init__()"),Rmt=o(" (throws an error)."),Smt=l(),cr=a("div"),f(Cw.$$.fragment),Pmt=l(),yge=a("p"),$mt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Imt=l(),Em=a("p"),jmt=o(`Note:
Loading a model from its configuration file does `),wge=a("strong"),Nmt=o("not"),Dmt=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),Age=a("em"),Gmt=o("~FlaxAutoModelForNextSentencePrediction.from_pretrained"),Omt=o(`] to load the model
weights.`),qmt=l(),xge=a("p"),zmt=o("Examples:"),Xmt=l(),f(yw.$$.fragment),Wmt=l(),Co=a("div"),f(ww.$$.fragment),Vmt=l(),Lge=a("p"),Qmt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Hmt=l(),mn=a("p"),Umt=o("The model class to instantiate is selected based on the "),Bge=a("em"),Jmt=o("model_type"),Kmt=o(` property of the config object (either
passed as an argument or loaded from `),kge=a("em"),Ymt=o("pretrained_model_name_or_path"),Zmt=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Rge=a("em"),eft=o("pretrained_model_name_or_path"),oft=o(":"),tft=l(),Sge=a("ul"),RT=a("li"),Pge=a("strong"),rft=o("bert"),aft=o(" \u2014 "),mD=a("a"),nft=o("FlaxBertForNextSentencePrediction"),sft=o(" (BERT model)"),lft=l(),$ge=a("p"),ift=o("Examples:"),dft=l(),f(Aw.$$.fragment),s3e=l(),Cm=a("h2"),ST=a("a"),Ige=a("span"),f(xw.$$.fragment),mft=l(),jge=a("span"),fft=o("FlaxAutoModelForImageClassification"),l3e=l(),Ct=a("div"),f(Lw.$$.fragment),cft=l(),ym=a("p"),gft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nge=a("code"),hft=o("from_pretrained()"),uft=o(` class method or the
`),Dge=a("code"),pft=o("from_config()"),_ft=o(" class method."),vft=l(),Bw=a("p"),bft=o("This class cannot be instantiated directly using "),Gge=a("code"),Tft=o("__init__()"),Fft=o(" (throws an error)."),Mft=l(),gr=a("div"),f(kw.$$.fragment),Eft=l(),Oge=a("p"),Cft=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),yft=l(),wm=a("p"),wft=o(`Note:
Loading a model from its configuration file does `),qge=a("strong"),Aft=o("not"),xft=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),zge=a("em"),Lft=o("~FlaxAutoModelForImageClassification.from_pretrained"),Bft=o(`] to load the model
weights.`),kft=l(),Xge=a("p"),Rft=o("Examples:"),Sft=l(),f(Rw.$$.fragment),Pft=l(),yo=a("div"),f(Sw.$$.fragment),$ft=l(),Wge=a("p"),Ift=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),jft=l(),fn=a("p"),Nft=o("The model class to instantiate is selected based on the "),Vge=a("em"),Dft=o("model_type"),Gft=o(` property of the config object (either
passed as an argument or loaded from `),Qge=a("em"),Oft=o("pretrained_model_name_or_path"),qft=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Hge=a("em"),zft=o("pretrained_model_name_or_path"),Xft=o(":"),Wft=l(),Pw=a("ul"),PT=a("li"),Uge=a("strong"),Vft=o("beit"),Qft=o(" \u2014 "),fD=a("a"),Hft=o("FlaxBeitForImageClassification"),Uft=o(" (BEiT model)"),Jft=l(),$T=a("li"),Jge=a("strong"),Kft=o("vit"),Yft=o(" \u2014 "),cD=a("a"),Zft=o("FlaxViTForImageClassification"),ect=o(" (ViT model)"),oct=l(),Kge=a("p"),tct=o("Examples:"),rct=l(),f($w.$$.fragment),i3e=l(),Am=a("h2"),IT=a("a"),Yge=a("span"),f(Iw.$$.fragment),act=l(),Zge=a("span"),nct=o("FlaxAutoModelForVision2Seq"),d3e=l(),yt=a("div"),f(jw.$$.fragment),sct=l(),xm=a("p"),lct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ehe=a("code"),ict=o("from_pretrained()"),dct=o(` class method or the
`),ohe=a("code"),mct=o("from_config()"),fct=o(" class method."),cct=l(),Nw=a("p"),gct=o("This class cannot be instantiated directly using "),the=a("code"),hct=o("__init__()"),uct=o(" (throws an error)."),pct=l(),hr=a("div"),f(Dw.$$.fragment),_ct=l(),rhe=a("p"),vct=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),bct=l(),Lm=a("p"),Tct=o(`Note:
Loading a model from its configuration file does `),ahe=a("strong"),Fct=o("not"),Mct=o(` load the model weights. It only affects the
model\u2019s configuration. Use [`),nhe=a("em"),Ect=o("~FlaxAutoModelForVision2Seq.from_pretrained"),Cct=o(`] to load the model
weights.`),yct=l(),she=a("p"),wct=o("Examples:"),Act=l(),f(Gw.$$.fragment),xct=l(),wo=a("div"),f(Ow.$$.fragment),Lct=l(),lhe=a("p"),Bct=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kct=l(),cn=a("p"),Rct=o("The model class to instantiate is selected based on the "),ihe=a("em"),Sct=o("model_type"),Pct=o(` property of the config object (either
passed as an argument or loaded from `),dhe=a("em"),$ct=o("pretrained_model_name_or_path"),Ict=o(` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),mhe=a("em"),jct=o("pretrained_model_name_or_path"),Nct=o(":"),Dct=l(),fhe=a("ul"),jT=a("li"),che=a("strong"),Gct=o("vision-encoder-decoder"),Oct=o(" \u2014 "),gD=a("a"),qct=o("FlaxVisionEncoderDecoderModel"),zct=o(" (Vision Encoder decoder model)"),Xct=l(),ghe=a("p"),Wct=o("Examples:"),Vct=l(),f(qw.$$.fragment),this.h()},l(d){const _=OVt('[data-svelte="svelte-1phssyn"]',document.head);J=n(_,"META",{name:!0,content:!0}),_.forEach(r),ye=i(d),se=n(d,"H1",{class:!0});var zw=s(se);de=n(zw,"A",{id:!0,class:!0,href:!0});var hhe=s(de);Ue=n(hhe,"SPAN",{});var uhe=s(Ue);c(ie.$$.fragment,uhe),uhe.forEach(r),hhe.forEach(r),ue=i(zw),Bo=n(zw,"SPAN",{});var Hct=s(Bo);Vl=t(Hct,"Auto Classes"),Hct.forEach(r),zw.forEach(r),km=i(d),zr=n(d,"P",{});var f3e=s(zr);Ql=t(f3e,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Hl=n(f3e,"CODE",{});var Uct=s(Hl);RF=t(Uct,"from_pretrained()"),Uct.forEach(r),Rm=t(f3e,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),f3e.forEach(r),Fe=i(d),Ze=n(d,"P",{});var NT=s(Ze);Ul=t(NT,"Instantiating one of "),gn=n(NT,"A",{href:!0});var Jct=s(gn);SF=t(Jct,"AutoConfig"),Jct.forEach(r),hn=t(NT,", "),un=n(NT,"A",{href:!0});var Kct=s(un);PF=t(Kct,"AutoModel"),Kct.forEach(r),Jl=t(NT,`, and
`),pn=n(NT,"A",{href:!0});var Yct=s(pn);$F=t(Yct,"AutoTokenizer"),Yct.forEach(r),Kl=t(NT," will directly create a class of the relevant architecture. For instance"),NT.forEach(r),Sm=i(d),c(ba.$$.fragment,d),eo=i(d),me=n(d,"P",{});var c3e=s(me);IA=t(c3e,"will create a model that is an instance of "),Yl=n(c3e,"A",{href:!0});var Zct=s(Yl);jA=t(Zct,"BertModel"),Zct.forEach(r),NA=t(c3e,"."),c3e.forEach(r),ko=i(d),Ta=n(d,"P",{});var g3e=s(Ta);DA=t(g3e,"There is one class of "),Pm=n(g3e,"CODE",{});var egt=s(Pm);GA=t(egt,"AutoModel"),egt.forEach(r),dwe=t(g3e," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),g3e.forEach(r),bEe=i(d),Zl=n(d,"H2",{class:!0});var h3e=s(Zl);$m=n(h3e,"A",{id:!0,class:!0,href:!0});var ogt=s($m);YG=n(ogt,"SPAN",{});var tgt=s(YG);c(IF.$$.fragment,tgt),tgt.forEach(r),ogt.forEach(r),mwe=i(h3e),ZG=n(h3e,"SPAN",{});var rgt=s(ZG);fwe=t(rgt,"Extending the Auto Classes"),rgt.forEach(r),h3e.forEach(r),TEe=i(d),_n=n(d,"P",{});var hD=s(_n);cwe=t(hD,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),eO=n(hD,"CODE",{});var agt=s(eO);gwe=t(agt,"NewModel"),agt.forEach(r),hwe=t(hD,", make sure you have a "),oO=n(hD,"CODE",{});var ngt=s(oO);uwe=t(ngt,"NewModelConfig"),ngt.forEach(r),pwe=t(hD,` then you can add those to the auto
classes like this:`),hD.forEach(r),FEe=i(d),c(jF.$$.fragment,d),MEe=i(d),OA=n(d,"P",{});var sgt=s(OA);_we=t(sgt,"You will then be able to use the auto classes like you would usually do!"),sgt.forEach(r),EEe=i(d),c(Im.$$.fragment,d),CEe=i(d),ei=n(d,"H2",{class:!0});var u3e=s(ei);jm=n(u3e,"A",{id:!0,class:!0,href:!0});var lgt=s(jm);tO=n(lgt,"SPAN",{});var igt=s(tO);c(NF.$$.fragment,igt),igt.forEach(r),lgt.forEach(r),vwe=i(u3e),rO=n(u3e,"SPAN",{});var dgt=s(rO);bwe=t(dgt,"AutoConfig"),dgt.forEach(r),u3e.forEach(r),yEe=i(d),Ro=n(d,"DIV",{class:!0});var ms=s(Ro);c(DF.$$.fragment,ms),Twe=i(ms),GF=n(ms,"P",{});var p3e=s(GF);Fwe=t(p3e,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),qA=n(p3e,"A",{href:!0});var mgt=s(qA);Mwe=t(mgt,"from_pretrained()"),mgt.forEach(r),Ewe=t(p3e," class method."),p3e.forEach(r),Cwe=i(ms),OF=n(ms,"P",{});var _3e=s(OF);ywe=t(_3e,"This class cannot be instantiated directly using "),aO=n(_3e,"CODE",{});var fgt=s(aO);wwe=t(fgt,"__init__()"),fgt.forEach(r),Awe=t(_3e," (throws an error)."),_3e.forEach(r),xwe=i(ms),oo=n(ms,"DIV",{class:!0});var Wr=s(oo);c(qF.$$.fragment,Wr),Lwe=i(Wr),nO=n(Wr,"P",{});var cgt=s(nO);Bwe=t(cgt,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),cgt.forEach(r),kwe=i(Wr),oi=n(Wr,"P",{});var uD=s(oi);Rwe=t(uD,"The configuration class to instantiate is selected based on the "),sO=n(uD,"EM",{});var ggt=s(sO);Swe=t(ggt,"model_type"),ggt.forEach(r),Pwe=t(uD,` property of the config object
that is loaded, or when it\u2019s missing, by falling back to using pattern matching on
`),lO=n(uD,"EM",{});var hgt=s(lO);$we=t(hgt,"pretrained_model_name_or_path"),hgt.forEach(r),Iwe=t(uD,":"),uD.forEach(r),jwe=i(Wr),b=n(Wr,"UL",{});var T=s(b);Nm=n(T,"LI",{});var phe=s(Nm);iO=n(phe,"STRONG",{});var ugt=s(iO);Nwe=t(ugt,"albert"),ugt.forEach(r),Dwe=t(phe," \u2014 "),zA=n(phe,"A",{href:!0});var pgt=s(zA);Gwe=t(pgt,"AlbertConfig"),pgt.forEach(r),Owe=t(phe," (ALBERT model)"),phe.forEach(r),qwe=i(T),Dm=n(T,"LI",{});var _he=s(Dm);dO=n(_he,"STRONG",{});var _gt=s(dO);zwe=t(_gt,"bart"),_gt.forEach(r),Xwe=t(_he," \u2014 "),XA=n(_he,"A",{href:!0});var vgt=s(XA);Wwe=t(vgt,"BartConfig"),vgt.forEach(r),Vwe=t(_he," (BART model)"),_he.forEach(r),Qwe=i(T),Gm=n(T,"LI",{});var vhe=s(Gm);mO=n(vhe,"STRONG",{});var bgt=s(mO);Hwe=t(bgt,"beit"),bgt.forEach(r),Uwe=t(vhe," \u2014 "),WA=n(vhe,"A",{href:!0});var Tgt=s(WA);Jwe=t(Tgt,"BeitConfig"),Tgt.forEach(r),Kwe=t(vhe," (BEiT model)"),vhe.forEach(r),Ywe=i(T),Om=n(T,"LI",{});var bhe=s(Om);fO=n(bhe,"STRONG",{});var Fgt=s(fO);Zwe=t(Fgt,"bert"),Fgt.forEach(r),eAe=t(bhe," \u2014 "),VA=n(bhe,"A",{href:!0});var Mgt=s(VA);oAe=t(Mgt,"BertConfig"),Mgt.forEach(r),tAe=t(bhe," (BERT model)"),bhe.forEach(r),rAe=i(T),qm=n(T,"LI",{});var The=s(qm);cO=n(The,"STRONG",{});var Egt=s(cO);aAe=t(Egt,"bert-generation"),Egt.forEach(r),nAe=t(The," \u2014 "),QA=n(The,"A",{href:!0});var Cgt=s(QA);sAe=t(Cgt,"BertGenerationConfig"),Cgt.forEach(r),lAe=t(The," (Bert Generation model)"),The.forEach(r),iAe=i(T),zm=n(T,"LI",{});var Fhe=s(zm);gO=n(Fhe,"STRONG",{});var ygt=s(gO);dAe=t(ygt,"big_bird"),ygt.forEach(r),mAe=t(Fhe," \u2014 "),HA=n(Fhe,"A",{href:!0});var wgt=s(HA);fAe=t(wgt,"BigBirdConfig"),wgt.forEach(r),cAe=t(Fhe," (BigBird model)"),Fhe.forEach(r),gAe=i(T),Xm=n(T,"LI",{});var Mhe=s(Xm);hO=n(Mhe,"STRONG",{});var Agt=s(hO);hAe=t(Agt,"bigbird_pegasus"),Agt.forEach(r),uAe=t(Mhe," \u2014 "),UA=n(Mhe,"A",{href:!0});var xgt=s(UA);pAe=t(xgt,"BigBirdPegasusConfig"),xgt.forEach(r),_Ae=t(Mhe," (BigBirdPegasus model)"),Mhe.forEach(r),vAe=i(T),Wm=n(T,"LI",{});var Ehe=s(Wm);uO=n(Ehe,"STRONG",{});var Lgt=s(uO);bAe=t(Lgt,"blenderbot"),Lgt.forEach(r),TAe=t(Ehe," \u2014 "),JA=n(Ehe,"A",{href:!0});var Bgt=s(JA);FAe=t(Bgt,"BlenderbotConfig"),Bgt.forEach(r),MAe=t(Ehe," (Blenderbot model)"),Ehe.forEach(r),EAe=i(T),Vm=n(T,"LI",{});var Che=s(Vm);pO=n(Che,"STRONG",{});var kgt=s(pO);CAe=t(kgt,"blenderbot-small"),kgt.forEach(r),yAe=t(Che," \u2014 "),KA=n(Che,"A",{href:!0});var Rgt=s(KA);wAe=t(Rgt,"BlenderbotSmallConfig"),Rgt.forEach(r),AAe=t(Che," (BlenderbotSmall model)"),Che.forEach(r),xAe=i(T),Qm=n(T,"LI",{});var yhe=s(Qm);_O=n(yhe,"STRONG",{});var Sgt=s(_O);LAe=t(Sgt,"camembert"),Sgt.forEach(r),BAe=t(yhe," \u2014 "),YA=n(yhe,"A",{href:!0});var Pgt=s(YA);kAe=t(Pgt,"CamembertConfig"),Pgt.forEach(r),RAe=t(yhe," (CamemBERT model)"),yhe.forEach(r),SAe=i(T),Hm=n(T,"LI",{});var whe=s(Hm);vO=n(whe,"STRONG",{});var $gt=s(vO);PAe=t($gt,"canine"),$gt.forEach(r),$Ae=t(whe," \u2014 "),ZA=n(whe,"A",{href:!0});var Igt=s(ZA);IAe=t(Igt,"CanineConfig"),Igt.forEach(r),jAe=t(whe," (Canine model)"),whe.forEach(r),NAe=i(T),Um=n(T,"LI",{});var Ahe=s(Um);bO=n(Ahe,"STRONG",{});var jgt=s(bO);DAe=t(jgt,"clip"),jgt.forEach(r),GAe=t(Ahe," \u2014 "),e7=n(Ahe,"A",{href:!0});var Ngt=s(e7);OAe=t(Ngt,"CLIPConfig"),Ngt.forEach(r),qAe=t(Ahe," (CLIP model)"),Ahe.forEach(r),zAe=i(T),Jm=n(T,"LI",{});var xhe=s(Jm);TO=n(xhe,"STRONG",{});var Dgt=s(TO);XAe=t(Dgt,"convbert"),Dgt.forEach(r),WAe=t(xhe," \u2014 "),o7=n(xhe,"A",{href:!0});var Ggt=s(o7);VAe=t(Ggt,"ConvBertConfig"),Ggt.forEach(r),QAe=t(xhe," (ConvBERT model)"),xhe.forEach(r),HAe=i(T),Km=n(T,"LI",{});var Lhe=s(Km);FO=n(Lhe,"STRONG",{});var Ogt=s(FO);UAe=t(Ogt,"ctrl"),Ogt.forEach(r),JAe=t(Lhe," \u2014 "),t7=n(Lhe,"A",{href:!0});var qgt=s(t7);KAe=t(qgt,"CTRLConfig"),qgt.forEach(r),YAe=t(Lhe," (CTRL model)"),Lhe.forEach(r),ZAe=i(T),Ym=n(T,"LI",{});var Bhe=s(Ym);MO=n(Bhe,"STRONG",{});var zgt=s(MO);e7e=t(zgt,"deberta"),zgt.forEach(r),o7e=t(Bhe," \u2014 "),r7=n(Bhe,"A",{href:!0});var Xgt=s(r7);t7e=t(Xgt,"DebertaConfig"),Xgt.forEach(r),r7e=t(Bhe," (DeBERTa model)"),Bhe.forEach(r),a7e=i(T),Zm=n(T,"LI",{});var khe=s(Zm);EO=n(khe,"STRONG",{});var Wgt=s(EO);n7e=t(Wgt,"deberta-v2"),Wgt.forEach(r),s7e=t(khe," \u2014 "),a7=n(khe,"A",{href:!0});var Vgt=s(a7);l7e=t(Vgt,"DebertaV2Config"),Vgt.forEach(r),i7e=t(khe," (DeBERTa-v2 model)"),khe.forEach(r),d7e=i(T),ef=n(T,"LI",{});var Rhe=s(ef);CO=n(Rhe,"STRONG",{});var Qgt=s(CO);m7e=t(Qgt,"deit"),Qgt.forEach(r),f7e=t(Rhe," \u2014 "),n7=n(Rhe,"A",{href:!0});var Hgt=s(n7);c7e=t(Hgt,"DeiTConfig"),Hgt.forEach(r),g7e=t(Rhe," (DeiT model)"),Rhe.forEach(r),h7e=i(T),of=n(T,"LI",{});var She=s(of);yO=n(She,"STRONG",{});var Ugt=s(yO);u7e=t(Ugt,"detr"),Ugt.forEach(r),p7e=t(She," \u2014 "),s7=n(She,"A",{href:!0});var Jgt=s(s7);_7e=t(Jgt,"DetrConfig"),Jgt.forEach(r),v7e=t(She," (DETR model)"),She.forEach(r),b7e=i(T),tf=n(T,"LI",{});var Phe=s(tf);wO=n(Phe,"STRONG",{});var Kgt=s(wO);T7e=t(Kgt,"distilbert"),Kgt.forEach(r),F7e=t(Phe," \u2014 "),l7=n(Phe,"A",{href:!0});var Ygt=s(l7);M7e=t(Ygt,"DistilBertConfig"),Ygt.forEach(r),E7e=t(Phe," (DistilBERT model)"),Phe.forEach(r),C7e=i(T),rf=n(T,"LI",{});var $he=s(rf);AO=n($he,"STRONG",{});var Zgt=s(AO);y7e=t(Zgt,"dpr"),Zgt.forEach(r),w7e=t($he," \u2014 "),i7=n($he,"A",{href:!0});var eht=s(i7);A7e=t(eht,"DPRConfig"),eht.forEach(r),x7e=t($he," (DPR model)"),$he.forEach(r),L7e=i(T),af=n(T,"LI",{});var Ihe=s(af);xO=n(Ihe,"STRONG",{});var oht=s(xO);B7e=t(oht,"electra"),oht.forEach(r),k7e=t(Ihe," \u2014 "),d7=n(Ihe,"A",{href:!0});var tht=s(d7);R7e=t(tht,"ElectraConfig"),tht.forEach(r),S7e=t(Ihe," (ELECTRA model)"),Ihe.forEach(r),P7e=i(T),nf=n(T,"LI",{});var jhe=s(nf);LO=n(jhe,"STRONG",{});var rht=s(LO);$7e=t(rht,"encoder-decoder"),rht.forEach(r),I7e=t(jhe," \u2014 "),m7=n(jhe,"A",{href:!0});var aht=s(m7);j7e=t(aht,"EncoderDecoderConfig"),aht.forEach(r),N7e=t(jhe," (Encoder decoder model)"),jhe.forEach(r),D7e=i(T),sf=n(T,"LI",{});var Nhe=s(sf);BO=n(Nhe,"STRONG",{});var nht=s(BO);G7e=t(nht,"flaubert"),nht.forEach(r),O7e=t(Nhe," \u2014 "),f7=n(Nhe,"A",{href:!0});var sht=s(f7);q7e=t(sht,"FlaubertConfig"),sht.forEach(r),z7e=t(Nhe," (FlauBERT model)"),Nhe.forEach(r),X7e=i(T),lf=n(T,"LI",{});var Dhe=s(lf);kO=n(Dhe,"STRONG",{});var lht=s(kO);W7e=t(lht,"fnet"),lht.forEach(r),V7e=t(Dhe," \u2014 "),c7=n(Dhe,"A",{href:!0});var iht=s(c7);Q7e=t(iht,"FNetConfig"),iht.forEach(r),H7e=t(Dhe," (FNet model)"),Dhe.forEach(r),U7e=i(T),df=n(T,"LI",{});var Ghe=s(df);RO=n(Ghe,"STRONG",{});var dht=s(RO);J7e=t(dht,"fsmt"),dht.forEach(r),K7e=t(Ghe," \u2014 "),g7=n(Ghe,"A",{href:!0});var mht=s(g7);Y7e=t(mht,"FSMTConfig"),mht.forEach(r),Z7e=t(Ghe," (FairSeq Machine-Translation model)"),Ghe.forEach(r),exe=i(T),mf=n(T,"LI",{});var Ohe=s(mf);SO=n(Ohe,"STRONG",{});var fht=s(SO);oxe=t(fht,"funnel"),fht.forEach(r),txe=t(Ohe," \u2014 "),h7=n(Ohe,"A",{href:!0});var cht=s(h7);rxe=t(cht,"FunnelConfig"),cht.forEach(r),axe=t(Ohe," (Funnel Transformer model)"),Ohe.forEach(r),nxe=i(T),ff=n(T,"LI",{});var qhe=s(ff);PO=n(qhe,"STRONG",{});var ght=s(PO);sxe=t(ght,"gpt2"),ght.forEach(r),lxe=t(qhe," \u2014 "),u7=n(qhe,"A",{href:!0});var hht=s(u7);ixe=t(hht,"GPT2Config"),hht.forEach(r),dxe=t(qhe," (OpenAI GPT-2 model)"),qhe.forEach(r),mxe=i(T),cf=n(T,"LI",{});var zhe=s(cf);$O=n(zhe,"STRONG",{});var uht=s($O);fxe=t(uht,"gpt_neo"),uht.forEach(r),cxe=t(zhe," \u2014 "),p7=n(zhe,"A",{href:!0});var pht=s(p7);gxe=t(pht,"GPTNeoConfig"),pht.forEach(r),hxe=t(zhe," (GPT Neo model)"),zhe.forEach(r),uxe=i(T),gf=n(T,"LI",{});var Xhe=s(gf);IO=n(Xhe,"STRONG",{});var _ht=s(IO);pxe=t(_ht,"gptj"),_ht.forEach(r),_xe=t(Xhe," \u2014 "),_7=n(Xhe,"A",{href:!0});var vht=s(_7);vxe=t(vht,"GPTJConfig"),vht.forEach(r),bxe=t(Xhe," (GPT-J model)"),Xhe.forEach(r),Txe=i(T),hf=n(T,"LI",{});var Whe=s(hf);jO=n(Whe,"STRONG",{});var bht=s(jO);Fxe=t(bht,"hubert"),bht.forEach(r),Mxe=t(Whe," \u2014 "),v7=n(Whe,"A",{href:!0});var Tht=s(v7);Exe=t(Tht,"HubertConfig"),Tht.forEach(r),Cxe=t(Whe," (Hubert model)"),Whe.forEach(r),yxe=i(T),uf=n(T,"LI",{});var Vhe=s(uf);NO=n(Vhe,"STRONG",{});var Fht=s(NO);wxe=t(Fht,"ibert"),Fht.forEach(r),Axe=t(Vhe," \u2014 "),b7=n(Vhe,"A",{href:!0});var Mht=s(b7);xxe=t(Mht,"IBertConfig"),Mht.forEach(r),Lxe=t(Vhe," (I-BERT model)"),Vhe.forEach(r),Bxe=i(T),pf=n(T,"LI",{});var Qhe=s(pf);DO=n(Qhe,"STRONG",{});var Eht=s(DO);kxe=t(Eht,"imagegpt"),Eht.forEach(r),Rxe=t(Qhe," \u2014 "),T7=n(Qhe,"A",{href:!0});var Cht=s(T7);Sxe=t(Cht,"ImageGPTConfig"),Cht.forEach(r),Pxe=t(Qhe," (ImageGPT model)"),Qhe.forEach(r),$xe=i(T),_f=n(T,"LI",{});var Hhe=s(_f);GO=n(Hhe,"STRONG",{});var yht=s(GO);Ixe=t(yht,"layoutlm"),yht.forEach(r),jxe=t(Hhe," \u2014 "),F7=n(Hhe,"A",{href:!0});var wht=s(F7);Nxe=t(wht,"LayoutLMConfig"),wht.forEach(r),Dxe=t(Hhe," (LayoutLM model)"),Hhe.forEach(r),Gxe=i(T),vf=n(T,"LI",{});var Uhe=s(vf);OO=n(Uhe,"STRONG",{});var Aht=s(OO);Oxe=t(Aht,"layoutlmv2"),Aht.forEach(r),qxe=t(Uhe," \u2014 "),M7=n(Uhe,"A",{href:!0});var xht=s(M7);zxe=t(xht,"LayoutLMv2Config"),xht.forEach(r),Xxe=t(Uhe," (LayoutLMv2 model)"),Uhe.forEach(r),Wxe=i(T),bf=n(T,"LI",{});var Jhe=s(bf);qO=n(Jhe,"STRONG",{});var Lht=s(qO);Vxe=t(Lht,"led"),Lht.forEach(r),Qxe=t(Jhe," \u2014 "),E7=n(Jhe,"A",{href:!0});var Bht=s(E7);Hxe=t(Bht,"LEDConfig"),Bht.forEach(r),Uxe=t(Jhe," (LED model)"),Jhe.forEach(r),Jxe=i(T),Tf=n(T,"LI",{});var Khe=s(Tf);zO=n(Khe,"STRONG",{});var kht=s(zO);Kxe=t(kht,"longformer"),kht.forEach(r),Yxe=t(Khe," \u2014 "),C7=n(Khe,"A",{href:!0});var Rht=s(C7);Zxe=t(Rht,"LongformerConfig"),Rht.forEach(r),e6e=t(Khe," (Longformer model)"),Khe.forEach(r),o6e=i(T),Ff=n(T,"LI",{});var Yhe=s(Ff);XO=n(Yhe,"STRONG",{});var Sht=s(XO);t6e=t(Sht,"luke"),Sht.forEach(r),r6e=t(Yhe," \u2014 "),y7=n(Yhe,"A",{href:!0});var Pht=s(y7);a6e=t(Pht,"LukeConfig"),Pht.forEach(r),n6e=t(Yhe," (LUKE model)"),Yhe.forEach(r),s6e=i(T),Mf=n(T,"LI",{});var Zhe=s(Mf);WO=n(Zhe,"STRONG",{});var $ht=s(WO);l6e=t($ht,"lxmert"),$ht.forEach(r),i6e=t(Zhe," \u2014 "),w7=n(Zhe,"A",{href:!0});var Iht=s(w7);d6e=t(Iht,"LxmertConfig"),Iht.forEach(r),m6e=t(Zhe," (LXMERT model)"),Zhe.forEach(r),f6e=i(T),Ef=n(T,"LI",{});var eue=s(Ef);VO=n(eue,"STRONG",{});var jht=s(VO);c6e=t(jht,"m2m_100"),jht.forEach(r),g6e=t(eue," \u2014 "),A7=n(eue,"A",{href:!0});var Nht=s(A7);h6e=t(Nht,"M2M100Config"),Nht.forEach(r),u6e=t(eue," (M2M100 model)"),eue.forEach(r),p6e=i(T),Cf=n(T,"LI",{});var oue=s(Cf);QO=n(oue,"STRONG",{});var Dht=s(QO);_6e=t(Dht,"marian"),Dht.forEach(r),v6e=t(oue," \u2014 "),x7=n(oue,"A",{href:!0});var Ght=s(x7);b6e=t(Ght,"MarianConfig"),Ght.forEach(r),T6e=t(oue," (Marian model)"),oue.forEach(r),F6e=i(T),yf=n(T,"LI",{});var tue=s(yf);HO=n(tue,"STRONG",{});var Oht=s(HO);M6e=t(Oht,"mbart"),Oht.forEach(r),E6e=t(tue," \u2014 "),L7=n(tue,"A",{href:!0});var qht=s(L7);C6e=t(qht,"MBartConfig"),qht.forEach(r),y6e=t(tue," (mBART model)"),tue.forEach(r),w6e=i(T),wf=n(T,"LI",{});var rue=s(wf);UO=n(rue,"STRONG",{});var zht=s(UO);A6e=t(zht,"megatron-bert"),zht.forEach(r),x6e=t(rue," \u2014 "),B7=n(rue,"A",{href:!0});var Xht=s(B7);L6e=t(Xht,"MegatronBertConfig"),Xht.forEach(r),B6e=t(rue," (MegatronBert model)"),rue.forEach(r),k6e=i(T),Af=n(T,"LI",{});var aue=s(Af);JO=n(aue,"STRONG",{});var Wht=s(JO);R6e=t(Wht,"mobilebert"),Wht.forEach(r),S6e=t(aue," \u2014 "),k7=n(aue,"A",{href:!0});var Vht=s(k7);P6e=t(Vht,"MobileBertConfig"),Vht.forEach(r),$6e=t(aue," (MobileBERT model)"),aue.forEach(r),I6e=i(T),xf=n(T,"LI",{});var nue=s(xf);KO=n(nue,"STRONG",{});var Qht=s(KO);j6e=t(Qht,"mpnet"),Qht.forEach(r),N6e=t(nue," \u2014 "),R7=n(nue,"A",{href:!0});var Hht=s(R7);D6e=t(Hht,"MPNetConfig"),Hht.forEach(r),G6e=t(nue," (MPNet model)"),nue.forEach(r),O6e=i(T),Lf=n(T,"LI",{});var sue=s(Lf);YO=n(sue,"STRONG",{});var Uht=s(YO);q6e=t(Uht,"mt5"),Uht.forEach(r),z6e=t(sue," \u2014 "),S7=n(sue,"A",{href:!0});var Jht=s(S7);X6e=t(Jht,"MT5Config"),Jht.forEach(r),W6e=t(sue," (mT5 model)"),sue.forEach(r),V6e=i(T),Bf=n(T,"LI",{});var lue=s(Bf);ZO=n(lue,"STRONG",{});var Kht=s(ZO);Q6e=t(Kht,"openai-gpt"),Kht.forEach(r),H6e=t(lue," \u2014 "),P7=n(lue,"A",{href:!0});var Yht=s(P7);U6e=t(Yht,"OpenAIGPTConfig"),Yht.forEach(r),J6e=t(lue," (OpenAI GPT model)"),lue.forEach(r),K6e=i(T),kf=n(T,"LI",{});var iue=s(kf);eq=n(iue,"STRONG",{});var Zht=s(eq);Y6e=t(Zht,"pegasus"),Zht.forEach(r),Z6e=t(iue," \u2014 "),$7=n(iue,"A",{href:!0});var eut=s($7);e8e=t(eut,"PegasusConfig"),eut.forEach(r),o8e=t(iue," (Pegasus model)"),iue.forEach(r),t8e=i(T),Rf=n(T,"LI",{});var due=s(Rf);oq=n(due,"STRONG",{});var out=s(oq);r8e=t(out,"perceiver"),out.forEach(r),a8e=t(due," \u2014 "),I7=n(due,"A",{href:!0});var tut=s(I7);n8e=t(tut,"PerceiverConfig"),tut.forEach(r),s8e=t(due," (Perceiver model)"),due.forEach(r),l8e=i(T),Sf=n(T,"LI",{});var mue=s(Sf);tq=n(mue,"STRONG",{});var rut=s(tq);i8e=t(rut,"prophetnet"),rut.forEach(r),d8e=t(mue," \u2014 "),j7=n(mue,"A",{href:!0});var aut=s(j7);m8e=t(aut,"ProphetNetConfig"),aut.forEach(r),f8e=t(mue," (ProphetNet model)"),mue.forEach(r),c8e=i(T),Pf=n(T,"LI",{});var fue=s(Pf);rq=n(fue,"STRONG",{});var nut=s(rq);g8e=t(nut,"qdqbert"),nut.forEach(r),h8e=t(fue," \u2014 "),N7=n(fue,"A",{href:!0});var sut=s(N7);u8e=t(sut,"QDQBertConfig"),sut.forEach(r),p8e=t(fue," (QDQBert model)"),fue.forEach(r),_8e=i(T),$f=n(T,"LI",{});var cue=s($f);aq=n(cue,"STRONG",{});var lut=s(aq);v8e=t(lut,"rag"),lut.forEach(r),b8e=t(cue," \u2014 "),D7=n(cue,"A",{href:!0});var iut=s(D7);T8e=t(iut,"RagConfig"),iut.forEach(r),F8e=t(cue," (RAG model)"),cue.forEach(r),M8e=i(T),If=n(T,"LI",{});var gue=s(If);nq=n(gue,"STRONG",{});var dut=s(nq);E8e=t(dut,"reformer"),dut.forEach(r),C8e=t(gue," \u2014 "),G7=n(gue,"A",{href:!0});var mut=s(G7);y8e=t(mut,"ReformerConfig"),mut.forEach(r),w8e=t(gue," (Reformer model)"),gue.forEach(r),A8e=i(T),jf=n(T,"LI",{});var hue=s(jf);sq=n(hue,"STRONG",{});var fut=s(sq);x8e=t(fut,"rembert"),fut.forEach(r),L8e=t(hue," \u2014 "),O7=n(hue,"A",{href:!0});var cut=s(O7);B8e=t(cut,"RemBertConfig"),cut.forEach(r),k8e=t(hue," (RemBERT model)"),hue.forEach(r),R8e=i(T),Nf=n(T,"LI",{});var uue=s(Nf);lq=n(uue,"STRONG",{});var gut=s(lq);S8e=t(gut,"retribert"),gut.forEach(r),P8e=t(uue," \u2014 "),q7=n(uue,"A",{href:!0});var hut=s(q7);$8e=t(hut,"RetriBertConfig"),hut.forEach(r),I8e=t(uue," (RetriBERT model)"),uue.forEach(r),j8e=i(T),Df=n(T,"LI",{});var pue=s(Df);iq=n(pue,"STRONG",{});var uut=s(iq);N8e=t(uut,"roberta"),uut.forEach(r),D8e=t(pue," \u2014 "),z7=n(pue,"A",{href:!0});var put=s(z7);G8e=t(put,"RobertaConfig"),put.forEach(r),O8e=t(pue," (RoBERTa model)"),pue.forEach(r),q8e=i(T),Gf=n(T,"LI",{});var _ue=s(Gf);dq=n(_ue,"STRONG",{});var _ut=s(dq);z8e=t(_ut,"roformer"),_ut.forEach(r),X8e=t(_ue," \u2014 "),X7=n(_ue,"A",{href:!0});var vut=s(X7);W8e=t(vut,"RoFormerConfig"),vut.forEach(r),V8e=t(_ue," (RoFormer model)"),_ue.forEach(r),Q8e=i(T),Of=n(T,"LI",{});var vue=s(Of);mq=n(vue,"STRONG",{});var but=s(mq);H8e=t(but,"segformer"),but.forEach(r),U8e=t(vue," \u2014 "),W7=n(vue,"A",{href:!0});var Tut=s(W7);J8e=t(Tut,"SegformerConfig"),Tut.forEach(r),K8e=t(vue," (SegFormer model)"),vue.forEach(r),Y8e=i(T),qf=n(T,"LI",{});var bue=s(qf);fq=n(bue,"STRONG",{});var Fut=s(fq);Z8e=t(Fut,"sew"),Fut.forEach(r),eLe=t(bue," \u2014 "),V7=n(bue,"A",{href:!0});var Mut=s(V7);oLe=t(Mut,"SEWConfig"),Mut.forEach(r),tLe=t(bue," (SEW model)"),bue.forEach(r),rLe=i(T),zf=n(T,"LI",{});var Tue=s(zf);cq=n(Tue,"STRONG",{});var Eut=s(cq);aLe=t(Eut,"sew-d"),Eut.forEach(r),nLe=t(Tue," \u2014 "),Q7=n(Tue,"A",{href:!0});var Cut=s(Q7);sLe=t(Cut,"SEWDConfig"),Cut.forEach(r),lLe=t(Tue," (SEW-D model)"),Tue.forEach(r),iLe=i(T),Xf=n(T,"LI",{});var Fue=s(Xf);gq=n(Fue,"STRONG",{});var yut=s(gq);dLe=t(yut,"speech-encoder-decoder"),yut.forEach(r),mLe=t(Fue," \u2014 "),H7=n(Fue,"A",{href:!0});var wut=s(H7);fLe=t(wut,"SpeechEncoderDecoderConfig"),wut.forEach(r),cLe=t(Fue," (Speech Encoder decoder model)"),Fue.forEach(r),gLe=i(T),Wf=n(T,"LI",{});var Mue=s(Wf);hq=n(Mue,"STRONG",{});var Aut=s(hq);hLe=t(Aut,"speech_to_text"),Aut.forEach(r),uLe=t(Mue," \u2014 "),U7=n(Mue,"A",{href:!0});var xut=s(U7);pLe=t(xut,"Speech2TextConfig"),xut.forEach(r),_Le=t(Mue," (Speech2Text model)"),Mue.forEach(r),vLe=i(T),Vf=n(T,"LI",{});var Eue=s(Vf);uq=n(Eue,"STRONG",{});var Lut=s(uq);bLe=t(Lut,"speech_to_text_2"),Lut.forEach(r),TLe=t(Eue," \u2014 "),J7=n(Eue,"A",{href:!0});var But=s(J7);FLe=t(But,"Speech2Text2Config"),But.forEach(r),MLe=t(Eue," (Speech2Text2 model)"),Eue.forEach(r),ELe=i(T),Qf=n(T,"LI",{});var Cue=s(Qf);pq=n(Cue,"STRONG",{});var kut=s(pq);CLe=t(kut,"splinter"),kut.forEach(r),yLe=t(Cue," \u2014 "),K7=n(Cue,"A",{href:!0});var Rut=s(K7);wLe=t(Rut,"SplinterConfig"),Rut.forEach(r),ALe=t(Cue," (Splinter model)"),Cue.forEach(r),xLe=i(T),Hf=n(T,"LI",{});var yue=s(Hf);_q=n(yue,"STRONG",{});var Sut=s(_q);LLe=t(Sut,"squeezebert"),Sut.forEach(r),BLe=t(yue," \u2014 "),Y7=n(yue,"A",{href:!0});var Put=s(Y7);kLe=t(Put,"SqueezeBertConfig"),Put.forEach(r),RLe=t(yue," (SqueezeBERT model)"),yue.forEach(r),SLe=i(T),Uf=n(T,"LI",{});var wue=s(Uf);vq=n(wue,"STRONG",{});var $ut=s(vq);PLe=t($ut,"t5"),$ut.forEach(r),$Le=t(wue," \u2014 "),Z7=n(wue,"A",{href:!0});var Iut=s(Z7);ILe=t(Iut,"T5Config"),Iut.forEach(r),jLe=t(wue," (T5 model)"),wue.forEach(r),NLe=i(T),Jf=n(T,"LI",{});var Aue=s(Jf);bq=n(Aue,"STRONG",{});var jut=s(bq);DLe=t(jut,"tapas"),jut.forEach(r),GLe=t(Aue," \u2014 "),ex=n(Aue,"A",{href:!0});var Nut=s(ex);OLe=t(Nut,"TapasConfig"),Nut.forEach(r),qLe=t(Aue," (TAPAS model)"),Aue.forEach(r),zLe=i(T),Kf=n(T,"LI",{});var xue=s(Kf);Tq=n(xue,"STRONG",{});var Dut=s(Tq);XLe=t(Dut,"transfo-xl"),Dut.forEach(r),WLe=t(xue," \u2014 "),ox=n(xue,"A",{href:!0});var Gut=s(ox);VLe=t(Gut,"TransfoXLConfig"),Gut.forEach(r),QLe=t(xue," (Transformer-XL model)"),xue.forEach(r),HLe=i(T),Yf=n(T,"LI",{});var Lue=s(Yf);Fq=n(Lue,"STRONG",{});var Out=s(Fq);ULe=t(Out,"trocr"),Out.forEach(r),JLe=t(Lue," \u2014 "),tx=n(Lue,"A",{href:!0});var qut=s(tx);KLe=t(qut,"TrOCRConfig"),qut.forEach(r),YLe=t(Lue," (TrOCR model)"),Lue.forEach(r),ZLe=i(T),Zf=n(T,"LI",{});var Bue=s(Zf);Mq=n(Bue,"STRONG",{});var zut=s(Mq);eBe=t(zut,"unispeech"),zut.forEach(r),oBe=t(Bue," \u2014 "),rx=n(Bue,"A",{href:!0});var Xut=s(rx);tBe=t(Xut,"UniSpeechConfig"),Xut.forEach(r),rBe=t(Bue," (UniSpeech model)"),Bue.forEach(r),aBe=i(T),ec=n(T,"LI",{});var kue=s(ec);Eq=n(kue,"STRONG",{});var Wut=s(Eq);nBe=t(Wut,"unispeech-sat"),Wut.forEach(r),sBe=t(kue," \u2014 "),ax=n(kue,"A",{href:!0});var Vut=s(ax);lBe=t(Vut,"UniSpeechSatConfig"),Vut.forEach(r),iBe=t(kue," (UniSpeechSat model)"),kue.forEach(r),dBe=i(T),oc=n(T,"LI",{});var Rue=s(oc);Cq=n(Rue,"STRONG",{});var Qut=s(Cq);mBe=t(Qut,"vision-encoder-decoder"),Qut.forEach(r),fBe=t(Rue," \u2014 "),nx=n(Rue,"A",{href:!0});var Hut=s(nx);cBe=t(Hut,"VisionEncoderDecoderConfig"),Hut.forEach(r),gBe=t(Rue," (Vision Encoder decoder model)"),Rue.forEach(r),hBe=i(T),tc=n(T,"LI",{});var Sue=s(tc);yq=n(Sue,"STRONG",{});var Uut=s(yq);uBe=t(Uut,"vision-text-dual-encoder"),Uut.forEach(r),pBe=t(Sue," \u2014 "),sx=n(Sue,"A",{href:!0});var Jut=s(sx);_Be=t(Jut,"VisionTextDualEncoderConfig"),Jut.forEach(r),vBe=t(Sue," (VisionTextDualEncoder model)"),Sue.forEach(r),bBe=i(T),rc=n(T,"LI",{});var Pue=s(rc);wq=n(Pue,"STRONG",{});var Kut=s(wq);TBe=t(Kut,"visual_bert"),Kut.forEach(r),FBe=t(Pue," \u2014 "),lx=n(Pue,"A",{href:!0});var Yut=s(lx);MBe=t(Yut,"VisualBertConfig"),Yut.forEach(r),EBe=t(Pue," (VisualBert model)"),Pue.forEach(r),CBe=i(T),ac=n(T,"LI",{});var $ue=s(ac);Aq=n($ue,"STRONG",{});var Zut=s(Aq);yBe=t(Zut,"vit"),Zut.forEach(r),wBe=t($ue," \u2014 "),ix=n($ue,"A",{href:!0});var ept=s(ix);ABe=t(ept,"ViTConfig"),ept.forEach(r),xBe=t($ue," (ViT model)"),$ue.forEach(r),LBe=i(T),nc=n(T,"LI",{});var Iue=s(nc);xq=n(Iue,"STRONG",{});var opt=s(xq);BBe=t(opt,"wav2vec2"),opt.forEach(r),kBe=t(Iue," \u2014 "),dx=n(Iue,"A",{href:!0});var tpt=s(dx);RBe=t(tpt,"Wav2Vec2Config"),tpt.forEach(r),SBe=t(Iue," (Wav2Vec2 model)"),Iue.forEach(r),PBe=i(T),sc=n(T,"LI",{});var jue=s(sc);Lq=n(jue,"STRONG",{});var rpt=s(Lq);$Be=t(rpt,"wavlm"),rpt.forEach(r),IBe=t(jue," \u2014 "),mx=n(jue,"A",{href:!0});var apt=s(mx);jBe=t(apt,"WavLMConfig"),apt.forEach(r),NBe=t(jue," (WavLM model)"),jue.forEach(r),DBe=i(T),lc=n(T,"LI",{});var Nue=s(lc);Bq=n(Nue,"STRONG",{});var npt=s(Bq);GBe=t(npt,"xlm"),npt.forEach(r),OBe=t(Nue," \u2014 "),fx=n(Nue,"A",{href:!0});var spt=s(fx);qBe=t(spt,"XLMConfig"),spt.forEach(r),zBe=t(Nue," (XLM model)"),Nue.forEach(r),XBe=i(T),ic=n(T,"LI",{});var Due=s(ic);kq=n(Due,"STRONG",{});var lpt=s(kq);WBe=t(lpt,"xlm-prophetnet"),lpt.forEach(r),VBe=t(Due," \u2014 "),cx=n(Due,"A",{href:!0});var ipt=s(cx);QBe=t(ipt,"XLMProphetNetConfig"),ipt.forEach(r),HBe=t(Due," (XLMProphetNet model)"),Due.forEach(r),UBe=i(T),dc=n(T,"LI",{});var Gue=s(dc);Rq=n(Gue,"STRONG",{});var dpt=s(Rq);JBe=t(dpt,"xlm-roberta"),dpt.forEach(r),KBe=t(Gue," \u2014 "),gx=n(Gue,"A",{href:!0});var mpt=s(gx);YBe=t(mpt,"XLMRobertaConfig"),mpt.forEach(r),ZBe=t(Gue," (XLM-RoBERTa model)"),Gue.forEach(r),e9e=i(T),mc=n(T,"LI",{});var Oue=s(mc);Sq=n(Oue,"STRONG",{});var fpt=s(Sq);o9e=t(fpt,"xlnet"),fpt.forEach(r),t9e=t(Oue," \u2014 "),hx=n(Oue,"A",{href:!0});var cpt=s(hx);r9e=t(cpt,"XLNetConfig"),cpt.forEach(r),a9e=t(Oue," (XLNet model)"),Oue.forEach(r),T.forEach(r),n9e=i(Wr),Pq=n(Wr,"P",{});var gpt=s(Pq);s9e=t(gpt,"Examples:"),gpt.forEach(r),l9e=i(Wr),c(zF.$$.fragment,Wr),Wr.forEach(r),i9e=i(ms),fc=n(ms,"DIV",{class:!0});var v3e=s(fc);c(XF.$$.fragment,v3e),d9e=i(v3e),$q=n(v3e,"P",{});var hpt=s($q);m9e=t(hpt,"Register a new configuration for this class."),hpt.forEach(r),v3e.forEach(r),ms.forEach(r),wEe=i(d),ti=n(d,"H2",{class:!0});var b3e=s(ti);cc=n(b3e,"A",{id:!0,class:!0,href:!0});var upt=s(cc);Iq=n(upt,"SPAN",{});var ppt=s(Iq);c(WF.$$.fragment,ppt),ppt.forEach(r),upt.forEach(r),f9e=i(b3e),jq=n(b3e,"SPAN",{});var _pt=s(jq);c9e=t(_pt,"AutoTokenizer"),_pt.forEach(r),b3e.forEach(r),AEe=i(d),So=n(d,"DIV",{class:!0});var fs=s(So);c(VF.$$.fragment,fs),g9e=i(fs),QF=n(fs,"P",{});var T3e=s(QF);h9e=t(T3e,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ux=n(T3e,"A",{href:!0});var vpt=s(ux);u9e=t(vpt,"AutoTokenizer.from_pretrained()"),vpt.forEach(r),p9e=t(T3e," class method."),T3e.forEach(r),_9e=i(fs),HF=n(fs,"P",{});var F3e=s(HF);v9e=t(F3e,"This class cannot be instantiated directly using "),Nq=n(F3e,"CODE",{});var bpt=s(Nq);b9e=t(bpt,"__init__()"),bpt.forEach(r),T9e=t(F3e," (throws an error)."),F3e.forEach(r),F9e=i(fs),to=n(fs,"DIV",{class:!0});var Vr=s(to);c(UF.$$.fragment,Vr),M9e=i(Vr),Dq=n(Vr,"P",{});var Tpt=s(Dq);E9e=t(Tpt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Tpt.forEach(r),C9e=i(Vr),Fa=n(Vr,"P",{});var DT=s(Fa);y9e=t(DT,"The tokenizer class to instantiate is selected based on the "),Gq=n(DT,"EM",{});var Fpt=s(Gq);w9e=t(Fpt,"model_type"),Fpt.forEach(r),A9e=t(DT,` property of the config object
(either passed as an argument or loaded from `),Oq=n(DT,"EM",{});var Mpt=s(Oq);x9e=t(Mpt,"pretrained_model_name_or_path"),Mpt.forEach(r),L9e=t(DT,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),qq=n(DT,"EM",{});var Ept=s(qq);B9e=t(Ept,"pretrained_model_name_or_path"),Ept.forEach(r),k9e=t(DT,":"),DT.forEach(r),R9e=i(Vr),E=n(Vr,"UL",{});var y=s(E);vn=n(y,"LI",{});var Xw=s(vn);zq=n(Xw,"STRONG",{});var Cpt=s(zq);S9e=t(Cpt,"albert"),Cpt.forEach(r),P9e=t(Xw," \u2014 "),px=n(Xw,"A",{href:!0});var ypt=s(px);$9e=t(ypt,"AlbertTokenizer"),ypt.forEach(r),I9e=t(Xw," or "),_x=n(Xw,"A",{href:!0});var wpt=s(_x);j9e=t(wpt,"AlbertTokenizerFast"),wpt.forEach(r),N9e=t(Xw," (ALBERT model)"),Xw.forEach(r),D9e=i(y),bn=n(y,"LI",{});var Ww=s(bn);Xq=n(Ww,"STRONG",{});var Apt=s(Xq);G9e=t(Apt,"bart"),Apt.forEach(r),O9e=t(Ww," \u2014 "),vx=n(Ww,"A",{href:!0});var xpt=s(vx);q9e=t(xpt,"BartTokenizer"),xpt.forEach(r),z9e=t(Ww," or "),bx=n(Ww,"A",{href:!0});var Lpt=s(bx);X9e=t(Lpt,"BartTokenizerFast"),Lpt.forEach(r),W9e=t(Ww," (BART model)"),Ww.forEach(r),V9e=i(y),Tn=n(y,"LI",{});var Vw=s(Tn);Wq=n(Vw,"STRONG",{});var Bpt=s(Wq);Q9e=t(Bpt,"barthez"),Bpt.forEach(r),H9e=t(Vw," \u2014 "),Tx=n(Vw,"A",{href:!0});var kpt=s(Tx);U9e=t(kpt,"BarthezTokenizer"),kpt.forEach(r),J9e=t(Vw," or "),Fx=n(Vw,"A",{href:!0});var Rpt=s(Fx);K9e=t(Rpt,"BarthezTokenizerFast"),Rpt.forEach(r),Y9e=t(Vw," (BARThez model)"),Vw.forEach(r),Z9e=i(y),gc=n(y,"LI",{});var que=s(gc);Vq=n(que,"STRONG",{});var Spt=s(Vq);eke=t(Spt,"bartpho"),Spt.forEach(r),oke=t(que," \u2014 "),Mx=n(que,"A",{href:!0});var Ppt=s(Mx);tke=t(Ppt,"BartphoTokenizer"),Ppt.forEach(r),rke=t(que," (BARTpho model)"),que.forEach(r),ake=i(y),Fn=n(y,"LI",{});var Qw=s(Fn);Qq=n(Qw,"STRONG",{});var $pt=s(Qq);nke=t($pt,"bert"),$pt.forEach(r),ske=t(Qw," \u2014 "),Ex=n(Qw,"A",{href:!0});var Ipt=s(Ex);lke=t(Ipt,"BertTokenizer"),Ipt.forEach(r),ike=t(Qw," or "),Cx=n(Qw,"A",{href:!0});var jpt=s(Cx);dke=t(jpt,"BertTokenizerFast"),jpt.forEach(r),mke=t(Qw," (BERT model)"),Qw.forEach(r),fke=i(y),hc=n(y,"LI",{});var zue=s(hc);Hq=n(zue,"STRONG",{});var Npt=s(Hq);cke=t(Npt,"bert-generation"),Npt.forEach(r),gke=t(zue," \u2014 "),yx=n(zue,"A",{href:!0});var Dpt=s(yx);hke=t(Dpt,"BertGenerationTokenizer"),Dpt.forEach(r),uke=t(zue," (Bert Generation model)"),zue.forEach(r),pke=i(y),uc=n(y,"LI",{});var Xue=s(uc);Uq=n(Xue,"STRONG",{});var Gpt=s(Uq);_ke=t(Gpt,"bert-japanese"),Gpt.forEach(r),vke=t(Xue," \u2014 "),wx=n(Xue,"A",{href:!0});var Opt=s(wx);bke=t(Opt,"BertJapaneseTokenizer"),Opt.forEach(r),Tke=t(Xue," (BertJapanese model)"),Xue.forEach(r),Fke=i(y),pc=n(y,"LI",{});var Wue=s(pc);Jq=n(Wue,"STRONG",{});var qpt=s(Jq);Mke=t(qpt,"bertweet"),qpt.forEach(r),Eke=t(Wue," \u2014 "),Ax=n(Wue,"A",{href:!0});var zpt=s(Ax);Cke=t(zpt,"BertweetTokenizer"),zpt.forEach(r),yke=t(Wue," (Bertweet model)"),Wue.forEach(r),wke=i(y),Mn=n(y,"LI",{});var Hw=s(Mn);Kq=n(Hw,"STRONG",{});var Xpt=s(Kq);Ake=t(Xpt,"big_bird"),Xpt.forEach(r),xke=t(Hw," \u2014 "),xx=n(Hw,"A",{href:!0});var Wpt=s(xx);Lke=t(Wpt,"BigBirdTokenizer"),Wpt.forEach(r),Bke=t(Hw," or "),Lx=n(Hw,"A",{href:!0});var Vpt=s(Lx);kke=t(Vpt,"BigBirdTokenizerFast"),Vpt.forEach(r),Rke=t(Hw," (BigBird model)"),Hw.forEach(r),Ske=i(y),En=n(y,"LI",{});var Uw=s(En);Yq=n(Uw,"STRONG",{});var Qpt=s(Yq);Pke=t(Qpt,"bigbird_pegasus"),Qpt.forEach(r),$ke=t(Uw," \u2014 "),Bx=n(Uw,"A",{href:!0});var Hpt=s(Bx);Ike=t(Hpt,"PegasusTokenizer"),Hpt.forEach(r),jke=t(Uw," or "),kx=n(Uw,"A",{href:!0});var Upt=s(kx);Nke=t(Upt,"PegasusTokenizerFast"),Upt.forEach(r),Dke=t(Uw," (BigBirdPegasus model)"),Uw.forEach(r),Gke=i(y),Cn=n(y,"LI",{});var Jw=s(Cn);Zq=n(Jw,"STRONG",{});var Jpt=s(Zq);Oke=t(Jpt,"blenderbot"),Jpt.forEach(r),qke=t(Jw," \u2014 "),Rx=n(Jw,"A",{href:!0});var Kpt=s(Rx);zke=t(Kpt,"BlenderbotTokenizer"),Kpt.forEach(r),Xke=t(Jw," or "),Sx=n(Jw,"A",{href:!0});var Ypt=s(Sx);Wke=t(Ypt,"BlenderbotTokenizerFast"),Ypt.forEach(r),Vke=t(Jw," (Blenderbot model)"),Jw.forEach(r),Qke=i(y),_c=n(y,"LI",{});var Vue=s(_c);ez=n(Vue,"STRONG",{});var Zpt=s(ez);Hke=t(Zpt,"blenderbot-small"),Zpt.forEach(r),Uke=t(Vue," \u2014 "),Px=n(Vue,"A",{href:!0});var e_t=s(Px);Jke=t(e_t,"BlenderbotSmallTokenizer"),e_t.forEach(r),Kke=t(Vue," (BlenderbotSmall model)"),Vue.forEach(r),Yke=i(y),vc=n(y,"LI",{});var Que=s(vc);oz=n(Que,"STRONG",{});var o_t=s(oz);Zke=t(o_t,"byt5"),o_t.forEach(r),eRe=t(Que," \u2014 "),$x=n(Que,"A",{href:!0});var t_t=s($x);oRe=t(t_t,"ByT5Tokenizer"),t_t.forEach(r),tRe=t(Que," (ByT5 model)"),Que.forEach(r),rRe=i(y),yn=n(y,"LI",{});var Kw=s(yn);tz=n(Kw,"STRONG",{});var r_t=s(tz);aRe=t(r_t,"camembert"),r_t.forEach(r),nRe=t(Kw," \u2014 "),Ix=n(Kw,"A",{href:!0});var a_t=s(Ix);sRe=t(a_t,"CamembertTokenizer"),a_t.forEach(r),lRe=t(Kw," or "),jx=n(Kw,"A",{href:!0});var n_t=s(jx);iRe=t(n_t,"CamembertTokenizerFast"),n_t.forEach(r),dRe=t(Kw," (CamemBERT model)"),Kw.forEach(r),mRe=i(y),bc=n(y,"LI",{});var Hue=s(bc);rz=n(Hue,"STRONG",{});var s_t=s(rz);fRe=t(s_t,"canine"),s_t.forEach(r),cRe=t(Hue," \u2014 "),Nx=n(Hue,"A",{href:!0});var l_t=s(Nx);gRe=t(l_t,"CanineTokenizer"),l_t.forEach(r),hRe=t(Hue," (Canine model)"),Hue.forEach(r),uRe=i(y),wn=n(y,"LI",{});var Yw=s(wn);az=n(Yw,"STRONG",{});var i_t=s(az);pRe=t(i_t,"clip"),i_t.forEach(r),_Re=t(Yw," \u2014 "),Dx=n(Yw,"A",{href:!0});var d_t=s(Dx);vRe=t(d_t,"CLIPTokenizer"),d_t.forEach(r),bRe=t(Yw," or "),Gx=n(Yw,"A",{href:!0});var m_t=s(Gx);TRe=t(m_t,"CLIPTokenizerFast"),m_t.forEach(r),FRe=t(Yw," (CLIP model)"),Yw.forEach(r),MRe=i(y),An=n(y,"LI",{});var Zw=s(An);nz=n(Zw,"STRONG",{});var f_t=s(nz);ERe=t(f_t,"convbert"),f_t.forEach(r),CRe=t(Zw," \u2014 "),Ox=n(Zw,"A",{href:!0});var c_t=s(Ox);yRe=t(c_t,"ConvBertTokenizer"),c_t.forEach(r),wRe=t(Zw," or "),qx=n(Zw,"A",{href:!0});var g_t=s(qx);ARe=t(g_t,"ConvBertTokenizerFast"),g_t.forEach(r),xRe=t(Zw," (ConvBERT model)"),Zw.forEach(r),LRe=i(y),xn=n(y,"LI",{});var eA=s(xn);sz=n(eA,"STRONG",{});var h_t=s(sz);BRe=t(h_t,"cpm"),h_t.forEach(r),kRe=t(eA," \u2014 "),zx=n(eA,"A",{href:!0});var u_t=s(zx);RRe=t(u_t,"CpmTokenizer"),u_t.forEach(r),SRe=t(eA," or "),lz=n(eA,"CODE",{});var p_t=s(lz);PRe=t(p_t,"CpmTokenizerFast"),p_t.forEach(r),$Re=t(eA," (CPM model)"),eA.forEach(r),IRe=i(y),Tc=n(y,"LI",{});var Uue=s(Tc);iz=n(Uue,"STRONG",{});var __t=s(iz);jRe=t(__t,"ctrl"),__t.forEach(r),NRe=t(Uue," \u2014 "),Xx=n(Uue,"A",{href:!0});var v_t=s(Xx);DRe=t(v_t,"CTRLTokenizer"),v_t.forEach(r),GRe=t(Uue," (CTRL model)"),Uue.forEach(r),ORe=i(y),Ln=n(y,"LI",{});var oA=s(Ln);dz=n(oA,"STRONG",{});var b_t=s(dz);qRe=t(b_t,"deberta"),b_t.forEach(r),zRe=t(oA," \u2014 "),Wx=n(oA,"A",{href:!0});var T_t=s(Wx);XRe=t(T_t,"DebertaTokenizer"),T_t.forEach(r),WRe=t(oA," or "),Vx=n(oA,"A",{href:!0});var F_t=s(Vx);VRe=t(F_t,"DebertaTokenizerFast"),F_t.forEach(r),QRe=t(oA," (DeBERTa model)"),oA.forEach(r),HRe=i(y),Fc=n(y,"LI",{});var Jue=s(Fc);mz=n(Jue,"STRONG",{});var M_t=s(mz);URe=t(M_t,"deberta-v2"),M_t.forEach(r),JRe=t(Jue," \u2014 "),Qx=n(Jue,"A",{href:!0});var E_t=s(Qx);KRe=t(E_t,"DebertaV2Tokenizer"),E_t.forEach(r),YRe=t(Jue," (DeBERTa-v2 model)"),Jue.forEach(r),ZRe=i(y),Bn=n(y,"LI",{});var tA=s(Bn);fz=n(tA,"STRONG",{});var C_t=s(fz);eSe=t(C_t,"distilbert"),C_t.forEach(r),oSe=t(tA," \u2014 "),Hx=n(tA,"A",{href:!0});var y_t=s(Hx);tSe=t(y_t,"DistilBertTokenizer"),y_t.forEach(r),rSe=t(tA," or "),Ux=n(tA,"A",{href:!0});var w_t=s(Ux);aSe=t(w_t,"DistilBertTokenizerFast"),w_t.forEach(r),nSe=t(tA," (DistilBERT model)"),tA.forEach(r),sSe=i(y),kn=n(y,"LI",{});var rA=s(kn);cz=n(rA,"STRONG",{});var A_t=s(cz);lSe=t(A_t,"dpr"),A_t.forEach(r),iSe=t(rA," \u2014 "),Jx=n(rA,"A",{href:!0});var x_t=s(Jx);dSe=t(x_t,"DPRQuestionEncoderTokenizer"),x_t.forEach(r),mSe=t(rA," or "),Kx=n(rA,"A",{href:!0});var L_t=s(Kx);fSe=t(L_t,"DPRQuestionEncoderTokenizerFast"),L_t.forEach(r),cSe=t(rA," (DPR model)"),rA.forEach(r),gSe=i(y),Rn=n(y,"LI",{});var aA=s(Rn);gz=n(aA,"STRONG",{});var B_t=s(gz);hSe=t(B_t,"electra"),B_t.forEach(r),uSe=t(aA," \u2014 "),Yx=n(aA,"A",{href:!0});var k_t=s(Yx);pSe=t(k_t,"ElectraTokenizer"),k_t.forEach(r),_Se=t(aA," or "),Zx=n(aA,"A",{href:!0});var R_t=s(Zx);vSe=t(R_t,"ElectraTokenizerFast"),R_t.forEach(r),bSe=t(aA," (ELECTRA model)"),aA.forEach(r),TSe=i(y),Mc=n(y,"LI",{});var Kue=s(Mc);hz=n(Kue,"STRONG",{});var S_t=s(hz);FSe=t(S_t,"flaubert"),S_t.forEach(r),MSe=t(Kue," \u2014 "),e6=n(Kue,"A",{href:!0});var P_t=s(e6);ESe=t(P_t,"FlaubertTokenizer"),P_t.forEach(r),CSe=t(Kue," (FlauBERT model)"),Kue.forEach(r),ySe=i(y),Sn=n(y,"LI",{});var nA=s(Sn);uz=n(nA,"STRONG",{});var $_t=s(uz);wSe=t($_t,"fnet"),$_t.forEach(r),ASe=t(nA," \u2014 "),o6=n(nA,"A",{href:!0});var I_t=s(o6);xSe=t(I_t,"FNetTokenizer"),I_t.forEach(r),LSe=t(nA," or "),t6=n(nA,"A",{href:!0});var j_t=s(t6);BSe=t(j_t,"FNetTokenizerFast"),j_t.forEach(r),kSe=t(nA," (FNet model)"),nA.forEach(r),RSe=i(y),Ec=n(y,"LI",{});var Yue=s(Ec);pz=n(Yue,"STRONG",{});var N_t=s(pz);SSe=t(N_t,"fsmt"),N_t.forEach(r),PSe=t(Yue," \u2014 "),r6=n(Yue,"A",{href:!0});var D_t=s(r6);$Se=t(D_t,"FSMTTokenizer"),D_t.forEach(r),ISe=t(Yue," (FairSeq Machine-Translation model)"),Yue.forEach(r),jSe=i(y),Pn=n(y,"LI",{});var sA=s(Pn);_z=n(sA,"STRONG",{});var G_t=s(_z);NSe=t(G_t,"funnel"),G_t.forEach(r),DSe=t(sA," \u2014 "),a6=n(sA,"A",{href:!0});var O_t=s(a6);GSe=t(O_t,"FunnelTokenizer"),O_t.forEach(r),OSe=t(sA," or "),n6=n(sA,"A",{href:!0});var q_t=s(n6);qSe=t(q_t,"FunnelTokenizerFast"),q_t.forEach(r),zSe=t(sA," (Funnel Transformer model)"),sA.forEach(r),XSe=i(y),$n=n(y,"LI",{});var lA=s($n);vz=n(lA,"STRONG",{});var z_t=s(vz);WSe=t(z_t,"gpt2"),z_t.forEach(r),VSe=t(lA," \u2014 "),s6=n(lA,"A",{href:!0});var X_t=s(s6);QSe=t(X_t,"GPT2Tokenizer"),X_t.forEach(r),HSe=t(lA," or "),l6=n(lA,"A",{href:!0});var W_t=s(l6);USe=t(W_t,"GPT2TokenizerFast"),W_t.forEach(r),JSe=t(lA," (OpenAI GPT-2 model)"),lA.forEach(r),KSe=i(y),In=n(y,"LI",{});var iA=s(In);bz=n(iA,"STRONG",{});var V_t=s(bz);YSe=t(V_t,"gpt_neo"),V_t.forEach(r),ZSe=t(iA," \u2014 "),i6=n(iA,"A",{href:!0});var Q_t=s(i6);ePe=t(Q_t,"GPT2Tokenizer"),Q_t.forEach(r),oPe=t(iA," or "),d6=n(iA,"A",{href:!0});var H_t=s(d6);tPe=t(H_t,"GPT2TokenizerFast"),H_t.forEach(r),rPe=t(iA," (GPT Neo model)"),iA.forEach(r),aPe=i(y),Cc=n(y,"LI",{});var Zue=s(Cc);Tz=n(Zue,"STRONG",{});var U_t=s(Tz);nPe=t(U_t,"hubert"),U_t.forEach(r),sPe=t(Zue," \u2014 "),m6=n(Zue,"A",{href:!0});var J_t=s(m6);lPe=t(J_t,"Wav2Vec2CTCTokenizer"),J_t.forEach(r),iPe=t(Zue," (Hubert model)"),Zue.forEach(r),dPe=i(y),jn=n(y,"LI",{});var dA=s(jn);Fz=n(dA,"STRONG",{});var K_t=s(Fz);mPe=t(K_t,"ibert"),K_t.forEach(r),fPe=t(dA," \u2014 "),f6=n(dA,"A",{href:!0});var Y_t=s(f6);cPe=t(Y_t,"RobertaTokenizer"),Y_t.forEach(r),gPe=t(dA," or "),c6=n(dA,"A",{href:!0});var Z_t=s(c6);hPe=t(Z_t,"RobertaTokenizerFast"),Z_t.forEach(r),uPe=t(dA," (I-BERT model)"),dA.forEach(r),pPe=i(y),Nn=n(y,"LI",{});var mA=s(Nn);Mz=n(mA,"STRONG",{});var evt=s(Mz);_Pe=t(evt,"layoutlm"),evt.forEach(r),vPe=t(mA," \u2014 "),g6=n(mA,"A",{href:!0});var ovt=s(g6);bPe=t(ovt,"LayoutLMTokenizer"),ovt.forEach(r),TPe=t(mA," or "),h6=n(mA,"A",{href:!0});var tvt=s(h6);FPe=t(tvt,"LayoutLMTokenizerFast"),tvt.forEach(r),MPe=t(mA," (LayoutLM model)"),mA.forEach(r),EPe=i(y),Dn=n(y,"LI",{});var fA=s(Dn);Ez=n(fA,"STRONG",{});var rvt=s(Ez);CPe=t(rvt,"layoutlmv2"),rvt.forEach(r),yPe=t(fA," \u2014 "),u6=n(fA,"A",{href:!0});var avt=s(u6);wPe=t(avt,"LayoutLMv2Tokenizer"),avt.forEach(r),APe=t(fA," or "),p6=n(fA,"A",{href:!0});var nvt=s(p6);xPe=t(nvt,"LayoutLMv2TokenizerFast"),nvt.forEach(r),LPe=t(fA," (LayoutLMv2 model)"),fA.forEach(r),BPe=i(y),Gn=n(y,"LI",{});var cA=s(Gn);Cz=n(cA,"STRONG",{});var svt=s(Cz);kPe=t(svt,"led"),svt.forEach(r),RPe=t(cA," \u2014 "),_6=n(cA,"A",{href:!0});var lvt=s(_6);SPe=t(lvt,"LEDTokenizer"),lvt.forEach(r),PPe=t(cA," or "),v6=n(cA,"A",{href:!0});var ivt=s(v6);$Pe=t(ivt,"LEDTokenizerFast"),ivt.forEach(r),IPe=t(cA," (LED model)"),cA.forEach(r),jPe=i(y),On=n(y,"LI",{});var gA=s(On);yz=n(gA,"STRONG",{});var dvt=s(yz);NPe=t(dvt,"longformer"),dvt.forEach(r),DPe=t(gA," \u2014 "),b6=n(gA,"A",{href:!0});var mvt=s(b6);GPe=t(mvt,"LongformerTokenizer"),mvt.forEach(r),OPe=t(gA," or "),T6=n(gA,"A",{href:!0});var fvt=s(T6);qPe=t(fvt,"LongformerTokenizerFast"),fvt.forEach(r),zPe=t(gA," (Longformer model)"),gA.forEach(r),XPe=i(y),yc=n(y,"LI",{});var epe=s(yc);wz=n(epe,"STRONG",{});var cvt=s(wz);WPe=t(cvt,"luke"),cvt.forEach(r),VPe=t(epe," \u2014 "),F6=n(epe,"A",{href:!0});var gvt=s(F6);QPe=t(gvt,"LukeTokenizer"),gvt.forEach(r),HPe=t(epe," (LUKE model)"),epe.forEach(r),UPe=i(y),qn=n(y,"LI",{});var hA=s(qn);Az=n(hA,"STRONG",{});var hvt=s(Az);JPe=t(hvt,"lxmert"),hvt.forEach(r),KPe=t(hA," \u2014 "),M6=n(hA,"A",{href:!0});var uvt=s(M6);YPe=t(uvt,"LxmertTokenizer"),uvt.forEach(r),ZPe=t(hA," or "),E6=n(hA,"A",{href:!0});var pvt=s(E6);e$e=t(pvt,"LxmertTokenizerFast"),pvt.forEach(r),o$e=t(hA," (LXMERT model)"),hA.forEach(r),t$e=i(y),wc=n(y,"LI",{});var ope=s(wc);xz=n(ope,"STRONG",{});var _vt=s(xz);r$e=t(_vt,"m2m_100"),_vt.forEach(r),a$e=t(ope," \u2014 "),C6=n(ope,"A",{href:!0});var vvt=s(C6);n$e=t(vvt,"M2M100Tokenizer"),vvt.forEach(r),s$e=t(ope," (M2M100 model)"),ope.forEach(r),l$e=i(y),Ac=n(y,"LI",{});var tpe=s(Ac);Lz=n(tpe,"STRONG",{});var bvt=s(Lz);i$e=t(bvt,"marian"),bvt.forEach(r),d$e=t(tpe," \u2014 "),y6=n(tpe,"A",{href:!0});var Tvt=s(y6);m$e=t(Tvt,"MarianTokenizer"),Tvt.forEach(r),f$e=t(tpe," (Marian model)"),tpe.forEach(r),c$e=i(y),zn=n(y,"LI",{});var uA=s(zn);Bz=n(uA,"STRONG",{});var Fvt=s(Bz);g$e=t(Fvt,"mbart"),Fvt.forEach(r),h$e=t(uA," \u2014 "),w6=n(uA,"A",{href:!0});var Mvt=s(w6);u$e=t(Mvt,"MBartTokenizer"),Mvt.forEach(r),p$e=t(uA," or "),A6=n(uA,"A",{href:!0});var Evt=s(A6);_$e=t(Evt,"MBartTokenizerFast"),Evt.forEach(r),v$e=t(uA," (mBART model)"),uA.forEach(r),b$e=i(y),Xn=n(y,"LI",{});var pA=s(Xn);kz=n(pA,"STRONG",{});var Cvt=s(kz);T$e=t(Cvt,"mbart50"),Cvt.forEach(r),F$e=t(pA," \u2014 "),x6=n(pA,"A",{href:!0});var yvt=s(x6);M$e=t(yvt,"MBart50Tokenizer"),yvt.forEach(r),E$e=t(pA," or "),L6=n(pA,"A",{href:!0});var wvt=s(L6);C$e=t(wvt,"MBart50TokenizerFast"),wvt.forEach(r),y$e=t(pA," (mBART-50 model)"),pA.forEach(r),w$e=i(y),Wn=n(y,"LI",{});var _A=s(Wn);Rz=n(_A,"STRONG",{});var Avt=s(Rz);A$e=t(Avt,"mobilebert"),Avt.forEach(r),x$e=t(_A," \u2014 "),B6=n(_A,"A",{href:!0});var xvt=s(B6);L$e=t(xvt,"MobileBertTokenizer"),xvt.forEach(r),B$e=t(_A," or "),k6=n(_A,"A",{href:!0});var Lvt=s(k6);k$e=t(Lvt,"MobileBertTokenizerFast"),Lvt.forEach(r),R$e=t(_A," (MobileBERT model)"),_A.forEach(r),S$e=i(y),Vn=n(y,"LI",{});var vA=s(Vn);Sz=n(vA,"STRONG",{});var Bvt=s(Sz);P$e=t(Bvt,"mpnet"),Bvt.forEach(r),$$e=t(vA," \u2014 "),R6=n(vA,"A",{href:!0});var kvt=s(R6);I$e=t(kvt,"MPNetTokenizer"),kvt.forEach(r),j$e=t(vA," or "),S6=n(vA,"A",{href:!0});var Rvt=s(S6);N$e=t(Rvt,"MPNetTokenizerFast"),Rvt.forEach(r),D$e=t(vA," (MPNet model)"),vA.forEach(r),G$e=i(y),Qn=n(y,"LI",{});var bA=s(Qn);Pz=n(bA,"STRONG",{});var Svt=s(Pz);O$e=t(Svt,"mt5"),Svt.forEach(r),q$e=t(bA," \u2014 "),P6=n(bA,"A",{href:!0});var Pvt=s(P6);z$e=t(Pvt,"MT5Tokenizer"),Pvt.forEach(r),X$e=t(bA," or "),$6=n(bA,"A",{href:!0});var $vt=s($6);W$e=t($vt,"MT5TokenizerFast"),$vt.forEach(r),V$e=t(bA," (mT5 model)"),bA.forEach(r),Q$e=i(y),Hn=n(y,"LI",{});var TA=s(Hn);$z=n(TA,"STRONG",{});var Ivt=s($z);H$e=t(Ivt,"openai-gpt"),Ivt.forEach(r),U$e=t(TA," \u2014 "),I6=n(TA,"A",{href:!0});var jvt=s(I6);J$e=t(jvt,"OpenAIGPTTokenizer"),jvt.forEach(r),K$e=t(TA," or "),j6=n(TA,"A",{href:!0});var Nvt=s(j6);Y$e=t(Nvt,"OpenAIGPTTokenizerFast"),Nvt.forEach(r),Z$e=t(TA," (OpenAI GPT model)"),TA.forEach(r),eIe=i(y),Un=n(y,"LI",{});var FA=s(Un);Iz=n(FA,"STRONG",{});var Dvt=s(Iz);oIe=t(Dvt,"pegasus"),Dvt.forEach(r),tIe=t(FA," \u2014 "),N6=n(FA,"A",{href:!0});var Gvt=s(N6);rIe=t(Gvt,"PegasusTokenizer"),Gvt.forEach(r),aIe=t(FA," or "),D6=n(FA,"A",{href:!0});var Ovt=s(D6);nIe=t(Ovt,"PegasusTokenizerFast"),Ovt.forEach(r),sIe=t(FA," (Pegasus model)"),FA.forEach(r),lIe=i(y),xc=n(y,"LI",{});var rpe=s(xc);jz=n(rpe,"STRONG",{});var qvt=s(jz);iIe=t(qvt,"perceiver"),qvt.forEach(r),dIe=t(rpe," \u2014 "),G6=n(rpe,"A",{href:!0});var zvt=s(G6);mIe=t(zvt,"PerceiverTokenizer"),zvt.forEach(r),fIe=t(rpe," (Perceiver model)"),rpe.forEach(r),cIe=i(y),Lc=n(y,"LI",{});var ape=s(Lc);Nz=n(ape,"STRONG",{});var Xvt=s(Nz);gIe=t(Xvt,"phobert"),Xvt.forEach(r),hIe=t(ape," \u2014 "),O6=n(ape,"A",{href:!0});var Wvt=s(O6);uIe=t(Wvt,"PhobertTokenizer"),Wvt.forEach(r),pIe=t(ape," (PhoBERT model)"),ape.forEach(r),_Ie=i(y),Bc=n(y,"LI",{});var npe=s(Bc);Dz=n(npe,"STRONG",{});var Vvt=s(Dz);vIe=t(Vvt,"prophetnet"),Vvt.forEach(r),bIe=t(npe," \u2014 "),q6=n(npe,"A",{href:!0});var Qvt=s(q6);TIe=t(Qvt,"ProphetNetTokenizer"),Qvt.forEach(r),FIe=t(npe," (ProphetNet model)"),npe.forEach(r),MIe=i(y),Jn=n(y,"LI",{});var MA=s(Jn);Gz=n(MA,"STRONG",{});var Hvt=s(Gz);EIe=t(Hvt,"qdqbert"),Hvt.forEach(r),CIe=t(MA," \u2014 "),z6=n(MA,"A",{href:!0});var Uvt=s(z6);yIe=t(Uvt,"BertTokenizer"),Uvt.forEach(r),wIe=t(MA," or "),X6=n(MA,"A",{href:!0});var Jvt=s(X6);AIe=t(Jvt,"BertTokenizerFast"),Jvt.forEach(r),xIe=t(MA," (QDQBert model)"),MA.forEach(r),LIe=i(y),kc=n(y,"LI",{});var spe=s(kc);Oz=n(spe,"STRONG",{});var Kvt=s(Oz);BIe=t(Kvt,"rag"),Kvt.forEach(r),kIe=t(spe," \u2014 "),W6=n(spe,"A",{href:!0});var Yvt=s(W6);RIe=t(Yvt,"RagTokenizer"),Yvt.forEach(r),SIe=t(spe," (RAG model)"),spe.forEach(r),PIe=i(y),Kn=n(y,"LI",{});var EA=s(Kn);qz=n(EA,"STRONG",{});var Zvt=s(qz);$Ie=t(Zvt,"reformer"),Zvt.forEach(r),IIe=t(EA," \u2014 "),V6=n(EA,"A",{href:!0});var e1t=s(V6);jIe=t(e1t,"ReformerTokenizer"),e1t.forEach(r),NIe=t(EA," or "),Q6=n(EA,"A",{href:!0});var o1t=s(Q6);DIe=t(o1t,"ReformerTokenizerFast"),o1t.forEach(r),GIe=t(EA," (Reformer model)"),EA.forEach(r),OIe=i(y),Yn=n(y,"LI",{});var CA=s(Yn);zz=n(CA,"STRONG",{});var t1t=s(zz);qIe=t(t1t,"rembert"),t1t.forEach(r),zIe=t(CA," \u2014 "),H6=n(CA,"A",{href:!0});var r1t=s(H6);XIe=t(r1t,"RemBertTokenizer"),r1t.forEach(r),WIe=t(CA," or "),U6=n(CA,"A",{href:!0});var a1t=s(U6);VIe=t(a1t,"RemBertTokenizerFast"),a1t.forEach(r),QIe=t(CA," (RemBERT model)"),CA.forEach(r),HIe=i(y),Zn=n(y,"LI",{});var yA=s(Zn);Xz=n(yA,"STRONG",{});var n1t=s(Xz);UIe=t(n1t,"retribert"),n1t.forEach(r),JIe=t(yA," \u2014 "),J6=n(yA,"A",{href:!0});var s1t=s(J6);KIe=t(s1t,"RetriBertTokenizer"),s1t.forEach(r),YIe=t(yA," or "),K6=n(yA,"A",{href:!0});var l1t=s(K6);ZIe=t(l1t,"RetriBertTokenizerFast"),l1t.forEach(r),eje=t(yA," (RetriBERT model)"),yA.forEach(r),oje=i(y),es=n(y,"LI",{});var wA=s(es);Wz=n(wA,"STRONG",{});var i1t=s(Wz);tje=t(i1t,"roberta"),i1t.forEach(r),rje=t(wA," \u2014 "),Y6=n(wA,"A",{href:!0});var d1t=s(Y6);aje=t(d1t,"RobertaTokenizer"),d1t.forEach(r),nje=t(wA," or "),Z6=n(wA,"A",{href:!0});var m1t=s(Z6);sje=t(m1t,"RobertaTokenizerFast"),m1t.forEach(r),lje=t(wA," (RoBERTa model)"),wA.forEach(r),ije=i(y),os=n(y,"LI",{});var AA=s(os);Vz=n(AA,"STRONG",{});var f1t=s(Vz);dje=t(f1t,"roformer"),f1t.forEach(r),mje=t(AA," \u2014 "),e8=n(AA,"A",{href:!0});var c1t=s(e8);fje=t(c1t,"RoFormerTokenizer"),c1t.forEach(r),cje=t(AA," or "),o8=n(AA,"A",{href:!0});var g1t=s(o8);gje=t(g1t,"RoFormerTokenizerFast"),g1t.forEach(r),hje=t(AA," (RoFormer model)"),AA.forEach(r),uje=i(y),Rc=n(y,"LI",{});var lpe=s(Rc);Qz=n(lpe,"STRONG",{});var h1t=s(Qz);pje=t(h1t,"speech_to_text"),h1t.forEach(r),_je=t(lpe," \u2014 "),t8=n(lpe,"A",{href:!0});var u1t=s(t8);vje=t(u1t,"Speech2TextTokenizer"),u1t.forEach(r),bje=t(lpe," (Speech2Text model)"),lpe.forEach(r),Tje=i(y),Sc=n(y,"LI",{});var ipe=s(Sc);Hz=n(ipe,"STRONG",{});var p1t=s(Hz);Fje=t(p1t,"speech_to_text_2"),p1t.forEach(r),Mje=t(ipe," \u2014 "),r8=n(ipe,"A",{href:!0});var _1t=s(r8);Eje=t(_1t,"Speech2Text2Tokenizer"),_1t.forEach(r),Cje=t(ipe," (Speech2Text2 model)"),ipe.forEach(r),yje=i(y),ts=n(y,"LI",{});var xA=s(ts);Uz=n(xA,"STRONG",{});var v1t=s(Uz);wje=t(v1t,"splinter"),v1t.forEach(r),Aje=t(xA," \u2014 "),a8=n(xA,"A",{href:!0});var b1t=s(a8);xje=t(b1t,"SplinterTokenizer"),b1t.forEach(r),Lje=t(xA," or "),n8=n(xA,"A",{href:!0});var T1t=s(n8);Bje=t(T1t,"SplinterTokenizerFast"),T1t.forEach(r),kje=t(xA," (Splinter model)"),xA.forEach(r),Rje=i(y),rs=n(y,"LI",{});var LA=s(rs);Jz=n(LA,"STRONG",{});var F1t=s(Jz);Sje=t(F1t,"squeezebert"),F1t.forEach(r),Pje=t(LA," \u2014 "),s8=n(LA,"A",{href:!0});var M1t=s(s8);$je=t(M1t,"SqueezeBertTokenizer"),M1t.forEach(r),Ije=t(LA," or "),l8=n(LA,"A",{href:!0});var E1t=s(l8);jje=t(E1t,"SqueezeBertTokenizerFast"),E1t.forEach(r),Nje=t(LA," (SqueezeBERT model)"),LA.forEach(r),Dje=i(y),as=n(y,"LI",{});var BA=s(as);Kz=n(BA,"STRONG",{});var C1t=s(Kz);Gje=t(C1t,"t5"),C1t.forEach(r),Oje=t(BA," \u2014 "),i8=n(BA,"A",{href:!0});var y1t=s(i8);qje=t(y1t,"T5Tokenizer"),y1t.forEach(r),zje=t(BA," or "),d8=n(BA,"A",{href:!0});var w1t=s(d8);Xje=t(w1t,"T5TokenizerFast"),w1t.forEach(r),Wje=t(BA," (T5 model)"),BA.forEach(r),Vje=i(y),Pc=n(y,"LI",{});var dpe=s(Pc);Yz=n(dpe,"STRONG",{});var A1t=s(Yz);Qje=t(A1t,"tapas"),A1t.forEach(r),Hje=t(dpe," \u2014 "),m8=n(dpe,"A",{href:!0});var x1t=s(m8);Uje=t(x1t,"TapasTokenizer"),x1t.forEach(r),Jje=t(dpe," (TAPAS model)"),dpe.forEach(r),Kje=i(y),$c=n(y,"LI",{});var mpe=s($c);Zz=n(mpe,"STRONG",{});var L1t=s(Zz);Yje=t(L1t,"transfo-xl"),L1t.forEach(r),Zje=t(mpe," \u2014 "),f8=n(mpe,"A",{href:!0});var B1t=s(f8);eNe=t(B1t,"TransfoXLTokenizer"),B1t.forEach(r),oNe=t(mpe," (Transformer-XL model)"),mpe.forEach(r),tNe=i(y),Ic=n(y,"LI",{});var fpe=s(Ic);eX=n(fpe,"STRONG",{});var k1t=s(eX);rNe=t(k1t,"wav2vec2"),k1t.forEach(r),aNe=t(fpe," \u2014 "),c8=n(fpe,"A",{href:!0});var R1t=s(c8);nNe=t(R1t,"Wav2Vec2CTCTokenizer"),R1t.forEach(r),sNe=t(fpe," (Wav2Vec2 model)"),fpe.forEach(r),lNe=i(y),jc=n(y,"LI",{});var cpe=s(jc);oX=n(cpe,"STRONG",{});var S1t=s(oX);iNe=t(S1t,"xlm"),S1t.forEach(r),dNe=t(cpe," \u2014 "),g8=n(cpe,"A",{href:!0});var P1t=s(g8);mNe=t(P1t,"XLMTokenizer"),P1t.forEach(r),fNe=t(cpe," (XLM model)"),cpe.forEach(r),cNe=i(y),Nc=n(y,"LI",{});var gpe=s(Nc);tX=n(gpe,"STRONG",{});var $1t=s(tX);gNe=t($1t,"xlm-prophetnet"),$1t.forEach(r),hNe=t(gpe," \u2014 "),h8=n(gpe,"A",{href:!0});var I1t=s(h8);uNe=t(I1t,"XLMProphetNetTokenizer"),I1t.forEach(r),pNe=t(gpe," (XLMProphetNet model)"),gpe.forEach(r),_Ne=i(y),ns=n(y,"LI",{});var kA=s(ns);rX=n(kA,"STRONG",{});var j1t=s(rX);vNe=t(j1t,"xlm-roberta"),j1t.forEach(r),bNe=t(kA," \u2014 "),u8=n(kA,"A",{href:!0});var N1t=s(u8);TNe=t(N1t,"XLMRobertaTokenizer"),N1t.forEach(r),FNe=t(kA," or "),p8=n(kA,"A",{href:!0});var D1t=s(p8);MNe=t(D1t,"XLMRobertaTokenizerFast"),D1t.forEach(r),ENe=t(kA," (XLM-RoBERTa model)"),kA.forEach(r),CNe=i(y),ss=n(y,"LI",{});var RA=s(ss);aX=n(RA,"STRONG",{});var G1t=s(aX);yNe=t(G1t,"xlnet"),G1t.forEach(r),wNe=t(RA," \u2014 "),_8=n(RA,"A",{href:!0});var O1t=s(_8);ANe=t(O1t,"XLNetTokenizer"),O1t.forEach(r),xNe=t(RA," or "),v8=n(RA,"A",{href:!0});var q1t=s(v8);LNe=t(q1t,"XLNetTokenizerFast"),q1t.forEach(r),BNe=t(RA," (XLNet model)"),RA.forEach(r),y.forEach(r),kNe=i(Vr),nX=n(Vr,"P",{});var z1t=s(nX);RNe=t(z1t,"Examples:"),z1t.forEach(r),SNe=i(Vr),c(JF.$$.fragment,Vr),Vr.forEach(r),PNe=i(fs),Dc=n(fs,"DIV",{class:!0});var M3e=s(Dc);c(KF.$$.fragment,M3e),$Ne=i(M3e),sX=n(M3e,"P",{});var X1t=s(sX);INe=t(X1t,"Register a new tokenizer in this mapping."),X1t.forEach(r),M3e.forEach(r),fs.forEach(r),xEe=i(d),ri=n(d,"H2",{class:!0});var E3e=s(ri);Gc=n(E3e,"A",{id:!0,class:!0,href:!0});var W1t=s(Gc);lX=n(W1t,"SPAN",{});var V1t=s(lX);c(YF.$$.fragment,V1t),V1t.forEach(r),W1t.forEach(r),jNe=i(E3e),iX=n(E3e,"SPAN",{});var Q1t=s(iX);NNe=t(Q1t,"AutoFeatureExtractor"),Q1t.forEach(r),E3e.forEach(r),LEe=i(d),Gr=n(d,"DIV",{class:!0});var GT=s(Gr);c(ZF.$$.fragment,GT),DNe=i(GT),eM=n(GT,"P",{});var C3e=s(eM);GNe=t(C3e,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),b8=n(C3e,"A",{href:!0});var H1t=s(b8);ONe=t(H1t,"AutoFeatureExtractor.from_pretrained()"),H1t.forEach(r),qNe=t(C3e," class method."),C3e.forEach(r),zNe=i(GT),oM=n(GT,"P",{});var y3e=s(oM);XNe=t(y3e,"This class cannot be instantiated directly using "),dX=n(y3e,"CODE",{});var U1t=s(dX);WNe=t(U1t,"__init__()"),U1t.forEach(r),VNe=t(y3e," (throws an error)."),y3e.forEach(r),QNe=i(GT),we=n(GT,"DIV",{class:!0});var ur=s(we);c(tM.$$.fragment,ur),HNe=i(ur),mX=n(ur,"P",{});var J1t=s(mX);UNe=t(J1t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),J1t.forEach(r),JNe=i(ur),Ma=n(ur,"P",{});var OT=s(Ma);KNe=t(OT,"The feature extractor class to instantiate is selected based on the "),fX=n(OT,"EM",{});var K1t=s(fX);YNe=t(K1t,"model_type"),K1t.forEach(r),ZNe=t(OT,` property of the config
object (either passed as an argument or loaded from `),cX=n(OT,"EM",{});var Y1t=s(cX);eDe=t(Y1t,"pretrained_model_name_or_path"),Y1t.forEach(r),oDe=t(OT,` if possible), or when
it\u2019s missing, by falling back to using pattern matching on `),gX=n(OT,"EM",{});var Z1t=s(gX);tDe=t(Z1t,"pretrained_model_name_or_path"),Z1t.forEach(r),rDe=t(OT,":"),OT.forEach(r),aDe=i(ur),fe=n(ur,"UL",{});var _e=s(fe);Oc=n(_e,"LI",{});var hpe=s(Oc);hX=n(hpe,"STRONG",{});var e2t=s(hX);nDe=t(e2t,"beit"),e2t.forEach(r),sDe=t(hpe," \u2014 "),T8=n(hpe,"A",{href:!0});var o2t=s(T8);lDe=t(o2t,"BeitFeatureExtractor"),o2t.forEach(r),iDe=t(hpe," (BEiT model)"),hpe.forEach(r),dDe=i(_e),qc=n(_e,"LI",{});var upe=s(qc);uX=n(upe,"STRONG",{});var t2t=s(uX);mDe=t(t2t,"clip"),t2t.forEach(r),fDe=t(upe," \u2014 "),F8=n(upe,"A",{href:!0});var r2t=s(F8);cDe=t(r2t,"CLIPFeatureExtractor"),r2t.forEach(r),gDe=t(upe," (CLIP model)"),upe.forEach(r),hDe=i(_e),zc=n(_e,"LI",{});var ppe=s(zc);pX=n(ppe,"STRONG",{});var a2t=s(pX);uDe=t(a2t,"deit"),a2t.forEach(r),pDe=t(ppe," \u2014 "),M8=n(ppe,"A",{href:!0});var n2t=s(M8);_De=t(n2t,"DeiTFeatureExtractor"),n2t.forEach(r),vDe=t(ppe," (DeiT model)"),ppe.forEach(r),bDe=i(_e),Xc=n(_e,"LI",{});var _pe=s(Xc);_X=n(_pe,"STRONG",{});var s2t=s(_X);TDe=t(s2t,"detr"),s2t.forEach(r),FDe=t(_pe," \u2014 "),E8=n(_pe,"A",{href:!0});var l2t=s(E8);MDe=t(l2t,"DetrFeatureExtractor"),l2t.forEach(r),EDe=t(_pe," (DETR model)"),_pe.forEach(r),CDe=i(_e),Wc=n(_e,"LI",{});var vpe=s(Wc);vX=n(vpe,"STRONG",{});var i2t=s(vX);yDe=t(i2t,"hubert"),i2t.forEach(r),wDe=t(vpe," \u2014 "),C8=n(vpe,"A",{href:!0});var d2t=s(C8);ADe=t(d2t,"Wav2Vec2FeatureExtractor"),d2t.forEach(r),xDe=t(vpe," (Hubert model)"),vpe.forEach(r),LDe=i(_e),Vc=n(_e,"LI",{});var bpe=s(Vc);bX=n(bpe,"STRONG",{});var m2t=s(bX);BDe=t(m2t,"layoutlmv2"),m2t.forEach(r),kDe=t(bpe," \u2014 "),y8=n(bpe,"A",{href:!0});var f2t=s(y8);RDe=t(f2t,"LayoutLMv2FeatureExtractor"),f2t.forEach(r),SDe=t(bpe," (LayoutLMv2 model)"),bpe.forEach(r),PDe=i(_e),Qc=n(_e,"LI",{});var Tpe=s(Qc);TX=n(Tpe,"STRONG",{});var c2t=s(TX);$De=t(c2t,"perceiver"),c2t.forEach(r),IDe=t(Tpe," \u2014 "),w8=n(Tpe,"A",{href:!0});var g2t=s(w8);jDe=t(g2t,"PerceiverFeatureExtractor"),g2t.forEach(r),NDe=t(Tpe," (Perceiver model)"),Tpe.forEach(r),DDe=i(_e),Hc=n(_e,"LI",{});var Fpe=s(Hc);FX=n(Fpe,"STRONG",{});var h2t=s(FX);GDe=t(h2t,"speech_to_text"),h2t.forEach(r),ODe=t(Fpe," \u2014 "),A8=n(Fpe,"A",{href:!0});var u2t=s(A8);qDe=t(u2t,"Speech2TextFeatureExtractor"),u2t.forEach(r),zDe=t(Fpe," (Speech2Text model)"),Fpe.forEach(r),XDe=i(_e),Uc=n(_e,"LI",{});var Mpe=s(Uc);MX=n(Mpe,"STRONG",{});var p2t=s(MX);WDe=t(p2t,"vit"),p2t.forEach(r),VDe=t(Mpe," \u2014 "),x8=n(Mpe,"A",{href:!0});var _2t=s(x8);QDe=t(_2t,"ViTFeatureExtractor"),_2t.forEach(r),HDe=t(Mpe," (ViT model)"),Mpe.forEach(r),UDe=i(_e),Jc=n(_e,"LI",{});var Epe=s(Jc);EX=n(Epe,"STRONG",{});var v2t=s(EX);JDe=t(v2t,"wav2vec2"),v2t.forEach(r),KDe=t(Epe," \u2014 "),L8=n(Epe,"A",{href:!0});var b2t=s(L8);YDe=t(b2t,"Wav2Vec2FeatureExtractor"),b2t.forEach(r),ZDe=t(Epe," (Wav2Vec2 model)"),Epe.forEach(r),_e.forEach(r),eGe=i(ur),c(Kc.$$.fragment,ur),oGe=i(ur),CX=n(ur,"P",{});var T2t=s(CX);tGe=t(T2t,"Examples:"),T2t.forEach(r),rGe=i(ur),c(rM.$$.fragment,ur),ur.forEach(r),GT.forEach(r),BEe=i(d),ai=n(d,"H2",{class:!0});var w3e=s(ai);Yc=n(w3e,"A",{id:!0,class:!0,href:!0});var F2t=s(Yc);yX=n(F2t,"SPAN",{});var M2t=s(yX);c(aM.$$.fragment,M2t),M2t.forEach(r),F2t.forEach(r),aGe=i(w3e),wX=n(w3e,"SPAN",{});var E2t=s(wX);nGe=t(E2t,"AutoProcessor"),E2t.forEach(r),w3e.forEach(r),kEe=i(d),Or=n(d,"DIV",{class:!0});var qT=s(Or);c(nM.$$.fragment,qT),sGe=i(qT),sM=n(qT,"P",{});var A3e=s(sM);lGe=t(A3e,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),B8=n(A3e,"A",{href:!0});var C2t=s(B8);iGe=t(C2t,"AutoProcessor.from_pretrained()"),C2t.forEach(r),dGe=t(A3e," class method."),A3e.forEach(r),mGe=i(qT),lM=n(qT,"P",{});var x3e=s(lM);fGe=t(x3e,"This class cannot be instantiated directly using "),AX=n(x3e,"CODE",{});var y2t=s(AX);cGe=t(y2t,"__init__()"),y2t.forEach(r),gGe=t(x3e," (throws an error)."),x3e.forEach(r),hGe=i(qT),Ae=n(qT,"DIV",{class:!0});var pr=s(Ae);c(iM.$$.fragment,pr),uGe=i(pr),xX=n(pr,"P",{});var w2t=s(xX);pGe=t(w2t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),w2t.forEach(r),_Ge=i(pr),ni=n(pr,"P",{});var pD=s(ni);vGe=t(pD,"The processor class to instantiate is selected based on the "),LX=n(pD,"EM",{});var A2t=s(LX);bGe=t(A2t,"model_type"),A2t.forEach(r),TGe=t(pD,` property of the config object
(either passed as an argument or loaded from `),BX=n(pD,"EM",{});var x2t=s(BX);FGe=t(x2t,"pretrained_model_name_or_path"),x2t.forEach(r),MGe=t(pD," if possible):"),pD.forEach(r),EGe=i(pr),Je=n(pr,"UL",{});var _r=s(Je);Zc=n(_r,"LI",{});var Cpe=s(Zc);kX=n(Cpe,"STRONG",{});var L2t=s(kX);CGe=t(L2t,"clip"),L2t.forEach(r),yGe=t(Cpe," \u2014 "),k8=n(Cpe,"A",{href:!0});var B2t=s(k8);wGe=t(B2t,"CLIPProcessor"),B2t.forEach(r),AGe=t(Cpe," (CLIP model)"),Cpe.forEach(r),xGe=i(_r),eg=n(_r,"LI",{});var ype=s(eg);RX=n(ype,"STRONG",{});var k2t=s(RX);LGe=t(k2t,"layoutlmv2"),k2t.forEach(r),BGe=t(ype," \u2014 "),R8=n(ype,"A",{href:!0});var R2t=s(R8);kGe=t(R2t,"LayoutLMv2Processor"),R2t.forEach(r),RGe=t(ype," (LayoutLMv2 model)"),ype.forEach(r),SGe=i(_r),og=n(_r,"LI",{});var wpe=s(og);SX=n(wpe,"STRONG",{});var S2t=s(SX);PGe=t(S2t,"speech_to_text"),S2t.forEach(r),$Ge=t(wpe," \u2014 "),S8=n(wpe,"A",{href:!0});var P2t=s(S8);IGe=t(P2t,"Speech2TextProcessor"),P2t.forEach(r),jGe=t(wpe," (Speech2Text model)"),wpe.forEach(r),NGe=i(_r),tg=n(_r,"LI",{});var Ape=s(tg);PX=n(Ape,"STRONG",{});var $2t=s(PX);DGe=t($2t,"speech_to_text_2"),$2t.forEach(r),GGe=t(Ape," \u2014 "),P8=n(Ape,"A",{href:!0});var I2t=s(P8);OGe=t(I2t,"Speech2Text2Processor"),I2t.forEach(r),qGe=t(Ape," (Speech2Text2 model)"),Ape.forEach(r),zGe=i(_r),rg=n(_r,"LI",{});var xpe=s(rg);$X=n(xpe,"STRONG",{});var j2t=s($X);XGe=t(j2t,"trocr"),j2t.forEach(r),WGe=t(xpe," \u2014 "),$8=n(xpe,"A",{href:!0});var N2t=s($8);VGe=t(N2t,"TrOCRProcessor"),N2t.forEach(r),QGe=t(xpe," (TrOCR model)"),xpe.forEach(r),HGe=i(_r),ag=n(_r,"LI",{});var Lpe=s(ag);IX=n(Lpe,"STRONG",{});var D2t=s(IX);UGe=t(D2t,"vision-text-dual-encoder"),D2t.forEach(r),JGe=t(Lpe," \u2014 "),I8=n(Lpe,"A",{href:!0});var G2t=s(I8);KGe=t(G2t,"VisionTextDualEncoderProcessor"),G2t.forEach(r),YGe=t(Lpe," (VisionTextDualEncoder model)"),Lpe.forEach(r),ZGe=i(_r),ng=n(_r,"LI",{});var Bpe=s(ng);jX=n(Bpe,"STRONG",{});var O2t=s(jX);eOe=t(O2t,"wav2vec2"),O2t.forEach(r),oOe=t(Bpe," \u2014 "),j8=n(Bpe,"A",{href:!0});var q2t=s(j8);tOe=t(q2t,"Wav2Vec2Processor"),q2t.forEach(r),rOe=t(Bpe," (Wav2Vec2 model)"),Bpe.forEach(r),_r.forEach(r),aOe=i(pr),c(sg.$$.fragment,pr),nOe=i(pr),NX=n(pr,"P",{});var z2t=s(NX);sOe=t(z2t,"Examples:"),z2t.forEach(r),lOe=i(pr),c(dM.$$.fragment,pr),pr.forEach(r),qT.forEach(r),REe=i(d),si=n(d,"H2",{class:!0});var L3e=s(si);lg=n(L3e,"A",{id:!0,class:!0,href:!0});var X2t=s(lg);DX=n(X2t,"SPAN",{});var W2t=s(DX);c(mM.$$.fragment,W2t),W2t.forEach(r),X2t.forEach(r),iOe=i(L3e),GX=n(L3e,"SPAN",{});var V2t=s(GX);dOe=t(V2t,"AutoModel"),V2t.forEach(r),L3e.forEach(r),SEe=i(d),Po=n(d,"DIV",{class:!0});var cs=s(Po);c(fM.$$.fragment,cs),mOe=i(cs),li=n(cs,"P",{});var _D=s(li);fOe=t(_D,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),OX=n(_D,"CODE",{});var Q2t=s(OX);cOe=t(Q2t,"from_pretrained()"),Q2t.forEach(r),gOe=t(_D,` class method or the
`),qX=n(_D,"CODE",{});var H2t=s(qX);hOe=t(H2t,"from_config()"),H2t.forEach(r),uOe=t(_D," class method."),_D.forEach(r),pOe=i(cs),cM=n(cs,"P",{});var B3e=s(cM);_Oe=t(B3e,"This class cannot be instantiated directly using "),zX=n(B3e,"CODE",{});var U2t=s(zX);vOe=t(U2t,"__init__()"),U2t.forEach(r),bOe=t(B3e," (throws an error)."),B3e.forEach(r),TOe=i(cs),wt=n(cs,"DIV",{class:!0});var gs=s(wt);c(gM.$$.fragment,gs),FOe=i(gs),XX=n(gs,"P",{});var J2t=s(XX);MOe=t(J2t,"Instantiates one of the base model classes of the library from a configuration."),J2t.forEach(r),EOe=i(gs),ii=n(gs,"P",{});var vD=s(ii);COe=t(vD,`Note:
Loading a model from its configuration file does `),WX=n(vD,"STRONG",{});var K2t=s(WX);yOe=t(K2t,"not"),K2t.forEach(r),wOe=t(vD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),VX=n(vD,"EM",{});var Y2t=s(VX);AOe=t(Y2t,"~AutoModel.from_pretrained"),Y2t.forEach(r),xOe=t(vD,`] to load the model
weights.`),vD.forEach(r),LOe=i(gs),QX=n(gs,"P",{});var Z2t=s(QX);BOe=t(Z2t,"Examples:"),Z2t.forEach(r),kOe=i(gs),c(hM.$$.fragment,gs),gs.forEach(r),ROe=i(cs),xe=n(cs,"DIV",{class:!0});var vr=s(xe);c(uM.$$.fragment,vr),SOe=i(vr),HX=n(vr,"P",{});var ebt=s(HX);POe=t(ebt,"Instantiate one of the base model classes of the library from a pretrained model."),ebt.forEach(r),$Oe=i(vr),Ea=n(vr,"P",{});var zT=s(Ea);IOe=t(zT,"The model class to instantiate is selected based on the "),UX=n(zT,"EM",{});var obt=s(UX);jOe=t(obt,"model_type"),obt.forEach(r),NOe=t(zT,` property of the config object (either
passed as an argument or loaded from `),JX=n(zT,"EM",{});var tbt=s(JX);DOe=t(tbt,"pretrained_model_name_or_path"),tbt.forEach(r),GOe=t(zT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),KX=n(zT,"EM",{});var rbt=s(KX);OOe=t(rbt,"pretrained_model_name_or_path"),rbt.forEach(r),qOe=t(zT,":"),zT.forEach(r),zOe=i(vr),F=n(vr,"UL",{});var M=s(F);ig=n(M,"LI",{});var kpe=s(ig);YX=n(kpe,"STRONG",{});var abt=s(YX);XOe=t(abt,"albert"),abt.forEach(r),WOe=t(kpe," \u2014 "),N8=n(kpe,"A",{href:!0});var nbt=s(N8);VOe=t(nbt,"AlbertModel"),nbt.forEach(r),QOe=t(kpe," (ALBERT model)"),kpe.forEach(r),HOe=i(M),dg=n(M,"LI",{});var Rpe=s(dg);ZX=n(Rpe,"STRONG",{});var sbt=s(ZX);UOe=t(sbt,"bart"),sbt.forEach(r),JOe=t(Rpe," \u2014 "),D8=n(Rpe,"A",{href:!0});var lbt=s(D8);KOe=t(lbt,"BartModel"),lbt.forEach(r),YOe=t(Rpe," (BART model)"),Rpe.forEach(r),ZOe=i(M),mg=n(M,"LI",{});var Spe=s(mg);eW=n(Spe,"STRONG",{});var ibt=s(eW);eqe=t(ibt,"beit"),ibt.forEach(r),oqe=t(Spe," \u2014 "),G8=n(Spe,"A",{href:!0});var dbt=s(G8);tqe=t(dbt,"BeitModel"),dbt.forEach(r),rqe=t(Spe," (BEiT model)"),Spe.forEach(r),aqe=i(M),fg=n(M,"LI",{});var Ppe=s(fg);oW=n(Ppe,"STRONG",{});var mbt=s(oW);nqe=t(mbt,"bert"),mbt.forEach(r),sqe=t(Ppe," \u2014 "),O8=n(Ppe,"A",{href:!0});var fbt=s(O8);lqe=t(fbt,"BertModel"),fbt.forEach(r),iqe=t(Ppe," (BERT model)"),Ppe.forEach(r),dqe=i(M),cg=n(M,"LI",{});var $pe=s(cg);tW=n($pe,"STRONG",{});var cbt=s(tW);mqe=t(cbt,"bert-generation"),cbt.forEach(r),fqe=t($pe," \u2014 "),q8=n($pe,"A",{href:!0});var gbt=s(q8);cqe=t(gbt,"BertGenerationEncoder"),gbt.forEach(r),gqe=t($pe," (Bert Generation model)"),$pe.forEach(r),hqe=i(M),gg=n(M,"LI",{});var Ipe=s(gg);rW=n(Ipe,"STRONG",{});var hbt=s(rW);uqe=t(hbt,"big_bird"),hbt.forEach(r),pqe=t(Ipe," \u2014 "),z8=n(Ipe,"A",{href:!0});var ubt=s(z8);_qe=t(ubt,"BigBirdModel"),ubt.forEach(r),vqe=t(Ipe," (BigBird model)"),Ipe.forEach(r),bqe=i(M),hg=n(M,"LI",{});var jpe=s(hg);aW=n(jpe,"STRONG",{});var pbt=s(aW);Tqe=t(pbt,"bigbird_pegasus"),pbt.forEach(r),Fqe=t(jpe," \u2014 "),X8=n(jpe,"A",{href:!0});var _bt=s(X8);Mqe=t(_bt,"BigBirdPegasusModel"),_bt.forEach(r),Eqe=t(jpe," (BigBirdPegasus model)"),jpe.forEach(r),Cqe=i(M),ug=n(M,"LI",{});var Npe=s(ug);nW=n(Npe,"STRONG",{});var vbt=s(nW);yqe=t(vbt,"blenderbot"),vbt.forEach(r),wqe=t(Npe," \u2014 "),W8=n(Npe,"A",{href:!0});var bbt=s(W8);Aqe=t(bbt,"BlenderbotModel"),bbt.forEach(r),xqe=t(Npe," (Blenderbot model)"),Npe.forEach(r),Lqe=i(M),pg=n(M,"LI",{});var Dpe=s(pg);sW=n(Dpe,"STRONG",{});var Tbt=s(sW);Bqe=t(Tbt,"blenderbot-small"),Tbt.forEach(r),kqe=t(Dpe," \u2014 "),V8=n(Dpe,"A",{href:!0});var Fbt=s(V8);Rqe=t(Fbt,"BlenderbotSmallModel"),Fbt.forEach(r),Sqe=t(Dpe," (BlenderbotSmall model)"),Dpe.forEach(r),Pqe=i(M),_g=n(M,"LI",{});var Gpe=s(_g);lW=n(Gpe,"STRONG",{});var Mbt=s(lW);$qe=t(Mbt,"camembert"),Mbt.forEach(r),Iqe=t(Gpe," \u2014 "),Q8=n(Gpe,"A",{href:!0});var Ebt=s(Q8);jqe=t(Ebt,"CamembertModel"),Ebt.forEach(r),Nqe=t(Gpe," (CamemBERT model)"),Gpe.forEach(r),Dqe=i(M),vg=n(M,"LI",{});var Ope=s(vg);iW=n(Ope,"STRONG",{});var Cbt=s(iW);Gqe=t(Cbt,"canine"),Cbt.forEach(r),Oqe=t(Ope," \u2014 "),H8=n(Ope,"A",{href:!0});var ybt=s(H8);qqe=t(ybt,"CanineModel"),ybt.forEach(r),zqe=t(Ope," (Canine model)"),Ope.forEach(r),Xqe=i(M),bg=n(M,"LI",{});var qpe=s(bg);dW=n(qpe,"STRONG",{});var wbt=s(dW);Wqe=t(wbt,"clip"),wbt.forEach(r),Vqe=t(qpe," \u2014 "),U8=n(qpe,"A",{href:!0});var Abt=s(U8);Qqe=t(Abt,"CLIPModel"),Abt.forEach(r),Hqe=t(qpe," (CLIP model)"),qpe.forEach(r),Uqe=i(M),Tg=n(M,"LI",{});var zpe=s(Tg);mW=n(zpe,"STRONG",{});var xbt=s(mW);Jqe=t(xbt,"convbert"),xbt.forEach(r),Kqe=t(zpe," \u2014 "),J8=n(zpe,"A",{href:!0});var Lbt=s(J8);Yqe=t(Lbt,"ConvBertModel"),Lbt.forEach(r),Zqe=t(zpe," (ConvBERT model)"),zpe.forEach(r),eze=i(M),Fg=n(M,"LI",{});var Xpe=s(Fg);fW=n(Xpe,"STRONG",{});var Bbt=s(fW);oze=t(Bbt,"ctrl"),Bbt.forEach(r),tze=t(Xpe," \u2014 "),K8=n(Xpe,"A",{href:!0});var kbt=s(K8);rze=t(kbt,"CTRLModel"),kbt.forEach(r),aze=t(Xpe," (CTRL model)"),Xpe.forEach(r),nze=i(M),Mg=n(M,"LI",{});var Wpe=s(Mg);cW=n(Wpe,"STRONG",{});var Rbt=s(cW);sze=t(Rbt,"deberta"),Rbt.forEach(r),lze=t(Wpe," \u2014 "),Y8=n(Wpe,"A",{href:!0});var Sbt=s(Y8);ize=t(Sbt,"DebertaModel"),Sbt.forEach(r),dze=t(Wpe," (DeBERTa model)"),Wpe.forEach(r),mze=i(M),Eg=n(M,"LI",{});var Vpe=s(Eg);gW=n(Vpe,"STRONG",{});var Pbt=s(gW);fze=t(Pbt,"deberta-v2"),Pbt.forEach(r),cze=t(Vpe," \u2014 "),Z8=n(Vpe,"A",{href:!0});var $bt=s(Z8);gze=t($bt,"DebertaV2Model"),$bt.forEach(r),hze=t(Vpe," (DeBERTa-v2 model)"),Vpe.forEach(r),uze=i(M),Cg=n(M,"LI",{});var Qpe=s(Cg);hW=n(Qpe,"STRONG",{});var Ibt=s(hW);pze=t(Ibt,"deit"),Ibt.forEach(r),_ze=t(Qpe," \u2014 "),eL=n(Qpe,"A",{href:!0});var jbt=s(eL);vze=t(jbt,"DeiTModel"),jbt.forEach(r),bze=t(Qpe," (DeiT model)"),Qpe.forEach(r),Tze=i(M),yg=n(M,"LI",{});var Hpe=s(yg);uW=n(Hpe,"STRONG",{});var Nbt=s(uW);Fze=t(Nbt,"detr"),Nbt.forEach(r),Mze=t(Hpe," \u2014 "),oL=n(Hpe,"A",{href:!0});var Dbt=s(oL);Eze=t(Dbt,"DetrModel"),Dbt.forEach(r),Cze=t(Hpe," (DETR model)"),Hpe.forEach(r),yze=i(M),wg=n(M,"LI",{});var Upe=s(wg);pW=n(Upe,"STRONG",{});var Gbt=s(pW);wze=t(Gbt,"distilbert"),Gbt.forEach(r),Aze=t(Upe," \u2014 "),tL=n(Upe,"A",{href:!0});var Obt=s(tL);xze=t(Obt,"DistilBertModel"),Obt.forEach(r),Lze=t(Upe," (DistilBERT model)"),Upe.forEach(r),Bze=i(M),Ag=n(M,"LI",{});var Jpe=s(Ag);_W=n(Jpe,"STRONG",{});var qbt=s(_W);kze=t(qbt,"dpr"),qbt.forEach(r),Rze=t(Jpe," \u2014 "),rL=n(Jpe,"A",{href:!0});var zbt=s(rL);Sze=t(zbt,"DPRQuestionEncoder"),zbt.forEach(r),Pze=t(Jpe," (DPR model)"),Jpe.forEach(r),$ze=i(M),xg=n(M,"LI",{});var Kpe=s(xg);vW=n(Kpe,"STRONG",{});var Xbt=s(vW);Ize=t(Xbt,"electra"),Xbt.forEach(r),jze=t(Kpe," \u2014 "),aL=n(Kpe,"A",{href:!0});var Wbt=s(aL);Nze=t(Wbt,"ElectraModel"),Wbt.forEach(r),Dze=t(Kpe," (ELECTRA model)"),Kpe.forEach(r),Gze=i(M),Lg=n(M,"LI",{});var Ype=s(Lg);bW=n(Ype,"STRONG",{});var Vbt=s(bW);Oze=t(Vbt,"flaubert"),Vbt.forEach(r),qze=t(Ype," \u2014 "),nL=n(Ype,"A",{href:!0});var Qbt=s(nL);zze=t(Qbt,"FlaubertModel"),Qbt.forEach(r),Xze=t(Ype," (FlauBERT model)"),Ype.forEach(r),Wze=i(M),Bg=n(M,"LI",{});var Zpe=s(Bg);TW=n(Zpe,"STRONG",{});var Hbt=s(TW);Vze=t(Hbt,"fnet"),Hbt.forEach(r),Qze=t(Zpe," \u2014 "),sL=n(Zpe,"A",{href:!0});var Ubt=s(sL);Hze=t(Ubt,"FNetModel"),Ubt.forEach(r),Uze=t(Zpe," (FNet model)"),Zpe.forEach(r),Jze=i(M),kg=n(M,"LI",{});var e_e=s(kg);FW=n(e_e,"STRONG",{});var Jbt=s(FW);Kze=t(Jbt,"fsmt"),Jbt.forEach(r),Yze=t(e_e," \u2014 "),lL=n(e_e,"A",{href:!0});var Kbt=s(lL);Zze=t(Kbt,"FSMTModel"),Kbt.forEach(r),eXe=t(e_e," (FairSeq Machine-Translation model)"),e_e.forEach(r),oXe=i(M),ls=n(M,"LI",{});var SA=s(ls);MW=n(SA,"STRONG",{});var Ybt=s(MW);tXe=t(Ybt,"funnel"),Ybt.forEach(r),rXe=t(SA," \u2014 "),iL=n(SA,"A",{href:!0});var Zbt=s(iL);aXe=t(Zbt,"FunnelModel"),Zbt.forEach(r),nXe=t(SA," or "),dL=n(SA,"A",{href:!0});var e4t=s(dL);sXe=t(e4t,"FunnelBaseModel"),e4t.forEach(r),lXe=t(SA," (Funnel Transformer model)"),SA.forEach(r),iXe=i(M),Rg=n(M,"LI",{});var o_e=s(Rg);EW=n(o_e,"STRONG",{});var o4t=s(EW);dXe=t(o4t,"gpt2"),o4t.forEach(r),mXe=t(o_e," \u2014 "),mL=n(o_e,"A",{href:!0});var t4t=s(mL);fXe=t(t4t,"GPT2Model"),t4t.forEach(r),cXe=t(o_e," (OpenAI GPT-2 model)"),o_e.forEach(r),gXe=i(M),Sg=n(M,"LI",{});var t_e=s(Sg);CW=n(t_e,"STRONG",{});var r4t=s(CW);hXe=t(r4t,"gpt_neo"),r4t.forEach(r),uXe=t(t_e," \u2014 "),fL=n(t_e,"A",{href:!0});var a4t=s(fL);pXe=t(a4t,"GPTNeoModel"),a4t.forEach(r),_Xe=t(t_e," (GPT Neo model)"),t_e.forEach(r),vXe=i(M),Pg=n(M,"LI",{});var r_e=s(Pg);yW=n(r_e,"STRONG",{});var n4t=s(yW);bXe=t(n4t,"gptj"),n4t.forEach(r),TXe=t(r_e," \u2014 "),cL=n(r_e,"A",{href:!0});var s4t=s(cL);FXe=t(s4t,"GPTJModel"),s4t.forEach(r),MXe=t(r_e," (GPT-J model)"),r_e.forEach(r),EXe=i(M),$g=n(M,"LI",{});var a_e=s($g);wW=n(a_e,"STRONG",{});var l4t=s(wW);CXe=t(l4t,"hubert"),l4t.forEach(r),yXe=t(a_e," \u2014 "),gL=n(a_e,"A",{href:!0});var i4t=s(gL);wXe=t(i4t,"HubertModel"),i4t.forEach(r),AXe=t(a_e," (Hubert model)"),a_e.forEach(r),xXe=i(M),Ig=n(M,"LI",{});var n_e=s(Ig);AW=n(n_e,"STRONG",{});var d4t=s(AW);LXe=t(d4t,"ibert"),d4t.forEach(r),BXe=t(n_e," \u2014 "),hL=n(n_e,"A",{href:!0});var m4t=s(hL);kXe=t(m4t,"IBertModel"),m4t.forEach(r),RXe=t(n_e," (I-BERT model)"),n_e.forEach(r),SXe=i(M),jg=n(M,"LI",{});var s_e=s(jg);xW=n(s_e,"STRONG",{});var f4t=s(xW);PXe=t(f4t,"imagegpt"),f4t.forEach(r),$Xe=t(s_e," \u2014 "),uL=n(s_e,"A",{href:!0});var c4t=s(uL);IXe=t(c4t,"ImageGPTModel"),c4t.forEach(r),jXe=t(s_e," (ImageGPT model)"),s_e.forEach(r),NXe=i(M),Ng=n(M,"LI",{});var l_e=s(Ng);LW=n(l_e,"STRONG",{});var g4t=s(LW);DXe=t(g4t,"layoutlm"),g4t.forEach(r),GXe=t(l_e," \u2014 "),pL=n(l_e,"A",{href:!0});var h4t=s(pL);OXe=t(h4t,"LayoutLMModel"),h4t.forEach(r),qXe=t(l_e," (LayoutLM model)"),l_e.forEach(r),zXe=i(M),Dg=n(M,"LI",{});var i_e=s(Dg);BW=n(i_e,"STRONG",{});var u4t=s(BW);XXe=t(u4t,"layoutlmv2"),u4t.forEach(r),WXe=t(i_e," \u2014 "),_L=n(i_e,"A",{href:!0});var p4t=s(_L);VXe=t(p4t,"LayoutLMv2Model"),p4t.forEach(r),QXe=t(i_e," (LayoutLMv2 model)"),i_e.forEach(r),HXe=i(M),Gg=n(M,"LI",{});var d_e=s(Gg);kW=n(d_e,"STRONG",{});var _4t=s(kW);UXe=t(_4t,"led"),_4t.forEach(r),JXe=t(d_e," \u2014 "),vL=n(d_e,"A",{href:!0});var v4t=s(vL);KXe=t(v4t,"LEDModel"),v4t.forEach(r),YXe=t(d_e," (LED model)"),d_e.forEach(r),ZXe=i(M),Og=n(M,"LI",{});var m_e=s(Og);RW=n(m_e,"STRONG",{});var b4t=s(RW);eWe=t(b4t,"longformer"),b4t.forEach(r),oWe=t(m_e," \u2014 "),bL=n(m_e,"A",{href:!0});var T4t=s(bL);tWe=t(T4t,"LongformerModel"),T4t.forEach(r),rWe=t(m_e," (Longformer model)"),m_e.forEach(r),aWe=i(M),qg=n(M,"LI",{});var f_e=s(qg);SW=n(f_e,"STRONG",{});var F4t=s(SW);nWe=t(F4t,"luke"),F4t.forEach(r),sWe=t(f_e," \u2014 "),TL=n(f_e,"A",{href:!0});var M4t=s(TL);lWe=t(M4t,"LukeModel"),M4t.forEach(r),iWe=t(f_e," (LUKE model)"),f_e.forEach(r),dWe=i(M),zg=n(M,"LI",{});var c_e=s(zg);PW=n(c_e,"STRONG",{});var E4t=s(PW);mWe=t(E4t,"lxmert"),E4t.forEach(r),fWe=t(c_e," \u2014 "),FL=n(c_e,"A",{href:!0});var C4t=s(FL);cWe=t(C4t,"LxmertModel"),C4t.forEach(r),gWe=t(c_e," (LXMERT model)"),c_e.forEach(r),hWe=i(M),Xg=n(M,"LI",{});var g_e=s(Xg);$W=n(g_e,"STRONG",{});var y4t=s($W);uWe=t(y4t,"m2m_100"),y4t.forEach(r),pWe=t(g_e," \u2014 "),ML=n(g_e,"A",{href:!0});var w4t=s(ML);_We=t(w4t,"M2M100Model"),w4t.forEach(r),vWe=t(g_e," (M2M100 model)"),g_e.forEach(r),bWe=i(M),Wg=n(M,"LI",{});var h_e=s(Wg);IW=n(h_e,"STRONG",{});var A4t=s(IW);TWe=t(A4t,"marian"),A4t.forEach(r),FWe=t(h_e," \u2014 "),EL=n(h_e,"A",{href:!0});var x4t=s(EL);MWe=t(x4t,"MarianModel"),x4t.forEach(r),EWe=t(h_e," (Marian model)"),h_e.forEach(r),CWe=i(M),Vg=n(M,"LI",{});var u_e=s(Vg);jW=n(u_e,"STRONG",{});var L4t=s(jW);yWe=t(L4t,"mbart"),L4t.forEach(r),wWe=t(u_e," \u2014 "),CL=n(u_e,"A",{href:!0});var B4t=s(CL);AWe=t(B4t,"MBartModel"),B4t.forEach(r),xWe=t(u_e," (mBART model)"),u_e.forEach(r),LWe=i(M),Qg=n(M,"LI",{});var p_e=s(Qg);NW=n(p_e,"STRONG",{});var k4t=s(NW);BWe=t(k4t,"megatron-bert"),k4t.forEach(r),kWe=t(p_e," \u2014 "),yL=n(p_e,"A",{href:!0});var R4t=s(yL);RWe=t(R4t,"MegatronBertModel"),R4t.forEach(r),SWe=t(p_e," (MegatronBert model)"),p_e.forEach(r),PWe=i(M),Hg=n(M,"LI",{});var __e=s(Hg);DW=n(__e,"STRONG",{});var S4t=s(DW);$We=t(S4t,"mobilebert"),S4t.forEach(r),IWe=t(__e," \u2014 "),wL=n(__e,"A",{href:!0});var P4t=s(wL);jWe=t(P4t,"MobileBertModel"),P4t.forEach(r),NWe=t(__e," (MobileBERT model)"),__e.forEach(r),DWe=i(M),Ug=n(M,"LI",{});var v_e=s(Ug);GW=n(v_e,"STRONG",{});var $4t=s(GW);GWe=t($4t,"mpnet"),$4t.forEach(r),OWe=t(v_e," \u2014 "),AL=n(v_e,"A",{href:!0});var I4t=s(AL);qWe=t(I4t,"MPNetModel"),I4t.forEach(r),zWe=t(v_e," (MPNet model)"),v_e.forEach(r),XWe=i(M),Jg=n(M,"LI",{});var b_e=s(Jg);OW=n(b_e,"STRONG",{});var j4t=s(OW);WWe=t(j4t,"mt5"),j4t.forEach(r),VWe=t(b_e," \u2014 "),xL=n(b_e,"A",{href:!0});var N4t=s(xL);QWe=t(N4t,"MT5Model"),N4t.forEach(r),HWe=t(b_e," (mT5 model)"),b_e.forEach(r),UWe=i(M),Kg=n(M,"LI",{});var T_e=s(Kg);qW=n(T_e,"STRONG",{});var D4t=s(qW);JWe=t(D4t,"openai-gpt"),D4t.forEach(r),KWe=t(T_e," \u2014 "),LL=n(T_e,"A",{href:!0});var G4t=s(LL);YWe=t(G4t,"OpenAIGPTModel"),G4t.forEach(r),ZWe=t(T_e," (OpenAI GPT model)"),T_e.forEach(r),eVe=i(M),Yg=n(M,"LI",{});var F_e=s(Yg);zW=n(F_e,"STRONG",{});var O4t=s(zW);oVe=t(O4t,"pegasus"),O4t.forEach(r),tVe=t(F_e," \u2014 "),BL=n(F_e,"A",{href:!0});var q4t=s(BL);rVe=t(q4t,"PegasusModel"),q4t.forEach(r),aVe=t(F_e," (Pegasus model)"),F_e.forEach(r),nVe=i(M),Zg=n(M,"LI",{});var M_e=s(Zg);XW=n(M_e,"STRONG",{});var z4t=s(XW);sVe=t(z4t,"perceiver"),z4t.forEach(r),lVe=t(M_e," \u2014 "),kL=n(M_e,"A",{href:!0});var X4t=s(kL);iVe=t(X4t,"PerceiverModel"),X4t.forEach(r),dVe=t(M_e," (Perceiver model)"),M_e.forEach(r),mVe=i(M),eh=n(M,"LI",{});var E_e=s(eh);WW=n(E_e,"STRONG",{});var W4t=s(WW);fVe=t(W4t,"prophetnet"),W4t.forEach(r),cVe=t(E_e," \u2014 "),RL=n(E_e,"A",{href:!0});var V4t=s(RL);gVe=t(V4t,"ProphetNetModel"),V4t.forEach(r),hVe=t(E_e," (ProphetNet model)"),E_e.forEach(r),uVe=i(M),oh=n(M,"LI",{});var C_e=s(oh);VW=n(C_e,"STRONG",{});var Q4t=s(VW);pVe=t(Q4t,"qdqbert"),Q4t.forEach(r),_Ve=t(C_e," \u2014 "),SL=n(C_e,"A",{href:!0});var H4t=s(SL);vVe=t(H4t,"QDQBertModel"),H4t.forEach(r),bVe=t(C_e," (QDQBert model)"),C_e.forEach(r),TVe=i(M),th=n(M,"LI",{});var y_e=s(th);QW=n(y_e,"STRONG",{});var U4t=s(QW);FVe=t(U4t,"reformer"),U4t.forEach(r),MVe=t(y_e," \u2014 "),PL=n(y_e,"A",{href:!0});var J4t=s(PL);EVe=t(J4t,"ReformerModel"),J4t.forEach(r),CVe=t(y_e," (Reformer model)"),y_e.forEach(r),yVe=i(M),rh=n(M,"LI",{});var w_e=s(rh);HW=n(w_e,"STRONG",{});var K4t=s(HW);wVe=t(K4t,"rembert"),K4t.forEach(r),AVe=t(w_e," \u2014 "),$L=n(w_e,"A",{href:!0});var Y4t=s($L);xVe=t(Y4t,"RemBertModel"),Y4t.forEach(r),LVe=t(w_e," (RemBERT model)"),w_e.forEach(r),BVe=i(M),ah=n(M,"LI",{});var A_e=s(ah);UW=n(A_e,"STRONG",{});var Z4t=s(UW);kVe=t(Z4t,"retribert"),Z4t.forEach(r),RVe=t(A_e," \u2014 "),IL=n(A_e,"A",{href:!0});var e5t=s(IL);SVe=t(e5t,"RetriBertModel"),e5t.forEach(r),PVe=t(A_e," (RetriBERT model)"),A_e.forEach(r),$Ve=i(M),nh=n(M,"LI",{});var x_e=s(nh);JW=n(x_e,"STRONG",{});var o5t=s(JW);IVe=t(o5t,"roberta"),o5t.forEach(r),jVe=t(x_e," \u2014 "),jL=n(x_e,"A",{href:!0});var t5t=s(jL);NVe=t(t5t,"RobertaModel"),t5t.forEach(r),DVe=t(x_e," (RoBERTa model)"),x_e.forEach(r),GVe=i(M),sh=n(M,"LI",{});var L_e=s(sh);KW=n(L_e,"STRONG",{});var r5t=s(KW);OVe=t(r5t,"roformer"),r5t.forEach(r),qVe=t(L_e," \u2014 "),NL=n(L_e,"A",{href:!0});var a5t=s(NL);zVe=t(a5t,"RoFormerModel"),a5t.forEach(r),XVe=t(L_e," (RoFormer model)"),L_e.forEach(r),WVe=i(M),lh=n(M,"LI",{});var B_e=s(lh);YW=n(B_e,"STRONG",{});var n5t=s(YW);VVe=t(n5t,"segformer"),n5t.forEach(r),QVe=t(B_e," \u2014 "),DL=n(B_e,"A",{href:!0});var s5t=s(DL);HVe=t(s5t,"SegformerModel"),s5t.forEach(r),UVe=t(B_e," (SegFormer model)"),B_e.forEach(r),JVe=i(M),ih=n(M,"LI",{});var k_e=s(ih);ZW=n(k_e,"STRONG",{});var l5t=s(ZW);KVe=t(l5t,"sew"),l5t.forEach(r),YVe=t(k_e," \u2014 "),GL=n(k_e,"A",{href:!0});var i5t=s(GL);ZVe=t(i5t,"SEWModel"),i5t.forEach(r),eQe=t(k_e," (SEW model)"),k_e.forEach(r),oQe=i(M),dh=n(M,"LI",{});var R_e=s(dh);eV=n(R_e,"STRONG",{});var d5t=s(eV);tQe=t(d5t,"sew-d"),d5t.forEach(r),rQe=t(R_e," \u2014 "),OL=n(R_e,"A",{href:!0});var m5t=s(OL);aQe=t(m5t,"SEWDModel"),m5t.forEach(r),nQe=t(R_e," (SEW-D model)"),R_e.forEach(r),sQe=i(M),mh=n(M,"LI",{});var S_e=s(mh);oV=n(S_e,"STRONG",{});var f5t=s(oV);lQe=t(f5t,"speech_to_text"),f5t.forEach(r),iQe=t(S_e," \u2014 "),qL=n(S_e,"A",{href:!0});var c5t=s(qL);dQe=t(c5t,"Speech2TextModel"),c5t.forEach(r),mQe=t(S_e," (Speech2Text model)"),S_e.forEach(r),fQe=i(M),fh=n(M,"LI",{});var P_e=s(fh);tV=n(P_e,"STRONG",{});var g5t=s(tV);cQe=t(g5t,"splinter"),g5t.forEach(r),gQe=t(P_e," \u2014 "),zL=n(P_e,"A",{href:!0});var h5t=s(zL);hQe=t(h5t,"SplinterModel"),h5t.forEach(r),uQe=t(P_e," (Splinter model)"),P_e.forEach(r),pQe=i(M),ch=n(M,"LI",{});var $_e=s(ch);rV=n($_e,"STRONG",{});var u5t=s(rV);_Qe=t(u5t,"squeezebert"),u5t.forEach(r),vQe=t($_e," \u2014 "),XL=n($_e,"A",{href:!0});var p5t=s(XL);bQe=t(p5t,"SqueezeBertModel"),p5t.forEach(r),TQe=t($_e," (SqueezeBERT model)"),$_e.forEach(r),FQe=i(M),gh=n(M,"LI",{});var I_e=s(gh);aV=n(I_e,"STRONG",{});var _5t=s(aV);MQe=t(_5t,"t5"),_5t.forEach(r),EQe=t(I_e," \u2014 "),WL=n(I_e,"A",{href:!0});var v5t=s(WL);CQe=t(v5t,"T5Model"),v5t.forEach(r),yQe=t(I_e," (T5 model)"),I_e.forEach(r),wQe=i(M),hh=n(M,"LI",{});var j_e=s(hh);nV=n(j_e,"STRONG",{});var b5t=s(nV);AQe=t(b5t,"tapas"),b5t.forEach(r),xQe=t(j_e," \u2014 "),VL=n(j_e,"A",{href:!0});var T5t=s(VL);LQe=t(T5t,"TapasModel"),T5t.forEach(r),BQe=t(j_e," (TAPAS model)"),j_e.forEach(r),kQe=i(M),uh=n(M,"LI",{});var N_e=s(uh);sV=n(N_e,"STRONG",{});var F5t=s(sV);RQe=t(F5t,"transfo-xl"),F5t.forEach(r),SQe=t(N_e," \u2014 "),QL=n(N_e,"A",{href:!0});var M5t=s(QL);PQe=t(M5t,"TransfoXLModel"),M5t.forEach(r),$Qe=t(N_e," (Transformer-XL model)"),N_e.forEach(r),IQe=i(M),ph=n(M,"LI",{});var D_e=s(ph);lV=n(D_e,"STRONG",{});var E5t=s(lV);jQe=t(E5t,"unispeech"),E5t.forEach(r),NQe=t(D_e," \u2014 "),HL=n(D_e,"A",{href:!0});var C5t=s(HL);DQe=t(C5t,"UniSpeechModel"),C5t.forEach(r),GQe=t(D_e," (UniSpeech model)"),D_e.forEach(r),OQe=i(M),_h=n(M,"LI",{});var G_e=s(_h);iV=n(G_e,"STRONG",{});var y5t=s(iV);qQe=t(y5t,"unispeech-sat"),y5t.forEach(r),zQe=t(G_e," \u2014 "),UL=n(G_e,"A",{href:!0});var w5t=s(UL);XQe=t(w5t,"UniSpeechSatModel"),w5t.forEach(r),WQe=t(G_e," (UniSpeechSat model)"),G_e.forEach(r),VQe=i(M),vh=n(M,"LI",{});var O_e=s(vh);dV=n(O_e,"STRONG",{});var A5t=s(dV);QQe=t(A5t,"vision-text-dual-encoder"),A5t.forEach(r),HQe=t(O_e," \u2014 "),JL=n(O_e,"A",{href:!0});var x5t=s(JL);UQe=t(x5t,"VisionTextDualEncoderModel"),x5t.forEach(r),JQe=t(O_e," (VisionTextDualEncoder model)"),O_e.forEach(r),KQe=i(M),bh=n(M,"LI",{});var q_e=s(bh);mV=n(q_e,"STRONG",{});var L5t=s(mV);YQe=t(L5t,"visual_bert"),L5t.forEach(r),ZQe=t(q_e," \u2014 "),KL=n(q_e,"A",{href:!0});var B5t=s(KL);eHe=t(B5t,"VisualBertModel"),B5t.forEach(r),oHe=t(q_e," (VisualBert model)"),q_e.forEach(r),tHe=i(M),Th=n(M,"LI",{});var z_e=s(Th);fV=n(z_e,"STRONG",{});var k5t=s(fV);rHe=t(k5t,"vit"),k5t.forEach(r),aHe=t(z_e," \u2014 "),YL=n(z_e,"A",{href:!0});var R5t=s(YL);nHe=t(R5t,"ViTModel"),R5t.forEach(r),sHe=t(z_e," (ViT model)"),z_e.forEach(r),lHe=i(M),Fh=n(M,"LI",{});var X_e=s(Fh);cV=n(X_e,"STRONG",{});var S5t=s(cV);iHe=t(S5t,"wav2vec2"),S5t.forEach(r),dHe=t(X_e," \u2014 "),ZL=n(X_e,"A",{href:!0});var P5t=s(ZL);mHe=t(P5t,"Wav2Vec2Model"),P5t.forEach(r),fHe=t(X_e," (Wav2Vec2 model)"),X_e.forEach(r),cHe=i(M),Mh=n(M,"LI",{});var W_e=s(Mh);gV=n(W_e,"STRONG",{});var $5t=s(gV);gHe=t($5t,"wavlm"),$5t.forEach(r),hHe=t(W_e," \u2014 "),eB=n(W_e,"A",{href:!0});var I5t=s(eB);uHe=t(I5t,"WavLMModel"),I5t.forEach(r),pHe=t(W_e," (WavLM model)"),W_e.forEach(r),_He=i(M),Eh=n(M,"LI",{});var V_e=s(Eh);hV=n(V_e,"STRONG",{});var j5t=s(hV);vHe=t(j5t,"xlm"),j5t.forEach(r),bHe=t(V_e," \u2014 "),oB=n(V_e,"A",{href:!0});var N5t=s(oB);THe=t(N5t,"XLMModel"),N5t.forEach(r),FHe=t(V_e," (XLM model)"),V_e.forEach(r),MHe=i(M),Ch=n(M,"LI",{});var Q_e=s(Ch);uV=n(Q_e,"STRONG",{});var D5t=s(uV);EHe=t(D5t,"xlm-prophetnet"),D5t.forEach(r),CHe=t(Q_e," \u2014 "),tB=n(Q_e,"A",{href:!0});var G5t=s(tB);yHe=t(G5t,"XLMProphetNetModel"),G5t.forEach(r),wHe=t(Q_e," (XLMProphetNet model)"),Q_e.forEach(r),AHe=i(M),yh=n(M,"LI",{});var H_e=s(yh);pV=n(H_e,"STRONG",{});var O5t=s(pV);xHe=t(O5t,"xlm-roberta"),O5t.forEach(r),LHe=t(H_e," \u2014 "),rB=n(H_e,"A",{href:!0});var q5t=s(rB);BHe=t(q5t,"XLMRobertaModel"),q5t.forEach(r),kHe=t(H_e," (XLM-RoBERTa model)"),H_e.forEach(r),RHe=i(M),wh=n(M,"LI",{});var U_e=s(wh);_V=n(U_e,"STRONG",{});var z5t=s(_V);SHe=t(z5t,"xlnet"),z5t.forEach(r),PHe=t(U_e," \u2014 "),aB=n(U_e,"A",{href:!0});var X5t=s(aB);$He=t(X5t,"XLNetModel"),X5t.forEach(r),IHe=t(U_e," (XLNet model)"),U_e.forEach(r),M.forEach(r),jHe=i(vr),Ah=n(vr,"P",{});var J_e=s(Ah);NHe=t(J_e,"The model is set in evaluation mode by default using "),vV=n(J_e,"EM",{});var W5t=s(vV);DHe=t(W5t,"model.eval()"),W5t.forEach(r),GHe=t(J_e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bV=n(J_e,"EM",{});var V5t=s(bV);OHe=t(V5t,"model.train()"),V5t.forEach(r),J_e.forEach(r),qHe=i(vr),TV=n(vr,"P",{});var Q5t=s(TV);zHe=t(Q5t,"Examples:"),Q5t.forEach(r),XHe=i(vr),c(pM.$$.fragment,vr),vr.forEach(r),cs.forEach(r),PEe=i(d),di=n(d,"H2",{class:!0});var k3e=s(di);xh=n(k3e,"A",{id:!0,class:!0,href:!0});var H5t=s(xh);FV=n(H5t,"SPAN",{});var U5t=s(FV);c(_M.$$.fragment,U5t),U5t.forEach(r),H5t.forEach(r),WHe=i(k3e),MV=n(k3e,"SPAN",{});var J5t=s(MV);VHe=t(J5t,"AutoModelForPreTraining"),J5t.forEach(r),k3e.forEach(r),$Ee=i(d),$o=n(d,"DIV",{class:!0});var hs=s($o);c(vM.$$.fragment,hs),QHe=i(hs),mi=n(hs,"P",{});var bD=s(mi);HHe=t(bD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EV=n(bD,"CODE",{});var K5t=s(EV);UHe=t(K5t,"from_pretrained()"),K5t.forEach(r),JHe=t(bD,` class method or the
`),CV=n(bD,"CODE",{});var Y5t=s(CV);KHe=t(Y5t,"from_config()"),Y5t.forEach(r),YHe=t(bD," class method."),bD.forEach(r),ZHe=i(hs),bM=n(hs,"P",{});var R3e=s(bM);eUe=t(R3e,"This class cannot be instantiated directly using "),yV=n(R3e,"CODE",{});var Z5t=s(yV);oUe=t(Z5t,"__init__()"),Z5t.forEach(r),tUe=t(R3e," (throws an error)."),R3e.forEach(r),rUe=i(hs),At=n(hs,"DIV",{class:!0});var us=s(At);c(TM.$$.fragment,us),aUe=i(us),wV=n(us,"P",{});var e0t=s(wV);nUe=t(e0t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),e0t.forEach(r),sUe=i(us),fi=n(us,"P",{});var TD=s(fi);lUe=t(TD,`Note:
Loading a model from its configuration file does `),AV=n(TD,"STRONG",{});var o0t=s(AV);iUe=t(o0t,"not"),o0t.forEach(r),dUe=t(TD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),xV=n(TD,"EM",{});var t0t=s(xV);mUe=t(t0t,"~AutoModelForPreTraining.from_pretrained"),t0t.forEach(r),fUe=t(TD,`] to load the model
weights.`),TD.forEach(r),cUe=i(us),LV=n(us,"P",{});var r0t=s(LV);gUe=t(r0t,"Examples:"),r0t.forEach(r),hUe=i(us),c(FM.$$.fragment,us),us.forEach(r),uUe=i(hs),Le=n(hs,"DIV",{class:!0});var br=s(Le);c(MM.$$.fragment,br),pUe=i(br),BV=n(br,"P",{});var a0t=s(BV);_Ue=t(a0t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),a0t.forEach(r),vUe=i(br),Ca=n(br,"P",{});var XT=s(Ca);bUe=t(XT,"The model class to instantiate is selected based on the "),kV=n(XT,"EM",{});var n0t=s(kV);TUe=t(n0t,"model_type"),n0t.forEach(r),FUe=t(XT,` property of the config object (either
passed as an argument or loaded from `),RV=n(XT,"EM",{});var s0t=s(RV);MUe=t(s0t,"pretrained_model_name_or_path"),s0t.forEach(r),EUe=t(XT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),SV=n(XT,"EM",{});var l0t=s(SV);CUe=t(l0t,"pretrained_model_name_or_path"),l0t.forEach(r),yUe=t(XT,":"),XT.forEach(r),wUe=i(br),k=n(br,"UL",{});var S=s(k);Lh=n(S,"LI",{});var K_e=s(Lh);PV=n(K_e,"STRONG",{});var i0t=s(PV);AUe=t(i0t,"albert"),i0t.forEach(r),xUe=t(K_e," \u2014 "),nB=n(K_e,"A",{href:!0});var d0t=s(nB);LUe=t(d0t,"AlbertForPreTraining"),d0t.forEach(r),BUe=t(K_e," (ALBERT model)"),K_e.forEach(r),kUe=i(S),Bh=n(S,"LI",{});var Y_e=s(Bh);$V=n(Y_e,"STRONG",{});var m0t=s($V);RUe=t(m0t,"bart"),m0t.forEach(r),SUe=t(Y_e," \u2014 "),sB=n(Y_e,"A",{href:!0});var f0t=s(sB);PUe=t(f0t,"BartForConditionalGeneration"),f0t.forEach(r),$Ue=t(Y_e," (BART model)"),Y_e.forEach(r),IUe=i(S),kh=n(S,"LI",{});var Z_e=s(kh);IV=n(Z_e,"STRONG",{});var c0t=s(IV);jUe=t(c0t,"bert"),c0t.forEach(r),NUe=t(Z_e," \u2014 "),lB=n(Z_e,"A",{href:!0});var g0t=s(lB);DUe=t(g0t,"BertForPreTraining"),g0t.forEach(r),GUe=t(Z_e," (BERT model)"),Z_e.forEach(r),OUe=i(S),Rh=n(S,"LI",{});var eve=s(Rh);jV=n(eve,"STRONG",{});var h0t=s(jV);qUe=t(h0t,"big_bird"),h0t.forEach(r),zUe=t(eve," \u2014 "),iB=n(eve,"A",{href:!0});var u0t=s(iB);XUe=t(u0t,"BigBirdForPreTraining"),u0t.forEach(r),WUe=t(eve," (BigBird model)"),eve.forEach(r),VUe=i(S),Sh=n(S,"LI",{});var ove=s(Sh);NV=n(ove,"STRONG",{});var p0t=s(NV);QUe=t(p0t,"camembert"),p0t.forEach(r),HUe=t(ove," \u2014 "),dB=n(ove,"A",{href:!0});var _0t=s(dB);UUe=t(_0t,"CamembertForMaskedLM"),_0t.forEach(r),JUe=t(ove," (CamemBERT model)"),ove.forEach(r),KUe=i(S),Ph=n(S,"LI",{});var tve=s(Ph);DV=n(tve,"STRONG",{});var v0t=s(DV);YUe=t(v0t,"ctrl"),v0t.forEach(r),ZUe=t(tve," \u2014 "),mB=n(tve,"A",{href:!0});var b0t=s(mB);eJe=t(b0t,"CTRLLMHeadModel"),b0t.forEach(r),oJe=t(tve," (CTRL model)"),tve.forEach(r),tJe=i(S),$h=n(S,"LI",{});var rve=s($h);GV=n(rve,"STRONG",{});var T0t=s(GV);rJe=t(T0t,"deberta"),T0t.forEach(r),aJe=t(rve," \u2014 "),fB=n(rve,"A",{href:!0});var F0t=s(fB);nJe=t(F0t,"DebertaForMaskedLM"),F0t.forEach(r),sJe=t(rve," (DeBERTa model)"),rve.forEach(r),lJe=i(S),Ih=n(S,"LI",{});var ave=s(Ih);OV=n(ave,"STRONG",{});var M0t=s(OV);iJe=t(M0t,"deberta-v2"),M0t.forEach(r),dJe=t(ave," \u2014 "),cB=n(ave,"A",{href:!0});var E0t=s(cB);mJe=t(E0t,"DebertaV2ForMaskedLM"),E0t.forEach(r),fJe=t(ave," (DeBERTa-v2 model)"),ave.forEach(r),cJe=i(S),jh=n(S,"LI",{});var nve=s(jh);qV=n(nve,"STRONG",{});var C0t=s(qV);gJe=t(C0t,"distilbert"),C0t.forEach(r),hJe=t(nve," \u2014 "),gB=n(nve,"A",{href:!0});var y0t=s(gB);uJe=t(y0t,"DistilBertForMaskedLM"),y0t.forEach(r),pJe=t(nve," (DistilBERT model)"),nve.forEach(r),_Je=i(S),Nh=n(S,"LI",{});var sve=s(Nh);zV=n(sve,"STRONG",{});var w0t=s(zV);vJe=t(w0t,"electra"),w0t.forEach(r),bJe=t(sve," \u2014 "),hB=n(sve,"A",{href:!0});var A0t=s(hB);TJe=t(A0t,"ElectraForPreTraining"),A0t.forEach(r),FJe=t(sve," (ELECTRA model)"),sve.forEach(r),MJe=i(S),Dh=n(S,"LI",{});var lve=s(Dh);XV=n(lve,"STRONG",{});var x0t=s(XV);EJe=t(x0t,"flaubert"),x0t.forEach(r),CJe=t(lve," \u2014 "),uB=n(lve,"A",{href:!0});var L0t=s(uB);yJe=t(L0t,"FlaubertWithLMHeadModel"),L0t.forEach(r),wJe=t(lve," (FlauBERT model)"),lve.forEach(r),AJe=i(S),Gh=n(S,"LI",{});var ive=s(Gh);WV=n(ive,"STRONG",{});var B0t=s(WV);xJe=t(B0t,"fnet"),B0t.forEach(r),LJe=t(ive," \u2014 "),pB=n(ive,"A",{href:!0});var k0t=s(pB);BJe=t(k0t,"FNetForPreTraining"),k0t.forEach(r),kJe=t(ive," (FNet model)"),ive.forEach(r),RJe=i(S),Oh=n(S,"LI",{});var dve=s(Oh);VV=n(dve,"STRONG",{});var R0t=s(VV);SJe=t(R0t,"fsmt"),R0t.forEach(r),PJe=t(dve," \u2014 "),_B=n(dve,"A",{href:!0});var S0t=s(_B);$Je=t(S0t,"FSMTForConditionalGeneration"),S0t.forEach(r),IJe=t(dve," (FairSeq Machine-Translation model)"),dve.forEach(r),jJe=i(S),qh=n(S,"LI",{});var mve=s(qh);QV=n(mve,"STRONG",{});var P0t=s(QV);NJe=t(P0t,"funnel"),P0t.forEach(r),DJe=t(mve," \u2014 "),vB=n(mve,"A",{href:!0});var $0t=s(vB);GJe=t($0t,"FunnelForPreTraining"),$0t.forEach(r),OJe=t(mve," (Funnel Transformer model)"),mve.forEach(r),qJe=i(S),zh=n(S,"LI",{});var fve=s(zh);HV=n(fve,"STRONG",{});var I0t=s(HV);zJe=t(I0t,"gpt2"),I0t.forEach(r),XJe=t(fve," \u2014 "),bB=n(fve,"A",{href:!0});var j0t=s(bB);WJe=t(j0t,"GPT2LMHeadModel"),j0t.forEach(r),VJe=t(fve," (OpenAI GPT-2 model)"),fve.forEach(r),QJe=i(S),Xh=n(S,"LI",{});var cve=s(Xh);UV=n(cve,"STRONG",{});var N0t=s(UV);HJe=t(N0t,"ibert"),N0t.forEach(r),UJe=t(cve," \u2014 "),TB=n(cve,"A",{href:!0});var D0t=s(TB);JJe=t(D0t,"IBertForMaskedLM"),D0t.forEach(r),KJe=t(cve," (I-BERT model)"),cve.forEach(r),YJe=i(S),Wh=n(S,"LI",{});var gve=s(Wh);JV=n(gve,"STRONG",{});var G0t=s(JV);ZJe=t(G0t,"layoutlm"),G0t.forEach(r),eKe=t(gve," \u2014 "),FB=n(gve,"A",{href:!0});var O0t=s(FB);oKe=t(O0t,"LayoutLMForMaskedLM"),O0t.forEach(r),tKe=t(gve," (LayoutLM model)"),gve.forEach(r),rKe=i(S),Vh=n(S,"LI",{});var hve=s(Vh);KV=n(hve,"STRONG",{});var q0t=s(KV);aKe=t(q0t,"longformer"),q0t.forEach(r),nKe=t(hve," \u2014 "),MB=n(hve,"A",{href:!0});var z0t=s(MB);sKe=t(z0t,"LongformerForMaskedLM"),z0t.forEach(r),lKe=t(hve," (Longformer model)"),hve.forEach(r),iKe=i(S),Qh=n(S,"LI",{});var uve=s(Qh);YV=n(uve,"STRONG",{});var X0t=s(YV);dKe=t(X0t,"lxmert"),X0t.forEach(r),mKe=t(uve," \u2014 "),EB=n(uve,"A",{href:!0});var W0t=s(EB);fKe=t(W0t,"LxmertForPreTraining"),W0t.forEach(r),cKe=t(uve," (LXMERT model)"),uve.forEach(r),gKe=i(S),Hh=n(S,"LI",{});var pve=s(Hh);ZV=n(pve,"STRONG",{});var V0t=s(ZV);hKe=t(V0t,"megatron-bert"),V0t.forEach(r),uKe=t(pve," \u2014 "),CB=n(pve,"A",{href:!0});var Q0t=s(CB);pKe=t(Q0t,"MegatronBertForPreTraining"),Q0t.forEach(r),_Ke=t(pve," (MegatronBert model)"),pve.forEach(r),vKe=i(S),Uh=n(S,"LI",{});var _ve=s(Uh);eQ=n(_ve,"STRONG",{});var H0t=s(eQ);bKe=t(H0t,"mobilebert"),H0t.forEach(r),TKe=t(_ve," \u2014 "),yB=n(_ve,"A",{href:!0});var U0t=s(yB);FKe=t(U0t,"MobileBertForPreTraining"),U0t.forEach(r),MKe=t(_ve," (MobileBERT model)"),_ve.forEach(r),EKe=i(S),Jh=n(S,"LI",{});var vve=s(Jh);oQ=n(vve,"STRONG",{});var J0t=s(oQ);CKe=t(J0t,"mpnet"),J0t.forEach(r),yKe=t(vve," \u2014 "),wB=n(vve,"A",{href:!0});var K0t=s(wB);wKe=t(K0t,"MPNetForMaskedLM"),K0t.forEach(r),AKe=t(vve," (MPNet model)"),vve.forEach(r),xKe=i(S),Kh=n(S,"LI",{});var bve=s(Kh);tQ=n(bve,"STRONG",{});var Y0t=s(tQ);LKe=t(Y0t,"openai-gpt"),Y0t.forEach(r),BKe=t(bve," \u2014 "),AB=n(bve,"A",{href:!0});var Z0t=s(AB);kKe=t(Z0t,"OpenAIGPTLMHeadModel"),Z0t.forEach(r),RKe=t(bve," (OpenAI GPT model)"),bve.forEach(r),SKe=i(S),Yh=n(S,"LI",{});var Tve=s(Yh);rQ=n(Tve,"STRONG",{});var eTt=s(rQ);PKe=t(eTt,"retribert"),eTt.forEach(r),$Ke=t(Tve," \u2014 "),xB=n(Tve,"A",{href:!0});var oTt=s(xB);IKe=t(oTt,"RetriBertModel"),oTt.forEach(r),jKe=t(Tve," (RetriBERT model)"),Tve.forEach(r),NKe=i(S),Zh=n(S,"LI",{});var Fve=s(Zh);aQ=n(Fve,"STRONG",{});var tTt=s(aQ);DKe=t(tTt,"roberta"),tTt.forEach(r),GKe=t(Fve," \u2014 "),LB=n(Fve,"A",{href:!0});var rTt=s(LB);OKe=t(rTt,"RobertaForMaskedLM"),rTt.forEach(r),qKe=t(Fve," (RoBERTa model)"),Fve.forEach(r),zKe=i(S),eu=n(S,"LI",{});var Mve=s(eu);nQ=n(Mve,"STRONG",{});var aTt=s(nQ);XKe=t(aTt,"squeezebert"),aTt.forEach(r),WKe=t(Mve," \u2014 "),BB=n(Mve,"A",{href:!0});var nTt=s(BB);VKe=t(nTt,"SqueezeBertForMaskedLM"),nTt.forEach(r),QKe=t(Mve," (SqueezeBERT model)"),Mve.forEach(r),HKe=i(S),ou=n(S,"LI",{});var Eve=s(ou);sQ=n(Eve,"STRONG",{});var sTt=s(sQ);UKe=t(sTt,"t5"),sTt.forEach(r),JKe=t(Eve," \u2014 "),kB=n(Eve,"A",{href:!0});var lTt=s(kB);KKe=t(lTt,"T5ForConditionalGeneration"),lTt.forEach(r),YKe=t(Eve," (T5 model)"),Eve.forEach(r),ZKe=i(S),tu=n(S,"LI",{});var Cve=s(tu);lQ=n(Cve,"STRONG",{});var iTt=s(lQ);eYe=t(iTt,"tapas"),iTt.forEach(r),oYe=t(Cve," \u2014 "),RB=n(Cve,"A",{href:!0});var dTt=s(RB);tYe=t(dTt,"TapasForMaskedLM"),dTt.forEach(r),rYe=t(Cve," (TAPAS model)"),Cve.forEach(r),aYe=i(S),ru=n(S,"LI",{});var yve=s(ru);iQ=n(yve,"STRONG",{});var mTt=s(iQ);nYe=t(mTt,"transfo-xl"),mTt.forEach(r),sYe=t(yve," \u2014 "),SB=n(yve,"A",{href:!0});var fTt=s(SB);lYe=t(fTt,"TransfoXLLMHeadModel"),fTt.forEach(r),iYe=t(yve," (Transformer-XL model)"),yve.forEach(r),dYe=i(S),au=n(S,"LI",{});var wve=s(au);dQ=n(wve,"STRONG",{});var cTt=s(dQ);mYe=t(cTt,"unispeech"),cTt.forEach(r),fYe=t(wve," \u2014 "),PB=n(wve,"A",{href:!0});var gTt=s(PB);cYe=t(gTt,"UniSpeechForPreTraining"),gTt.forEach(r),gYe=t(wve," (UniSpeech model)"),wve.forEach(r),hYe=i(S),nu=n(S,"LI",{});var Ave=s(nu);mQ=n(Ave,"STRONG",{});var hTt=s(mQ);uYe=t(hTt,"unispeech-sat"),hTt.forEach(r),pYe=t(Ave," \u2014 "),$B=n(Ave,"A",{href:!0});var uTt=s($B);_Ye=t(uTt,"UniSpeechSatForPreTraining"),uTt.forEach(r),vYe=t(Ave," (UniSpeechSat model)"),Ave.forEach(r),bYe=i(S),su=n(S,"LI",{});var xve=s(su);fQ=n(xve,"STRONG",{});var pTt=s(fQ);TYe=t(pTt,"visual_bert"),pTt.forEach(r),FYe=t(xve," \u2014 "),IB=n(xve,"A",{href:!0});var _Tt=s(IB);MYe=t(_Tt,"VisualBertForPreTraining"),_Tt.forEach(r),EYe=t(xve," (VisualBert model)"),xve.forEach(r),CYe=i(S),lu=n(S,"LI",{});var Lve=s(lu);cQ=n(Lve,"STRONG",{});var vTt=s(cQ);yYe=t(vTt,"wav2vec2"),vTt.forEach(r),wYe=t(Lve," \u2014 "),jB=n(Lve,"A",{href:!0});var bTt=s(jB);AYe=t(bTt,"Wav2Vec2ForPreTraining"),bTt.forEach(r),xYe=t(Lve," (Wav2Vec2 model)"),Lve.forEach(r),LYe=i(S),iu=n(S,"LI",{});var Bve=s(iu);gQ=n(Bve,"STRONG",{});var TTt=s(gQ);BYe=t(TTt,"xlm"),TTt.forEach(r),kYe=t(Bve," \u2014 "),NB=n(Bve,"A",{href:!0});var FTt=s(NB);RYe=t(FTt,"XLMWithLMHeadModel"),FTt.forEach(r),SYe=t(Bve," (XLM model)"),Bve.forEach(r),PYe=i(S),du=n(S,"LI",{});var kve=s(du);hQ=n(kve,"STRONG",{});var MTt=s(hQ);$Ye=t(MTt,"xlm-roberta"),MTt.forEach(r),IYe=t(kve," \u2014 "),DB=n(kve,"A",{href:!0});var ETt=s(DB);jYe=t(ETt,"XLMRobertaForMaskedLM"),ETt.forEach(r),NYe=t(kve," (XLM-RoBERTa model)"),kve.forEach(r),DYe=i(S),mu=n(S,"LI",{});var Rve=s(mu);uQ=n(Rve,"STRONG",{});var CTt=s(uQ);GYe=t(CTt,"xlnet"),CTt.forEach(r),OYe=t(Rve," \u2014 "),GB=n(Rve,"A",{href:!0});var yTt=s(GB);qYe=t(yTt,"XLNetLMHeadModel"),yTt.forEach(r),zYe=t(Rve," (XLNet model)"),Rve.forEach(r),S.forEach(r),XYe=i(br),fu=n(br,"P",{});var Sve=s(fu);WYe=t(Sve,"The model is set in evaluation mode by default using "),pQ=n(Sve,"EM",{});var wTt=s(pQ);VYe=t(wTt,"model.eval()"),wTt.forEach(r),QYe=t(Sve,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Q=n(Sve,"EM",{});var ATt=s(_Q);HYe=t(ATt,"model.train()"),ATt.forEach(r),Sve.forEach(r),UYe=i(br),vQ=n(br,"P",{});var xTt=s(vQ);JYe=t(xTt,"Examples:"),xTt.forEach(r),KYe=i(br),c(EM.$$.fragment,br),br.forEach(r),hs.forEach(r),IEe=i(d),ci=n(d,"H2",{class:!0});var S3e=s(ci);cu=n(S3e,"A",{id:!0,class:!0,href:!0});var LTt=s(cu);bQ=n(LTt,"SPAN",{});var BTt=s(bQ);c(CM.$$.fragment,BTt),BTt.forEach(r),LTt.forEach(r),YYe=i(S3e),TQ=n(S3e,"SPAN",{});var kTt=s(TQ);ZYe=t(kTt,"AutoModelForCausalLM"),kTt.forEach(r),S3e.forEach(r),jEe=i(d),Io=n(d,"DIV",{class:!0});var ps=s(Io);c(yM.$$.fragment,ps),eZe=i(ps),gi=n(ps,"P",{});var FD=s(gi);oZe=t(FD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),FQ=n(FD,"CODE",{});var RTt=s(FQ);tZe=t(RTt,"from_pretrained()"),RTt.forEach(r),rZe=t(FD,` class method or the
`),MQ=n(FD,"CODE",{});var STt=s(MQ);aZe=t(STt,"from_config()"),STt.forEach(r),nZe=t(FD," class method."),FD.forEach(r),sZe=i(ps),wM=n(ps,"P",{});var P3e=s(wM);lZe=t(P3e,"This class cannot be instantiated directly using "),EQ=n(P3e,"CODE",{});var PTt=s(EQ);iZe=t(PTt,"__init__()"),PTt.forEach(r),dZe=t(P3e," (throws an error)."),P3e.forEach(r),mZe=i(ps),xt=n(ps,"DIV",{class:!0});var _s=s(xt);c(AM.$$.fragment,_s),fZe=i(_s),CQ=n(_s,"P",{});var $Tt=s(CQ);cZe=t($Tt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$Tt.forEach(r),gZe=i(_s),hi=n(_s,"P",{});var MD=s(hi);hZe=t(MD,`Note:
Loading a model from its configuration file does `),yQ=n(MD,"STRONG",{});var ITt=s(yQ);uZe=t(ITt,"not"),ITt.forEach(r),pZe=t(MD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),wQ=n(MD,"EM",{});var jTt=s(wQ);_Ze=t(jTt,"~AutoModelForCausalLM.from_pretrained"),jTt.forEach(r),vZe=t(MD,`] to load the model
weights.`),MD.forEach(r),bZe=i(_s),AQ=n(_s,"P",{});var NTt=s(AQ);TZe=t(NTt,"Examples:"),NTt.forEach(r),FZe=i(_s),c(xM.$$.fragment,_s),_s.forEach(r),MZe=i(ps),Be=n(ps,"DIV",{class:!0});var Tr=s(Be);c(LM.$$.fragment,Tr),EZe=i(Tr),xQ=n(Tr,"P",{});var DTt=s(xQ);CZe=t(DTt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),DTt.forEach(r),yZe=i(Tr),ya=n(Tr,"P",{});var WT=s(ya);wZe=t(WT,"The model class to instantiate is selected based on the "),LQ=n(WT,"EM",{});var GTt=s(LQ);AZe=t(GTt,"model_type"),GTt.forEach(r),xZe=t(WT,` property of the config object (either
passed as an argument or loaded from `),BQ=n(WT,"EM",{});var OTt=s(BQ);LZe=t(OTt,"pretrained_model_name_or_path"),OTt.forEach(r),BZe=t(WT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),kQ=n(WT,"EM",{});var qTt=s(kQ);kZe=t(qTt,"pretrained_model_name_or_path"),qTt.forEach(r),RZe=t(WT,":"),WT.forEach(r),SZe=i(Tr),I=n(Tr,"UL",{});var D=s(I);gu=n(D,"LI",{});var Pve=s(gu);RQ=n(Pve,"STRONG",{});var zTt=s(RQ);PZe=t(zTt,"bart"),zTt.forEach(r),$Ze=t(Pve," \u2014 "),OB=n(Pve,"A",{href:!0});var XTt=s(OB);IZe=t(XTt,"BartForCausalLM"),XTt.forEach(r),jZe=t(Pve," (BART model)"),Pve.forEach(r),NZe=i(D),hu=n(D,"LI",{});var $ve=s(hu);SQ=n($ve,"STRONG",{});var WTt=s(SQ);DZe=t(WTt,"bert"),WTt.forEach(r),GZe=t($ve," \u2014 "),qB=n($ve,"A",{href:!0});var VTt=s(qB);OZe=t(VTt,"BertLMHeadModel"),VTt.forEach(r),qZe=t($ve," (BERT model)"),$ve.forEach(r),zZe=i(D),uu=n(D,"LI",{});var Ive=s(uu);PQ=n(Ive,"STRONG",{});var QTt=s(PQ);XZe=t(QTt,"bert-generation"),QTt.forEach(r),WZe=t(Ive," \u2014 "),zB=n(Ive,"A",{href:!0});var HTt=s(zB);VZe=t(HTt,"BertGenerationDecoder"),HTt.forEach(r),QZe=t(Ive," (Bert Generation model)"),Ive.forEach(r),HZe=i(D),pu=n(D,"LI",{});var jve=s(pu);$Q=n(jve,"STRONG",{});var UTt=s($Q);UZe=t(UTt,"big_bird"),UTt.forEach(r),JZe=t(jve," \u2014 "),XB=n(jve,"A",{href:!0});var JTt=s(XB);KZe=t(JTt,"BigBirdForCausalLM"),JTt.forEach(r),YZe=t(jve," (BigBird model)"),jve.forEach(r),ZZe=i(D),_u=n(D,"LI",{});var Nve=s(_u);IQ=n(Nve,"STRONG",{});var KTt=s(IQ);eeo=t(KTt,"bigbird_pegasus"),KTt.forEach(r),oeo=t(Nve," \u2014 "),WB=n(Nve,"A",{href:!0});var YTt=s(WB);teo=t(YTt,"BigBirdPegasusForCausalLM"),YTt.forEach(r),reo=t(Nve," (BigBirdPegasus model)"),Nve.forEach(r),aeo=i(D),vu=n(D,"LI",{});var Dve=s(vu);jQ=n(Dve,"STRONG",{});var ZTt=s(jQ);neo=t(ZTt,"blenderbot"),ZTt.forEach(r),seo=t(Dve," \u2014 "),VB=n(Dve,"A",{href:!0});var eFt=s(VB);leo=t(eFt,"BlenderbotForCausalLM"),eFt.forEach(r),ieo=t(Dve," (Blenderbot model)"),Dve.forEach(r),deo=i(D),bu=n(D,"LI",{});var Gve=s(bu);NQ=n(Gve,"STRONG",{});var oFt=s(NQ);meo=t(oFt,"blenderbot-small"),oFt.forEach(r),feo=t(Gve," \u2014 "),QB=n(Gve,"A",{href:!0});var tFt=s(QB);ceo=t(tFt,"BlenderbotSmallForCausalLM"),tFt.forEach(r),geo=t(Gve," (BlenderbotSmall model)"),Gve.forEach(r),heo=i(D),Tu=n(D,"LI",{});var Ove=s(Tu);DQ=n(Ove,"STRONG",{});var rFt=s(DQ);ueo=t(rFt,"camembert"),rFt.forEach(r),peo=t(Ove," \u2014 "),HB=n(Ove,"A",{href:!0});var aFt=s(HB);_eo=t(aFt,"CamembertForCausalLM"),aFt.forEach(r),veo=t(Ove," (CamemBERT model)"),Ove.forEach(r),beo=i(D),Fu=n(D,"LI",{});var qve=s(Fu);GQ=n(qve,"STRONG",{});var nFt=s(GQ);Teo=t(nFt,"ctrl"),nFt.forEach(r),Feo=t(qve," \u2014 "),UB=n(qve,"A",{href:!0});var sFt=s(UB);Meo=t(sFt,"CTRLLMHeadModel"),sFt.forEach(r),Eeo=t(qve," (CTRL model)"),qve.forEach(r),Ceo=i(D),Mu=n(D,"LI",{});var zve=s(Mu);OQ=n(zve,"STRONG",{});var lFt=s(OQ);yeo=t(lFt,"gpt2"),lFt.forEach(r),weo=t(zve," \u2014 "),JB=n(zve,"A",{href:!0});var iFt=s(JB);Aeo=t(iFt,"GPT2LMHeadModel"),iFt.forEach(r),xeo=t(zve," (OpenAI GPT-2 model)"),zve.forEach(r),Leo=i(D),Eu=n(D,"LI",{});var Xve=s(Eu);qQ=n(Xve,"STRONG",{});var dFt=s(qQ);Beo=t(dFt,"gpt_neo"),dFt.forEach(r),keo=t(Xve," \u2014 "),KB=n(Xve,"A",{href:!0});var mFt=s(KB);Reo=t(mFt,"GPTNeoForCausalLM"),mFt.forEach(r),Seo=t(Xve," (GPT Neo model)"),Xve.forEach(r),Peo=i(D),Cu=n(D,"LI",{});var Wve=s(Cu);zQ=n(Wve,"STRONG",{});var fFt=s(zQ);$eo=t(fFt,"gptj"),fFt.forEach(r),Ieo=t(Wve," \u2014 "),YB=n(Wve,"A",{href:!0});var cFt=s(YB);jeo=t(cFt,"GPTJForCausalLM"),cFt.forEach(r),Neo=t(Wve," (GPT-J model)"),Wve.forEach(r),Deo=i(D),yu=n(D,"LI",{});var Vve=s(yu);XQ=n(Vve,"STRONG",{});var gFt=s(XQ);Geo=t(gFt,"marian"),gFt.forEach(r),Oeo=t(Vve," \u2014 "),ZB=n(Vve,"A",{href:!0});var hFt=s(ZB);qeo=t(hFt,"MarianForCausalLM"),hFt.forEach(r),zeo=t(Vve," (Marian model)"),Vve.forEach(r),Xeo=i(D),wu=n(D,"LI",{});var Qve=s(wu);WQ=n(Qve,"STRONG",{});var uFt=s(WQ);Weo=t(uFt,"mbart"),uFt.forEach(r),Veo=t(Qve," \u2014 "),e9=n(Qve,"A",{href:!0});var pFt=s(e9);Qeo=t(pFt,"MBartForCausalLM"),pFt.forEach(r),Heo=t(Qve," (mBART model)"),Qve.forEach(r),Ueo=i(D),Au=n(D,"LI",{});var Hve=s(Au);VQ=n(Hve,"STRONG",{});var _Ft=s(VQ);Jeo=t(_Ft,"megatron-bert"),_Ft.forEach(r),Keo=t(Hve," \u2014 "),o9=n(Hve,"A",{href:!0});var vFt=s(o9);Yeo=t(vFt,"MegatronBertForCausalLM"),vFt.forEach(r),Zeo=t(Hve," (MegatronBert model)"),Hve.forEach(r),eoo=i(D),xu=n(D,"LI",{});var Uve=s(xu);QQ=n(Uve,"STRONG",{});var bFt=s(QQ);ooo=t(bFt,"openai-gpt"),bFt.forEach(r),too=t(Uve," \u2014 "),t9=n(Uve,"A",{href:!0});var TFt=s(t9);roo=t(TFt,"OpenAIGPTLMHeadModel"),TFt.forEach(r),aoo=t(Uve," (OpenAI GPT model)"),Uve.forEach(r),noo=i(D),Lu=n(D,"LI",{});var Jve=s(Lu);HQ=n(Jve,"STRONG",{});var FFt=s(HQ);soo=t(FFt,"pegasus"),FFt.forEach(r),loo=t(Jve," \u2014 "),r9=n(Jve,"A",{href:!0});var MFt=s(r9);ioo=t(MFt,"PegasusForCausalLM"),MFt.forEach(r),doo=t(Jve," (Pegasus model)"),Jve.forEach(r),moo=i(D),Bu=n(D,"LI",{});var Kve=s(Bu);UQ=n(Kve,"STRONG",{});var EFt=s(UQ);foo=t(EFt,"prophetnet"),EFt.forEach(r),coo=t(Kve," \u2014 "),a9=n(Kve,"A",{href:!0});var CFt=s(a9);goo=t(CFt,"ProphetNetForCausalLM"),CFt.forEach(r),hoo=t(Kve," (ProphetNet model)"),Kve.forEach(r),uoo=i(D),ku=n(D,"LI",{});var Yve=s(ku);JQ=n(Yve,"STRONG",{});var yFt=s(JQ);poo=t(yFt,"qdqbert"),yFt.forEach(r),_oo=t(Yve," \u2014 "),n9=n(Yve,"A",{href:!0});var wFt=s(n9);voo=t(wFt,"QDQBertLMHeadModel"),wFt.forEach(r),boo=t(Yve," (QDQBert model)"),Yve.forEach(r),Too=i(D),Ru=n(D,"LI",{});var Zve=s(Ru);KQ=n(Zve,"STRONG",{});var AFt=s(KQ);Foo=t(AFt,"reformer"),AFt.forEach(r),Moo=t(Zve," \u2014 "),s9=n(Zve,"A",{href:!0});var xFt=s(s9);Eoo=t(xFt,"ReformerModelWithLMHead"),xFt.forEach(r),Coo=t(Zve," (Reformer model)"),Zve.forEach(r),yoo=i(D),Su=n(D,"LI",{});var e1e=s(Su);YQ=n(e1e,"STRONG",{});var LFt=s(YQ);woo=t(LFt,"rembert"),LFt.forEach(r),Aoo=t(e1e," \u2014 "),l9=n(e1e,"A",{href:!0});var BFt=s(l9);xoo=t(BFt,"RemBertForCausalLM"),BFt.forEach(r),Loo=t(e1e," (RemBERT model)"),e1e.forEach(r),Boo=i(D),Pu=n(D,"LI",{});var o1e=s(Pu);ZQ=n(o1e,"STRONG",{});var kFt=s(ZQ);koo=t(kFt,"roberta"),kFt.forEach(r),Roo=t(o1e," \u2014 "),i9=n(o1e,"A",{href:!0});var RFt=s(i9);Soo=t(RFt,"RobertaForCausalLM"),RFt.forEach(r),Poo=t(o1e," (RoBERTa model)"),o1e.forEach(r),$oo=i(D),$u=n(D,"LI",{});var t1e=s($u);eH=n(t1e,"STRONG",{});var SFt=s(eH);Ioo=t(SFt,"roformer"),SFt.forEach(r),joo=t(t1e," \u2014 "),d9=n(t1e,"A",{href:!0});var PFt=s(d9);Noo=t(PFt,"RoFormerForCausalLM"),PFt.forEach(r),Doo=t(t1e," (RoFormer model)"),t1e.forEach(r),Goo=i(D),Iu=n(D,"LI",{});var r1e=s(Iu);oH=n(r1e,"STRONG",{});var $Ft=s(oH);Ooo=t($Ft,"speech_to_text_2"),$Ft.forEach(r),qoo=t(r1e," \u2014 "),m9=n(r1e,"A",{href:!0});var IFt=s(m9);zoo=t(IFt,"Speech2Text2ForCausalLM"),IFt.forEach(r),Xoo=t(r1e," (Speech2Text2 model)"),r1e.forEach(r),Woo=i(D),ju=n(D,"LI",{});var a1e=s(ju);tH=n(a1e,"STRONG",{});var jFt=s(tH);Voo=t(jFt,"transfo-xl"),jFt.forEach(r),Qoo=t(a1e," \u2014 "),f9=n(a1e,"A",{href:!0});var NFt=s(f9);Hoo=t(NFt,"TransfoXLLMHeadModel"),NFt.forEach(r),Uoo=t(a1e," (Transformer-XL model)"),a1e.forEach(r),Joo=i(D),Nu=n(D,"LI",{});var n1e=s(Nu);rH=n(n1e,"STRONG",{});var DFt=s(rH);Koo=t(DFt,"trocr"),DFt.forEach(r),Yoo=t(n1e," \u2014 "),c9=n(n1e,"A",{href:!0});var GFt=s(c9);Zoo=t(GFt,"TrOCRForCausalLM"),GFt.forEach(r),eto=t(n1e," (TrOCR model)"),n1e.forEach(r),oto=i(D),Du=n(D,"LI",{});var s1e=s(Du);aH=n(s1e,"STRONG",{});var OFt=s(aH);tto=t(OFt,"xlm"),OFt.forEach(r),rto=t(s1e," \u2014 "),g9=n(s1e,"A",{href:!0});var qFt=s(g9);ato=t(qFt,"XLMWithLMHeadModel"),qFt.forEach(r),nto=t(s1e," (XLM model)"),s1e.forEach(r),sto=i(D),Gu=n(D,"LI",{});var l1e=s(Gu);nH=n(l1e,"STRONG",{});var zFt=s(nH);lto=t(zFt,"xlm-prophetnet"),zFt.forEach(r),ito=t(l1e," \u2014 "),h9=n(l1e,"A",{href:!0});var XFt=s(h9);dto=t(XFt,"XLMProphetNetForCausalLM"),XFt.forEach(r),mto=t(l1e," (XLMProphetNet model)"),l1e.forEach(r),fto=i(D),Ou=n(D,"LI",{});var i1e=s(Ou);sH=n(i1e,"STRONG",{});var WFt=s(sH);cto=t(WFt,"xlm-roberta"),WFt.forEach(r),gto=t(i1e," \u2014 "),u9=n(i1e,"A",{href:!0});var VFt=s(u9);hto=t(VFt,"XLMRobertaForCausalLM"),VFt.forEach(r),uto=t(i1e," (XLM-RoBERTa model)"),i1e.forEach(r),pto=i(D),qu=n(D,"LI",{});var d1e=s(qu);lH=n(d1e,"STRONG",{});var QFt=s(lH);_to=t(QFt,"xlnet"),QFt.forEach(r),vto=t(d1e," \u2014 "),p9=n(d1e,"A",{href:!0});var HFt=s(p9);bto=t(HFt,"XLNetLMHeadModel"),HFt.forEach(r),Tto=t(d1e," (XLNet model)"),d1e.forEach(r),D.forEach(r),Fto=i(Tr),zu=n(Tr,"P",{});var m1e=s(zu);Mto=t(m1e,"The model is set in evaluation mode by default using "),iH=n(m1e,"EM",{});var UFt=s(iH);Eto=t(UFt,"model.eval()"),UFt.forEach(r),Cto=t(m1e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dH=n(m1e,"EM",{});var JFt=s(dH);yto=t(JFt,"model.train()"),JFt.forEach(r),m1e.forEach(r),wto=i(Tr),mH=n(Tr,"P",{});var KFt=s(mH);Ato=t(KFt,"Examples:"),KFt.forEach(r),xto=i(Tr),c(BM.$$.fragment,Tr),Tr.forEach(r),ps.forEach(r),NEe=i(d),ui=n(d,"H2",{class:!0});var $3e=s(ui);Xu=n($3e,"A",{id:!0,class:!0,href:!0});var YFt=s(Xu);fH=n(YFt,"SPAN",{});var ZFt=s(fH);c(kM.$$.fragment,ZFt),ZFt.forEach(r),YFt.forEach(r),Lto=i($3e),cH=n($3e,"SPAN",{});var eMt=s(cH);Bto=t(eMt,"AutoModelForMaskedLM"),eMt.forEach(r),$3e.forEach(r),DEe=i(d),jo=n(d,"DIV",{class:!0});var vs=s(jo);c(RM.$$.fragment,vs),kto=i(vs),pi=n(vs,"P",{});var ED=s(pi);Rto=t(ED,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gH=n(ED,"CODE",{});var oMt=s(gH);Sto=t(oMt,"from_pretrained()"),oMt.forEach(r),Pto=t(ED,` class method or the
`),hH=n(ED,"CODE",{});var tMt=s(hH);$to=t(tMt,"from_config()"),tMt.forEach(r),Ito=t(ED," class method."),ED.forEach(r),jto=i(vs),SM=n(vs,"P",{});var I3e=s(SM);Nto=t(I3e,"This class cannot be instantiated directly using "),uH=n(I3e,"CODE",{});var rMt=s(uH);Dto=t(rMt,"__init__()"),rMt.forEach(r),Gto=t(I3e," (throws an error)."),I3e.forEach(r),Oto=i(vs),Lt=n(vs,"DIV",{class:!0});var bs=s(Lt);c(PM.$$.fragment,bs),qto=i(bs),pH=n(bs,"P",{});var aMt=s(pH);zto=t(aMt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),aMt.forEach(r),Xto=i(bs),_i=n(bs,"P",{});var CD=s(_i);Wto=t(CD,`Note:
Loading a model from its configuration file does `),_H=n(CD,"STRONG",{});var nMt=s(_H);Vto=t(nMt,"not"),nMt.forEach(r),Qto=t(CD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),vH=n(CD,"EM",{});var sMt=s(vH);Hto=t(sMt,"~AutoModelForMaskedLM.from_pretrained"),sMt.forEach(r),Uto=t(CD,`] to load the model
weights.`),CD.forEach(r),Jto=i(bs),bH=n(bs,"P",{});var lMt=s(bH);Kto=t(lMt,"Examples:"),lMt.forEach(r),Yto=i(bs),c($M.$$.fragment,bs),bs.forEach(r),Zto=i(vs),ke=n(vs,"DIV",{class:!0});var Fr=s(ke);c(IM.$$.fragment,Fr),ero=i(Fr),TH=n(Fr,"P",{});var iMt=s(TH);oro=t(iMt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),iMt.forEach(r),tro=i(Fr),wa=n(Fr,"P",{});var VT=s(wa);rro=t(VT,"The model class to instantiate is selected based on the "),FH=n(VT,"EM",{});var dMt=s(FH);aro=t(dMt,"model_type"),dMt.forEach(r),nro=t(VT,` property of the config object (either
passed as an argument or loaded from `),MH=n(VT,"EM",{});var mMt=s(MH);sro=t(mMt,"pretrained_model_name_or_path"),mMt.forEach(r),lro=t(VT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),EH=n(VT,"EM",{});var fMt=s(EH);iro=t(fMt,"pretrained_model_name_or_path"),fMt.forEach(r),dro=t(VT,":"),VT.forEach(r),mro=i(Fr),$=n(Fr,"UL",{});var j=s($);Wu=n(j,"LI",{});var f1e=s(Wu);CH=n(f1e,"STRONG",{});var cMt=s(CH);fro=t(cMt,"albert"),cMt.forEach(r),cro=t(f1e," \u2014 "),_9=n(f1e,"A",{href:!0});var gMt=s(_9);gro=t(gMt,"AlbertForMaskedLM"),gMt.forEach(r),hro=t(f1e," (ALBERT model)"),f1e.forEach(r),uro=i(j),Vu=n(j,"LI",{});var c1e=s(Vu);yH=n(c1e,"STRONG",{});var hMt=s(yH);pro=t(hMt,"bart"),hMt.forEach(r),_ro=t(c1e," \u2014 "),v9=n(c1e,"A",{href:!0});var uMt=s(v9);vro=t(uMt,"BartForConditionalGeneration"),uMt.forEach(r),bro=t(c1e," (BART model)"),c1e.forEach(r),Tro=i(j),Qu=n(j,"LI",{});var g1e=s(Qu);wH=n(g1e,"STRONG",{});var pMt=s(wH);Fro=t(pMt,"bert"),pMt.forEach(r),Mro=t(g1e," \u2014 "),b9=n(g1e,"A",{href:!0});var _Mt=s(b9);Ero=t(_Mt,"BertForMaskedLM"),_Mt.forEach(r),Cro=t(g1e," (BERT model)"),g1e.forEach(r),yro=i(j),Hu=n(j,"LI",{});var h1e=s(Hu);AH=n(h1e,"STRONG",{});var vMt=s(AH);wro=t(vMt,"big_bird"),vMt.forEach(r),Aro=t(h1e," \u2014 "),T9=n(h1e,"A",{href:!0});var bMt=s(T9);xro=t(bMt,"BigBirdForMaskedLM"),bMt.forEach(r),Lro=t(h1e," (BigBird model)"),h1e.forEach(r),Bro=i(j),Uu=n(j,"LI",{});var u1e=s(Uu);xH=n(u1e,"STRONG",{});var TMt=s(xH);kro=t(TMt,"camembert"),TMt.forEach(r),Rro=t(u1e," \u2014 "),F9=n(u1e,"A",{href:!0});var FMt=s(F9);Sro=t(FMt,"CamembertForMaskedLM"),FMt.forEach(r),Pro=t(u1e," (CamemBERT model)"),u1e.forEach(r),$ro=i(j),Ju=n(j,"LI",{});var p1e=s(Ju);LH=n(p1e,"STRONG",{});var MMt=s(LH);Iro=t(MMt,"convbert"),MMt.forEach(r),jro=t(p1e," \u2014 "),M9=n(p1e,"A",{href:!0});var EMt=s(M9);Nro=t(EMt,"ConvBertForMaskedLM"),EMt.forEach(r),Dro=t(p1e," (ConvBERT model)"),p1e.forEach(r),Gro=i(j),Ku=n(j,"LI",{});var _1e=s(Ku);BH=n(_1e,"STRONG",{});var CMt=s(BH);Oro=t(CMt,"deberta"),CMt.forEach(r),qro=t(_1e," \u2014 "),E9=n(_1e,"A",{href:!0});var yMt=s(E9);zro=t(yMt,"DebertaForMaskedLM"),yMt.forEach(r),Xro=t(_1e," (DeBERTa model)"),_1e.forEach(r),Wro=i(j),Yu=n(j,"LI",{});var v1e=s(Yu);kH=n(v1e,"STRONG",{});var wMt=s(kH);Vro=t(wMt,"deberta-v2"),wMt.forEach(r),Qro=t(v1e," \u2014 "),C9=n(v1e,"A",{href:!0});var AMt=s(C9);Hro=t(AMt,"DebertaV2ForMaskedLM"),AMt.forEach(r),Uro=t(v1e," (DeBERTa-v2 model)"),v1e.forEach(r),Jro=i(j),Zu=n(j,"LI",{});var b1e=s(Zu);RH=n(b1e,"STRONG",{});var xMt=s(RH);Kro=t(xMt,"distilbert"),xMt.forEach(r),Yro=t(b1e," \u2014 "),y9=n(b1e,"A",{href:!0});var LMt=s(y9);Zro=t(LMt,"DistilBertForMaskedLM"),LMt.forEach(r),eao=t(b1e," (DistilBERT model)"),b1e.forEach(r),oao=i(j),ep=n(j,"LI",{});var T1e=s(ep);SH=n(T1e,"STRONG",{});var BMt=s(SH);tao=t(BMt,"electra"),BMt.forEach(r),rao=t(T1e," \u2014 "),w9=n(T1e,"A",{href:!0});var kMt=s(w9);aao=t(kMt,"ElectraForMaskedLM"),kMt.forEach(r),nao=t(T1e," (ELECTRA model)"),T1e.forEach(r),sao=i(j),op=n(j,"LI",{});var F1e=s(op);PH=n(F1e,"STRONG",{});var RMt=s(PH);lao=t(RMt,"flaubert"),RMt.forEach(r),iao=t(F1e," \u2014 "),A9=n(F1e,"A",{href:!0});var SMt=s(A9);dao=t(SMt,"FlaubertWithLMHeadModel"),SMt.forEach(r),mao=t(F1e," (FlauBERT model)"),F1e.forEach(r),fao=i(j),tp=n(j,"LI",{});var M1e=s(tp);$H=n(M1e,"STRONG",{});var PMt=s($H);cao=t(PMt,"fnet"),PMt.forEach(r),gao=t(M1e," \u2014 "),x9=n(M1e,"A",{href:!0});var $Mt=s(x9);hao=t($Mt,"FNetForMaskedLM"),$Mt.forEach(r),uao=t(M1e," (FNet model)"),M1e.forEach(r),pao=i(j),rp=n(j,"LI",{});var E1e=s(rp);IH=n(E1e,"STRONG",{});var IMt=s(IH);_ao=t(IMt,"funnel"),IMt.forEach(r),vao=t(E1e," \u2014 "),L9=n(E1e,"A",{href:!0});var jMt=s(L9);bao=t(jMt,"FunnelForMaskedLM"),jMt.forEach(r),Tao=t(E1e," (Funnel Transformer model)"),E1e.forEach(r),Fao=i(j),ap=n(j,"LI",{});var C1e=s(ap);jH=n(C1e,"STRONG",{});var NMt=s(jH);Mao=t(NMt,"ibert"),NMt.forEach(r),Eao=t(C1e," \u2014 "),B9=n(C1e,"A",{href:!0});var DMt=s(B9);Cao=t(DMt,"IBertForMaskedLM"),DMt.forEach(r),yao=t(C1e," (I-BERT model)"),C1e.forEach(r),wao=i(j),np=n(j,"LI",{});var y1e=s(np);NH=n(y1e,"STRONG",{});var GMt=s(NH);Aao=t(GMt,"layoutlm"),GMt.forEach(r),xao=t(y1e," \u2014 "),k9=n(y1e,"A",{href:!0});var OMt=s(k9);Lao=t(OMt,"LayoutLMForMaskedLM"),OMt.forEach(r),Bao=t(y1e," (LayoutLM model)"),y1e.forEach(r),kao=i(j),sp=n(j,"LI",{});var w1e=s(sp);DH=n(w1e,"STRONG",{});var qMt=s(DH);Rao=t(qMt,"longformer"),qMt.forEach(r),Sao=t(w1e," \u2014 "),R9=n(w1e,"A",{href:!0});var zMt=s(R9);Pao=t(zMt,"LongformerForMaskedLM"),zMt.forEach(r),$ao=t(w1e," (Longformer model)"),w1e.forEach(r),Iao=i(j),lp=n(j,"LI",{});var A1e=s(lp);GH=n(A1e,"STRONG",{});var XMt=s(GH);jao=t(XMt,"mbart"),XMt.forEach(r),Nao=t(A1e," \u2014 "),S9=n(A1e,"A",{href:!0});var WMt=s(S9);Dao=t(WMt,"MBartForConditionalGeneration"),WMt.forEach(r),Gao=t(A1e," (mBART model)"),A1e.forEach(r),Oao=i(j),ip=n(j,"LI",{});var x1e=s(ip);OH=n(x1e,"STRONG",{});var VMt=s(OH);qao=t(VMt,"megatron-bert"),VMt.forEach(r),zao=t(x1e," \u2014 "),P9=n(x1e,"A",{href:!0});var QMt=s(P9);Xao=t(QMt,"MegatronBertForMaskedLM"),QMt.forEach(r),Wao=t(x1e," (MegatronBert model)"),x1e.forEach(r),Vao=i(j),dp=n(j,"LI",{});var L1e=s(dp);qH=n(L1e,"STRONG",{});var HMt=s(qH);Qao=t(HMt,"mobilebert"),HMt.forEach(r),Hao=t(L1e," \u2014 "),$9=n(L1e,"A",{href:!0});var UMt=s($9);Uao=t(UMt,"MobileBertForMaskedLM"),UMt.forEach(r),Jao=t(L1e," (MobileBERT model)"),L1e.forEach(r),Kao=i(j),mp=n(j,"LI",{});var B1e=s(mp);zH=n(B1e,"STRONG",{});var JMt=s(zH);Yao=t(JMt,"mpnet"),JMt.forEach(r),Zao=t(B1e," \u2014 "),I9=n(B1e,"A",{href:!0});var KMt=s(I9);eno=t(KMt,"MPNetForMaskedLM"),KMt.forEach(r),ono=t(B1e," (MPNet model)"),B1e.forEach(r),tno=i(j),fp=n(j,"LI",{});var k1e=s(fp);XH=n(k1e,"STRONG",{});var YMt=s(XH);rno=t(YMt,"perceiver"),YMt.forEach(r),ano=t(k1e," \u2014 "),j9=n(k1e,"A",{href:!0});var ZMt=s(j9);nno=t(ZMt,"PerceiverForMaskedLM"),ZMt.forEach(r),sno=t(k1e," (Perceiver model)"),k1e.forEach(r),lno=i(j),cp=n(j,"LI",{});var R1e=s(cp);WH=n(R1e,"STRONG",{});var eEt=s(WH);ino=t(eEt,"qdqbert"),eEt.forEach(r),dno=t(R1e," \u2014 "),N9=n(R1e,"A",{href:!0});var oEt=s(N9);mno=t(oEt,"QDQBertForMaskedLM"),oEt.forEach(r),fno=t(R1e," (QDQBert model)"),R1e.forEach(r),cno=i(j),gp=n(j,"LI",{});var S1e=s(gp);VH=n(S1e,"STRONG",{});var tEt=s(VH);gno=t(tEt,"reformer"),tEt.forEach(r),hno=t(S1e," \u2014 "),D9=n(S1e,"A",{href:!0});var rEt=s(D9);uno=t(rEt,"ReformerForMaskedLM"),rEt.forEach(r),pno=t(S1e," (Reformer model)"),S1e.forEach(r),_no=i(j),hp=n(j,"LI",{});var P1e=s(hp);QH=n(P1e,"STRONG",{});var aEt=s(QH);vno=t(aEt,"rembert"),aEt.forEach(r),bno=t(P1e," \u2014 "),G9=n(P1e,"A",{href:!0});var nEt=s(G9);Tno=t(nEt,"RemBertForMaskedLM"),nEt.forEach(r),Fno=t(P1e," (RemBERT model)"),P1e.forEach(r),Mno=i(j),up=n(j,"LI",{});var $1e=s(up);HH=n($1e,"STRONG",{});var sEt=s(HH);Eno=t(sEt,"roberta"),sEt.forEach(r),Cno=t($1e," \u2014 "),O9=n($1e,"A",{href:!0});var lEt=s(O9);yno=t(lEt,"RobertaForMaskedLM"),lEt.forEach(r),wno=t($1e," (RoBERTa model)"),$1e.forEach(r),Ano=i(j),pp=n(j,"LI",{});var I1e=s(pp);UH=n(I1e,"STRONG",{});var iEt=s(UH);xno=t(iEt,"roformer"),iEt.forEach(r),Lno=t(I1e," \u2014 "),q9=n(I1e,"A",{href:!0});var dEt=s(q9);Bno=t(dEt,"RoFormerForMaskedLM"),dEt.forEach(r),kno=t(I1e," (RoFormer model)"),I1e.forEach(r),Rno=i(j),_p=n(j,"LI",{});var j1e=s(_p);JH=n(j1e,"STRONG",{});var mEt=s(JH);Sno=t(mEt,"squeezebert"),mEt.forEach(r),Pno=t(j1e," \u2014 "),z9=n(j1e,"A",{href:!0});var fEt=s(z9);$no=t(fEt,"SqueezeBertForMaskedLM"),fEt.forEach(r),Ino=t(j1e," (SqueezeBERT model)"),j1e.forEach(r),jno=i(j),vp=n(j,"LI",{});var N1e=s(vp);KH=n(N1e,"STRONG",{});var cEt=s(KH);Nno=t(cEt,"tapas"),cEt.forEach(r),Dno=t(N1e," \u2014 "),X9=n(N1e,"A",{href:!0});var gEt=s(X9);Gno=t(gEt,"TapasForMaskedLM"),gEt.forEach(r),Ono=t(N1e," (TAPAS model)"),N1e.forEach(r),qno=i(j),bp=n(j,"LI",{});var D1e=s(bp);YH=n(D1e,"STRONG",{});var hEt=s(YH);zno=t(hEt,"wav2vec2"),hEt.forEach(r),Xno=t(D1e," \u2014 "),ZH=n(D1e,"CODE",{});var uEt=s(ZH);Wno=t(uEt,"Wav2Vec2ForMaskedLM"),uEt.forEach(r),Vno=t(D1e," (Wav2Vec2 model)"),D1e.forEach(r),Qno=i(j),Tp=n(j,"LI",{});var G1e=s(Tp);eU=n(G1e,"STRONG",{});var pEt=s(eU);Hno=t(pEt,"xlm"),pEt.forEach(r),Uno=t(G1e," \u2014 "),W9=n(G1e,"A",{href:!0});var _Et=s(W9);Jno=t(_Et,"XLMWithLMHeadModel"),_Et.forEach(r),Kno=t(G1e," (XLM model)"),G1e.forEach(r),Yno=i(j),Fp=n(j,"LI",{});var O1e=s(Fp);oU=n(O1e,"STRONG",{});var vEt=s(oU);Zno=t(vEt,"xlm-roberta"),vEt.forEach(r),eso=t(O1e," \u2014 "),V9=n(O1e,"A",{href:!0});var bEt=s(V9);oso=t(bEt,"XLMRobertaForMaskedLM"),bEt.forEach(r),tso=t(O1e," (XLM-RoBERTa model)"),O1e.forEach(r),j.forEach(r),rso=i(Fr),Mp=n(Fr,"P",{});var q1e=s(Mp);aso=t(q1e,"The model is set in evaluation mode by default using "),tU=n(q1e,"EM",{});var TEt=s(tU);nso=t(TEt,"model.eval()"),TEt.forEach(r),sso=t(q1e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rU=n(q1e,"EM",{});var FEt=s(rU);lso=t(FEt,"model.train()"),FEt.forEach(r),q1e.forEach(r),iso=i(Fr),aU=n(Fr,"P",{});var MEt=s(aU);dso=t(MEt,"Examples:"),MEt.forEach(r),mso=i(Fr),c(jM.$$.fragment,Fr),Fr.forEach(r),vs.forEach(r),GEe=i(d),vi=n(d,"H2",{class:!0});var j3e=s(vi);Ep=n(j3e,"A",{id:!0,class:!0,href:!0});var EEt=s(Ep);nU=n(EEt,"SPAN",{});var CEt=s(nU);c(NM.$$.fragment,CEt),CEt.forEach(r),EEt.forEach(r),fso=i(j3e),sU=n(j3e,"SPAN",{});var yEt=s(sU);cso=t(yEt,"AutoModelForSeq2SeqLM"),yEt.forEach(r),j3e.forEach(r),OEe=i(d),No=n(d,"DIV",{class:!0});var Ts=s(No);c(DM.$$.fragment,Ts),gso=i(Ts),bi=n(Ts,"P",{});var yD=s(bi);hso=t(yD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),lU=n(yD,"CODE",{});var wEt=s(lU);uso=t(wEt,"from_pretrained()"),wEt.forEach(r),pso=t(yD,` class method or the
`),iU=n(yD,"CODE",{});var AEt=s(iU);_so=t(AEt,"from_config()"),AEt.forEach(r),vso=t(yD," class method."),yD.forEach(r),bso=i(Ts),GM=n(Ts,"P",{});var N3e=s(GM);Tso=t(N3e,"This class cannot be instantiated directly using "),dU=n(N3e,"CODE",{});var xEt=s(dU);Fso=t(xEt,"__init__()"),xEt.forEach(r),Mso=t(N3e," (throws an error)."),N3e.forEach(r),Eso=i(Ts),Bt=n(Ts,"DIV",{class:!0});var Fs=s(Bt);c(OM.$$.fragment,Fs),Cso=i(Fs),mU=n(Fs,"P",{});var LEt=s(mU);yso=t(LEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),LEt.forEach(r),wso=i(Fs),Ti=n(Fs,"P",{});var wD=s(Ti);Aso=t(wD,`Note:
Loading a model from its configuration file does `),fU=n(wD,"STRONG",{});var BEt=s(fU);xso=t(BEt,"not"),BEt.forEach(r),Lso=t(wD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),cU=n(wD,"EM",{});var kEt=s(cU);Bso=t(kEt,"~AutoModelForSeq2SeqLM.from_pretrained"),kEt.forEach(r),kso=t(wD,`] to load the model
weights.`),wD.forEach(r),Rso=i(Fs),gU=n(Fs,"P",{});var REt=s(gU);Sso=t(REt,"Examples:"),REt.forEach(r),Pso=i(Fs),c(qM.$$.fragment,Fs),Fs.forEach(r),$so=i(Ts),Re=n(Ts,"DIV",{class:!0});var Mr=s(Re);c(zM.$$.fragment,Mr),Iso=i(Mr),hU=n(Mr,"P",{});var SEt=s(hU);jso=t(SEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),SEt.forEach(r),Nso=i(Mr),Aa=n(Mr,"P",{});var QT=s(Aa);Dso=t(QT,"The model class to instantiate is selected based on the "),uU=n(QT,"EM",{});var PEt=s(uU);Gso=t(PEt,"model_type"),PEt.forEach(r),Oso=t(QT,` property of the config object (either
passed as an argument or loaded from `),pU=n(QT,"EM",{});var $Et=s(pU);qso=t($Et,"pretrained_model_name_or_path"),$Et.forEach(r),zso=t(QT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),_U=n(QT,"EM",{});var IEt=s(_U);Xso=t(IEt,"pretrained_model_name_or_path"),IEt.forEach(r),Wso=t(QT,":"),QT.forEach(r),Vso=i(Mr),ne=n(Mr,"UL",{});var le=s(ne);Cp=n(le,"LI",{});var z1e=s(Cp);vU=n(z1e,"STRONG",{});var jEt=s(vU);Qso=t(jEt,"bart"),jEt.forEach(r),Hso=t(z1e," \u2014 "),Q9=n(z1e,"A",{href:!0});var NEt=s(Q9);Uso=t(NEt,"BartForConditionalGeneration"),NEt.forEach(r),Jso=t(z1e," (BART model)"),z1e.forEach(r),Kso=i(le),yp=n(le,"LI",{});var X1e=s(yp);bU=n(X1e,"STRONG",{});var DEt=s(bU);Yso=t(DEt,"bigbird_pegasus"),DEt.forEach(r),Zso=t(X1e," \u2014 "),H9=n(X1e,"A",{href:!0});var GEt=s(H9);elo=t(GEt,"BigBirdPegasusForConditionalGeneration"),GEt.forEach(r),olo=t(X1e," (BigBirdPegasus model)"),X1e.forEach(r),tlo=i(le),wp=n(le,"LI",{});var W1e=s(wp);TU=n(W1e,"STRONG",{});var OEt=s(TU);rlo=t(OEt,"blenderbot"),OEt.forEach(r),alo=t(W1e," \u2014 "),U9=n(W1e,"A",{href:!0});var qEt=s(U9);nlo=t(qEt,"BlenderbotForConditionalGeneration"),qEt.forEach(r),slo=t(W1e," (Blenderbot model)"),W1e.forEach(r),llo=i(le),Ap=n(le,"LI",{});var V1e=s(Ap);FU=n(V1e,"STRONG",{});var zEt=s(FU);ilo=t(zEt,"blenderbot-small"),zEt.forEach(r),dlo=t(V1e," \u2014 "),J9=n(V1e,"A",{href:!0});var XEt=s(J9);mlo=t(XEt,"BlenderbotSmallForConditionalGeneration"),XEt.forEach(r),flo=t(V1e," (BlenderbotSmall model)"),V1e.forEach(r),clo=i(le),xp=n(le,"LI",{});var Q1e=s(xp);MU=n(Q1e,"STRONG",{});var WEt=s(MU);glo=t(WEt,"encoder-decoder"),WEt.forEach(r),hlo=t(Q1e," \u2014 "),K9=n(Q1e,"A",{href:!0});var VEt=s(K9);ulo=t(VEt,"EncoderDecoderModel"),VEt.forEach(r),plo=t(Q1e," (Encoder decoder model)"),Q1e.forEach(r),_lo=i(le),Lp=n(le,"LI",{});var H1e=s(Lp);EU=n(H1e,"STRONG",{});var QEt=s(EU);vlo=t(QEt,"fsmt"),QEt.forEach(r),blo=t(H1e," \u2014 "),Y9=n(H1e,"A",{href:!0});var HEt=s(Y9);Tlo=t(HEt,"FSMTForConditionalGeneration"),HEt.forEach(r),Flo=t(H1e," (FairSeq Machine-Translation model)"),H1e.forEach(r),Mlo=i(le),Bp=n(le,"LI",{});var U1e=s(Bp);CU=n(U1e,"STRONG",{});var UEt=s(CU);Elo=t(UEt,"led"),UEt.forEach(r),Clo=t(U1e," \u2014 "),Z9=n(U1e,"A",{href:!0});var JEt=s(Z9);ylo=t(JEt,"LEDForConditionalGeneration"),JEt.forEach(r),wlo=t(U1e," (LED model)"),U1e.forEach(r),Alo=i(le),kp=n(le,"LI",{});var J1e=s(kp);yU=n(J1e,"STRONG",{});var KEt=s(yU);xlo=t(KEt,"m2m_100"),KEt.forEach(r),Llo=t(J1e," \u2014 "),ek=n(J1e,"A",{href:!0});var YEt=s(ek);Blo=t(YEt,"M2M100ForConditionalGeneration"),YEt.forEach(r),klo=t(J1e," (M2M100 model)"),J1e.forEach(r),Rlo=i(le),Rp=n(le,"LI",{});var K1e=s(Rp);wU=n(K1e,"STRONG",{});var ZEt=s(wU);Slo=t(ZEt,"marian"),ZEt.forEach(r),Plo=t(K1e," \u2014 "),ok=n(K1e,"A",{href:!0});var eCt=s(ok);$lo=t(eCt,"MarianMTModel"),eCt.forEach(r),Ilo=t(K1e," (Marian model)"),K1e.forEach(r),jlo=i(le),Sp=n(le,"LI",{});var Y1e=s(Sp);AU=n(Y1e,"STRONG",{});var oCt=s(AU);Nlo=t(oCt,"mbart"),oCt.forEach(r),Dlo=t(Y1e," \u2014 "),tk=n(Y1e,"A",{href:!0});var tCt=s(tk);Glo=t(tCt,"MBartForConditionalGeneration"),tCt.forEach(r),Olo=t(Y1e," (mBART model)"),Y1e.forEach(r),qlo=i(le),Pp=n(le,"LI",{});var Z1e=s(Pp);xU=n(Z1e,"STRONG",{});var rCt=s(xU);zlo=t(rCt,"mt5"),rCt.forEach(r),Xlo=t(Z1e," \u2014 "),rk=n(Z1e,"A",{href:!0});var aCt=s(rk);Wlo=t(aCt,"MT5ForConditionalGeneration"),aCt.forEach(r),Vlo=t(Z1e," (mT5 model)"),Z1e.forEach(r),Qlo=i(le),$p=n(le,"LI",{});var e2e=s($p);LU=n(e2e,"STRONG",{});var nCt=s(LU);Hlo=t(nCt,"pegasus"),nCt.forEach(r),Ulo=t(e2e," \u2014 "),ak=n(e2e,"A",{href:!0});var sCt=s(ak);Jlo=t(sCt,"PegasusForConditionalGeneration"),sCt.forEach(r),Klo=t(e2e," (Pegasus model)"),e2e.forEach(r),Ylo=i(le),Ip=n(le,"LI",{});var o2e=s(Ip);BU=n(o2e,"STRONG",{});var lCt=s(BU);Zlo=t(lCt,"prophetnet"),lCt.forEach(r),eio=t(o2e," \u2014 "),nk=n(o2e,"A",{href:!0});var iCt=s(nk);oio=t(iCt,"ProphetNetForConditionalGeneration"),iCt.forEach(r),tio=t(o2e," (ProphetNet model)"),o2e.forEach(r),rio=i(le),jp=n(le,"LI",{});var t2e=s(jp);kU=n(t2e,"STRONG",{});var dCt=s(kU);aio=t(dCt,"t5"),dCt.forEach(r),nio=t(t2e," \u2014 "),sk=n(t2e,"A",{href:!0});var mCt=s(sk);sio=t(mCt,"T5ForConditionalGeneration"),mCt.forEach(r),lio=t(t2e," (T5 model)"),t2e.forEach(r),iio=i(le),Np=n(le,"LI",{});var r2e=s(Np);RU=n(r2e,"STRONG",{});var fCt=s(RU);dio=t(fCt,"xlm-prophetnet"),fCt.forEach(r),mio=t(r2e," \u2014 "),lk=n(r2e,"A",{href:!0});var cCt=s(lk);fio=t(cCt,"XLMProphetNetForConditionalGeneration"),cCt.forEach(r),cio=t(r2e," (XLMProphetNet model)"),r2e.forEach(r),le.forEach(r),gio=i(Mr),Dp=n(Mr,"P",{});var a2e=s(Dp);hio=t(a2e,"The model is set in evaluation mode by default using "),SU=n(a2e,"EM",{});var gCt=s(SU);uio=t(gCt,"model.eval()"),gCt.forEach(r),pio=t(a2e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PU=n(a2e,"EM",{});var hCt=s(PU);_io=t(hCt,"model.train()"),hCt.forEach(r),a2e.forEach(r),vio=i(Mr),$U=n(Mr,"P",{});var uCt=s($U);bio=t(uCt,"Examples:"),uCt.forEach(r),Tio=i(Mr),c(XM.$$.fragment,Mr),Mr.forEach(r),Ts.forEach(r),qEe=i(d),Fi=n(d,"H2",{class:!0});var D3e=s(Fi);Gp=n(D3e,"A",{id:!0,class:!0,href:!0});var pCt=s(Gp);IU=n(pCt,"SPAN",{});var _Ct=s(IU);c(WM.$$.fragment,_Ct),_Ct.forEach(r),pCt.forEach(r),Fio=i(D3e),jU=n(D3e,"SPAN",{});var vCt=s(jU);Mio=t(vCt,"AutoModelForSequenceClassification"),vCt.forEach(r),D3e.forEach(r),zEe=i(d),Do=n(d,"DIV",{class:!0});var Ms=s(Do);c(VM.$$.fragment,Ms),Eio=i(Ms),Mi=n(Ms,"P",{});var AD=s(Mi);Cio=t(AD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),NU=n(AD,"CODE",{});var bCt=s(NU);yio=t(bCt,"from_pretrained()"),bCt.forEach(r),wio=t(AD,` class method or the
`),DU=n(AD,"CODE",{});var TCt=s(DU);Aio=t(TCt,"from_config()"),TCt.forEach(r),xio=t(AD," class method."),AD.forEach(r),Lio=i(Ms),QM=n(Ms,"P",{});var G3e=s(QM);Bio=t(G3e,"This class cannot be instantiated directly using "),GU=n(G3e,"CODE",{});var FCt=s(GU);kio=t(FCt,"__init__()"),FCt.forEach(r),Rio=t(G3e," (throws an error)."),G3e.forEach(r),Sio=i(Ms),kt=n(Ms,"DIV",{class:!0});var Es=s(kt);c(HM.$$.fragment,Es),Pio=i(Es),OU=n(Es,"P",{});var MCt=s(OU);$io=t(MCt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),MCt.forEach(r),Iio=i(Es),Ei=n(Es,"P",{});var xD=s(Ei);jio=t(xD,`Note:
Loading a model from its configuration file does `),qU=n(xD,"STRONG",{});var ECt=s(qU);Nio=t(ECt,"not"),ECt.forEach(r),Dio=t(xD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),zU=n(xD,"EM",{});var CCt=s(zU);Gio=t(CCt,"~AutoModelForSequenceClassification.from_pretrained"),CCt.forEach(r),Oio=t(xD,`] to load the model
weights.`),xD.forEach(r),qio=i(Es),XU=n(Es,"P",{});var yCt=s(XU);zio=t(yCt,"Examples:"),yCt.forEach(r),Xio=i(Es),c(UM.$$.fragment,Es),Es.forEach(r),Wio=i(Ms),Se=n(Ms,"DIV",{class:!0});var Er=s(Se);c(JM.$$.fragment,Er),Vio=i(Er),WU=n(Er,"P",{});var wCt=s(WU);Qio=t(wCt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),wCt.forEach(r),Hio=i(Er),xa=n(Er,"P",{});var HT=s(xa);Uio=t(HT,"The model class to instantiate is selected based on the "),VU=n(HT,"EM",{});var ACt=s(VU);Jio=t(ACt,"model_type"),ACt.forEach(r),Kio=t(HT,` property of the config object (either
passed as an argument or loaded from `),QU=n(HT,"EM",{});var xCt=s(QU);Yio=t(xCt,"pretrained_model_name_or_path"),xCt.forEach(r),Zio=t(HT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),HU=n(HT,"EM",{});var LCt=s(HU);edo=t(LCt,"pretrained_model_name_or_path"),LCt.forEach(r),odo=t(HT,":"),HT.forEach(r),tdo=i(Er),A=n(Er,"UL",{});var x=s(A);Op=n(x,"LI",{});var n2e=s(Op);UU=n(n2e,"STRONG",{});var BCt=s(UU);rdo=t(BCt,"albert"),BCt.forEach(r),ado=t(n2e," \u2014 "),ik=n(n2e,"A",{href:!0});var kCt=s(ik);ndo=t(kCt,"AlbertForSequenceClassification"),kCt.forEach(r),sdo=t(n2e," (ALBERT model)"),n2e.forEach(r),ldo=i(x),qp=n(x,"LI",{});var s2e=s(qp);JU=n(s2e,"STRONG",{});var RCt=s(JU);ido=t(RCt,"bart"),RCt.forEach(r),ddo=t(s2e," \u2014 "),dk=n(s2e,"A",{href:!0});var SCt=s(dk);mdo=t(SCt,"BartForSequenceClassification"),SCt.forEach(r),fdo=t(s2e," (BART model)"),s2e.forEach(r),cdo=i(x),zp=n(x,"LI",{});var l2e=s(zp);KU=n(l2e,"STRONG",{});var PCt=s(KU);gdo=t(PCt,"bert"),PCt.forEach(r),hdo=t(l2e," \u2014 "),mk=n(l2e,"A",{href:!0});var $Ct=s(mk);udo=t($Ct,"BertForSequenceClassification"),$Ct.forEach(r),pdo=t(l2e," (BERT model)"),l2e.forEach(r),_do=i(x),Xp=n(x,"LI",{});var i2e=s(Xp);YU=n(i2e,"STRONG",{});var ICt=s(YU);vdo=t(ICt,"big_bird"),ICt.forEach(r),bdo=t(i2e," \u2014 "),fk=n(i2e,"A",{href:!0});var jCt=s(fk);Tdo=t(jCt,"BigBirdForSequenceClassification"),jCt.forEach(r),Fdo=t(i2e," (BigBird model)"),i2e.forEach(r),Mdo=i(x),Wp=n(x,"LI",{});var d2e=s(Wp);ZU=n(d2e,"STRONG",{});var NCt=s(ZU);Edo=t(NCt,"bigbird_pegasus"),NCt.forEach(r),Cdo=t(d2e," \u2014 "),ck=n(d2e,"A",{href:!0});var DCt=s(ck);ydo=t(DCt,"BigBirdPegasusForSequenceClassification"),DCt.forEach(r),wdo=t(d2e," (BigBirdPegasus model)"),d2e.forEach(r),Ado=i(x),Vp=n(x,"LI",{});var m2e=s(Vp);eJ=n(m2e,"STRONG",{});var GCt=s(eJ);xdo=t(GCt,"camembert"),GCt.forEach(r),Ldo=t(m2e," \u2014 "),gk=n(m2e,"A",{href:!0});var OCt=s(gk);Bdo=t(OCt,"CamembertForSequenceClassification"),OCt.forEach(r),kdo=t(m2e," (CamemBERT model)"),m2e.forEach(r),Rdo=i(x),Qp=n(x,"LI",{});var f2e=s(Qp);oJ=n(f2e,"STRONG",{});var qCt=s(oJ);Sdo=t(qCt,"canine"),qCt.forEach(r),Pdo=t(f2e," \u2014 "),hk=n(f2e,"A",{href:!0});var zCt=s(hk);$do=t(zCt,"CanineForSequenceClassification"),zCt.forEach(r),Ido=t(f2e," (Canine model)"),f2e.forEach(r),jdo=i(x),Hp=n(x,"LI",{});var c2e=s(Hp);tJ=n(c2e,"STRONG",{});var XCt=s(tJ);Ndo=t(XCt,"convbert"),XCt.forEach(r),Ddo=t(c2e," \u2014 "),uk=n(c2e,"A",{href:!0});var WCt=s(uk);Gdo=t(WCt,"ConvBertForSequenceClassification"),WCt.forEach(r),Odo=t(c2e," (ConvBERT model)"),c2e.forEach(r),qdo=i(x),Up=n(x,"LI",{});var g2e=s(Up);rJ=n(g2e,"STRONG",{});var VCt=s(rJ);zdo=t(VCt,"ctrl"),VCt.forEach(r),Xdo=t(g2e," \u2014 "),pk=n(g2e,"A",{href:!0});var QCt=s(pk);Wdo=t(QCt,"CTRLForSequenceClassification"),QCt.forEach(r),Vdo=t(g2e," (CTRL model)"),g2e.forEach(r),Qdo=i(x),Jp=n(x,"LI",{});var h2e=s(Jp);aJ=n(h2e,"STRONG",{});var HCt=s(aJ);Hdo=t(HCt,"deberta"),HCt.forEach(r),Udo=t(h2e," \u2014 "),_k=n(h2e,"A",{href:!0});var UCt=s(_k);Jdo=t(UCt,"DebertaForSequenceClassification"),UCt.forEach(r),Kdo=t(h2e," (DeBERTa model)"),h2e.forEach(r),Ydo=i(x),Kp=n(x,"LI",{});var u2e=s(Kp);nJ=n(u2e,"STRONG",{});var JCt=s(nJ);Zdo=t(JCt,"deberta-v2"),JCt.forEach(r),emo=t(u2e," \u2014 "),vk=n(u2e,"A",{href:!0});var KCt=s(vk);omo=t(KCt,"DebertaV2ForSequenceClassification"),KCt.forEach(r),tmo=t(u2e," (DeBERTa-v2 model)"),u2e.forEach(r),rmo=i(x),Yp=n(x,"LI",{});var p2e=s(Yp);sJ=n(p2e,"STRONG",{});var YCt=s(sJ);amo=t(YCt,"distilbert"),YCt.forEach(r),nmo=t(p2e," \u2014 "),bk=n(p2e,"A",{href:!0});var ZCt=s(bk);smo=t(ZCt,"DistilBertForSequenceClassification"),ZCt.forEach(r),lmo=t(p2e," (DistilBERT model)"),p2e.forEach(r),imo=i(x),Zp=n(x,"LI",{});var _2e=s(Zp);lJ=n(_2e,"STRONG",{});var e3t=s(lJ);dmo=t(e3t,"electra"),e3t.forEach(r),mmo=t(_2e," \u2014 "),Tk=n(_2e,"A",{href:!0});var o3t=s(Tk);fmo=t(o3t,"ElectraForSequenceClassification"),o3t.forEach(r),cmo=t(_2e," (ELECTRA model)"),_2e.forEach(r),gmo=i(x),e_=n(x,"LI",{});var v2e=s(e_);iJ=n(v2e,"STRONG",{});var t3t=s(iJ);hmo=t(t3t,"flaubert"),t3t.forEach(r),umo=t(v2e," \u2014 "),Fk=n(v2e,"A",{href:!0});var r3t=s(Fk);pmo=t(r3t,"FlaubertForSequenceClassification"),r3t.forEach(r),_mo=t(v2e," (FlauBERT model)"),v2e.forEach(r),vmo=i(x),o_=n(x,"LI",{});var b2e=s(o_);dJ=n(b2e,"STRONG",{});var a3t=s(dJ);bmo=t(a3t,"fnet"),a3t.forEach(r),Tmo=t(b2e," \u2014 "),Mk=n(b2e,"A",{href:!0});var n3t=s(Mk);Fmo=t(n3t,"FNetForSequenceClassification"),n3t.forEach(r),Mmo=t(b2e," (FNet model)"),b2e.forEach(r),Emo=i(x),t_=n(x,"LI",{});var T2e=s(t_);mJ=n(T2e,"STRONG",{});var s3t=s(mJ);Cmo=t(s3t,"funnel"),s3t.forEach(r),ymo=t(T2e," \u2014 "),Ek=n(T2e,"A",{href:!0});var l3t=s(Ek);wmo=t(l3t,"FunnelForSequenceClassification"),l3t.forEach(r),Amo=t(T2e," (Funnel Transformer model)"),T2e.forEach(r),xmo=i(x),r_=n(x,"LI",{});var F2e=s(r_);fJ=n(F2e,"STRONG",{});var i3t=s(fJ);Lmo=t(i3t,"gpt2"),i3t.forEach(r),Bmo=t(F2e," \u2014 "),Ck=n(F2e,"A",{href:!0});var d3t=s(Ck);kmo=t(d3t,"GPT2ForSequenceClassification"),d3t.forEach(r),Rmo=t(F2e," (OpenAI GPT-2 model)"),F2e.forEach(r),Smo=i(x),a_=n(x,"LI",{});var M2e=s(a_);cJ=n(M2e,"STRONG",{});var m3t=s(cJ);Pmo=t(m3t,"gpt_neo"),m3t.forEach(r),$mo=t(M2e," \u2014 "),yk=n(M2e,"A",{href:!0});var f3t=s(yk);Imo=t(f3t,"GPTNeoForSequenceClassification"),f3t.forEach(r),jmo=t(M2e," (GPT Neo model)"),M2e.forEach(r),Nmo=i(x),n_=n(x,"LI",{});var E2e=s(n_);gJ=n(E2e,"STRONG",{});var c3t=s(gJ);Dmo=t(c3t,"gptj"),c3t.forEach(r),Gmo=t(E2e," \u2014 "),wk=n(E2e,"A",{href:!0});var g3t=s(wk);Omo=t(g3t,"GPTJForSequenceClassification"),g3t.forEach(r),qmo=t(E2e," (GPT-J model)"),E2e.forEach(r),zmo=i(x),s_=n(x,"LI",{});var C2e=s(s_);hJ=n(C2e,"STRONG",{});var h3t=s(hJ);Xmo=t(h3t,"ibert"),h3t.forEach(r),Wmo=t(C2e," \u2014 "),Ak=n(C2e,"A",{href:!0});var u3t=s(Ak);Vmo=t(u3t,"IBertForSequenceClassification"),u3t.forEach(r),Qmo=t(C2e," (I-BERT model)"),C2e.forEach(r),Hmo=i(x),l_=n(x,"LI",{});var y2e=s(l_);uJ=n(y2e,"STRONG",{});var p3t=s(uJ);Umo=t(p3t,"layoutlm"),p3t.forEach(r),Jmo=t(y2e," \u2014 "),xk=n(y2e,"A",{href:!0});var _3t=s(xk);Kmo=t(_3t,"LayoutLMForSequenceClassification"),_3t.forEach(r),Ymo=t(y2e," (LayoutLM model)"),y2e.forEach(r),Zmo=i(x),i_=n(x,"LI",{});var w2e=s(i_);pJ=n(w2e,"STRONG",{});var v3t=s(pJ);efo=t(v3t,"layoutlmv2"),v3t.forEach(r),ofo=t(w2e," \u2014 "),Lk=n(w2e,"A",{href:!0});var b3t=s(Lk);tfo=t(b3t,"LayoutLMv2ForSequenceClassification"),b3t.forEach(r),rfo=t(w2e," (LayoutLMv2 model)"),w2e.forEach(r),afo=i(x),d_=n(x,"LI",{});var A2e=s(d_);_J=n(A2e,"STRONG",{});var T3t=s(_J);nfo=t(T3t,"led"),T3t.forEach(r),sfo=t(A2e," \u2014 "),Bk=n(A2e,"A",{href:!0});var F3t=s(Bk);lfo=t(F3t,"LEDForSequenceClassification"),F3t.forEach(r),ifo=t(A2e," (LED model)"),A2e.forEach(r),dfo=i(x),m_=n(x,"LI",{});var x2e=s(m_);vJ=n(x2e,"STRONG",{});var M3t=s(vJ);mfo=t(M3t,"longformer"),M3t.forEach(r),ffo=t(x2e," \u2014 "),kk=n(x2e,"A",{href:!0});var E3t=s(kk);cfo=t(E3t,"LongformerForSequenceClassification"),E3t.forEach(r),gfo=t(x2e," (Longformer model)"),x2e.forEach(r),hfo=i(x),f_=n(x,"LI",{});var L2e=s(f_);bJ=n(L2e,"STRONG",{});var C3t=s(bJ);ufo=t(C3t,"mbart"),C3t.forEach(r),pfo=t(L2e," \u2014 "),Rk=n(L2e,"A",{href:!0});var y3t=s(Rk);_fo=t(y3t,"MBartForSequenceClassification"),y3t.forEach(r),vfo=t(L2e," (mBART model)"),L2e.forEach(r),bfo=i(x),c_=n(x,"LI",{});var B2e=s(c_);TJ=n(B2e,"STRONG",{});var w3t=s(TJ);Tfo=t(w3t,"megatron-bert"),w3t.forEach(r),Ffo=t(B2e," \u2014 "),Sk=n(B2e,"A",{href:!0});var A3t=s(Sk);Mfo=t(A3t,"MegatronBertForSequenceClassification"),A3t.forEach(r),Efo=t(B2e," (MegatronBert model)"),B2e.forEach(r),Cfo=i(x),g_=n(x,"LI",{});var k2e=s(g_);FJ=n(k2e,"STRONG",{});var x3t=s(FJ);yfo=t(x3t,"mobilebert"),x3t.forEach(r),wfo=t(k2e," \u2014 "),Pk=n(k2e,"A",{href:!0});var L3t=s(Pk);Afo=t(L3t,"MobileBertForSequenceClassification"),L3t.forEach(r),xfo=t(k2e," (MobileBERT model)"),k2e.forEach(r),Lfo=i(x),h_=n(x,"LI",{});var R2e=s(h_);MJ=n(R2e,"STRONG",{});var B3t=s(MJ);Bfo=t(B3t,"mpnet"),B3t.forEach(r),kfo=t(R2e," \u2014 "),$k=n(R2e,"A",{href:!0});var k3t=s($k);Rfo=t(k3t,"MPNetForSequenceClassification"),k3t.forEach(r),Sfo=t(R2e," (MPNet model)"),R2e.forEach(r),Pfo=i(x),u_=n(x,"LI",{});var S2e=s(u_);EJ=n(S2e,"STRONG",{});var R3t=s(EJ);$fo=t(R3t,"openai-gpt"),R3t.forEach(r),Ifo=t(S2e," \u2014 "),Ik=n(S2e,"A",{href:!0});var S3t=s(Ik);jfo=t(S3t,"OpenAIGPTForSequenceClassification"),S3t.forEach(r),Nfo=t(S2e," (OpenAI GPT model)"),S2e.forEach(r),Dfo=i(x),p_=n(x,"LI",{});var P2e=s(p_);CJ=n(P2e,"STRONG",{});var P3t=s(CJ);Gfo=t(P3t,"perceiver"),P3t.forEach(r),Ofo=t(P2e," \u2014 "),jk=n(P2e,"A",{href:!0});var $3t=s(jk);qfo=t($3t,"PerceiverForSequenceClassification"),$3t.forEach(r),zfo=t(P2e," (Perceiver model)"),P2e.forEach(r),Xfo=i(x),__=n(x,"LI",{});var $2e=s(__);yJ=n($2e,"STRONG",{});var I3t=s(yJ);Wfo=t(I3t,"qdqbert"),I3t.forEach(r),Vfo=t($2e," \u2014 "),Nk=n($2e,"A",{href:!0});var j3t=s(Nk);Qfo=t(j3t,"QDQBertForSequenceClassification"),j3t.forEach(r),Hfo=t($2e," (QDQBert model)"),$2e.forEach(r),Ufo=i(x),v_=n(x,"LI",{});var I2e=s(v_);wJ=n(I2e,"STRONG",{});var N3t=s(wJ);Jfo=t(N3t,"reformer"),N3t.forEach(r),Kfo=t(I2e," \u2014 "),Dk=n(I2e,"A",{href:!0});var D3t=s(Dk);Yfo=t(D3t,"ReformerForSequenceClassification"),D3t.forEach(r),Zfo=t(I2e," (Reformer model)"),I2e.forEach(r),eco=i(x),b_=n(x,"LI",{});var j2e=s(b_);AJ=n(j2e,"STRONG",{});var G3t=s(AJ);oco=t(G3t,"rembert"),G3t.forEach(r),tco=t(j2e," \u2014 "),Gk=n(j2e,"A",{href:!0});var O3t=s(Gk);rco=t(O3t,"RemBertForSequenceClassification"),O3t.forEach(r),aco=t(j2e," (RemBERT model)"),j2e.forEach(r),nco=i(x),T_=n(x,"LI",{});var N2e=s(T_);xJ=n(N2e,"STRONG",{});var q3t=s(xJ);sco=t(q3t,"roberta"),q3t.forEach(r),lco=t(N2e," \u2014 "),Ok=n(N2e,"A",{href:!0});var z3t=s(Ok);ico=t(z3t,"RobertaForSequenceClassification"),z3t.forEach(r),dco=t(N2e," (RoBERTa model)"),N2e.forEach(r),mco=i(x),F_=n(x,"LI",{});var D2e=s(F_);LJ=n(D2e,"STRONG",{});var X3t=s(LJ);fco=t(X3t,"roformer"),X3t.forEach(r),cco=t(D2e," \u2014 "),qk=n(D2e,"A",{href:!0});var W3t=s(qk);gco=t(W3t,"RoFormerForSequenceClassification"),W3t.forEach(r),hco=t(D2e," (RoFormer model)"),D2e.forEach(r),uco=i(x),M_=n(x,"LI",{});var G2e=s(M_);BJ=n(G2e,"STRONG",{});var V3t=s(BJ);pco=t(V3t,"squeezebert"),V3t.forEach(r),_co=t(G2e," \u2014 "),zk=n(G2e,"A",{href:!0});var Q3t=s(zk);vco=t(Q3t,"SqueezeBertForSequenceClassification"),Q3t.forEach(r),bco=t(G2e," (SqueezeBERT model)"),G2e.forEach(r),Tco=i(x),E_=n(x,"LI",{});var O2e=s(E_);kJ=n(O2e,"STRONG",{});var H3t=s(kJ);Fco=t(H3t,"tapas"),H3t.forEach(r),Mco=t(O2e," \u2014 "),Xk=n(O2e,"A",{href:!0});var U3t=s(Xk);Eco=t(U3t,"TapasForSequenceClassification"),U3t.forEach(r),Cco=t(O2e," (TAPAS model)"),O2e.forEach(r),yco=i(x),C_=n(x,"LI",{});var q2e=s(C_);RJ=n(q2e,"STRONG",{});var J3t=s(RJ);wco=t(J3t,"transfo-xl"),J3t.forEach(r),Aco=t(q2e," \u2014 "),Wk=n(q2e,"A",{href:!0});var K3t=s(Wk);xco=t(K3t,"TransfoXLForSequenceClassification"),K3t.forEach(r),Lco=t(q2e," (Transformer-XL model)"),q2e.forEach(r),Bco=i(x),y_=n(x,"LI",{});var z2e=s(y_);SJ=n(z2e,"STRONG",{});var Y3t=s(SJ);kco=t(Y3t,"xlm"),Y3t.forEach(r),Rco=t(z2e," \u2014 "),Vk=n(z2e,"A",{href:!0});var Z3t=s(Vk);Sco=t(Z3t,"XLMForSequenceClassification"),Z3t.forEach(r),Pco=t(z2e," (XLM model)"),z2e.forEach(r),$co=i(x),w_=n(x,"LI",{});var X2e=s(w_);PJ=n(X2e,"STRONG",{});var eyt=s(PJ);Ico=t(eyt,"xlm-roberta"),eyt.forEach(r),jco=t(X2e," \u2014 "),Qk=n(X2e,"A",{href:!0});var oyt=s(Qk);Nco=t(oyt,"XLMRobertaForSequenceClassification"),oyt.forEach(r),Dco=t(X2e," (XLM-RoBERTa model)"),X2e.forEach(r),Gco=i(x),A_=n(x,"LI",{});var W2e=s(A_);$J=n(W2e,"STRONG",{});var tyt=s($J);Oco=t(tyt,"xlnet"),tyt.forEach(r),qco=t(W2e," \u2014 "),Hk=n(W2e,"A",{href:!0});var ryt=s(Hk);zco=t(ryt,"XLNetForSequenceClassification"),ryt.forEach(r),Xco=t(W2e," (XLNet model)"),W2e.forEach(r),x.forEach(r),Wco=i(Er),x_=n(Er,"P",{});var V2e=s(x_);Vco=t(V2e,"The model is set in evaluation mode by default using "),IJ=n(V2e,"EM",{});var ayt=s(IJ);Qco=t(ayt,"model.eval()"),ayt.forEach(r),Hco=t(V2e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),jJ=n(V2e,"EM",{});var nyt=s(jJ);Uco=t(nyt,"model.train()"),nyt.forEach(r),V2e.forEach(r),Jco=i(Er),NJ=n(Er,"P",{});var syt=s(NJ);Kco=t(syt,"Examples:"),syt.forEach(r),Yco=i(Er),c(KM.$$.fragment,Er),Er.forEach(r),Ms.forEach(r),XEe=i(d),Ci=n(d,"H2",{class:!0});var O3e=s(Ci);L_=n(O3e,"A",{id:!0,class:!0,href:!0});var lyt=s(L_);DJ=n(lyt,"SPAN",{});var iyt=s(DJ);c(YM.$$.fragment,iyt),iyt.forEach(r),lyt.forEach(r),Zco=i(O3e),GJ=n(O3e,"SPAN",{});var dyt=s(GJ);ego=t(dyt,"AutoModelForMultipleChoice"),dyt.forEach(r),O3e.forEach(r),WEe=i(d),Go=n(d,"DIV",{class:!0});var Cs=s(Go);c(ZM.$$.fragment,Cs),ogo=i(Cs),yi=n(Cs,"P",{});var LD=s(yi);tgo=t(LD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),OJ=n(LD,"CODE",{});var myt=s(OJ);rgo=t(myt,"from_pretrained()"),myt.forEach(r),ago=t(LD,` class method or the
`),qJ=n(LD,"CODE",{});var fyt=s(qJ);ngo=t(fyt,"from_config()"),fyt.forEach(r),sgo=t(LD," class method."),LD.forEach(r),lgo=i(Cs),eE=n(Cs,"P",{});var q3e=s(eE);igo=t(q3e,"This class cannot be instantiated directly using "),zJ=n(q3e,"CODE",{});var cyt=s(zJ);dgo=t(cyt,"__init__()"),cyt.forEach(r),mgo=t(q3e," (throws an error)."),q3e.forEach(r),fgo=i(Cs),Rt=n(Cs,"DIV",{class:!0});var ys=s(Rt);c(oE.$$.fragment,ys),cgo=i(ys),XJ=n(ys,"P",{});var gyt=s(XJ);ggo=t(gyt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),gyt.forEach(r),hgo=i(ys),wi=n(ys,"P",{});var BD=s(wi);ugo=t(BD,`Note:
Loading a model from its configuration file does `),WJ=n(BD,"STRONG",{});var hyt=s(WJ);pgo=t(hyt,"not"),hyt.forEach(r),_go=t(BD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),VJ=n(BD,"EM",{});var uyt=s(VJ);vgo=t(uyt,"~AutoModelForMultipleChoice.from_pretrained"),uyt.forEach(r),bgo=t(BD,`] to load the model
weights.`),BD.forEach(r),Tgo=i(ys),QJ=n(ys,"P",{});var pyt=s(QJ);Fgo=t(pyt,"Examples:"),pyt.forEach(r),Mgo=i(ys),c(tE.$$.fragment,ys),ys.forEach(r),Ego=i(Cs),Pe=n(Cs,"DIV",{class:!0});var Cr=s(Pe);c(rE.$$.fragment,Cr),Cgo=i(Cr),HJ=n(Cr,"P",{});var _yt=s(HJ);ygo=t(_yt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),_yt.forEach(r),wgo=i(Cr),La=n(Cr,"P",{});var UT=s(La);Ago=t(UT,"The model class to instantiate is selected based on the "),UJ=n(UT,"EM",{});var vyt=s(UJ);xgo=t(vyt,"model_type"),vyt.forEach(r),Lgo=t(UT,` property of the config object (either
passed as an argument or loaded from `),JJ=n(UT,"EM",{});var byt=s(JJ);Bgo=t(byt,"pretrained_model_name_or_path"),byt.forEach(r),kgo=t(UT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),KJ=n(UT,"EM",{});var Tyt=s(KJ);Rgo=t(Tyt,"pretrained_model_name_or_path"),Tyt.forEach(r),Sgo=t(UT,":"),UT.forEach(r),Pgo=i(Cr),q=n(Cr,"UL",{});var W=s(q);B_=n(W,"LI",{});var Q2e=s(B_);YJ=n(Q2e,"STRONG",{});var Fyt=s(YJ);$go=t(Fyt,"albert"),Fyt.forEach(r),Igo=t(Q2e," \u2014 "),Uk=n(Q2e,"A",{href:!0});var Myt=s(Uk);jgo=t(Myt,"AlbertForMultipleChoice"),Myt.forEach(r),Ngo=t(Q2e," (ALBERT model)"),Q2e.forEach(r),Dgo=i(W),k_=n(W,"LI",{});var H2e=s(k_);ZJ=n(H2e,"STRONG",{});var Eyt=s(ZJ);Ggo=t(Eyt,"bert"),Eyt.forEach(r),Ogo=t(H2e," \u2014 "),Jk=n(H2e,"A",{href:!0});var Cyt=s(Jk);qgo=t(Cyt,"BertForMultipleChoice"),Cyt.forEach(r),zgo=t(H2e," (BERT model)"),H2e.forEach(r),Xgo=i(W),R_=n(W,"LI",{});var U2e=s(R_);eK=n(U2e,"STRONG",{});var yyt=s(eK);Wgo=t(yyt,"big_bird"),yyt.forEach(r),Vgo=t(U2e," \u2014 "),Kk=n(U2e,"A",{href:!0});var wyt=s(Kk);Qgo=t(wyt,"BigBirdForMultipleChoice"),wyt.forEach(r),Hgo=t(U2e," (BigBird model)"),U2e.forEach(r),Ugo=i(W),S_=n(W,"LI",{});var J2e=s(S_);oK=n(J2e,"STRONG",{});var Ayt=s(oK);Jgo=t(Ayt,"camembert"),Ayt.forEach(r),Kgo=t(J2e," \u2014 "),Yk=n(J2e,"A",{href:!0});var xyt=s(Yk);Ygo=t(xyt,"CamembertForMultipleChoice"),xyt.forEach(r),Zgo=t(J2e," (CamemBERT model)"),J2e.forEach(r),eho=i(W),P_=n(W,"LI",{});var K2e=s(P_);tK=n(K2e,"STRONG",{});var Lyt=s(tK);oho=t(Lyt,"canine"),Lyt.forEach(r),tho=t(K2e," \u2014 "),Zk=n(K2e,"A",{href:!0});var Byt=s(Zk);rho=t(Byt,"CanineForMultipleChoice"),Byt.forEach(r),aho=t(K2e," (Canine model)"),K2e.forEach(r),nho=i(W),$_=n(W,"LI",{});var Y2e=s($_);rK=n(Y2e,"STRONG",{});var kyt=s(rK);sho=t(kyt,"convbert"),kyt.forEach(r),lho=t(Y2e," \u2014 "),eR=n(Y2e,"A",{href:!0});var Ryt=s(eR);iho=t(Ryt,"ConvBertForMultipleChoice"),Ryt.forEach(r),dho=t(Y2e," (ConvBERT model)"),Y2e.forEach(r),mho=i(W),I_=n(W,"LI",{});var Z2e=s(I_);aK=n(Z2e,"STRONG",{});var Syt=s(aK);fho=t(Syt,"distilbert"),Syt.forEach(r),cho=t(Z2e," \u2014 "),oR=n(Z2e,"A",{href:!0});var Pyt=s(oR);gho=t(Pyt,"DistilBertForMultipleChoice"),Pyt.forEach(r),hho=t(Z2e," (DistilBERT model)"),Z2e.forEach(r),uho=i(W),j_=n(W,"LI",{});var ebe=s(j_);nK=n(ebe,"STRONG",{});var $yt=s(nK);pho=t($yt,"electra"),$yt.forEach(r),_ho=t(ebe," \u2014 "),tR=n(ebe,"A",{href:!0});var Iyt=s(tR);vho=t(Iyt,"ElectraForMultipleChoice"),Iyt.forEach(r),bho=t(ebe," (ELECTRA model)"),ebe.forEach(r),Tho=i(W),N_=n(W,"LI",{});var obe=s(N_);sK=n(obe,"STRONG",{});var jyt=s(sK);Fho=t(jyt,"flaubert"),jyt.forEach(r),Mho=t(obe," \u2014 "),rR=n(obe,"A",{href:!0});var Nyt=s(rR);Eho=t(Nyt,"FlaubertForMultipleChoice"),Nyt.forEach(r),Cho=t(obe," (FlauBERT model)"),obe.forEach(r),yho=i(W),D_=n(W,"LI",{});var tbe=s(D_);lK=n(tbe,"STRONG",{});var Dyt=s(lK);who=t(Dyt,"fnet"),Dyt.forEach(r),Aho=t(tbe," \u2014 "),aR=n(tbe,"A",{href:!0});var Gyt=s(aR);xho=t(Gyt,"FNetForMultipleChoice"),Gyt.forEach(r),Lho=t(tbe," (FNet model)"),tbe.forEach(r),Bho=i(W),G_=n(W,"LI",{});var rbe=s(G_);iK=n(rbe,"STRONG",{});var Oyt=s(iK);kho=t(Oyt,"funnel"),Oyt.forEach(r),Rho=t(rbe," \u2014 "),nR=n(rbe,"A",{href:!0});var qyt=s(nR);Sho=t(qyt,"FunnelForMultipleChoice"),qyt.forEach(r),Pho=t(rbe," (Funnel Transformer model)"),rbe.forEach(r),$ho=i(W),O_=n(W,"LI",{});var abe=s(O_);dK=n(abe,"STRONG",{});var zyt=s(dK);Iho=t(zyt,"ibert"),zyt.forEach(r),jho=t(abe," \u2014 "),sR=n(abe,"A",{href:!0});var Xyt=s(sR);Nho=t(Xyt,"IBertForMultipleChoice"),Xyt.forEach(r),Dho=t(abe," (I-BERT model)"),abe.forEach(r),Gho=i(W),q_=n(W,"LI",{});var nbe=s(q_);mK=n(nbe,"STRONG",{});var Wyt=s(mK);Oho=t(Wyt,"longformer"),Wyt.forEach(r),qho=t(nbe," \u2014 "),lR=n(nbe,"A",{href:!0});var Vyt=s(lR);zho=t(Vyt,"LongformerForMultipleChoice"),Vyt.forEach(r),Xho=t(nbe," (Longformer model)"),nbe.forEach(r),Who=i(W),z_=n(W,"LI",{});var sbe=s(z_);fK=n(sbe,"STRONG",{});var Qyt=s(fK);Vho=t(Qyt,"megatron-bert"),Qyt.forEach(r),Qho=t(sbe," \u2014 "),iR=n(sbe,"A",{href:!0});var Hyt=s(iR);Hho=t(Hyt,"MegatronBertForMultipleChoice"),Hyt.forEach(r),Uho=t(sbe," (MegatronBert model)"),sbe.forEach(r),Jho=i(W),X_=n(W,"LI",{});var lbe=s(X_);cK=n(lbe,"STRONG",{});var Uyt=s(cK);Kho=t(Uyt,"mobilebert"),Uyt.forEach(r),Yho=t(lbe," \u2014 "),dR=n(lbe,"A",{href:!0});var Jyt=s(dR);Zho=t(Jyt,"MobileBertForMultipleChoice"),Jyt.forEach(r),euo=t(lbe," (MobileBERT model)"),lbe.forEach(r),ouo=i(W),W_=n(W,"LI",{});var ibe=s(W_);gK=n(ibe,"STRONG",{});var Kyt=s(gK);tuo=t(Kyt,"mpnet"),Kyt.forEach(r),ruo=t(ibe," \u2014 "),mR=n(ibe,"A",{href:!0});var Yyt=s(mR);auo=t(Yyt,"MPNetForMultipleChoice"),Yyt.forEach(r),nuo=t(ibe," (MPNet model)"),ibe.forEach(r),suo=i(W),V_=n(W,"LI",{});var dbe=s(V_);hK=n(dbe,"STRONG",{});var Zyt=s(hK);luo=t(Zyt,"qdqbert"),Zyt.forEach(r),iuo=t(dbe," \u2014 "),fR=n(dbe,"A",{href:!0});var ewt=s(fR);duo=t(ewt,"QDQBertForMultipleChoice"),ewt.forEach(r),muo=t(dbe," (QDQBert model)"),dbe.forEach(r),fuo=i(W),Q_=n(W,"LI",{});var mbe=s(Q_);uK=n(mbe,"STRONG",{});var owt=s(uK);cuo=t(owt,"rembert"),owt.forEach(r),guo=t(mbe," \u2014 "),cR=n(mbe,"A",{href:!0});var twt=s(cR);huo=t(twt,"RemBertForMultipleChoice"),twt.forEach(r),uuo=t(mbe," (RemBERT model)"),mbe.forEach(r),puo=i(W),H_=n(W,"LI",{});var fbe=s(H_);pK=n(fbe,"STRONG",{});var rwt=s(pK);_uo=t(rwt,"roberta"),rwt.forEach(r),vuo=t(fbe," \u2014 "),gR=n(fbe,"A",{href:!0});var awt=s(gR);buo=t(awt,"RobertaForMultipleChoice"),awt.forEach(r),Tuo=t(fbe," (RoBERTa model)"),fbe.forEach(r),Fuo=i(W),U_=n(W,"LI",{});var cbe=s(U_);_K=n(cbe,"STRONG",{});var nwt=s(_K);Muo=t(nwt,"roformer"),nwt.forEach(r),Euo=t(cbe," \u2014 "),hR=n(cbe,"A",{href:!0});var swt=s(hR);Cuo=t(swt,"RoFormerForMultipleChoice"),swt.forEach(r),yuo=t(cbe," (RoFormer model)"),cbe.forEach(r),wuo=i(W),J_=n(W,"LI",{});var gbe=s(J_);vK=n(gbe,"STRONG",{});var lwt=s(vK);Auo=t(lwt,"squeezebert"),lwt.forEach(r),xuo=t(gbe," \u2014 "),uR=n(gbe,"A",{href:!0});var iwt=s(uR);Luo=t(iwt,"SqueezeBertForMultipleChoice"),iwt.forEach(r),Buo=t(gbe," (SqueezeBERT model)"),gbe.forEach(r),kuo=i(W),K_=n(W,"LI",{});var hbe=s(K_);bK=n(hbe,"STRONG",{});var dwt=s(bK);Ruo=t(dwt,"xlm"),dwt.forEach(r),Suo=t(hbe," \u2014 "),pR=n(hbe,"A",{href:!0});var mwt=s(pR);Puo=t(mwt,"XLMForMultipleChoice"),mwt.forEach(r),$uo=t(hbe," (XLM model)"),hbe.forEach(r),Iuo=i(W),Y_=n(W,"LI",{});var ube=s(Y_);TK=n(ube,"STRONG",{});var fwt=s(TK);juo=t(fwt,"xlm-roberta"),fwt.forEach(r),Nuo=t(ube," \u2014 "),_R=n(ube,"A",{href:!0});var cwt=s(_R);Duo=t(cwt,"XLMRobertaForMultipleChoice"),cwt.forEach(r),Guo=t(ube," (XLM-RoBERTa model)"),ube.forEach(r),Ouo=i(W),Z_=n(W,"LI",{});var pbe=s(Z_);FK=n(pbe,"STRONG",{});var gwt=s(FK);quo=t(gwt,"xlnet"),gwt.forEach(r),zuo=t(pbe," \u2014 "),vR=n(pbe,"A",{href:!0});var hwt=s(vR);Xuo=t(hwt,"XLNetForMultipleChoice"),hwt.forEach(r),Wuo=t(pbe," (XLNet model)"),pbe.forEach(r),W.forEach(r),Vuo=i(Cr),ev=n(Cr,"P",{});var _be=s(ev);Quo=t(_be,"The model is set in evaluation mode by default using "),MK=n(_be,"EM",{});var uwt=s(MK);Huo=t(uwt,"model.eval()"),uwt.forEach(r),Uuo=t(_be,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EK=n(_be,"EM",{});var pwt=s(EK);Juo=t(pwt,"model.train()"),pwt.forEach(r),_be.forEach(r),Kuo=i(Cr),CK=n(Cr,"P",{});var _wt=s(CK);Yuo=t(_wt,"Examples:"),_wt.forEach(r),Zuo=i(Cr),c(aE.$$.fragment,Cr),Cr.forEach(r),Cs.forEach(r),VEe=i(d),Ai=n(d,"H2",{class:!0});var z3e=s(Ai);ov=n(z3e,"A",{id:!0,class:!0,href:!0});var vwt=s(ov);yK=n(vwt,"SPAN",{});var bwt=s(yK);c(nE.$$.fragment,bwt),bwt.forEach(r),vwt.forEach(r),epo=i(z3e),wK=n(z3e,"SPAN",{});var Twt=s(wK);opo=t(Twt,"AutoModelForNextSentencePrediction"),Twt.forEach(r),z3e.forEach(r),QEe=i(d),Oo=n(d,"DIV",{class:!0});var ws=s(Oo);c(sE.$$.fragment,ws),tpo=i(ws),xi=n(ws,"P",{});var kD=s(xi);rpo=t(kD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),AK=n(kD,"CODE",{});var Fwt=s(AK);apo=t(Fwt,"from_pretrained()"),Fwt.forEach(r),npo=t(kD,` class method or the
`),xK=n(kD,"CODE",{});var Mwt=s(xK);spo=t(Mwt,"from_config()"),Mwt.forEach(r),lpo=t(kD," class method."),kD.forEach(r),ipo=i(ws),lE=n(ws,"P",{});var X3e=s(lE);dpo=t(X3e,"This class cannot be instantiated directly using "),LK=n(X3e,"CODE",{});var Ewt=s(LK);mpo=t(Ewt,"__init__()"),Ewt.forEach(r),fpo=t(X3e," (throws an error)."),X3e.forEach(r),cpo=i(ws),St=n(ws,"DIV",{class:!0});var As=s(St);c(iE.$$.fragment,As),gpo=i(As),BK=n(As,"P",{});var Cwt=s(BK);hpo=t(Cwt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Cwt.forEach(r),upo=i(As),Li=n(As,"P",{});var RD=s(Li);ppo=t(RD,`Note:
Loading a model from its configuration file does `),kK=n(RD,"STRONG",{});var ywt=s(kK);_po=t(ywt,"not"),ywt.forEach(r),vpo=t(RD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),RK=n(RD,"EM",{});var wwt=s(RK);bpo=t(wwt,"~AutoModelForNextSentencePrediction.from_pretrained"),wwt.forEach(r),Tpo=t(RD,`] to load the model
weights.`),RD.forEach(r),Fpo=i(As),SK=n(As,"P",{});var Awt=s(SK);Mpo=t(Awt,"Examples:"),Awt.forEach(r),Epo=i(As),c(dE.$$.fragment,As),As.forEach(r),Cpo=i(ws),$e=n(ws,"DIV",{class:!0});var yr=s($e);c(mE.$$.fragment,yr),ypo=i(yr),PK=n(yr,"P",{});var xwt=s(PK);wpo=t(xwt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),xwt.forEach(r),Apo=i(yr),Ba=n(yr,"P",{});var JT=s(Ba);xpo=t(JT,"The model class to instantiate is selected based on the "),$K=n(JT,"EM",{});var Lwt=s($K);Lpo=t(Lwt,"model_type"),Lwt.forEach(r),Bpo=t(JT,` property of the config object (either
passed as an argument or loaded from `),IK=n(JT,"EM",{});var Bwt=s(IK);kpo=t(Bwt,"pretrained_model_name_or_path"),Bwt.forEach(r),Rpo=t(JT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),jK=n(JT,"EM",{});var kwt=s(jK);Spo=t(kwt,"pretrained_model_name_or_path"),kwt.forEach(r),Ppo=t(JT,":"),JT.forEach(r),$po=i(yr),qr=n(yr,"UL",{});var xs=s(qr);tv=n(xs,"LI",{});var vbe=s(tv);NK=n(vbe,"STRONG",{});var Rwt=s(NK);Ipo=t(Rwt,"bert"),Rwt.forEach(r),jpo=t(vbe," \u2014 "),bR=n(vbe,"A",{href:!0});var Swt=s(bR);Npo=t(Swt,"BertForNextSentencePrediction"),Swt.forEach(r),Dpo=t(vbe," (BERT model)"),vbe.forEach(r),Gpo=i(xs),rv=n(xs,"LI",{});var bbe=s(rv);DK=n(bbe,"STRONG",{});var Pwt=s(DK);Opo=t(Pwt,"fnet"),Pwt.forEach(r),qpo=t(bbe," \u2014 "),TR=n(bbe,"A",{href:!0});var $wt=s(TR);zpo=t($wt,"FNetForNextSentencePrediction"),$wt.forEach(r),Xpo=t(bbe," (FNet model)"),bbe.forEach(r),Wpo=i(xs),av=n(xs,"LI",{});var Tbe=s(av);GK=n(Tbe,"STRONG",{});var Iwt=s(GK);Vpo=t(Iwt,"megatron-bert"),Iwt.forEach(r),Qpo=t(Tbe," \u2014 "),FR=n(Tbe,"A",{href:!0});var jwt=s(FR);Hpo=t(jwt,"MegatronBertForNextSentencePrediction"),jwt.forEach(r),Upo=t(Tbe," (MegatronBert model)"),Tbe.forEach(r),Jpo=i(xs),nv=n(xs,"LI",{});var Fbe=s(nv);OK=n(Fbe,"STRONG",{});var Nwt=s(OK);Kpo=t(Nwt,"mobilebert"),Nwt.forEach(r),Ypo=t(Fbe," \u2014 "),MR=n(Fbe,"A",{href:!0});var Dwt=s(MR);Zpo=t(Dwt,"MobileBertForNextSentencePrediction"),Dwt.forEach(r),e_o=t(Fbe," (MobileBERT model)"),Fbe.forEach(r),o_o=i(xs),sv=n(xs,"LI",{});var Mbe=s(sv);qK=n(Mbe,"STRONG",{});var Gwt=s(qK);t_o=t(Gwt,"qdqbert"),Gwt.forEach(r),r_o=t(Mbe," \u2014 "),ER=n(Mbe,"A",{href:!0});var Owt=s(ER);a_o=t(Owt,"QDQBertForNextSentencePrediction"),Owt.forEach(r),n_o=t(Mbe," (QDQBert model)"),Mbe.forEach(r),xs.forEach(r),s_o=i(yr),lv=n(yr,"P",{});var Ebe=s(lv);l_o=t(Ebe,"The model is set in evaluation mode by default using "),zK=n(Ebe,"EM",{});var qwt=s(zK);i_o=t(qwt,"model.eval()"),qwt.forEach(r),d_o=t(Ebe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XK=n(Ebe,"EM",{});var zwt=s(XK);m_o=t(zwt,"model.train()"),zwt.forEach(r),Ebe.forEach(r),f_o=i(yr),WK=n(yr,"P",{});var Xwt=s(WK);c_o=t(Xwt,"Examples:"),Xwt.forEach(r),g_o=i(yr),c(fE.$$.fragment,yr),yr.forEach(r),ws.forEach(r),HEe=i(d),Bi=n(d,"H2",{class:!0});var W3e=s(Bi);iv=n(W3e,"A",{id:!0,class:!0,href:!0});var Wwt=s(iv);VK=n(Wwt,"SPAN",{});var Vwt=s(VK);c(cE.$$.fragment,Vwt),Vwt.forEach(r),Wwt.forEach(r),h_o=i(W3e),QK=n(W3e,"SPAN",{});var Qwt=s(QK);u_o=t(Qwt,"AutoModelForTokenClassification"),Qwt.forEach(r),W3e.forEach(r),UEe=i(d),qo=n(d,"DIV",{class:!0});var Ls=s(qo);c(gE.$$.fragment,Ls),p_o=i(Ls),ki=n(Ls,"P",{});var SD=s(ki);__o=t(SD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HK=n(SD,"CODE",{});var Hwt=s(HK);v_o=t(Hwt,"from_pretrained()"),Hwt.forEach(r),b_o=t(SD,` class method or the
`),UK=n(SD,"CODE",{});var Uwt=s(UK);T_o=t(Uwt,"from_config()"),Uwt.forEach(r),F_o=t(SD," class method."),SD.forEach(r),M_o=i(Ls),hE=n(Ls,"P",{});var V3e=s(hE);E_o=t(V3e,"This class cannot be instantiated directly using "),JK=n(V3e,"CODE",{});var Jwt=s(JK);C_o=t(Jwt,"__init__()"),Jwt.forEach(r),y_o=t(V3e," (throws an error)."),V3e.forEach(r),w_o=i(Ls),Pt=n(Ls,"DIV",{class:!0});var Bs=s(Pt);c(uE.$$.fragment,Bs),A_o=i(Bs),KK=n(Bs,"P",{});var Kwt=s(KK);x_o=t(Kwt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Kwt.forEach(r),L_o=i(Bs),Ri=n(Bs,"P",{});var PD=s(Ri);B_o=t(PD,`Note:
Loading a model from its configuration file does `),YK=n(PD,"STRONG",{});var Ywt=s(YK);k_o=t(Ywt,"not"),Ywt.forEach(r),R_o=t(PD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),ZK=n(PD,"EM",{});var Zwt=s(ZK);S_o=t(Zwt,"~AutoModelForTokenClassification.from_pretrained"),Zwt.forEach(r),P_o=t(PD,`] to load the model
weights.`),PD.forEach(r),$_o=i(Bs),eY=n(Bs,"P",{});var eAt=s(eY);I_o=t(eAt,"Examples:"),eAt.forEach(r),j_o=i(Bs),c(pE.$$.fragment,Bs),Bs.forEach(r),N_o=i(Ls),Ie=n(Ls,"DIV",{class:!0});var wr=s(Ie);c(_E.$$.fragment,wr),D_o=i(wr),oY=n(wr,"P",{});var oAt=s(oY);G_o=t(oAt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),oAt.forEach(r),O_o=i(wr),ka=n(wr,"P",{});var KT=s(ka);q_o=t(KT,"The model class to instantiate is selected based on the "),tY=n(KT,"EM",{});var tAt=s(tY);z_o=t(tAt,"model_type"),tAt.forEach(r),X_o=t(KT,` property of the config object (either
passed as an argument or loaded from `),rY=n(KT,"EM",{});var rAt=s(rY);W_o=t(rAt,"pretrained_model_name_or_path"),rAt.forEach(r),V_o=t(KT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),aY=n(KT,"EM",{});var aAt=s(aY);Q_o=t(aAt,"pretrained_model_name_or_path"),aAt.forEach(r),H_o=t(KT,":"),KT.forEach(r),U_o=i(wr),N=n(wr,"UL",{});var G=s(N);dv=n(G,"LI",{});var Cbe=s(dv);nY=n(Cbe,"STRONG",{});var nAt=s(nY);J_o=t(nAt,"albert"),nAt.forEach(r),K_o=t(Cbe," \u2014 "),CR=n(Cbe,"A",{href:!0});var sAt=s(CR);Y_o=t(sAt,"AlbertForTokenClassification"),sAt.forEach(r),Z_o=t(Cbe," (ALBERT model)"),Cbe.forEach(r),evo=i(G),mv=n(G,"LI",{});var ybe=s(mv);sY=n(ybe,"STRONG",{});var lAt=s(sY);ovo=t(lAt,"bert"),lAt.forEach(r),tvo=t(ybe," \u2014 "),yR=n(ybe,"A",{href:!0});var iAt=s(yR);rvo=t(iAt,"BertForTokenClassification"),iAt.forEach(r),avo=t(ybe," (BERT model)"),ybe.forEach(r),nvo=i(G),fv=n(G,"LI",{});var wbe=s(fv);lY=n(wbe,"STRONG",{});var dAt=s(lY);svo=t(dAt,"big_bird"),dAt.forEach(r),lvo=t(wbe," \u2014 "),wR=n(wbe,"A",{href:!0});var mAt=s(wR);ivo=t(mAt,"BigBirdForTokenClassification"),mAt.forEach(r),dvo=t(wbe," (BigBird model)"),wbe.forEach(r),mvo=i(G),cv=n(G,"LI",{});var Abe=s(cv);iY=n(Abe,"STRONG",{});var fAt=s(iY);fvo=t(fAt,"camembert"),fAt.forEach(r),cvo=t(Abe," \u2014 "),AR=n(Abe,"A",{href:!0});var cAt=s(AR);gvo=t(cAt,"CamembertForTokenClassification"),cAt.forEach(r),hvo=t(Abe," (CamemBERT model)"),Abe.forEach(r),uvo=i(G),gv=n(G,"LI",{});var xbe=s(gv);dY=n(xbe,"STRONG",{});var gAt=s(dY);pvo=t(gAt,"canine"),gAt.forEach(r),_vo=t(xbe," \u2014 "),xR=n(xbe,"A",{href:!0});var hAt=s(xR);vvo=t(hAt,"CanineForTokenClassification"),hAt.forEach(r),bvo=t(xbe," (Canine model)"),xbe.forEach(r),Tvo=i(G),hv=n(G,"LI",{});var Lbe=s(hv);mY=n(Lbe,"STRONG",{});var uAt=s(mY);Fvo=t(uAt,"convbert"),uAt.forEach(r),Mvo=t(Lbe," \u2014 "),LR=n(Lbe,"A",{href:!0});var pAt=s(LR);Evo=t(pAt,"ConvBertForTokenClassification"),pAt.forEach(r),Cvo=t(Lbe," (ConvBERT model)"),Lbe.forEach(r),yvo=i(G),uv=n(G,"LI",{});var Bbe=s(uv);fY=n(Bbe,"STRONG",{});var _At=s(fY);wvo=t(_At,"deberta"),_At.forEach(r),Avo=t(Bbe," \u2014 "),BR=n(Bbe,"A",{href:!0});var vAt=s(BR);xvo=t(vAt,"DebertaForTokenClassification"),vAt.forEach(r),Lvo=t(Bbe," (DeBERTa model)"),Bbe.forEach(r),Bvo=i(G),pv=n(G,"LI",{});var kbe=s(pv);cY=n(kbe,"STRONG",{});var bAt=s(cY);kvo=t(bAt,"deberta-v2"),bAt.forEach(r),Rvo=t(kbe," \u2014 "),kR=n(kbe,"A",{href:!0});var TAt=s(kR);Svo=t(TAt,"DebertaV2ForTokenClassification"),TAt.forEach(r),Pvo=t(kbe," (DeBERTa-v2 model)"),kbe.forEach(r),$vo=i(G),_v=n(G,"LI",{});var Rbe=s(_v);gY=n(Rbe,"STRONG",{});var FAt=s(gY);Ivo=t(FAt,"distilbert"),FAt.forEach(r),jvo=t(Rbe," \u2014 "),RR=n(Rbe,"A",{href:!0});var MAt=s(RR);Nvo=t(MAt,"DistilBertForTokenClassification"),MAt.forEach(r),Dvo=t(Rbe," (DistilBERT model)"),Rbe.forEach(r),Gvo=i(G),vv=n(G,"LI",{});var Sbe=s(vv);hY=n(Sbe,"STRONG",{});var EAt=s(hY);Ovo=t(EAt,"electra"),EAt.forEach(r),qvo=t(Sbe," \u2014 "),SR=n(Sbe,"A",{href:!0});var CAt=s(SR);zvo=t(CAt,"ElectraForTokenClassification"),CAt.forEach(r),Xvo=t(Sbe," (ELECTRA model)"),Sbe.forEach(r),Wvo=i(G),bv=n(G,"LI",{});var Pbe=s(bv);uY=n(Pbe,"STRONG",{});var yAt=s(uY);Vvo=t(yAt,"flaubert"),yAt.forEach(r),Qvo=t(Pbe," \u2014 "),PR=n(Pbe,"A",{href:!0});var wAt=s(PR);Hvo=t(wAt,"FlaubertForTokenClassification"),wAt.forEach(r),Uvo=t(Pbe," (FlauBERT model)"),Pbe.forEach(r),Jvo=i(G),Tv=n(G,"LI",{});var $be=s(Tv);pY=n($be,"STRONG",{});var AAt=s(pY);Kvo=t(AAt,"fnet"),AAt.forEach(r),Yvo=t($be," \u2014 "),$R=n($be,"A",{href:!0});var xAt=s($R);Zvo=t(xAt,"FNetForTokenClassification"),xAt.forEach(r),e1o=t($be," (FNet model)"),$be.forEach(r),o1o=i(G),Fv=n(G,"LI",{});var Ibe=s(Fv);_Y=n(Ibe,"STRONG",{});var LAt=s(_Y);t1o=t(LAt,"funnel"),LAt.forEach(r),r1o=t(Ibe," \u2014 "),IR=n(Ibe,"A",{href:!0});var BAt=s(IR);a1o=t(BAt,"FunnelForTokenClassification"),BAt.forEach(r),n1o=t(Ibe," (Funnel Transformer model)"),Ibe.forEach(r),s1o=i(G),Mv=n(G,"LI",{});var jbe=s(Mv);vY=n(jbe,"STRONG",{});var kAt=s(vY);l1o=t(kAt,"gpt2"),kAt.forEach(r),i1o=t(jbe," \u2014 "),jR=n(jbe,"A",{href:!0});var RAt=s(jR);d1o=t(RAt,"GPT2ForTokenClassification"),RAt.forEach(r),m1o=t(jbe," (OpenAI GPT-2 model)"),jbe.forEach(r),f1o=i(G),Ev=n(G,"LI",{});var Nbe=s(Ev);bY=n(Nbe,"STRONG",{});var SAt=s(bY);c1o=t(SAt,"ibert"),SAt.forEach(r),g1o=t(Nbe," \u2014 "),NR=n(Nbe,"A",{href:!0});var PAt=s(NR);h1o=t(PAt,"IBertForTokenClassification"),PAt.forEach(r),u1o=t(Nbe," (I-BERT model)"),Nbe.forEach(r),p1o=i(G),Cv=n(G,"LI",{});var Dbe=s(Cv);TY=n(Dbe,"STRONG",{});var $At=s(TY);_1o=t($At,"layoutlm"),$At.forEach(r),v1o=t(Dbe," \u2014 "),DR=n(Dbe,"A",{href:!0});var IAt=s(DR);b1o=t(IAt,"LayoutLMForTokenClassification"),IAt.forEach(r),T1o=t(Dbe," (LayoutLM model)"),Dbe.forEach(r),F1o=i(G),yv=n(G,"LI",{});var Gbe=s(yv);FY=n(Gbe,"STRONG",{});var jAt=s(FY);M1o=t(jAt,"layoutlmv2"),jAt.forEach(r),E1o=t(Gbe," \u2014 "),GR=n(Gbe,"A",{href:!0});var NAt=s(GR);C1o=t(NAt,"LayoutLMv2ForTokenClassification"),NAt.forEach(r),y1o=t(Gbe," (LayoutLMv2 model)"),Gbe.forEach(r),w1o=i(G),wv=n(G,"LI",{});var Obe=s(wv);MY=n(Obe,"STRONG",{});var DAt=s(MY);A1o=t(DAt,"longformer"),DAt.forEach(r),x1o=t(Obe," \u2014 "),OR=n(Obe,"A",{href:!0});var GAt=s(OR);L1o=t(GAt,"LongformerForTokenClassification"),GAt.forEach(r),B1o=t(Obe," (Longformer model)"),Obe.forEach(r),k1o=i(G),Av=n(G,"LI",{});var qbe=s(Av);EY=n(qbe,"STRONG",{});var OAt=s(EY);R1o=t(OAt,"megatron-bert"),OAt.forEach(r),S1o=t(qbe," \u2014 "),qR=n(qbe,"A",{href:!0});var qAt=s(qR);P1o=t(qAt,"MegatronBertForTokenClassification"),qAt.forEach(r),$1o=t(qbe," (MegatronBert model)"),qbe.forEach(r),I1o=i(G),xv=n(G,"LI",{});var zbe=s(xv);CY=n(zbe,"STRONG",{});var zAt=s(CY);j1o=t(zAt,"mobilebert"),zAt.forEach(r),N1o=t(zbe," \u2014 "),zR=n(zbe,"A",{href:!0});var XAt=s(zR);D1o=t(XAt,"MobileBertForTokenClassification"),XAt.forEach(r),G1o=t(zbe," (MobileBERT model)"),zbe.forEach(r),O1o=i(G),Lv=n(G,"LI",{});var Xbe=s(Lv);yY=n(Xbe,"STRONG",{});var WAt=s(yY);q1o=t(WAt,"mpnet"),WAt.forEach(r),z1o=t(Xbe," \u2014 "),XR=n(Xbe,"A",{href:!0});var VAt=s(XR);X1o=t(VAt,"MPNetForTokenClassification"),VAt.forEach(r),W1o=t(Xbe," (MPNet model)"),Xbe.forEach(r),V1o=i(G),Bv=n(G,"LI",{});var Wbe=s(Bv);wY=n(Wbe,"STRONG",{});var QAt=s(wY);Q1o=t(QAt,"qdqbert"),QAt.forEach(r),H1o=t(Wbe," \u2014 "),WR=n(Wbe,"A",{href:!0});var HAt=s(WR);U1o=t(HAt,"QDQBertForTokenClassification"),HAt.forEach(r),J1o=t(Wbe," (QDQBert model)"),Wbe.forEach(r),K1o=i(G),kv=n(G,"LI",{});var Vbe=s(kv);AY=n(Vbe,"STRONG",{});var UAt=s(AY);Y1o=t(UAt,"rembert"),UAt.forEach(r),Z1o=t(Vbe," \u2014 "),VR=n(Vbe,"A",{href:!0});var JAt=s(VR);e2o=t(JAt,"RemBertForTokenClassification"),JAt.forEach(r),o2o=t(Vbe," (RemBERT model)"),Vbe.forEach(r),t2o=i(G),Rv=n(G,"LI",{});var Qbe=s(Rv);xY=n(Qbe,"STRONG",{});var KAt=s(xY);r2o=t(KAt,"roberta"),KAt.forEach(r),a2o=t(Qbe," \u2014 "),QR=n(Qbe,"A",{href:!0});var YAt=s(QR);n2o=t(YAt,"RobertaForTokenClassification"),YAt.forEach(r),s2o=t(Qbe," (RoBERTa model)"),Qbe.forEach(r),l2o=i(G),Sv=n(G,"LI",{});var Hbe=s(Sv);LY=n(Hbe,"STRONG",{});var ZAt=s(LY);i2o=t(ZAt,"roformer"),ZAt.forEach(r),d2o=t(Hbe," \u2014 "),HR=n(Hbe,"A",{href:!0});var e7t=s(HR);m2o=t(e7t,"RoFormerForTokenClassification"),e7t.forEach(r),f2o=t(Hbe," (RoFormer model)"),Hbe.forEach(r),c2o=i(G),Pv=n(G,"LI",{});var Ube=s(Pv);BY=n(Ube,"STRONG",{});var o7t=s(BY);g2o=t(o7t,"squeezebert"),o7t.forEach(r),h2o=t(Ube," \u2014 "),UR=n(Ube,"A",{href:!0});var t7t=s(UR);u2o=t(t7t,"SqueezeBertForTokenClassification"),t7t.forEach(r),p2o=t(Ube," (SqueezeBERT model)"),Ube.forEach(r),_2o=i(G),$v=n(G,"LI",{});var Jbe=s($v);kY=n(Jbe,"STRONG",{});var r7t=s(kY);v2o=t(r7t,"xlm"),r7t.forEach(r),b2o=t(Jbe," \u2014 "),JR=n(Jbe,"A",{href:!0});var a7t=s(JR);T2o=t(a7t,"XLMForTokenClassification"),a7t.forEach(r),F2o=t(Jbe," (XLM model)"),Jbe.forEach(r),M2o=i(G),Iv=n(G,"LI",{});var Kbe=s(Iv);RY=n(Kbe,"STRONG",{});var n7t=s(RY);E2o=t(n7t,"xlm-roberta"),n7t.forEach(r),C2o=t(Kbe," \u2014 "),KR=n(Kbe,"A",{href:!0});var s7t=s(KR);y2o=t(s7t,"XLMRobertaForTokenClassification"),s7t.forEach(r),w2o=t(Kbe," (XLM-RoBERTa model)"),Kbe.forEach(r),A2o=i(G),jv=n(G,"LI",{});var Ybe=s(jv);SY=n(Ybe,"STRONG",{});var l7t=s(SY);x2o=t(l7t,"xlnet"),l7t.forEach(r),L2o=t(Ybe," \u2014 "),YR=n(Ybe,"A",{href:!0});var i7t=s(YR);B2o=t(i7t,"XLNetForTokenClassification"),i7t.forEach(r),k2o=t(Ybe," (XLNet model)"),Ybe.forEach(r),G.forEach(r),R2o=i(wr),Nv=n(wr,"P",{});var Zbe=s(Nv);S2o=t(Zbe,"The model is set in evaluation mode by default using "),PY=n(Zbe,"EM",{});var d7t=s(PY);P2o=t(d7t,"model.eval()"),d7t.forEach(r),$2o=t(Zbe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Y=n(Zbe,"EM",{});var m7t=s($Y);I2o=t(m7t,"model.train()"),m7t.forEach(r),Zbe.forEach(r),j2o=i(wr),IY=n(wr,"P",{});var f7t=s(IY);N2o=t(f7t,"Examples:"),f7t.forEach(r),D2o=i(wr),c(vE.$$.fragment,wr),wr.forEach(r),Ls.forEach(r),JEe=i(d),Si=n(d,"H2",{class:!0});var Q3e=s(Si);Dv=n(Q3e,"A",{id:!0,class:!0,href:!0});var c7t=s(Dv);jY=n(c7t,"SPAN",{});var g7t=s(jY);c(bE.$$.fragment,g7t),g7t.forEach(r),c7t.forEach(r),G2o=i(Q3e),NY=n(Q3e,"SPAN",{});var h7t=s(NY);O2o=t(h7t,"AutoModelForQuestionAnswering"),h7t.forEach(r),Q3e.forEach(r),KEe=i(d),zo=n(d,"DIV",{class:!0});var ks=s(zo);c(TE.$$.fragment,ks),q2o=i(ks),Pi=n(ks,"P",{});var $D=s(Pi);z2o=t($D,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DY=n($D,"CODE",{});var u7t=s(DY);X2o=t(u7t,"from_pretrained()"),u7t.forEach(r),W2o=t($D,` class method or the
`),GY=n($D,"CODE",{});var p7t=s(GY);V2o=t(p7t,"from_config()"),p7t.forEach(r),Q2o=t($D," class method."),$D.forEach(r),H2o=i(ks),FE=n(ks,"P",{});var H3e=s(FE);U2o=t(H3e,"This class cannot be instantiated directly using "),OY=n(H3e,"CODE",{});var _7t=s(OY);J2o=t(_7t,"__init__()"),_7t.forEach(r),K2o=t(H3e," (throws an error)."),H3e.forEach(r),Y2o=i(ks),$t=n(ks,"DIV",{class:!0});var Rs=s($t);c(ME.$$.fragment,Rs),Z2o=i(Rs),qY=n(Rs,"P",{});var v7t=s(qY);ebo=t(v7t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v7t.forEach(r),obo=i(Rs),$i=n(Rs,"P",{});var ID=s($i);tbo=t(ID,`Note:
Loading a model from its configuration file does `),zY=n(ID,"STRONG",{});var b7t=s(zY);rbo=t(b7t,"not"),b7t.forEach(r),abo=t(ID,` load the model weights. It only affects the
model\u2019s configuration. Use [`),XY=n(ID,"EM",{});var T7t=s(XY);nbo=t(T7t,"~AutoModelForQuestionAnswering.from_pretrained"),T7t.forEach(r),sbo=t(ID,`] to load the model
weights.`),ID.forEach(r),lbo=i(Rs),WY=n(Rs,"P",{});var F7t=s(WY);ibo=t(F7t,"Examples:"),F7t.forEach(r),dbo=i(Rs),c(EE.$$.fragment,Rs),Rs.forEach(r),mbo=i(ks),je=n(ks,"DIV",{class:!0});var Ar=s(je);c(CE.$$.fragment,Ar),fbo=i(Ar),VY=n(Ar,"P",{});var M7t=s(VY);cbo=t(M7t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),M7t.forEach(r),gbo=i(Ar),Ra=n(Ar,"P",{});var YT=s(Ra);hbo=t(YT,"The model class to instantiate is selected based on the "),QY=n(YT,"EM",{});var E7t=s(QY);ubo=t(E7t,"model_type"),E7t.forEach(r),pbo=t(YT,` property of the config object (either
passed as an argument or loaded from `),HY=n(YT,"EM",{});var C7t=s(HY);_bo=t(C7t,"pretrained_model_name_or_path"),C7t.forEach(r),vbo=t(YT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),UY=n(YT,"EM",{});var y7t=s(UY);bbo=t(y7t,"pretrained_model_name_or_path"),y7t.forEach(r),Tbo=t(YT,":"),YT.forEach(r),Fbo=i(Ar),R=n(Ar,"UL",{});var P=s(R);Gv=n(P,"LI",{});var e4e=s(Gv);JY=n(e4e,"STRONG",{});var w7t=s(JY);Mbo=t(w7t,"albert"),w7t.forEach(r),Ebo=t(e4e," \u2014 "),ZR=n(e4e,"A",{href:!0});var A7t=s(ZR);Cbo=t(A7t,"AlbertForQuestionAnswering"),A7t.forEach(r),ybo=t(e4e," (ALBERT model)"),e4e.forEach(r),wbo=i(P),Ov=n(P,"LI",{});var o4e=s(Ov);KY=n(o4e,"STRONG",{});var x7t=s(KY);Abo=t(x7t,"bart"),x7t.forEach(r),xbo=t(o4e," \u2014 "),eS=n(o4e,"A",{href:!0});var L7t=s(eS);Lbo=t(L7t,"BartForQuestionAnswering"),L7t.forEach(r),Bbo=t(o4e," (BART model)"),o4e.forEach(r),kbo=i(P),qv=n(P,"LI",{});var t4e=s(qv);YY=n(t4e,"STRONG",{});var B7t=s(YY);Rbo=t(B7t,"bert"),B7t.forEach(r),Sbo=t(t4e," \u2014 "),oS=n(t4e,"A",{href:!0});var k7t=s(oS);Pbo=t(k7t,"BertForQuestionAnswering"),k7t.forEach(r),$bo=t(t4e," (BERT model)"),t4e.forEach(r),Ibo=i(P),zv=n(P,"LI",{});var r4e=s(zv);ZY=n(r4e,"STRONG",{});var R7t=s(ZY);jbo=t(R7t,"big_bird"),R7t.forEach(r),Nbo=t(r4e," \u2014 "),tS=n(r4e,"A",{href:!0});var S7t=s(tS);Dbo=t(S7t,"BigBirdForQuestionAnswering"),S7t.forEach(r),Gbo=t(r4e," (BigBird model)"),r4e.forEach(r),Obo=i(P),Xv=n(P,"LI",{});var a4e=s(Xv);eZ=n(a4e,"STRONG",{});var P7t=s(eZ);qbo=t(P7t,"bigbird_pegasus"),P7t.forEach(r),zbo=t(a4e," \u2014 "),rS=n(a4e,"A",{href:!0});var $7t=s(rS);Xbo=t($7t,"BigBirdPegasusForQuestionAnswering"),$7t.forEach(r),Wbo=t(a4e," (BigBirdPegasus model)"),a4e.forEach(r),Vbo=i(P),Wv=n(P,"LI",{});var n4e=s(Wv);oZ=n(n4e,"STRONG",{});var I7t=s(oZ);Qbo=t(I7t,"camembert"),I7t.forEach(r),Hbo=t(n4e," \u2014 "),aS=n(n4e,"A",{href:!0});var j7t=s(aS);Ubo=t(j7t,"CamembertForQuestionAnswering"),j7t.forEach(r),Jbo=t(n4e," (CamemBERT model)"),n4e.forEach(r),Kbo=i(P),Vv=n(P,"LI",{});var s4e=s(Vv);tZ=n(s4e,"STRONG",{});var N7t=s(tZ);Ybo=t(N7t,"canine"),N7t.forEach(r),Zbo=t(s4e," \u2014 "),nS=n(s4e,"A",{href:!0});var D7t=s(nS);e4o=t(D7t,"CanineForQuestionAnswering"),D7t.forEach(r),o4o=t(s4e," (Canine model)"),s4e.forEach(r),t4o=i(P),Qv=n(P,"LI",{});var l4e=s(Qv);rZ=n(l4e,"STRONG",{});var G7t=s(rZ);r4o=t(G7t,"convbert"),G7t.forEach(r),a4o=t(l4e," \u2014 "),sS=n(l4e,"A",{href:!0});var O7t=s(sS);n4o=t(O7t,"ConvBertForQuestionAnswering"),O7t.forEach(r),s4o=t(l4e," (ConvBERT model)"),l4e.forEach(r),l4o=i(P),Hv=n(P,"LI",{});var i4e=s(Hv);aZ=n(i4e,"STRONG",{});var q7t=s(aZ);i4o=t(q7t,"deberta"),q7t.forEach(r),d4o=t(i4e," \u2014 "),lS=n(i4e,"A",{href:!0});var z7t=s(lS);m4o=t(z7t,"DebertaForQuestionAnswering"),z7t.forEach(r),f4o=t(i4e," (DeBERTa model)"),i4e.forEach(r),c4o=i(P),Uv=n(P,"LI",{});var d4e=s(Uv);nZ=n(d4e,"STRONG",{});var X7t=s(nZ);g4o=t(X7t,"deberta-v2"),X7t.forEach(r),h4o=t(d4e," \u2014 "),iS=n(d4e,"A",{href:!0});var W7t=s(iS);u4o=t(W7t,"DebertaV2ForQuestionAnswering"),W7t.forEach(r),p4o=t(d4e," (DeBERTa-v2 model)"),d4e.forEach(r),_4o=i(P),Jv=n(P,"LI",{});var m4e=s(Jv);sZ=n(m4e,"STRONG",{});var V7t=s(sZ);v4o=t(V7t,"distilbert"),V7t.forEach(r),b4o=t(m4e," \u2014 "),dS=n(m4e,"A",{href:!0});var Q7t=s(dS);T4o=t(Q7t,"DistilBertForQuestionAnswering"),Q7t.forEach(r),F4o=t(m4e," (DistilBERT model)"),m4e.forEach(r),M4o=i(P),Kv=n(P,"LI",{});var f4e=s(Kv);lZ=n(f4e,"STRONG",{});var H7t=s(lZ);E4o=t(H7t,"electra"),H7t.forEach(r),C4o=t(f4e," \u2014 "),mS=n(f4e,"A",{href:!0});var U7t=s(mS);y4o=t(U7t,"ElectraForQuestionAnswering"),U7t.forEach(r),w4o=t(f4e," (ELECTRA model)"),f4e.forEach(r),A4o=i(P),Yv=n(P,"LI",{});var c4e=s(Yv);iZ=n(c4e,"STRONG",{});var J7t=s(iZ);x4o=t(J7t,"flaubert"),J7t.forEach(r),L4o=t(c4e," \u2014 "),fS=n(c4e,"A",{href:!0});var K7t=s(fS);B4o=t(K7t,"FlaubertForQuestionAnsweringSimple"),K7t.forEach(r),k4o=t(c4e," (FlauBERT model)"),c4e.forEach(r),R4o=i(P),Zv=n(P,"LI",{});var g4e=s(Zv);dZ=n(g4e,"STRONG",{});var Y7t=s(dZ);S4o=t(Y7t,"fnet"),Y7t.forEach(r),P4o=t(g4e," \u2014 "),cS=n(g4e,"A",{href:!0});var Z7t=s(cS);$4o=t(Z7t,"FNetForQuestionAnswering"),Z7t.forEach(r),I4o=t(g4e," (FNet model)"),g4e.forEach(r),j4o=i(P),e1=n(P,"LI",{});var h4e=s(e1);mZ=n(h4e,"STRONG",{});var ext=s(mZ);N4o=t(ext,"funnel"),ext.forEach(r),D4o=t(h4e," \u2014 "),gS=n(h4e,"A",{href:!0});var oxt=s(gS);G4o=t(oxt,"FunnelForQuestionAnswering"),oxt.forEach(r),O4o=t(h4e," (Funnel Transformer model)"),h4e.forEach(r),q4o=i(P),o1=n(P,"LI",{});var u4e=s(o1);fZ=n(u4e,"STRONG",{});var txt=s(fZ);z4o=t(txt,"gptj"),txt.forEach(r),X4o=t(u4e," \u2014 "),hS=n(u4e,"A",{href:!0});var rxt=s(hS);W4o=t(rxt,"GPTJForQuestionAnswering"),rxt.forEach(r),V4o=t(u4e," (GPT-J model)"),u4e.forEach(r),Q4o=i(P),t1=n(P,"LI",{});var p4e=s(t1);cZ=n(p4e,"STRONG",{});var axt=s(cZ);H4o=t(axt,"ibert"),axt.forEach(r),U4o=t(p4e," \u2014 "),uS=n(p4e,"A",{href:!0});var nxt=s(uS);J4o=t(nxt,"IBertForQuestionAnswering"),nxt.forEach(r),K4o=t(p4e," (I-BERT model)"),p4e.forEach(r),Y4o=i(P),r1=n(P,"LI",{});var _4e=s(r1);gZ=n(_4e,"STRONG",{});var sxt=s(gZ);Z4o=t(sxt,"layoutlmv2"),sxt.forEach(r),e5o=t(_4e," \u2014 "),pS=n(_4e,"A",{href:!0});var lxt=s(pS);o5o=t(lxt,"LayoutLMv2ForQuestionAnswering"),lxt.forEach(r),t5o=t(_4e," (LayoutLMv2 model)"),_4e.forEach(r),r5o=i(P),a1=n(P,"LI",{});var v4e=s(a1);hZ=n(v4e,"STRONG",{});var ixt=s(hZ);a5o=t(ixt,"led"),ixt.forEach(r),n5o=t(v4e," \u2014 "),_S=n(v4e,"A",{href:!0});var dxt=s(_S);s5o=t(dxt,"LEDForQuestionAnswering"),dxt.forEach(r),l5o=t(v4e," (LED model)"),v4e.forEach(r),i5o=i(P),n1=n(P,"LI",{});var b4e=s(n1);uZ=n(b4e,"STRONG",{});var mxt=s(uZ);d5o=t(mxt,"longformer"),mxt.forEach(r),m5o=t(b4e," \u2014 "),vS=n(b4e,"A",{href:!0});var fxt=s(vS);f5o=t(fxt,"LongformerForQuestionAnswering"),fxt.forEach(r),c5o=t(b4e," (Longformer model)"),b4e.forEach(r),g5o=i(P),s1=n(P,"LI",{});var T4e=s(s1);pZ=n(T4e,"STRONG",{});var cxt=s(pZ);h5o=t(cxt,"lxmert"),cxt.forEach(r),u5o=t(T4e," \u2014 "),bS=n(T4e,"A",{href:!0});var gxt=s(bS);p5o=t(gxt,"LxmertForQuestionAnswering"),gxt.forEach(r),_5o=t(T4e," (LXMERT model)"),T4e.forEach(r),v5o=i(P),l1=n(P,"LI",{});var F4e=s(l1);_Z=n(F4e,"STRONG",{});var hxt=s(_Z);b5o=t(hxt,"mbart"),hxt.forEach(r),T5o=t(F4e," \u2014 "),TS=n(F4e,"A",{href:!0});var uxt=s(TS);F5o=t(uxt,"MBartForQuestionAnswering"),uxt.forEach(r),M5o=t(F4e," (mBART model)"),F4e.forEach(r),E5o=i(P),i1=n(P,"LI",{});var M4e=s(i1);vZ=n(M4e,"STRONG",{});var pxt=s(vZ);C5o=t(pxt,"megatron-bert"),pxt.forEach(r),y5o=t(M4e," \u2014 "),FS=n(M4e,"A",{href:!0});var _xt=s(FS);w5o=t(_xt,"MegatronBertForQuestionAnswering"),_xt.forEach(r),A5o=t(M4e," (MegatronBert model)"),M4e.forEach(r),x5o=i(P),d1=n(P,"LI",{});var E4e=s(d1);bZ=n(E4e,"STRONG",{});var vxt=s(bZ);L5o=t(vxt,"mobilebert"),vxt.forEach(r),B5o=t(E4e," \u2014 "),MS=n(E4e,"A",{href:!0});var bxt=s(MS);k5o=t(bxt,"MobileBertForQuestionAnswering"),bxt.forEach(r),R5o=t(E4e," (MobileBERT model)"),E4e.forEach(r),S5o=i(P),m1=n(P,"LI",{});var C4e=s(m1);TZ=n(C4e,"STRONG",{});var Txt=s(TZ);P5o=t(Txt,"mpnet"),Txt.forEach(r),$5o=t(C4e," \u2014 "),ES=n(C4e,"A",{href:!0});var Fxt=s(ES);I5o=t(Fxt,"MPNetForQuestionAnswering"),Fxt.forEach(r),j5o=t(C4e," (MPNet model)"),C4e.forEach(r),N5o=i(P),f1=n(P,"LI",{});var y4e=s(f1);FZ=n(y4e,"STRONG",{});var Mxt=s(FZ);D5o=t(Mxt,"qdqbert"),Mxt.forEach(r),G5o=t(y4e," \u2014 "),CS=n(y4e,"A",{href:!0});var Ext=s(CS);O5o=t(Ext,"QDQBertForQuestionAnswering"),Ext.forEach(r),q5o=t(y4e," (QDQBert model)"),y4e.forEach(r),z5o=i(P),c1=n(P,"LI",{});var w4e=s(c1);MZ=n(w4e,"STRONG",{});var Cxt=s(MZ);X5o=t(Cxt,"reformer"),Cxt.forEach(r),W5o=t(w4e," \u2014 "),yS=n(w4e,"A",{href:!0});var yxt=s(yS);V5o=t(yxt,"ReformerForQuestionAnswering"),yxt.forEach(r),Q5o=t(w4e," (Reformer model)"),w4e.forEach(r),H5o=i(P),g1=n(P,"LI",{});var A4e=s(g1);EZ=n(A4e,"STRONG",{});var wxt=s(EZ);U5o=t(wxt,"rembert"),wxt.forEach(r),J5o=t(A4e," \u2014 "),wS=n(A4e,"A",{href:!0});var Axt=s(wS);K5o=t(Axt,"RemBertForQuestionAnswering"),Axt.forEach(r),Y5o=t(A4e," (RemBERT model)"),A4e.forEach(r),Z5o=i(P),h1=n(P,"LI",{});var x4e=s(h1);CZ=n(x4e,"STRONG",{});var xxt=s(CZ);e0o=t(xxt,"roberta"),xxt.forEach(r),o0o=t(x4e," \u2014 "),AS=n(x4e,"A",{href:!0});var Lxt=s(AS);t0o=t(Lxt,"RobertaForQuestionAnswering"),Lxt.forEach(r),r0o=t(x4e," (RoBERTa model)"),x4e.forEach(r),a0o=i(P),u1=n(P,"LI",{});var L4e=s(u1);yZ=n(L4e,"STRONG",{});var Bxt=s(yZ);n0o=t(Bxt,"roformer"),Bxt.forEach(r),s0o=t(L4e," \u2014 "),xS=n(L4e,"A",{href:!0});var kxt=s(xS);l0o=t(kxt,"RoFormerForQuestionAnswering"),kxt.forEach(r),i0o=t(L4e," (RoFormer model)"),L4e.forEach(r),d0o=i(P),p1=n(P,"LI",{});var B4e=s(p1);wZ=n(B4e,"STRONG",{});var Rxt=s(wZ);m0o=t(Rxt,"splinter"),Rxt.forEach(r),f0o=t(B4e," \u2014 "),LS=n(B4e,"A",{href:!0});var Sxt=s(LS);c0o=t(Sxt,"SplinterForQuestionAnswering"),Sxt.forEach(r),g0o=t(B4e," (Splinter model)"),B4e.forEach(r),h0o=i(P),_1=n(P,"LI",{});var k4e=s(_1);AZ=n(k4e,"STRONG",{});var Pxt=s(AZ);u0o=t(Pxt,"squeezebert"),Pxt.forEach(r),p0o=t(k4e," \u2014 "),BS=n(k4e,"A",{href:!0});var $xt=s(BS);_0o=t($xt,"SqueezeBertForQuestionAnswering"),$xt.forEach(r),v0o=t(k4e," (SqueezeBERT model)"),k4e.forEach(r),b0o=i(P),v1=n(P,"LI",{});var R4e=s(v1);xZ=n(R4e,"STRONG",{});var Ixt=s(xZ);T0o=t(Ixt,"xlm"),Ixt.forEach(r),F0o=t(R4e," \u2014 "),kS=n(R4e,"A",{href:!0});var jxt=s(kS);M0o=t(jxt,"XLMForQuestionAnsweringSimple"),jxt.forEach(r),E0o=t(R4e," (XLM model)"),R4e.forEach(r),C0o=i(P),b1=n(P,"LI",{});var S4e=s(b1);LZ=n(S4e,"STRONG",{});var Nxt=s(LZ);y0o=t(Nxt,"xlm-roberta"),Nxt.forEach(r),w0o=t(S4e," \u2014 "),RS=n(S4e,"A",{href:!0});var Dxt=s(RS);A0o=t(Dxt,"XLMRobertaForQuestionAnswering"),Dxt.forEach(r),x0o=t(S4e," (XLM-RoBERTa model)"),S4e.forEach(r),L0o=i(P),T1=n(P,"LI",{});var P4e=s(T1);BZ=n(P4e,"STRONG",{});var Gxt=s(BZ);B0o=t(Gxt,"xlnet"),Gxt.forEach(r),k0o=t(P4e," \u2014 "),SS=n(P4e,"A",{href:!0});var Oxt=s(SS);R0o=t(Oxt,"XLNetForQuestionAnsweringSimple"),Oxt.forEach(r),S0o=t(P4e," (XLNet model)"),P4e.forEach(r),P.forEach(r),P0o=i(Ar),F1=n(Ar,"P",{});var $4e=s(F1);$0o=t($4e,"The model is set in evaluation mode by default using "),kZ=n($4e,"EM",{});var qxt=s(kZ);I0o=t(qxt,"model.eval()"),qxt.forEach(r),j0o=t($4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),RZ=n($4e,"EM",{});var zxt=s(RZ);N0o=t(zxt,"model.train()"),zxt.forEach(r),$4e.forEach(r),D0o=i(Ar),SZ=n(Ar,"P",{});var Xxt=s(SZ);G0o=t(Xxt,"Examples:"),Xxt.forEach(r),O0o=i(Ar),c(yE.$$.fragment,Ar),Ar.forEach(r),ks.forEach(r),YEe=i(d),Ii=n(d,"H2",{class:!0});var U3e=s(Ii);M1=n(U3e,"A",{id:!0,class:!0,href:!0});var Wxt=s(M1);PZ=n(Wxt,"SPAN",{});var Vxt=s(PZ);c(wE.$$.fragment,Vxt),Vxt.forEach(r),Wxt.forEach(r),q0o=i(U3e),$Z=n(U3e,"SPAN",{});var Qxt=s($Z);z0o=t(Qxt,"AutoModelForTableQuestionAnswering"),Qxt.forEach(r),U3e.forEach(r),ZEe=i(d),Xo=n(d,"DIV",{class:!0});var Ss=s(Xo);c(AE.$$.fragment,Ss),X0o=i(Ss),ji=n(Ss,"P",{});var jD=s(ji);W0o=t(jD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),IZ=n(jD,"CODE",{});var Hxt=s(IZ);V0o=t(Hxt,"from_pretrained()"),Hxt.forEach(r),Q0o=t(jD,` class method or the
`),jZ=n(jD,"CODE",{});var Uxt=s(jZ);H0o=t(Uxt,"from_config()"),Uxt.forEach(r),U0o=t(jD," class method."),jD.forEach(r),J0o=i(Ss),xE=n(Ss,"P",{});var J3e=s(xE);K0o=t(J3e,"This class cannot be instantiated directly using "),NZ=n(J3e,"CODE",{});var Jxt=s(NZ);Y0o=t(Jxt,"__init__()"),Jxt.forEach(r),Z0o=t(J3e," (throws an error)."),J3e.forEach(r),eTo=i(Ss),It=n(Ss,"DIV",{class:!0});var Ps=s(It);c(LE.$$.fragment,Ps),oTo=i(Ps),DZ=n(Ps,"P",{});var Kxt=s(DZ);tTo=t(Kxt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Kxt.forEach(r),rTo=i(Ps),Ni=n(Ps,"P",{});var ND=s(Ni);aTo=t(ND,`Note:
Loading a model from its configuration file does `),GZ=n(ND,"STRONG",{});var Yxt=s(GZ);nTo=t(Yxt,"not"),Yxt.forEach(r),sTo=t(ND,` load the model weights. It only affects the
model\u2019s configuration. Use [`),OZ=n(ND,"EM",{});var Zxt=s(OZ);lTo=t(Zxt,"~AutoModelForTableQuestionAnswering.from_pretrained"),Zxt.forEach(r),iTo=t(ND,`] to load the model
weights.`),ND.forEach(r),dTo=i(Ps),qZ=n(Ps,"P",{});var e6t=s(qZ);mTo=t(e6t,"Examples:"),e6t.forEach(r),fTo=i(Ps),c(BE.$$.fragment,Ps),Ps.forEach(r),cTo=i(Ss),Ne=n(Ss,"DIV",{class:!0});var xr=s(Ne);c(kE.$$.fragment,xr),gTo=i(xr),zZ=n(xr,"P",{});var o6t=s(zZ);hTo=t(o6t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),o6t.forEach(r),uTo=i(xr),Sa=n(xr,"P",{});var ZT=s(Sa);pTo=t(ZT,"The model class to instantiate is selected based on the "),XZ=n(ZT,"EM",{});var t6t=s(XZ);_To=t(t6t,"model_type"),t6t.forEach(r),vTo=t(ZT,` property of the config object (either
passed as an argument or loaded from `),WZ=n(ZT,"EM",{});var r6t=s(WZ);bTo=t(r6t,"pretrained_model_name_or_path"),r6t.forEach(r),TTo=t(ZT,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),VZ=n(ZT,"EM",{});var a6t=s(VZ);FTo=t(a6t,"pretrained_model_name_or_path"),a6t.forEach(r),MTo=t(ZT,":"),ZT.forEach(r),ETo=i(xr),QZ=n(xr,"UL",{});var n6t=s(QZ);E1=n(n6t,"LI",{});var I4e=s(E1);HZ=n(I4e,"STRONG",{});var s6t=s(HZ);CTo=t(s6t,"tapas"),s6t.forEach(r),yTo=t(I4e," \u2014 "),PS=n(I4e,"A",{href:!0});var l6t=s(PS);wTo=t(l6t,"TapasForQuestionAnswering"),l6t.forEach(r),ATo=t(I4e," (TAPAS model)"),I4e.forEach(r),n6t.forEach(r),xTo=i(xr),C1=n(xr,"P",{});var j4e=s(C1);LTo=t(j4e,"The model is set in evaluation mode by default using "),UZ=n(j4e,"EM",{});var i6t=s(UZ);BTo=t(i6t,"model.eval()"),i6t.forEach(r),kTo=t(j4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JZ=n(j4e,"EM",{});var d6t=s(JZ);RTo=t(d6t,"model.train()"),d6t.forEach(r),j4e.forEach(r),STo=i(xr),KZ=n(xr,"P",{});var m6t=s(KZ);PTo=t(m6t,"Examples:"),m6t.forEach(r),$To=i(xr),c(RE.$$.fragment,xr),xr.forEach(r),Ss.forEach(r),eCe=i(d),Di=n(d,"H2",{class:!0});var K3e=s(Di);y1=n(K3e,"A",{id:!0,class:!0,href:!0});var f6t=s(y1);YZ=n(f6t,"SPAN",{});var c6t=s(YZ);c(SE.$$.fragment,c6t),c6t.forEach(r),f6t.forEach(r),ITo=i(K3e),ZZ=n(K3e,"SPAN",{});var g6t=s(ZZ);jTo=t(g6t,"AutoModelForImageClassification"),g6t.forEach(r),K3e.forEach(r),oCe=i(d),Wo=n(d,"DIV",{class:!0});var $s=s(Wo);c(PE.$$.fragment,$s),NTo=i($s),Gi=n($s,"P",{});var DD=s(Gi);DTo=t(DD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eee=n(DD,"CODE",{});var h6t=s(eee);GTo=t(h6t,"from_pretrained()"),h6t.forEach(r),OTo=t(DD,` class method or the
`),oee=n(DD,"CODE",{});var u6t=s(oee);qTo=t(u6t,"from_config()"),u6t.forEach(r),zTo=t(DD," class method."),DD.forEach(r),XTo=i($s),$E=n($s,"P",{});var Y3e=s($E);WTo=t(Y3e,"This class cannot be instantiated directly using "),tee=n(Y3e,"CODE",{});var p6t=s(tee);VTo=t(p6t,"__init__()"),p6t.forEach(r),QTo=t(Y3e," (throws an error)."),Y3e.forEach(r),HTo=i($s),jt=n($s,"DIV",{class:!0});var Is=s(jt);c(IE.$$.fragment,Is),UTo=i(Is),ree=n(Is,"P",{});var _6t=s(ree);JTo=t(_6t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_6t.forEach(r),KTo=i(Is),Oi=n(Is,"P",{});var GD=s(Oi);YTo=t(GD,`Note:
Loading a model from its configuration file does `),aee=n(GD,"STRONG",{});var v6t=s(aee);ZTo=t(v6t,"not"),v6t.forEach(r),eFo=t(GD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),nee=n(GD,"EM",{});var b6t=s(nee);oFo=t(b6t,"~AutoModelForImageClassification.from_pretrained"),b6t.forEach(r),tFo=t(GD,`] to load the model
weights.`),GD.forEach(r),rFo=i(Is),see=n(Is,"P",{});var T6t=s(see);aFo=t(T6t,"Examples:"),T6t.forEach(r),nFo=i(Is),c(jE.$$.fragment,Is),Is.forEach(r),sFo=i($s),De=n($s,"DIV",{class:!0});var Lr=s(De);c(NE.$$.fragment,Lr),lFo=i(Lr),lee=n(Lr,"P",{});var F6t=s(lee);iFo=t(F6t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),F6t.forEach(r),dFo=i(Lr),Pa=n(Lr,"P",{});var eF=s(Pa);mFo=t(eF,"The model class to instantiate is selected based on the "),iee=n(eF,"EM",{});var M6t=s(iee);fFo=t(M6t,"model_type"),M6t.forEach(r),cFo=t(eF,` property of the config object (either
passed as an argument or loaded from `),dee=n(eF,"EM",{});var E6t=s(dee);gFo=t(E6t,"pretrained_model_name_or_path"),E6t.forEach(r),hFo=t(eF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),mee=n(eF,"EM",{});var C6t=s(mee);uFo=t(C6t,"pretrained_model_name_or_path"),C6t.forEach(r),pFo=t(eF,":"),eF.forEach(r),_Fo=i(Lr),Vo=n(Lr,"UL",{});var Qr=s(Vo);w1=n(Qr,"LI",{});var N4e=s(w1);fee=n(N4e,"STRONG",{});var y6t=s(fee);vFo=t(y6t,"beit"),y6t.forEach(r),bFo=t(N4e," \u2014 "),$S=n(N4e,"A",{href:!0});var w6t=s($S);TFo=t(w6t,"BeitForImageClassification"),w6t.forEach(r),FFo=t(N4e," (BEiT model)"),N4e.forEach(r),MFo=i(Qr),is=n(Qr,"LI",{});var PA=s(is);cee=n(PA,"STRONG",{});var A6t=s(cee);EFo=t(A6t,"deit"),A6t.forEach(r),CFo=t(PA," \u2014 "),IS=n(PA,"A",{href:!0});var x6t=s(IS);yFo=t(x6t,"DeiTForImageClassification"),x6t.forEach(r),wFo=t(PA," or "),jS=n(PA,"A",{href:!0});var L6t=s(jS);AFo=t(L6t,"DeiTForImageClassificationWithTeacher"),L6t.forEach(r),xFo=t(PA," (DeiT model)"),PA.forEach(r),LFo=i(Qr),A1=n(Qr,"LI",{});var D4e=s(A1);gee=n(D4e,"STRONG",{});var B6t=s(gee);BFo=t(B6t,"imagegpt"),B6t.forEach(r),kFo=t(D4e," \u2014 "),NS=n(D4e,"A",{href:!0});var k6t=s(NS);RFo=t(k6t,"ImageGPTForImageClassification"),k6t.forEach(r),SFo=t(D4e," (ImageGPT model)"),D4e.forEach(r),PFo=i(Qr),Xr=n(Qr,"LI",{});var Bm=s(Xr);hee=n(Bm,"STRONG",{});var R6t=s(hee);$Fo=t(R6t,"perceiver"),R6t.forEach(r),IFo=t(Bm," \u2014 "),DS=n(Bm,"A",{href:!0});var S6t=s(DS);jFo=t(S6t,"PerceiverForImageClassificationLearned"),S6t.forEach(r),NFo=t(Bm," or "),GS=n(Bm,"A",{href:!0});var P6t=s(GS);DFo=t(P6t,"PerceiverForImageClassificationFourier"),P6t.forEach(r),GFo=t(Bm," or "),OS=n(Bm,"A",{href:!0});var $6t=s(OS);OFo=t($6t,"PerceiverForImageClassificationConvProcessing"),$6t.forEach(r),qFo=t(Bm," (Perceiver model)"),Bm.forEach(r),zFo=i(Qr),x1=n(Qr,"LI",{});var G4e=s(x1);uee=n(G4e,"STRONG",{});var I6t=s(uee);XFo=t(I6t,"segformer"),I6t.forEach(r),WFo=t(G4e," \u2014 "),qS=n(G4e,"A",{href:!0});var j6t=s(qS);VFo=t(j6t,"SegformerForImageClassification"),j6t.forEach(r),QFo=t(G4e," (SegFormer model)"),G4e.forEach(r),HFo=i(Qr),L1=n(Qr,"LI",{});var O4e=s(L1);pee=n(O4e,"STRONG",{});var N6t=s(pee);UFo=t(N6t,"vit"),N6t.forEach(r),JFo=t(O4e," \u2014 "),zS=n(O4e,"A",{href:!0});var D6t=s(zS);KFo=t(D6t,"ViTForImageClassification"),D6t.forEach(r),YFo=t(O4e," (ViT model)"),O4e.forEach(r),Qr.forEach(r),ZFo=i(Lr),B1=n(Lr,"P",{});var q4e=s(B1);eMo=t(q4e,"The model is set in evaluation mode by default using "),_ee=n(q4e,"EM",{});var G6t=s(_ee);oMo=t(G6t,"model.eval()"),G6t.forEach(r),tMo=t(q4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vee=n(q4e,"EM",{});var O6t=s(vee);rMo=t(O6t,"model.train()"),O6t.forEach(r),q4e.forEach(r),aMo=i(Lr),bee=n(Lr,"P",{});var q6t=s(bee);nMo=t(q6t,"Examples:"),q6t.forEach(r),sMo=i(Lr),c(DE.$$.fragment,Lr),Lr.forEach(r),$s.forEach(r),tCe=i(d),qi=n(d,"H2",{class:!0});var Z3e=s(qi);k1=n(Z3e,"A",{id:!0,class:!0,href:!0});var z6t=s(k1);Tee=n(z6t,"SPAN",{});var X6t=s(Tee);c(GE.$$.fragment,X6t),X6t.forEach(r),z6t.forEach(r),lMo=i(Z3e),Fee=n(Z3e,"SPAN",{});var W6t=s(Fee);iMo=t(W6t,"AutoModelForVision2Seq"),W6t.forEach(r),Z3e.forEach(r),rCe=i(d),Qo=n(d,"DIV",{class:!0});var js=s(Qo);c(OE.$$.fragment,js),dMo=i(js),zi=n(js,"P",{});var OD=s(zi);mMo=t(OD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Mee=n(OD,"CODE",{});var V6t=s(Mee);fMo=t(V6t,"from_pretrained()"),V6t.forEach(r),cMo=t(OD,` class method or the
`),Eee=n(OD,"CODE",{});var Q6t=s(Eee);gMo=t(Q6t,"from_config()"),Q6t.forEach(r),hMo=t(OD," class method."),OD.forEach(r),uMo=i(js),qE=n(js,"P",{});var eye=s(qE);pMo=t(eye,"This class cannot be instantiated directly using "),Cee=n(eye,"CODE",{});var H6t=s(Cee);_Mo=t(H6t,"__init__()"),H6t.forEach(r),vMo=t(eye," (throws an error)."),eye.forEach(r),bMo=i(js),Nt=n(js,"DIV",{class:!0});var Ns=s(Nt);c(zE.$$.fragment,Ns),TMo=i(Ns),yee=n(Ns,"P",{});var U6t=s(yee);FMo=t(U6t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),U6t.forEach(r),MMo=i(Ns),Xi=n(Ns,"P",{});var qD=s(Xi);EMo=t(qD,`Note:
Loading a model from its configuration file does `),wee=n(qD,"STRONG",{});var J6t=s(wee);CMo=t(J6t,"not"),J6t.forEach(r),yMo=t(qD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Aee=n(qD,"EM",{});var K6t=s(Aee);wMo=t(K6t,"~AutoModelForVision2Seq.from_pretrained"),K6t.forEach(r),AMo=t(qD,`] to load the model
weights.`),qD.forEach(r),xMo=i(Ns),xee=n(Ns,"P",{});var Y6t=s(xee);LMo=t(Y6t,"Examples:"),Y6t.forEach(r),BMo=i(Ns),c(XE.$$.fragment,Ns),Ns.forEach(r),kMo=i(js),Ge=n(js,"DIV",{class:!0});var Br=s(Ge);c(WE.$$.fragment,Br),RMo=i(Br),Lee=n(Br,"P",{});var Z6t=s(Lee);SMo=t(Z6t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Z6t.forEach(r),PMo=i(Br),$a=n(Br,"P",{});var oF=s($a);$Mo=t(oF,"The model class to instantiate is selected based on the "),Bee=n(oF,"EM",{});var e8t=s(Bee);IMo=t(e8t,"model_type"),e8t.forEach(r),jMo=t(oF,` property of the config object (either
passed as an argument or loaded from `),kee=n(oF,"EM",{});var o8t=s(kee);NMo=t(o8t,"pretrained_model_name_or_path"),o8t.forEach(r),DMo=t(oF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ree=n(oF,"EM",{});var t8t=s(Ree);GMo=t(t8t,"pretrained_model_name_or_path"),t8t.forEach(r),OMo=t(oF,":"),oF.forEach(r),qMo=i(Br),See=n(Br,"UL",{});var r8t=s(See);R1=n(r8t,"LI",{});var z4e=s(R1);Pee=n(z4e,"STRONG",{});var a8t=s(Pee);zMo=t(a8t,"vision-encoder-decoder"),a8t.forEach(r),XMo=t(z4e," \u2014 "),XS=n(z4e,"A",{href:!0});var n8t=s(XS);WMo=t(n8t,"VisionEncoderDecoderModel"),n8t.forEach(r),VMo=t(z4e," (Vision Encoder decoder model)"),z4e.forEach(r),r8t.forEach(r),QMo=i(Br),S1=n(Br,"P",{});var X4e=s(S1);HMo=t(X4e,"The model is set in evaluation mode by default using "),$ee=n(X4e,"EM",{});var s8t=s($ee);UMo=t(s8t,"model.eval()"),s8t.forEach(r),JMo=t(X4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Iee=n(X4e,"EM",{});var l8t=s(Iee);KMo=t(l8t,"model.train()"),l8t.forEach(r),X4e.forEach(r),YMo=i(Br),jee=n(Br,"P",{});var i8t=s(jee);ZMo=t(i8t,"Examples:"),i8t.forEach(r),eEo=i(Br),c(VE.$$.fragment,Br),Br.forEach(r),js.forEach(r),aCe=i(d),Wi=n(d,"H2",{class:!0});var oye=s(Wi);P1=n(oye,"A",{id:!0,class:!0,href:!0});var d8t=s(P1);Nee=n(d8t,"SPAN",{});var m8t=s(Nee);c(QE.$$.fragment,m8t),m8t.forEach(r),d8t.forEach(r),oEo=i(oye),Dee=n(oye,"SPAN",{});var f8t=s(Dee);tEo=t(f8t,"AutoModelForAudioClassification"),f8t.forEach(r),oye.forEach(r),nCe=i(d),Ho=n(d,"DIV",{class:!0});var Ds=s(Ho);c(HE.$$.fragment,Ds),rEo=i(Ds),Vi=n(Ds,"P",{});var zD=s(Vi);aEo=t(zD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Gee=n(zD,"CODE",{});var c8t=s(Gee);nEo=t(c8t,"from_pretrained()"),c8t.forEach(r),sEo=t(zD,` class method or the
`),Oee=n(zD,"CODE",{});var g8t=s(Oee);lEo=t(g8t,"from_config()"),g8t.forEach(r),iEo=t(zD," class method."),zD.forEach(r),dEo=i(Ds),UE=n(Ds,"P",{});var tye=s(UE);mEo=t(tye,"This class cannot be instantiated directly using "),qee=n(tye,"CODE",{});var h8t=s(qee);fEo=t(h8t,"__init__()"),h8t.forEach(r),cEo=t(tye," (throws an error)."),tye.forEach(r),gEo=i(Ds),Dt=n(Ds,"DIV",{class:!0});var Gs=s(Dt);c(JE.$$.fragment,Gs),hEo=i(Gs),zee=n(Gs,"P",{});var u8t=s(zee);uEo=t(u8t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),u8t.forEach(r),pEo=i(Gs),Qi=n(Gs,"P",{});var XD=s(Qi);_Eo=t(XD,`Note:
Loading a model from its configuration file does `),Xee=n(XD,"STRONG",{});var p8t=s(Xee);vEo=t(p8t,"not"),p8t.forEach(r),bEo=t(XD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Wee=n(XD,"EM",{});var _8t=s(Wee);TEo=t(_8t,"~AutoModelForAudioClassification.from_pretrained"),_8t.forEach(r),FEo=t(XD,`] to load the model
weights.`),XD.forEach(r),MEo=i(Gs),Vee=n(Gs,"P",{});var v8t=s(Vee);EEo=t(v8t,"Examples:"),v8t.forEach(r),CEo=i(Gs),c(KE.$$.fragment,Gs),Gs.forEach(r),yEo=i(Ds),Oe=n(Ds,"DIV",{class:!0});var kr=s(Oe);c(YE.$$.fragment,kr),wEo=i(kr),Qee=n(kr,"P",{});var b8t=s(Qee);AEo=t(b8t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),b8t.forEach(r),xEo=i(kr),Ia=n(kr,"P",{});var tF=s(Ia);LEo=t(tF,"The model class to instantiate is selected based on the "),Hee=n(tF,"EM",{});var T8t=s(Hee);BEo=t(T8t,"model_type"),T8t.forEach(r),kEo=t(tF,` property of the config object (either
passed as an argument or loaded from `),Uee=n(tF,"EM",{});var F8t=s(Uee);REo=t(F8t,"pretrained_model_name_or_path"),F8t.forEach(r),SEo=t(tF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Jee=n(tF,"EM",{});var M8t=s(Jee);PEo=t(M8t,"pretrained_model_name_or_path"),M8t.forEach(r),$Eo=t(tF,":"),tF.forEach(r),IEo=i(kr),Ke=n(kr,"UL",{});var Rr=s(Ke);$1=n(Rr,"LI",{});var W4e=s($1);Kee=n(W4e,"STRONG",{});var E8t=s(Kee);jEo=t(E8t,"hubert"),E8t.forEach(r),NEo=t(W4e," \u2014 "),WS=n(W4e,"A",{href:!0});var C8t=s(WS);DEo=t(C8t,"HubertForSequenceClassification"),C8t.forEach(r),GEo=t(W4e," (Hubert model)"),W4e.forEach(r),OEo=i(Rr),I1=n(Rr,"LI",{});var V4e=s(I1);Yee=n(V4e,"STRONG",{});var y8t=s(Yee);qEo=t(y8t,"sew"),y8t.forEach(r),zEo=t(V4e," \u2014 "),VS=n(V4e,"A",{href:!0});var w8t=s(VS);XEo=t(w8t,"SEWForSequenceClassification"),w8t.forEach(r),WEo=t(V4e," (SEW model)"),V4e.forEach(r),VEo=i(Rr),j1=n(Rr,"LI",{});var Q4e=s(j1);Zee=n(Q4e,"STRONG",{});var A8t=s(Zee);QEo=t(A8t,"sew-d"),A8t.forEach(r),HEo=t(Q4e," \u2014 "),QS=n(Q4e,"A",{href:!0});var x8t=s(QS);UEo=t(x8t,"SEWDForSequenceClassification"),x8t.forEach(r),JEo=t(Q4e," (SEW-D model)"),Q4e.forEach(r),KEo=i(Rr),N1=n(Rr,"LI",{});var H4e=s(N1);eoe=n(H4e,"STRONG",{});var L8t=s(eoe);YEo=t(L8t,"unispeech"),L8t.forEach(r),ZEo=t(H4e," \u2014 "),HS=n(H4e,"A",{href:!0});var B8t=s(HS);eCo=t(B8t,"UniSpeechForSequenceClassification"),B8t.forEach(r),oCo=t(H4e," (UniSpeech model)"),H4e.forEach(r),tCo=i(Rr),D1=n(Rr,"LI",{});var U4e=s(D1);ooe=n(U4e,"STRONG",{});var k8t=s(ooe);rCo=t(k8t,"unispeech-sat"),k8t.forEach(r),aCo=t(U4e," \u2014 "),US=n(U4e,"A",{href:!0});var R8t=s(US);nCo=t(R8t,"UniSpeechSatForSequenceClassification"),R8t.forEach(r),sCo=t(U4e," (UniSpeechSat model)"),U4e.forEach(r),lCo=i(Rr),G1=n(Rr,"LI",{});var J4e=s(G1);toe=n(J4e,"STRONG",{});var S8t=s(toe);iCo=t(S8t,"wav2vec2"),S8t.forEach(r),dCo=t(J4e," \u2014 "),JS=n(J4e,"A",{href:!0});var P8t=s(JS);mCo=t(P8t,"Wav2Vec2ForSequenceClassification"),P8t.forEach(r),fCo=t(J4e," (Wav2Vec2 model)"),J4e.forEach(r),cCo=i(Rr),O1=n(Rr,"LI",{});var K4e=s(O1);roe=n(K4e,"STRONG",{});var $8t=s(roe);gCo=t($8t,"wavlm"),$8t.forEach(r),hCo=t(K4e," \u2014 "),KS=n(K4e,"A",{href:!0});var I8t=s(KS);uCo=t(I8t,"WavLMForSequenceClassification"),I8t.forEach(r),pCo=t(K4e," (WavLM model)"),K4e.forEach(r),Rr.forEach(r),_Co=i(kr),q1=n(kr,"P",{});var Y4e=s(q1);vCo=t(Y4e,"The model is set in evaluation mode by default using "),aoe=n(Y4e,"EM",{});var j8t=s(aoe);bCo=t(j8t,"model.eval()"),j8t.forEach(r),TCo=t(Y4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),noe=n(Y4e,"EM",{});var N8t=s(noe);FCo=t(N8t,"model.train()"),N8t.forEach(r),Y4e.forEach(r),MCo=i(kr),soe=n(kr,"P",{});var D8t=s(soe);ECo=t(D8t,"Examples:"),D8t.forEach(r),CCo=i(kr),c(ZE.$$.fragment,kr),kr.forEach(r),Ds.forEach(r),sCe=i(d),Hi=n(d,"H2",{class:!0});var rye=s(Hi);z1=n(rye,"A",{id:!0,class:!0,href:!0});var G8t=s(z1);loe=n(G8t,"SPAN",{});var O8t=s(loe);c(eC.$$.fragment,O8t),O8t.forEach(r),G8t.forEach(r),yCo=i(rye),ioe=n(rye,"SPAN",{});var q8t=s(ioe);wCo=t(q8t,"AutoModelForAudioFrameClassification"),q8t.forEach(r),rye.forEach(r),lCe=i(d),Uo=n(d,"DIV",{class:!0});var Os=s(Uo);c(oC.$$.fragment,Os),ACo=i(Os),Ui=n(Os,"P",{});var WD=s(Ui);xCo=t(WD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),doe=n(WD,"CODE",{});var z8t=s(doe);LCo=t(z8t,"from_pretrained()"),z8t.forEach(r),BCo=t(WD,` class method or the
`),moe=n(WD,"CODE",{});var X8t=s(moe);kCo=t(X8t,"from_config()"),X8t.forEach(r),RCo=t(WD," class method."),WD.forEach(r),SCo=i(Os),tC=n(Os,"P",{});var aye=s(tC);PCo=t(aye,"This class cannot be instantiated directly using "),foe=n(aye,"CODE",{});var W8t=s(foe);$Co=t(W8t,"__init__()"),W8t.forEach(r),ICo=t(aye," (throws an error)."),aye.forEach(r),jCo=i(Os),Gt=n(Os,"DIV",{class:!0});var qs=s(Gt);c(rC.$$.fragment,qs),NCo=i(qs),coe=n(qs,"P",{});var V8t=s(coe);DCo=t(V8t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),V8t.forEach(r),GCo=i(qs),Ji=n(qs,"P",{});var VD=s(Ji);OCo=t(VD,`Note:
Loading a model from its configuration file does `),goe=n(VD,"STRONG",{});var Q8t=s(goe);qCo=t(Q8t,"not"),Q8t.forEach(r),zCo=t(VD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),hoe=n(VD,"EM",{});var H8t=s(hoe);XCo=t(H8t,"~AutoModelForAudioFrameClassification.from_pretrained"),H8t.forEach(r),WCo=t(VD,`] to load the model
weights.`),VD.forEach(r),VCo=i(qs),uoe=n(qs,"P",{});var U8t=s(uoe);QCo=t(U8t,"Examples:"),U8t.forEach(r),HCo=i(qs),c(aC.$$.fragment,qs),qs.forEach(r),UCo=i(Os),qe=n(Os,"DIV",{class:!0});var Sr=s(qe);c(nC.$$.fragment,Sr),JCo=i(Sr),poe=n(Sr,"P",{});var J8t=s(poe);KCo=t(J8t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),J8t.forEach(r),YCo=i(Sr),ja=n(Sr,"P",{});var rF=s(ja);ZCo=t(rF,"The model class to instantiate is selected based on the "),_oe=n(rF,"EM",{});var K8t=s(_oe);e3o=t(K8t,"model_type"),K8t.forEach(r),o3o=t(rF,` property of the config object (either
passed as an argument or loaded from `),voe=n(rF,"EM",{});var Y8t=s(voe);t3o=t(Y8t,"pretrained_model_name_or_path"),Y8t.forEach(r),r3o=t(rF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),boe=n(rF,"EM",{});var Z8t=s(boe);a3o=t(Z8t,"pretrained_model_name_or_path"),Z8t.forEach(r),n3o=t(rF,":"),rF.forEach(r),s3o=i(Sr),Ki=n(Sr,"UL",{});var QD=s(Ki);X1=n(QD,"LI",{});var Z4e=s(X1);Toe=n(Z4e,"STRONG",{});var eLt=s(Toe);l3o=t(eLt,"unispeech-sat"),eLt.forEach(r),i3o=t(Z4e," \u2014 "),YS=n(Z4e,"A",{href:!0});var oLt=s(YS);d3o=t(oLt,"UniSpeechSatForAudioFrameClassification"),oLt.forEach(r),m3o=t(Z4e," (UniSpeechSat model)"),Z4e.forEach(r),f3o=i(QD),W1=n(QD,"LI",{});var e5e=s(W1);Foe=n(e5e,"STRONG",{});var tLt=s(Foe);c3o=t(tLt,"wav2vec2"),tLt.forEach(r),g3o=t(e5e," \u2014 "),ZS=n(e5e,"A",{href:!0});var rLt=s(ZS);h3o=t(rLt,"Wav2Vec2ForAudioFrameClassification"),rLt.forEach(r),u3o=t(e5e," (Wav2Vec2 model)"),e5e.forEach(r),p3o=i(QD),V1=n(QD,"LI",{});var o5e=s(V1);Moe=n(o5e,"STRONG",{});var aLt=s(Moe);_3o=t(aLt,"wavlm"),aLt.forEach(r),v3o=t(o5e," \u2014 "),eP=n(o5e,"A",{href:!0});var nLt=s(eP);b3o=t(nLt,"WavLMForAudioFrameClassification"),nLt.forEach(r),T3o=t(o5e," (WavLM model)"),o5e.forEach(r),QD.forEach(r),F3o=i(Sr),Q1=n(Sr,"P",{});var t5e=s(Q1);M3o=t(t5e,"The model is set in evaluation mode by default using "),Eoe=n(t5e,"EM",{});var sLt=s(Eoe);E3o=t(sLt,"model.eval()"),sLt.forEach(r),C3o=t(t5e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Coe=n(t5e,"EM",{});var lLt=s(Coe);y3o=t(lLt,"model.train()"),lLt.forEach(r),t5e.forEach(r),w3o=i(Sr),yoe=n(Sr,"P",{});var iLt=s(yoe);A3o=t(iLt,"Examples:"),iLt.forEach(r),x3o=i(Sr),c(sC.$$.fragment,Sr),Sr.forEach(r),Os.forEach(r),iCe=i(d),Yi=n(d,"H2",{class:!0});var nye=s(Yi);H1=n(nye,"A",{id:!0,class:!0,href:!0});var dLt=s(H1);woe=n(dLt,"SPAN",{});var mLt=s(woe);c(lC.$$.fragment,mLt),mLt.forEach(r),dLt.forEach(r),L3o=i(nye),Aoe=n(nye,"SPAN",{});var fLt=s(Aoe);B3o=t(fLt,"AutoModelForCTC"),fLt.forEach(r),nye.forEach(r),dCe=i(d),Jo=n(d,"DIV",{class:!0});var zs=s(Jo);c(iC.$$.fragment,zs),k3o=i(zs),Zi=n(zs,"P",{});var HD=s(Zi);R3o=t(HD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),xoe=n(HD,"CODE",{});var cLt=s(xoe);S3o=t(cLt,"from_pretrained()"),cLt.forEach(r),P3o=t(HD,` class method or the
`),Loe=n(HD,"CODE",{});var gLt=s(Loe);$3o=t(gLt,"from_config()"),gLt.forEach(r),I3o=t(HD," class method."),HD.forEach(r),j3o=i(zs),dC=n(zs,"P",{});var sye=s(dC);N3o=t(sye,"This class cannot be instantiated directly using "),Boe=n(sye,"CODE",{});var hLt=s(Boe);D3o=t(hLt,"__init__()"),hLt.forEach(r),G3o=t(sye," (throws an error)."),sye.forEach(r),O3o=i(zs),Ot=n(zs,"DIV",{class:!0});var Xs=s(Ot);c(mC.$$.fragment,Xs),q3o=i(Xs),koe=n(Xs,"P",{});var uLt=s(koe);z3o=t(uLt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),uLt.forEach(r),X3o=i(Xs),ed=n(Xs,"P",{});var UD=s(ed);W3o=t(UD,`Note:
Loading a model from its configuration file does `),Roe=n(UD,"STRONG",{});var pLt=s(Roe);V3o=t(pLt,"not"),pLt.forEach(r),Q3o=t(UD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Soe=n(UD,"EM",{});var _Lt=s(Soe);H3o=t(_Lt,"~AutoModelForCTC.from_pretrained"),_Lt.forEach(r),U3o=t(UD,`] to load the model
weights.`),UD.forEach(r),J3o=i(Xs),Poe=n(Xs,"P",{});var vLt=s(Poe);K3o=t(vLt,"Examples:"),vLt.forEach(r),Y3o=i(Xs),c(fC.$$.fragment,Xs),Xs.forEach(r),Z3o=i(zs),ze=n(zs,"DIV",{class:!0});var Pr=s(ze);c(cC.$$.fragment,Pr),eyo=i(Pr),$oe=n(Pr,"P",{});var bLt=s($oe);oyo=t(bLt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),bLt.forEach(r),tyo=i(Pr),Na=n(Pr,"P",{});var aF=s(Na);ryo=t(aF,"The model class to instantiate is selected based on the "),Ioe=n(aF,"EM",{});var TLt=s(Ioe);ayo=t(TLt,"model_type"),TLt.forEach(r),nyo=t(aF,` property of the config object (either
passed as an argument or loaded from `),joe=n(aF,"EM",{});var FLt=s(joe);syo=t(FLt,"pretrained_model_name_or_path"),FLt.forEach(r),lyo=t(aF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Noe=n(aF,"EM",{});var MLt=s(Noe);iyo=t(MLt,"pretrained_model_name_or_path"),MLt.forEach(r),dyo=t(aF,":"),aF.forEach(r),myo=i(Pr),Ye=n(Pr,"UL",{});var $r=s(Ye);U1=n($r,"LI",{});var r5e=s(U1);Doe=n(r5e,"STRONG",{});var ELt=s(Doe);fyo=t(ELt,"hubert"),ELt.forEach(r),cyo=t(r5e," \u2014 "),oP=n(r5e,"A",{href:!0});var CLt=s(oP);gyo=t(CLt,"HubertForCTC"),CLt.forEach(r),hyo=t(r5e," (Hubert model)"),r5e.forEach(r),uyo=i($r),J1=n($r,"LI",{});var a5e=s(J1);Goe=n(a5e,"STRONG",{});var yLt=s(Goe);pyo=t(yLt,"sew"),yLt.forEach(r),_yo=t(a5e," \u2014 "),tP=n(a5e,"A",{href:!0});var wLt=s(tP);vyo=t(wLt,"SEWForCTC"),wLt.forEach(r),byo=t(a5e," (SEW model)"),a5e.forEach(r),Tyo=i($r),K1=n($r,"LI",{});var n5e=s(K1);Ooe=n(n5e,"STRONG",{});var ALt=s(Ooe);Fyo=t(ALt,"sew-d"),ALt.forEach(r),Myo=t(n5e," \u2014 "),rP=n(n5e,"A",{href:!0});var xLt=s(rP);Eyo=t(xLt,"SEWDForCTC"),xLt.forEach(r),Cyo=t(n5e," (SEW-D model)"),n5e.forEach(r),yyo=i($r),Y1=n($r,"LI",{});var s5e=s(Y1);qoe=n(s5e,"STRONG",{});var LLt=s(qoe);wyo=t(LLt,"unispeech"),LLt.forEach(r),Ayo=t(s5e," \u2014 "),aP=n(s5e,"A",{href:!0});var BLt=s(aP);xyo=t(BLt,"UniSpeechForCTC"),BLt.forEach(r),Lyo=t(s5e," (UniSpeech model)"),s5e.forEach(r),Byo=i($r),Z1=n($r,"LI",{});var l5e=s(Z1);zoe=n(l5e,"STRONG",{});var kLt=s(zoe);kyo=t(kLt,"unispeech-sat"),kLt.forEach(r),Ryo=t(l5e," \u2014 "),nP=n(l5e,"A",{href:!0});var RLt=s(nP);Syo=t(RLt,"UniSpeechSatForCTC"),RLt.forEach(r),Pyo=t(l5e," (UniSpeechSat model)"),l5e.forEach(r),$yo=i($r),e2=n($r,"LI",{});var i5e=s(e2);Xoe=n(i5e,"STRONG",{});var SLt=s(Xoe);Iyo=t(SLt,"wav2vec2"),SLt.forEach(r),jyo=t(i5e," \u2014 "),sP=n(i5e,"A",{href:!0});var PLt=s(sP);Nyo=t(PLt,"Wav2Vec2ForCTC"),PLt.forEach(r),Dyo=t(i5e," (Wav2Vec2 model)"),i5e.forEach(r),Gyo=i($r),o2=n($r,"LI",{});var d5e=s(o2);Woe=n(d5e,"STRONG",{});var $Lt=s(Woe);Oyo=t($Lt,"wavlm"),$Lt.forEach(r),qyo=t(d5e," \u2014 "),lP=n(d5e,"A",{href:!0});var ILt=s(lP);zyo=t(ILt,"WavLMForCTC"),ILt.forEach(r),Xyo=t(d5e," (WavLM model)"),d5e.forEach(r),$r.forEach(r),Wyo=i(Pr),t2=n(Pr,"P",{});var m5e=s(t2);Vyo=t(m5e,"The model is set in evaluation mode by default using "),Voe=n(m5e,"EM",{});var jLt=s(Voe);Qyo=t(jLt,"model.eval()"),jLt.forEach(r),Hyo=t(m5e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qoe=n(m5e,"EM",{});var NLt=s(Qoe);Uyo=t(NLt,"model.train()"),NLt.forEach(r),m5e.forEach(r),Jyo=i(Pr),Hoe=n(Pr,"P",{});var DLt=s(Hoe);Kyo=t(DLt,"Examples:"),DLt.forEach(r),Yyo=i(Pr),c(gC.$$.fragment,Pr),Pr.forEach(r),zs.forEach(r),mCe=i(d),od=n(d,"H2",{class:!0});var lye=s(od);r2=n(lye,"A",{id:!0,class:!0,href:!0});var GLt=s(r2);Uoe=n(GLt,"SPAN",{});var OLt=s(Uoe);c(hC.$$.fragment,OLt),OLt.forEach(r),GLt.forEach(r),Zyo=i(lye),Joe=n(lye,"SPAN",{});var qLt=s(Joe);ewo=t(qLt,"AutoModelForSpeechSeq2Seq"),qLt.forEach(r),lye.forEach(r),fCe=i(d),Ko=n(d,"DIV",{class:!0});var Ws=s(Ko);c(uC.$$.fragment,Ws),owo=i(Ws),td=n(Ws,"P",{});var JD=s(td);two=t(JD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) when created
with the `),Koe=n(JD,"CODE",{});var zLt=s(Koe);rwo=t(zLt,"from_pretrained()"),zLt.forEach(r),awo=t(JD,` class method or the
`),Yoe=n(JD,"CODE",{});var XLt=s(Yoe);nwo=t(XLt,"from_config()"),XLt.forEach(r),swo=t(JD," class method."),JD.forEach(r),lwo=i(Ws),pC=n(Ws,"P",{});var iye=s(pC);iwo=t(iye,"This class cannot be instantiated directly using "),Zoe=n(iye,"CODE",{});var WLt=s(Zoe);dwo=t(WLt,"__init__()"),WLt.forEach(r),mwo=t(iye," (throws an error)."),iye.forEach(r),fwo=i(Ws),qt=n(Ws,"DIV",{class:!0});var Vs=s(qt);c(_C.$$.fragment,Vs),cwo=i(Vs),ete=n(Vs,"P",{});var VLt=s(ete);gwo=t(VLt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a configuration."),VLt.forEach(r),hwo=i(Vs),rd=n(Vs,"P",{});var KD=s(rd);uwo=t(KD,`Note:
Loading a model from its configuration file does `),ote=n(KD,"STRONG",{});var QLt=s(ote);pwo=t(QLt,"not"),QLt.forEach(r),_wo=t(KD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),tte=n(KD,"EM",{});var HLt=s(tte);vwo=t(HLt,"~AutoModelForSpeechSeq2Seq.from_pretrained"),HLt.forEach(r),bwo=t(KD,`] to load the model
weights.`),KD.forEach(r),Two=i(Vs),rte=n(Vs,"P",{});var ULt=s(rte);Fwo=t(ULt,"Examples:"),ULt.forEach(r),Mwo=i(Vs),c(vC.$$.fragment,Vs),Vs.forEach(r),Ewo=i(Ws),Xe=n(Ws,"DIV",{class:!0});var Ir=s(Xe);c(bC.$$.fragment,Ir),Cwo=i(Ir),ate=n(Ir,"P",{});var JLt=s(ate);ywo=t(JLt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeing head) from a pretrained model."),JLt.forEach(r),wwo=i(Ir),Da=n(Ir,"P",{});var nF=s(Da);Awo=t(nF,"The model class to instantiate is selected based on the "),nte=n(nF,"EM",{});var KLt=s(nte);xwo=t(KLt,"model_type"),KLt.forEach(r),Lwo=t(nF,` property of the config object (either
passed as an argument or loaded from `),ste=n(nF,"EM",{});var YLt=s(ste);Bwo=t(YLt,"pretrained_model_name_or_path"),YLt.forEach(r),kwo=t(nF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),lte=n(nF,"EM",{});var ZLt=s(lte);Rwo=t(ZLt,"pretrained_model_name_or_path"),ZLt.forEach(r),Swo=t(nF,":"),nF.forEach(r),Pwo=i(Ir),TC=n(Ir,"UL",{});var dye=s(TC);a2=n(dye,"LI",{});var f5e=s(a2);ite=n(f5e,"STRONG",{});var eBt=s(ite);$wo=t(eBt,"speech-encoder-decoder"),eBt.forEach(r),Iwo=t(f5e," \u2014 "),iP=n(f5e,"A",{href:!0});var oBt=s(iP);jwo=t(oBt,"SpeechEncoderDecoderModel"),oBt.forEach(r),Nwo=t(f5e," (Speech Encoder decoder model)"),f5e.forEach(r),Dwo=i(dye),n2=n(dye,"LI",{});var c5e=s(n2);dte=n(c5e,"STRONG",{});var tBt=s(dte);Gwo=t(tBt,"speech_to_text"),tBt.forEach(r),Owo=t(c5e," \u2014 "),dP=n(c5e,"A",{href:!0});var rBt=s(dP);qwo=t(rBt,"Speech2TextForConditionalGeneration"),rBt.forEach(r),zwo=t(c5e," (Speech2Text model)"),c5e.forEach(r),dye.forEach(r),Xwo=i(Ir),s2=n(Ir,"P",{});var g5e=s(s2);Wwo=t(g5e,"The model is set in evaluation mode by default using "),mte=n(g5e,"EM",{});var aBt=s(mte);Vwo=t(aBt,"model.eval()"),aBt.forEach(r),Qwo=t(g5e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fte=n(g5e,"EM",{});var nBt=s(fte);Hwo=t(nBt,"model.train()"),nBt.forEach(r),g5e.forEach(r),Uwo=i(Ir),cte=n(Ir,"P",{});var sBt=s(cte);Jwo=t(sBt,"Examples:"),sBt.forEach(r),Kwo=i(Ir),c(FC.$$.fragment,Ir),Ir.forEach(r),Ws.forEach(r),cCe=i(d),ad=n(d,"H2",{class:!0});var mye=s(ad);l2=n(mye,"A",{id:!0,class:!0,href:!0});var lBt=s(l2);gte=n(lBt,"SPAN",{});var iBt=s(gte);c(MC.$$.fragment,iBt),iBt.forEach(r),lBt.forEach(r),Ywo=i(mye),hte=n(mye,"SPAN",{});var dBt=s(hte);Zwo=t(dBt,"AutoModelForAudioXVector"),dBt.forEach(r),mye.forEach(r),gCe=i(d),Yo=n(d,"DIV",{class:!0});var Qs=s(Yo);c(EC.$$.fragment,Qs),eAo=i(Qs),nd=n(Qs,"P",{});var YD=s(nd);oAo=t(YD,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),ute=n(YD,"CODE",{});var mBt=s(ute);tAo=t(mBt,"from_pretrained()"),mBt.forEach(r),rAo=t(YD,` class method or the
`),pte=n(YD,"CODE",{});var fBt=s(pte);aAo=t(fBt,"from_config()"),fBt.forEach(r),nAo=t(YD," class method."),YD.forEach(r),sAo=i(Qs),CC=n(Qs,"P",{});var fye=s(CC);lAo=t(fye,"This class cannot be instantiated directly using "),_te=n(fye,"CODE",{});var cBt=s(_te);iAo=t(cBt,"__init__()"),cBt.forEach(r),dAo=t(fye," (throws an error)."),fye.forEach(r),mAo=i(Qs),zt=n(Qs,"DIV",{class:!0});var Hs=s(zt);c(yC.$$.fragment,Hs),fAo=i(Hs),vte=n(Hs,"P",{});var gBt=s(vte);cAo=t(gBt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),gBt.forEach(r),gAo=i(Hs),sd=n(Hs,"P",{});var ZD=s(sd);hAo=t(ZD,`Note:
Loading a model from its configuration file does `),bte=n(ZD,"STRONG",{});var hBt=s(bte);uAo=t(hBt,"not"),hBt.forEach(r),pAo=t(ZD,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Tte=n(ZD,"EM",{});var uBt=s(Tte);_Ao=t(uBt,"~AutoModelForAudioXVector.from_pretrained"),uBt.forEach(r),vAo=t(ZD,`] to load the model
weights.`),ZD.forEach(r),bAo=i(Hs),Fte=n(Hs,"P",{});var pBt=s(Fte);TAo=t(pBt,"Examples:"),pBt.forEach(r),FAo=i(Hs),c(wC.$$.fragment,Hs),Hs.forEach(r),MAo=i(Qs),We=n(Qs,"DIV",{class:!0});var jr=s(We);c(AC.$$.fragment,jr),EAo=i(jr),Mte=n(jr,"P",{});var _Bt=s(Mte);CAo=t(_Bt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),_Bt.forEach(r),yAo=i(jr),Ga=n(jr,"P",{});var sF=s(Ga);wAo=t(sF,"The model class to instantiate is selected based on the "),Ete=n(sF,"EM",{});var vBt=s(Ete);AAo=t(vBt,"model_type"),vBt.forEach(r),xAo=t(sF,` property of the config object (either
passed as an argument or loaded from `),Cte=n(sF,"EM",{});var bBt=s(Cte);LAo=t(bBt,"pretrained_model_name_or_path"),bBt.forEach(r),BAo=t(sF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),yte=n(sF,"EM",{});var TBt=s(yte);kAo=t(TBt,"pretrained_model_name_or_path"),TBt.forEach(r),RAo=t(sF,":"),sF.forEach(r),SAo=i(jr),ld=n(jr,"UL",{});var eG=s(ld);i2=n(eG,"LI",{});var h5e=s(i2);wte=n(h5e,"STRONG",{});var FBt=s(wte);PAo=t(FBt,"unispeech-sat"),FBt.forEach(r),$Ao=t(h5e," \u2014 "),mP=n(h5e,"A",{href:!0});var MBt=s(mP);IAo=t(MBt,"UniSpeechSatForXVector"),MBt.forEach(r),jAo=t(h5e," (UniSpeechSat model)"),h5e.forEach(r),NAo=i(eG),d2=n(eG,"LI",{});var u5e=s(d2);Ate=n(u5e,"STRONG",{});var EBt=s(Ate);DAo=t(EBt,"wav2vec2"),EBt.forEach(r),GAo=t(u5e," \u2014 "),fP=n(u5e,"A",{href:!0});var CBt=s(fP);OAo=t(CBt,"Wav2Vec2ForXVector"),CBt.forEach(r),qAo=t(u5e," (Wav2Vec2 model)"),u5e.forEach(r),zAo=i(eG),m2=n(eG,"LI",{});var p5e=s(m2);xte=n(p5e,"STRONG",{});var yBt=s(xte);XAo=t(yBt,"wavlm"),yBt.forEach(r),WAo=t(p5e," \u2014 "),cP=n(p5e,"A",{href:!0});var wBt=s(cP);VAo=t(wBt,"WavLMForXVector"),wBt.forEach(r),QAo=t(p5e," (WavLM model)"),p5e.forEach(r),eG.forEach(r),HAo=i(jr),f2=n(jr,"P",{});var _5e=s(f2);UAo=t(_5e,"The model is set in evaluation mode by default using "),Lte=n(_5e,"EM",{});var ABt=s(Lte);JAo=t(ABt,"model.eval()"),ABt.forEach(r),KAo=t(_5e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bte=n(_5e,"EM",{});var xBt=s(Bte);YAo=t(xBt,"model.train()"),xBt.forEach(r),_5e.forEach(r),ZAo=i(jr),kte=n(jr,"P",{});var LBt=s(kte);e7o=t(LBt,"Examples:"),LBt.forEach(r),o7o=i(jr),c(xC.$$.fragment,jr),jr.forEach(r),Qs.forEach(r),hCe=i(d),id=n(d,"H2",{class:!0});var cye=s(id);c2=n(cye,"A",{id:!0,class:!0,href:!0});var BBt=s(c2);Rte=n(BBt,"SPAN",{});var kBt=s(Rte);c(LC.$$.fragment,kBt),kBt.forEach(r),BBt.forEach(r),t7o=i(cye),Ste=n(cye,"SPAN",{});var RBt=s(Ste);r7o=t(RBt,"AutoModelForObjectDetection"),RBt.forEach(r),cye.forEach(r),uCe=i(d),Zo=n(d,"DIV",{class:!0});var Us=s(Zo);c(BC.$$.fragment,Us),a7o=i(Us),dd=n(Us,"P",{});var oG=s(dd);n7o=t(oG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Pte=n(oG,"CODE",{});var SBt=s(Pte);s7o=t(SBt,"from_pretrained()"),SBt.forEach(r),l7o=t(oG,` class method or the
`),$te=n(oG,"CODE",{});var PBt=s($te);i7o=t(PBt,"from_config()"),PBt.forEach(r),d7o=t(oG," class method."),oG.forEach(r),m7o=i(Us),kC=n(Us,"P",{});var gye=s(kC);f7o=t(gye,"This class cannot be instantiated directly using "),Ite=n(gye,"CODE",{});var $Bt=s(Ite);c7o=t($Bt,"__init__()"),$Bt.forEach(r),g7o=t(gye," (throws an error)."),gye.forEach(r),h7o=i(Us),Xt=n(Us,"DIV",{class:!0});var Js=s(Xt);c(RC.$$.fragment,Js),u7o=i(Js),jte=n(Js,"P",{});var IBt=s(jte);p7o=t(IBt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),IBt.forEach(r),_7o=i(Js),md=n(Js,"P",{});var tG=s(md);v7o=t(tG,`Note:
Loading a model from its configuration file does `),Nte=n(tG,"STRONG",{});var jBt=s(Nte);b7o=t(jBt,"not"),jBt.forEach(r),T7o=t(tG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Dte=n(tG,"EM",{});var NBt=s(Dte);F7o=t(NBt,"~AutoModelForObjectDetection.from_pretrained"),NBt.forEach(r),M7o=t(tG,`] to load the model
weights.`),tG.forEach(r),E7o=i(Js),Gte=n(Js,"P",{});var DBt=s(Gte);C7o=t(DBt,"Examples:"),DBt.forEach(r),y7o=i(Js),c(SC.$$.fragment,Js),Js.forEach(r),w7o=i(Us),Ve=n(Us,"DIV",{class:!0});var Nr=s(Ve);c(PC.$$.fragment,Nr),A7o=i(Nr),Ote=n(Nr,"P",{});var GBt=s(Ote);x7o=t(GBt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),GBt.forEach(r),L7o=i(Nr),Oa=n(Nr,"P",{});var lF=s(Oa);B7o=t(lF,"The model class to instantiate is selected based on the "),qte=n(lF,"EM",{});var OBt=s(qte);k7o=t(OBt,"model_type"),OBt.forEach(r),R7o=t(lF,` property of the config object (either
passed as an argument or loaded from `),zte=n(lF,"EM",{});var qBt=s(zte);S7o=t(qBt,"pretrained_model_name_or_path"),qBt.forEach(r),P7o=t(lF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Xte=n(lF,"EM",{});var zBt=s(Xte);$7o=t(zBt,"pretrained_model_name_or_path"),zBt.forEach(r),I7o=t(lF,":"),lF.forEach(r),j7o=i(Nr),Wte=n(Nr,"UL",{});var XBt=s(Wte);g2=n(XBt,"LI",{});var v5e=s(g2);Vte=n(v5e,"STRONG",{});var WBt=s(Vte);N7o=t(WBt,"detr"),WBt.forEach(r),D7o=t(v5e," \u2014 "),gP=n(v5e,"A",{href:!0});var VBt=s(gP);G7o=t(VBt,"DetrForObjectDetection"),VBt.forEach(r),O7o=t(v5e," (DETR model)"),v5e.forEach(r),XBt.forEach(r),q7o=i(Nr),h2=n(Nr,"P",{});var b5e=s(h2);z7o=t(b5e,"The model is set in evaluation mode by default using "),Qte=n(b5e,"EM",{});var QBt=s(Qte);X7o=t(QBt,"model.eval()"),QBt.forEach(r),W7o=t(b5e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hte=n(b5e,"EM",{});var HBt=s(Hte);V7o=t(HBt,"model.train()"),HBt.forEach(r),b5e.forEach(r),Q7o=i(Nr),Ute=n(Nr,"P",{});var UBt=s(Ute);H7o=t(UBt,"Examples:"),UBt.forEach(r),U7o=i(Nr),c($C.$$.fragment,Nr),Nr.forEach(r),Us.forEach(r),pCe=i(d),fd=n(d,"H2",{class:!0});var hye=s(fd);u2=n(hye,"A",{id:!0,class:!0,href:!0});var JBt=s(u2);Jte=n(JBt,"SPAN",{});var KBt=s(Jte);c(IC.$$.fragment,KBt),KBt.forEach(r),JBt.forEach(r),J7o=i(hye),Kte=n(hye,"SPAN",{});var YBt=s(Kte);K7o=t(YBt,"AutoModelForImageSegmentation"),YBt.forEach(r),hye.forEach(r),_Ce=i(d),et=n(d,"DIV",{class:!0});var Ks=s(et);c(jC.$$.fragment,Ks),Y7o=i(Ks),cd=n(Ks,"P",{});var rG=s(cd);Z7o=t(rG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Yte=n(rG,"CODE",{});var ZBt=s(Yte);exo=t(ZBt,"from_pretrained()"),ZBt.forEach(r),oxo=t(rG,` class method or the
`),Zte=n(rG,"CODE",{});var e9t=s(Zte);txo=t(e9t,"from_config()"),e9t.forEach(r),rxo=t(rG," class method."),rG.forEach(r),axo=i(Ks),NC=n(Ks,"P",{});var uye=s(NC);nxo=t(uye,"This class cannot be instantiated directly using "),ere=n(uye,"CODE",{});var o9t=s(ere);sxo=t(o9t,"__init__()"),o9t.forEach(r),lxo=t(uye," (throws an error)."),uye.forEach(r),ixo=i(Ks),Wt=n(Ks,"DIV",{class:!0});var Ys=s(Wt);c(DC.$$.fragment,Ys),dxo=i(Ys),ore=n(Ys,"P",{});var t9t=s(ore);mxo=t(t9t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),t9t.forEach(r),fxo=i(Ys),gd=n(Ys,"P",{});var aG=s(gd);cxo=t(aG,`Note:
Loading a model from its configuration file does `),tre=n(aG,"STRONG",{});var r9t=s(tre);gxo=t(r9t,"not"),r9t.forEach(r),hxo=t(aG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),rre=n(aG,"EM",{});var a9t=s(rre);uxo=t(a9t,"~AutoModelForImageSegmentation.from_pretrained"),a9t.forEach(r),pxo=t(aG,`] to load the model
weights.`),aG.forEach(r),_xo=i(Ys),are=n(Ys,"P",{});var n9t=s(are);vxo=t(n9t,"Examples:"),n9t.forEach(r),bxo=i(Ys),c(GC.$$.fragment,Ys),Ys.forEach(r),Txo=i(Ks),Qe=n(Ks,"DIV",{class:!0});var Dr=s(Qe);c(OC.$$.fragment,Dr),Fxo=i(Dr),nre=n(Dr,"P",{});var s9t=s(nre);Mxo=t(s9t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),s9t.forEach(r),Exo=i(Dr),qa=n(Dr,"P",{});var iF=s(qa);Cxo=t(iF,"The model class to instantiate is selected based on the "),sre=n(iF,"EM",{});var l9t=s(sre);yxo=t(l9t,"model_type"),l9t.forEach(r),wxo=t(iF,` property of the config object (either
passed as an argument or loaded from `),lre=n(iF,"EM",{});var i9t=s(lre);Axo=t(i9t,"pretrained_model_name_or_path"),i9t.forEach(r),xxo=t(iF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),ire=n(iF,"EM",{});var d9t=s(ire);Lxo=t(d9t,"pretrained_model_name_or_path"),d9t.forEach(r),Bxo=t(iF,":"),iF.forEach(r),kxo=i(Dr),dre=n(Dr,"UL",{});var m9t=s(dre);p2=n(m9t,"LI",{});var T5e=s(p2);mre=n(T5e,"STRONG",{});var f9t=s(mre);Rxo=t(f9t,"detr"),f9t.forEach(r),Sxo=t(T5e," \u2014 "),hP=n(T5e,"A",{href:!0});var c9t=s(hP);Pxo=t(c9t,"DetrForSegmentation"),c9t.forEach(r),$xo=t(T5e," (DETR model)"),T5e.forEach(r),m9t.forEach(r),Ixo=i(Dr),_2=n(Dr,"P",{});var F5e=s(_2);jxo=t(F5e,"The model is set in evaluation mode by default using "),fre=n(F5e,"EM",{});var g9t=s(fre);Nxo=t(g9t,"model.eval()"),g9t.forEach(r),Dxo=t(F5e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cre=n(F5e,"EM",{});var h9t=s(cre);Gxo=t(h9t,"model.train()"),h9t.forEach(r),F5e.forEach(r),Oxo=i(Dr),gre=n(Dr,"P",{});var u9t=s(gre);qxo=t(u9t,"Examples:"),u9t.forEach(r),zxo=i(Dr),c(qC.$$.fragment,Dr),Dr.forEach(r),Ks.forEach(r),vCe=i(d),hd=n(d,"H2",{class:!0});var pye=s(hd);v2=n(pye,"A",{id:!0,class:!0,href:!0});var p9t=s(v2);hre=n(p9t,"SPAN",{});var _9t=s(hre);c(zC.$$.fragment,_9t),_9t.forEach(r),p9t.forEach(r),Xxo=i(pye),ure=n(pye,"SPAN",{});var v9t=s(ure);Wxo=t(v9t,"TFAutoModel"),v9t.forEach(r),pye.forEach(r),bCe=i(d),ot=n(d,"DIV",{class:!0});var Zs=s(ot);c(XC.$$.fragment,Zs),Vxo=i(Zs),ud=n(Zs,"P",{});var nG=s(ud);Qxo=t(nG,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pre=n(nG,"CODE",{});var b9t=s(pre);Hxo=t(b9t,"from_pretrained()"),b9t.forEach(r),Uxo=t(nG,` class method or the
`),_re=n(nG,"CODE",{});var T9t=s(_re);Jxo=t(T9t,"from_config()"),T9t.forEach(r),Kxo=t(nG," class method."),nG.forEach(r),Yxo=i(Zs),WC=n(Zs,"P",{});var _ye=s(WC);Zxo=t(_ye,"This class cannot be instantiated directly using "),vre=n(_ye,"CODE",{});var F9t=s(vre);e6o=t(F9t,"__init__()"),F9t.forEach(r),o6o=t(_ye," (throws an error)."),_ye.forEach(r),t6o=i(Zs),Vt=n(Zs,"DIV",{class:!0});var el=s(Vt);c(VC.$$.fragment,el),r6o=i(el),bre=n(el,"P",{});var M9t=s(bre);a6o=t(M9t,"Instantiates one of the base model classes of the library from a configuration."),M9t.forEach(r),n6o=i(el),pd=n(el,"P",{});var sG=s(pd);s6o=t(sG,`Note:
Loading a model from its configuration file does `),Tre=n(sG,"STRONG",{});var E9t=s(Tre);l6o=t(E9t,"not"),E9t.forEach(r),i6o=t(sG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Fre=n(sG,"EM",{});var C9t=s(Fre);d6o=t(C9t,"~TFAutoModel.from_pretrained"),C9t.forEach(r),m6o=t(sG,`] to load the model
weights.`),sG.forEach(r),f6o=i(el),Mre=n(el,"P",{});var y9t=s(Mre);c6o=t(y9t,"Examples:"),y9t.forEach(r),g6o=i(el),c(QC.$$.fragment,el),el.forEach(r),h6o=i(Zs),ro=n(Zs,"DIV",{class:!0});var Hr=s(ro);c(HC.$$.fragment,Hr),u6o=i(Hr),Ere=n(Hr,"P",{});var w9t=s(Ere);p6o=t(w9t,"Instantiate one of the base model classes of the library from a pretrained model."),w9t.forEach(r),_6o=i(Hr),za=n(Hr,"P",{});var dF=s(za);v6o=t(dF,"The model class to instantiate is selected based on the "),Cre=n(dF,"EM",{});var A9t=s(Cre);b6o=t(A9t,"model_type"),A9t.forEach(r),T6o=t(dF,` property of the config object (either
passed as an argument or loaded from `),yre=n(dF,"EM",{});var x9t=s(yre);F6o=t(x9t,"pretrained_model_name_or_path"),x9t.forEach(r),M6o=t(dF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),wre=n(dF,"EM",{});var L9t=s(wre);E6o=t(L9t,"pretrained_model_name_or_path"),L9t.forEach(r),C6o=t(dF,":"),dF.forEach(r),y6o=i(Hr),L=n(Hr,"UL",{});var B=s(L);b2=n(B,"LI",{});var M5e=s(b2);Are=n(M5e,"STRONG",{});var B9t=s(Are);w6o=t(B9t,"albert"),B9t.forEach(r),A6o=t(M5e," \u2014 "),uP=n(M5e,"A",{href:!0});var k9t=s(uP);x6o=t(k9t,"TFAlbertModel"),k9t.forEach(r),L6o=t(M5e," (ALBERT model)"),M5e.forEach(r),B6o=i(B),T2=n(B,"LI",{});var E5e=s(T2);xre=n(E5e,"STRONG",{});var R9t=s(xre);k6o=t(R9t,"bart"),R9t.forEach(r),R6o=t(E5e," \u2014 "),pP=n(E5e,"A",{href:!0});var S9t=s(pP);S6o=t(S9t,"TFBartModel"),S9t.forEach(r),P6o=t(E5e," (BART model)"),E5e.forEach(r),$6o=i(B),F2=n(B,"LI",{});var C5e=s(F2);Lre=n(C5e,"STRONG",{});var P9t=s(Lre);I6o=t(P9t,"bert"),P9t.forEach(r),j6o=t(C5e," \u2014 "),_P=n(C5e,"A",{href:!0});var $9t=s(_P);N6o=t($9t,"TFBertModel"),$9t.forEach(r),D6o=t(C5e," (BERT model)"),C5e.forEach(r),G6o=i(B),M2=n(B,"LI",{});var y5e=s(M2);Bre=n(y5e,"STRONG",{});var I9t=s(Bre);O6o=t(I9t,"blenderbot"),I9t.forEach(r),q6o=t(y5e," \u2014 "),vP=n(y5e,"A",{href:!0});var j9t=s(vP);z6o=t(j9t,"TFBlenderbotModel"),j9t.forEach(r),X6o=t(y5e," (Blenderbot model)"),y5e.forEach(r),W6o=i(B),E2=n(B,"LI",{});var w5e=s(E2);kre=n(w5e,"STRONG",{});var N9t=s(kre);V6o=t(N9t,"blenderbot-small"),N9t.forEach(r),Q6o=t(w5e," \u2014 "),bP=n(w5e,"A",{href:!0});var D9t=s(bP);H6o=t(D9t,"TFBlenderbotSmallModel"),D9t.forEach(r),U6o=t(w5e," (BlenderbotSmall model)"),w5e.forEach(r),J6o=i(B),C2=n(B,"LI",{});var A5e=s(C2);Rre=n(A5e,"STRONG",{});var G9t=s(Rre);K6o=t(G9t,"camembert"),G9t.forEach(r),Y6o=t(A5e," \u2014 "),TP=n(A5e,"A",{href:!0});var O9t=s(TP);Z6o=t(O9t,"TFCamembertModel"),O9t.forEach(r),e8o=t(A5e," (CamemBERT model)"),A5e.forEach(r),o8o=i(B),y2=n(B,"LI",{});var x5e=s(y2);Sre=n(x5e,"STRONG",{});var q9t=s(Sre);t8o=t(q9t,"convbert"),q9t.forEach(r),r8o=t(x5e," \u2014 "),FP=n(x5e,"A",{href:!0});var z9t=s(FP);a8o=t(z9t,"TFConvBertModel"),z9t.forEach(r),n8o=t(x5e," (ConvBERT model)"),x5e.forEach(r),s8o=i(B),w2=n(B,"LI",{});var L5e=s(w2);Pre=n(L5e,"STRONG",{});var X9t=s(Pre);l8o=t(X9t,"ctrl"),X9t.forEach(r),i8o=t(L5e," \u2014 "),MP=n(L5e,"A",{href:!0});var W9t=s(MP);d8o=t(W9t,"TFCTRLModel"),W9t.forEach(r),m8o=t(L5e," (CTRL model)"),L5e.forEach(r),f8o=i(B),A2=n(B,"LI",{});var B5e=s(A2);$re=n(B5e,"STRONG",{});var V9t=s($re);c8o=t(V9t,"deberta"),V9t.forEach(r),g8o=t(B5e," \u2014 "),EP=n(B5e,"A",{href:!0});var Q9t=s(EP);h8o=t(Q9t,"TFDebertaModel"),Q9t.forEach(r),u8o=t(B5e," (DeBERTa model)"),B5e.forEach(r),p8o=i(B),x2=n(B,"LI",{});var k5e=s(x2);Ire=n(k5e,"STRONG",{});var H9t=s(Ire);_8o=t(H9t,"deberta-v2"),H9t.forEach(r),v8o=t(k5e," \u2014 "),CP=n(k5e,"A",{href:!0});var U9t=s(CP);b8o=t(U9t,"TFDebertaV2Model"),U9t.forEach(r),T8o=t(k5e," (DeBERTa-v2 model)"),k5e.forEach(r),F8o=i(B),L2=n(B,"LI",{});var R5e=s(L2);jre=n(R5e,"STRONG",{});var J9t=s(jre);M8o=t(J9t,"distilbert"),J9t.forEach(r),E8o=t(R5e," \u2014 "),yP=n(R5e,"A",{href:!0});var K9t=s(yP);C8o=t(K9t,"TFDistilBertModel"),K9t.forEach(r),y8o=t(R5e," (DistilBERT model)"),R5e.forEach(r),w8o=i(B),B2=n(B,"LI",{});var S5e=s(B2);Nre=n(S5e,"STRONG",{});var Y9t=s(Nre);A8o=t(Y9t,"dpr"),Y9t.forEach(r),x8o=t(S5e," \u2014 "),wP=n(S5e,"A",{href:!0});var Z9t=s(wP);L8o=t(Z9t,"TFDPRQuestionEncoder"),Z9t.forEach(r),B8o=t(S5e," (DPR model)"),S5e.forEach(r),k8o=i(B),k2=n(B,"LI",{});var P5e=s(k2);Dre=n(P5e,"STRONG",{});var ekt=s(Dre);R8o=t(ekt,"electra"),ekt.forEach(r),S8o=t(P5e," \u2014 "),AP=n(P5e,"A",{href:!0});var okt=s(AP);P8o=t(okt,"TFElectraModel"),okt.forEach(r),$8o=t(P5e," (ELECTRA model)"),P5e.forEach(r),I8o=i(B),R2=n(B,"LI",{});var $5e=s(R2);Gre=n($5e,"STRONG",{});var tkt=s(Gre);j8o=t(tkt,"flaubert"),tkt.forEach(r),N8o=t($5e," \u2014 "),xP=n($5e,"A",{href:!0});var rkt=s(xP);D8o=t(rkt,"TFFlaubertModel"),rkt.forEach(r),G8o=t($5e," (FlauBERT model)"),$5e.forEach(r),O8o=i(B),ds=n(B,"LI",{});var $A=s(ds);Ore=n($A,"STRONG",{});var akt=s(Ore);q8o=t(akt,"funnel"),akt.forEach(r),z8o=t($A," \u2014 "),LP=n($A,"A",{href:!0});var nkt=s(LP);X8o=t(nkt,"TFFunnelModel"),nkt.forEach(r),W8o=t($A," or "),BP=n($A,"A",{href:!0});var skt=s(BP);V8o=t(skt,"TFFunnelBaseModel"),skt.forEach(r),Q8o=t($A," (Funnel Transformer model)"),$A.forEach(r),H8o=i(B),S2=n(B,"LI",{});var I5e=s(S2);qre=n(I5e,"STRONG",{});var lkt=s(qre);U8o=t(lkt,"gpt2"),lkt.forEach(r),J8o=t(I5e," \u2014 "),kP=n(I5e,"A",{href:!0});var ikt=s(kP);K8o=t(ikt,"TFGPT2Model"),ikt.forEach(r),Y8o=t(I5e," (OpenAI GPT-2 model)"),I5e.forEach(r),Z8o=i(B),P2=n(B,"LI",{});var j5e=s(P2);zre=n(j5e,"STRONG",{});var dkt=s(zre);eLo=t(dkt,"hubert"),dkt.forEach(r),oLo=t(j5e," \u2014 "),RP=n(j5e,"A",{href:!0});var mkt=s(RP);tLo=t(mkt,"TFHubertModel"),mkt.forEach(r),rLo=t(j5e," (Hubert model)"),j5e.forEach(r),aLo=i(B),$2=n(B,"LI",{});var N5e=s($2);Xre=n(N5e,"STRONG",{});var fkt=s(Xre);nLo=t(fkt,"layoutlm"),fkt.forEach(r),sLo=t(N5e," \u2014 "),SP=n(N5e,"A",{href:!0});var ckt=s(SP);lLo=t(ckt,"TFLayoutLMModel"),ckt.forEach(r),iLo=t(N5e," (LayoutLM model)"),N5e.forEach(r),dLo=i(B),I2=n(B,"LI",{});var D5e=s(I2);Wre=n(D5e,"STRONG",{});var gkt=s(Wre);mLo=t(gkt,"led"),gkt.forEach(r),fLo=t(D5e," \u2014 "),PP=n(D5e,"A",{href:!0});var hkt=s(PP);cLo=t(hkt,"TFLEDModel"),hkt.forEach(r),gLo=t(D5e," (LED model)"),D5e.forEach(r),hLo=i(B),j2=n(B,"LI",{});var G5e=s(j2);Vre=n(G5e,"STRONG",{});var ukt=s(Vre);uLo=t(ukt,"longformer"),ukt.forEach(r),pLo=t(G5e," \u2014 "),$P=n(G5e,"A",{href:!0});var pkt=s($P);_Lo=t(pkt,"TFLongformerModel"),pkt.forEach(r),vLo=t(G5e," (Longformer model)"),G5e.forEach(r),bLo=i(B),N2=n(B,"LI",{});var O5e=s(N2);Qre=n(O5e,"STRONG",{});var _kt=s(Qre);TLo=t(_kt,"lxmert"),_kt.forEach(r),FLo=t(O5e," \u2014 "),IP=n(O5e,"A",{href:!0});var vkt=s(IP);MLo=t(vkt,"TFLxmertModel"),vkt.forEach(r),ELo=t(O5e," (LXMERT model)"),O5e.forEach(r),CLo=i(B),D2=n(B,"LI",{});var q5e=s(D2);Hre=n(q5e,"STRONG",{});var bkt=s(Hre);yLo=t(bkt,"marian"),bkt.forEach(r),wLo=t(q5e," \u2014 "),jP=n(q5e,"A",{href:!0});var Tkt=s(jP);ALo=t(Tkt,"TFMarianModel"),Tkt.forEach(r),xLo=t(q5e," (Marian model)"),q5e.forEach(r),LLo=i(B),G2=n(B,"LI",{});var z5e=s(G2);Ure=n(z5e,"STRONG",{});var Fkt=s(Ure);BLo=t(Fkt,"mbart"),Fkt.forEach(r),kLo=t(z5e," \u2014 "),NP=n(z5e,"A",{href:!0});var Mkt=s(NP);RLo=t(Mkt,"TFMBartModel"),Mkt.forEach(r),SLo=t(z5e," (mBART model)"),z5e.forEach(r),PLo=i(B),O2=n(B,"LI",{});var X5e=s(O2);Jre=n(X5e,"STRONG",{});var Ekt=s(Jre);$Lo=t(Ekt,"mobilebert"),Ekt.forEach(r),ILo=t(X5e," \u2014 "),DP=n(X5e,"A",{href:!0});var Ckt=s(DP);jLo=t(Ckt,"TFMobileBertModel"),Ckt.forEach(r),NLo=t(X5e," (MobileBERT model)"),X5e.forEach(r),DLo=i(B),q2=n(B,"LI",{});var W5e=s(q2);Kre=n(W5e,"STRONG",{});var ykt=s(Kre);GLo=t(ykt,"mpnet"),ykt.forEach(r),OLo=t(W5e," \u2014 "),GP=n(W5e,"A",{href:!0});var wkt=s(GP);qLo=t(wkt,"TFMPNetModel"),wkt.forEach(r),zLo=t(W5e," (MPNet model)"),W5e.forEach(r),XLo=i(B),z2=n(B,"LI",{});var V5e=s(z2);Yre=n(V5e,"STRONG",{});var Akt=s(Yre);WLo=t(Akt,"mt5"),Akt.forEach(r),VLo=t(V5e," \u2014 "),OP=n(V5e,"A",{href:!0});var xkt=s(OP);QLo=t(xkt,"TFMT5Model"),xkt.forEach(r),HLo=t(V5e," (mT5 model)"),V5e.forEach(r),ULo=i(B),X2=n(B,"LI",{});var Q5e=s(X2);Zre=n(Q5e,"STRONG",{});var Lkt=s(Zre);JLo=t(Lkt,"openai-gpt"),Lkt.forEach(r),KLo=t(Q5e," \u2014 "),qP=n(Q5e,"A",{href:!0});var Bkt=s(qP);YLo=t(Bkt,"TFOpenAIGPTModel"),Bkt.forEach(r),ZLo=t(Q5e," (OpenAI GPT model)"),Q5e.forEach(r),eBo=i(B),W2=n(B,"LI",{});var H5e=s(W2);eae=n(H5e,"STRONG",{});var kkt=s(eae);oBo=t(kkt,"pegasus"),kkt.forEach(r),tBo=t(H5e," \u2014 "),zP=n(H5e,"A",{href:!0});var Rkt=s(zP);rBo=t(Rkt,"TFPegasusModel"),Rkt.forEach(r),aBo=t(H5e," (Pegasus model)"),H5e.forEach(r),nBo=i(B),V2=n(B,"LI",{});var U5e=s(V2);oae=n(U5e,"STRONG",{});var Skt=s(oae);sBo=t(Skt,"rembert"),Skt.forEach(r),lBo=t(U5e," \u2014 "),XP=n(U5e,"A",{href:!0});var Pkt=s(XP);iBo=t(Pkt,"TFRemBertModel"),Pkt.forEach(r),dBo=t(U5e," (RemBERT model)"),U5e.forEach(r),mBo=i(B),Q2=n(B,"LI",{});var J5e=s(Q2);tae=n(J5e,"STRONG",{});var $kt=s(tae);fBo=t($kt,"roberta"),$kt.forEach(r),cBo=t(J5e," \u2014 "),WP=n(J5e,"A",{href:!0});var Ikt=s(WP);gBo=t(Ikt,"TFRobertaModel"),Ikt.forEach(r),hBo=t(J5e," (RoBERTa model)"),J5e.forEach(r),uBo=i(B),H2=n(B,"LI",{});var K5e=s(H2);rae=n(K5e,"STRONG",{});var jkt=s(rae);pBo=t(jkt,"roformer"),jkt.forEach(r),_Bo=t(K5e," \u2014 "),VP=n(K5e,"A",{href:!0});var Nkt=s(VP);vBo=t(Nkt,"TFRoFormerModel"),Nkt.forEach(r),bBo=t(K5e," (RoFormer model)"),K5e.forEach(r),TBo=i(B),U2=n(B,"LI",{});var Y5e=s(U2);aae=n(Y5e,"STRONG",{});var Dkt=s(aae);FBo=t(Dkt,"t5"),Dkt.forEach(r),MBo=t(Y5e," \u2014 "),QP=n(Y5e,"A",{href:!0});var Gkt=s(QP);EBo=t(Gkt,"TFT5Model"),Gkt.forEach(r),CBo=t(Y5e," (T5 model)"),Y5e.forEach(r),yBo=i(B),J2=n(B,"LI",{});var Z5e=s(J2);nae=n(Z5e,"STRONG",{});var Okt=s(nae);wBo=t(Okt,"tapas"),Okt.forEach(r),ABo=t(Z5e," \u2014 "),HP=n(Z5e,"A",{href:!0});var qkt=s(HP);xBo=t(qkt,"TFTapasModel"),qkt.forEach(r),LBo=t(Z5e," (TAPAS model)"),Z5e.forEach(r),BBo=i(B),K2=n(B,"LI",{});var e0e=s(K2);sae=n(e0e,"STRONG",{});var zkt=s(sae);kBo=t(zkt,"transfo-xl"),zkt.forEach(r),RBo=t(e0e," \u2014 "),UP=n(e0e,"A",{href:!0});var Xkt=s(UP);SBo=t(Xkt,"TFTransfoXLModel"),Xkt.forEach(r),PBo=t(e0e," (Transformer-XL model)"),e0e.forEach(r),$Bo=i(B),Y2=n(B,"LI",{});var o0e=s(Y2);lae=n(o0e,"STRONG",{});var Wkt=s(lae);IBo=t(Wkt,"vit"),Wkt.forEach(r),jBo=t(o0e," \u2014 "),JP=n(o0e,"A",{href:!0});var Vkt=s(JP);NBo=t(Vkt,"TFViTModel"),Vkt.forEach(r),DBo=t(o0e," (ViT model)"),o0e.forEach(r),GBo=i(B),Z2=n(B,"LI",{});var t0e=s(Z2);iae=n(t0e,"STRONG",{});var Qkt=s(iae);OBo=t(Qkt,"wav2vec2"),Qkt.forEach(r),qBo=t(t0e," \u2014 "),KP=n(t0e,"A",{href:!0});var Hkt=s(KP);zBo=t(Hkt,"TFWav2Vec2Model"),Hkt.forEach(r),XBo=t(t0e," (Wav2Vec2 model)"),t0e.forEach(r),WBo=i(B),eb=n(B,"LI",{});var r0e=s(eb);dae=n(r0e,"STRONG",{});var Ukt=s(dae);VBo=t(Ukt,"xlm"),Ukt.forEach(r),QBo=t(r0e," \u2014 "),YP=n(r0e,"A",{href:!0});var Jkt=s(YP);HBo=t(Jkt,"TFXLMModel"),Jkt.forEach(r),UBo=t(r0e," (XLM model)"),r0e.forEach(r),JBo=i(B),ob=n(B,"LI",{});var a0e=s(ob);mae=n(a0e,"STRONG",{});var Kkt=s(mae);KBo=t(Kkt,"xlm-roberta"),Kkt.forEach(r),YBo=t(a0e," \u2014 "),ZP=n(a0e,"A",{href:!0});var Ykt=s(ZP);ZBo=t(Ykt,"TFXLMRobertaModel"),Ykt.forEach(r),e9o=t(a0e," (XLM-RoBERTa model)"),a0e.forEach(r),o9o=i(B),tb=n(B,"LI",{});var n0e=s(tb);fae=n(n0e,"STRONG",{});var Zkt=s(fae);t9o=t(Zkt,"xlnet"),Zkt.forEach(r),r9o=t(n0e," \u2014 "),e$=n(n0e,"A",{href:!0});var eRt=s(e$);a9o=t(eRt,"TFXLNetModel"),eRt.forEach(r),n9o=t(n0e," (XLNet model)"),n0e.forEach(r),B.forEach(r),s9o=i(Hr),cae=n(Hr,"P",{});var oRt=s(cae);l9o=t(oRt,"Examples:"),oRt.forEach(r),i9o=i(Hr),c(UC.$$.fragment,Hr),Hr.forEach(r),Zs.forEach(r),TCe=i(d),_d=n(d,"H2",{class:!0});var vye=s(_d);rb=n(vye,"A",{id:!0,class:!0,href:!0});var tRt=s(rb);gae=n(tRt,"SPAN",{});var rRt=s(gae);c(JC.$$.fragment,rRt),rRt.forEach(r),tRt.forEach(r),d9o=i(vye),hae=n(vye,"SPAN",{});var aRt=s(hae);m9o=t(aRt,"TFAutoModelForPreTraining"),aRt.forEach(r),vye.forEach(r),FCe=i(d),tt=n(d,"DIV",{class:!0});var ol=s(tt);c(KC.$$.fragment,ol),f9o=i(ol),vd=n(ol,"P",{});var lG=s(vd);c9o=t(lG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),uae=n(lG,"CODE",{});var nRt=s(uae);g9o=t(nRt,"from_pretrained()"),nRt.forEach(r),h9o=t(lG,` class method or the
`),pae=n(lG,"CODE",{});var sRt=s(pae);u9o=t(sRt,"from_config()"),sRt.forEach(r),p9o=t(lG," class method."),lG.forEach(r),_9o=i(ol),YC=n(ol,"P",{});var bye=s(YC);v9o=t(bye,"This class cannot be instantiated directly using "),_ae=n(bye,"CODE",{});var lRt=s(_ae);b9o=t(lRt,"__init__()"),lRt.forEach(r),T9o=t(bye," (throws an error)."),bye.forEach(r),F9o=i(ol),Qt=n(ol,"DIV",{class:!0});var tl=s(Qt);c(ZC.$$.fragment,tl),M9o=i(tl),vae=n(tl,"P",{});var iRt=s(vae);E9o=t(iRt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),iRt.forEach(r),C9o=i(tl),bd=n(tl,"P",{});var iG=s(bd);y9o=t(iG,`Note:
Loading a model from its configuration file does `),bae=n(iG,"STRONG",{});var dRt=s(bae);w9o=t(dRt,"not"),dRt.forEach(r),A9o=t(iG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Tae=n(iG,"EM",{});var mRt=s(Tae);x9o=t(mRt,"~TFAutoModelForPreTraining.from_pretrained"),mRt.forEach(r),L9o=t(iG,`] to load the model
weights.`),iG.forEach(r),B9o=i(tl),Fae=n(tl,"P",{});var fRt=s(Fae);k9o=t(fRt,"Examples:"),fRt.forEach(r),R9o=i(tl),c(e3.$$.fragment,tl),tl.forEach(r),S9o=i(ol),ao=n(ol,"DIV",{class:!0});var Ur=s(ao);c(o3.$$.fragment,Ur),P9o=i(Ur),Mae=n(Ur,"P",{});var cRt=s(Mae);$9o=t(cRt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),cRt.forEach(r),I9o=i(Ur),Xa=n(Ur,"P",{});var mF=s(Xa);j9o=t(mF,"The model class to instantiate is selected based on the "),Eae=n(mF,"EM",{});var gRt=s(Eae);N9o=t(gRt,"model_type"),gRt.forEach(r),D9o=t(mF,` property of the config object (either
passed as an argument or loaded from `),Cae=n(mF,"EM",{});var hRt=s(Cae);G9o=t(hRt,"pretrained_model_name_or_path"),hRt.forEach(r),O9o=t(mF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),yae=n(mF,"EM",{});var uRt=s(yae);q9o=t(uRt,"pretrained_model_name_or_path"),uRt.forEach(r),z9o=t(mF,":"),mF.forEach(r),X9o=i(Ur),V=n(Ur,"UL",{});var H=s(V);ab=n(H,"LI",{});var s0e=s(ab);wae=n(s0e,"STRONG",{});var pRt=s(wae);W9o=t(pRt,"albert"),pRt.forEach(r),V9o=t(s0e," \u2014 "),o$=n(s0e,"A",{href:!0});var _Rt=s(o$);Q9o=t(_Rt,"TFAlbertForPreTraining"),_Rt.forEach(r),H9o=t(s0e," (ALBERT model)"),s0e.forEach(r),U9o=i(H),nb=n(H,"LI",{});var l0e=s(nb);Aae=n(l0e,"STRONG",{});var vRt=s(Aae);J9o=t(vRt,"bart"),vRt.forEach(r),K9o=t(l0e," \u2014 "),t$=n(l0e,"A",{href:!0});var bRt=s(t$);Y9o=t(bRt,"TFBartForConditionalGeneration"),bRt.forEach(r),Z9o=t(l0e," (BART model)"),l0e.forEach(r),eko=i(H),sb=n(H,"LI",{});var i0e=s(sb);xae=n(i0e,"STRONG",{});var TRt=s(xae);oko=t(TRt,"bert"),TRt.forEach(r),tko=t(i0e," \u2014 "),r$=n(i0e,"A",{href:!0});var FRt=s(r$);rko=t(FRt,"TFBertForPreTraining"),FRt.forEach(r),ako=t(i0e," (BERT model)"),i0e.forEach(r),nko=i(H),lb=n(H,"LI",{});var d0e=s(lb);Lae=n(d0e,"STRONG",{});var MRt=s(Lae);sko=t(MRt,"camembert"),MRt.forEach(r),lko=t(d0e," \u2014 "),a$=n(d0e,"A",{href:!0});var ERt=s(a$);iko=t(ERt,"TFCamembertForMaskedLM"),ERt.forEach(r),dko=t(d0e," (CamemBERT model)"),d0e.forEach(r),mko=i(H),ib=n(H,"LI",{});var m0e=s(ib);Bae=n(m0e,"STRONG",{});var CRt=s(Bae);fko=t(CRt,"ctrl"),CRt.forEach(r),cko=t(m0e," \u2014 "),n$=n(m0e,"A",{href:!0});var yRt=s(n$);gko=t(yRt,"TFCTRLLMHeadModel"),yRt.forEach(r),hko=t(m0e," (CTRL model)"),m0e.forEach(r),uko=i(H),db=n(H,"LI",{});var f0e=s(db);kae=n(f0e,"STRONG",{});var wRt=s(kae);pko=t(wRt,"distilbert"),wRt.forEach(r),_ko=t(f0e," \u2014 "),s$=n(f0e,"A",{href:!0});var ARt=s(s$);vko=t(ARt,"TFDistilBertForMaskedLM"),ARt.forEach(r),bko=t(f0e," (DistilBERT model)"),f0e.forEach(r),Tko=i(H),mb=n(H,"LI",{});var c0e=s(mb);Rae=n(c0e,"STRONG",{});var xRt=s(Rae);Fko=t(xRt,"electra"),xRt.forEach(r),Mko=t(c0e," \u2014 "),l$=n(c0e,"A",{href:!0});var LRt=s(l$);Eko=t(LRt,"TFElectraForPreTraining"),LRt.forEach(r),Cko=t(c0e," (ELECTRA model)"),c0e.forEach(r),yko=i(H),fb=n(H,"LI",{});var g0e=s(fb);Sae=n(g0e,"STRONG",{});var BRt=s(Sae);wko=t(BRt,"flaubert"),BRt.forEach(r),Ako=t(g0e," \u2014 "),i$=n(g0e,"A",{href:!0});var kRt=s(i$);xko=t(kRt,"TFFlaubertWithLMHeadModel"),kRt.forEach(r),Lko=t(g0e," (FlauBERT model)"),g0e.forEach(r),Bko=i(H),cb=n(H,"LI",{});var h0e=s(cb);Pae=n(h0e,"STRONG",{});var RRt=s(Pae);kko=t(RRt,"funnel"),RRt.forEach(r),Rko=t(h0e," \u2014 "),d$=n(h0e,"A",{href:!0});var SRt=s(d$);Sko=t(SRt,"TFFunnelForPreTraining"),SRt.forEach(r),Pko=t(h0e," (Funnel Transformer model)"),h0e.forEach(r),$ko=i(H),gb=n(H,"LI",{});var u0e=s(gb);$ae=n(u0e,"STRONG",{});var PRt=s($ae);Iko=t(PRt,"gpt2"),PRt.forEach(r),jko=t(u0e," \u2014 "),m$=n(u0e,"A",{href:!0});var $Rt=s(m$);Nko=t($Rt,"TFGPT2LMHeadModel"),$Rt.forEach(r),Dko=t(u0e," (OpenAI GPT-2 model)"),u0e.forEach(r),Gko=i(H),hb=n(H,"LI",{});var p0e=s(hb);Iae=n(p0e,"STRONG",{});var IRt=s(Iae);Oko=t(IRt,"layoutlm"),IRt.forEach(r),qko=t(p0e," \u2014 "),f$=n(p0e,"A",{href:!0});var jRt=s(f$);zko=t(jRt,"TFLayoutLMForMaskedLM"),jRt.forEach(r),Xko=t(p0e," (LayoutLM model)"),p0e.forEach(r),Wko=i(H),ub=n(H,"LI",{});var _0e=s(ub);jae=n(_0e,"STRONG",{});var NRt=s(jae);Vko=t(NRt,"lxmert"),NRt.forEach(r),Qko=t(_0e," \u2014 "),c$=n(_0e,"A",{href:!0});var DRt=s(c$);Hko=t(DRt,"TFLxmertForPreTraining"),DRt.forEach(r),Uko=t(_0e," (LXMERT model)"),_0e.forEach(r),Jko=i(H),pb=n(H,"LI",{});var v0e=s(pb);Nae=n(v0e,"STRONG",{});var GRt=s(Nae);Kko=t(GRt,"mobilebert"),GRt.forEach(r),Yko=t(v0e," \u2014 "),g$=n(v0e,"A",{href:!0});var ORt=s(g$);Zko=t(ORt,"TFMobileBertForPreTraining"),ORt.forEach(r),eRo=t(v0e," (MobileBERT model)"),v0e.forEach(r),oRo=i(H),_b=n(H,"LI",{});var b0e=s(_b);Dae=n(b0e,"STRONG",{});var qRt=s(Dae);tRo=t(qRt,"mpnet"),qRt.forEach(r),rRo=t(b0e," \u2014 "),h$=n(b0e,"A",{href:!0});var zRt=s(h$);aRo=t(zRt,"TFMPNetForMaskedLM"),zRt.forEach(r),nRo=t(b0e," (MPNet model)"),b0e.forEach(r),sRo=i(H),vb=n(H,"LI",{});var T0e=s(vb);Gae=n(T0e,"STRONG",{});var XRt=s(Gae);lRo=t(XRt,"openai-gpt"),XRt.forEach(r),iRo=t(T0e," \u2014 "),u$=n(T0e,"A",{href:!0});var WRt=s(u$);dRo=t(WRt,"TFOpenAIGPTLMHeadModel"),WRt.forEach(r),mRo=t(T0e," (OpenAI GPT model)"),T0e.forEach(r),fRo=i(H),bb=n(H,"LI",{});var F0e=s(bb);Oae=n(F0e,"STRONG",{});var VRt=s(Oae);cRo=t(VRt,"roberta"),VRt.forEach(r),gRo=t(F0e," \u2014 "),p$=n(F0e,"A",{href:!0});var QRt=s(p$);hRo=t(QRt,"TFRobertaForMaskedLM"),QRt.forEach(r),uRo=t(F0e," (RoBERTa model)"),F0e.forEach(r),pRo=i(H),Tb=n(H,"LI",{});var M0e=s(Tb);qae=n(M0e,"STRONG",{});var HRt=s(qae);_Ro=t(HRt,"t5"),HRt.forEach(r),vRo=t(M0e," \u2014 "),_$=n(M0e,"A",{href:!0});var URt=s(_$);bRo=t(URt,"TFT5ForConditionalGeneration"),URt.forEach(r),TRo=t(M0e," (T5 model)"),M0e.forEach(r),FRo=i(H),Fb=n(H,"LI",{});var E0e=s(Fb);zae=n(E0e,"STRONG",{});var JRt=s(zae);MRo=t(JRt,"tapas"),JRt.forEach(r),ERo=t(E0e," \u2014 "),v$=n(E0e,"A",{href:!0});var KRt=s(v$);CRo=t(KRt,"TFTapasForMaskedLM"),KRt.forEach(r),yRo=t(E0e," (TAPAS model)"),E0e.forEach(r),wRo=i(H),Mb=n(H,"LI",{});var C0e=s(Mb);Xae=n(C0e,"STRONG",{});var YRt=s(Xae);ARo=t(YRt,"transfo-xl"),YRt.forEach(r),xRo=t(C0e," \u2014 "),b$=n(C0e,"A",{href:!0});var ZRt=s(b$);LRo=t(ZRt,"TFTransfoXLLMHeadModel"),ZRt.forEach(r),BRo=t(C0e," (Transformer-XL model)"),C0e.forEach(r),kRo=i(H),Eb=n(H,"LI",{});var y0e=s(Eb);Wae=n(y0e,"STRONG",{});var eSt=s(Wae);RRo=t(eSt,"xlm"),eSt.forEach(r),SRo=t(y0e," \u2014 "),T$=n(y0e,"A",{href:!0});var oSt=s(T$);PRo=t(oSt,"TFXLMWithLMHeadModel"),oSt.forEach(r),$Ro=t(y0e," (XLM model)"),y0e.forEach(r),IRo=i(H),Cb=n(H,"LI",{});var w0e=s(Cb);Vae=n(w0e,"STRONG",{});var tSt=s(Vae);jRo=t(tSt,"xlm-roberta"),tSt.forEach(r),NRo=t(w0e," \u2014 "),F$=n(w0e,"A",{href:!0});var rSt=s(F$);DRo=t(rSt,"TFXLMRobertaForMaskedLM"),rSt.forEach(r),GRo=t(w0e," (XLM-RoBERTa model)"),w0e.forEach(r),ORo=i(H),yb=n(H,"LI",{});var A0e=s(yb);Qae=n(A0e,"STRONG",{});var aSt=s(Qae);qRo=t(aSt,"xlnet"),aSt.forEach(r),zRo=t(A0e," \u2014 "),M$=n(A0e,"A",{href:!0});var nSt=s(M$);XRo=t(nSt,"TFXLNetLMHeadModel"),nSt.forEach(r),WRo=t(A0e," (XLNet model)"),A0e.forEach(r),H.forEach(r),VRo=i(Ur),Hae=n(Ur,"P",{});var sSt=s(Hae);QRo=t(sSt,"Examples:"),sSt.forEach(r),HRo=i(Ur),c(t3.$$.fragment,Ur),Ur.forEach(r),ol.forEach(r),MCe=i(d),Td=n(d,"H2",{class:!0});var Tye=s(Td);wb=n(Tye,"A",{id:!0,class:!0,href:!0});var lSt=s(wb);Uae=n(lSt,"SPAN",{});var iSt=s(Uae);c(r3.$$.fragment,iSt),iSt.forEach(r),lSt.forEach(r),URo=i(Tye),Jae=n(Tye,"SPAN",{});var dSt=s(Jae);JRo=t(dSt,"TFAutoModelForCausalLM"),dSt.forEach(r),Tye.forEach(r),ECe=i(d),rt=n(d,"DIV",{class:!0});var rl=s(rt);c(a3.$$.fragment,rl),KRo=i(rl),Fd=n(rl,"P",{});var dG=s(Fd);YRo=t(dG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Kae=n(dG,"CODE",{});var mSt=s(Kae);ZRo=t(mSt,"from_pretrained()"),mSt.forEach(r),eSo=t(dG,` class method or the
`),Yae=n(dG,"CODE",{});var fSt=s(Yae);oSo=t(fSt,"from_config()"),fSt.forEach(r),tSo=t(dG," class method."),dG.forEach(r),rSo=i(rl),n3=n(rl,"P",{});var Fye=s(n3);aSo=t(Fye,"This class cannot be instantiated directly using "),Zae=n(Fye,"CODE",{});var cSt=s(Zae);nSo=t(cSt,"__init__()"),cSt.forEach(r),sSo=t(Fye," (throws an error)."),Fye.forEach(r),lSo=i(rl),Ht=n(rl,"DIV",{class:!0});var al=s(Ht);c(s3.$$.fragment,al),iSo=i(al),ene=n(al,"P",{});var gSt=s(ene);dSo=t(gSt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gSt.forEach(r),mSo=i(al),Md=n(al,"P",{});var mG=s(Md);fSo=t(mG,`Note:
Loading a model from its configuration file does `),one=n(mG,"STRONG",{});var hSt=s(one);cSo=t(hSt,"not"),hSt.forEach(r),gSo=t(mG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),tne=n(mG,"EM",{});var uSt=s(tne);hSo=t(uSt,"~TFAutoModelForCausalLM.from_pretrained"),uSt.forEach(r),uSo=t(mG,`] to load the model
weights.`),mG.forEach(r),pSo=i(al),rne=n(al,"P",{});var pSt=s(rne);_So=t(pSt,"Examples:"),pSt.forEach(r),vSo=i(al),c(l3.$$.fragment,al),al.forEach(r),bSo=i(rl),no=n(rl,"DIV",{class:!0});var Jr=s(no);c(i3.$$.fragment,Jr),TSo=i(Jr),ane=n(Jr,"P",{});var _St=s(ane);FSo=t(_St,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),_St.forEach(r),MSo=i(Jr),Wa=n(Jr,"P",{});var fF=s(Wa);ESo=t(fF,"The model class to instantiate is selected based on the "),nne=n(fF,"EM",{});var vSt=s(nne);CSo=t(vSt,"model_type"),vSt.forEach(r),ySo=t(fF,` property of the config object (either
passed as an argument or loaded from `),sne=n(fF,"EM",{});var bSt=s(sne);wSo=t(bSt,"pretrained_model_name_or_path"),bSt.forEach(r),ASo=t(fF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),lne=n(fF,"EM",{});var TSt=s(lne);xSo=t(TSt,"pretrained_model_name_or_path"),TSt.forEach(r),LSo=t(fF,":"),fF.forEach(r),BSo=i(Jr),ce=n(Jr,"UL",{});var ve=s(ce);Ab=n(ve,"LI",{});var x0e=s(Ab);ine=n(x0e,"STRONG",{});var FSt=s(ine);kSo=t(FSt,"bert"),FSt.forEach(r),RSo=t(x0e," \u2014 "),E$=n(x0e,"A",{href:!0});var MSt=s(E$);SSo=t(MSt,"TFBertLMHeadModel"),MSt.forEach(r),PSo=t(x0e," (BERT model)"),x0e.forEach(r),$So=i(ve),xb=n(ve,"LI",{});var L0e=s(xb);dne=n(L0e,"STRONG",{});var ESt=s(dne);ISo=t(ESt,"ctrl"),ESt.forEach(r),jSo=t(L0e," \u2014 "),C$=n(L0e,"A",{href:!0});var CSt=s(C$);NSo=t(CSt,"TFCTRLLMHeadModel"),CSt.forEach(r),DSo=t(L0e," (CTRL model)"),L0e.forEach(r),GSo=i(ve),Lb=n(ve,"LI",{});var B0e=s(Lb);mne=n(B0e,"STRONG",{});var ySt=s(mne);OSo=t(ySt,"gpt2"),ySt.forEach(r),qSo=t(B0e," \u2014 "),y$=n(B0e,"A",{href:!0});var wSt=s(y$);zSo=t(wSt,"TFGPT2LMHeadModel"),wSt.forEach(r),XSo=t(B0e," (OpenAI GPT-2 model)"),B0e.forEach(r),WSo=i(ve),Bb=n(ve,"LI",{});var k0e=s(Bb);fne=n(k0e,"STRONG",{});var ASt=s(fne);VSo=t(ASt,"openai-gpt"),ASt.forEach(r),QSo=t(k0e," \u2014 "),w$=n(k0e,"A",{href:!0});var xSt=s(w$);HSo=t(xSt,"TFOpenAIGPTLMHeadModel"),xSt.forEach(r),USo=t(k0e," (OpenAI GPT model)"),k0e.forEach(r),JSo=i(ve),kb=n(ve,"LI",{});var R0e=s(kb);cne=n(R0e,"STRONG",{});var LSt=s(cne);KSo=t(LSt,"rembert"),LSt.forEach(r),YSo=t(R0e," \u2014 "),A$=n(R0e,"A",{href:!0});var BSt=s(A$);ZSo=t(BSt,"TFRemBertForCausalLM"),BSt.forEach(r),ePo=t(R0e," (RemBERT model)"),R0e.forEach(r),oPo=i(ve),Rb=n(ve,"LI",{});var S0e=s(Rb);gne=n(S0e,"STRONG",{});var kSt=s(gne);tPo=t(kSt,"roberta"),kSt.forEach(r),rPo=t(S0e," \u2014 "),x$=n(S0e,"A",{href:!0});var RSt=s(x$);aPo=t(RSt,"TFRobertaForCausalLM"),RSt.forEach(r),nPo=t(S0e," (RoBERTa model)"),S0e.forEach(r),sPo=i(ve),Sb=n(ve,"LI",{});var P0e=s(Sb);hne=n(P0e,"STRONG",{});var SSt=s(hne);lPo=t(SSt,"roformer"),SSt.forEach(r),iPo=t(P0e," \u2014 "),L$=n(P0e,"A",{href:!0});var PSt=s(L$);dPo=t(PSt,"TFRoFormerForCausalLM"),PSt.forEach(r),mPo=t(P0e," (RoFormer model)"),P0e.forEach(r),fPo=i(ve),Pb=n(ve,"LI",{});var $0e=s(Pb);une=n($0e,"STRONG",{});var $St=s(une);cPo=t($St,"transfo-xl"),$St.forEach(r),gPo=t($0e," \u2014 "),B$=n($0e,"A",{href:!0});var ISt=s(B$);hPo=t(ISt,"TFTransfoXLLMHeadModel"),ISt.forEach(r),uPo=t($0e," (Transformer-XL model)"),$0e.forEach(r),pPo=i(ve),$b=n(ve,"LI",{});var I0e=s($b);pne=n(I0e,"STRONG",{});var jSt=s(pne);_Po=t(jSt,"xlm"),jSt.forEach(r),vPo=t(I0e," \u2014 "),k$=n(I0e,"A",{href:!0});var NSt=s(k$);bPo=t(NSt,"TFXLMWithLMHeadModel"),NSt.forEach(r),TPo=t(I0e," (XLM model)"),I0e.forEach(r),FPo=i(ve),Ib=n(ve,"LI",{});var j0e=s(Ib);_ne=n(j0e,"STRONG",{});var DSt=s(_ne);MPo=t(DSt,"xlnet"),DSt.forEach(r),EPo=t(j0e," \u2014 "),R$=n(j0e,"A",{href:!0});var GSt=s(R$);CPo=t(GSt,"TFXLNetLMHeadModel"),GSt.forEach(r),yPo=t(j0e," (XLNet model)"),j0e.forEach(r),ve.forEach(r),wPo=i(Jr),vne=n(Jr,"P",{});var OSt=s(vne);APo=t(OSt,"Examples:"),OSt.forEach(r),xPo=i(Jr),c(d3.$$.fragment,Jr),Jr.forEach(r),rl.forEach(r),CCe=i(d),Ed=n(d,"H2",{class:!0});var Mye=s(Ed);jb=n(Mye,"A",{id:!0,class:!0,href:!0});var qSt=s(jb);bne=n(qSt,"SPAN",{});var zSt=s(bne);c(m3.$$.fragment,zSt),zSt.forEach(r),qSt.forEach(r),LPo=i(Mye),Tne=n(Mye,"SPAN",{});var XSt=s(Tne);BPo=t(XSt,"TFAutoModelForImageClassification"),XSt.forEach(r),Mye.forEach(r),yCe=i(d),at=n(d,"DIV",{class:!0});var nl=s(at);c(f3.$$.fragment,nl),kPo=i(nl),Cd=n(nl,"P",{});var fG=s(Cd);RPo=t(fG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Fne=n(fG,"CODE",{});var WSt=s(Fne);SPo=t(WSt,"from_pretrained()"),WSt.forEach(r),PPo=t(fG,` class method or the
`),Mne=n(fG,"CODE",{});var VSt=s(Mne);$Po=t(VSt,"from_config()"),VSt.forEach(r),IPo=t(fG," class method."),fG.forEach(r),jPo=i(nl),c3=n(nl,"P",{});var Eye=s(c3);NPo=t(Eye,"This class cannot be instantiated directly using "),Ene=n(Eye,"CODE",{});var QSt=s(Ene);DPo=t(QSt,"__init__()"),QSt.forEach(r),GPo=t(Eye," (throws an error)."),Eye.forEach(r),OPo=i(nl),Ut=n(nl,"DIV",{class:!0});var sl=s(Ut);c(g3.$$.fragment,sl),qPo=i(sl),Cne=n(sl,"P",{});var HSt=s(Cne);zPo=t(HSt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),HSt.forEach(r),XPo=i(sl),yd=n(sl,"P",{});var cG=s(yd);WPo=t(cG,`Note:
Loading a model from its configuration file does `),yne=n(cG,"STRONG",{});var USt=s(yne);VPo=t(USt,"not"),USt.forEach(r),QPo=t(cG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),wne=n(cG,"EM",{});var JSt=s(wne);HPo=t(JSt,"~TFAutoModelForImageClassification.from_pretrained"),JSt.forEach(r),UPo=t(cG,`] to load the model
weights.`),cG.forEach(r),JPo=i(sl),Ane=n(sl,"P",{});var KSt=s(Ane);KPo=t(KSt,"Examples:"),KSt.forEach(r),YPo=i(sl),c(h3.$$.fragment,sl),sl.forEach(r),ZPo=i(nl),so=n(nl,"DIV",{class:!0});var Kr=s(so);c(u3.$$.fragment,Kr),e$o=i(Kr),xne=n(Kr,"P",{});var YSt=s(xne);o$o=t(YSt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),YSt.forEach(r),t$o=i(Kr),Va=n(Kr,"P",{});var cF=s(Va);r$o=t(cF,"The model class to instantiate is selected based on the "),Lne=n(cF,"EM",{});var ZSt=s(Lne);a$o=t(ZSt,"model_type"),ZSt.forEach(r),n$o=t(cF,` property of the config object (either
passed as an argument or loaded from `),Bne=n(cF,"EM",{});var ePt=s(Bne);s$o=t(ePt,"pretrained_model_name_or_path"),ePt.forEach(r),l$o=t(cF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),kne=n(cF,"EM",{});var oPt=s(kne);i$o=t(oPt,"pretrained_model_name_or_path"),oPt.forEach(r),d$o=t(cF,":"),cF.forEach(r),m$o=i(Kr),Rne=n(Kr,"UL",{});var tPt=s(Rne);Nb=n(tPt,"LI",{});var N0e=s(Nb);Sne=n(N0e,"STRONG",{});var rPt=s(Sne);f$o=t(rPt,"vit"),rPt.forEach(r),c$o=t(N0e," \u2014 "),S$=n(N0e,"A",{href:!0});var aPt=s(S$);g$o=t(aPt,"TFViTForImageClassification"),aPt.forEach(r),h$o=t(N0e," (ViT model)"),N0e.forEach(r),tPt.forEach(r),u$o=i(Kr),Pne=n(Kr,"P",{});var nPt=s(Pne);p$o=t(nPt,"Examples:"),nPt.forEach(r),_$o=i(Kr),c(p3.$$.fragment,Kr),Kr.forEach(r),nl.forEach(r),wCe=i(d),wd=n(d,"H2",{class:!0});var Cye=s(wd);Db=n(Cye,"A",{id:!0,class:!0,href:!0});var sPt=s(Db);$ne=n(sPt,"SPAN",{});var lPt=s($ne);c(_3.$$.fragment,lPt),lPt.forEach(r),sPt.forEach(r),v$o=i(Cye),Ine=n(Cye,"SPAN",{});var iPt=s(Ine);b$o=t(iPt,"TFAutoModelForMaskedLM"),iPt.forEach(r),Cye.forEach(r),ACe=i(d),nt=n(d,"DIV",{class:!0});var ll=s(nt);c(v3.$$.fragment,ll),T$o=i(ll),Ad=n(ll,"P",{});var gG=s(Ad);F$o=t(gG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jne=n(gG,"CODE",{});var dPt=s(jne);M$o=t(dPt,"from_pretrained()"),dPt.forEach(r),E$o=t(gG,` class method or the
`),Nne=n(gG,"CODE",{});var mPt=s(Nne);C$o=t(mPt,"from_config()"),mPt.forEach(r),y$o=t(gG," class method."),gG.forEach(r),w$o=i(ll),b3=n(ll,"P",{});var yye=s(b3);A$o=t(yye,"This class cannot be instantiated directly using "),Dne=n(yye,"CODE",{});var fPt=s(Dne);x$o=t(fPt,"__init__()"),fPt.forEach(r),L$o=t(yye," (throws an error)."),yye.forEach(r),B$o=i(ll),Jt=n(ll,"DIV",{class:!0});var il=s(Jt);c(T3.$$.fragment,il),k$o=i(il),Gne=n(il,"P",{});var cPt=s(Gne);R$o=t(cPt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),cPt.forEach(r),S$o=i(il),xd=n(il,"P",{});var hG=s(xd);P$o=t(hG,`Note:
Loading a model from its configuration file does `),One=n(hG,"STRONG",{});var gPt=s(One);$$o=t(gPt,"not"),gPt.forEach(r),I$o=t(hG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),qne=n(hG,"EM",{});var hPt=s(qne);j$o=t(hPt,"~TFAutoModelForMaskedLM.from_pretrained"),hPt.forEach(r),N$o=t(hG,`] to load the model
weights.`),hG.forEach(r),D$o=i(il),zne=n(il,"P",{});var uPt=s(zne);G$o=t(uPt,"Examples:"),uPt.forEach(r),O$o=i(il),c(F3.$$.fragment,il),il.forEach(r),q$o=i(ll),lo=n(ll,"DIV",{class:!0});var Yr=s(lo);c(M3.$$.fragment,Yr),z$o=i(Yr),Xne=n(Yr,"P",{});var pPt=s(Xne);X$o=t(pPt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),pPt.forEach(r),W$o=i(Yr),Qa=n(Yr,"P",{});var gF=s(Qa);V$o=t(gF,"The model class to instantiate is selected based on the "),Wne=n(gF,"EM",{});var _Pt=s(Wne);Q$o=t(_Pt,"model_type"),_Pt.forEach(r),H$o=t(gF,` property of the config object (either
passed as an argument or loaded from `),Vne=n(gF,"EM",{});var vPt=s(Vne);U$o=t(vPt,"pretrained_model_name_or_path"),vPt.forEach(r),J$o=t(gF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Qne=n(gF,"EM",{});var bPt=s(Qne);K$o=t(bPt,"pretrained_model_name_or_path"),bPt.forEach(r),Y$o=t(gF,":"),gF.forEach(r),Z$o=i(Yr),K=n(Yr,"UL",{});var ee=s(K);Gb=n(ee,"LI",{});var D0e=s(Gb);Hne=n(D0e,"STRONG",{});var TPt=s(Hne);eIo=t(TPt,"albert"),TPt.forEach(r),oIo=t(D0e," \u2014 "),P$=n(D0e,"A",{href:!0});var FPt=s(P$);tIo=t(FPt,"TFAlbertForMaskedLM"),FPt.forEach(r),rIo=t(D0e," (ALBERT model)"),D0e.forEach(r),aIo=i(ee),Ob=n(ee,"LI",{});var G0e=s(Ob);Une=n(G0e,"STRONG",{});var MPt=s(Une);nIo=t(MPt,"bert"),MPt.forEach(r),sIo=t(G0e," \u2014 "),$$=n(G0e,"A",{href:!0});var EPt=s($$);lIo=t(EPt,"TFBertForMaskedLM"),EPt.forEach(r),iIo=t(G0e," (BERT model)"),G0e.forEach(r),dIo=i(ee),qb=n(ee,"LI",{});var O0e=s(qb);Jne=n(O0e,"STRONG",{});var CPt=s(Jne);mIo=t(CPt,"camembert"),CPt.forEach(r),fIo=t(O0e," \u2014 "),I$=n(O0e,"A",{href:!0});var yPt=s(I$);cIo=t(yPt,"TFCamembertForMaskedLM"),yPt.forEach(r),gIo=t(O0e," (CamemBERT model)"),O0e.forEach(r),hIo=i(ee),zb=n(ee,"LI",{});var q0e=s(zb);Kne=n(q0e,"STRONG",{});var wPt=s(Kne);uIo=t(wPt,"convbert"),wPt.forEach(r),pIo=t(q0e," \u2014 "),j$=n(q0e,"A",{href:!0});var APt=s(j$);_Io=t(APt,"TFConvBertForMaskedLM"),APt.forEach(r),vIo=t(q0e," (ConvBERT model)"),q0e.forEach(r),bIo=i(ee),Xb=n(ee,"LI",{});var z0e=s(Xb);Yne=n(z0e,"STRONG",{});var xPt=s(Yne);TIo=t(xPt,"deberta"),xPt.forEach(r),FIo=t(z0e," \u2014 "),N$=n(z0e,"A",{href:!0});var LPt=s(N$);MIo=t(LPt,"TFDebertaForMaskedLM"),LPt.forEach(r),EIo=t(z0e," (DeBERTa model)"),z0e.forEach(r),CIo=i(ee),Wb=n(ee,"LI",{});var X0e=s(Wb);Zne=n(X0e,"STRONG",{});var BPt=s(Zne);yIo=t(BPt,"deberta-v2"),BPt.forEach(r),wIo=t(X0e," \u2014 "),D$=n(X0e,"A",{href:!0});var kPt=s(D$);AIo=t(kPt,"TFDebertaV2ForMaskedLM"),kPt.forEach(r),xIo=t(X0e," (DeBERTa-v2 model)"),X0e.forEach(r),LIo=i(ee),Vb=n(ee,"LI",{});var W0e=s(Vb);ese=n(W0e,"STRONG",{});var RPt=s(ese);BIo=t(RPt,"distilbert"),RPt.forEach(r),kIo=t(W0e," \u2014 "),G$=n(W0e,"A",{href:!0});var SPt=s(G$);RIo=t(SPt,"TFDistilBertForMaskedLM"),SPt.forEach(r),SIo=t(W0e," (DistilBERT model)"),W0e.forEach(r),PIo=i(ee),Qb=n(ee,"LI",{});var V0e=s(Qb);ose=n(V0e,"STRONG",{});var PPt=s(ose);$Io=t(PPt,"electra"),PPt.forEach(r),IIo=t(V0e," \u2014 "),O$=n(V0e,"A",{href:!0});var $Pt=s(O$);jIo=t($Pt,"TFElectraForMaskedLM"),$Pt.forEach(r),NIo=t(V0e," (ELECTRA model)"),V0e.forEach(r),DIo=i(ee),Hb=n(ee,"LI",{});var Q0e=s(Hb);tse=n(Q0e,"STRONG",{});var IPt=s(tse);GIo=t(IPt,"flaubert"),IPt.forEach(r),OIo=t(Q0e," \u2014 "),q$=n(Q0e,"A",{href:!0});var jPt=s(q$);qIo=t(jPt,"TFFlaubertWithLMHeadModel"),jPt.forEach(r),zIo=t(Q0e," (FlauBERT model)"),Q0e.forEach(r),XIo=i(ee),Ub=n(ee,"LI",{});var H0e=s(Ub);rse=n(H0e,"STRONG",{});var NPt=s(rse);WIo=t(NPt,"funnel"),NPt.forEach(r),VIo=t(H0e," \u2014 "),z$=n(H0e,"A",{href:!0});var DPt=s(z$);QIo=t(DPt,"TFFunnelForMaskedLM"),DPt.forEach(r),HIo=t(H0e," (Funnel Transformer model)"),H0e.forEach(r),UIo=i(ee),Jb=n(ee,"LI",{});var U0e=s(Jb);ase=n(U0e,"STRONG",{});var GPt=s(ase);JIo=t(GPt,"layoutlm"),GPt.forEach(r),KIo=t(U0e," \u2014 "),X$=n(U0e,"A",{href:!0});var OPt=s(X$);YIo=t(OPt,"TFLayoutLMForMaskedLM"),OPt.forEach(r),ZIo=t(U0e," (LayoutLM model)"),U0e.forEach(r),ejo=i(ee),Kb=n(ee,"LI",{});var J0e=s(Kb);nse=n(J0e,"STRONG",{});var qPt=s(nse);ojo=t(qPt,"longformer"),qPt.forEach(r),tjo=t(J0e," \u2014 "),W$=n(J0e,"A",{href:!0});var zPt=s(W$);rjo=t(zPt,"TFLongformerForMaskedLM"),zPt.forEach(r),ajo=t(J0e," (Longformer model)"),J0e.forEach(r),njo=i(ee),Yb=n(ee,"LI",{});var K0e=s(Yb);sse=n(K0e,"STRONG",{});var XPt=s(sse);sjo=t(XPt,"mobilebert"),XPt.forEach(r),ljo=t(K0e," \u2014 "),V$=n(K0e,"A",{href:!0});var WPt=s(V$);ijo=t(WPt,"TFMobileBertForMaskedLM"),WPt.forEach(r),djo=t(K0e," (MobileBERT model)"),K0e.forEach(r),mjo=i(ee),Zb=n(ee,"LI",{});var Y0e=s(Zb);lse=n(Y0e,"STRONG",{});var VPt=s(lse);fjo=t(VPt,"mpnet"),VPt.forEach(r),cjo=t(Y0e," \u2014 "),Q$=n(Y0e,"A",{href:!0});var QPt=s(Q$);gjo=t(QPt,"TFMPNetForMaskedLM"),QPt.forEach(r),hjo=t(Y0e," (MPNet model)"),Y0e.forEach(r),ujo=i(ee),e4=n(ee,"LI",{});var Z0e=s(e4);ise=n(Z0e,"STRONG",{});var HPt=s(ise);pjo=t(HPt,"rembert"),HPt.forEach(r),_jo=t(Z0e," \u2014 "),H$=n(Z0e,"A",{href:!0});var UPt=s(H$);vjo=t(UPt,"TFRemBertForMaskedLM"),UPt.forEach(r),bjo=t(Z0e," (RemBERT model)"),Z0e.forEach(r),Tjo=i(ee),o4=n(ee,"LI",{});var eTe=s(o4);dse=n(eTe,"STRONG",{});var JPt=s(dse);Fjo=t(JPt,"roberta"),JPt.forEach(r),Mjo=t(eTe," \u2014 "),U$=n(eTe,"A",{href:!0});var KPt=s(U$);Ejo=t(KPt,"TFRobertaForMaskedLM"),KPt.forEach(r),Cjo=t(eTe," (RoBERTa model)"),eTe.forEach(r),yjo=i(ee),t4=n(ee,"LI",{});var oTe=s(t4);mse=n(oTe,"STRONG",{});var YPt=s(mse);wjo=t(YPt,"roformer"),YPt.forEach(r),Ajo=t(oTe," \u2014 "),J$=n(oTe,"A",{href:!0});var ZPt=s(J$);xjo=t(ZPt,"TFRoFormerForMaskedLM"),ZPt.forEach(r),Ljo=t(oTe," (RoFormer model)"),oTe.forEach(r),Bjo=i(ee),r4=n(ee,"LI",{});var tTe=s(r4);fse=n(tTe,"STRONG",{});var e$t=s(fse);kjo=t(e$t,"tapas"),e$t.forEach(r),Rjo=t(tTe," \u2014 "),K$=n(tTe,"A",{href:!0});var o$t=s(K$);Sjo=t(o$t,"TFTapasForMaskedLM"),o$t.forEach(r),Pjo=t(tTe," (TAPAS model)"),tTe.forEach(r),$jo=i(ee),a4=n(ee,"LI",{});var rTe=s(a4);cse=n(rTe,"STRONG",{});var t$t=s(cse);Ijo=t(t$t,"xlm"),t$t.forEach(r),jjo=t(rTe," \u2014 "),Y$=n(rTe,"A",{href:!0});var r$t=s(Y$);Njo=t(r$t,"TFXLMWithLMHeadModel"),r$t.forEach(r),Djo=t(rTe," (XLM model)"),rTe.forEach(r),Gjo=i(ee),n4=n(ee,"LI",{});var aTe=s(n4);gse=n(aTe,"STRONG",{});var a$t=s(gse);Ojo=t(a$t,"xlm-roberta"),a$t.forEach(r),qjo=t(aTe," \u2014 "),Z$=n(aTe,"A",{href:!0});var n$t=s(Z$);zjo=t(n$t,"TFXLMRobertaForMaskedLM"),n$t.forEach(r),Xjo=t(aTe," (XLM-RoBERTa model)"),aTe.forEach(r),ee.forEach(r),Wjo=i(Yr),hse=n(Yr,"P",{});var s$t=s(hse);Vjo=t(s$t,"Examples:"),s$t.forEach(r),Qjo=i(Yr),c(E3.$$.fragment,Yr),Yr.forEach(r),ll.forEach(r),xCe=i(d),Ld=n(d,"H2",{class:!0});var wye=s(Ld);s4=n(wye,"A",{id:!0,class:!0,href:!0});var l$t=s(s4);use=n(l$t,"SPAN",{});var i$t=s(use);c(C3.$$.fragment,i$t),i$t.forEach(r),l$t.forEach(r),Hjo=i(wye),pse=n(wye,"SPAN",{});var d$t=s(pse);Ujo=t(d$t,"TFAutoModelForSeq2SeqLM"),d$t.forEach(r),wye.forEach(r),LCe=i(d),st=n(d,"DIV",{class:!0});var dl=s(st);c(y3.$$.fragment,dl),Jjo=i(dl),Bd=n(dl,"P",{});var uG=s(Bd);Kjo=t(uG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_se=n(uG,"CODE",{});var m$t=s(_se);Yjo=t(m$t,"from_pretrained()"),m$t.forEach(r),Zjo=t(uG,` class method or the
`),vse=n(uG,"CODE",{});var f$t=s(vse);eNo=t(f$t,"from_config()"),f$t.forEach(r),oNo=t(uG," class method."),uG.forEach(r),tNo=i(dl),w3=n(dl,"P",{});var Aye=s(w3);rNo=t(Aye,"This class cannot be instantiated directly using "),bse=n(Aye,"CODE",{});var c$t=s(bse);aNo=t(c$t,"__init__()"),c$t.forEach(r),nNo=t(Aye," (throws an error)."),Aye.forEach(r),sNo=i(dl),Kt=n(dl,"DIV",{class:!0});var ml=s(Kt);c(A3.$$.fragment,ml),lNo=i(ml),Tse=n(ml,"P",{});var g$t=s(Tse);iNo=t(g$t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),g$t.forEach(r),dNo=i(ml),kd=n(ml,"P",{});var pG=s(kd);mNo=t(pG,`Note:
Loading a model from its configuration file does `),Fse=n(pG,"STRONG",{});var h$t=s(Fse);fNo=t(h$t,"not"),h$t.forEach(r),cNo=t(pG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Mse=n(pG,"EM",{});var u$t=s(Mse);gNo=t(u$t,"~TFAutoModelForSeq2SeqLM.from_pretrained"),u$t.forEach(r),hNo=t(pG,`] to load the model
weights.`),pG.forEach(r),uNo=i(ml),Ese=n(ml,"P",{});var p$t=s(Ese);pNo=t(p$t,"Examples:"),p$t.forEach(r),_No=i(ml),c(x3.$$.fragment,ml),ml.forEach(r),vNo=i(dl),io=n(dl,"DIV",{class:!0});var Zr=s(io);c(L3.$$.fragment,Zr),bNo=i(Zr),Cse=n(Zr,"P",{});var _$t=s(Cse);TNo=t(_$t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),_$t.forEach(r),FNo=i(Zr),Ha=n(Zr,"P",{});var hF=s(Ha);MNo=t(hF,"The model class to instantiate is selected based on the "),yse=n(hF,"EM",{});var v$t=s(yse);ENo=t(v$t,"model_type"),v$t.forEach(r),CNo=t(hF,` property of the config object (either
passed as an argument or loaded from `),wse=n(hF,"EM",{});var b$t=s(wse);yNo=t(b$t,"pretrained_model_name_or_path"),b$t.forEach(r),wNo=t(hF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ase=n(hF,"EM",{});var T$t=s(Ase);ANo=t(T$t,"pretrained_model_name_or_path"),T$t.forEach(r),xNo=t(hF,":"),hF.forEach(r),LNo=i(Zr),ge=n(Zr,"UL",{});var be=s(ge);l4=n(be,"LI",{});var nTe=s(l4);xse=n(nTe,"STRONG",{});var F$t=s(xse);BNo=t(F$t,"bart"),F$t.forEach(r),kNo=t(nTe," \u2014 "),eI=n(nTe,"A",{href:!0});var M$t=s(eI);RNo=t(M$t,"TFBartForConditionalGeneration"),M$t.forEach(r),SNo=t(nTe," (BART model)"),nTe.forEach(r),PNo=i(be),i4=n(be,"LI",{});var sTe=s(i4);Lse=n(sTe,"STRONG",{});var E$t=s(Lse);$No=t(E$t,"blenderbot"),E$t.forEach(r),INo=t(sTe," \u2014 "),oI=n(sTe,"A",{href:!0});var C$t=s(oI);jNo=t(C$t,"TFBlenderbotForConditionalGeneration"),C$t.forEach(r),NNo=t(sTe," (Blenderbot model)"),sTe.forEach(r),DNo=i(be),d4=n(be,"LI",{});var lTe=s(d4);Bse=n(lTe,"STRONG",{});var y$t=s(Bse);GNo=t(y$t,"blenderbot-small"),y$t.forEach(r),ONo=t(lTe," \u2014 "),tI=n(lTe,"A",{href:!0});var w$t=s(tI);qNo=t(w$t,"TFBlenderbotSmallForConditionalGeneration"),w$t.forEach(r),zNo=t(lTe," (BlenderbotSmall model)"),lTe.forEach(r),XNo=i(be),m4=n(be,"LI",{});var iTe=s(m4);kse=n(iTe,"STRONG",{});var A$t=s(kse);WNo=t(A$t,"encoder-decoder"),A$t.forEach(r),VNo=t(iTe," \u2014 "),rI=n(iTe,"A",{href:!0});var x$t=s(rI);QNo=t(x$t,"TFEncoderDecoderModel"),x$t.forEach(r),HNo=t(iTe," (Encoder decoder model)"),iTe.forEach(r),UNo=i(be),f4=n(be,"LI",{});var dTe=s(f4);Rse=n(dTe,"STRONG",{});var L$t=s(Rse);JNo=t(L$t,"led"),L$t.forEach(r),KNo=t(dTe," \u2014 "),aI=n(dTe,"A",{href:!0});var B$t=s(aI);YNo=t(B$t,"TFLEDForConditionalGeneration"),B$t.forEach(r),ZNo=t(dTe," (LED model)"),dTe.forEach(r),eDo=i(be),c4=n(be,"LI",{});var mTe=s(c4);Sse=n(mTe,"STRONG",{});var k$t=s(Sse);oDo=t(k$t,"marian"),k$t.forEach(r),tDo=t(mTe," \u2014 "),nI=n(mTe,"A",{href:!0});var R$t=s(nI);rDo=t(R$t,"TFMarianMTModel"),R$t.forEach(r),aDo=t(mTe," (Marian model)"),mTe.forEach(r),nDo=i(be),g4=n(be,"LI",{});var fTe=s(g4);Pse=n(fTe,"STRONG",{});var S$t=s(Pse);sDo=t(S$t,"mbart"),S$t.forEach(r),lDo=t(fTe," \u2014 "),sI=n(fTe,"A",{href:!0});var P$t=s(sI);iDo=t(P$t,"TFMBartForConditionalGeneration"),P$t.forEach(r),dDo=t(fTe," (mBART model)"),fTe.forEach(r),mDo=i(be),h4=n(be,"LI",{});var cTe=s(h4);$se=n(cTe,"STRONG",{});var $$t=s($se);fDo=t($$t,"mt5"),$$t.forEach(r),cDo=t(cTe," \u2014 "),lI=n(cTe,"A",{href:!0});var I$t=s(lI);gDo=t(I$t,"TFMT5ForConditionalGeneration"),I$t.forEach(r),hDo=t(cTe," (mT5 model)"),cTe.forEach(r),uDo=i(be),u4=n(be,"LI",{});var gTe=s(u4);Ise=n(gTe,"STRONG",{});var j$t=s(Ise);pDo=t(j$t,"pegasus"),j$t.forEach(r),_Do=t(gTe," \u2014 "),iI=n(gTe,"A",{href:!0});var N$t=s(iI);vDo=t(N$t,"TFPegasusForConditionalGeneration"),N$t.forEach(r),bDo=t(gTe," (Pegasus model)"),gTe.forEach(r),TDo=i(be),p4=n(be,"LI",{});var hTe=s(p4);jse=n(hTe,"STRONG",{});var D$t=s(jse);FDo=t(D$t,"t5"),D$t.forEach(r),MDo=t(hTe," \u2014 "),dI=n(hTe,"A",{href:!0});var G$t=s(dI);EDo=t(G$t,"TFT5ForConditionalGeneration"),G$t.forEach(r),CDo=t(hTe," (T5 model)"),hTe.forEach(r),be.forEach(r),yDo=i(Zr),Nse=n(Zr,"P",{});var O$t=s(Nse);wDo=t(O$t,"Examples:"),O$t.forEach(r),ADo=i(Zr),c(B3.$$.fragment,Zr),Zr.forEach(r),dl.forEach(r),BCe=i(d),Rd=n(d,"H2",{class:!0});var xye=s(Rd);_4=n(xye,"A",{id:!0,class:!0,href:!0});var q$t=s(_4);Dse=n(q$t,"SPAN",{});var z$t=s(Dse);c(k3.$$.fragment,z$t),z$t.forEach(r),q$t.forEach(r),xDo=i(xye),Gse=n(xye,"SPAN",{});var X$t=s(Gse);LDo=t(X$t,"TFAutoModelForSequenceClassification"),X$t.forEach(r),xye.forEach(r),kCe=i(d),lt=n(d,"DIV",{class:!0});var fl=s(lt);c(R3.$$.fragment,fl),BDo=i(fl),Sd=n(fl,"P",{});var _G=s(Sd);kDo=t(_G,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Ose=n(_G,"CODE",{});var W$t=s(Ose);RDo=t(W$t,"from_pretrained()"),W$t.forEach(r),SDo=t(_G,` class method or the
`),qse=n(_G,"CODE",{});var V$t=s(qse);PDo=t(V$t,"from_config()"),V$t.forEach(r),$Do=t(_G," class method."),_G.forEach(r),IDo=i(fl),S3=n(fl,"P",{});var Lye=s(S3);jDo=t(Lye,"This class cannot be instantiated directly using "),zse=n(Lye,"CODE",{});var Q$t=s(zse);NDo=t(Q$t,"__init__()"),Q$t.forEach(r),DDo=t(Lye," (throws an error)."),Lye.forEach(r),GDo=i(fl),Yt=n(fl,"DIV",{class:!0});var cl=s(Yt);c(P3.$$.fragment,cl),ODo=i(cl),Xse=n(cl,"P",{});var H$t=s(Xse);qDo=t(H$t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),H$t.forEach(r),zDo=i(cl),Pd=n(cl,"P",{});var vG=s(Pd);XDo=t(vG,`Note:
Loading a model from its configuration file does `),Wse=n(vG,"STRONG",{});var U$t=s(Wse);WDo=t(U$t,"not"),U$t.forEach(r),VDo=t(vG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Vse=n(vG,"EM",{});var J$t=s(Vse);QDo=t(J$t,"~TFAutoModelForSequenceClassification.from_pretrained"),J$t.forEach(r),HDo=t(vG,`] to load the model
weights.`),vG.forEach(r),UDo=i(cl),Qse=n(cl,"P",{});var K$t=s(Qse);JDo=t(K$t,"Examples:"),K$t.forEach(r),KDo=i(cl),c($3.$$.fragment,cl),cl.forEach(r),YDo=i(fl),mo=n(fl,"DIV",{class:!0});var ea=s(mo);c(I3.$$.fragment,ea),ZDo=i(ea),Hse=n(ea,"P",{});var Y$t=s(Hse);eGo=t(Y$t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Y$t.forEach(r),oGo=i(ea),Ua=n(ea,"P",{});var uF=s(Ua);tGo=t(uF,"The model class to instantiate is selected based on the "),Use=n(uF,"EM",{});var Z$t=s(Use);rGo=t(Z$t,"model_type"),Z$t.forEach(r),aGo=t(uF,` property of the config object (either
passed as an argument or loaded from `),Jse=n(uF,"EM",{});var eIt=s(Jse);nGo=t(eIt,"pretrained_model_name_or_path"),eIt.forEach(r),sGo=t(uF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Kse=n(uF,"EM",{});var oIt=s(Kse);lGo=t(oIt,"pretrained_model_name_or_path"),oIt.forEach(r),iGo=t(uF,":"),uF.forEach(r),dGo=i(ea),O=n(ea,"UL",{});var z=s(O);v4=n(z,"LI",{});var uTe=s(v4);Yse=n(uTe,"STRONG",{});var tIt=s(Yse);mGo=t(tIt,"albert"),tIt.forEach(r),fGo=t(uTe," \u2014 "),mI=n(uTe,"A",{href:!0});var rIt=s(mI);cGo=t(rIt,"TFAlbertForSequenceClassification"),rIt.forEach(r),gGo=t(uTe," (ALBERT model)"),uTe.forEach(r),hGo=i(z),b4=n(z,"LI",{});var pTe=s(b4);Zse=n(pTe,"STRONG",{});var aIt=s(Zse);uGo=t(aIt,"bert"),aIt.forEach(r),pGo=t(pTe," \u2014 "),fI=n(pTe,"A",{href:!0});var nIt=s(fI);_Go=t(nIt,"TFBertForSequenceClassification"),nIt.forEach(r),vGo=t(pTe," (BERT model)"),pTe.forEach(r),bGo=i(z),T4=n(z,"LI",{});var _Te=s(T4);ele=n(_Te,"STRONG",{});var sIt=s(ele);TGo=t(sIt,"camembert"),sIt.forEach(r),FGo=t(_Te," \u2014 "),cI=n(_Te,"A",{href:!0});var lIt=s(cI);MGo=t(lIt,"TFCamembertForSequenceClassification"),lIt.forEach(r),EGo=t(_Te," (CamemBERT model)"),_Te.forEach(r),CGo=i(z),F4=n(z,"LI",{});var vTe=s(F4);ole=n(vTe,"STRONG",{});var iIt=s(ole);yGo=t(iIt,"convbert"),iIt.forEach(r),wGo=t(vTe," \u2014 "),gI=n(vTe,"A",{href:!0});var dIt=s(gI);AGo=t(dIt,"TFConvBertForSequenceClassification"),dIt.forEach(r),xGo=t(vTe," (ConvBERT model)"),vTe.forEach(r),LGo=i(z),M4=n(z,"LI",{});var bTe=s(M4);tle=n(bTe,"STRONG",{});var mIt=s(tle);BGo=t(mIt,"ctrl"),mIt.forEach(r),kGo=t(bTe," \u2014 "),hI=n(bTe,"A",{href:!0});var fIt=s(hI);RGo=t(fIt,"TFCTRLForSequenceClassification"),fIt.forEach(r),SGo=t(bTe," (CTRL model)"),bTe.forEach(r),PGo=i(z),E4=n(z,"LI",{});var TTe=s(E4);rle=n(TTe,"STRONG",{});var cIt=s(rle);$Go=t(cIt,"deberta"),cIt.forEach(r),IGo=t(TTe," \u2014 "),uI=n(TTe,"A",{href:!0});var gIt=s(uI);jGo=t(gIt,"TFDebertaForSequenceClassification"),gIt.forEach(r),NGo=t(TTe," (DeBERTa model)"),TTe.forEach(r),DGo=i(z),C4=n(z,"LI",{});var FTe=s(C4);ale=n(FTe,"STRONG",{});var hIt=s(ale);GGo=t(hIt,"deberta-v2"),hIt.forEach(r),OGo=t(FTe," \u2014 "),pI=n(FTe,"A",{href:!0});var uIt=s(pI);qGo=t(uIt,"TFDebertaV2ForSequenceClassification"),uIt.forEach(r),zGo=t(FTe," (DeBERTa-v2 model)"),FTe.forEach(r),XGo=i(z),y4=n(z,"LI",{});var MTe=s(y4);nle=n(MTe,"STRONG",{});var pIt=s(nle);WGo=t(pIt,"distilbert"),pIt.forEach(r),VGo=t(MTe," \u2014 "),_I=n(MTe,"A",{href:!0});var _It=s(_I);QGo=t(_It,"TFDistilBertForSequenceClassification"),_It.forEach(r),HGo=t(MTe," (DistilBERT model)"),MTe.forEach(r),UGo=i(z),w4=n(z,"LI",{});var ETe=s(w4);sle=n(ETe,"STRONG",{});var vIt=s(sle);JGo=t(vIt,"electra"),vIt.forEach(r),KGo=t(ETe," \u2014 "),vI=n(ETe,"A",{href:!0});var bIt=s(vI);YGo=t(bIt,"TFElectraForSequenceClassification"),bIt.forEach(r),ZGo=t(ETe," (ELECTRA model)"),ETe.forEach(r),eOo=i(z),A4=n(z,"LI",{});var CTe=s(A4);lle=n(CTe,"STRONG",{});var TIt=s(lle);oOo=t(TIt,"flaubert"),TIt.forEach(r),tOo=t(CTe," \u2014 "),bI=n(CTe,"A",{href:!0});var FIt=s(bI);rOo=t(FIt,"TFFlaubertForSequenceClassification"),FIt.forEach(r),aOo=t(CTe," (FlauBERT model)"),CTe.forEach(r),nOo=i(z),x4=n(z,"LI",{});var yTe=s(x4);ile=n(yTe,"STRONG",{});var MIt=s(ile);sOo=t(MIt,"funnel"),MIt.forEach(r),lOo=t(yTe," \u2014 "),TI=n(yTe,"A",{href:!0});var EIt=s(TI);iOo=t(EIt,"TFFunnelForSequenceClassification"),EIt.forEach(r),dOo=t(yTe," (Funnel Transformer model)"),yTe.forEach(r),mOo=i(z),L4=n(z,"LI",{});var wTe=s(L4);dle=n(wTe,"STRONG",{});var CIt=s(dle);fOo=t(CIt,"gpt2"),CIt.forEach(r),cOo=t(wTe," \u2014 "),FI=n(wTe,"A",{href:!0});var yIt=s(FI);gOo=t(yIt,"TFGPT2ForSequenceClassification"),yIt.forEach(r),hOo=t(wTe," (OpenAI GPT-2 model)"),wTe.forEach(r),uOo=i(z),B4=n(z,"LI",{});var ATe=s(B4);mle=n(ATe,"STRONG",{});var wIt=s(mle);pOo=t(wIt,"layoutlm"),wIt.forEach(r),_Oo=t(ATe," \u2014 "),MI=n(ATe,"A",{href:!0});var AIt=s(MI);vOo=t(AIt,"TFLayoutLMForSequenceClassification"),AIt.forEach(r),bOo=t(ATe," (LayoutLM model)"),ATe.forEach(r),TOo=i(z),k4=n(z,"LI",{});var xTe=s(k4);fle=n(xTe,"STRONG",{});var xIt=s(fle);FOo=t(xIt,"longformer"),xIt.forEach(r),MOo=t(xTe," \u2014 "),EI=n(xTe,"A",{href:!0});var LIt=s(EI);EOo=t(LIt,"TFLongformerForSequenceClassification"),LIt.forEach(r),COo=t(xTe," (Longformer model)"),xTe.forEach(r),yOo=i(z),R4=n(z,"LI",{});var LTe=s(R4);cle=n(LTe,"STRONG",{});var BIt=s(cle);wOo=t(BIt,"mobilebert"),BIt.forEach(r),AOo=t(LTe," \u2014 "),CI=n(LTe,"A",{href:!0});var kIt=s(CI);xOo=t(kIt,"TFMobileBertForSequenceClassification"),kIt.forEach(r),LOo=t(LTe," (MobileBERT model)"),LTe.forEach(r),BOo=i(z),S4=n(z,"LI",{});var BTe=s(S4);gle=n(BTe,"STRONG",{});var RIt=s(gle);kOo=t(RIt,"mpnet"),RIt.forEach(r),ROo=t(BTe," \u2014 "),yI=n(BTe,"A",{href:!0});var SIt=s(yI);SOo=t(SIt,"TFMPNetForSequenceClassification"),SIt.forEach(r),POo=t(BTe," (MPNet model)"),BTe.forEach(r),$Oo=i(z),P4=n(z,"LI",{});var kTe=s(P4);hle=n(kTe,"STRONG",{});var PIt=s(hle);IOo=t(PIt,"openai-gpt"),PIt.forEach(r),jOo=t(kTe," \u2014 "),wI=n(kTe,"A",{href:!0});var $It=s(wI);NOo=t($It,"TFOpenAIGPTForSequenceClassification"),$It.forEach(r),DOo=t(kTe," (OpenAI GPT model)"),kTe.forEach(r),GOo=i(z),$4=n(z,"LI",{});var RTe=s($4);ule=n(RTe,"STRONG",{});var IIt=s(ule);OOo=t(IIt,"rembert"),IIt.forEach(r),qOo=t(RTe," \u2014 "),AI=n(RTe,"A",{href:!0});var jIt=s(AI);zOo=t(jIt,"TFRemBertForSequenceClassification"),jIt.forEach(r),XOo=t(RTe," (RemBERT model)"),RTe.forEach(r),WOo=i(z),I4=n(z,"LI",{});var STe=s(I4);ple=n(STe,"STRONG",{});var NIt=s(ple);VOo=t(NIt,"roberta"),NIt.forEach(r),QOo=t(STe," \u2014 "),xI=n(STe,"A",{href:!0});var DIt=s(xI);HOo=t(DIt,"TFRobertaForSequenceClassification"),DIt.forEach(r),UOo=t(STe," (RoBERTa model)"),STe.forEach(r),JOo=i(z),j4=n(z,"LI",{});var PTe=s(j4);_le=n(PTe,"STRONG",{});var GIt=s(_le);KOo=t(GIt,"roformer"),GIt.forEach(r),YOo=t(PTe," \u2014 "),LI=n(PTe,"A",{href:!0});var OIt=s(LI);ZOo=t(OIt,"TFRoFormerForSequenceClassification"),OIt.forEach(r),eqo=t(PTe," (RoFormer model)"),PTe.forEach(r),oqo=i(z),N4=n(z,"LI",{});var $Te=s(N4);vle=n($Te,"STRONG",{});var qIt=s(vle);tqo=t(qIt,"tapas"),qIt.forEach(r),rqo=t($Te," \u2014 "),BI=n($Te,"A",{href:!0});var zIt=s(BI);aqo=t(zIt,"TFTapasForSequenceClassification"),zIt.forEach(r),nqo=t($Te," (TAPAS model)"),$Te.forEach(r),sqo=i(z),D4=n(z,"LI",{});var ITe=s(D4);ble=n(ITe,"STRONG",{});var XIt=s(ble);lqo=t(XIt,"transfo-xl"),XIt.forEach(r),iqo=t(ITe," \u2014 "),kI=n(ITe,"A",{href:!0});var WIt=s(kI);dqo=t(WIt,"TFTransfoXLForSequenceClassification"),WIt.forEach(r),mqo=t(ITe," (Transformer-XL model)"),ITe.forEach(r),fqo=i(z),G4=n(z,"LI",{});var jTe=s(G4);Tle=n(jTe,"STRONG",{});var VIt=s(Tle);cqo=t(VIt,"xlm"),VIt.forEach(r),gqo=t(jTe," \u2014 "),RI=n(jTe,"A",{href:!0});var QIt=s(RI);hqo=t(QIt,"TFXLMForSequenceClassification"),QIt.forEach(r),uqo=t(jTe," (XLM model)"),jTe.forEach(r),pqo=i(z),O4=n(z,"LI",{});var NTe=s(O4);Fle=n(NTe,"STRONG",{});var HIt=s(Fle);_qo=t(HIt,"xlm-roberta"),HIt.forEach(r),vqo=t(NTe," \u2014 "),SI=n(NTe,"A",{href:!0});var UIt=s(SI);bqo=t(UIt,"TFXLMRobertaForSequenceClassification"),UIt.forEach(r),Tqo=t(NTe," (XLM-RoBERTa model)"),NTe.forEach(r),Fqo=i(z),q4=n(z,"LI",{});var DTe=s(q4);Mle=n(DTe,"STRONG",{});var JIt=s(Mle);Mqo=t(JIt,"xlnet"),JIt.forEach(r),Eqo=t(DTe," \u2014 "),PI=n(DTe,"A",{href:!0});var KIt=s(PI);Cqo=t(KIt,"TFXLNetForSequenceClassification"),KIt.forEach(r),yqo=t(DTe," (XLNet model)"),DTe.forEach(r),z.forEach(r),wqo=i(ea),Ele=n(ea,"P",{});var YIt=s(Ele);Aqo=t(YIt,"Examples:"),YIt.forEach(r),xqo=i(ea),c(j3.$$.fragment,ea),ea.forEach(r),fl.forEach(r),RCe=i(d),$d=n(d,"H2",{class:!0});var Bye=s($d);z4=n(Bye,"A",{id:!0,class:!0,href:!0});var ZIt=s(z4);Cle=n(ZIt,"SPAN",{});var ejt=s(Cle);c(N3.$$.fragment,ejt),ejt.forEach(r),ZIt.forEach(r),Lqo=i(Bye),yle=n(Bye,"SPAN",{});var ojt=s(yle);Bqo=t(ojt,"TFAutoModelForMultipleChoice"),ojt.forEach(r),Bye.forEach(r),SCe=i(d),it=n(d,"DIV",{class:!0});var gl=s(it);c(D3.$$.fragment,gl),kqo=i(gl),Id=n(gl,"P",{});var bG=s(Id);Rqo=t(bG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),wle=n(bG,"CODE",{});var tjt=s(wle);Sqo=t(tjt,"from_pretrained()"),tjt.forEach(r),Pqo=t(bG,` class method or the
`),Ale=n(bG,"CODE",{});var rjt=s(Ale);$qo=t(rjt,"from_config()"),rjt.forEach(r),Iqo=t(bG," class method."),bG.forEach(r),jqo=i(gl),G3=n(gl,"P",{});var kye=s(G3);Nqo=t(kye,"This class cannot be instantiated directly using "),xle=n(kye,"CODE",{});var ajt=s(xle);Dqo=t(ajt,"__init__()"),ajt.forEach(r),Gqo=t(kye," (throws an error)."),kye.forEach(r),Oqo=i(gl),Zt=n(gl,"DIV",{class:!0});var hl=s(Zt);c(O3.$$.fragment,hl),qqo=i(hl),Lle=n(hl,"P",{});var njt=s(Lle);zqo=t(njt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),njt.forEach(r),Xqo=i(hl),jd=n(hl,"P",{});var TG=s(jd);Wqo=t(TG,`Note:
Loading a model from its configuration file does `),Ble=n(TG,"STRONG",{});var sjt=s(Ble);Vqo=t(sjt,"not"),sjt.forEach(r),Qqo=t(TG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),kle=n(TG,"EM",{});var ljt=s(kle);Hqo=t(ljt,"~TFAutoModelForMultipleChoice.from_pretrained"),ljt.forEach(r),Uqo=t(TG,`] to load the model
weights.`),TG.forEach(r),Jqo=i(hl),Rle=n(hl,"P",{});var ijt=s(Rle);Kqo=t(ijt,"Examples:"),ijt.forEach(r),Yqo=i(hl),c(q3.$$.fragment,hl),hl.forEach(r),Zqo=i(gl),fo=n(gl,"DIV",{class:!0});var oa=s(fo);c(z3.$$.fragment,oa),ezo=i(oa),Sle=n(oa,"P",{});var djt=s(Sle);ozo=t(djt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),djt.forEach(r),tzo=i(oa),Ja=n(oa,"P",{});var pF=s(Ja);rzo=t(pF,"The model class to instantiate is selected based on the "),Ple=n(pF,"EM",{});var mjt=s(Ple);azo=t(mjt,"model_type"),mjt.forEach(r),nzo=t(pF,` property of the config object (either
passed as an argument or loaded from `),$le=n(pF,"EM",{});var fjt=s($le);szo=t(fjt,"pretrained_model_name_or_path"),fjt.forEach(r),lzo=t(pF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ile=n(pF,"EM",{});var cjt=s(Ile);izo=t(cjt,"pretrained_model_name_or_path"),cjt.forEach(r),dzo=t(pF,":"),pF.forEach(r),mzo=i(oa),re=n(oa,"UL",{});var ae=s(re);X4=n(ae,"LI",{});var GTe=s(X4);jle=n(GTe,"STRONG",{});var gjt=s(jle);fzo=t(gjt,"albert"),gjt.forEach(r),czo=t(GTe," \u2014 "),$I=n(GTe,"A",{href:!0});var hjt=s($I);gzo=t(hjt,"TFAlbertForMultipleChoice"),hjt.forEach(r),hzo=t(GTe," (ALBERT model)"),GTe.forEach(r),uzo=i(ae),W4=n(ae,"LI",{});var OTe=s(W4);Nle=n(OTe,"STRONG",{});var ujt=s(Nle);pzo=t(ujt,"bert"),ujt.forEach(r),_zo=t(OTe," \u2014 "),II=n(OTe,"A",{href:!0});var pjt=s(II);vzo=t(pjt,"TFBertForMultipleChoice"),pjt.forEach(r),bzo=t(OTe," (BERT model)"),OTe.forEach(r),Tzo=i(ae),V4=n(ae,"LI",{});var qTe=s(V4);Dle=n(qTe,"STRONG",{});var _jt=s(Dle);Fzo=t(_jt,"camembert"),_jt.forEach(r),Mzo=t(qTe," \u2014 "),jI=n(qTe,"A",{href:!0});var vjt=s(jI);Ezo=t(vjt,"TFCamembertForMultipleChoice"),vjt.forEach(r),Czo=t(qTe," (CamemBERT model)"),qTe.forEach(r),yzo=i(ae),Q4=n(ae,"LI",{});var zTe=s(Q4);Gle=n(zTe,"STRONG",{});var bjt=s(Gle);wzo=t(bjt,"convbert"),bjt.forEach(r),Azo=t(zTe," \u2014 "),NI=n(zTe,"A",{href:!0});var Tjt=s(NI);xzo=t(Tjt,"TFConvBertForMultipleChoice"),Tjt.forEach(r),Lzo=t(zTe," (ConvBERT model)"),zTe.forEach(r),Bzo=i(ae),H4=n(ae,"LI",{});var XTe=s(H4);Ole=n(XTe,"STRONG",{});var Fjt=s(Ole);kzo=t(Fjt,"distilbert"),Fjt.forEach(r),Rzo=t(XTe," \u2014 "),DI=n(XTe,"A",{href:!0});var Mjt=s(DI);Szo=t(Mjt,"TFDistilBertForMultipleChoice"),Mjt.forEach(r),Pzo=t(XTe," (DistilBERT model)"),XTe.forEach(r),$zo=i(ae),U4=n(ae,"LI",{});var WTe=s(U4);qle=n(WTe,"STRONG",{});var Ejt=s(qle);Izo=t(Ejt,"electra"),Ejt.forEach(r),jzo=t(WTe," \u2014 "),GI=n(WTe,"A",{href:!0});var Cjt=s(GI);Nzo=t(Cjt,"TFElectraForMultipleChoice"),Cjt.forEach(r),Dzo=t(WTe," (ELECTRA model)"),WTe.forEach(r),Gzo=i(ae),J4=n(ae,"LI",{});var VTe=s(J4);zle=n(VTe,"STRONG",{});var yjt=s(zle);Ozo=t(yjt,"flaubert"),yjt.forEach(r),qzo=t(VTe," \u2014 "),OI=n(VTe,"A",{href:!0});var wjt=s(OI);zzo=t(wjt,"TFFlaubertForMultipleChoice"),wjt.forEach(r),Xzo=t(VTe," (FlauBERT model)"),VTe.forEach(r),Wzo=i(ae),K4=n(ae,"LI",{});var QTe=s(K4);Xle=n(QTe,"STRONG",{});var Ajt=s(Xle);Vzo=t(Ajt,"funnel"),Ajt.forEach(r),Qzo=t(QTe," \u2014 "),qI=n(QTe,"A",{href:!0});var xjt=s(qI);Hzo=t(xjt,"TFFunnelForMultipleChoice"),xjt.forEach(r),Uzo=t(QTe," (Funnel Transformer model)"),QTe.forEach(r),Jzo=i(ae),Y4=n(ae,"LI",{});var HTe=s(Y4);Wle=n(HTe,"STRONG",{});var Ljt=s(Wle);Kzo=t(Ljt,"longformer"),Ljt.forEach(r),Yzo=t(HTe," \u2014 "),zI=n(HTe,"A",{href:!0});var Bjt=s(zI);Zzo=t(Bjt,"TFLongformerForMultipleChoice"),Bjt.forEach(r),eXo=t(HTe," (Longformer model)"),HTe.forEach(r),oXo=i(ae),Z4=n(ae,"LI",{});var UTe=s(Z4);Vle=n(UTe,"STRONG",{});var kjt=s(Vle);tXo=t(kjt,"mobilebert"),kjt.forEach(r),rXo=t(UTe," \u2014 "),XI=n(UTe,"A",{href:!0});var Rjt=s(XI);aXo=t(Rjt,"TFMobileBertForMultipleChoice"),Rjt.forEach(r),nXo=t(UTe," (MobileBERT model)"),UTe.forEach(r),sXo=i(ae),e5=n(ae,"LI",{});var JTe=s(e5);Qle=n(JTe,"STRONG",{});var Sjt=s(Qle);lXo=t(Sjt,"mpnet"),Sjt.forEach(r),iXo=t(JTe," \u2014 "),WI=n(JTe,"A",{href:!0});var Pjt=s(WI);dXo=t(Pjt,"TFMPNetForMultipleChoice"),Pjt.forEach(r),mXo=t(JTe," (MPNet model)"),JTe.forEach(r),fXo=i(ae),o5=n(ae,"LI",{});var KTe=s(o5);Hle=n(KTe,"STRONG",{});var $jt=s(Hle);cXo=t($jt,"rembert"),$jt.forEach(r),gXo=t(KTe," \u2014 "),VI=n(KTe,"A",{href:!0});var Ijt=s(VI);hXo=t(Ijt,"TFRemBertForMultipleChoice"),Ijt.forEach(r),uXo=t(KTe," (RemBERT model)"),KTe.forEach(r),pXo=i(ae),t5=n(ae,"LI",{});var YTe=s(t5);Ule=n(YTe,"STRONG",{});var jjt=s(Ule);_Xo=t(jjt,"roberta"),jjt.forEach(r),vXo=t(YTe," \u2014 "),QI=n(YTe,"A",{href:!0});var Njt=s(QI);bXo=t(Njt,"TFRobertaForMultipleChoice"),Njt.forEach(r),TXo=t(YTe," (RoBERTa model)"),YTe.forEach(r),FXo=i(ae),r5=n(ae,"LI",{});var ZTe=s(r5);Jle=n(ZTe,"STRONG",{});var Djt=s(Jle);MXo=t(Djt,"roformer"),Djt.forEach(r),EXo=t(ZTe," \u2014 "),HI=n(ZTe,"A",{href:!0});var Gjt=s(HI);CXo=t(Gjt,"TFRoFormerForMultipleChoice"),Gjt.forEach(r),yXo=t(ZTe," (RoFormer model)"),ZTe.forEach(r),wXo=i(ae),a5=n(ae,"LI",{});var eFe=s(a5);Kle=n(eFe,"STRONG",{});var Ojt=s(Kle);AXo=t(Ojt,"xlm"),Ojt.forEach(r),xXo=t(eFe," \u2014 "),UI=n(eFe,"A",{href:!0});var qjt=s(UI);LXo=t(qjt,"TFXLMForMultipleChoice"),qjt.forEach(r),BXo=t(eFe," (XLM model)"),eFe.forEach(r),kXo=i(ae),n5=n(ae,"LI",{});var oFe=s(n5);Yle=n(oFe,"STRONG",{});var zjt=s(Yle);RXo=t(zjt,"xlm-roberta"),zjt.forEach(r),SXo=t(oFe," \u2014 "),JI=n(oFe,"A",{href:!0});var Xjt=s(JI);PXo=t(Xjt,"TFXLMRobertaForMultipleChoice"),Xjt.forEach(r),$Xo=t(oFe," (XLM-RoBERTa model)"),oFe.forEach(r),IXo=i(ae),s5=n(ae,"LI",{});var tFe=s(s5);Zle=n(tFe,"STRONG",{});var Wjt=s(Zle);jXo=t(Wjt,"xlnet"),Wjt.forEach(r),NXo=t(tFe," \u2014 "),KI=n(tFe,"A",{href:!0});var Vjt=s(KI);DXo=t(Vjt,"TFXLNetForMultipleChoice"),Vjt.forEach(r),GXo=t(tFe," (XLNet model)"),tFe.forEach(r),ae.forEach(r),OXo=i(oa),eie=n(oa,"P",{});var Qjt=s(eie);qXo=t(Qjt,"Examples:"),Qjt.forEach(r),zXo=i(oa),c(X3.$$.fragment,oa),oa.forEach(r),gl.forEach(r),PCe=i(d),Nd=n(d,"H2",{class:!0});var Rye=s(Nd);l5=n(Rye,"A",{id:!0,class:!0,href:!0});var Hjt=s(l5);oie=n(Hjt,"SPAN",{});var Ujt=s(oie);c(W3.$$.fragment,Ujt),Ujt.forEach(r),Hjt.forEach(r),XXo=i(Rye),tie=n(Rye,"SPAN",{});var Jjt=s(tie);WXo=t(Jjt,"TFAutoModelForTableQuestionAnswering"),Jjt.forEach(r),Rye.forEach(r),$Ce=i(d),dt=n(d,"DIV",{class:!0});var ul=s(dt);c(V3.$$.fragment,ul),VXo=i(ul),Dd=n(ul,"P",{});var FG=s(Dd);QXo=t(FG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),rie=n(FG,"CODE",{});var Kjt=s(rie);HXo=t(Kjt,"from_pretrained()"),Kjt.forEach(r),UXo=t(FG,` class method or the
`),aie=n(FG,"CODE",{});var Yjt=s(aie);JXo=t(Yjt,"from_config()"),Yjt.forEach(r),KXo=t(FG," class method."),FG.forEach(r),YXo=i(ul),Q3=n(ul,"P",{});var Sye=s(Q3);ZXo=t(Sye,"This class cannot be instantiated directly using "),nie=n(Sye,"CODE",{});var Zjt=s(nie);eWo=t(Zjt,"__init__()"),Zjt.forEach(r),oWo=t(Sye," (throws an error)."),Sye.forEach(r),tWo=i(ul),er=n(ul,"DIV",{class:!0});var pl=s(er);c(H3.$$.fragment,pl),rWo=i(pl),sie=n(pl,"P",{});var eNt=s(sie);aWo=t(eNt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),eNt.forEach(r),nWo=i(pl),Gd=n(pl,"P",{});var MG=s(Gd);sWo=t(MG,`Note:
Loading a model from its configuration file does `),lie=n(MG,"STRONG",{});var oNt=s(lie);lWo=t(oNt,"not"),oNt.forEach(r),iWo=t(MG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),iie=n(MG,"EM",{});var tNt=s(iie);dWo=t(tNt,"~TFAutoModelForTableQuestionAnswering.from_pretrained"),tNt.forEach(r),mWo=t(MG,`] to load the model
weights.`),MG.forEach(r),fWo=i(pl),die=n(pl,"P",{});var rNt=s(die);cWo=t(rNt,"Examples:"),rNt.forEach(r),gWo=i(pl),c(U3.$$.fragment,pl),pl.forEach(r),hWo=i(ul),co=n(ul,"DIV",{class:!0});var ta=s(co);c(J3.$$.fragment,ta),uWo=i(ta),mie=n(ta,"P",{});var aNt=s(mie);pWo=t(aNt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),aNt.forEach(r),_Wo=i(ta),Ka=n(ta,"P",{});var _F=s(Ka);vWo=t(_F,"The model class to instantiate is selected based on the "),fie=n(_F,"EM",{});var nNt=s(fie);bWo=t(nNt,"model_type"),nNt.forEach(r),TWo=t(_F,` property of the config object (either
passed as an argument or loaded from `),cie=n(_F,"EM",{});var sNt=s(cie);FWo=t(sNt,"pretrained_model_name_or_path"),sNt.forEach(r),MWo=t(_F,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),gie=n(_F,"EM",{});var lNt=s(gie);EWo=t(lNt,"pretrained_model_name_or_path"),lNt.forEach(r),CWo=t(_F,":"),_F.forEach(r),yWo=i(ta),hie=n(ta,"UL",{});var iNt=s(hie);i5=n(iNt,"LI",{});var rFe=s(i5);uie=n(rFe,"STRONG",{});var dNt=s(uie);wWo=t(dNt,"tapas"),dNt.forEach(r),AWo=t(rFe," \u2014 "),YI=n(rFe,"A",{href:!0});var mNt=s(YI);xWo=t(mNt,"TFTapasForQuestionAnswering"),mNt.forEach(r),LWo=t(rFe," (TAPAS model)"),rFe.forEach(r),iNt.forEach(r),BWo=i(ta),pie=n(ta,"P",{});var fNt=s(pie);kWo=t(fNt,"Examples:"),fNt.forEach(r),RWo=i(ta),c(K3.$$.fragment,ta),ta.forEach(r),ul.forEach(r),ICe=i(d),Od=n(d,"H2",{class:!0});var Pye=s(Od);d5=n(Pye,"A",{id:!0,class:!0,href:!0});var cNt=s(d5);_ie=n(cNt,"SPAN",{});var gNt=s(_ie);c(Y3.$$.fragment,gNt),gNt.forEach(r),cNt.forEach(r),SWo=i(Pye),vie=n(Pye,"SPAN",{});var hNt=s(vie);PWo=t(hNt,"TFAutoModelForTokenClassification"),hNt.forEach(r),Pye.forEach(r),jCe=i(d),mt=n(d,"DIV",{class:!0});var _l=s(mt);c(Z3.$$.fragment,_l),$Wo=i(_l),qd=n(_l,"P",{});var EG=s(qd);IWo=t(EG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bie=n(EG,"CODE",{});var uNt=s(bie);jWo=t(uNt,"from_pretrained()"),uNt.forEach(r),NWo=t(EG,` class method or the
`),Tie=n(EG,"CODE",{});var pNt=s(Tie);DWo=t(pNt,"from_config()"),pNt.forEach(r),GWo=t(EG," class method."),EG.forEach(r),OWo=i(_l),ey=n(_l,"P",{});var $ye=s(ey);qWo=t($ye,"This class cannot be instantiated directly using "),Fie=n($ye,"CODE",{});var _Nt=s(Fie);zWo=t(_Nt,"__init__()"),_Nt.forEach(r),XWo=t($ye," (throws an error)."),$ye.forEach(r),WWo=i(_l),or=n(_l,"DIV",{class:!0});var vl=s(or);c(oy.$$.fragment,vl),VWo=i(vl),Mie=n(vl,"P",{});var vNt=s(Mie);QWo=t(vNt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),vNt.forEach(r),HWo=i(vl),zd=n(vl,"P",{});var CG=s(zd);UWo=t(CG,`Note:
Loading a model from its configuration file does `),Eie=n(CG,"STRONG",{});var bNt=s(Eie);JWo=t(bNt,"not"),bNt.forEach(r),KWo=t(CG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Cie=n(CG,"EM",{});var TNt=s(Cie);YWo=t(TNt,"~TFAutoModelForTokenClassification.from_pretrained"),TNt.forEach(r),ZWo=t(CG,`] to load the model
weights.`),CG.forEach(r),eVo=i(vl),yie=n(vl,"P",{});var FNt=s(yie);oVo=t(FNt,"Examples:"),FNt.forEach(r),tVo=i(vl),c(ty.$$.fragment,vl),vl.forEach(r),rVo=i(_l),go=n(_l,"DIV",{class:!0});var ra=s(go);c(ry.$$.fragment,ra),aVo=i(ra),wie=n(ra,"P",{});var MNt=s(wie);nVo=t(MNt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),MNt.forEach(r),sVo=i(ra),Ya=n(ra,"P",{});var vF=s(Ya);lVo=t(vF,"The model class to instantiate is selected based on the "),Aie=n(vF,"EM",{});var ENt=s(Aie);iVo=t(ENt,"model_type"),ENt.forEach(r),dVo=t(vF,` property of the config object (either
passed as an argument or loaded from `),xie=n(vF,"EM",{});var CNt=s(xie);mVo=t(CNt,"pretrained_model_name_or_path"),CNt.forEach(r),fVo=t(vF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Lie=n(vF,"EM",{});var yNt=s(Lie);cVo=t(yNt,"pretrained_model_name_or_path"),yNt.forEach(r),gVo=t(vF,":"),vF.forEach(r),hVo=i(ra),Y=n(ra,"UL",{});var oe=s(Y);m5=n(oe,"LI",{});var aFe=s(m5);Bie=n(aFe,"STRONG",{});var wNt=s(Bie);uVo=t(wNt,"albert"),wNt.forEach(r),pVo=t(aFe," \u2014 "),ZI=n(aFe,"A",{href:!0});var ANt=s(ZI);_Vo=t(ANt,"TFAlbertForTokenClassification"),ANt.forEach(r),vVo=t(aFe," (ALBERT model)"),aFe.forEach(r),bVo=i(oe),f5=n(oe,"LI",{});var nFe=s(f5);kie=n(nFe,"STRONG",{});var xNt=s(kie);TVo=t(xNt,"bert"),xNt.forEach(r),FVo=t(nFe," \u2014 "),ej=n(nFe,"A",{href:!0});var LNt=s(ej);MVo=t(LNt,"TFBertForTokenClassification"),LNt.forEach(r),EVo=t(nFe," (BERT model)"),nFe.forEach(r),CVo=i(oe),c5=n(oe,"LI",{});var sFe=s(c5);Rie=n(sFe,"STRONG",{});var BNt=s(Rie);yVo=t(BNt,"camembert"),BNt.forEach(r),wVo=t(sFe," \u2014 "),oj=n(sFe,"A",{href:!0});var kNt=s(oj);AVo=t(kNt,"TFCamembertForTokenClassification"),kNt.forEach(r),xVo=t(sFe," (CamemBERT model)"),sFe.forEach(r),LVo=i(oe),g5=n(oe,"LI",{});var lFe=s(g5);Sie=n(lFe,"STRONG",{});var RNt=s(Sie);BVo=t(RNt,"convbert"),RNt.forEach(r),kVo=t(lFe," \u2014 "),tj=n(lFe,"A",{href:!0});var SNt=s(tj);RVo=t(SNt,"TFConvBertForTokenClassification"),SNt.forEach(r),SVo=t(lFe," (ConvBERT model)"),lFe.forEach(r),PVo=i(oe),h5=n(oe,"LI",{});var iFe=s(h5);Pie=n(iFe,"STRONG",{});var PNt=s(Pie);$Vo=t(PNt,"deberta"),PNt.forEach(r),IVo=t(iFe," \u2014 "),rj=n(iFe,"A",{href:!0});var $Nt=s(rj);jVo=t($Nt,"TFDebertaForTokenClassification"),$Nt.forEach(r),NVo=t(iFe," (DeBERTa model)"),iFe.forEach(r),DVo=i(oe),u5=n(oe,"LI",{});var dFe=s(u5);$ie=n(dFe,"STRONG",{});var INt=s($ie);GVo=t(INt,"deberta-v2"),INt.forEach(r),OVo=t(dFe," \u2014 "),aj=n(dFe,"A",{href:!0});var jNt=s(aj);qVo=t(jNt,"TFDebertaV2ForTokenClassification"),jNt.forEach(r),zVo=t(dFe," (DeBERTa-v2 model)"),dFe.forEach(r),XVo=i(oe),p5=n(oe,"LI",{});var mFe=s(p5);Iie=n(mFe,"STRONG",{});var NNt=s(Iie);WVo=t(NNt,"distilbert"),NNt.forEach(r),VVo=t(mFe," \u2014 "),nj=n(mFe,"A",{href:!0});var DNt=s(nj);QVo=t(DNt,"TFDistilBertForTokenClassification"),DNt.forEach(r),HVo=t(mFe," (DistilBERT model)"),mFe.forEach(r),UVo=i(oe),_5=n(oe,"LI",{});var fFe=s(_5);jie=n(fFe,"STRONG",{});var GNt=s(jie);JVo=t(GNt,"electra"),GNt.forEach(r),KVo=t(fFe," \u2014 "),sj=n(fFe,"A",{href:!0});var ONt=s(sj);YVo=t(ONt,"TFElectraForTokenClassification"),ONt.forEach(r),ZVo=t(fFe," (ELECTRA model)"),fFe.forEach(r),eQo=i(oe),v5=n(oe,"LI",{});var cFe=s(v5);Nie=n(cFe,"STRONG",{});var qNt=s(Nie);oQo=t(qNt,"flaubert"),qNt.forEach(r),tQo=t(cFe," \u2014 "),lj=n(cFe,"A",{href:!0});var zNt=s(lj);rQo=t(zNt,"TFFlaubertForTokenClassification"),zNt.forEach(r),aQo=t(cFe," (FlauBERT model)"),cFe.forEach(r),nQo=i(oe),b5=n(oe,"LI",{});var gFe=s(b5);Die=n(gFe,"STRONG",{});var XNt=s(Die);sQo=t(XNt,"funnel"),XNt.forEach(r),lQo=t(gFe," \u2014 "),ij=n(gFe,"A",{href:!0});var WNt=s(ij);iQo=t(WNt,"TFFunnelForTokenClassification"),WNt.forEach(r),dQo=t(gFe," (Funnel Transformer model)"),gFe.forEach(r),mQo=i(oe),T5=n(oe,"LI",{});var hFe=s(T5);Gie=n(hFe,"STRONG",{});var VNt=s(Gie);fQo=t(VNt,"layoutlm"),VNt.forEach(r),cQo=t(hFe," \u2014 "),dj=n(hFe,"A",{href:!0});var QNt=s(dj);gQo=t(QNt,"TFLayoutLMForTokenClassification"),QNt.forEach(r),hQo=t(hFe," (LayoutLM model)"),hFe.forEach(r),uQo=i(oe),F5=n(oe,"LI",{});var uFe=s(F5);Oie=n(uFe,"STRONG",{});var HNt=s(Oie);pQo=t(HNt,"longformer"),HNt.forEach(r),_Qo=t(uFe," \u2014 "),mj=n(uFe,"A",{href:!0});var UNt=s(mj);vQo=t(UNt,"TFLongformerForTokenClassification"),UNt.forEach(r),bQo=t(uFe," (Longformer model)"),uFe.forEach(r),TQo=i(oe),M5=n(oe,"LI",{});var pFe=s(M5);qie=n(pFe,"STRONG",{});var JNt=s(qie);FQo=t(JNt,"mobilebert"),JNt.forEach(r),MQo=t(pFe," \u2014 "),fj=n(pFe,"A",{href:!0});var KNt=s(fj);EQo=t(KNt,"TFMobileBertForTokenClassification"),KNt.forEach(r),CQo=t(pFe," (MobileBERT model)"),pFe.forEach(r),yQo=i(oe),E5=n(oe,"LI",{});var _Fe=s(E5);zie=n(_Fe,"STRONG",{});var YNt=s(zie);wQo=t(YNt,"mpnet"),YNt.forEach(r),AQo=t(_Fe," \u2014 "),cj=n(_Fe,"A",{href:!0});var ZNt=s(cj);xQo=t(ZNt,"TFMPNetForTokenClassification"),ZNt.forEach(r),LQo=t(_Fe," (MPNet model)"),_Fe.forEach(r),BQo=i(oe),C5=n(oe,"LI",{});var vFe=s(C5);Xie=n(vFe,"STRONG",{});var eDt=s(Xie);kQo=t(eDt,"rembert"),eDt.forEach(r),RQo=t(vFe," \u2014 "),gj=n(vFe,"A",{href:!0});var oDt=s(gj);SQo=t(oDt,"TFRemBertForTokenClassification"),oDt.forEach(r),PQo=t(vFe," (RemBERT model)"),vFe.forEach(r),$Qo=i(oe),y5=n(oe,"LI",{});var bFe=s(y5);Wie=n(bFe,"STRONG",{});var tDt=s(Wie);IQo=t(tDt,"roberta"),tDt.forEach(r),jQo=t(bFe," \u2014 "),hj=n(bFe,"A",{href:!0});var rDt=s(hj);NQo=t(rDt,"TFRobertaForTokenClassification"),rDt.forEach(r),DQo=t(bFe," (RoBERTa model)"),bFe.forEach(r),GQo=i(oe),w5=n(oe,"LI",{});var TFe=s(w5);Vie=n(TFe,"STRONG",{});var aDt=s(Vie);OQo=t(aDt,"roformer"),aDt.forEach(r),qQo=t(TFe," \u2014 "),uj=n(TFe,"A",{href:!0});var nDt=s(uj);zQo=t(nDt,"TFRoFormerForTokenClassification"),nDt.forEach(r),XQo=t(TFe," (RoFormer model)"),TFe.forEach(r),WQo=i(oe),A5=n(oe,"LI",{});var FFe=s(A5);Qie=n(FFe,"STRONG",{});var sDt=s(Qie);VQo=t(sDt,"xlm"),sDt.forEach(r),QQo=t(FFe," \u2014 "),pj=n(FFe,"A",{href:!0});var lDt=s(pj);HQo=t(lDt,"TFXLMForTokenClassification"),lDt.forEach(r),UQo=t(FFe," (XLM model)"),FFe.forEach(r),JQo=i(oe),x5=n(oe,"LI",{});var MFe=s(x5);Hie=n(MFe,"STRONG",{});var iDt=s(Hie);KQo=t(iDt,"xlm-roberta"),iDt.forEach(r),YQo=t(MFe," \u2014 "),_j=n(MFe,"A",{href:!0});var dDt=s(_j);ZQo=t(dDt,"TFXLMRobertaForTokenClassification"),dDt.forEach(r),eHo=t(MFe," (XLM-RoBERTa model)"),MFe.forEach(r),oHo=i(oe),L5=n(oe,"LI",{});var EFe=s(L5);Uie=n(EFe,"STRONG",{});var mDt=s(Uie);tHo=t(mDt,"xlnet"),mDt.forEach(r),rHo=t(EFe," \u2014 "),vj=n(EFe,"A",{href:!0});var fDt=s(vj);aHo=t(fDt,"TFXLNetForTokenClassification"),fDt.forEach(r),nHo=t(EFe," (XLNet model)"),EFe.forEach(r),oe.forEach(r),sHo=i(ra),Jie=n(ra,"P",{});var cDt=s(Jie);lHo=t(cDt,"Examples:"),cDt.forEach(r),iHo=i(ra),c(ay.$$.fragment,ra),ra.forEach(r),_l.forEach(r),NCe=i(d),Xd=n(d,"H2",{class:!0});var Iye=s(Xd);B5=n(Iye,"A",{id:!0,class:!0,href:!0});var gDt=s(B5);Kie=n(gDt,"SPAN",{});var hDt=s(Kie);c(ny.$$.fragment,hDt),hDt.forEach(r),gDt.forEach(r),dHo=i(Iye),Yie=n(Iye,"SPAN",{});var uDt=s(Yie);mHo=t(uDt,"TFAutoModelForQuestionAnswering"),uDt.forEach(r),Iye.forEach(r),DCe=i(d),ft=n(d,"DIV",{class:!0});var bl=s(ft);c(sy.$$.fragment,bl),fHo=i(bl),Wd=n(bl,"P",{});var yG=s(Wd);cHo=t(yG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Zie=n(yG,"CODE",{});var pDt=s(Zie);gHo=t(pDt,"from_pretrained()"),pDt.forEach(r),hHo=t(yG,` class method or the
`),ede=n(yG,"CODE",{});var _Dt=s(ede);uHo=t(_Dt,"from_config()"),_Dt.forEach(r),pHo=t(yG," class method."),yG.forEach(r),_Ho=i(bl),ly=n(bl,"P",{});var jye=s(ly);vHo=t(jye,"This class cannot be instantiated directly using "),ode=n(jye,"CODE",{});var vDt=s(ode);bHo=t(vDt,"__init__()"),vDt.forEach(r),THo=t(jye," (throws an error)."),jye.forEach(r),FHo=i(bl),tr=n(bl,"DIV",{class:!0});var Tl=s(tr);c(iy.$$.fragment,Tl),MHo=i(Tl),tde=n(Tl,"P",{});var bDt=s(tde);EHo=t(bDt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),bDt.forEach(r),CHo=i(Tl),Vd=n(Tl,"P",{});var wG=s(Vd);yHo=t(wG,`Note:
Loading a model from its configuration file does `),rde=n(wG,"STRONG",{});var TDt=s(rde);wHo=t(TDt,"not"),TDt.forEach(r),AHo=t(wG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),ade=n(wG,"EM",{});var FDt=s(ade);xHo=t(FDt,"~TFAutoModelForQuestionAnswering.from_pretrained"),FDt.forEach(r),LHo=t(wG,`] to load the model
weights.`),wG.forEach(r),BHo=i(Tl),nde=n(Tl,"P",{});var MDt=s(nde);kHo=t(MDt,"Examples:"),MDt.forEach(r),RHo=i(Tl),c(dy.$$.fragment,Tl),Tl.forEach(r),SHo=i(bl),ho=n(bl,"DIV",{class:!0});var aa=s(ho);c(my.$$.fragment,aa),PHo=i(aa),sde=n(aa,"P",{});var EDt=s(sde);$Ho=t(EDt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),EDt.forEach(r),IHo=i(aa),Za=n(aa,"P",{});var bF=s(Za);jHo=t(bF,"The model class to instantiate is selected based on the "),lde=n(bF,"EM",{});var CDt=s(lde);NHo=t(CDt,"model_type"),CDt.forEach(r),DHo=t(bF,` property of the config object (either
passed as an argument or loaded from `),ide=n(bF,"EM",{});var yDt=s(ide);GHo=t(yDt,"pretrained_model_name_or_path"),yDt.forEach(r),OHo=t(bF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),dde=n(bF,"EM",{});var wDt=s(dde);qHo=t(wDt,"pretrained_model_name_or_path"),wDt.forEach(r),zHo=t(bF,":"),bF.forEach(r),XHo=i(aa),Z=n(aa,"UL",{});var te=s(Z);k5=n(te,"LI",{});var CFe=s(k5);mde=n(CFe,"STRONG",{});var ADt=s(mde);WHo=t(ADt,"albert"),ADt.forEach(r),VHo=t(CFe," \u2014 "),bj=n(CFe,"A",{href:!0});var xDt=s(bj);QHo=t(xDt,"TFAlbertForQuestionAnswering"),xDt.forEach(r),HHo=t(CFe," (ALBERT model)"),CFe.forEach(r),UHo=i(te),R5=n(te,"LI",{});var yFe=s(R5);fde=n(yFe,"STRONG",{});var LDt=s(fde);JHo=t(LDt,"bert"),LDt.forEach(r),KHo=t(yFe," \u2014 "),Tj=n(yFe,"A",{href:!0});var BDt=s(Tj);YHo=t(BDt,"TFBertForQuestionAnswering"),BDt.forEach(r),ZHo=t(yFe," (BERT model)"),yFe.forEach(r),eUo=i(te),S5=n(te,"LI",{});var wFe=s(S5);cde=n(wFe,"STRONG",{});var kDt=s(cde);oUo=t(kDt,"camembert"),kDt.forEach(r),tUo=t(wFe," \u2014 "),Fj=n(wFe,"A",{href:!0});var RDt=s(Fj);rUo=t(RDt,"TFCamembertForQuestionAnswering"),RDt.forEach(r),aUo=t(wFe," (CamemBERT model)"),wFe.forEach(r),nUo=i(te),P5=n(te,"LI",{});var AFe=s(P5);gde=n(AFe,"STRONG",{});var SDt=s(gde);sUo=t(SDt,"convbert"),SDt.forEach(r),lUo=t(AFe," \u2014 "),Mj=n(AFe,"A",{href:!0});var PDt=s(Mj);iUo=t(PDt,"TFConvBertForQuestionAnswering"),PDt.forEach(r),dUo=t(AFe," (ConvBERT model)"),AFe.forEach(r),mUo=i(te),$5=n(te,"LI",{});var xFe=s($5);hde=n(xFe,"STRONG",{});var $Dt=s(hde);fUo=t($Dt,"deberta"),$Dt.forEach(r),cUo=t(xFe," \u2014 "),Ej=n(xFe,"A",{href:!0});var IDt=s(Ej);gUo=t(IDt,"TFDebertaForQuestionAnswering"),IDt.forEach(r),hUo=t(xFe," (DeBERTa model)"),xFe.forEach(r),uUo=i(te),I5=n(te,"LI",{});var LFe=s(I5);ude=n(LFe,"STRONG",{});var jDt=s(ude);pUo=t(jDt,"deberta-v2"),jDt.forEach(r),_Uo=t(LFe," \u2014 "),Cj=n(LFe,"A",{href:!0});var NDt=s(Cj);vUo=t(NDt,"TFDebertaV2ForQuestionAnswering"),NDt.forEach(r),bUo=t(LFe," (DeBERTa-v2 model)"),LFe.forEach(r),TUo=i(te),j5=n(te,"LI",{});var BFe=s(j5);pde=n(BFe,"STRONG",{});var DDt=s(pde);FUo=t(DDt,"distilbert"),DDt.forEach(r),MUo=t(BFe," \u2014 "),yj=n(BFe,"A",{href:!0});var GDt=s(yj);EUo=t(GDt,"TFDistilBertForQuestionAnswering"),GDt.forEach(r),CUo=t(BFe," (DistilBERT model)"),BFe.forEach(r),yUo=i(te),N5=n(te,"LI",{});var kFe=s(N5);_de=n(kFe,"STRONG",{});var ODt=s(_de);wUo=t(ODt,"electra"),ODt.forEach(r),AUo=t(kFe," \u2014 "),wj=n(kFe,"A",{href:!0});var qDt=s(wj);xUo=t(qDt,"TFElectraForQuestionAnswering"),qDt.forEach(r),LUo=t(kFe," (ELECTRA model)"),kFe.forEach(r),BUo=i(te),D5=n(te,"LI",{});var RFe=s(D5);vde=n(RFe,"STRONG",{});var zDt=s(vde);kUo=t(zDt,"flaubert"),zDt.forEach(r),RUo=t(RFe," \u2014 "),Aj=n(RFe,"A",{href:!0});var XDt=s(Aj);SUo=t(XDt,"TFFlaubertForQuestionAnsweringSimple"),XDt.forEach(r),PUo=t(RFe," (FlauBERT model)"),RFe.forEach(r),$Uo=i(te),G5=n(te,"LI",{});var SFe=s(G5);bde=n(SFe,"STRONG",{});var WDt=s(bde);IUo=t(WDt,"funnel"),WDt.forEach(r),jUo=t(SFe," \u2014 "),xj=n(SFe,"A",{href:!0});var VDt=s(xj);NUo=t(VDt,"TFFunnelForQuestionAnswering"),VDt.forEach(r),DUo=t(SFe," (Funnel Transformer model)"),SFe.forEach(r),GUo=i(te),O5=n(te,"LI",{});var PFe=s(O5);Tde=n(PFe,"STRONG",{});var QDt=s(Tde);OUo=t(QDt,"longformer"),QDt.forEach(r),qUo=t(PFe," \u2014 "),Lj=n(PFe,"A",{href:!0});var HDt=s(Lj);zUo=t(HDt,"TFLongformerForQuestionAnswering"),HDt.forEach(r),XUo=t(PFe," (Longformer model)"),PFe.forEach(r),WUo=i(te),q5=n(te,"LI",{});var $Fe=s(q5);Fde=n($Fe,"STRONG",{});var UDt=s(Fde);VUo=t(UDt,"mobilebert"),UDt.forEach(r),QUo=t($Fe," \u2014 "),Bj=n($Fe,"A",{href:!0});var JDt=s(Bj);HUo=t(JDt,"TFMobileBertForQuestionAnswering"),JDt.forEach(r),UUo=t($Fe," (MobileBERT model)"),$Fe.forEach(r),JUo=i(te),z5=n(te,"LI",{});var IFe=s(z5);Mde=n(IFe,"STRONG",{});var KDt=s(Mde);KUo=t(KDt,"mpnet"),KDt.forEach(r),YUo=t(IFe," \u2014 "),kj=n(IFe,"A",{href:!0});var YDt=s(kj);ZUo=t(YDt,"TFMPNetForQuestionAnswering"),YDt.forEach(r),eJo=t(IFe," (MPNet model)"),IFe.forEach(r),oJo=i(te),X5=n(te,"LI",{});var jFe=s(X5);Ede=n(jFe,"STRONG",{});var ZDt=s(Ede);tJo=t(ZDt,"rembert"),ZDt.forEach(r),rJo=t(jFe," \u2014 "),Rj=n(jFe,"A",{href:!0});var eGt=s(Rj);aJo=t(eGt,"TFRemBertForQuestionAnswering"),eGt.forEach(r),nJo=t(jFe," (RemBERT model)"),jFe.forEach(r),sJo=i(te),W5=n(te,"LI",{});var NFe=s(W5);Cde=n(NFe,"STRONG",{});var oGt=s(Cde);lJo=t(oGt,"roberta"),oGt.forEach(r),iJo=t(NFe," \u2014 "),Sj=n(NFe,"A",{href:!0});var tGt=s(Sj);dJo=t(tGt,"TFRobertaForQuestionAnswering"),tGt.forEach(r),mJo=t(NFe," (RoBERTa model)"),NFe.forEach(r),fJo=i(te),V5=n(te,"LI",{});var DFe=s(V5);yde=n(DFe,"STRONG",{});var rGt=s(yde);cJo=t(rGt,"roformer"),rGt.forEach(r),gJo=t(DFe," \u2014 "),Pj=n(DFe,"A",{href:!0});var aGt=s(Pj);hJo=t(aGt,"TFRoFormerForQuestionAnswering"),aGt.forEach(r),uJo=t(DFe," (RoFormer model)"),DFe.forEach(r),pJo=i(te),Q5=n(te,"LI",{});var GFe=s(Q5);wde=n(GFe,"STRONG",{});var nGt=s(wde);_Jo=t(nGt,"xlm"),nGt.forEach(r),vJo=t(GFe," \u2014 "),$j=n(GFe,"A",{href:!0});var sGt=s($j);bJo=t(sGt,"TFXLMForQuestionAnsweringSimple"),sGt.forEach(r),TJo=t(GFe," (XLM model)"),GFe.forEach(r),FJo=i(te),H5=n(te,"LI",{});var OFe=s(H5);Ade=n(OFe,"STRONG",{});var lGt=s(Ade);MJo=t(lGt,"xlm-roberta"),lGt.forEach(r),EJo=t(OFe," \u2014 "),Ij=n(OFe,"A",{href:!0});var iGt=s(Ij);CJo=t(iGt,"TFXLMRobertaForQuestionAnswering"),iGt.forEach(r),yJo=t(OFe," (XLM-RoBERTa model)"),OFe.forEach(r),wJo=i(te),U5=n(te,"LI",{});var qFe=s(U5);xde=n(qFe,"STRONG",{});var dGt=s(xde);AJo=t(dGt,"xlnet"),dGt.forEach(r),xJo=t(qFe," \u2014 "),jj=n(qFe,"A",{href:!0});var mGt=s(jj);LJo=t(mGt,"TFXLNetForQuestionAnsweringSimple"),mGt.forEach(r),BJo=t(qFe," (XLNet model)"),qFe.forEach(r),te.forEach(r),kJo=i(aa),Lde=n(aa,"P",{});var fGt=s(Lde);RJo=t(fGt,"Examples:"),fGt.forEach(r),SJo=i(aa),c(fy.$$.fragment,aa),aa.forEach(r),bl.forEach(r),GCe=i(d),Qd=n(d,"H2",{class:!0});var Nye=s(Qd);J5=n(Nye,"A",{id:!0,class:!0,href:!0});var cGt=s(J5);Bde=n(cGt,"SPAN",{});var gGt=s(Bde);c(cy.$$.fragment,gGt),gGt.forEach(r),cGt.forEach(r),PJo=i(Nye),kde=n(Nye,"SPAN",{});var hGt=s(kde);$Jo=t(hGt,"FlaxAutoModel"),hGt.forEach(r),Nye.forEach(r),OCe=i(d),ct=n(d,"DIV",{class:!0});var Fl=s(ct);c(gy.$$.fragment,Fl),IJo=i(Fl),Hd=n(Fl,"P",{});var AG=s(Hd);jJo=t(AG,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Rde=n(AG,"CODE",{});var uGt=s(Rde);NJo=t(uGt,"from_pretrained()"),uGt.forEach(r),DJo=t(AG,` class method or the
`),Sde=n(AG,"CODE",{});var pGt=s(Sde);GJo=t(pGt,"from_config()"),pGt.forEach(r),OJo=t(AG," class method."),AG.forEach(r),qJo=i(Fl),hy=n(Fl,"P",{});var Dye=s(hy);zJo=t(Dye,"This class cannot be instantiated directly using "),Pde=n(Dye,"CODE",{});var _Gt=s(Pde);XJo=t(_Gt,"__init__()"),_Gt.forEach(r),WJo=t(Dye," (throws an error)."),Dye.forEach(r),VJo=i(Fl),rr=n(Fl,"DIV",{class:!0});var Ml=s(rr);c(uy.$$.fragment,Ml),QJo=i(Ml),$de=n(Ml,"P",{});var vGt=s($de);HJo=t(vGt,"Instantiates one of the base model classes of the library from a configuration."),vGt.forEach(r),UJo=i(Ml),Ud=n(Ml,"P",{});var xG=s(Ud);JJo=t(xG,`Note:
Loading a model from its configuration file does `),Ide=n(xG,"STRONG",{});var bGt=s(Ide);KJo=t(bGt,"not"),bGt.forEach(r),YJo=t(xG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),jde=n(xG,"EM",{});var TGt=s(jde);ZJo=t(TGt,"~FlaxAutoModel.from_pretrained"),TGt.forEach(r),eKo=t(xG,`] to load the model
weights.`),xG.forEach(r),oKo=i(Ml),Nde=n(Ml,"P",{});var FGt=s(Nde);tKo=t(FGt,"Examples:"),FGt.forEach(r),rKo=i(Ml),c(py.$$.fragment,Ml),Ml.forEach(r),aKo=i(Fl),uo=n(Fl,"DIV",{class:!0});var na=s(uo);c(_y.$$.fragment,na),nKo=i(na),Dde=n(na,"P",{});var MGt=s(Dde);sKo=t(MGt,"Instantiate one of the base model classes of the library from a pretrained model."),MGt.forEach(r),lKo=i(na),en=n(na,"P",{});var TF=s(en);iKo=t(TF,"The model class to instantiate is selected based on the "),Gde=n(TF,"EM",{});var EGt=s(Gde);dKo=t(EGt,"model_type"),EGt.forEach(r),mKo=t(TF,` property of the config object (either
passed as an argument or loaded from `),Ode=n(TF,"EM",{});var CGt=s(Ode);fKo=t(CGt,"pretrained_model_name_or_path"),CGt.forEach(r),cKo=t(TF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),qde=n(TF,"EM",{});var yGt=s(qde);gKo=t(yGt,"pretrained_model_name_or_path"),yGt.forEach(r),hKo=t(TF,":"),TF.forEach(r),uKo=i(na),Q=n(na,"UL",{});var U=s(Q);K5=n(U,"LI",{});var zFe=s(K5);zde=n(zFe,"STRONG",{});var wGt=s(zde);pKo=t(wGt,"albert"),wGt.forEach(r),_Ko=t(zFe," \u2014 "),Nj=n(zFe,"A",{href:!0});var AGt=s(Nj);vKo=t(AGt,"FlaxAlbertModel"),AGt.forEach(r),bKo=t(zFe," (ALBERT model)"),zFe.forEach(r),TKo=i(U),Y5=n(U,"LI",{});var XFe=s(Y5);Xde=n(XFe,"STRONG",{});var xGt=s(Xde);FKo=t(xGt,"bart"),xGt.forEach(r),MKo=t(XFe," \u2014 "),Dj=n(XFe,"A",{href:!0});var LGt=s(Dj);EKo=t(LGt,"FlaxBartModel"),LGt.forEach(r),CKo=t(XFe," (BART model)"),XFe.forEach(r),yKo=i(U),Z5=n(U,"LI",{});var WFe=s(Z5);Wde=n(WFe,"STRONG",{});var BGt=s(Wde);wKo=t(BGt,"beit"),BGt.forEach(r),AKo=t(WFe," \u2014 "),Gj=n(WFe,"A",{href:!0});var kGt=s(Gj);xKo=t(kGt,"FlaxBeitModel"),kGt.forEach(r),LKo=t(WFe," (BEiT model)"),WFe.forEach(r),BKo=i(U),e0=n(U,"LI",{});var VFe=s(e0);Vde=n(VFe,"STRONG",{});var RGt=s(Vde);kKo=t(RGt,"bert"),RGt.forEach(r),RKo=t(VFe," \u2014 "),Oj=n(VFe,"A",{href:!0});var SGt=s(Oj);SKo=t(SGt,"FlaxBertModel"),SGt.forEach(r),PKo=t(VFe," (BERT model)"),VFe.forEach(r),$Ko=i(U),o0=n(U,"LI",{});var QFe=s(o0);Qde=n(QFe,"STRONG",{});var PGt=s(Qde);IKo=t(PGt,"big_bird"),PGt.forEach(r),jKo=t(QFe," \u2014 "),qj=n(QFe,"A",{href:!0});var $Gt=s(qj);NKo=t($Gt,"FlaxBigBirdModel"),$Gt.forEach(r),DKo=t(QFe," (BigBird model)"),QFe.forEach(r),GKo=i(U),t0=n(U,"LI",{});var HFe=s(t0);Hde=n(HFe,"STRONG",{});var IGt=s(Hde);OKo=t(IGt,"blenderbot"),IGt.forEach(r),qKo=t(HFe," \u2014 "),zj=n(HFe,"A",{href:!0});var jGt=s(zj);zKo=t(jGt,"FlaxBlenderbotModel"),jGt.forEach(r),XKo=t(HFe," (Blenderbot model)"),HFe.forEach(r),WKo=i(U),r0=n(U,"LI",{});var UFe=s(r0);Ude=n(UFe,"STRONG",{});var NGt=s(Ude);VKo=t(NGt,"blenderbot-small"),NGt.forEach(r),QKo=t(UFe," \u2014 "),Xj=n(UFe,"A",{href:!0});var DGt=s(Xj);HKo=t(DGt,"FlaxBlenderbotSmallModel"),DGt.forEach(r),UKo=t(UFe," (BlenderbotSmall model)"),UFe.forEach(r),JKo=i(U),a0=n(U,"LI",{});var JFe=s(a0);Jde=n(JFe,"STRONG",{});var GGt=s(Jde);KKo=t(GGt,"clip"),GGt.forEach(r),YKo=t(JFe," \u2014 "),Wj=n(JFe,"A",{href:!0});var OGt=s(Wj);ZKo=t(OGt,"FlaxCLIPModel"),OGt.forEach(r),eYo=t(JFe," (CLIP model)"),JFe.forEach(r),oYo=i(U),n0=n(U,"LI",{});var KFe=s(n0);Kde=n(KFe,"STRONG",{});var qGt=s(Kde);tYo=t(qGt,"distilbert"),qGt.forEach(r),rYo=t(KFe," \u2014 "),Vj=n(KFe,"A",{href:!0});var zGt=s(Vj);aYo=t(zGt,"FlaxDistilBertModel"),zGt.forEach(r),nYo=t(KFe," (DistilBERT model)"),KFe.forEach(r),sYo=i(U),s0=n(U,"LI",{});var YFe=s(s0);Yde=n(YFe,"STRONG",{});var XGt=s(Yde);lYo=t(XGt,"electra"),XGt.forEach(r),iYo=t(YFe," \u2014 "),Qj=n(YFe,"A",{href:!0});var WGt=s(Qj);dYo=t(WGt,"FlaxElectraModel"),WGt.forEach(r),mYo=t(YFe," (ELECTRA model)"),YFe.forEach(r),fYo=i(U),l0=n(U,"LI",{});var ZFe=s(l0);Zde=n(ZFe,"STRONG",{});var VGt=s(Zde);cYo=t(VGt,"gpt2"),VGt.forEach(r),gYo=t(ZFe," \u2014 "),Hj=n(ZFe,"A",{href:!0});var QGt=s(Hj);hYo=t(QGt,"FlaxGPT2Model"),QGt.forEach(r),uYo=t(ZFe," (OpenAI GPT-2 model)"),ZFe.forEach(r),pYo=i(U),i0=n(U,"LI",{});var eMe=s(i0);eme=n(eMe,"STRONG",{});var HGt=s(eme);_Yo=t(HGt,"gpt_neo"),HGt.forEach(r),vYo=t(eMe," \u2014 "),Uj=n(eMe,"A",{href:!0});var UGt=s(Uj);bYo=t(UGt,"FlaxGPTNeoModel"),UGt.forEach(r),TYo=t(eMe," (GPT Neo model)"),eMe.forEach(r),FYo=i(U),d0=n(U,"LI",{});var oMe=s(d0);ome=n(oMe,"STRONG",{});var JGt=s(ome);MYo=t(JGt,"gptj"),JGt.forEach(r),EYo=t(oMe," \u2014 "),Jj=n(oMe,"A",{href:!0});var KGt=s(Jj);CYo=t(KGt,"FlaxGPTJModel"),KGt.forEach(r),yYo=t(oMe," (GPT-J model)"),oMe.forEach(r),wYo=i(U),m0=n(U,"LI",{});var tMe=s(m0);tme=n(tMe,"STRONG",{});var YGt=s(tme);AYo=t(YGt,"marian"),YGt.forEach(r),xYo=t(tMe," \u2014 "),Kj=n(tMe,"A",{href:!0});var ZGt=s(Kj);LYo=t(ZGt,"FlaxMarianModel"),ZGt.forEach(r),BYo=t(tMe," (Marian model)"),tMe.forEach(r),kYo=i(U),f0=n(U,"LI",{});var rMe=s(f0);rme=n(rMe,"STRONG",{});var eOt=s(rme);RYo=t(eOt,"mbart"),eOt.forEach(r),SYo=t(rMe," \u2014 "),Yj=n(rMe,"A",{href:!0});var oOt=s(Yj);PYo=t(oOt,"FlaxMBartModel"),oOt.forEach(r),$Yo=t(rMe," (mBART model)"),rMe.forEach(r),IYo=i(U),c0=n(U,"LI",{});var aMe=s(c0);ame=n(aMe,"STRONG",{});var tOt=s(ame);jYo=t(tOt,"mt5"),tOt.forEach(r),NYo=t(aMe," \u2014 "),Zj=n(aMe,"A",{href:!0});var rOt=s(Zj);DYo=t(rOt,"FlaxMT5Model"),rOt.forEach(r),GYo=t(aMe," (mT5 model)"),aMe.forEach(r),OYo=i(U),g0=n(U,"LI",{});var nMe=s(g0);nme=n(nMe,"STRONG",{});var aOt=s(nme);qYo=t(aOt,"pegasus"),aOt.forEach(r),zYo=t(nMe," \u2014 "),eN=n(nMe,"A",{href:!0});var nOt=s(eN);XYo=t(nOt,"FlaxPegasusModel"),nOt.forEach(r),WYo=t(nMe," (Pegasus model)"),nMe.forEach(r),VYo=i(U),h0=n(U,"LI",{});var sMe=s(h0);sme=n(sMe,"STRONG",{});var sOt=s(sme);QYo=t(sOt,"roberta"),sOt.forEach(r),HYo=t(sMe," \u2014 "),oN=n(sMe,"A",{href:!0});var lOt=s(oN);UYo=t(lOt,"FlaxRobertaModel"),lOt.forEach(r),JYo=t(sMe," (RoBERTa model)"),sMe.forEach(r),KYo=i(U),u0=n(U,"LI",{});var lMe=s(u0);lme=n(lMe,"STRONG",{});var iOt=s(lme);YYo=t(iOt,"t5"),iOt.forEach(r),ZYo=t(lMe," \u2014 "),tN=n(lMe,"A",{href:!0});var dOt=s(tN);eZo=t(dOt,"FlaxT5Model"),dOt.forEach(r),oZo=t(lMe," (T5 model)"),lMe.forEach(r),tZo=i(U),p0=n(U,"LI",{});var iMe=s(p0);ime=n(iMe,"STRONG",{});var mOt=s(ime);rZo=t(mOt,"vision-text-dual-encoder"),mOt.forEach(r),aZo=t(iMe," \u2014 "),rN=n(iMe,"A",{href:!0});var fOt=s(rN);nZo=t(fOt,"FlaxVisionTextDualEncoderModel"),fOt.forEach(r),sZo=t(iMe," (VisionTextDualEncoder model)"),iMe.forEach(r),lZo=i(U),_0=n(U,"LI",{});var dMe=s(_0);dme=n(dMe,"STRONG",{});var cOt=s(dme);iZo=t(cOt,"vit"),cOt.forEach(r),dZo=t(dMe," \u2014 "),aN=n(dMe,"A",{href:!0});var gOt=s(aN);mZo=t(gOt,"FlaxViTModel"),gOt.forEach(r),fZo=t(dMe," (ViT model)"),dMe.forEach(r),cZo=i(U),v0=n(U,"LI",{});var mMe=s(v0);mme=n(mMe,"STRONG",{});var hOt=s(mme);gZo=t(hOt,"wav2vec2"),hOt.forEach(r),hZo=t(mMe," \u2014 "),nN=n(mMe,"A",{href:!0});var uOt=s(nN);uZo=t(uOt,"FlaxWav2Vec2Model"),uOt.forEach(r),pZo=t(mMe," (Wav2Vec2 model)"),mMe.forEach(r),U.forEach(r),_Zo=i(na),fme=n(na,"P",{});var pOt=s(fme);vZo=t(pOt,"Examples:"),pOt.forEach(r),bZo=i(na),c(vy.$$.fragment,na),na.forEach(r),Fl.forEach(r),qCe=i(d),Jd=n(d,"H2",{class:!0});var Gye=s(Jd);b0=n(Gye,"A",{id:!0,class:!0,href:!0});var _Ot=s(b0);cme=n(_Ot,"SPAN",{});var vOt=s(cme);c(by.$$.fragment,vOt),vOt.forEach(r),_Ot.forEach(r),TZo=i(Gye),gme=n(Gye,"SPAN",{});var bOt=s(gme);FZo=t(bOt,"FlaxAutoModelForCausalLM"),bOt.forEach(r),Gye.forEach(r),zCe=i(d),gt=n(d,"DIV",{class:!0});var El=s(gt);c(Ty.$$.fragment,El),MZo=i(El),Kd=n(El,"P",{});var LG=s(Kd);EZo=t(LG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hme=n(LG,"CODE",{});var TOt=s(hme);CZo=t(TOt,"from_pretrained()"),TOt.forEach(r),yZo=t(LG,` class method or the
`),ume=n(LG,"CODE",{});var FOt=s(ume);wZo=t(FOt,"from_config()"),FOt.forEach(r),AZo=t(LG," class method."),LG.forEach(r),xZo=i(El),Fy=n(El,"P",{});var Oye=s(Fy);LZo=t(Oye,"This class cannot be instantiated directly using "),pme=n(Oye,"CODE",{});var MOt=s(pme);BZo=t(MOt,"__init__()"),MOt.forEach(r),kZo=t(Oye," (throws an error)."),Oye.forEach(r),RZo=i(El),ar=n(El,"DIV",{class:!0});var Cl=s(ar);c(My.$$.fragment,Cl),SZo=i(Cl),_me=n(Cl,"P",{});var EOt=s(_me);PZo=t(EOt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),EOt.forEach(r),$Zo=i(Cl),Yd=n(Cl,"P",{});var BG=s(Yd);IZo=t(BG,`Note:
Loading a model from its configuration file does `),vme=n(BG,"STRONG",{});var COt=s(vme);jZo=t(COt,"not"),COt.forEach(r),NZo=t(BG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),bme=n(BG,"EM",{});var yOt=s(bme);DZo=t(yOt,"~FlaxAutoModelForCausalLM.from_pretrained"),yOt.forEach(r),GZo=t(BG,`] to load the model
weights.`),BG.forEach(r),OZo=i(Cl),Tme=n(Cl,"P",{});var wOt=s(Tme);qZo=t(wOt,"Examples:"),wOt.forEach(r),zZo=i(Cl),c(Ey.$$.fragment,Cl),Cl.forEach(r),XZo=i(El),po=n(El,"DIV",{class:!0});var sa=s(po);c(Cy.$$.fragment,sa),WZo=i(sa),Fme=n(sa,"P",{});var AOt=s(Fme);VZo=t(AOt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),AOt.forEach(r),QZo=i(sa),on=n(sa,"P",{});var FF=s(on);HZo=t(FF,"The model class to instantiate is selected based on the "),Mme=n(FF,"EM",{});var xOt=s(Mme);UZo=t(xOt,"model_type"),xOt.forEach(r),JZo=t(FF,` property of the config object (either
passed as an argument or loaded from `),Eme=n(FF,"EM",{});var LOt=s(Eme);KZo=t(LOt,"pretrained_model_name_or_path"),LOt.forEach(r),YZo=t(FF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Cme=n(FF,"EM",{});var BOt=s(Cme);ZZo=t(BOt,"pretrained_model_name_or_path"),BOt.forEach(r),eet=t(FF,":"),FF.forEach(r),oet=i(sa),Zd=n(sa,"UL",{});var kG=s(Zd);T0=n(kG,"LI",{});var fMe=s(T0);yme=n(fMe,"STRONG",{});var kOt=s(yme);tet=t(kOt,"gpt2"),kOt.forEach(r),ret=t(fMe," \u2014 "),sN=n(fMe,"A",{href:!0});var ROt=s(sN);aet=t(ROt,"FlaxGPT2LMHeadModel"),ROt.forEach(r),net=t(fMe," (OpenAI GPT-2 model)"),fMe.forEach(r),set=i(kG),F0=n(kG,"LI",{});var cMe=s(F0);wme=n(cMe,"STRONG",{});var SOt=s(wme);iet=t(SOt,"gpt_neo"),SOt.forEach(r),det=t(cMe," \u2014 "),lN=n(cMe,"A",{href:!0});var POt=s(lN);met=t(POt,"FlaxGPTNeoForCausalLM"),POt.forEach(r),fet=t(cMe," (GPT Neo model)"),cMe.forEach(r),cet=i(kG),M0=n(kG,"LI",{});var gMe=s(M0);Ame=n(gMe,"STRONG",{});var $Ot=s(Ame);get=t($Ot,"gptj"),$Ot.forEach(r),het=t(gMe," \u2014 "),iN=n(gMe,"A",{href:!0});var IOt=s(iN);uet=t(IOt,"FlaxGPTJForCausalLM"),IOt.forEach(r),pet=t(gMe," (GPT-J model)"),gMe.forEach(r),kG.forEach(r),_et=i(sa),xme=n(sa,"P",{});var jOt=s(xme);vet=t(jOt,"Examples:"),jOt.forEach(r),bet=i(sa),c(yy.$$.fragment,sa),sa.forEach(r),El.forEach(r),XCe=i(d),em=n(d,"H2",{class:!0});var qye=s(em);E0=n(qye,"A",{id:!0,class:!0,href:!0});var NOt=s(E0);Lme=n(NOt,"SPAN",{});var DOt=s(Lme);c(wy.$$.fragment,DOt),DOt.forEach(r),NOt.forEach(r),Tet=i(qye),Bme=n(qye,"SPAN",{});var GOt=s(Bme);Fet=t(GOt,"FlaxAutoModelForPreTraining"),GOt.forEach(r),qye.forEach(r),WCe=i(d),ht=n(d,"DIV",{class:!0});var yl=s(ht);c(Ay.$$.fragment,yl),Met=i(yl),om=n(yl,"P",{});var RG=s(om);Eet=t(RG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kme=n(RG,"CODE",{});var OOt=s(kme);Cet=t(OOt,"from_pretrained()"),OOt.forEach(r),yet=t(RG,` class method or the
`),Rme=n(RG,"CODE",{});var qOt=s(Rme);wet=t(qOt,"from_config()"),qOt.forEach(r),Aet=t(RG," class method."),RG.forEach(r),xet=i(yl),xy=n(yl,"P",{});var zye=s(xy);Let=t(zye,"This class cannot be instantiated directly using "),Sme=n(zye,"CODE",{});var zOt=s(Sme);Bet=t(zOt,"__init__()"),zOt.forEach(r),ket=t(zye," (throws an error)."),zye.forEach(r),Ret=i(yl),nr=n(yl,"DIV",{class:!0});var wl=s(nr);c(Ly.$$.fragment,wl),Set=i(wl),Pme=n(wl,"P",{});var XOt=s(Pme);Pet=t(XOt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),XOt.forEach(r),$et=i(wl),tm=n(wl,"P",{});var SG=s(tm);Iet=t(SG,`Note:
Loading a model from its configuration file does `),$me=n(SG,"STRONG",{});var WOt=s($me);jet=t(WOt,"not"),WOt.forEach(r),Net=t(SG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Ime=n(SG,"EM",{});var VOt=s(Ime);Det=t(VOt,"~FlaxAutoModelForPreTraining.from_pretrained"),VOt.forEach(r),Get=t(SG,`] to load the model
weights.`),SG.forEach(r),Oet=i(wl),jme=n(wl,"P",{});var QOt=s(jme);qet=t(QOt,"Examples:"),QOt.forEach(r),zet=i(wl),c(By.$$.fragment,wl),wl.forEach(r),Xet=i(yl),_o=n(yl,"DIV",{class:!0});var la=s(_o);c(ky.$$.fragment,la),Wet=i(la),Nme=n(la,"P",{});var HOt=s(Nme);Vet=t(HOt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),HOt.forEach(r),Qet=i(la),tn=n(la,"P",{});var MF=s(tn);Het=t(MF,"The model class to instantiate is selected based on the "),Dme=n(MF,"EM",{});var UOt=s(Dme);Uet=t(UOt,"model_type"),UOt.forEach(r),Jet=t(MF,` property of the config object (either
passed as an argument or loaded from `),Gme=n(MF,"EM",{});var JOt=s(Gme);Ket=t(JOt,"pretrained_model_name_or_path"),JOt.forEach(r),Yet=t(MF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Ome=n(MF,"EM",{});var KOt=s(Ome);Zet=t(KOt,"pretrained_model_name_or_path"),KOt.forEach(r),eot=t(MF,":"),MF.forEach(r),oot=i(la),he=n(la,"UL",{});var Te=s(he);C0=n(Te,"LI",{});var hMe=s(C0);qme=n(hMe,"STRONG",{});var YOt=s(qme);tot=t(YOt,"albert"),YOt.forEach(r),rot=t(hMe," \u2014 "),dN=n(hMe,"A",{href:!0});var ZOt=s(dN);aot=t(ZOt,"FlaxAlbertForPreTraining"),ZOt.forEach(r),not=t(hMe," (ALBERT model)"),hMe.forEach(r),sot=i(Te),y0=n(Te,"LI",{});var uMe=s(y0);zme=n(uMe,"STRONG",{});var eqt=s(zme);lot=t(eqt,"bart"),eqt.forEach(r),iot=t(uMe," \u2014 "),mN=n(uMe,"A",{href:!0});var oqt=s(mN);dot=t(oqt,"FlaxBartForConditionalGeneration"),oqt.forEach(r),mot=t(uMe," (BART model)"),uMe.forEach(r),fot=i(Te),w0=n(Te,"LI",{});var pMe=s(w0);Xme=n(pMe,"STRONG",{});var tqt=s(Xme);cot=t(tqt,"bert"),tqt.forEach(r),got=t(pMe," \u2014 "),fN=n(pMe,"A",{href:!0});var rqt=s(fN);hot=t(rqt,"FlaxBertForPreTraining"),rqt.forEach(r),uot=t(pMe," (BERT model)"),pMe.forEach(r),pot=i(Te),A0=n(Te,"LI",{});var _Me=s(A0);Wme=n(_Me,"STRONG",{});var aqt=s(Wme);_ot=t(aqt,"big_bird"),aqt.forEach(r),vot=t(_Me," \u2014 "),cN=n(_Me,"A",{href:!0});var nqt=s(cN);bot=t(nqt,"FlaxBigBirdForPreTraining"),nqt.forEach(r),Tot=t(_Me," (BigBird model)"),_Me.forEach(r),Fot=i(Te),x0=n(Te,"LI",{});var vMe=s(x0);Vme=n(vMe,"STRONG",{});var sqt=s(Vme);Mot=t(sqt,"electra"),sqt.forEach(r),Eot=t(vMe," \u2014 "),gN=n(vMe,"A",{href:!0});var lqt=s(gN);Cot=t(lqt,"FlaxElectraForPreTraining"),lqt.forEach(r),yot=t(vMe," (ELECTRA model)"),vMe.forEach(r),wot=i(Te),L0=n(Te,"LI",{});var bMe=s(L0);Qme=n(bMe,"STRONG",{});var iqt=s(Qme);Aot=t(iqt,"mbart"),iqt.forEach(r),xot=t(bMe," \u2014 "),hN=n(bMe,"A",{href:!0});var dqt=s(hN);Lot=t(dqt,"FlaxMBartForConditionalGeneration"),dqt.forEach(r),Bot=t(bMe," (mBART model)"),bMe.forEach(r),kot=i(Te),B0=n(Te,"LI",{});var TMe=s(B0);Hme=n(TMe,"STRONG",{});var mqt=s(Hme);Rot=t(mqt,"mt5"),mqt.forEach(r),Sot=t(TMe," \u2014 "),uN=n(TMe,"A",{href:!0});var fqt=s(uN);Pot=t(fqt,"FlaxMT5ForConditionalGeneration"),fqt.forEach(r),$ot=t(TMe," (mT5 model)"),TMe.forEach(r),Iot=i(Te),k0=n(Te,"LI",{});var FMe=s(k0);Ume=n(FMe,"STRONG",{});var cqt=s(Ume);jot=t(cqt,"roberta"),cqt.forEach(r),Not=t(FMe," \u2014 "),pN=n(FMe,"A",{href:!0});var gqt=s(pN);Dot=t(gqt,"FlaxRobertaForMaskedLM"),gqt.forEach(r),Got=t(FMe," (RoBERTa model)"),FMe.forEach(r),Oot=i(Te),R0=n(Te,"LI",{});var MMe=s(R0);Jme=n(MMe,"STRONG",{});var hqt=s(Jme);qot=t(hqt,"t5"),hqt.forEach(r),zot=t(MMe," \u2014 "),_N=n(MMe,"A",{href:!0});var uqt=s(_N);Xot=t(uqt,"FlaxT5ForConditionalGeneration"),uqt.forEach(r),Wot=t(MMe," (T5 model)"),MMe.forEach(r),Vot=i(Te),S0=n(Te,"LI",{});var EMe=s(S0);Kme=n(EMe,"STRONG",{});var pqt=s(Kme);Qot=t(pqt,"wav2vec2"),pqt.forEach(r),Hot=t(EMe," \u2014 "),vN=n(EMe,"A",{href:!0});var _qt=s(vN);Uot=t(_qt,"FlaxWav2Vec2ForPreTraining"),_qt.forEach(r),Jot=t(EMe," (Wav2Vec2 model)"),EMe.forEach(r),Te.forEach(r),Kot=i(la),Yme=n(la,"P",{});var vqt=s(Yme);Yot=t(vqt,"Examples:"),vqt.forEach(r),Zot=i(la),c(Ry.$$.fragment,la),la.forEach(r),yl.forEach(r),VCe=i(d),rm=n(d,"H2",{class:!0});var Xye=s(rm);P0=n(Xye,"A",{id:!0,class:!0,href:!0});var bqt=s(P0);Zme=n(bqt,"SPAN",{});var Tqt=s(Zme);c(Sy.$$.fragment,Tqt),Tqt.forEach(r),bqt.forEach(r),ett=i(Xye),efe=n(Xye,"SPAN",{});var Fqt=s(efe);ott=t(Fqt,"FlaxAutoModelForMaskedLM"),Fqt.forEach(r),Xye.forEach(r),QCe=i(d),ut=n(d,"DIV",{class:!0});var Al=s(ut);c(Py.$$.fragment,Al),ttt=i(Al),am=n(Al,"P",{});var PG=s(am);rtt=t(PG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ofe=n(PG,"CODE",{});var Mqt=s(ofe);att=t(Mqt,"from_pretrained()"),Mqt.forEach(r),ntt=t(PG,` class method or the
`),tfe=n(PG,"CODE",{});var Eqt=s(tfe);stt=t(Eqt,"from_config()"),Eqt.forEach(r),ltt=t(PG," class method."),PG.forEach(r),itt=i(Al),$y=n(Al,"P",{});var Wye=s($y);dtt=t(Wye,"This class cannot be instantiated directly using "),rfe=n(Wye,"CODE",{});var Cqt=s(rfe);mtt=t(Cqt,"__init__()"),Cqt.forEach(r),ftt=t(Wye," (throws an error)."),Wye.forEach(r),ctt=i(Al),sr=n(Al,"DIV",{class:!0});var xl=s(sr);c(Iy.$$.fragment,xl),gtt=i(xl),afe=n(xl,"P",{});var yqt=s(afe);htt=t(yqt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),yqt.forEach(r),utt=i(xl),nm=n(xl,"P",{});var $G=s(nm);ptt=t($G,`Note:
Loading a model from its configuration file does `),nfe=n($G,"STRONG",{});var wqt=s(nfe);_tt=t(wqt,"not"),wqt.forEach(r),vtt=t($G,` load the model weights. It only affects the
model\u2019s configuration. Use [`),sfe=n($G,"EM",{});var Aqt=s(sfe);btt=t(Aqt,"~FlaxAutoModelForMaskedLM.from_pretrained"),Aqt.forEach(r),Ttt=t($G,`] to load the model
weights.`),$G.forEach(r),Ftt=i(xl),lfe=n(xl,"P",{});var xqt=s(lfe);Mtt=t(xqt,"Examples:"),xqt.forEach(r),Ett=i(xl),c(jy.$$.fragment,xl),xl.forEach(r),Ctt=i(Al),vo=n(Al,"DIV",{class:!0});var ia=s(vo);c(Ny.$$.fragment,ia),ytt=i(ia),ife=n(ia,"P",{});var Lqt=s(ife);wtt=t(Lqt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Lqt.forEach(r),Att=i(ia),rn=n(ia,"P",{});var EF=s(rn);xtt=t(EF,"The model class to instantiate is selected based on the "),dfe=n(EF,"EM",{});var Bqt=s(dfe);Ltt=t(Bqt,"model_type"),Bqt.forEach(r),Btt=t(EF,` property of the config object (either
passed as an argument or loaded from `),mfe=n(EF,"EM",{});var kqt=s(mfe);ktt=t(kqt,"pretrained_model_name_or_path"),kqt.forEach(r),Rtt=t(EF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),ffe=n(EF,"EM",{});var Rqt=s(ffe);Stt=t(Rqt,"pretrained_model_name_or_path"),Rqt.forEach(r),Ptt=t(EF,":"),EF.forEach(r),$tt=i(ia),Me=n(ia,"UL",{});var Ao=s(Me);$0=n(Ao,"LI",{});var CMe=s($0);cfe=n(CMe,"STRONG",{});var Sqt=s(cfe);Itt=t(Sqt,"albert"),Sqt.forEach(r),jtt=t(CMe," \u2014 "),bN=n(CMe,"A",{href:!0});var Pqt=s(bN);Ntt=t(Pqt,"FlaxAlbertForMaskedLM"),Pqt.forEach(r),Dtt=t(CMe," (ALBERT model)"),CMe.forEach(r),Gtt=i(Ao),I0=n(Ao,"LI",{});var yMe=s(I0);gfe=n(yMe,"STRONG",{});var $qt=s(gfe);Ott=t($qt,"bart"),$qt.forEach(r),qtt=t(yMe," \u2014 "),TN=n(yMe,"A",{href:!0});var Iqt=s(TN);ztt=t(Iqt,"FlaxBartForConditionalGeneration"),Iqt.forEach(r),Xtt=t(yMe," (BART model)"),yMe.forEach(r),Wtt=i(Ao),j0=n(Ao,"LI",{});var wMe=s(j0);hfe=n(wMe,"STRONG",{});var jqt=s(hfe);Vtt=t(jqt,"bert"),jqt.forEach(r),Qtt=t(wMe," \u2014 "),FN=n(wMe,"A",{href:!0});var Nqt=s(FN);Htt=t(Nqt,"FlaxBertForMaskedLM"),Nqt.forEach(r),Utt=t(wMe," (BERT model)"),wMe.forEach(r),Jtt=i(Ao),N0=n(Ao,"LI",{});var AMe=s(N0);ufe=n(AMe,"STRONG",{});var Dqt=s(ufe);Ktt=t(Dqt,"big_bird"),Dqt.forEach(r),Ytt=t(AMe," \u2014 "),MN=n(AMe,"A",{href:!0});var Gqt=s(MN);Ztt=t(Gqt,"FlaxBigBirdForMaskedLM"),Gqt.forEach(r),ert=t(AMe," (BigBird model)"),AMe.forEach(r),ort=i(Ao),D0=n(Ao,"LI",{});var xMe=s(D0);pfe=n(xMe,"STRONG",{});var Oqt=s(pfe);trt=t(Oqt,"distilbert"),Oqt.forEach(r),rrt=t(xMe," \u2014 "),EN=n(xMe,"A",{href:!0});var qqt=s(EN);art=t(qqt,"FlaxDistilBertForMaskedLM"),qqt.forEach(r),nrt=t(xMe," (DistilBERT model)"),xMe.forEach(r),srt=i(Ao),G0=n(Ao,"LI",{});var LMe=s(G0);_fe=n(LMe,"STRONG",{});var zqt=s(_fe);lrt=t(zqt,"electra"),zqt.forEach(r),irt=t(LMe," \u2014 "),CN=n(LMe,"A",{href:!0});var Xqt=s(CN);drt=t(Xqt,"FlaxElectraForMaskedLM"),Xqt.forEach(r),mrt=t(LMe," (ELECTRA model)"),LMe.forEach(r),frt=i(Ao),O0=n(Ao,"LI",{});var BMe=s(O0);vfe=n(BMe,"STRONG",{});var Wqt=s(vfe);crt=t(Wqt,"mbart"),Wqt.forEach(r),grt=t(BMe," \u2014 "),yN=n(BMe,"A",{href:!0});var Vqt=s(yN);hrt=t(Vqt,"FlaxMBartForConditionalGeneration"),Vqt.forEach(r),urt=t(BMe," (mBART model)"),BMe.forEach(r),prt=i(Ao),q0=n(Ao,"LI",{});var kMe=s(q0);bfe=n(kMe,"STRONG",{});var Qqt=s(bfe);_rt=t(Qqt,"roberta"),Qqt.forEach(r),vrt=t(kMe," \u2014 "),wN=n(kMe,"A",{href:!0});var Hqt=s(wN);brt=t(Hqt,"FlaxRobertaForMaskedLM"),Hqt.forEach(r),Trt=t(kMe," (RoBERTa model)"),kMe.forEach(r),Ao.forEach(r),Frt=i(ia),Tfe=n(ia,"P",{});var Uqt=s(Tfe);Mrt=t(Uqt,"Examples:"),Uqt.forEach(r),Ert=i(ia),c(Dy.$$.fragment,ia),ia.forEach(r),Al.forEach(r),HCe=i(d),sm=n(d,"H2",{class:!0});var Vye=s(sm);z0=n(Vye,"A",{id:!0,class:!0,href:!0});var Jqt=s(z0);Ffe=n(Jqt,"SPAN",{});var Kqt=s(Ffe);c(Gy.$$.fragment,Kqt),Kqt.forEach(r),Jqt.forEach(r),Crt=i(Vye),Mfe=n(Vye,"SPAN",{});var Yqt=s(Mfe);yrt=t(Yqt,"FlaxAutoModelForSeq2SeqLM"),Yqt.forEach(r),Vye.forEach(r),UCe=i(d),pt=n(d,"DIV",{class:!0});var Ll=s(pt);c(Oy.$$.fragment,Ll),wrt=i(Ll),lm=n(Ll,"P",{});var IG=s(lm);Art=t(IG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Efe=n(IG,"CODE",{});var Zqt=s(Efe);xrt=t(Zqt,"from_pretrained()"),Zqt.forEach(r),Lrt=t(IG,` class method or the
`),Cfe=n(IG,"CODE",{});var ezt=s(Cfe);Brt=t(ezt,"from_config()"),ezt.forEach(r),krt=t(IG," class method."),IG.forEach(r),Rrt=i(Ll),qy=n(Ll,"P",{});var Qye=s(qy);Srt=t(Qye,"This class cannot be instantiated directly using "),yfe=n(Qye,"CODE",{});var ozt=s(yfe);Prt=t(ozt,"__init__()"),ozt.forEach(r),$rt=t(Qye," (throws an error)."),Qye.forEach(r),Irt=i(Ll),lr=n(Ll,"DIV",{class:!0});var Bl=s(lr);c(zy.$$.fragment,Bl),jrt=i(Bl),wfe=n(Bl,"P",{});var tzt=s(wfe);Nrt=t(tzt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),tzt.forEach(r),Drt=i(Bl),im=n(Bl,"P",{});var jG=s(im);Grt=t(jG,`Note:
Loading a model from its configuration file does `),Afe=n(jG,"STRONG",{});var rzt=s(Afe);Ort=t(rzt,"not"),rzt.forEach(r),qrt=t(jG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),xfe=n(jG,"EM",{});var azt=s(xfe);zrt=t(azt,"~FlaxAutoModelForSeq2SeqLM.from_pretrained"),azt.forEach(r),Xrt=t(jG,`] to load the model
weights.`),jG.forEach(r),Wrt=i(Bl),Lfe=n(Bl,"P",{});var nzt=s(Lfe);Vrt=t(nzt,"Examples:"),nzt.forEach(r),Qrt=i(Bl),c(Xy.$$.fragment,Bl),Bl.forEach(r),Hrt=i(Ll),bo=n(Ll,"DIV",{class:!0});var da=s(bo);c(Wy.$$.fragment,da),Urt=i(da),Bfe=n(da,"P",{});var szt=s(Bfe);Jrt=t(szt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),szt.forEach(r),Krt=i(da),an=n(da,"P",{});var CF=s(an);Yrt=t(CF,"The model class to instantiate is selected based on the "),kfe=n(CF,"EM",{});var lzt=s(kfe);Zrt=t(lzt,"model_type"),lzt.forEach(r),eat=t(CF,` property of the config object (either
passed as an argument or loaded from `),Rfe=n(CF,"EM",{});var izt=s(Rfe);oat=t(izt,"pretrained_model_name_or_path"),izt.forEach(r),tat=t(CF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Sfe=n(CF,"EM",{});var dzt=s(Sfe);rat=t(dzt,"pretrained_model_name_or_path"),dzt.forEach(r),aat=t(CF,":"),CF.forEach(r),nat=i(da),pe=n(da,"UL",{});var He=s(pe);X0=n(He,"LI",{});var RMe=s(X0);Pfe=n(RMe,"STRONG",{});var mzt=s(Pfe);sat=t(mzt,"bart"),mzt.forEach(r),lat=t(RMe," \u2014 "),AN=n(RMe,"A",{href:!0});var fzt=s(AN);iat=t(fzt,"FlaxBartForConditionalGeneration"),fzt.forEach(r),dat=t(RMe," (BART model)"),RMe.forEach(r),mat=i(He),W0=n(He,"LI",{});var SMe=s(W0);$fe=n(SMe,"STRONG",{});var czt=s($fe);fat=t(czt,"blenderbot"),czt.forEach(r),cat=t(SMe," \u2014 "),xN=n(SMe,"A",{href:!0});var gzt=s(xN);gat=t(gzt,"FlaxBlenderbotForConditionalGeneration"),gzt.forEach(r),hat=t(SMe," (Blenderbot model)"),SMe.forEach(r),uat=i(He),V0=n(He,"LI",{});var PMe=s(V0);Ife=n(PMe,"STRONG",{});var hzt=s(Ife);pat=t(hzt,"blenderbot-small"),hzt.forEach(r),_at=t(PMe," \u2014 "),LN=n(PMe,"A",{href:!0});var uzt=s(LN);vat=t(uzt,"FlaxBlenderbotSmallForConditionalGeneration"),uzt.forEach(r),bat=t(PMe," (BlenderbotSmall model)"),PMe.forEach(r),Tat=i(He),Q0=n(He,"LI",{});var $Me=s(Q0);jfe=n($Me,"STRONG",{});var pzt=s(jfe);Fat=t(pzt,"encoder-decoder"),pzt.forEach(r),Mat=t($Me," \u2014 "),BN=n($Me,"A",{href:!0});var _zt=s(BN);Eat=t(_zt,"FlaxEncoderDecoderModel"),_zt.forEach(r),Cat=t($Me," (Encoder decoder model)"),$Me.forEach(r),yat=i(He),H0=n(He,"LI",{});var IMe=s(H0);Nfe=n(IMe,"STRONG",{});var vzt=s(Nfe);wat=t(vzt,"marian"),vzt.forEach(r),Aat=t(IMe," \u2014 "),kN=n(IMe,"A",{href:!0});var bzt=s(kN);xat=t(bzt,"FlaxMarianMTModel"),bzt.forEach(r),Lat=t(IMe," (Marian model)"),IMe.forEach(r),Bat=i(He),U0=n(He,"LI",{});var jMe=s(U0);Dfe=n(jMe,"STRONG",{});var Tzt=s(Dfe);kat=t(Tzt,"mbart"),Tzt.forEach(r),Rat=t(jMe," \u2014 "),RN=n(jMe,"A",{href:!0});var Fzt=s(RN);Sat=t(Fzt,"FlaxMBartForConditionalGeneration"),Fzt.forEach(r),Pat=t(jMe," (mBART model)"),jMe.forEach(r),$at=i(He),J0=n(He,"LI",{});var NMe=s(J0);Gfe=n(NMe,"STRONG",{});var Mzt=s(Gfe);Iat=t(Mzt,"mt5"),Mzt.forEach(r),jat=t(NMe," \u2014 "),SN=n(NMe,"A",{href:!0});var Ezt=s(SN);Nat=t(Ezt,"FlaxMT5ForConditionalGeneration"),Ezt.forEach(r),Dat=t(NMe," (mT5 model)"),NMe.forEach(r),Gat=i(He),K0=n(He,"LI",{});var DMe=s(K0);Ofe=n(DMe,"STRONG",{});var Czt=s(Ofe);Oat=t(Czt,"pegasus"),Czt.forEach(r),qat=t(DMe," \u2014 "),PN=n(DMe,"A",{href:!0});var yzt=s(PN);zat=t(yzt,"FlaxPegasusForConditionalGeneration"),yzt.forEach(r),Xat=t(DMe," (Pegasus model)"),DMe.forEach(r),Wat=i(He),Y0=n(He,"LI",{});var GMe=s(Y0);qfe=n(GMe,"STRONG",{});var wzt=s(qfe);Vat=t(wzt,"t5"),wzt.forEach(r),Qat=t(GMe," \u2014 "),$N=n(GMe,"A",{href:!0});var Azt=s($N);Hat=t(Azt,"FlaxT5ForConditionalGeneration"),Azt.forEach(r),Uat=t(GMe," (T5 model)"),GMe.forEach(r),He.forEach(r),Jat=i(da),zfe=n(da,"P",{});var xzt=s(zfe);Kat=t(xzt,"Examples:"),xzt.forEach(r),Yat=i(da),c(Vy.$$.fragment,da),da.forEach(r),Ll.forEach(r),JCe=i(d),dm=n(d,"H2",{class:!0});var Hye=s(dm);Z0=n(Hye,"A",{id:!0,class:!0,href:!0});var Lzt=s(Z0);Xfe=n(Lzt,"SPAN",{});var Bzt=s(Xfe);c(Qy.$$.fragment,Bzt),Bzt.forEach(r),Lzt.forEach(r),Zat=i(Hye),Wfe=n(Hye,"SPAN",{});var kzt=s(Wfe);ent=t(kzt,"FlaxAutoModelForSequenceClassification"),kzt.forEach(r),Hye.forEach(r),KCe=i(d),_t=n(d,"DIV",{class:!0});var kl=s(_t);c(Hy.$$.fragment,kl),ont=i(kl),mm=n(kl,"P",{});var NG=s(mm);tnt=t(NG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Vfe=n(NG,"CODE",{});var Rzt=s(Vfe);rnt=t(Rzt,"from_pretrained()"),Rzt.forEach(r),ant=t(NG,` class method or the
`),Qfe=n(NG,"CODE",{});var Szt=s(Qfe);nnt=t(Szt,"from_config()"),Szt.forEach(r),snt=t(NG," class method."),NG.forEach(r),lnt=i(kl),Uy=n(kl,"P",{});var Uye=s(Uy);int=t(Uye,"This class cannot be instantiated directly using "),Hfe=n(Uye,"CODE",{});var Pzt=s(Hfe);dnt=t(Pzt,"__init__()"),Pzt.forEach(r),mnt=t(Uye," (throws an error)."),Uye.forEach(r),fnt=i(kl),ir=n(kl,"DIV",{class:!0});var Rl=s(ir);c(Jy.$$.fragment,Rl),cnt=i(Rl),Ufe=n(Rl,"P",{});var $zt=s(Ufe);gnt=t($zt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),$zt.forEach(r),hnt=i(Rl),fm=n(Rl,"P",{});var DG=s(fm);unt=t(DG,`Note:
Loading a model from its configuration file does `),Jfe=n(DG,"STRONG",{});var Izt=s(Jfe);pnt=t(Izt,"not"),Izt.forEach(r),_nt=t(DG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Kfe=n(DG,"EM",{});var jzt=s(Kfe);vnt=t(jzt,"~FlaxAutoModelForSequenceClassification.from_pretrained"),jzt.forEach(r),bnt=t(DG,`] to load the model
weights.`),DG.forEach(r),Tnt=i(Rl),Yfe=n(Rl,"P",{});var Nzt=s(Yfe);Fnt=t(Nzt,"Examples:"),Nzt.forEach(r),Mnt=i(Rl),c(Ky.$$.fragment,Rl),Rl.forEach(r),Ent=i(kl),To=n(kl,"DIV",{class:!0});var ma=s(To);c(Yy.$$.fragment,ma),Cnt=i(ma),Zfe=n(ma,"P",{});var Dzt=s(Zfe);ynt=t(Dzt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Dzt.forEach(r),wnt=i(ma),nn=n(ma,"P",{});var yF=s(nn);Ant=t(yF,"The model class to instantiate is selected based on the "),ece=n(yF,"EM",{});var Gzt=s(ece);xnt=t(Gzt,"model_type"),Gzt.forEach(r),Lnt=t(yF,` property of the config object (either
passed as an argument or loaded from `),oce=n(yF,"EM",{});var Ozt=s(oce);Bnt=t(Ozt,"pretrained_model_name_or_path"),Ozt.forEach(r),knt=t(yF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),tce=n(yF,"EM",{});var qzt=s(tce);Rnt=t(qzt,"pretrained_model_name_or_path"),qzt.forEach(r),Snt=t(yF,":"),yF.forEach(r),Pnt=i(ma),Ee=n(ma,"UL",{});var xo=s(Ee);eT=n(xo,"LI",{});var OMe=s(eT);rce=n(OMe,"STRONG",{});var zzt=s(rce);$nt=t(zzt,"albert"),zzt.forEach(r),Int=t(OMe," \u2014 "),IN=n(OMe,"A",{href:!0});var Xzt=s(IN);jnt=t(Xzt,"FlaxAlbertForSequenceClassification"),Xzt.forEach(r),Nnt=t(OMe," (ALBERT model)"),OMe.forEach(r),Dnt=i(xo),oT=n(xo,"LI",{});var qMe=s(oT);ace=n(qMe,"STRONG",{});var Wzt=s(ace);Gnt=t(Wzt,"bart"),Wzt.forEach(r),Ont=t(qMe," \u2014 "),jN=n(qMe,"A",{href:!0});var Vzt=s(jN);qnt=t(Vzt,"FlaxBartForSequenceClassification"),Vzt.forEach(r),znt=t(qMe," (BART model)"),qMe.forEach(r),Xnt=i(xo),tT=n(xo,"LI",{});var zMe=s(tT);nce=n(zMe,"STRONG",{});var Qzt=s(nce);Wnt=t(Qzt,"bert"),Qzt.forEach(r),Vnt=t(zMe," \u2014 "),NN=n(zMe,"A",{href:!0});var Hzt=s(NN);Qnt=t(Hzt,"FlaxBertForSequenceClassification"),Hzt.forEach(r),Hnt=t(zMe," (BERT model)"),zMe.forEach(r),Unt=i(xo),rT=n(xo,"LI",{});var XMe=s(rT);sce=n(XMe,"STRONG",{});var Uzt=s(sce);Jnt=t(Uzt,"big_bird"),Uzt.forEach(r),Knt=t(XMe," \u2014 "),DN=n(XMe,"A",{href:!0});var Jzt=s(DN);Ynt=t(Jzt,"FlaxBigBirdForSequenceClassification"),Jzt.forEach(r),Znt=t(XMe," (BigBird model)"),XMe.forEach(r),est=i(xo),aT=n(xo,"LI",{});var WMe=s(aT);lce=n(WMe,"STRONG",{});var Kzt=s(lce);ost=t(Kzt,"distilbert"),Kzt.forEach(r),tst=t(WMe," \u2014 "),GN=n(WMe,"A",{href:!0});var Yzt=s(GN);rst=t(Yzt,"FlaxDistilBertForSequenceClassification"),Yzt.forEach(r),ast=t(WMe," (DistilBERT model)"),WMe.forEach(r),nst=i(xo),nT=n(xo,"LI",{});var VMe=s(nT);ice=n(VMe,"STRONG",{});var Zzt=s(ice);sst=t(Zzt,"electra"),Zzt.forEach(r),lst=t(VMe," \u2014 "),ON=n(VMe,"A",{href:!0});var eXt=s(ON);ist=t(eXt,"FlaxElectraForSequenceClassification"),eXt.forEach(r),dst=t(VMe," (ELECTRA model)"),VMe.forEach(r),mst=i(xo),sT=n(xo,"LI",{});var QMe=s(sT);dce=n(QMe,"STRONG",{});var oXt=s(dce);fst=t(oXt,"mbart"),oXt.forEach(r),cst=t(QMe," \u2014 "),qN=n(QMe,"A",{href:!0});var tXt=s(qN);gst=t(tXt,"FlaxMBartForSequenceClassification"),tXt.forEach(r),hst=t(QMe," (mBART model)"),QMe.forEach(r),ust=i(xo),lT=n(xo,"LI",{});var HMe=s(lT);mce=n(HMe,"STRONG",{});var rXt=s(mce);pst=t(rXt,"roberta"),rXt.forEach(r),_st=t(HMe," \u2014 "),zN=n(HMe,"A",{href:!0});var aXt=s(zN);vst=t(aXt,"FlaxRobertaForSequenceClassification"),aXt.forEach(r),bst=t(HMe," (RoBERTa model)"),HMe.forEach(r),xo.forEach(r),Tst=i(ma),fce=n(ma,"P",{});var nXt=s(fce);Fst=t(nXt,"Examples:"),nXt.forEach(r),Mst=i(ma),c(Zy.$$.fragment,ma),ma.forEach(r),kl.forEach(r),YCe=i(d),cm=n(d,"H2",{class:!0});var Jye=s(cm);iT=n(Jye,"A",{id:!0,class:!0,href:!0});var sXt=s(iT);cce=n(sXt,"SPAN",{});var lXt=s(cce);c(ew.$$.fragment,lXt),lXt.forEach(r),sXt.forEach(r),Est=i(Jye),gce=n(Jye,"SPAN",{});var iXt=s(gce);Cst=t(iXt,"FlaxAutoModelForQuestionAnswering"),iXt.forEach(r),Jye.forEach(r),ZCe=i(d),vt=n(d,"DIV",{class:!0});var Sl=s(vt);c(ow.$$.fragment,Sl),yst=i(Sl),gm=n(Sl,"P",{});var GG=s(gm);wst=t(GG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hce=n(GG,"CODE",{});var dXt=s(hce);Ast=t(dXt,"from_pretrained()"),dXt.forEach(r),xst=t(GG,` class method or the
`),uce=n(GG,"CODE",{});var mXt=s(uce);Lst=t(mXt,"from_config()"),mXt.forEach(r),Bst=t(GG," class method."),GG.forEach(r),kst=i(Sl),tw=n(Sl,"P",{});var Kye=s(tw);Rst=t(Kye,"This class cannot be instantiated directly using "),pce=n(Kye,"CODE",{});var fXt=s(pce);Sst=t(fXt,"__init__()"),fXt.forEach(r),Pst=t(Kye," (throws an error)."),Kye.forEach(r),$st=i(Sl),dr=n(Sl,"DIV",{class:!0});var Pl=s(dr);c(rw.$$.fragment,Pl),Ist=i(Pl),_ce=n(Pl,"P",{});var cXt=s(_ce);jst=t(cXt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cXt.forEach(r),Nst=i(Pl),hm=n(Pl,"P",{});var OG=s(hm);Dst=t(OG,`Note:
Loading a model from its configuration file does `),vce=n(OG,"STRONG",{});var gXt=s(vce);Gst=t(gXt,"not"),gXt.forEach(r),Ost=t(OG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),bce=n(OG,"EM",{});var hXt=s(bce);qst=t(hXt,"~FlaxAutoModelForQuestionAnswering.from_pretrained"),hXt.forEach(r),zst=t(OG,`] to load the model
weights.`),OG.forEach(r),Xst=i(Pl),Tce=n(Pl,"P",{});var uXt=s(Tce);Wst=t(uXt,"Examples:"),uXt.forEach(r),Vst=i(Pl),c(aw.$$.fragment,Pl),Pl.forEach(r),Qst=i(Sl),Fo=n(Sl,"DIV",{class:!0});var fa=s(Fo);c(nw.$$.fragment,fa),Hst=i(fa),Fce=n(fa,"P",{});var pXt=s(Fce);Ust=t(pXt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),pXt.forEach(r),Jst=i(fa),sn=n(fa,"P",{});var wF=s(sn);Kst=t(wF,"The model class to instantiate is selected based on the "),Mce=n(wF,"EM",{});var _Xt=s(Mce);Yst=t(_Xt,"model_type"),_Xt.forEach(r),Zst=t(wF,` property of the config object (either
passed as an argument or loaded from `),Ece=n(wF,"EM",{});var vXt=s(Ece);elt=t(vXt,"pretrained_model_name_or_path"),vXt.forEach(r),olt=t(wF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Cce=n(wF,"EM",{});var bXt=s(Cce);tlt=t(bXt,"pretrained_model_name_or_path"),bXt.forEach(r),rlt=t(wF,":"),wF.forEach(r),alt=i(fa),Ce=n(fa,"UL",{});var Lo=s(Ce);dT=n(Lo,"LI",{});var UMe=s(dT);yce=n(UMe,"STRONG",{});var TXt=s(yce);nlt=t(TXt,"albert"),TXt.forEach(r),slt=t(UMe," \u2014 "),XN=n(UMe,"A",{href:!0});var FXt=s(XN);llt=t(FXt,"FlaxAlbertForQuestionAnswering"),FXt.forEach(r),ilt=t(UMe," (ALBERT model)"),UMe.forEach(r),dlt=i(Lo),mT=n(Lo,"LI",{});var JMe=s(mT);wce=n(JMe,"STRONG",{});var MXt=s(wce);mlt=t(MXt,"bart"),MXt.forEach(r),flt=t(JMe," \u2014 "),WN=n(JMe,"A",{href:!0});var EXt=s(WN);clt=t(EXt,"FlaxBartForQuestionAnswering"),EXt.forEach(r),glt=t(JMe," (BART model)"),JMe.forEach(r),hlt=i(Lo),fT=n(Lo,"LI",{});var KMe=s(fT);Ace=n(KMe,"STRONG",{});var CXt=s(Ace);ult=t(CXt,"bert"),CXt.forEach(r),plt=t(KMe," \u2014 "),VN=n(KMe,"A",{href:!0});var yXt=s(VN);_lt=t(yXt,"FlaxBertForQuestionAnswering"),yXt.forEach(r),vlt=t(KMe," (BERT model)"),KMe.forEach(r),blt=i(Lo),cT=n(Lo,"LI",{});var YMe=s(cT);xce=n(YMe,"STRONG",{});var wXt=s(xce);Tlt=t(wXt,"big_bird"),wXt.forEach(r),Flt=t(YMe," \u2014 "),QN=n(YMe,"A",{href:!0});var AXt=s(QN);Mlt=t(AXt,"FlaxBigBirdForQuestionAnswering"),AXt.forEach(r),Elt=t(YMe," (BigBird model)"),YMe.forEach(r),Clt=i(Lo),gT=n(Lo,"LI",{});var ZMe=s(gT);Lce=n(ZMe,"STRONG",{});var xXt=s(Lce);ylt=t(xXt,"distilbert"),xXt.forEach(r),wlt=t(ZMe," \u2014 "),HN=n(ZMe,"A",{href:!0});var LXt=s(HN);Alt=t(LXt,"FlaxDistilBertForQuestionAnswering"),LXt.forEach(r),xlt=t(ZMe," (DistilBERT model)"),ZMe.forEach(r),Llt=i(Lo),hT=n(Lo,"LI",{});var eEe=s(hT);Bce=n(eEe,"STRONG",{});var BXt=s(Bce);Blt=t(BXt,"electra"),BXt.forEach(r),klt=t(eEe," \u2014 "),UN=n(eEe,"A",{href:!0});var kXt=s(UN);Rlt=t(kXt,"FlaxElectraForQuestionAnswering"),kXt.forEach(r),Slt=t(eEe," (ELECTRA model)"),eEe.forEach(r),Plt=i(Lo),uT=n(Lo,"LI",{});var oEe=s(uT);kce=n(oEe,"STRONG",{});var RXt=s(kce);$lt=t(RXt,"mbart"),RXt.forEach(r),Ilt=t(oEe," \u2014 "),JN=n(oEe,"A",{href:!0});var SXt=s(JN);jlt=t(SXt,"FlaxMBartForQuestionAnswering"),SXt.forEach(r),Nlt=t(oEe," (mBART model)"),oEe.forEach(r),Dlt=i(Lo),pT=n(Lo,"LI",{});var tEe=s(pT);Rce=n(tEe,"STRONG",{});var PXt=s(Rce);Glt=t(PXt,"roberta"),PXt.forEach(r),Olt=t(tEe," \u2014 "),KN=n(tEe,"A",{href:!0});var $Xt=s(KN);qlt=t($Xt,"FlaxRobertaForQuestionAnswering"),$Xt.forEach(r),zlt=t(tEe," (RoBERTa model)"),tEe.forEach(r),Lo.forEach(r),Xlt=i(fa),Sce=n(fa,"P",{});var IXt=s(Sce);Wlt=t(IXt,"Examples:"),IXt.forEach(r),Vlt=i(fa),c(sw.$$.fragment,fa),fa.forEach(r),Sl.forEach(r),e3e=i(d),um=n(d,"H2",{class:!0});var Yye=s(um);_T=n(Yye,"A",{id:!0,class:!0,href:!0});var jXt=s(_T);Pce=n(jXt,"SPAN",{});var NXt=s(Pce);c(lw.$$.fragment,NXt),NXt.forEach(r),jXt.forEach(r),Qlt=i(Yye),$ce=n(Yye,"SPAN",{});var DXt=s($ce);Hlt=t(DXt,"FlaxAutoModelForTokenClassification"),DXt.forEach(r),Yye.forEach(r),o3e=i(d),bt=n(d,"DIV",{class:!0});var $l=s(bt);c(iw.$$.fragment,$l),Ult=i($l),pm=n($l,"P",{});var qG=s(pm);Jlt=t(qG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Ice=n(qG,"CODE",{});var GXt=s(Ice);Klt=t(GXt,"from_pretrained()"),GXt.forEach(r),Ylt=t(qG,` class method or the
`),jce=n(qG,"CODE",{});var OXt=s(jce);Zlt=t(OXt,"from_config()"),OXt.forEach(r),eit=t(qG," class method."),qG.forEach(r),oit=i($l),dw=n($l,"P",{});var Zye=s(dw);tit=t(Zye,"This class cannot be instantiated directly using "),Nce=n(Zye,"CODE",{});var qXt=s(Nce);rit=t(qXt,"__init__()"),qXt.forEach(r),ait=t(Zye," (throws an error)."),Zye.forEach(r),nit=i($l),mr=n($l,"DIV",{class:!0});var Il=s(mr);c(mw.$$.fragment,Il),sit=i(Il),Dce=n(Il,"P",{});var zXt=s(Dce);lit=t(zXt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),zXt.forEach(r),iit=i(Il),_m=n(Il,"P",{});var zG=s(_m);dit=t(zG,`Note:
Loading a model from its configuration file does `),Gce=n(zG,"STRONG",{});var XXt=s(Gce);mit=t(XXt,"not"),XXt.forEach(r),fit=t(zG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Oce=n(zG,"EM",{});var WXt=s(Oce);cit=t(WXt,"~FlaxAutoModelForTokenClassification.from_pretrained"),WXt.forEach(r),git=t(zG,`] to load the model
weights.`),zG.forEach(r),hit=i(Il),qce=n(Il,"P",{});var VXt=s(qce);uit=t(VXt,"Examples:"),VXt.forEach(r),pit=i(Il),c(fw.$$.fragment,Il),Il.forEach(r),_it=i($l),Mo=n($l,"DIV",{class:!0});var ca=s(Mo);c(cw.$$.fragment,ca),vit=i(ca),zce=n(ca,"P",{});var QXt=s(zce);bit=t(QXt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),QXt.forEach(r),Tit=i(ca),ln=n(ca,"P",{});var AF=s(ln);Fit=t(AF,"The model class to instantiate is selected based on the "),Xce=n(AF,"EM",{});var HXt=s(Xce);Mit=t(HXt,"model_type"),HXt.forEach(r),Eit=t(AF,` property of the config object (either
passed as an argument or loaded from `),Wce=n(AF,"EM",{});var UXt=s(Wce);Cit=t(UXt,"pretrained_model_name_or_path"),UXt.forEach(r),yit=t(AF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Vce=n(AF,"EM",{});var JXt=s(Vce);wit=t(JXt,"pretrained_model_name_or_path"),JXt.forEach(r),Ait=t(AF,":"),AF.forEach(r),xit=i(ca),Tt=n(ca,"UL",{});var ga=s(Tt);vT=n(ga,"LI",{});var rEe=s(vT);Qce=n(rEe,"STRONG",{});var KXt=s(Qce);Lit=t(KXt,"albert"),KXt.forEach(r),Bit=t(rEe," \u2014 "),YN=n(rEe,"A",{href:!0});var YXt=s(YN);kit=t(YXt,"FlaxAlbertForTokenClassification"),YXt.forEach(r),Rit=t(rEe," (ALBERT model)"),rEe.forEach(r),Sit=i(ga),bT=n(ga,"LI",{});var aEe=s(bT);Hce=n(aEe,"STRONG",{});var ZXt=s(Hce);Pit=t(ZXt,"bert"),ZXt.forEach(r),$it=t(aEe," \u2014 "),ZN=n(aEe,"A",{href:!0});var eWt=s(ZN);Iit=t(eWt,"FlaxBertForTokenClassification"),eWt.forEach(r),jit=t(aEe," (BERT model)"),aEe.forEach(r),Nit=i(ga),TT=n(ga,"LI",{});var nEe=s(TT);Uce=n(nEe,"STRONG",{});var oWt=s(Uce);Dit=t(oWt,"big_bird"),oWt.forEach(r),Git=t(nEe," \u2014 "),eD=n(nEe,"A",{href:!0});var tWt=s(eD);Oit=t(tWt,"FlaxBigBirdForTokenClassification"),tWt.forEach(r),qit=t(nEe," (BigBird model)"),nEe.forEach(r),zit=i(ga),FT=n(ga,"LI",{});var sEe=s(FT);Jce=n(sEe,"STRONG",{});var rWt=s(Jce);Xit=t(rWt,"distilbert"),rWt.forEach(r),Wit=t(sEe," \u2014 "),oD=n(sEe,"A",{href:!0});var aWt=s(oD);Vit=t(aWt,"FlaxDistilBertForTokenClassification"),aWt.forEach(r),Qit=t(sEe," (DistilBERT model)"),sEe.forEach(r),Hit=i(ga),MT=n(ga,"LI",{});var lEe=s(MT);Kce=n(lEe,"STRONG",{});var nWt=s(Kce);Uit=t(nWt,"electra"),nWt.forEach(r),Jit=t(lEe," \u2014 "),tD=n(lEe,"A",{href:!0});var sWt=s(tD);Kit=t(sWt,"FlaxElectraForTokenClassification"),sWt.forEach(r),Yit=t(lEe," (ELECTRA model)"),lEe.forEach(r),Zit=i(ga),ET=n(ga,"LI",{});var iEe=s(ET);Yce=n(iEe,"STRONG",{});var lWt=s(Yce);edt=t(lWt,"roberta"),lWt.forEach(r),odt=t(iEe," \u2014 "),rD=n(iEe,"A",{href:!0});var iWt=s(rD);tdt=t(iWt,"FlaxRobertaForTokenClassification"),iWt.forEach(r),rdt=t(iEe," (RoBERTa model)"),iEe.forEach(r),ga.forEach(r),adt=i(ca),Zce=n(ca,"P",{});var dWt=s(Zce);ndt=t(dWt,"Examples:"),dWt.forEach(r),sdt=i(ca),c(gw.$$.fragment,ca),ca.forEach(r),$l.forEach(r),t3e=i(d),vm=n(d,"H2",{class:!0});var ewe=s(vm);CT=n(ewe,"A",{id:!0,class:!0,href:!0});var mWt=s(CT);ege=n(mWt,"SPAN",{});var fWt=s(ege);c(hw.$$.fragment,fWt),fWt.forEach(r),mWt.forEach(r),ldt=i(ewe),oge=n(ewe,"SPAN",{});var cWt=s(oge);idt=t(cWt,"FlaxAutoModelForMultipleChoice"),cWt.forEach(r),ewe.forEach(r),r3e=i(d),Ft=n(d,"DIV",{class:!0});var jl=s(Ft);c(uw.$$.fragment,jl),ddt=i(jl),bm=n(jl,"P",{});var XG=s(bm);mdt=t(XG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),tge=n(XG,"CODE",{});var gWt=s(tge);fdt=t(gWt,"from_pretrained()"),gWt.forEach(r),cdt=t(XG,` class method or the
`),rge=n(XG,"CODE",{});var hWt=s(rge);gdt=t(hWt,"from_config()"),hWt.forEach(r),hdt=t(XG," class method."),XG.forEach(r),udt=i(jl),pw=n(jl,"P",{});var owe=s(pw);pdt=t(owe,"This class cannot be instantiated directly using "),age=n(owe,"CODE",{});var uWt=s(age);_dt=t(uWt,"__init__()"),uWt.forEach(r),vdt=t(owe," (throws an error)."),owe.forEach(r),bdt=i(jl),fr=n(jl,"DIV",{class:!0});var Nl=s(fr);c(_w.$$.fragment,Nl),Tdt=i(Nl),nge=n(Nl,"P",{});var pWt=s(nge);Fdt=t(pWt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),pWt.forEach(r),Mdt=i(Nl),Tm=n(Nl,"P",{});var WG=s(Tm);Edt=t(WG,`Note:
Loading a model from its configuration file does `),sge=n(WG,"STRONG",{});var _Wt=s(sge);Cdt=t(_Wt,"not"),_Wt.forEach(r),ydt=t(WG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),lge=n(WG,"EM",{});var vWt=s(lge);wdt=t(vWt,"~FlaxAutoModelForMultipleChoice.from_pretrained"),vWt.forEach(r),Adt=t(WG,`] to load the model
weights.`),WG.forEach(r),xdt=i(Nl),ige=n(Nl,"P",{});var bWt=s(ige);Ldt=t(bWt,"Examples:"),bWt.forEach(r),Bdt=i(Nl),c(vw.$$.fragment,Nl),Nl.forEach(r),kdt=i(jl),Eo=n(jl,"DIV",{class:!0});var ha=s(Eo);c(bw.$$.fragment,ha),Rdt=i(ha),dge=n(ha,"P",{});var TWt=s(dge);Sdt=t(TWt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),TWt.forEach(r),Pdt=i(ha),dn=n(ha,"P",{});var xF=s(dn);$dt=t(xF,"The model class to instantiate is selected based on the "),mge=n(xF,"EM",{});var FWt=s(mge);Idt=t(FWt,"model_type"),FWt.forEach(r),jdt=t(xF,` property of the config object (either
passed as an argument or loaded from `),fge=n(xF,"EM",{});var MWt=s(fge);Ndt=t(MWt,"pretrained_model_name_or_path"),MWt.forEach(r),Ddt=t(xF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),cge=n(xF,"EM",{});var EWt=s(cge);Gdt=t(EWt,"pretrained_model_name_or_path"),EWt.forEach(r),Odt=t(xF,":"),xF.forEach(r),qdt=i(ha),Mt=n(ha,"UL",{});var ua=s(Mt);yT=n(ua,"LI",{});var dEe=s(yT);gge=n(dEe,"STRONG",{});var CWt=s(gge);zdt=t(CWt,"albert"),CWt.forEach(r),Xdt=t(dEe," \u2014 "),aD=n(dEe,"A",{href:!0});var yWt=s(aD);Wdt=t(yWt,"FlaxAlbertForMultipleChoice"),yWt.forEach(r),Vdt=t(dEe," (ALBERT model)"),dEe.forEach(r),Qdt=i(ua),wT=n(ua,"LI",{});var mEe=s(wT);hge=n(mEe,"STRONG",{});var wWt=s(hge);Hdt=t(wWt,"bert"),wWt.forEach(r),Udt=t(mEe," \u2014 "),nD=n(mEe,"A",{href:!0});var AWt=s(nD);Jdt=t(AWt,"FlaxBertForMultipleChoice"),AWt.forEach(r),Kdt=t(mEe," (BERT model)"),mEe.forEach(r),Ydt=i(ua),AT=n(ua,"LI",{});var fEe=s(AT);uge=n(fEe,"STRONG",{});var xWt=s(uge);Zdt=t(xWt,"big_bird"),xWt.forEach(r),emt=t(fEe," \u2014 "),sD=n(fEe,"A",{href:!0});var LWt=s(sD);omt=t(LWt,"FlaxBigBirdForMultipleChoice"),LWt.forEach(r),tmt=t(fEe," (BigBird model)"),fEe.forEach(r),rmt=i(ua),xT=n(ua,"LI",{});var cEe=s(xT);pge=n(cEe,"STRONG",{});var BWt=s(pge);amt=t(BWt,"distilbert"),BWt.forEach(r),nmt=t(cEe," \u2014 "),lD=n(cEe,"A",{href:!0});var kWt=s(lD);smt=t(kWt,"FlaxDistilBertForMultipleChoice"),kWt.forEach(r),lmt=t(cEe," (DistilBERT model)"),cEe.forEach(r),imt=i(ua),LT=n(ua,"LI",{});var gEe=s(LT);_ge=n(gEe,"STRONG",{});var RWt=s(_ge);dmt=t(RWt,"electra"),RWt.forEach(r),mmt=t(gEe," \u2014 "),iD=n(gEe,"A",{href:!0});var SWt=s(iD);fmt=t(SWt,"FlaxElectraForMultipleChoice"),SWt.forEach(r),cmt=t(gEe," (ELECTRA model)"),gEe.forEach(r),gmt=i(ua),BT=n(ua,"LI",{});var hEe=s(BT);vge=n(hEe,"STRONG",{});var PWt=s(vge);hmt=t(PWt,"roberta"),PWt.forEach(r),umt=t(hEe," \u2014 "),dD=n(hEe,"A",{href:!0});var $Wt=s(dD);pmt=t($Wt,"FlaxRobertaForMultipleChoice"),$Wt.forEach(r),_mt=t(hEe," (RoBERTa model)"),hEe.forEach(r),ua.forEach(r),vmt=i(ha),bge=n(ha,"P",{});var IWt=s(bge);bmt=t(IWt,"Examples:"),IWt.forEach(r),Tmt=i(ha),c(Tw.$$.fragment,ha),ha.forEach(r),jl.forEach(r),a3e=i(d),Fm=n(d,"H2",{class:!0});var twe=s(Fm);kT=n(twe,"A",{id:!0,class:!0,href:!0});var jWt=s(kT);Tge=n(jWt,"SPAN",{});var NWt=s(Tge);c(Fw.$$.fragment,NWt),NWt.forEach(r),jWt.forEach(r),Fmt=i(twe),Fge=n(twe,"SPAN",{});var DWt=s(Fge);Mmt=t(DWt,"FlaxAutoModelForNextSentencePrediction"),DWt.forEach(r),twe.forEach(r),n3e=i(d),Et=n(d,"DIV",{class:!0});var Dl=s(Et);c(Mw.$$.fragment,Dl),Emt=i(Dl),Mm=n(Dl,"P",{});var VG=s(Mm);Cmt=t(VG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Mge=n(VG,"CODE",{});var GWt=s(Mge);ymt=t(GWt,"from_pretrained()"),GWt.forEach(r),wmt=t(VG,` class method or the
`),Ege=n(VG,"CODE",{});var OWt=s(Ege);Amt=t(OWt,"from_config()"),OWt.forEach(r),xmt=t(VG," class method."),VG.forEach(r),Lmt=i(Dl),Ew=n(Dl,"P",{});var rwe=s(Ew);Bmt=t(rwe,"This class cannot be instantiated directly using "),Cge=n(rwe,"CODE",{});var qWt=s(Cge);kmt=t(qWt,"__init__()"),qWt.forEach(r),Rmt=t(rwe," (throws an error)."),rwe.forEach(r),Smt=i(Dl),cr=n(Dl,"DIV",{class:!0});var Gl=s(cr);c(Cw.$$.fragment,Gl),Pmt=i(Gl),yge=n(Gl,"P",{});var zWt=s(yge);$mt=t(zWt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),zWt.forEach(r),Imt=i(Gl),Em=n(Gl,"P",{});var QG=s(Em);jmt=t(QG,`Note:
Loading a model from its configuration file does `),wge=n(QG,"STRONG",{});var XWt=s(wge);Nmt=t(XWt,"not"),XWt.forEach(r),Dmt=t(QG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),Age=n(QG,"EM",{});var WWt=s(Age);Gmt=t(WWt,"~FlaxAutoModelForNextSentencePrediction.from_pretrained"),WWt.forEach(r),Omt=t(QG,`] to load the model
weights.`),QG.forEach(r),qmt=i(Gl),xge=n(Gl,"P",{});var VWt=s(xge);zmt=t(VWt,"Examples:"),VWt.forEach(r),Xmt=i(Gl),c(yw.$$.fragment,Gl),Gl.forEach(r),Wmt=i(Dl),Co=n(Dl,"DIV",{class:!0});var pa=s(Co);c(ww.$$.fragment,pa),Vmt=i(pa),Lge=n(pa,"P",{});var QWt=s(Lge);Qmt=t(QWt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),QWt.forEach(r),Hmt=i(pa),mn=n(pa,"P",{});var LF=s(mn);Umt=t(LF,"The model class to instantiate is selected based on the "),Bge=n(LF,"EM",{});var HWt=s(Bge);Jmt=t(HWt,"model_type"),HWt.forEach(r),Kmt=t(LF,` property of the config object (either
passed as an argument or loaded from `),kge=n(LF,"EM",{});var UWt=s(kge);Ymt=t(UWt,"pretrained_model_name_or_path"),UWt.forEach(r),Zmt=t(LF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Rge=n(LF,"EM",{});var JWt=s(Rge);eft=t(JWt,"pretrained_model_name_or_path"),JWt.forEach(r),oft=t(LF,":"),LF.forEach(r),tft=i(pa),Sge=n(pa,"UL",{});var KWt=s(Sge);RT=n(KWt,"LI",{});var uEe=s(RT);Pge=n(uEe,"STRONG",{});var YWt=s(Pge);rft=t(YWt,"bert"),YWt.forEach(r),aft=t(uEe," \u2014 "),mD=n(uEe,"A",{href:!0});var ZWt=s(mD);nft=t(ZWt,"FlaxBertForNextSentencePrediction"),ZWt.forEach(r),sft=t(uEe," (BERT model)"),uEe.forEach(r),KWt.forEach(r),lft=i(pa),$ge=n(pa,"P",{});var eVt=s($ge);ift=t(eVt,"Examples:"),eVt.forEach(r),dft=i(pa),c(Aw.$$.fragment,pa),pa.forEach(r),Dl.forEach(r),s3e=i(d),Cm=n(d,"H2",{class:!0});var awe=s(Cm);ST=n(awe,"A",{id:!0,class:!0,href:!0});var oVt=s(ST);Ige=n(oVt,"SPAN",{});var tVt=s(Ige);c(xw.$$.fragment,tVt),tVt.forEach(r),oVt.forEach(r),mft=i(awe),jge=n(awe,"SPAN",{});var rVt=s(jge);fft=t(rVt,"FlaxAutoModelForImageClassification"),rVt.forEach(r),awe.forEach(r),l3e=i(d),Ct=n(d,"DIV",{class:!0});var Ol=s(Ct);c(Lw.$$.fragment,Ol),cft=i(Ol),ym=n(Ol,"P",{});var HG=s(ym);gft=t(HG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Nge=n(HG,"CODE",{});var aVt=s(Nge);hft=t(aVt,"from_pretrained()"),aVt.forEach(r),uft=t(HG,` class method or the
`),Dge=n(HG,"CODE",{});var nVt=s(Dge);pft=t(nVt,"from_config()"),nVt.forEach(r),_ft=t(HG," class method."),HG.forEach(r),vft=i(Ol),Bw=n(Ol,"P",{});var nwe=s(Bw);bft=t(nwe,"This class cannot be instantiated directly using "),Gge=n(nwe,"CODE",{});var sVt=s(Gge);Tft=t(sVt,"__init__()"),sVt.forEach(r),Fft=t(nwe," (throws an error)."),nwe.forEach(r),Mft=i(Ol),gr=n(Ol,"DIV",{class:!0});var ql=s(gr);c(kw.$$.fragment,ql),Eft=i(ql),Oge=n(ql,"P",{});var lVt=s(Oge);Cft=t(lVt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),lVt.forEach(r),yft=i(ql),wm=n(ql,"P",{});var UG=s(wm);wft=t(UG,`Note:
Loading a model from its configuration file does `),qge=n(UG,"STRONG",{});var iVt=s(qge);Aft=t(iVt,"not"),iVt.forEach(r),xft=t(UG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),zge=n(UG,"EM",{});var dVt=s(zge);Lft=t(dVt,"~FlaxAutoModelForImageClassification.from_pretrained"),dVt.forEach(r),Bft=t(UG,`] to load the model
weights.`),UG.forEach(r),kft=i(ql),Xge=n(ql,"P",{});var mVt=s(Xge);Rft=t(mVt,"Examples:"),mVt.forEach(r),Sft=i(ql),c(Rw.$$.fragment,ql),ql.forEach(r),Pft=i(Ol),yo=n(Ol,"DIV",{class:!0});var _a=s(yo);c(Sw.$$.fragment,_a),$ft=i(_a),Wge=n(_a,"P",{});var fVt=s(Wge);Ift=t(fVt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),fVt.forEach(r),jft=i(_a),fn=n(_a,"P",{});var BF=s(fn);Nft=t(BF,"The model class to instantiate is selected based on the "),Vge=n(BF,"EM",{});var cVt=s(Vge);Dft=t(cVt,"model_type"),cVt.forEach(r),Gft=t(BF,` property of the config object (either
passed as an argument or loaded from `),Qge=n(BF,"EM",{});var gVt=s(Qge);Oft=t(gVt,"pretrained_model_name_or_path"),gVt.forEach(r),qft=t(BF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),Hge=n(BF,"EM",{});var hVt=s(Hge);zft=t(hVt,"pretrained_model_name_or_path"),hVt.forEach(r),Xft=t(BF,":"),BF.forEach(r),Wft=i(_a),Pw=n(_a,"UL",{});var swe=s(Pw);PT=n(swe,"LI",{});var pEe=s(PT);Uge=n(pEe,"STRONG",{});var uVt=s(Uge);Vft=t(uVt,"beit"),uVt.forEach(r),Qft=t(pEe," \u2014 "),fD=n(pEe,"A",{href:!0});var pVt=s(fD);Hft=t(pVt,"FlaxBeitForImageClassification"),pVt.forEach(r),Uft=t(pEe," (BEiT model)"),pEe.forEach(r),Jft=i(swe),$T=n(swe,"LI",{});var _Ee=s($T);Jge=n(_Ee,"STRONG",{});var _Vt=s(Jge);Kft=t(_Vt,"vit"),_Vt.forEach(r),Yft=t(_Ee," \u2014 "),cD=n(_Ee,"A",{href:!0});var vVt=s(cD);Zft=t(vVt,"FlaxViTForImageClassification"),vVt.forEach(r),ect=t(_Ee," (ViT model)"),_Ee.forEach(r),swe.forEach(r),oct=i(_a),Kge=n(_a,"P",{});var bVt=s(Kge);tct=t(bVt,"Examples:"),bVt.forEach(r),rct=i(_a),c($w.$$.fragment,_a),_a.forEach(r),Ol.forEach(r),i3e=i(d),Am=n(d,"H2",{class:!0});var lwe=s(Am);IT=n(lwe,"A",{id:!0,class:!0,href:!0});var TVt=s(IT);Yge=n(TVt,"SPAN",{});var FVt=s(Yge);c(Iw.$$.fragment,FVt),FVt.forEach(r),TVt.forEach(r),act=i(lwe),Zge=n(lwe,"SPAN",{});var MVt=s(Zge);nct=t(MVt,"FlaxAutoModelForVision2Seq"),MVt.forEach(r),lwe.forEach(r),d3e=i(d),yt=n(d,"DIV",{class:!0});var zl=s(yt);c(jw.$$.fragment,zl),sct=i(zl),xm=n(zl,"P",{});var JG=s(xm);lct=t(JG,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ehe=n(JG,"CODE",{});var EVt=s(ehe);ict=t(EVt,"from_pretrained()"),EVt.forEach(r),dct=t(JG,` class method or the
`),ohe=n(JG,"CODE",{});var CVt=s(ohe);mct=t(CVt,"from_config()"),CVt.forEach(r),fct=t(JG," class method."),JG.forEach(r),cct=i(zl),Nw=n(zl,"P",{});var iwe=s(Nw);gct=t(iwe,"This class cannot be instantiated directly using "),the=n(iwe,"CODE",{});var yVt=s(the);hct=t(yVt,"__init__()"),yVt.forEach(r),uct=t(iwe," (throws an error)."),iwe.forEach(r),pct=i(zl),hr=n(zl,"DIV",{class:!0});var Xl=s(hr);c(Dw.$$.fragment,Xl),_ct=i(Xl),rhe=n(Xl,"P",{});var wVt=s(rhe);vct=t(wVt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),wVt.forEach(r),bct=i(Xl),Lm=n(Xl,"P",{});var KG=s(Lm);Tct=t(KG,`Note:
Loading a model from its configuration file does `),ahe=n(KG,"STRONG",{});var AVt=s(ahe);Fct=t(AVt,"not"),AVt.forEach(r),Mct=t(KG,` load the model weights. It only affects the
model\u2019s configuration. Use [`),nhe=n(KG,"EM",{});var xVt=s(nhe);Ect=t(xVt,"~FlaxAutoModelForVision2Seq.from_pretrained"),xVt.forEach(r),Cct=t(KG,`] to load the model
weights.`),KG.forEach(r),yct=i(Xl),she=n(Xl,"P",{});var LVt=s(she);wct=t(LVt,"Examples:"),LVt.forEach(r),Act=i(Xl),c(Gw.$$.fragment,Xl),Xl.forEach(r),xct=i(zl),wo=n(zl,"DIV",{class:!0});var va=s(wo);c(Ow.$$.fragment,va),Lct=i(va),lhe=n(va,"P",{});var BVt=s(lhe);Bct=t(BVt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),BVt.forEach(r),kct=i(va),cn=n(va,"P",{});var kF=s(cn);Rct=t(kF,"The model class to instantiate is selected based on the "),ihe=n(kF,"EM",{});var kVt=s(ihe);Sct=t(kVt,"model_type"),kVt.forEach(r),Pct=t(kF,` property of the config object (either
passed as an argument or loaded from `),dhe=n(kF,"EM",{});var RVt=s(dhe);$ct=t(RVt,"pretrained_model_name_or_path"),RVt.forEach(r),Ict=t(kF,` if possible), or when it\u2019s missing,
by falling back to using pattern matching on `),mhe=n(kF,"EM",{});var SVt=s(mhe);jct=t(SVt,"pretrained_model_name_or_path"),SVt.forEach(r),Nct=t(kF,":"),kF.forEach(r),Dct=i(va),fhe=n(va,"UL",{});var PVt=s(fhe);jT=n(PVt,"LI",{});var vEe=s(jT);che=n(vEe,"STRONG",{});var $Vt=s(che);Gct=t($Vt,"vision-encoder-decoder"),$Vt.forEach(r),Oct=t(vEe," \u2014 "),gD=n(vEe,"A",{href:!0});var IVt=s(gD);qct=t(IVt,"FlaxVisionEncoderDecoderModel"),IVt.forEach(r),zct=t(vEe," (Vision Encoder decoder model)"),vEe.forEach(r),PVt.forEach(r),Xct=i(va),ghe=n(va,"P",{});var jVt=s(ghe);Wct=t(jVt,"Examples:"),jVt.forEach(r),Vct=i(va),c(qw.$$.fragment,va),va.forEach(r),zl.forEach(r),this.h()},h(){m(J,"name","hf:doc:metadata"),m(J,"content",JSON.stringify(VVt)),m(de,"id","auto-classes"),m(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(de,"href","#auto-classes"),m(se,"class","relative group"),m(gn,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoConfig"),m(un,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoModel"),m(pn,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoTokenizer"),m(Yl,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertModel"),m($m,"id","extending-the-auto-classes"),m($m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($m,"href","#extending-the-auto-classes"),m(Zl,"class","relative group"),m(jm,"id","transformers.AutoConfig"),m(jm,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(jm,"href","#transformers.AutoConfig"),m(ei,"class","relative group"),m(qA,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m(zA,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertConfig"),m(XA,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartConfig"),m(WA,"href","/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitConfig"),m(VA,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertConfig"),m(QA,"href","/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationConfig"),m(HA,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdConfig"),m(UA,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(JA,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(KA,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallConfig"),m(YA,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertConfig"),m(ZA,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineConfig"),m(e7,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPConfig"),m(o7,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertConfig"),m(t7,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLConfig"),m(r7,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaConfig"),m(a7,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Config"),m(n7,"href","/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTConfig"),m(s7,"href","/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrConfig"),m(l7,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertConfig"),m(i7,"href","/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRConfig"),m(d7,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraConfig"),m(m7,"href","/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.EncoderDecoderConfig"),m(f7,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertConfig"),m(c7,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetConfig"),m(g7,"href","/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTConfig"),m(h7,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelConfig"),m(u7,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Config"),m(p7,"href","/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(_7,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJConfig"),m(v7,"href","/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertConfig"),m(b7,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertConfig"),m(T7,"href","/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(F7,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(M7,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(E7,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDConfig"),m(C7,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerConfig"),m(y7,"href","/docs/transformers/v4.15.0/en/model_doc/luke#transformers.LukeConfig"),m(w7,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertConfig"),m(A7,"href","/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100Config"),m(x7,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianConfig"),m(L7,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartConfig"),m(B7,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertConfig"),m(k7,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(R7,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetConfig"),m(S7,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Config"),m(P7,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTConfig"),m($7,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusConfig"),m(I7,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverConfig"),m(j7,"href","/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(N7,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(D7,"href","/docs/transformers/v4.15.0/en/model_doc/rag#transformers.RagConfig"),m(G7,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerConfig"),m(O7,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertConfig"),m(q7,"href","/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertConfig"),m(z7,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaConfig"),m(X7,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerConfig"),m(W7,"href","/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerConfig"),m(V7,"href","/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWConfig"),m(Q7,"href","/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDConfig"),m(H7,"href","/docs/transformers/v4.15.0/en/model_doc/speechencoderdecoder#transformers.SpeechEncoderDecoderConfig"),m(U7,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(J7,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(K7,"href","/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterConfig"),m(Y7,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m(Z7,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Config"),m(ex,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasConfig"),m(ox,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLConfig"),m(tx,"href","/docs/transformers/v4.15.0/en/model_doc/trocr#transformers.TrOCRConfig"),m(rx,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(ax,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatConfig"),m(nx,"href","/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderConfig"),m(sx,"href","/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.VisionTextDualEncoderConfig"),m(lx,"href","/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(ix,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTConfig"),m(dx,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(mx,"href","/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMConfig"),m(fx,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMConfig"),m(cx,"href","/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetConfig"),m(gx,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaConfig"),m(hx,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetConfig"),m(oo,"class","docstring"),m(fc,"class","docstring"),m(Ro,"class","docstring"),m(cc,"id","transformers.AutoTokenizer"),m(cc,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cc,"href","#transformers.AutoTokenizer"),m(ti,"class","relative group"),m(ux,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(px,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertTokenizer"),m(_x,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(vx,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartTokenizer"),m(bx,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartTokenizerFast"),m(Tx,"href","/docs/transformers/v4.15.0/en/model_doc/barthez#transformers.BarthezTokenizer"),m(Fx,"href","/docs/transformers/v4.15.0/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(Mx,"href","/docs/transformers/v4.15.0/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(Ex,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertTokenizer"),m(Cx,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertTokenizerFast"),m(yx,"href","/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationTokenizer"),m(wx,"href","/docs/transformers/v4.15.0/en/model_doc/bert_japanese#transformers.BertJapaneseTokenizer"),m(Ax,"href","/docs/transformers/v4.15.0/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(xx,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdTokenizer"),m(Lx,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdTokenizerFast"),m(Bx,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(kx,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(Rx,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(Sx,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(Px,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallTokenizer"),m($x,"href","/docs/transformers/v4.15.0/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(Ix,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertTokenizer"),m(jx,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(Nx,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineTokenizer"),m(Dx,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPTokenizer"),m(Gx,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(Ox,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(qx,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(zx,"href","/docs/transformers/v4.15.0/en/model_doc/cpm#transformers.CpmTokenizer"),m(Xx,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLTokenizer"),m(Wx,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaTokenizer"),m(Vx,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(Qx,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Tokenizer"),m(Hx,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(Ux,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(Jx,"href","/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(Kx,"href","/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(Yx,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraTokenizer"),m(Zx,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(e6,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(o6,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetTokenizer"),m(t6,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(r6,"href","/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(a6,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelTokenizer"),m(n6,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(s6,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(l6,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(i6,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(d6,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(m6,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(f6,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaTokenizer"),m(c6,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(g6,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(h6,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(u6,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m(p6,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(_6,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDTokenizer"),m(v6,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDTokenizerFast"),m(b6,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerTokenizer"),m(T6,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(F6,"href","/docs/transformers/v4.15.0/en/model_doc/luke#transformers.LukeTokenizer"),m(M6,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertTokenizer"),m(E6,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(C6,"href","/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(y6,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianTokenizer"),m(w6,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartTokenizer"),m(A6,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(x6,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(L6,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(B6,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(k6,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(R6,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(S6,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(P6,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.T5Tokenizer"),m($6,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.T5TokenizerFast"),m(I6,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTTokenizer"),m(j6,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTTokenizerFast"),m(N6,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(D6,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(G6,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(O6,"href","/docs/transformers/v4.15.0/en/model_doc/phobert#transformers.PhobertTokenizer"),m(q6,"href","/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(z6,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertTokenizer"),m(X6,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertTokenizerFast"),m(W6,"href","/docs/transformers/v4.15.0/en/model_doc/rag#transformers.RagTokenizer"),m(V6,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerTokenizer"),m(Q6,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(H6,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertTokenizer"),m(U6,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(J6,"href","/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertTokenizer"),m(K6,"href","/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m(Y6,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaTokenizer"),m(Z6,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(e8,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerTokenizer"),m(o8,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(t8,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(r8,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(a8,"href","/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterTokenizer"),m(n8,"href","/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m(s8,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(l8,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(i8,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.T5Tokenizer"),m(d8,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.T5TokenizerFast"),m(m8,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasTokenizer"),m(f8,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLTokenizer"),m(c8,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(g8,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMTokenizer"),m(h8,"href","/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetTokenizer"),m(u8,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaTokenizer"),m(p8,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaTokenizerFast"),m(_8,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(v8,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(to,"class","docstring"),m(Dc,"class","docstring"),m(So,"class","docstring"),m(Gc,"id","transformers.AutoFeatureExtractor"),m(Gc,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Gc,"href","#transformers.AutoFeatureExtractor"),m(ri,"class","relative group"),m(b8,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(T8,"href","/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(F8,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(M8,"href","/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTFeatureExtractor"),m(E8,"href","/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(C8,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(y8,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),m(w8,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),m(A8,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(x8,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(L8,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(we,"class","docstring"),m(Gr,"class","docstring"),m(Yc,"id","transformers.AutoProcessor"),m(Yc,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Yc,"href","#transformers.AutoProcessor"),m(ai,"class","relative group"),m(B8,"href","/docs/transformers/v4.15.0/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(k8,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPProcessor"),m(R8,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(S8,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(P8,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m($8,"href","/docs/transformers/v4.15.0/en/model_doc/trocr#transformers.TrOCRProcessor"),m(I8,"href","/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.VisionTextDualEncoderProcessor"),m(j8,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(Ae,"class","docstring"),m(Or,"class","docstring"),m(lg,"id","transformers.AutoModel"),m(lg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(lg,"href","#transformers.AutoModel"),m(si,"class","relative group"),m(wt,"class","docstring"),m(N8,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertModel"),m(D8,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartModel"),m(G8,"href","/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitModel"),m(O8,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertModel"),m(q8,"href","/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationEncoder"),m(z8,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdModel"),m(X8,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(W8,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotModel"),m(V8,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallModel"),m(Q8,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertModel"),m(H8,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineModel"),m(U8,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.CLIPModel"),m(J8,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertModel"),m(K8,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLModel"),m(Y8,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaModel"),m(Z8,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2Model"),m(eL,"href","/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTModel"),m(oL,"href","/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrModel"),m(tL,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertModel"),m(rL,"href","/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(aL,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraModel"),m(nL,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertModel"),m(sL,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetModel"),m(lL,"href","/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTModel"),m(iL,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelModel"),m(dL,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelBaseModel"),m(mL,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2Model"),m(fL,"href","/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(cL,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJModel"),m(gL,"href","/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertModel"),m(hL,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertModel"),m(uL,"href","/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(pL,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMModel"),m(_L,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(vL,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDModel"),m(bL,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerModel"),m(TL,"href","/docs/transformers/v4.15.0/en/model_doc/luke#transformers.LukeModel"),m(FL,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertModel"),m(ML,"href","/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100Model"),m(EL,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianModel"),m(CL,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartModel"),m(yL,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertModel"),m(wL,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertModel"),m(AL,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetModel"),m(xL,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5Model"),m(LL,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTModel"),m(BL,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusModel"),m(kL,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverModel"),m(RL,"href","/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(SL,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertModel"),m(PL,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerModel"),m($L,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertModel"),m(IL,"href","/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertModel"),m(jL,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaModel"),m(NL,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerModel"),m(DL,"href","/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerModel"),m(GL,"href","/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWModel"),m(OL,"href","/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDModel"),m(qL,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(zL,"href","/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterModel"),m(XL,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(WL,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5Model"),m(VL,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasModel"),m(QL,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLModel"),m(HL,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechModel"),m(UL,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatModel"),m(JL,"href","/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.VisionTextDualEncoderModel"),m(KL,"href","/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertModel"),m(YL,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTModel"),m(ZL,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(eB,"href","/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMModel"),m(oB,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMModel"),m(tB,"href","/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetModel"),m(rB,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaModel"),m(aB,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetModel"),m(xe,"class","docstring"),m(Po,"class","docstring"),m(xh,"id","transformers.AutoModelForPreTraining"),m(xh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xh,"href","#transformers.AutoModelForPreTraining"),m(di,"class","relative group"),m(At,"class","docstring"),m(nB,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForPreTraining"),m(sB,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(lB,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForPreTraining"),m(iB,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForPreTraining"),m(dB,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(mB,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(fB,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(cB,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForMaskedLM"),m(gB,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(hB,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForPreTraining"),m(uB,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(pB,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForPreTraining"),m(_B,"href","/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(vB,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(bB,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(TB,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(FB,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(MB,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(EB,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(CB,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForPreTraining"),m(yB,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(wB,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(AB,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTLMHeadModel"),m(xB,"href","/docs/transformers/v4.15.0/en/model_doc/retribert#transformers.RetriBertModel"),m(LB,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(BB,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(kB,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(RB,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(SB,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLLMHeadModel"),m(PB,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m($B,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForPreTraining"),m(IB,"href","/docs/transformers/v4.15.0/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(jB,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(NB,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(DB,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForMaskedLM"),m(GB,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(Le,"class","docstring"),m($o,"class","docstring"),m(cu,"id","transformers.AutoModelForCausalLM"),m(cu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cu,"href","#transformers.AutoModelForCausalLM"),m(ci,"class","relative group"),m(xt,"class","docstring"),m(OB,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForCausalLM"),m(qB,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertLMHeadModel"),m(zB,"href","/docs/transformers/v4.15.0/en/model_doc/bertgeneration#transformers.BertGenerationDecoder"),m(XB,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForCausalLM"),m(WB,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(VB,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(QB,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallForCausalLM"),m(HB,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(UB,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(JB,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(KB,"href","/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(YB,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(ZB,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianForCausalLM"),m(e9,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForCausalLM"),m(o9,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForCausalLM"),m(t9,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTLMHeadModel"),m(r9,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(a9,"href","/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(n9,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(s9,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m(l9,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(i9,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForCausalLM"),m(d9,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(m9,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m(f9,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLLMHeadModel"),m(c9,"href","/docs/transformers/v4.15.0/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(g9,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(h9,"href","/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetForCausalLM"),m(u9,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForCausalLM"),m(p9,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(Be,"class","docstring"),m(Io,"class","docstring"),m(Xu,"id","transformers.AutoModelForMaskedLM"),m(Xu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Xu,"href","#transformers.AutoModelForMaskedLM"),m(ui,"class","relative group"),m(Lt,"class","docstring"),m(_9,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(v9,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(b9,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForMaskedLM"),m(T9,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForMaskedLM"),m(F9,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(M9,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(E9,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(C9,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForMaskedLM"),m(y9,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(w9,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(A9,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(x9,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(L9,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(B9,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(k9,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(R9,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(S9,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(P9,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForMaskedLM"),m($9,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(I9,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(j9,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(N9,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(D9,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(G9,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(O9,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(q9,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(z9,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(X9,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(W9,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(V9,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForMaskedLM"),m(ke,"class","docstring"),m(jo,"class","docstring"),m(Ep,"id","transformers.AutoModelForSeq2SeqLM"),m(Ep,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ep,"href","#transformers.AutoModelForSeq2SeqLM"),m(vi,"class","relative group"),m(Bt,"class","docstring"),m(Q9,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(H9,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(U9,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(J9,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.BlenderbotSmallForConditionalGeneration"),m(K9,"href","/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.EncoderDecoderModel"),m(Y9,"href","/docs/transformers/v4.15.0/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(Z9,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(ek,"href","/docs/transformers/v4.15.0/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(ok,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.MarianMTModel"),m(tk,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(rk,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(ak,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(nk,"href","/docs/transformers/v4.15.0/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(sk,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(lk,"href","/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(Re,"class","docstring"),m(No,"class","docstring"),m(Gp,"id","transformers.AutoModelForSequenceClassification"),m(Gp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Gp,"href","#transformers.AutoModelForSequenceClassification"),m(Fi,"class","relative group"),m(kt,"class","docstring"),m(ik,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(dk,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForSequenceClassification"),m(mk,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForSequenceClassification"),m(fk,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForSequenceClassification"),m(ck,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(gk,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(hk,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(uk,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(pk,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(_k,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(vk,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForSequenceClassification"),m(bk,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m(Tk,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(Fk,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(Mk,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(Ek,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(Ck,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(yk,"href","/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(wk,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(Ak,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m(xk,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(Lk,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m(Bk,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDForSequenceClassification"),m(kk,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(Rk,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(Sk,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForSequenceClassification"),m(Pk,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m($k,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(Ik,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.OpenAIGPTForSequenceClassification"),m(jk,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(Nk,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(Dk,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(Gk,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(Ok,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(qk,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(zk,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(Xk,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(Wk,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TransfoXLForSequenceClassification"),m(Vk,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(Qk,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForSequenceClassification"),m(Hk,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(Se,"class","docstring"),m(Do,"class","docstring"),m(L_,"id","transformers.AutoModelForMultipleChoice"),m(L_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(L_,"href","#transformers.AutoModelForMultipleChoice"),m(Ci,"class","relative group"),m(Rt,"class","docstring"),m(Uk,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(Jk,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForMultipleChoice"),m(Kk,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForMultipleChoice"),m(Yk,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(Zk,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(eR,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(oR,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m(tR,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(rR,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(aR,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(nR,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(sR,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(lR,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(iR,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForMultipleChoice"),m(dR,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m(mR,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(fR,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m(cR,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(gR,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(hR,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(uR,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(pR,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(_R,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForMultipleChoice"),m(vR,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(Pe,"class","docstring"),m(Go,"class","docstring"),m(ov,"id","transformers.AutoModelForNextSentencePrediction"),m(ov,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ov,"href","#transformers.AutoModelForNextSentencePrediction"),m(Ai,"class","relative group"),m(St,"class","docstring"),m(bR,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(TR,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(FR,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForNextSentencePrediction"),m(MR,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(ER,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m($e,"class","docstring"),m(Oo,"class","docstring"),m(iv,"id","transformers.AutoModelForTokenClassification"),m(iv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(iv,"href","#transformers.AutoModelForTokenClassification"),m(Bi,"class","relative group"),m(Pt,"class","docstring"),m(CR,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(yR,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForTokenClassification"),m(wR,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForTokenClassification"),m(AR,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(xR,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForTokenClassification"),m(LR,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(BR,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(kR,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForTokenClassification"),m(RR,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(SR,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(PR,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m($R,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(IR,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(jR,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m(NR,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(DR,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(GR,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(OR,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(qR,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForTokenClassification"),m(zR,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m(XR,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(WR,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m(VR,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(QR,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(HR,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(UR,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(JR,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(KR,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForTokenClassification"),m(YR,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(Ie,"class","docstring"),m(qo,"class","docstring"),m(Dv,"id","transformers.AutoModelForQuestionAnswering"),m(Dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Dv,"href","#transformers.AutoModelForQuestionAnswering"),m(Si,"class","relative group"),m($t,"class","docstring"),m(ZR,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(eS,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(oS,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(tS,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.BigBirdForQuestionAnswering"),m(rS,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(aS,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(nS,"href","/docs/transformers/v4.15.0/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(sS,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(lS,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(iS,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.DebertaV2ForQuestionAnswering"),m(dS,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(mS,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(fS,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(cS,"href","/docs/transformers/v4.15.0/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(gS,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(hS,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(uS,"href","/docs/transformers/v4.15.0/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(pS,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(_S,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(vS,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(bS,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(TS,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(FS,"href","/docs/transformers/v4.15.0/en/model_doc/megatron_bert#transformers.MegatronBertForQuestionAnswering"),m(MS,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m(ES,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(CS,"href","/docs/transformers/v4.15.0/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(yS,"href","/docs/transformers/v4.15.0/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m(wS,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(AS,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m(xS,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(LS,"href","/docs/transformers/v4.15.0/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m(BS,"href","/docs/transformers/v4.15.0/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(kS,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(RS,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.XLMRobertaForQuestionAnswering"),m(SS,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(je,"class","docstring"),m(zo,"class","docstring"),m(M1,"id","transformers.AutoModelForTableQuestionAnswering"),m(M1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(M1,"href","#transformers.AutoModelForTableQuestionAnswering"),m(Ii,"class","relative group"),m(It,"class","docstring"),m(PS,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(Ne,"class","docstring"),m(Xo,"class","docstring"),m(y1,"id","transformers.AutoModelForImageClassification"),m(y1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y1,"href","#transformers.AutoModelForImageClassification"),m(Di,"class","relative group"),m(jt,"class","docstring"),m($S,"href","/docs/transformers/v4.15.0/en/model_doc/beit#transformers.BeitForImageClassification"),m(IS,"href","/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTForImageClassification"),m(jS,"href","/docs/transformers/v4.15.0/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(NS,"href","/docs/transformers/v4.15.0/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(DS,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(GS,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(OS,"href","/docs/transformers/v4.15.0/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(qS,"href","/docs/transformers/v4.15.0/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(zS,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.ViTForImageClassification"),m(De,"class","docstring"),m(Wo,"class","docstring"),m(k1,"id","transformers.AutoModelForVision2Seq"),m(k1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(k1,"href","#transformers.AutoModelForVision2Seq"),m(qi,"class","relative group"),m(Nt,"class","docstring"),m(XS,"href","/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.VisionEncoderDecoderModel"),m(Ge,"class","docstring"),m(Qo,"class","docstring"),m(P1,"id","transformers.AutoModelForAudioClassification"),m(P1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P1,"href","#transformers.AutoModelForAudioClassification"),m(Wi,"class","relative group"),m(Dt,"class","docstring"),m(WS,"href","/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(VS,"href","/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(QS,"href","/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDForSequenceClassification"),m(HS,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m(US,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForSequenceClassification"),m(JS,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(KS,"href","/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(Oe,"class","docstring"),m(Ho,"class","docstring"),m(z1,"id","transformers.AutoModelForAudioFrameClassification"),m(z1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(z1,"href","#transformers.AutoModelForAudioFrameClassification"),m(Hi,"class","relative group"),m(Gt,"class","docstring"),m(YS,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForAudioFrameClassification"),m(ZS,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(eP,"href","/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(qe,"class","docstring"),m(Uo,"class","docstring"),m(H1,"id","transformers.AutoModelForCTC"),m(H1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(H1,"href","#transformers.AutoModelForCTC"),m(Yi,"class","relative group"),m(Ot,"class","docstring"),m(oP,"href","/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.HubertForCTC"),m(tP,"href","/docs/transformers/v4.15.0/en/model_doc/sew#transformers.SEWForCTC"),m(rP,"href","/docs/transformers/v4.15.0/en/model_doc/sew_d#transformers.SEWDForCTC"),m(aP,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(nP,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForCTC"),m(sP,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(lP,"href","/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForCTC"),m(ze,"class","docstring"),m(Jo,"class","docstring"),m(r2,"id","transformers.AutoModelForSpeechSeq2Seq"),m(r2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(r2,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(od,"class","relative group"),m(qt,"class","docstring"),m(iP,"href","/docs/transformers/v4.15.0/en/model_doc/speechencoderdecoder#transformers.SpeechEncoderDecoderModel"),m(dP,"href","/docs/transformers/v4.15.0/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(Xe,"class","docstring"),m(Ko,"class","docstring"),m(l2,"id","transformers.AutoModelForAudioXVector"),m(l2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(l2,"href","#transformers.AutoModelForAudioXVector"),m(ad,"class","relative group"),m(zt,"class","docstring"),m(mP,"href","/docs/transformers/v4.15.0/en/model_doc/unispeech_sat#transformers.UniSpeechSatForXVector"),m(fP,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(cP,"href","/docs/transformers/v4.15.0/en/model_doc/wavlm#transformers.WavLMForXVector"),m(We,"class","docstring"),m(Yo,"class","docstring"),m(c2,"id","transformers.AutoModelForObjectDetection"),m(c2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(c2,"href","#transformers.AutoModelForObjectDetection"),m(id,"class","relative group"),m(Xt,"class","docstring"),m(gP,"href","/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrForObjectDetection"),m(Ve,"class","docstring"),m(Zo,"class","docstring"),m(u2,"id","transformers.AutoModelForImageSegmentation"),m(u2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(u2,"href","#transformers.AutoModelForImageSegmentation"),m(fd,"class","relative group"),m(Wt,"class","docstring"),m(hP,"href","/docs/transformers/v4.15.0/en/model_doc/detr#transformers.DetrForSegmentation"),m(Qe,"class","docstring"),m(et,"class","docstring"),m(v2,"id","transformers.TFAutoModel"),m(v2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(v2,"href","#transformers.TFAutoModel"),m(hd,"class","relative group"),m(Vt,"class","docstring"),m(uP,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertModel"),m(pP,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.TFBartModel"),m(_P,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertModel"),m(vP,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(bP,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.TFBlenderbotSmallModel"),m(TP,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertModel"),m(FP,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertModel"),m(MP,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLModel"),m(EP,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaModel"),m(CP,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2Model"),m(yP,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(wP,"href","/docs/transformers/v4.15.0/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(AP,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraModel"),m(xP,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertModel"),m(LP,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelModel"),m(BP,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m(kP,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2Model"),m(RP,"href","/docs/transformers/v4.15.0/en/model_doc/hubert#transformers.TFHubertModel"),m(SP,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(PP,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.TFLEDModel"),m($P,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerModel"),m(IP,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.TFLxmertModel"),m(jP,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.TFMarianModel"),m(NP,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.TFMBartModel"),m(DP,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(GP,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetModel"),m(OP,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.TFMT5Model"),m(qP,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTModel"),m(zP,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.TFPegasusModel"),m(XP,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertModel"),m(WP,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaModel"),m(VP,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerModel"),m(QP,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.TFT5Model"),m(HP,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasModel"),m(UP,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLModel"),m(JP,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.TFViTModel"),m(KP,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(YP,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMModel"),m(ZP,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaModel"),m(e$,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetModel"),m(ro,"class","docstring"),m(ot,"class","docstring"),m(rb,"id","transformers.TFAutoModelForPreTraining"),m(rb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(rb,"href","#transformers.TFAutoModelForPreTraining"),m(_d,"class","relative group"),m(Qt,"class","docstring"),m(o$,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(t$,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(r$,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForPreTraining"),m(a$,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(n$,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(s$,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(l$,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(i$,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(d$,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(m$,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(f$,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(c$,"href","/docs/transformers/v4.15.0/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m(g$,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(h$,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(u$,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTLMHeadModel"),m(p$,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(_$,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(v$,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(b$,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLLMHeadModel"),m(T$,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(F$,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForMaskedLM"),m(M$,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(ao,"class","docstring"),m(tt,"class","docstring"),m(wb,"id","transformers.TFAutoModelForCausalLM"),m(wb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(wb,"href","#transformers.TFAutoModelForCausalLM"),m(Td,"class","relative group"),m(Ht,"class","docstring"),m(E$,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(C$,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(y$,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(w$,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTLMHeadModel"),m(A$,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(x$,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(L$,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(B$,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLLMHeadModel"),m(k$,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(R$,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(no,"class","docstring"),m(rt,"class","docstring"),m(jb,"id","transformers.TFAutoModelForImageClassification"),m(jb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(jb,"href","#transformers.TFAutoModelForImageClassification"),m(Ed,"class","relative group"),m(Ut,"class","docstring"),m(S$,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.TFViTForImageClassification"),m(so,"class","docstring"),m(at,"class","docstring"),m(Db,"id","transformers.TFAutoModelForMaskedLM"),m(Db,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Db,"href","#transformers.TFAutoModelForMaskedLM"),m(wd,"class","relative group"),m(Jt,"class","docstring"),m(P$,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m($$,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(I$,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(j$,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(N$,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m(D$,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForMaskedLM"),m(G$,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(O$,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(q$,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(z$,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(X$,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(W$,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(V$,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(Q$,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(H$,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(U$,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(J$,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(K$,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Y$,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Z$,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForMaskedLM"),m(lo,"class","docstring"),m(nt,"class","docstring"),m(s4,"id","transformers.TFAutoModelForSeq2SeqLM"),m(s4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s4,"href","#transformers.TFAutoModelForSeq2SeqLM"),m(Ld,"class","relative group"),m(Kt,"class","docstring"),m(eI,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(oI,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(tI,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(rI,"href","/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.TFEncoderDecoderModel"),m(aI,"href","/docs/transformers/v4.15.0/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(nI,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.TFMarianMTModel"),m(sI,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(lI,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(iI,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(dI,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(io,"class","docstring"),m(st,"class","docstring"),m(_4,"id","transformers.TFAutoModelForSequenceClassification"),m(_4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_4,"href","#transformers.TFAutoModelForSequenceClassification"),m(Rd,"class","relative group"),m(Yt,"class","docstring"),m(mI,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(fI,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(cI,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(gI,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(hI,"href","/docs/transformers/v4.15.0/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(uI,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(pI,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForSequenceClassification"),m(_I,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(vI,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(bI,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(TI,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(FI,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(MI,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(EI,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(CI,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(yI,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(wI,"href","/docs/transformers/v4.15.0/en/model_doc/gpt#transformers.TFOpenAIGPTForSequenceClassification"),m(AI,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(xI,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m(LI,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(BI,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m(kI,"href","/docs/transformers/v4.15.0/en/model_doc/transformerxl#transformers.TFTransfoXLForSequenceClassification"),m(RI,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m(SI,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForSequenceClassification"),m(PI,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(mo,"class","docstring"),m(lt,"class","docstring"),m(z4,"id","transformers.TFAutoModelForMultipleChoice"),m(z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(z4,"href","#transformers.TFAutoModelForMultipleChoice"),m($d,"class","relative group"),m(Zt,"class","docstring"),m($I,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m(II,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(jI,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(NI,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(DI,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(GI,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(OI,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(qI,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(zI,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(XI,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(WI,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(VI,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(QI,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(HI,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(UI,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(JI,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForMultipleChoice"),m(KI,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(fo,"class","docstring"),m(it,"class","docstring"),m(l5,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(l5,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(Nd,"class","relative group"),m(er,"class","docstring"),m(YI,"href","/docs/transformers/v4.15.0/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(co,"class","docstring"),m(dt,"class","docstring"),m(d5,"id","transformers.TFAutoModelForTokenClassification"),m(d5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(d5,"href","#transformers.TFAutoModelForTokenClassification"),m(Od,"class","relative group"),m(or,"class","docstring"),m(ZI,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(ej,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(oj,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(tj,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(rj,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(aj,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForTokenClassification"),m(nj,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(sj,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(lj,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m(ij,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(dj,"href","/docs/transformers/v4.15.0/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m(mj,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m(fj,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(cj,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(gj,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m(hj,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(uj,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(pj,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(_j,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForTokenClassification"),m(vj,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(go,"class","docstring"),m(mt,"class","docstring"),m(B5,"id","transformers.TFAutoModelForQuestionAnswering"),m(B5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(B5,"href","#transformers.TFAutoModelForQuestionAnswering"),m(Xd,"class","relative group"),m(tr,"class","docstring"),m(bj,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(Tj,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(Fj,"href","/docs/transformers/v4.15.0/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(Mj,"href","/docs/transformers/v4.15.0/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(Ej,"href","/docs/transformers/v4.15.0/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(Cj,"href","/docs/transformers/v4.15.0/en/model_doc/deberta_v2#transformers.TFDebertaV2ForQuestionAnswering"),m(yj,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(wj,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(Aj,"href","/docs/transformers/v4.15.0/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(xj,"href","/docs/transformers/v4.15.0/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(Lj,"href","/docs/transformers/v4.15.0/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(Bj,"href","/docs/transformers/v4.15.0/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(kj,"href","/docs/transformers/v4.15.0/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(Rj,"href","/docs/transformers/v4.15.0/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(Sj,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(Pj,"href","/docs/transformers/v4.15.0/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m($j,"href","/docs/transformers/v4.15.0/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(Ij,"href","/docs/transformers/v4.15.0/en/model_doc/xlmroberta#transformers.TFXLMRobertaForQuestionAnswering"),m(jj,"href","/docs/transformers/v4.15.0/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(ho,"class","docstring"),m(ft,"class","docstring"),m(J5,"id","transformers.FlaxAutoModel"),m(J5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(J5,"href","#transformers.FlaxAutoModel"),m(Qd,"class","relative group"),m(rr,"class","docstring"),m(Nj,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertModel"),m(Dj,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartModel"),m(Gj,"href","/docs/transformers/v4.15.0/en/model_doc/beit#transformers.FlaxBeitModel"),m(Oj,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertModel"),m(qj,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdModel"),m(zj,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m(Xj,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.FlaxBlenderbotSmallModel"),m(Wj,"href","/docs/transformers/v4.15.0/en/model_doc/clip#transformers.FlaxCLIPModel"),m(Vj,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(Qj,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraModel"),m(Hj,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(Uj,"href","/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(Jj,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(Kj,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.FlaxMarianModel"),m(Yj,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartModel"),m(Zj,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.FlaxMT5Model"),m(eN,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(oN,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(tN,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.FlaxT5Model"),m(rN,"href","/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder#transformers.FlaxVisionTextDualEncoderModel"),m(aN,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.FlaxViTModel"),m(nN,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(uo,"class","docstring"),m(ct,"class","docstring"),m(b0,"id","transformers.FlaxAutoModelForCausalLM"),m(b0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(b0,"href","#transformers.FlaxAutoModelForCausalLM"),m(Jd,"class","relative group"),m(ar,"class","docstring"),m(sN,"href","/docs/transformers/v4.15.0/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(lN,"href","/docs/transformers/v4.15.0/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(iN,"href","/docs/transformers/v4.15.0/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(po,"class","docstring"),m(gt,"class","docstring"),m(E0,"id","transformers.FlaxAutoModelForPreTraining"),m(E0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E0,"href","#transformers.FlaxAutoModelForPreTraining"),m(em,"class","relative group"),m(nr,"class","docstring"),m(dN,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(mN,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(fN,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(cN,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForPreTraining"),m(gN,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(hN,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(uN,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(pN,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(_N,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(vN,"href","/docs/transformers/v4.15.0/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(_o,"class","docstring"),m(ht,"class","docstring"),m(P0,"id","transformers.FlaxAutoModelForMaskedLM"),m(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P0,"href","#transformers.FlaxAutoModelForMaskedLM"),m(rm,"class","relative group"),m(sr,"class","docstring"),m(bN,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m(TN,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(FN,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m(MN,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForMaskedLM"),m(EN,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m(CN,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(yN,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(wN,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(vo,"class","docstring"),m(ut,"class","docstring"),m(z0,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(z0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(z0,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(sm,"class","relative group"),m(lr,"class","docstring"),m(AN,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(xN,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(LN,"href","/docs/transformers/v4.15.0/en/model_doc/blenderbot_small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(BN,"href","/docs/transformers/v4.15.0/en/model_doc/encoderdecoder#transformers.FlaxEncoderDecoderModel"),m(kN,"href","/docs/transformers/v4.15.0/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(RN,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(SN,"href","/docs/transformers/v4.15.0/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(PN,"href","/docs/transformers/v4.15.0/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m($N,"href","/docs/transformers/v4.15.0/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(bo,"class","docstring"),m(pt,"class","docstring"),m(Z0,"id","transformers.FlaxAutoModelForSequenceClassification"),m(Z0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Z0,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(dm,"class","relative group"),m(ir,"class","docstring"),m(IN,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(jN,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(NN,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(DN,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForSequenceClassification"),m(GN,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(ON,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(qN,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(zN,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(To,"class","docstring"),m(_t,"class","docstring"),m(iT,"id","transformers.FlaxAutoModelForQuestionAnswering"),m(iT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(iT,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(cm,"class","relative group"),m(dr,"class","docstring"),m(XN,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(WN,"href","/docs/transformers/v4.15.0/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(VN,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(QN,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForQuestionAnswering"),m(HN,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(UN,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m(JN,"href","/docs/transformers/v4.15.0/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(KN,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(Fo,"class","docstring"),m(vt,"class","docstring"),m(_T,"id","transformers.FlaxAutoModelForTokenClassification"),m(_T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_T,"href","#transformers.FlaxAutoModelForTokenClassification"),m(um,"class","relative group"),m(mr,"class","docstring"),m(YN,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(ZN,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(eD,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForTokenClassification"),m(oD,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(tD,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m(rD,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(Mo,"class","docstring"),m(bt,"class","docstring"),m(CT,"id","transformers.FlaxAutoModelForMultipleChoice"),m(CT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(CT,"href","#transformers.FlaxAutoModelForMultipleChoice"),m(vm,"class","relative group"),m(fr,"class","docstring"),m(aD,"href","/docs/transformers/v4.15.0/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(nD,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(sD,"href","/docs/transformers/v4.15.0/en/model_doc/bigbird#transformers.FlaxBigBirdForMultipleChoice"),m(lD,"href","/docs/transformers/v4.15.0/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m(iD,"href","/docs/transformers/v4.15.0/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(dD,"href","/docs/transformers/v4.15.0/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(Eo,"class","docstring"),m(Ft,"class","docstring"),m(kT,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(kT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(kT,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(Fm,"class","relative group"),m(cr,"class","docstring"),m(mD,"href","/docs/transformers/v4.15.0/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(Co,"class","docstring"),m(Et,"class","docstring"),m(ST,"id","transformers.FlaxAutoModelForImageClassification"),m(ST,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ST,"href","#transformers.FlaxAutoModelForImageClassification"),m(Cm,"class","relative group"),m(gr,"class","docstring"),m(fD,"href","/docs/transformers/v4.15.0/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(cD,"href","/docs/transformers/v4.15.0/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(yo,"class","docstring"),m(Ct,"class","docstring"),m(IT,"id","transformers.FlaxAutoModelForVision2Seq"),m(IT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(IT,"href","#transformers.FlaxAutoModelForVision2Seq"),m(Am,"class","relative group"),m(hr,"class","docstring"),m(gD,"href","/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder#transformers.FlaxVisionEncoderDecoderModel"),m(wo,"class","docstring"),m(yt,"class","docstring")},m(d,_){e(document.head,J),v(d,ye,_),v(d,se,_),e(se,de),e(de,Ue),g(ie,Ue,null),e(se,ue),e(se,Bo),e(Bo,Vl),v(d,km,_),v(d,zr,_),e(zr,Ql),e(zr,Hl),e(Hl,RF),e(zr,Rm),v(d,Fe,_),v(d,Ze,_),e(Ze,Ul),e(Ze,gn),e(gn,SF),e(Ze,hn),e(Ze,un),e(un,PF),e(Ze,Jl),e(Ze,pn),e(pn,$F),e(Ze,Kl),v(d,Sm,_),g(ba,d,_),v(d,eo,_),v(d,me,_),e(me,IA),e(me,Yl),e(Yl,jA),e(me,NA),v(d,ko,_),v(d,Ta,_),e(Ta,DA),e(Ta,Pm),e(Pm,GA),e(Ta,dwe),v(d,bEe,_),v(d,Zl,_),e(Zl,$m),e($m,YG),g(IF,YG,null),e(Zl,mwe),e(Zl,ZG),e(ZG,fwe),v(d,TEe,_),v(d,_n,_),e(_n,cwe),e(_n,eO),e(eO,gwe),e(_n,hwe),e(_n,oO),e(oO,uwe),e(_n,pwe),v(d,FEe,_),g(jF,d,_),v(d,MEe,_),v(d,OA,_),e(OA,_we),v(d,EEe,_),g(Im,d,_),v(d,CEe,_),v(d,ei,_),e(ei,jm),e(jm,tO),g(NF,tO,null),e(ei,vwe),e(ei,rO),e(rO,bwe),v(d,yEe,_),v(d,Ro,_),g(DF,Ro,null),e(Ro,Twe),e(Ro,GF),e(GF,Fwe),e(GF,qA),e(qA,Mwe),e(GF,Ewe),e(Ro,Cwe),e(Ro,OF),e(OF,ywe),e(OF,aO),e(aO,wwe),e(OF,Awe),e(Ro,xwe),e(Ro,oo),g(qF,oo,null),e(oo,Lwe),e(oo,nO),e(nO,Bwe),e(oo,kwe),e(oo,oi),e(oi,Rwe),e(oi,sO),e(sO,Swe),e(oi,Pwe),e(oi,lO),e(lO,$we),e(oi,Iwe),e(oo,jwe),e(oo,b),e(b,Nm),e(Nm,iO),e(iO,Nwe),e(Nm,Dwe),e(Nm,zA),e(zA,Gwe),e(Nm,Owe),e(b,qwe),e(b,Dm),e(Dm,dO),e(dO,zwe),e(Dm,Xwe),e(Dm,XA),e(XA,Wwe),e(Dm,Vwe),e(b,Qwe),e(b,Gm),e(Gm,mO),e(mO,Hwe),e(Gm,Uwe),e(Gm,WA),e(WA,Jwe),e(Gm,Kwe),e(b,Ywe),e(b,Om),e(Om,fO),e(fO,Zwe),e(Om,eAe),e(Om,VA),e(VA,oAe),e(Om,tAe),e(b,rAe),e(b,qm),e(qm,cO),e(cO,aAe),e(qm,nAe),e(qm,QA),e(QA,sAe),e(qm,lAe),e(b,iAe),e(b,zm),e(zm,gO),e(gO,dAe),e(zm,mAe),e(zm,HA),e(HA,fAe),e(zm,cAe),e(b,gAe),e(b,Xm),e(Xm,hO),e(hO,hAe),e(Xm,uAe),e(Xm,UA),e(UA,pAe),e(Xm,_Ae),e(b,vAe),e(b,Wm),e(Wm,uO),e(uO,bAe),e(Wm,TAe),e(Wm,JA),e(JA,FAe),e(Wm,MAe),e(b,EAe),e(b,Vm),e(Vm,pO),e(pO,CAe),e(Vm,yAe),e(Vm,KA),e(KA,wAe),e(Vm,AAe),e(b,xAe),e(b,Qm),e(Qm,_O),e(_O,LAe),e(Qm,BAe),e(Qm,YA),e(YA,kAe),e(Qm,RAe),e(b,SAe),e(b,Hm),e(Hm,vO),e(vO,PAe),e(Hm,$Ae),e(Hm,ZA),e(ZA,IAe),e(Hm,jAe),e(b,NAe),e(b,Um),e(Um,bO),e(bO,DAe),e(Um,GAe),e(Um,e7),e(e7,OAe),e(Um,qAe),e(b,zAe),e(b,Jm),e(Jm,TO),e(TO,XAe),e(Jm,WAe),e(Jm,o7),e(o7,VAe),e(Jm,QAe),e(b,HAe),e(b,Km),e(Km,FO),e(FO,UAe),e(Km,JAe),e(Km,t7),e(t7,KAe),e(Km,YAe),e(b,ZAe),e(b,Ym),e(Ym,MO),e(MO,e7e),e(Ym,o7e),e(Ym,r7),e(r7,t7e),e(Ym,r7e),e(b,a7e),e(b,Zm),e(Zm,EO),e(EO,n7e),e(Zm,s7e),e(Zm,a7),e(a7,l7e),e(Zm,i7e),e(b,d7e),e(b,ef),e(ef,CO),e(CO,m7e),e(ef,f7e),e(ef,n7),e(n7,c7e),e(ef,g7e),e(b,h7e),e(b,of),e(of,yO),e(yO,u7e),e(of,p7e),e(of,s7),e(s7,_7e),e(of,v7e),e(b,b7e),e(b,tf),e(tf,wO),e(wO,T7e),e(tf,F7e),e(tf,l7),e(l7,M7e),e(tf,E7e),e(b,C7e),e(b,rf),e(rf,AO),e(AO,y7e),e(rf,w7e),e(rf,i7),e(i7,A7e),e(rf,x7e),e(b,L7e),e(b,af),e(af,xO),e(xO,B7e),e(af,k7e),e(af,d7),e(d7,R7e),e(af,S7e),e(b,P7e),e(b,nf),e(nf,LO),e(LO,$7e),e(nf,I7e),e(nf,m7),e(m7,j7e),e(nf,N7e),e(b,D7e),e(b,sf),e(sf,BO),e(BO,G7e),e(sf,O7e),e(sf,f7),e(f7,q7e),e(sf,z7e),e(b,X7e),e(b,lf),e(lf,kO),e(kO,W7e),e(lf,V7e),e(lf,c7),e(c7,Q7e),e(lf,H7e),e(b,U7e),e(b,df),e(df,RO),e(RO,J7e),e(df,K7e),e(df,g7),e(g7,Y7e),e(df,Z7e),e(b,exe),e(b,mf),e(mf,SO),e(SO,oxe),e(mf,txe),e(mf,h7),e(h7,rxe),e(mf,axe),e(b,nxe),e(b,ff),e(ff,PO),e(PO,sxe),e(ff,lxe),e(ff,u7),e(u7,ixe),e(ff,dxe),e(b,mxe),e(b,cf),e(cf,$O),e($O,fxe),e(cf,cxe),e(cf,p7),e(p7,gxe),e(cf,hxe),e(b,uxe),e(b,gf),e(gf,IO),e(IO,pxe),e(gf,_xe),e(gf,_7),e(_7,vxe),e(gf,bxe),e(b,Txe),e(b,hf),e(hf,jO),e(jO,Fxe),e(hf,Mxe),e(hf,v7),e(v7,Exe),e(hf,Cxe),e(b,yxe),e(b,uf),e(uf,NO),e(NO,wxe),e(uf,Axe),e(uf,b7),e(b7,xxe),e(uf,Lxe),e(b,Bxe),e(b,pf),e(pf,DO),e(DO,kxe),e(pf,Rxe),e(pf,T7),e(T7,Sxe),e(pf,Pxe),e(b,$xe),e(b,_f),e(_f,GO),e(GO,Ixe),e(_f,jxe),e(_f,F7),e(F7,Nxe),e(_f,Dxe),e(b,Gxe),e(b,vf),e(vf,OO),e(OO,Oxe),e(vf,qxe),e(vf,M7),e(M7,zxe),e(vf,Xxe),e(b,Wxe),e(b,bf),e(bf,qO),e(qO,Vxe),e(bf,Qxe),e(bf,E7),e(E7,Hxe),e(bf,Uxe),e(b,Jxe),e(b,Tf),e(Tf,zO),e(zO,Kxe),e(Tf,Yxe),e(Tf,C7),e(C7,Zxe),e(Tf,e6e),e(b,o6e),e(b,Ff),e(Ff,XO),e(XO,t6e),e(Ff,r6e),e(Ff,y7),e(y7,a6e),e(Ff,n6e),e(b,s6e),e(b,Mf),e(Mf,WO),e(WO,l6e),e(Mf,i6e),e(Mf,w7),e(w7,d6e),e(Mf,m6e),e(b,f6e),e(b,Ef),e(Ef,VO),e(VO,c6e),e(Ef,g6e),e(Ef,A7),e(A7,h6e),e(Ef,u6e),e(b,p6e),e(b,Cf),e(Cf,QO),e(QO,_6e),e(Cf,v6e),e(Cf,x7),e(x7,b6e),e(Cf,T6e),e(b,F6e),e(b,yf),e(yf,HO),e(HO,M6e),e(yf,E6e),e(yf,L7),e(L7,C6e),e(yf,y6e),e(b,w6e),e(b,wf),e(wf,UO),e(UO,A6e),e(wf,x6e),e(wf,B7),e(B7,L6e),e(wf,B6e),e(b,k6e),e(b,Af),e(Af,JO),e(JO,R6e),e(Af,S6e),e(Af,k7),e(k7,P6e),e(Af,$6e),e(b,I6e),e(b,xf),e(xf,KO),e(KO,j6e),e(xf,N6e),e(xf,R7),e(R7,D6e),e(xf,G6e),e(b,O6e),e(b,Lf),e(Lf,YO),e(YO,q6e),e(Lf,z6e),e(Lf,S7),e(S7,X6e),e(Lf,W6e),e(b,V6e),e(b,Bf),e(Bf,ZO),e(ZO,Q6e),e(Bf,H6e),e(Bf,P7),e(P7,U6e),e(Bf,J6e),e(b,K6e),e(b,kf),e(kf,eq),e(eq,Y6e),e(kf,Z6e),e(kf,$7),e($7,e8e),e(kf,o8e),e(b,t8e),e(b,Rf),e(Rf,oq),e(oq,r8e),e(Rf,a8e),e(Rf,I7),e(I7,n8e),e(Rf,s8e),e(b,l8e),e(b,Sf),e(Sf,tq),e(tq,i8e),e(Sf,d8e),e(Sf,j7),e(j7,m8e),e(Sf,f8e),e(b,c8e),e(b,Pf),e(Pf,rq),e(rq,g8e),e(Pf,h8e),e(Pf,N7),e(N7,u8e),e(Pf,p8e),e(b,_8e),e(b,$f),e($f,aq),e(aq,v8e),e($f,b8e),e($f,D7),e(D7,T8e),e($f,F8e),e(b,M8e),e(b,If),e(If,nq),e(nq,E8e),e(If,C8e),e(If,G7),e(G7,y8e),e(If,w8e),e(b,A8e),e(b,jf),e(jf,sq),e(sq,x8e),e(jf,L8e),e(jf,O7),e(O7,B8e),e(jf,k8e),e(b,R8e),e(b,Nf),e(Nf,lq),e(lq,S8e),e(Nf,P8e),e(Nf,q7),e(q7,$8e),e(Nf,I8e),e(b,j8e),e(b,Df),e(Df,iq),e(iq,N8e),e(Df,D8e),e(Df,z7),e(z7,G8e),e(Df,O8e),e(b,q8e),e(b,Gf),e(Gf,dq),e(dq,z8e),e(Gf,X8e),e(Gf,X7),e(X7,W8e),e(Gf,V8e),e(b,Q8e),e(b,Of),e(Of,mq),e(mq,H8e),e(Of,U8e),e(Of,W7),e(W7,J8e),e(Of,K8e),e(b,Y8e),e(b,qf),e(qf,fq),e(fq,Z8e),e(qf,eLe),e(qf,V7),e(V7,oLe),e(qf,tLe),e(b,rLe),e(b,zf),e(zf,cq),e(cq,aLe),e(zf,nLe),e(zf,Q7),e(Q7,sLe),e(zf,lLe),e(b,iLe),e(b,Xf),e(Xf,gq),e(gq,dLe),e(Xf,mLe),e(Xf,H7),e(H7,fLe),e(Xf,cLe),e(b,gLe),e(b,Wf),e(Wf,hq),e(hq,hLe),e(Wf,uLe),e(Wf,U7),e(U7,pLe),e(Wf,_Le),e(b,vLe),e(b,Vf),e(Vf,uq),e(uq,bLe),e(Vf,TLe),e(Vf,J7),e(J7,FLe),e(Vf,MLe),e(b,ELe),e(b,Qf),e(Qf,pq),e(pq,CLe),e(Qf,yLe),e(Qf,K7),e(K7,wLe),e(Qf,ALe),e(b,xLe),e(b,Hf),e(Hf,_q),e(_q,LLe),e(Hf,BLe),e(Hf,Y7),e(Y7,kLe),e(Hf,RLe),e(b,SLe),e(b,Uf),e(Uf,vq),e(vq,PLe),e(Uf,$Le),e(Uf,Z7),e(Z7,ILe),e(Uf,jLe),e(b,NLe),e(b,Jf),e(Jf,bq),e(bq,DLe),e(Jf,GLe),e(Jf,ex),e(ex,OLe),e(Jf,qLe),e(b,zLe),e(b,Kf),e(Kf,Tq),e(Tq,XLe),e(Kf,WLe),e(Kf,ox),e(ox,VLe),e(Kf,QLe),e(b,HLe),e(b,Yf),e(Yf,Fq),e(Fq,ULe),e(Yf,JLe),e(Yf,tx),e(tx,KLe),e(Yf,YLe),e(b,ZLe),e(b,Zf),e(Zf,Mq),e(Mq,eBe),e(Zf,oBe),e(Zf,rx),e(rx,tBe),e(Zf,rBe),e(b,aBe),e(b,ec),e(ec,Eq),e(Eq,nBe),e(ec,sBe),e(ec,ax),e(ax,lBe),e(ec,iBe),e(b,dBe),e(b,oc),e(oc,Cq),e(Cq,mBe),e(oc,fBe),e(oc,nx),e(nx,cBe),e(oc,gBe),e(b,hBe),e(b,tc),e(tc,yq),e(yq,uBe),e(tc,pBe),e(tc,sx),e(sx,_Be),e(tc,vBe),e(b,bBe),e(b,rc),e(rc,wq),e(wq,TBe),e(rc,FBe),e(rc,lx),e(lx,MBe),e(rc,EBe),e(b,CBe),e(b,ac),e(ac,Aq),e(Aq,yBe),e(ac,wBe),e(ac,ix),e(ix,ABe),e(ac,xBe),e(b,LBe),e(b,nc),e(nc,xq),e(xq,BBe),e(nc,kBe),e(nc,dx),e(dx,RBe),e(nc,SBe),e(b,PBe),e(b,sc),e(sc,Lq),e(Lq,$Be),e(sc,IBe),e(sc,mx),e(mx,jBe),e(sc,NBe),e(b,DBe),e(b,lc),e(lc,Bq),e(Bq,GBe),e(lc,OBe),e(lc,fx),e(fx,qBe),e(lc,zBe),e(b,XBe),e(b,ic),e(ic,kq),e(kq,WBe),e(ic,VBe),e(ic,cx),e(cx,QBe),e(ic,HBe),e(b,UBe),e(b,dc),e(dc,Rq),e(Rq,JBe),e(dc,KBe),e(dc,gx),e(gx,YBe),e(dc,ZBe),e(b,e9e),e(b,mc),e(mc,Sq),e(Sq,o9e),e(mc,t9e),e(mc,hx),e(hx,r9e),e(mc,a9e),e(oo,n9e),e(oo,Pq),e(Pq,s9e),e(oo,l9e),g(zF,oo,null),e(Ro,i9e),e(Ro,fc),g(XF,fc,null),e(fc,d9e),e(fc,$q),e($q,m9e),v(d,wEe,_),v(d,ti,_),e(ti,cc),e(cc,Iq),g(WF,Iq,null),e(ti,f9e),e(ti,jq),e(jq,c9e),v(d,AEe,_),v(d,So,_),g(VF,So,null),e(So,g9e),e(So,QF),e(QF,h9e),e(QF,ux),e(ux,u9e),e(QF,p9e),e(So,_9e),e(So,HF),e(HF,v9e),e(HF,Nq),e(Nq,b9e),e(HF,T9e),e(So,F9e),e(So,to),g(UF,to,null),e(to,M9e),e(to,Dq),e(Dq,E9e),e(to,C9e),e(to,Fa),e(Fa,y9e),e(Fa,Gq),e(Gq,w9e),e(Fa,A9e),e(Fa,Oq),e(Oq,x9e),e(Fa,L9e),e(Fa,qq),e(qq,B9e),e(Fa,k9e),e(to,R9e),e(to,E),e(E,vn),e(vn,zq),e(zq,S9e),e(vn,P9e),e(vn,px),e(px,$9e),e(vn,I9e),e(vn,_x),e(_x,j9e),e(vn,N9e),e(E,D9e),e(E,bn),e(bn,Xq),e(Xq,G9e),e(bn,O9e),e(bn,vx),e(vx,q9e),e(bn,z9e),e(bn,bx),e(bx,X9e),e(bn,W9e),e(E,V9e),e(E,Tn),e(Tn,Wq),e(Wq,Q9e),e(Tn,H9e),e(Tn,Tx),e(Tx,U9e),e(Tn,J9e),e(Tn,Fx),e(Fx,K9e),e(Tn,Y9e),e(E,Z9e),e(E,gc),e(gc,Vq),e(Vq,eke),e(gc,oke),e(gc,Mx),e(Mx,tke),e(gc,rke),e(E,ake),e(E,Fn),e(Fn,Qq),e(Qq,nke),e(Fn,ske),e(Fn,Ex),e(Ex,lke),e(Fn,ike),e(Fn,Cx),e(Cx,dke),e(Fn,mke),e(E,fke),e(E,hc),e(hc,Hq),e(Hq,cke),e(hc,gke),e(hc,yx),e(yx,hke),e(hc,uke),e(E,pke),e(E,uc),e(uc,Uq),e(Uq,_ke),e(uc,vke),e(uc,wx),e(wx,bke),e(uc,Tke),e(E,Fke),e(E,pc),e(pc,Jq),e(Jq,Mke),e(pc,Eke),e(pc,Ax),e(Ax,Cke),e(pc,yke),e(E,wke),e(E,Mn),e(Mn,Kq),e(Kq,Ake),e(Mn,xke),e(Mn,xx),e(xx,Lke),e(Mn,Bke),e(Mn,Lx),e(Lx,kke),e(Mn,Rke),e(E,Ske),e(E,En),e(En,Yq),e(Yq,Pke),e(En,$ke),e(En,Bx),e(Bx,Ike),e(En,jke),e(En,kx),e(kx,Nke),e(En,Dke),e(E,Gke),e(E,Cn),e(Cn,Zq),e(Zq,Oke),e(Cn,qke),e(Cn,Rx),e(Rx,zke),e(Cn,Xke),e(Cn,Sx),e(Sx,Wke),e(Cn,Vke),e(E,Qke),e(E,_c),e(_c,ez),e(ez,Hke),e(_c,Uke),e(_c,Px),e(Px,Jke),e(_c,Kke),e(E,Yke),e(E,vc),e(vc,oz),e(oz,Zke),e(vc,eRe),e(vc,$x),e($x,oRe),e(vc,tRe),e(E,rRe),e(E,yn),e(yn,tz),e(tz,aRe),e(yn,nRe),e(yn,Ix),e(Ix,sRe),e(yn,lRe),e(yn,jx),e(jx,iRe),e(yn,dRe),e(E,mRe),e(E,bc),e(bc,rz),e(rz,fRe),e(bc,cRe),e(bc,Nx),e(Nx,gRe),e(bc,hRe),e(E,uRe),e(E,wn),e(wn,az),e(az,pRe),e(wn,_Re),e(wn,Dx),e(Dx,vRe),e(wn,bRe),e(wn,Gx),e(Gx,TRe),e(wn,FRe),e(E,MRe),e(E,An),e(An,nz),e(nz,ERe),e(An,CRe),e(An,Ox),e(Ox,yRe),e(An,wRe),e(An,qx),e(qx,ARe),e(An,xRe),e(E,LRe),e(E,xn),e(xn,sz),e(sz,BRe),e(xn,kRe),e(xn,zx),e(zx,RRe),e(xn,SRe),e(xn,lz),e(lz,PRe),e(xn,$Re),e(E,IRe),e(E,Tc),e(Tc,iz),e(iz,jRe),e(Tc,NRe),e(Tc,Xx),e(Xx,DRe),e(Tc,GRe),e(E,ORe),e(E,Ln),e(Ln,dz),e(dz,qRe),e(Ln,zRe),e(Ln,Wx),e(Wx,XRe),e(Ln,WRe),e(Ln,Vx),e(Vx,VRe),e(Ln,QRe),e(E,HRe),e(E,Fc),e(Fc,mz),e(mz,URe),e(Fc,JRe),e(Fc,Qx),e(Qx,KRe),e(Fc,YRe),e(E,ZRe),e(E,Bn),e(Bn,fz),e(fz,eSe),e(Bn,oSe),e(Bn,Hx),e(Hx,tSe),e(Bn,rSe),e(Bn,Ux),e(Ux,aSe),e(Bn,nSe),e(E,sSe),e(E,kn),e(kn,cz),e(cz,lSe),e(kn,iSe),e(kn,Jx),e(Jx,dSe),e(kn,mSe),e(kn,Kx),e(Kx,fSe),e(kn,cSe),e(E,gSe),e(E,Rn),e(Rn,gz),e(gz,hSe),e(Rn,uSe),e(Rn,Yx),e(Yx,pSe),e(Rn,_Se),e(Rn,Zx),e(Zx,vSe),e(Rn,bSe),e(E,TSe),e(E,Mc),e(Mc,hz),e(hz,FSe),e(Mc,MSe),e(Mc,e6),e(e6,ESe),e(Mc,CSe),e(E,ySe),e(E,Sn),e(Sn,uz),e(uz,wSe),e(Sn,ASe),e(Sn,o6),e(o6,xSe),e(Sn,LSe),e(Sn,t6),e(t6,BSe),e(Sn,kSe),e(E,RSe),e(E,Ec),e(Ec,pz),e(pz,SSe),e(Ec,PSe),e(Ec,r6),e(r6,$Se),e(Ec,ISe),e(E,jSe),e(E,Pn),e(Pn,_z),e(_z,NSe),e(Pn,DSe),e(Pn,a6),e(a6,GSe),e(Pn,OSe),e(Pn,n6),e(n6,qSe),e(Pn,zSe),e(E,XSe),e(E,$n),e($n,vz),e(vz,WSe),e($n,VSe),e($n,s6),e(s6,QSe),e($n,HSe),e($n,l6),e(l6,USe),e($n,JSe),e(E,KSe),e(E,In),e(In,bz),e(bz,YSe),e(In,ZSe),e(In,i6),e(i6,ePe),e(In,oPe),e(In,d6),e(d6,tPe),e(In,rPe),e(E,aPe),e(E,Cc),e(Cc,Tz),e(Tz,nPe),e(Cc,sPe),e(Cc,m6),e(m6,lPe),e(Cc,iPe),e(E,dPe),e(E,jn),e(jn,Fz),e(Fz,mPe),e(jn,fPe),e(jn,f6),e(f6,cPe),e(jn,gPe),e(jn,c6),e(c6,hPe),e(jn,uPe),e(E,pPe),e(E,Nn),e(Nn,Mz),e(Mz,_Pe),e(Nn,vPe),e(Nn,g6),e(g6,bPe),e(Nn,TPe),e(Nn,h6),e(h6,FPe),e(Nn,MPe),e(E,EPe),e(E,Dn),e(Dn,Ez),e(Ez,CPe),e(Dn,yPe),e(Dn,u6),e(u6,wPe),e(Dn,APe),e(Dn,p6),e(p6,xPe),e(Dn,LPe),e(E,BPe),e(E,Gn),e(Gn,Cz),e(Cz,kPe),e(Gn,RPe),e(Gn,_6),e(_6,SPe),e(Gn,PPe),e(Gn,v6),e(v6,$Pe),e(Gn,IPe),e(E,jPe),e(E,On),e(On,yz),e(yz,NPe),e(On,DPe),e(On,b6),e(b6,GPe),e(On,OPe),e(On,T6),e(T6,qPe),e(On,zPe),e(E,XPe),e(E,yc),e(yc,wz),e(wz,WPe),e(yc,VPe),e(yc,F6),e(F6,QPe),e(yc,HPe),e(E,UPe),e(E,qn),e(qn,Az),e(Az,JPe),e(qn,KPe),e(qn,M6),e(M6,YPe),e(qn,ZPe),e(qn,E6),e(E6,e$e),e(qn,o$e),e(E,t$e),e(E,wc),e(wc,xz),e(xz,r$e),e(wc,a$e),e(wc,C6),e(C6,n$e),e(wc,s$e),e(E,l$e),e(E,Ac),e(Ac,Lz),e(Lz,i$e),e(Ac,d$e),e(Ac,y6),e(y6,m$e),e(Ac,f$e),e(E,c$e),e(E,zn),e(zn,Bz),e(Bz,g$e),e(zn,h$e),e(zn,w6),e(w6,u$e),e(zn,p$e),e(zn,A6),e(A6,_$e),e(zn,v$e),e(E,b$e),e(E,Xn),e(Xn,kz),e(kz,T$e),e(Xn,F$e),e(Xn,x6),e(x6,M$e),e(Xn,E$e),e(Xn,L6),e(L6,C$e),e(Xn,y$e),e(E,w$e),e(E,Wn),e(Wn,Rz),e(Rz,A$e),e(Wn,x$e),e(Wn,B6),e(B6,L$e),e(Wn,B$e),e(Wn,k6),e(k6,k$e),e(Wn,R$e),e(E,S$e),e(E,Vn),e(Vn,Sz),e(Sz,P$e),e(Vn,$$e),e(Vn,R6),e(R6,I$e),e(Vn,j$e),e(Vn,S6),e(S6,N$e),e(Vn,D$e),e(E,G$e),e(E,Qn),e(Qn,Pz),e(Pz,O$e),e(Qn,q$e),e(Qn,P6),e(P6,z$e),e(Qn,X$e),e(Qn,$6),e($6,W$e),e(Qn,V$e),e(E,Q$e),e(E,Hn),e(Hn,$z),e($z,H$e),e(Hn,U$e),e(Hn,I6),e(I6,J$e),e(Hn,K$e),e(Hn,j6),e(j6,Y$e),e(Hn,Z$e),e(E,eIe),e(E,Un),e(Un,Iz),e(Iz,oIe),e(Un,tIe),e(Un,N6),e(N6,rIe),e(Un,aIe),e(Un,D6),e(D6,nIe),e(Un,sIe),e(E,lIe),e(E,xc),e(xc,jz),e(jz,iIe),e(xc,dIe),e(xc,G6),e(G6,mIe),e(xc,fIe),e(E,cIe),e(E,Lc),e(Lc,Nz),e(Nz,gIe),e(Lc,hIe),e(Lc,O6),e(O6,uIe),e(Lc,pIe),e(E,_Ie),e(E,Bc),e(Bc,Dz),e(Dz,vIe),e(Bc,bIe),e(Bc,q6),e(q6,TIe),e(Bc,FIe),e(E,MIe),e(E,Jn),e(Jn,Gz),e(Gz,EIe),e(Jn,CIe),e(Jn,z6),e(z6,yIe),e(Jn,wIe),e(Jn,X6),e(X6,AIe),e(Jn,xIe),e(E,LIe),e(E,kc),e(kc,Oz),e(Oz,BIe),e(kc,kIe),e(kc,W6),e(W6,RIe),e(kc,SIe),e(E,PIe),e(E,Kn),e(Kn,qz),e(qz,$Ie),e(Kn,IIe),e(Kn,V6),e(V6,jIe),e(Kn,NIe),e(Kn,Q6),e(Q6,DIe),e(Kn,GIe),e(E,OIe),e(E,Yn),e(Yn,zz),e(zz,qIe),e(Yn,zIe),e(Yn,H6),e(H6,XIe),e(Yn,WIe),e(Yn,U6),e(U6,VIe),e(Yn,QIe),e(E,HIe),e(E,Zn),e(Zn,Xz),e(Xz,UIe),e(Zn,JIe),e(Zn,J6),e(J6,KIe),e(Zn,YIe),e(Zn,K6),e(K6,ZIe),e(Zn,eje),e(E,oje),e(E,es),e(es,Wz),e(Wz,tje),e(es,rje),e(es,Y6),e(Y6,aje),e(es,nje),e(es,Z6),e(Z6,sje),e(es,lje),e(E,ije),e(E,os),e(os,Vz),e(Vz,dje),e(os,mje),e(os,e8),e(e8,fje),e(os,cje),e(os,o8),e(o8,gje),e(os,hje),e(E,uje),e(E,Rc),e(Rc,Qz),e(Qz,pje),e(Rc,_je),e(Rc,t8),e(t8,vje),e(Rc,bje),e(E,Tje),e(E,Sc),e(Sc,Hz),e(Hz,Fje),e(Sc,Mje),e(Sc,r8),e(r8,Eje),e(Sc,Cje),e(E,yje),e(E,ts),e(ts,Uz),e(Uz,wje),e(ts,Aje),e(ts,a8),e(a8,xje),e(ts,Lje),e(ts,n8),e(n8,Bje),e(ts,kje),e(E,Rje),e(E,rs),e(rs,Jz),e(Jz,Sje),e(rs,Pje),e(rs,s8),e(s8,$je),e(rs,Ije),e(rs,l8),e(l8,jje),e(rs,Nje),e(E,Dje),e(E,as),e(as,Kz),e(Kz,Gje),e(as,Oje),e(as,i8),e(i8,qje),e(as,zje),e(as,d8),e(d8,Xje),e(as,Wje),e(E,Vje),e(E,Pc),e(Pc,Yz),e(Yz,Qje),e(Pc,Hje),e(Pc,m8),e(m8,Uje),e(Pc,Jje),e(E,Kje),e(E,$c),e($c,Zz),e(Zz,Yje),e($c,Zje),e($c,f8),e(f8,eNe),e($c,oNe),e(E,tNe),e(E,Ic),e(Ic,eX),e(eX,rNe),e(Ic,aNe),e(Ic,c8),e(c8,nNe),e(Ic,sNe),e(E,lNe),e(E,jc),e(jc,oX),e(oX,iNe),e(jc,dNe),e(jc,g8),e(g8,mNe),e(jc,fNe),e(E,cNe),e(E,Nc),e(Nc,tX),e(tX,gNe),e(Nc,hNe),e(Nc,h8),e(h8,uNe),e(Nc,pNe),e(E,_Ne),e(E,ns),e(ns,rX),e(rX,vNe),e(ns,bNe),e(ns,u8),e(u8,TNe),e(ns,FNe),e(ns,p8),e(p8,MNe),e(ns,ENe),e(E,CNe),e(E,ss),e(ss,aX),e(aX,yNe),e(ss,wNe),e(ss,_8),e(_8,ANe),e(ss,xNe),e(ss,v8),e(v8,LNe),e(ss,BNe),e(to,kNe),e(to,nX),e(nX,RNe),e(to,SNe),g(JF,to,null),e(So,PNe),e(So,Dc),g(KF,Dc,null),e(Dc,$Ne),e(Dc,sX),e(sX,INe),v(d,xEe,_),v(d,ri,_),e(ri,Gc),e(Gc,lX),g(YF,lX,null),e(ri,jNe),e(ri,iX),e(iX,NNe),v(d,LEe,_),v(d,Gr,_),g(ZF,Gr,null),e(Gr,DNe),e(Gr,eM),e(eM,GNe),e(eM,b8),e(b8,ONe),e(eM,qNe),e(Gr,zNe),e(Gr,oM),e(oM,XNe),e(oM,dX),e(dX,WNe),e(oM,VNe),e(Gr,QNe),e(Gr,we),g(tM,we,null),e(we,HNe),e(we,mX),e(mX,UNe),e(we,JNe),e(we,Ma),e(Ma,KNe),e(Ma,fX),e(fX,YNe),e(Ma,ZNe),e(Ma,cX),e(cX,eDe),e(Ma,oDe),e(Ma,gX),e(gX,tDe),e(Ma,rDe),e(we,aDe),e(we,fe),e(fe,Oc),e(Oc,hX),e(hX,nDe),e(Oc,sDe),e(Oc,T8),e(T8,lDe),e(Oc,iDe),e(fe,dDe),e(fe,qc),e(qc,uX),e(uX,mDe),e(qc,fDe),e(qc,F8),e(F8,cDe),e(qc,gDe),e(fe,hDe),e(fe,zc),e(zc,pX),e(pX,uDe),e(zc,pDe),e(zc,M8),e(M8,_De),e(zc,vDe),e(fe,bDe),e(fe,Xc),e(Xc,_X),e(_X,TDe),e(Xc,FDe),e(Xc,E8),e(E8,MDe),e(Xc,EDe),e(fe,CDe),e(fe,Wc),e(Wc,vX),e(vX,yDe),e(Wc,wDe),e(Wc,C8),e(C8,ADe),e(Wc,xDe),e(fe,LDe),e(fe,Vc),e(Vc,bX),e(bX,BDe),e(Vc,kDe),e(Vc,y8),e(y8,RDe),e(Vc,SDe),e(fe,PDe),e(fe,Qc),e(Qc,TX),e(TX,$De),e(Qc,IDe),e(Qc,w8),e(w8,jDe),e(Qc,NDe),e(fe,DDe),e(fe,Hc),e(Hc,FX),e(FX,GDe),e(Hc,ODe),e(Hc,A8),e(A8,qDe),e(Hc,zDe),e(fe,XDe),e(fe,Uc),e(Uc,MX),e(MX,WDe),e(Uc,VDe),e(Uc,x8),e(x8,QDe),e(Uc,HDe),e(fe,UDe),e(fe,Jc),e(Jc,EX),e(EX,JDe),e(Jc,KDe),e(Jc,L8),e(L8,YDe),e(Jc,ZDe),e(we,eGe),g(Kc,we,null),e(we,oGe),e(we,CX),e(CX,tGe),e(we,rGe),g(rM,we,null),v(d,BEe,_),v(d,ai,_),e(ai,Yc),e(Yc,yX),g(aM,yX,null),e(ai,aGe),e(ai,wX),e(wX,nGe),v(d,kEe,_),v(d,Or,_),g(nM,Or,null),e(Or,sGe),e(Or,sM),e(sM,lGe),e(sM,B8),e(B8,iGe),e(sM,dGe),e(Or,mGe),e(Or,lM),e(lM,fGe),e(lM,AX),e(AX,cGe),e(lM,gGe),e(Or,hGe),e(Or,Ae),g(iM,Ae,null),e(Ae,uGe),e(Ae,xX),e(xX,pGe),e(Ae,_Ge),e(Ae,ni),e(ni,vGe),e(ni,LX),e(LX,bGe),e(ni,TGe),e(ni,BX),e(BX,FGe),e(ni,MGe),e(Ae,EGe),e(Ae,Je),e(Je,Zc),e(Zc,kX),e(kX,CGe),e(Zc,yGe),e(Zc,k8),e(k8,wGe),e(Zc,AGe),e(Je,xGe),e(Je,eg),e(eg,RX),e(RX,LGe),e(eg,BGe),e(eg,R8),e(R8,kGe),e(eg,RGe),e(Je,SGe),e(Je,og),e(og,SX),e(SX,PGe),e(og,$Ge),e(og,S8),e(S8,IGe),e(og,jGe),e(Je,NGe),e(Je,tg),e(tg,PX),e(PX,DGe),e(tg,GGe),e(tg,P8),e(P8,OGe),e(tg,qGe),e(Je,zGe),e(Je,rg),e(rg,$X),e($X,XGe),e(rg,WGe),e(rg,$8),e($8,VGe),e(rg,QGe),e(Je,HGe),e(Je,ag),e(ag,IX),e(IX,UGe),e(ag,JGe),e(ag,I8),e(I8,KGe),e(ag,YGe),e(Je,ZGe),e(Je,ng),e(ng,jX),e(jX,eOe),e(ng,oOe),e(ng,j8),e(j8,tOe),e(ng,rOe),e(Ae,aOe),g(sg,Ae,null),e(Ae,nOe),e(Ae,NX),e(NX,sOe),e(Ae,lOe),g(dM,Ae,null),v(d,REe,_),v(d,si,_),e(si,lg),e(lg,DX),g(mM,DX,null),e(si,iOe),e(si,GX),e(GX,dOe),v(d,SEe,_),v(d,Po,_),g(fM,Po,null),e(Po,mOe),e(Po,li),e(li,fOe),e(li,OX),e(OX,cOe),e(li,gOe),e(li,qX),e(qX,hOe),e(li,uOe),e(Po,pOe),e(Po,cM),e(cM,_Oe),e(cM,zX),e(zX,vOe),e(cM,bOe),e(Po,TOe),e(Po,wt),g(gM,wt,null),e(wt,FOe),e(wt,XX),e(XX,MOe),e(wt,EOe),e(wt,ii),e(ii,COe),e(ii,WX),e(WX,yOe),e(ii,wOe),e(ii,VX),e(VX,AOe),e(ii,xOe),e(wt,LOe),e(wt,QX),e(QX,BOe),e(wt,kOe),g(hM,wt,null),e(Po,ROe),e(Po,xe),g(uM,xe,null),e(xe,SOe),e(xe,HX),e(HX,POe),e(xe,$Oe),e(xe,Ea),e(Ea,IOe),e(Ea,UX),e(UX,jOe),e(Ea,NOe),e(Ea,JX),e(JX,DOe),e(Ea,GOe),e(Ea,KX),e(KX,OOe),e(Ea,qOe),e(xe,zOe),e(xe,F),e(F,ig),e(ig,YX),e(YX,XOe),e(ig,WOe),e(ig,N8),e(N8,VOe),e(ig,QOe),e(F,HOe),e(F,dg),e(dg,ZX),e(ZX,UOe),e(dg,JOe),e(dg,D8),e(D8,KOe),e(dg,YOe),e(F,ZOe),e(F,mg),e(mg,eW),e(eW,eqe),e(mg,oqe),e(mg,G8),e(G8,tqe),e(mg,rqe),e(F,aqe),e(F,fg),e(fg,oW),e(oW,nqe),e(fg,sqe),e(fg,O8),e(O8,lqe),e(fg,iqe),e(F,dqe),e(F,cg),e(cg,tW),e(tW,mqe),e(cg,fqe),e(cg,q8),e(q8,cqe),e(cg,gqe),e(F,hqe),e(F,gg),e(gg,rW),e(rW,uqe),e(gg,pqe),e(gg,z8),e(z8,_qe),e(gg,vqe),e(F,bqe),e(F,hg),e(hg,aW),e(aW,Tqe),e(hg,Fqe),e(hg,X8),e(X8,Mqe),e(hg,Eqe),e(F,Cqe),e(F,ug),e(ug,nW),e(nW,yqe),e(ug,wqe),e(ug,W8),e(W8,Aqe),e(ug,xqe),e(F,Lqe),e(F,pg),e(pg,sW),e(sW,Bqe),e(pg,kqe),e(pg,V8),e(V8,Rqe),e(pg,Sqe),e(F,Pqe),e(F,_g),e(_g,lW),e(lW,$qe),e(_g,Iqe),e(_g,Q8),e(Q8,jqe),e(_g,Nqe),e(F,Dqe),e(F,vg),e(vg,iW),e(iW,Gqe),e(vg,Oqe),e(vg,H8),e(H8,qqe),e(vg,zqe),e(F,Xqe),e(F,bg),e(bg,dW),e(dW,Wqe),e(bg,Vqe),e(bg,U8),e(U8,Qqe),e(bg,Hqe),e(F,Uqe),e(F,Tg),e(Tg,mW),e(mW,Jqe),e(Tg,Kqe),e(Tg,J8),e(J8,Yqe),e(Tg,Zqe),e(F,eze),e(F,Fg),e(Fg,fW),e(fW,oze),e(Fg,tze),e(Fg,K8),e(K8,rze),e(Fg,aze),e(F,nze),e(F,Mg),e(Mg,cW),e(cW,sze),e(Mg,lze),e(Mg,Y8),e(Y8,ize),e(Mg,dze),e(F,mze),e(F,Eg),e(Eg,gW),e(gW,fze),e(Eg,cze),e(Eg,Z8),e(Z8,gze),e(Eg,hze),e(F,uze),e(F,Cg),e(Cg,hW),e(hW,pze),e(Cg,_ze),e(Cg,eL),e(eL,vze),e(Cg,bze),e(F,Tze),e(F,yg),e(yg,uW),e(uW,Fze),e(yg,Mze),e(yg,oL),e(oL,Eze),e(yg,Cze),e(F,yze),e(F,wg),e(wg,pW),e(pW,wze),e(wg,Aze),e(wg,tL),e(tL,xze),e(wg,Lze),e(F,Bze),e(F,Ag),e(Ag,_W),e(_W,kze),e(Ag,Rze),e(Ag,rL),e(rL,Sze),e(Ag,Pze),e(F,$ze),e(F,xg),e(xg,vW),e(vW,Ize),e(xg,jze),e(xg,aL),e(aL,Nze),e(xg,Dze),e(F,Gze),e(F,Lg),e(Lg,bW),e(bW,Oze),e(Lg,qze),e(Lg,nL),e(nL,zze),e(Lg,Xze),e(F,Wze),e(F,Bg),e(Bg,TW),e(TW,Vze),e(Bg,Qze),e(Bg,sL),e(sL,Hze),e(Bg,Uze),e(F,Jze),e(F,kg),e(kg,FW),e(FW,Kze),e(kg,Yze),e(kg,lL),e(lL,Zze),e(kg,eXe),e(F,oXe),e(F,ls),e(ls,MW),e(MW,tXe),e(ls,rXe),e(ls,iL),e(iL,aXe),e(ls,nXe),e(ls,dL),e(dL,sXe),e(ls,lXe),e(F,iXe),e(F,Rg),e(Rg,EW),e(EW,dXe),e(Rg,mXe),e(Rg,mL),e(mL,fXe),e(Rg,cXe),e(F,gXe),e(F,Sg),e(Sg,CW),e(CW,hXe),e(Sg,uXe),e(Sg,fL),e(fL,pXe),e(Sg,_Xe),e(F,vXe),e(F,Pg),e(Pg,yW),e(yW,bXe),e(Pg,TXe),e(Pg,cL),e(cL,FXe),e(Pg,MXe),e(F,EXe),e(F,$g),e($g,wW),e(wW,CXe),e($g,yXe),e($g,gL),e(gL,wXe),e($g,AXe),e(F,xXe),e(F,Ig),e(Ig,AW),e(AW,LXe),e(Ig,BXe),e(Ig,hL),e(hL,kXe),e(Ig,RXe),e(F,SXe),e(F,jg),e(jg,xW),e(xW,PXe),e(jg,$Xe),e(jg,uL),e(uL,IXe),e(jg,jXe),e(F,NXe),e(F,Ng),e(Ng,LW),e(LW,DXe),e(Ng,GXe),e(Ng,pL),e(pL,OXe),e(Ng,qXe),e(F,zXe),e(F,Dg),e(Dg,BW),e(BW,XXe),e(Dg,WXe),e(Dg,_L),e(_L,VXe),e(Dg,QXe),e(F,HXe),e(F,Gg),e(Gg,kW),e(kW,UXe),e(Gg,JXe),e(Gg,vL),e(vL,KXe),e(Gg,YXe),e(F,ZXe),e(F,Og),e(Og,RW),e(RW,eWe),e(Og,oWe),e(Og,bL),e(bL,tWe),e(Og,rWe),e(F,aWe),e(F,qg),e(qg,SW),e(SW,nWe),e(qg,sWe),e(qg,TL),e(TL,lWe),e(qg,iWe),e(F,dWe),e(F,zg),e(zg,PW),e(PW,mWe),e(zg,fWe),e(zg,FL),e(FL,cWe),e(zg,gWe),e(F,hWe),e(F,Xg),e(Xg,$W),e($W,uWe),e(Xg,pWe),e(Xg,ML),e(ML,_We),e(Xg,vWe),e(F,bWe),e(F,Wg),e(Wg,IW),e(IW,TWe),e(Wg,FWe),e(Wg,EL),e(EL,MWe),e(Wg,EWe),e(F,CWe),e(F,Vg),e(Vg,jW),e(jW,yWe),e(Vg,wWe),e(Vg,CL),e(CL,AWe),e(Vg,xWe),e(F,LWe),e(F,Qg),e(Qg,NW),e(NW,BWe),e(Qg,kWe),e(Qg,yL),e(yL,RWe),e(Qg,SWe),e(F,PWe),e(F,Hg),e(Hg,DW),e(DW,$We),e(Hg,IWe),e(Hg,wL),e(wL,jWe),e(Hg,NWe),e(F,DWe),e(F,Ug),e(Ug,GW),e(GW,GWe),e(Ug,OWe),e(Ug,AL),e(AL,qWe),e(Ug,zWe),e(F,XWe),e(F,Jg),e(Jg,OW),e(OW,WWe),e(Jg,VWe),e(Jg,xL),e(xL,QWe),e(Jg,HWe),e(F,UWe),e(F,Kg),e(Kg,qW),e(qW,JWe),e(Kg,KWe),e(Kg,LL),e(LL,YWe),e(Kg,ZWe),e(F,eVe),e(F,Yg),e(Yg,zW),e(zW,oVe),e(Yg,tVe),e(Yg,BL),e(BL,rVe),e(Yg,aVe),e(F,nVe),e(F,Zg),e(Zg,XW),e(XW,sVe),e(Zg,lVe),e(Zg,kL),e(kL,iVe),e(Zg,dVe),e(F,mVe),e(F,eh),e(eh,WW),e(WW,fVe),e(eh,cVe),e(eh,RL),e(RL,gVe),e(eh,hVe),e(F,uVe),e(F,oh),e(oh,VW),e(VW,pVe),e(oh,_Ve),e(oh,SL),e(SL,vVe),e(oh,bVe),e(F,TVe),e(F,th),e(th,QW),e(QW,FVe),e(th,MVe),e(th,PL),e(PL,EVe),e(th,CVe),e(F,yVe),e(F,rh),e(rh,HW),e(HW,wVe),e(rh,AVe),e(rh,$L),e($L,xVe),e(rh,LVe),e(F,BVe),e(F,ah),e(ah,UW),e(UW,kVe),e(ah,RVe),e(ah,IL),e(IL,SVe),e(ah,PVe),e(F,$Ve),e(F,nh),e(nh,JW),e(JW,IVe),e(nh,jVe),e(nh,jL),e(jL,NVe),e(nh,DVe),e(F,GVe),e(F,sh),e(sh,KW),e(KW,OVe),e(sh,qVe),e(sh,NL),e(NL,zVe),e(sh,XVe),e(F,WVe),e(F,lh),e(lh,YW),e(YW,VVe),e(lh,QVe),e(lh,DL),e(DL,HVe),e(lh,UVe),e(F,JVe),e(F,ih),e(ih,ZW),e(ZW,KVe),e(ih,YVe),e(ih,GL),e(GL,ZVe),e(ih,eQe),e(F,oQe),e(F,dh),e(dh,eV),e(eV,tQe),e(dh,rQe),e(dh,OL),e(OL,aQe),e(dh,nQe),e(F,sQe),e(F,mh),e(mh,oV),e(oV,lQe),e(mh,iQe),e(mh,qL),e(qL,dQe),e(mh,mQe),e(F,fQe),e(F,fh),e(fh,tV),e(tV,cQe),e(fh,gQe),e(fh,zL),e(zL,hQe),e(fh,uQe),e(F,pQe),e(F,ch),e(ch,rV),e(rV,_Qe),e(ch,vQe),e(ch,XL),e(XL,bQe),e(ch,TQe),e(F,FQe),e(F,gh),e(gh,aV),e(aV,MQe),e(gh,EQe),e(gh,WL),e(WL,CQe),e(gh,yQe),e(F,wQe),e(F,hh),e(hh,nV),e(nV,AQe),e(hh,xQe),e(hh,VL),e(VL,LQe),e(hh,BQe),e(F,kQe),e(F,uh),e(uh,sV),e(sV,RQe),e(uh,SQe),e(uh,QL),e(QL,PQe),e(uh,$Qe),e(F,IQe),e(F,ph),e(ph,lV),e(lV,jQe),e(ph,NQe),e(ph,HL),e(HL,DQe),e(ph,GQe),e(F,OQe),e(F,_h),e(_h,iV),e(iV,qQe),e(_h,zQe),e(_h,UL),e(UL,XQe),e(_h,WQe),e(F,VQe),e(F,vh),e(vh,dV),e(dV,QQe),e(vh,HQe),e(vh,JL),e(JL,UQe),e(vh,JQe),e(F,KQe),e(F,bh),e(bh,mV),e(mV,YQe),e(bh,ZQe),e(bh,KL),e(KL,eHe),e(bh,oHe),e(F,tHe),e(F,Th),e(Th,fV),e(fV,rHe),e(Th,aHe),e(Th,YL),e(YL,nHe),e(Th,sHe),e(F,lHe),e(F,Fh),e(Fh,cV),e(cV,iHe),e(Fh,dHe),e(Fh,ZL),e(ZL,mHe),e(Fh,fHe),e(F,cHe),e(F,Mh),e(Mh,gV),e(gV,gHe),e(Mh,hHe),e(Mh,eB),e(eB,uHe),e(Mh,pHe),e(F,_He),e(F,Eh),e(Eh,hV),e(hV,vHe),e(Eh,bHe),e(Eh,oB),e(oB,THe),e(Eh,FHe),e(F,MHe),e(F,Ch),e(Ch,uV),e(uV,EHe),e(Ch,CHe),e(Ch,tB),e(tB,yHe),e(Ch,wHe),e(F,AHe),e(F,yh),e(yh,pV),e(pV,xHe),e(yh,LHe),e(yh,rB),e(rB,BHe),e(yh,kHe),e(F,RHe),e(F,wh),e(wh,_V),e(_V,SHe),e(wh,PHe),e(wh,aB),e(aB,$He),e(wh,IHe),e(xe,jHe),e(xe,Ah),e(Ah,NHe),e(Ah,vV),e(vV,DHe),e(Ah,GHe),e(Ah,bV),e(bV,OHe),e(xe,qHe),e(xe,TV),e(TV,zHe),e(xe,XHe),g(pM,xe,null),v(d,PEe,_),v(d,di,_),e(di,xh),e(xh,FV),g(_M,FV,null),e(di,WHe),e(di,MV),e(MV,VHe),v(d,$Ee,_),v(d,$o,_),g(vM,$o,null),e($o,QHe),e($o,mi),e(mi,HHe),e(mi,EV),e(EV,UHe),e(mi,JHe),e(mi,CV),e(CV,KHe),e(mi,YHe),e($o,ZHe),e($o,bM),e(bM,eUe),e(bM,yV),e(yV,oUe),e(bM,tUe),e($o,rUe),e($o,At),g(TM,At,null),e(At,aUe),e(At,wV),e(wV,nUe),e(At,sUe),e(At,fi),e(fi,lUe),e(fi,AV),e(AV,iUe),e(fi,dUe),e(fi,xV),e(xV,mUe),e(fi,fUe),e(At,cUe),e(At,LV),e(LV,gUe),e(At,hUe),g(FM,At,null),e($o,uUe),e($o,Le),g(MM,Le,null),e(Le,pUe),e(Le,BV),e(BV,_Ue),e(Le,vUe),e(Le,Ca),e(Ca,bUe),e(Ca,kV),e(kV,TUe),e(Ca,FUe),e(Ca,RV),e(RV,MUe),e(Ca,EUe),e(Ca,SV),e(SV,CUe),e(Ca,yUe),e(Le,wUe),e(Le,k),e(k,Lh),e(Lh,PV),e(PV,AUe),e(Lh,xUe),e(Lh,nB),e(nB,LUe),e(Lh,BUe),e(k,kUe),e(k,Bh),e(Bh,$V),e($V,RUe),e(Bh,SUe),e(Bh,sB),e(sB,PUe),e(Bh,$Ue),e(k,IUe),e(k,kh),e(kh,IV),e(IV,jUe),e(kh,NUe),e(kh,lB),e(lB,DUe),e(kh,GUe),e(k,OUe),e(k,Rh),e(Rh,jV),e(jV,qUe),e(Rh,zUe),e(Rh,iB),e(iB,XUe),e(Rh,WUe),e(k,VUe),e(k,Sh),e(Sh,NV),e(NV,QUe),e(Sh,HUe),e(Sh,dB),e(dB,UUe),e(Sh,JUe),e(k,KUe),e(k,Ph),e(Ph,DV),e(DV,YUe),e(Ph,ZUe),e(Ph,mB),e(mB,eJe),e(Ph,oJe),e(k,tJe),e(k,$h),e($h,GV),e(GV,rJe),e($h,aJe),e($h,fB),e(fB,nJe),e($h,sJe),e(k,lJe),e(k,Ih),e(Ih,OV),e(OV,iJe),e(Ih,dJe),e(Ih,cB),e(cB,mJe),e(Ih,fJe),e(k,cJe),e(k,jh),e(jh,qV),e(qV,gJe),e(jh,hJe),e(jh,gB),e(gB,uJe),e(jh,pJe),e(k,_Je),e(k,Nh),e(Nh,zV),e(zV,vJe),e(Nh,bJe),e(Nh,hB),e(hB,TJe),e(Nh,FJe),e(k,MJe),e(k,Dh),e(Dh,XV),e(XV,EJe),e(Dh,CJe),e(Dh,uB),e(uB,yJe),e(Dh,wJe),e(k,AJe),e(k,Gh),e(Gh,WV),e(WV,xJe),e(Gh,LJe),e(Gh,pB),e(pB,BJe),e(Gh,kJe),e(k,RJe),e(k,Oh),e(Oh,VV),e(VV,SJe),e(Oh,PJe),e(Oh,_B),e(_B,$Je),e(Oh,IJe),e(k,jJe),e(k,qh),e(qh,QV),e(QV,NJe),e(qh,DJe),e(qh,vB),e(vB,GJe),e(qh,OJe),e(k,qJe),e(k,zh),e(zh,HV),e(HV,zJe),e(zh,XJe),e(zh,bB),e(bB,WJe),e(zh,VJe),e(k,QJe),e(k,Xh),e(Xh,UV),e(UV,HJe),e(Xh,UJe),e(Xh,TB),e(TB,JJe),e(Xh,KJe),e(k,YJe),e(k,Wh),e(Wh,JV),e(JV,ZJe),e(Wh,eKe),e(Wh,FB),e(FB,oKe),e(Wh,tKe),e(k,rKe),e(k,Vh),e(Vh,KV),e(KV,aKe),e(Vh,nKe),e(Vh,MB),e(MB,sKe),e(Vh,lKe),e(k,iKe),e(k,Qh),e(Qh,YV),e(YV,dKe),e(Qh,mKe),e(Qh,EB),e(EB,fKe),e(Qh,cKe),e(k,gKe),e(k,Hh),e(Hh,ZV),e(ZV,hKe),e(Hh,uKe),e(Hh,CB),e(CB,pKe),e(Hh,_Ke),e(k,vKe),e(k,Uh),e(Uh,eQ),e(eQ,bKe),e(Uh,TKe),e(Uh,yB),e(yB,FKe),e(Uh,MKe),e(k,EKe),e(k,Jh),e(Jh,oQ),e(oQ,CKe),e(Jh,yKe),e(Jh,wB),e(wB,wKe),e(Jh,AKe),e(k,xKe),e(k,Kh),e(Kh,tQ),e(tQ,LKe),e(Kh,BKe),e(Kh,AB),e(AB,kKe),e(Kh,RKe),e(k,SKe),e(k,Yh),e(Yh,rQ),e(rQ,PKe),e(Yh,$Ke),e(Yh,xB),e(xB,IKe),e(Yh,jKe),e(k,NKe),e(k,Zh),e(Zh,aQ),e(aQ,DKe),e(Zh,GKe),e(Zh,LB),e(LB,OKe),e(Zh,qKe),e(k,zKe),e(k,eu),e(eu,nQ),e(nQ,XKe),e(eu,WKe),e(eu,BB),e(BB,VKe),e(eu,QKe),e(k,HKe),e(k,ou),e(ou,sQ),e(sQ,UKe),e(ou,JKe),e(ou,kB),e(kB,KKe),e(ou,YKe),e(k,ZKe),e(k,tu),e(tu,lQ),e(lQ,eYe),e(tu,oYe),e(tu,RB),e(RB,tYe),e(tu,rYe),e(k,aYe),e(k,ru),e(ru,iQ),e(iQ,nYe),e(ru,sYe),e(ru,SB),e(SB,lYe),e(ru,iYe),e(k,dYe),e(k,au),e(au,dQ),e(dQ,mYe),e(au,fYe),e(au,PB),e(PB,cYe),e(au,gYe),e(k,hYe),e(k,nu),e(nu,mQ),e(mQ,uYe),e(nu,pYe),e(nu,$B),e($B,_Ye),e(nu,vYe),e(k,bYe),e(k,su),e(su,fQ),e(fQ,TYe),e(su,FYe),e(su,IB),e(IB,MYe),e(su,EYe),e(k,CYe),e(k,lu),e(lu,cQ),e(cQ,yYe),e(lu,wYe),e(lu,jB),e(jB,AYe),e(lu,xYe),e(k,LYe),e(k,iu),e(iu,gQ),e(gQ,BYe),e(iu,kYe),e(iu,NB),e(NB,RYe),e(iu,SYe),e(k,PYe),e(k,du),e(du,hQ),e(hQ,$Ye),e(du,IYe),e(du,DB),e(DB,jYe),e(du,NYe),e(k,DYe),e(k,mu),e(mu,uQ),e(uQ,GYe),e(mu,OYe),e(mu,GB),e(GB,qYe),e(mu,zYe),e(Le,XYe),e(Le,fu),e(fu,WYe),e(fu,pQ),e(pQ,VYe),e(fu,QYe),e(fu,_Q),e(_Q,HYe),e(Le,UYe),e(Le,vQ),e(vQ,JYe),e(Le,KYe),g(EM,Le,null),v(d,IEe,_),v(d,ci,_),e(ci,cu),e(cu,bQ),g(CM,bQ,null),e(ci,YYe),e(ci,TQ),e(TQ,ZYe),v(d,jEe,_),v(d,Io,_),g(yM,Io,null),e(Io,eZe),e(Io,gi),e(gi,oZe),e(gi,FQ),e(FQ,tZe),e(gi,rZe),e(gi,MQ),e(MQ,aZe),e(gi,nZe),e(Io,sZe),e(Io,wM),e(wM,lZe),e(wM,EQ),e(EQ,iZe),e(wM,dZe),e(Io,mZe),e(Io,xt),g(AM,xt,null),e(xt,fZe),e(xt,CQ),e(CQ,cZe),e(xt,gZe),e(xt,hi),e(hi,hZe),e(hi,yQ),e(yQ,uZe),e(hi,pZe),e(hi,wQ),e(wQ,_Ze),e(hi,vZe),e(xt,bZe),e(xt,AQ),e(AQ,TZe),e(xt,FZe),g(xM,xt,null),e(Io,MZe),e(Io,Be),g(LM,Be,null),e(Be,EZe),e(Be,xQ),e(xQ,CZe),e(Be,yZe),e(Be,ya),e(ya,wZe),e(ya,LQ),e(LQ,AZe),e(ya,xZe),e(ya,BQ),e(BQ,LZe),e(ya,BZe),e(ya,kQ),e(kQ,kZe),e(ya,RZe),e(Be,SZe),e(Be,I),e(I,gu),e(gu,RQ),e(RQ,PZe),e(gu,$Ze),e(gu,OB),e(OB,IZe),e(gu,jZe),e(I,NZe),e(I,hu),e(hu,SQ),e(SQ,DZe),e(hu,GZe),e(hu,qB),e(qB,OZe),e(hu,qZe),e(I,zZe),e(I,uu),e(uu,PQ),e(PQ,XZe),e(uu,WZe),e(uu,zB),e(zB,VZe),e(uu,QZe),e(I,HZe),e(I,pu),e(pu,$Q),e($Q,UZe),e(pu,JZe),e(pu,XB),e(XB,KZe),e(pu,YZe),e(I,ZZe),e(I,_u),e(_u,IQ),e(IQ,eeo),e(_u,oeo),e(_u,WB),e(WB,teo),e(_u,reo),e(I,aeo),e(I,vu),e(vu,jQ),e(jQ,neo),e(vu,seo),e(vu,VB),e(VB,leo),e(vu,ieo),e(I,deo),e(I,bu),e(bu,NQ),e(NQ,meo),e(bu,feo),e(bu,QB),e(QB,ceo),e(bu,geo),e(I,heo),e(I,Tu),e(Tu,DQ),e(DQ,ueo),e(Tu,peo),e(Tu,HB),e(HB,_eo),e(Tu,veo),e(I,beo),e(I,Fu),e(Fu,GQ),e(GQ,Teo),e(Fu,Feo),e(Fu,UB),e(UB,Meo),e(Fu,Eeo),e(I,Ceo),e(I,Mu),e(Mu,OQ),e(OQ,yeo),e(Mu,weo),e(Mu,JB),e(JB,Aeo),e(Mu,xeo),e(I,Leo),e(I,Eu),e(Eu,qQ),e(qQ,Beo),e(Eu,keo),e(Eu,KB),e(KB,Reo),e(Eu,Seo),e(I,Peo),e(I,Cu),e(Cu,zQ),e(zQ,$eo),e(Cu,Ieo),e(Cu,YB),e(YB,jeo),e(Cu,Neo),e(I,Deo),e(I,yu),e(yu,XQ),e(XQ,Geo),e(yu,Oeo),e(yu,ZB),e(ZB,qeo),e(yu,zeo),e(I,Xeo),e(I,wu),e(wu,WQ),e(WQ,Weo),e(wu,Veo),e(wu,e9),e(e9,Qeo),e(wu,Heo),e(I,Ueo),e(I,Au),e(Au,VQ),e(VQ,Jeo),e(Au,Keo),e(Au,o9),e(o9,Yeo),e(Au,Zeo),e(I,eoo),e(I,xu),e(xu,QQ),e(QQ,ooo),e(xu,too),e(xu,t9),e(t9,roo),e(xu,aoo),e(I,noo),e(I,Lu),e(Lu,HQ),e(HQ,soo),e(Lu,loo),e(Lu,r9),e(r9,ioo),e(Lu,doo),e(I,moo),e(I,Bu),e(Bu,UQ),e(UQ,foo),e(Bu,coo),e(Bu,a9),e(a9,goo),e(Bu,hoo),e(I,uoo),e(I,ku),e(ku,JQ),e(JQ,poo),e(ku,_oo),e(ku,n9),e(n9,voo),e(ku,boo),e(I,Too),e(I,Ru),e(Ru,KQ),e(KQ,Foo),e(Ru,Moo),e(Ru,s9),e(s9,Eoo),e(Ru,Coo),e(I,yoo),e(I,Su),e(Su,YQ),e(YQ,woo),e(Su,Aoo),e(Su,l9),e(l9,xoo),e(Su,Loo),e(I,Boo),e(I,Pu),e(Pu,ZQ),e(ZQ,koo),e(Pu,Roo),e(Pu,i9),e(i9,Soo),e(Pu,Poo),e(I,$oo),e(I,$u),e($u,eH),e(eH,Ioo),e($u,joo),e($u,d9),e(d9,Noo),e($u,Doo),e(I,Goo),e(I,Iu),e(Iu,oH),e(oH,Ooo),e(Iu,qoo),e(Iu,m9),e(m9,zoo),e(Iu,Xoo),e(I,Woo),e(I,ju),e(ju,tH),e(tH,Voo),e(ju,Qoo),e(ju,f9),e(f9,Hoo),e(ju,Uoo),e(I,Joo),e(I,Nu),e(Nu,rH),e(rH,Koo),e(Nu,Yoo),e(Nu,c9),e(c9,Zoo),e(Nu,eto),e(I,oto),e(I,Du),e(Du,aH),e(aH,tto),e(Du,rto),e(Du,g9),e(g9,ato),e(Du,nto),e(I,sto),e(I,Gu),e(Gu,nH),e(nH,lto),e(Gu,ito),e(Gu,h9),e(h9,dto),e(Gu,mto),e(I,fto),e(I,Ou),e(Ou,sH),e(sH,cto),e(Ou,gto),e(Ou,u9),e(u9,hto),e(Ou,uto),e(I,pto),e(I,qu),e(qu,lH),e(lH,_to),e(qu,vto),e(qu,p9),e(p9,bto),e(qu,Tto),e(Be,Fto),e(Be,zu),e(zu,Mto),e(zu,iH),e(iH,Eto),e(zu,Cto),e(zu,dH),e(dH,yto),e(Be,wto),e(Be,mH),e(mH,Ato),e(Be,xto),g(BM,Be,null),v(d,NEe,_),v(d,ui,_),e(ui,Xu),e(Xu,fH),g(kM,fH,null),e(ui,Lto),e(ui,cH),e(cH,Bto),v(d,DEe,_),v(d,jo,_),g(RM,jo,null),e(jo,kto),e(jo,pi),e(pi,Rto),e(pi,gH),e(gH,Sto),e(pi,Pto),e(pi,hH),e(hH,$to),e(pi,Ito),e(jo,jto),e(jo,SM),e(SM,Nto),e(SM,uH),e(uH,Dto),e(SM,Gto),e(jo,Oto),e(jo,Lt),g(PM,Lt,null),e(Lt,qto),e(Lt,pH),e(pH,zto),e(Lt,Xto),e(Lt,_i),e(_i,Wto),e(_i,_H),e(_H,Vto),e(_i,Qto),e(_i,vH),e(vH,Hto),e(_i,Uto),e(Lt,Jto),e(Lt,bH),e(bH,Kto),e(Lt,Yto),g($M,Lt,null),e(jo,Zto),e(jo,ke),g(IM,ke,null),e(ke,ero),e(ke,TH),e(TH,oro),e(ke,tro),e(ke,wa),e(wa,rro),e(wa,FH),e(FH,aro),e(wa,nro),e(wa,MH),e(MH,sro),e(wa,lro),e(wa,EH),e(EH,iro),e(wa,dro),e(ke,mro),e(ke,$),e($,Wu),e(Wu,CH),e(CH,fro),e(Wu,cro),e(Wu,_9),e(_9,gro),e(Wu,hro),e($,uro),e($,Vu),e(Vu,yH),e(yH,pro),e(Vu,_ro),e(Vu,v9),e(v9,vro),e(Vu,bro),e($,Tro),e($,Qu),e(Qu,wH),e(wH,Fro),e(Qu,Mro),e(Qu,b9),e(b9,Ero),e(Qu,Cro),e($,yro),e($,Hu),e(Hu,AH),e(AH,wro),e(Hu,Aro),e(Hu,T9),e(T9,xro),e(Hu,Lro),e($,Bro),e($,Uu),e(Uu,xH),e(xH,kro),e(Uu,Rro),e(Uu,F9),e(F9,Sro),e(Uu,Pro),e($,$ro),e($,Ju),e(Ju,LH),e(LH,Iro),e(Ju,jro),e(Ju,M9),e(M9,Nro),e(Ju,Dro),e($,Gro),e($,Ku),e(Ku,BH),e(BH,Oro),e(Ku,qro),e(Ku,E9),e(E9,zro),e(Ku,Xro),e($,Wro),e($,Yu),e(Yu,kH),e(kH,Vro),e(Yu,Qro),e(Yu,C9),e(C9,Hro),e(Yu,Uro),e($,Jro),e($,Zu),e(Zu,RH),e(RH,Kro),e(Zu,Yro),e(Zu,y9),e(y9,Zro),e(Zu,eao),e($,oao),e($,ep),e(ep,SH),e(SH,tao),e(ep,rao),e(ep,w9),e(w9,aao),e(ep,nao),e($,sao),e($,op),e(op,PH),e(PH,lao),e(op,iao),e(op,A9),e(A9,dao),e(op,mao),e($,fao),e($,tp),e(tp,$H),e($H,cao),e(tp,gao),e(tp,x9),e(x9,hao),e(tp,uao),e($,pao),e($,rp),e(rp,IH),e(IH,_ao),e(rp,vao),e(rp,L9),e(L9,bao),e(rp,Tao),e($,Fao),e($,ap),e(ap,jH),e(jH,Mao),e(ap,Eao),e(ap,B9),e(B9,Cao),e(ap,yao),e($,wao),e($,np),e(np,NH),e(NH,Aao),e(np,xao),e(np,k9),e(k9,Lao),e(np,Bao),e($,kao),e($,sp),e(sp,DH),e(DH,Rao),e(sp,Sao),e(sp,R9),e(R9,Pao),e(sp,$ao),e($,Iao),e($,lp),e(lp,GH),e(GH,jao),e(lp,Nao),e(lp,S9),e(S9,Dao),e(lp,Gao),e($,Oao),e($,ip),e(ip,OH),e(OH,qao),e(ip,zao),e(ip,P9),e(P9,Xao),e(ip,Wao),e($,Vao),e($,dp),e(dp,qH),e(qH,Qao),e(dp,Hao),e(dp,$9),e($9,Uao),e(dp,Jao),e($,Kao),e($,mp),e(mp,zH),e(zH,Yao),e(mp,Zao),e(mp,I9),e(I9,eno),e(mp,ono),e($,tno),e($,fp),e(fp,XH),e(XH,rno),e(fp,ano),e(fp,j9),e(j9,nno),e(fp,sno),e($,lno),e($,cp),e(cp,WH),e(WH,ino),e(cp,dno),e(cp,N9),e(N9,mno),e(cp,fno),e($,cno),e($,gp),e(gp,VH),e(VH,gno),e(gp,hno),e(gp,D9),e(D9,uno),e(gp,pno),e($,_no),e($,hp),e(hp,QH),e(QH,vno),e(hp,bno),e(hp,G9),e(G9,Tno),e(hp,Fno),e($,Mno),e($,up),e(up,HH),e(HH,Eno),e(up,Cno),e(up,O9),e(O9,yno),e(up,wno),e($,Ano),e($,pp),e(pp,UH),e(UH,xno),e(pp,Lno),e(pp,q9),e(q9,Bno),e(pp,kno),e($,Rno),e($,_p),e(_p,JH),e(JH,Sno),e(_p,Pno),e(_p,z9),e(z9,$no),e(_p,Ino),e($,jno),e($,vp),e(vp,KH),e(KH,Nno),e(vp,Dno),e(vp,X9),e(X9,Gno),e(vp,Ono),e($,qno),e($,bp),e(bp,YH),e(YH,zno),e(bp,Xno),e(bp,ZH),e(ZH,Wno),e(bp,Vno),e($,Qno),e($,Tp),e(Tp,eU),e(eU,Hno),e(Tp,Uno),e(Tp,W9),e(W9,Jno),e(Tp,Kno),e($,Yno),e($,Fp),e(Fp,oU),e(oU,Zno),e(Fp,eso),e(Fp,V9),e(V9,oso),e(Fp,tso),e(ke,rso),e(ke,Mp),e(Mp,aso),e(Mp,tU),e(tU,nso),e(Mp,sso),e(Mp,rU),e(rU,lso),e(ke,iso),e(ke,aU),e(aU,dso),e(ke,mso),g(jM,ke,null),v(d,GEe,_),v(d,vi,_),e(vi,Ep),e(Ep,nU),g(NM,nU,null),e(vi,fso),e(vi,sU),e(sU,cso),v(d,OEe,_),v(d,No,_),g(DM,No,null),e(No,gso),e(No,bi),e(bi,hso),e(bi,lU),e(lU,uso),e(bi,pso),e(bi,iU),e(iU,_so),e(bi,vso),e(No,bso),e(No,GM),e(GM,Tso),e(GM,dU),e(dU,Fso),e(GM,Mso),e(No,Eso),e(No,Bt),g(OM,Bt,null),e(Bt,Cso),e(Bt,mU),e(mU,yso),e(Bt,wso),e(Bt,Ti),e(Ti,Aso),e(Ti,fU),e(fU,xso),e(Ti,Lso),e(Ti,cU),e(cU,Bso),e(Ti,kso),e(Bt,Rso),e(Bt,gU),e(gU,Sso),e(Bt,Pso),g(qM,Bt,null),e(No,$so),e(No,Re),g(zM,Re,null),e(Re,Iso),e(Re,hU),e(hU,jso),e(Re,Nso),e(Re,Aa),e(Aa,Dso),e(Aa,uU),e(uU,Gso),e(Aa,Oso),e(Aa,pU),e(pU,qso),e(Aa,zso),e(Aa,_U),e(_U,Xso),e(Aa,Wso),e(Re,Vso),e(Re,ne),e(ne,Cp),e(Cp,vU),e(vU,Qso),e(Cp,Hso),e(Cp,Q9),e(Q9,Uso),e(Cp,Jso),e(ne,Kso),e(ne,yp),e(yp,bU),e(bU,Yso),e(yp,Zso),e(yp,H9),e(H9,elo),e(yp,olo),e(ne,tlo),e(ne,wp),e(wp,TU),e(TU,rlo),e(wp,alo),e(wp,U9),e(U9,nlo),e(wp,slo),e(ne,llo),e(ne,Ap),e(Ap,FU),e(FU,ilo),e(Ap,dlo),e(Ap,J9),e(J9,mlo),e(Ap,flo),e(ne,clo),e(ne,xp),e(xp,MU),e(MU,glo),e(xp,hlo),e(xp,K9),e(K9,ulo),e(xp,plo),e(ne,_lo),e(ne,Lp),e(Lp,EU),e(EU,vlo),e(Lp,blo),e(Lp,Y9),e(Y9,Tlo),e(Lp,Flo),e(ne,Mlo),e(ne,Bp),e(Bp,CU),e(CU,Elo),e(Bp,Clo),e(Bp,Z9),e(Z9,ylo),e(Bp,wlo),e(ne,Alo),e(ne,kp),e(kp,yU),e(yU,xlo),e(kp,Llo),e(kp,ek),e(ek,Blo),e(kp,klo),e(ne,Rlo),e(ne,Rp),e(Rp,wU),e(wU,Slo),e(Rp,Plo),e(Rp,ok),e(ok,$lo),e(Rp,Ilo),e(ne,jlo),e(ne,Sp),e(Sp,AU),e(AU,Nlo),e(Sp,Dlo),e(Sp,tk),e(tk,Glo),e(Sp,Olo),e(ne,qlo),e(ne,Pp),e(Pp,xU),e(xU,zlo),e(Pp,Xlo),e(Pp,rk),e(rk,Wlo),e(Pp,Vlo),e(ne,Qlo),e(ne,$p),e($p,LU),e(LU,Hlo),e($p,Ulo),e($p,ak),e(ak,Jlo),e($p,Klo),e(ne,Ylo),e(ne,Ip),e(Ip,BU),e(BU,Zlo),e(Ip,eio),e(Ip,nk),e(nk,oio),e(Ip,tio),e(ne,rio),e(ne,jp),e(jp,kU),e(kU,aio),e(jp,nio),e(jp,sk),e(sk,sio),e(jp,lio),e(ne,iio),e(ne,Np),e(Np,RU),e(RU,dio),e(Np,mio),e(Np,lk),e(lk,fio),e(Np,cio),e(Re,gio),e(Re,Dp),e(Dp,hio),e(Dp,SU),e(SU,uio),e(Dp,pio),e(Dp,PU),e(PU,_io),e(Re,vio),e(Re,$U),e($U,bio),e(Re,Tio),g(XM,Re,null),v(d,qEe,_),v(d,Fi,_),e(Fi,Gp),e(Gp,IU),g(WM,IU,null),e(Fi,Fio),e(Fi,jU),e(jU,Mio),v(d,zEe,_),v(d,Do,_),g(VM,Do,null),e(Do,Eio),e(Do,Mi),e(Mi,Cio),e(Mi,NU),e(NU,yio),e(Mi,wio),e(Mi,DU),e(DU,Aio),e(Mi,xio),e(Do,Lio),e(Do,QM),e(QM,Bio),e(QM,GU),e(GU,kio),e(QM,Rio),e(Do,Sio),e(Do,kt),g(HM,kt,null),e(kt,Pio),e(kt,OU),e(OU,$io),e(kt,Iio),e(kt,Ei),e(Ei,jio),e(Ei,qU),e(qU,Nio),e(Ei,Dio),e(Ei,zU),e(zU,Gio),e(Ei,Oio),e(kt,qio),e(kt,XU),e(XU,zio),e(kt,Xio),g(UM,kt,null),e(Do,Wio),e(Do,Se),g(JM,Se,null),e(Se,Vio),e(Se,WU),e(WU,Qio),e(Se,Hio),e(Se,xa),e(xa,Uio),e(xa,VU),e(VU,Jio),e(xa,Kio),e(xa,QU),e(QU,Yio),e(xa,Zio),e(xa,HU),e(HU,edo),e(xa,odo),e(Se,tdo),e(Se,A),e(A,Op),e(Op,UU),e(UU,rdo),e(Op,ado),e(Op,ik),e(ik,ndo),e(Op,sdo),e(A,ldo),e(A,qp),e(qp,JU),e(JU,ido),e(qp,ddo),e(qp,dk),e(dk,mdo),e(qp,fdo),e(A,cdo),e(A,zp),e(zp,KU),e(KU,gdo),e(zp,hdo),e(zp,mk),e(mk,udo),e(zp,pdo),e(A,_do),e(A,Xp),e(Xp,YU),e(YU,vdo),e(Xp,bdo),e(Xp,fk),e(fk,Tdo),e(Xp,Fdo),e(A,Mdo),e(A,Wp),e(Wp,ZU),e(ZU,Edo),e(Wp,Cdo),e(Wp,ck),e(ck,ydo),e(Wp,wdo),e(A,Ado),e(A,Vp),e(Vp,eJ),e(eJ,xdo),e(Vp,Ldo),e(Vp,gk),e(gk,Bdo),e(Vp,kdo),e(A,Rdo),e(A,Qp),e(Qp,oJ),e(oJ,Sdo),e(Qp,Pdo),e(Qp,hk),e(hk,$do),e(Qp,Ido),e(A,jdo),e(A,Hp),e(Hp,tJ),e(tJ,Ndo),e(Hp,Ddo),e(Hp,uk),e(uk,Gdo),e(Hp,Odo),e(A,qdo),e(A,Up),e(Up,rJ),e(rJ,zdo),e(Up,Xdo),e(Up,pk),e(pk,Wdo),e(Up,Vdo),e(A,Qdo),e(A,Jp),e(Jp,aJ),e(aJ,Hdo),e(Jp,Udo),e(Jp,_k),e(_k,Jdo),e(Jp,Kdo),e(A,Ydo),e(A,Kp),e(Kp,nJ),e(nJ,Zdo),e(Kp,emo),e(Kp,vk),e(vk,omo),e(Kp,tmo),e(A,rmo),e(A,Yp),e(Yp,sJ),e(sJ,amo),e(Yp,nmo),e(Yp,bk),e(bk,smo),e(Yp,lmo),e(A,imo),e(A,Zp),e(Zp,lJ),e(lJ,dmo),e(Zp,mmo),e(Zp,Tk),e(Tk,fmo),e(Zp,cmo),e(A,gmo),e(A,e_),e(e_,iJ),e(iJ,hmo),e(e_,umo),e(e_,Fk),e(Fk,pmo),e(e_,_mo),e(A,vmo),e(A,o_),e(o_,dJ),e(dJ,bmo),e(o_,Tmo),e(o_,Mk),e(Mk,Fmo),e(o_,Mmo),e(A,Emo),e(A,t_),e(t_,mJ),e(mJ,Cmo),e(t_,ymo),e(t_,Ek),e(Ek,wmo),e(t_,Amo),e(A,xmo),e(A,r_),e(r_,fJ),e(fJ,Lmo),e(r_,Bmo),e(r_,Ck),e(Ck,kmo),e(r_,Rmo),e(A,Smo),e(A,a_),e(a_,cJ),e(cJ,Pmo),e(a_,$mo),e(a_,yk),e(yk,Imo),e(a_,jmo),e(A,Nmo),e(A,n_),e(n_,gJ),e(gJ,Dmo),e(n_,Gmo),e(n_,wk),e(wk,Omo),e(n_,qmo),e(A,zmo),e(A,s_),e(s_,hJ),e(hJ,Xmo),e(s_,Wmo),e(s_,Ak),e(Ak,Vmo),e(s_,Qmo),e(A,Hmo),e(A,l_),e(l_,uJ),e(uJ,Umo),e(l_,Jmo),e(l_,xk),e(xk,Kmo),e(l_,Ymo),e(A,Zmo),e(A,i_),e(i_,pJ),e(pJ,efo),e(i_,ofo),e(i_,Lk),e(Lk,tfo),e(i_,rfo),e(A,afo),e(A,d_),e(d_,_J),e(_J,nfo),e(d_,sfo),e(d_,Bk),e(Bk,lfo),e(d_,ifo),e(A,dfo),e(A,m_),e(m_,vJ),e(vJ,mfo),e(m_,ffo),e(m_,kk),e(kk,cfo),e(m_,gfo),e(A,hfo),e(A,f_),e(f_,bJ),e(bJ,ufo),e(f_,pfo),e(f_,Rk),e(Rk,_fo),e(f_,vfo),e(A,bfo),e(A,c_),e(c_,TJ),e(TJ,Tfo),e(c_,Ffo),e(c_,Sk),e(Sk,Mfo),e(c_,Efo),e(A,Cfo),e(A,g_),e(g_,FJ),e(FJ,yfo),e(g_,wfo),e(g_,Pk),e(Pk,Afo),e(g_,xfo),e(A,Lfo),e(A,h_),e(h_,MJ),e(MJ,Bfo),e(h_,kfo),e(h_,$k),e($k,Rfo),e(h_,Sfo),e(A,Pfo),e(A,u_),e(u_,EJ),e(EJ,$fo),e(u_,Ifo),e(u_,Ik),e(Ik,jfo),e(u_,Nfo),e(A,Dfo),e(A,p_),e(p_,CJ),e(CJ,Gfo),e(p_,Ofo),e(p_,jk),e(jk,qfo),e(p_,zfo),e(A,Xfo),e(A,__),e(__,yJ),e(yJ,Wfo),e(__,Vfo),e(__,Nk),e(Nk,Qfo),e(__,Hfo),e(A,Ufo),e(A,v_),e(v_,wJ),e(wJ,Jfo),e(v_,Kfo),e(v_,Dk),e(Dk,Yfo),e(v_,Zfo),e(A,eco),e(A,b_),e(b_,AJ),e(AJ,oco),e(b_,tco),e(b_,Gk),e(Gk,rco),e(b_,aco),e(A,nco),e(A,T_),e(T_,xJ),e(xJ,sco),e(T_,lco),e(T_,Ok),e(Ok,ico),e(T_,dco),e(A,mco),e(A,F_),e(F_,LJ),e(LJ,fco),e(F_,cco),e(F_,qk),e(qk,gco),e(F_,hco),e(A,uco),e(A,M_),e(M_,BJ),e(BJ,pco),e(M_,_co),e(M_,zk),e(zk,vco),e(M_,bco),e(A,Tco),e(A,E_),e(E_,kJ),e(kJ,Fco),e(E_,Mco),e(E_,Xk),e(Xk,Eco),e(E_,Cco),e(A,yco),e(A,C_),e(C_,RJ),e(RJ,wco),e(C_,Aco),e(C_,Wk),e(Wk,xco),e(C_,Lco),e(A,Bco),e(A,y_),e(y_,SJ),e(SJ,kco),e(y_,Rco),e(y_,Vk),e(Vk,Sco),e(y_,Pco),e(A,$co),e(A,w_),e(w_,PJ),e(PJ,Ico),e(w_,jco),e(w_,Qk),e(Qk,Nco),e(w_,Dco),e(A,Gco),e(A,A_),e(A_,$J),e($J,Oco),e(A_,qco),e(A_,Hk),e(Hk,zco),e(A_,Xco),e(Se,Wco),e(Se,x_),e(x_,Vco),e(x_,IJ),e(IJ,Qco),e(x_,Hco),e(x_,jJ),e(jJ,Uco),e(Se,Jco),e(Se,NJ),e(NJ,Kco),e(Se,Yco),g(KM,Se,null),v(d,XEe,_),v(d,Ci,_),e(Ci,L_),e(L_,DJ),g(YM,DJ,null),e(Ci,Zco),e(Ci,GJ),e(GJ,ego),v(d,WEe,_),v(d,Go,_),g(ZM,Go,null),e(Go,ogo),e(Go,yi),e(yi,tgo),e(yi,OJ),e(OJ,rgo),e(yi,ago),e(yi,qJ),e(qJ,ngo),e(yi,sgo),e(Go,lgo),e(Go,eE),e(eE,igo),e(eE,zJ),e(zJ,dgo),e(eE,mgo),e(Go,fgo),e(Go,Rt),g(oE,Rt,null),e(Rt,cgo),e(Rt,XJ),e(XJ,ggo),e(Rt,hgo),e(Rt,wi),e(wi,ugo),e(wi,WJ),e(WJ,pgo),e(wi,_go),e(wi,VJ),e(VJ,vgo),e(wi,bgo),e(Rt,Tgo),e(Rt,QJ),e(QJ,Fgo),e(Rt,Mgo),g(tE,Rt,null),e(Go,Ego),e(Go,Pe),g(rE,Pe,null),e(Pe,Cgo),e(Pe,HJ),e(HJ,ygo),e(Pe,wgo),e(Pe,La),e(La,Ago),e(La,UJ),e(UJ,xgo),e(La,Lgo),e(La,JJ),e(JJ,Bgo),e(La,kgo),e(La,KJ),e(KJ,Rgo),e(La,Sgo),e(Pe,Pgo),e(Pe,q),e(q,B_),e(B_,YJ),e(YJ,$go),e(B_,Igo),e(B_,Uk),e(Uk,jgo),e(B_,Ngo),e(q,Dgo),e(q,k_),e(k_,ZJ),e(ZJ,Ggo),e(k_,Ogo),e(k_,Jk),e(Jk,qgo),e(k_,zgo),e(q,Xgo),e(q,R_),e(R_,eK),e(eK,Wgo),e(R_,Vgo),e(R_,Kk),e(Kk,Qgo),e(R_,Hgo),e(q,Ugo),e(q,S_),e(S_,oK),e(oK,Jgo),e(S_,Kgo),e(S_,Yk),e(Yk,Ygo),e(S_,Zgo),e(q,eho),e(q,P_),e(P_,tK),e(tK,oho),e(P_,tho),e(P_,Zk),e(Zk,rho),e(P_,aho),e(q,nho),e(q,$_),e($_,rK),e(rK,sho),e($_,lho),e($_,eR),e(eR,iho),e($_,dho),e(q,mho),e(q,I_),e(I_,aK),e(aK,fho),e(I_,cho),e(I_,oR),e(oR,gho),e(I_,hho),e(q,uho),e(q,j_),e(j_,nK),e(nK,pho),e(j_,_ho),e(j_,tR),e(tR,vho),e(j_,bho),e(q,Tho),e(q,N_),e(N_,sK),e(sK,Fho),e(N_,Mho),e(N_,rR),e(rR,Eho),e(N_,Cho),e(q,yho),e(q,D_),e(D_,lK),e(lK,who),e(D_,Aho),e(D_,aR),e(aR,xho),e(D_,Lho),e(q,Bho),e(q,G_),e(G_,iK),e(iK,kho),e(G_,Rho),e(G_,nR),e(nR,Sho),e(G_,Pho),e(q,$ho),e(q,O_),e(O_,dK),e(dK,Iho),e(O_,jho),e(O_,sR),e(sR,Nho),e(O_,Dho),e(q,Gho),e(q,q_),e(q_,mK),e(mK,Oho),e(q_,qho),e(q_,lR),e(lR,zho),e(q_,Xho),e(q,Who),e(q,z_),e(z_,fK),e(fK,Vho),e(z_,Qho),e(z_,iR),e(iR,Hho),e(z_,Uho),e(q,Jho),e(q,X_),e(X_,cK),e(cK,Kho),e(X_,Yho),e(X_,dR),e(dR,Zho),e(X_,euo),e(q,ouo),e(q,W_),e(W_,gK),e(gK,tuo),e(W_,ruo),e(W_,mR),e(mR,auo),e(W_,nuo),e(q,suo),e(q,V_),e(V_,hK),e(hK,luo),e(V_,iuo),e(V_,fR),e(fR,duo),e(V_,muo),e(q,fuo),e(q,Q_),e(Q_,uK),e(uK,cuo),e(Q_,guo),e(Q_,cR),e(cR,huo),e(Q_,uuo),e(q,puo),e(q,H_),e(H_,pK),e(pK,_uo),e(H_,vuo),e(H_,gR),e(gR,buo),e(H_,Tuo),e(q,Fuo),e(q,U_),e(U_,_K),e(_K,Muo),e(U_,Euo),e(U_,hR),e(hR,Cuo),e(U_,yuo),e(q,wuo),e(q,J_),e(J_,vK),e(vK,Auo),e(J_,xuo),e(J_,uR),e(uR,Luo),e(J_,Buo),e(q,kuo),e(q,K_),e(K_,bK),e(bK,Ruo),e(K_,Suo),e(K_,pR),e(pR,Puo),e(K_,$uo),e(q,Iuo),e(q,Y_),e(Y_,TK),e(TK,juo),e(Y_,Nuo),e(Y_,_R),e(_R,Duo),e(Y_,Guo),e(q,Ouo),e(q,Z_),e(Z_,FK),e(FK,quo),e(Z_,zuo),e(Z_,vR),e(vR,Xuo),e(Z_,Wuo),e(Pe,Vuo),e(Pe,ev),e(ev,Quo),e(ev,MK),e(MK,Huo),e(ev,Uuo),e(ev,EK),e(EK,Juo),e(Pe,Kuo),e(Pe,CK),e(CK,Yuo),e(Pe,Zuo),g(aE,Pe,null),v(d,VEe,_),v(d,Ai,_),e(Ai,ov),e(ov,yK),g(nE,yK,null),e(Ai,epo),e(Ai,wK),e(wK,opo),v(d,QEe,_),v(d,Oo,_),g(sE,Oo,null),e(Oo,tpo),e(Oo,xi),e(xi,rpo),e(xi,AK),e(AK,apo),e(xi,npo),e(xi,xK),e(xK,spo),e(xi,lpo),e(Oo,ipo),e(Oo,lE),e(lE,dpo),e(lE,LK),e(LK,mpo),e(lE,fpo),e(Oo,cpo),e(Oo,St),g(iE,St,null),e(St,gpo),e(St,BK),e(BK,hpo),e(St,upo),e(St,Li),e(Li,ppo),e(Li,kK),e(kK,_po),e(Li,vpo),e(Li,RK),e(RK,bpo),e(Li,Tpo),e(St,Fpo),e(St,SK),e(SK,Mpo),e(St,Epo),g(dE,St,null),e(Oo,Cpo),e(Oo,$e),g(mE,$e,null),e($e,ypo),e($e,PK),e(PK,wpo),e($e,Apo),e($e,Ba),e(Ba,xpo),e(Ba,$K),e($K,Lpo),e(Ba,Bpo),e(Ba,IK),e(IK,kpo),e(Ba,Rpo),e(Ba,jK),e(jK,Spo),e(Ba,Ppo),e($e,$po),e($e,qr),e(qr,tv),e(tv,NK),e(NK,Ipo),e(tv,jpo),e(tv,bR),e(bR,Npo),e(tv,Dpo),e(qr,Gpo),e(qr,rv),e(rv,DK),e(DK,Opo),e(rv,qpo),e(rv,TR),e(TR,zpo),e(rv,Xpo),e(qr,Wpo),e(qr,av),e(av,GK),e(GK,Vpo),e(av,Qpo),e(av,FR),e(FR,Hpo),e(av,Upo),e(qr,Jpo),e(qr,nv),e(nv,OK),e(OK,Kpo),e(nv,Ypo),e(nv,MR),e(MR,Zpo),e(nv,e_o),e(qr,o_o),e(qr,sv),e(sv,qK),e(qK,t_o),e(sv,r_o),e(sv,ER),e(ER,a_o),e(sv,n_o),e($e,s_o),e($e,lv),e(lv,l_o),e(lv,zK),e(zK,i_o),e(lv,d_o),e(lv,XK),e(XK,m_o),e($e,f_o),e($e,WK),e(WK,c_o),e($e,g_o),g(fE,$e,null),v(d,HEe,_),v(d,Bi,_),e(Bi,iv),e(iv,VK),g(cE,VK,null),e(Bi,h_o),e(Bi,QK),e(QK,u_o),v(d,UEe,_),v(d,qo,_),g(gE,qo,null),e(qo,p_o),e(qo,ki),e(ki,__o),e(ki,HK),e(HK,v_o),e(ki,b_o),e(ki,UK),e(UK,T_o),e(ki,F_o),e(qo,M_o),e(qo,hE),e(hE,E_o),e(hE,JK),e(JK,C_o),e(hE,y_o),e(qo,w_o),e(qo,Pt),g(uE,Pt,null),e(Pt,A_o),e(Pt,KK),e(KK,x_o),e(Pt,L_o),e(Pt,Ri),e(Ri,B_o),e(Ri,YK),e(YK,k_o),e(Ri,R_o),e(Ri,ZK),e(ZK,S_o),e(Ri,P_o),e(Pt,$_o),e(Pt,eY),e(eY,I_o),e(Pt,j_o),g(pE,Pt,null),e(qo,N_o),e(qo,Ie),g(_E,Ie,null),e(Ie,D_o),e(Ie,oY),e(oY,G_o),e(Ie,O_o),e(Ie,ka),e(ka,q_o),e(ka,tY),e(tY,z_o),e(ka,X_o),e(ka,rY),e(rY,W_o),e(ka,V_o),e(ka,aY),e(aY,Q_o),e(ka,H_o),e(Ie,U_o),e(Ie,N),e(N,dv),e(dv,nY),e(nY,J_o),e(dv,K_o),e(dv,CR),e(CR,Y_o),e(dv,Z_o),e(N,evo),e(N,mv),e(mv,sY),e(sY,ovo),e(mv,tvo),e(mv,yR),e(yR,rvo),e(mv,avo),e(N,nvo),e(N,fv),e(fv,lY),e(lY,svo),e(fv,lvo),e(fv,wR),e(wR,ivo),e(fv,dvo),e(N,mvo),e(N,cv),e(cv,iY),e(iY,fvo),e(cv,cvo),e(cv,AR),e(AR,gvo),e(cv,hvo),e(N,uvo),e(N,gv),e(gv,dY),e(dY,pvo),e(gv,_vo),e(gv,xR),e(xR,vvo),e(gv,bvo),e(N,Tvo),e(N,hv),e(hv,mY),e(mY,Fvo),e(hv,Mvo),e(hv,LR),e(LR,Evo),e(hv,Cvo),e(N,yvo),e(N,uv),e(uv,fY),e(fY,wvo),e(uv,Avo),e(uv,BR),e(BR,xvo),e(uv,Lvo),e(N,Bvo),e(N,pv),e(pv,cY),e(cY,kvo),e(pv,Rvo),e(pv,kR),e(kR,Svo),e(pv,Pvo),e(N,$vo),e(N,_v),e(_v,gY),e(gY,Ivo),e(_v,jvo),e(_v,RR),e(RR,Nvo),e(_v,Dvo),e(N,Gvo),e(N,vv),e(vv,hY),e(hY,Ovo),e(vv,qvo),e(vv,SR),e(SR,zvo),e(vv,Xvo),e(N,Wvo),e(N,bv),e(bv,uY),e(uY,Vvo),e(bv,Qvo),e(bv,PR),e(PR,Hvo),e(bv,Uvo),e(N,Jvo),e(N,Tv),e(Tv,pY),e(pY,Kvo),e(Tv,Yvo),e(Tv,$R),e($R,Zvo),e(Tv,e1o),e(N,o1o),e(N,Fv),e(Fv,_Y),e(_Y,t1o),e(Fv,r1o),e(Fv,IR),e(IR,a1o),e(Fv,n1o),e(N,s1o),e(N,Mv),e(Mv,vY),e(vY,l1o),e(Mv,i1o),e(Mv,jR),e(jR,d1o),e(Mv,m1o),e(N,f1o),e(N,Ev),e(Ev,bY),e(bY,c1o),e(Ev,g1o),e(Ev,NR),e(NR,h1o),e(Ev,u1o),e(N,p1o),e(N,Cv),e(Cv,TY),e(TY,_1o),e(Cv,v1o),e(Cv,DR),e(DR,b1o),e(Cv,T1o),e(N,F1o),e(N,yv),e(yv,FY),e(FY,M1o),e(yv,E1o),e(yv,GR),e(GR,C1o),e(yv,y1o),e(N,w1o),e(N,wv),e(wv,MY),e(MY,A1o),e(wv,x1o),e(wv,OR),e(OR,L1o),e(wv,B1o),e(N,k1o),e(N,Av),e(Av,EY),e(EY,R1o),e(Av,S1o),e(Av,qR),e(qR,P1o),e(Av,$1o),e(N,I1o),e(N,xv),e(xv,CY),e(CY,j1o),e(xv,N1o),e(xv,zR),e(zR,D1o),e(xv,G1o),e(N,O1o),e(N,Lv),e(Lv,yY),e(yY,q1o),e(Lv,z1o),e(Lv,XR),e(XR,X1o),e(Lv,W1o),e(N,V1o),e(N,Bv),e(Bv,wY),e(wY,Q1o),e(Bv,H1o),e(Bv,WR),e(WR,U1o),e(Bv,J1o),e(N,K1o),e(N,kv),e(kv,AY),e(AY,Y1o),e(kv,Z1o),e(kv,VR),e(VR,e2o),e(kv,o2o),e(N,t2o),e(N,Rv),e(Rv,xY),e(xY,r2o),e(Rv,a2o),e(Rv,QR),e(QR,n2o),e(Rv,s2o),e(N,l2o),e(N,Sv),e(Sv,LY),e(LY,i2o),e(Sv,d2o),e(Sv,HR),e(HR,m2o),e(Sv,f2o),e(N,c2o),e(N,Pv),e(Pv,BY),e(BY,g2o),e(Pv,h2o),e(Pv,UR),e(UR,u2o),e(Pv,p2o),e(N,_2o),e(N,$v),e($v,kY),e(kY,v2o),e($v,b2o),e($v,JR),e(JR,T2o),e($v,F2o),e(N,M2o),e(N,Iv),e(Iv,RY),e(RY,E2o),e(Iv,C2o),e(Iv,KR),e(KR,y2o),e(Iv,w2o),e(N,A2o),e(N,jv),e(jv,SY),e(SY,x2o),e(jv,L2o),e(jv,YR),e(YR,B2o),e(jv,k2o),e(Ie,R2o),e(Ie,Nv),e(Nv,S2o),e(Nv,PY),e(PY,P2o),e(Nv,$2o),e(Nv,$Y),e($Y,I2o),e(Ie,j2o),e(Ie,IY),e(IY,N2o),e(Ie,D2o),g(vE,Ie,null),v(d,JEe,_),v(d,Si,_),e(Si,Dv),e(Dv,jY),g(bE,jY,null),e(Si,G2o),e(Si,NY),e(NY,O2o),v(d,KEe,_),v(d,zo,_),g(TE,zo,null),e(zo,q2o),e(zo,Pi),e(Pi,z2o),e(Pi,DY),e(DY,X2o),e(Pi,W2o),e(Pi,GY),e(GY,V2o),e(Pi,Q2o),e(zo,H2o),e(zo,FE),e(FE,U2o),e(FE,OY),e(OY,J2o),e(FE,K2o),e(zo,Y2o),e(zo,$t),g(ME,$t,null),e($t,Z2o),e($t,qY),e(qY,ebo),e($t,obo),e($t,$i),e($i,tbo),e($i,zY),e(zY,rbo),e($i,abo),e($i,XY),e(XY,nbo),e($i,sbo),e($t,lbo),e($t,WY),e(WY,ibo),e($t,dbo),g(EE,$t,null),e(zo,mbo),e(zo,je),g(CE,je,null),e(je,fbo),e(je,VY),e(VY,cbo),e(je,gbo),e(je,Ra),e(Ra,hbo),e(Ra,QY),e(QY,ubo),e(Ra,pbo),e(Ra,HY),e(HY,_bo),e(Ra,vbo),e(Ra,UY),e(UY,bbo),e(Ra,Tbo),e(je,Fbo),e(je,R),e(R,Gv),e(Gv,JY),e(JY,Mbo),e(Gv,Ebo),e(Gv,ZR),e(ZR,Cbo),e(Gv,ybo),e(R,wbo),e(R,Ov),e(Ov,KY),e(KY,Abo),e(Ov,xbo),e(Ov,eS),e(eS,Lbo),e(Ov,Bbo),e(R,kbo),e(R,qv),e(qv,YY),e(YY,Rbo),e(qv,Sbo),e(qv,oS),e(oS,Pbo),e(qv,$bo),e(R,Ibo),e(R,zv),e(zv,ZY),e(ZY,jbo),e(zv,Nbo),e(zv,tS),e(tS,Dbo),e(zv,Gbo),e(R,Obo),e(R,Xv),e(Xv,eZ),e(eZ,qbo),e(Xv,zbo),e(Xv,rS),e(rS,Xbo),e(Xv,Wbo),e(R,Vbo),e(R,Wv),e(Wv,oZ),e(oZ,Qbo),e(Wv,Hbo),e(Wv,aS),e(aS,Ubo),e(Wv,Jbo),e(R,Kbo),e(R,Vv),e(Vv,tZ),e(tZ,Ybo),e(Vv,Zbo),e(Vv,nS),e(nS,e4o),e(Vv,o4o),e(R,t4o),e(R,Qv),e(Qv,rZ),e(rZ,r4o),e(Qv,a4o),e(Qv,sS),e(sS,n4o),e(Qv,s4o),e(R,l4o),e(R,Hv),e(Hv,aZ),e(aZ,i4o),e(Hv,d4o),e(Hv,lS),e(lS,m4o),e(Hv,f4o),e(R,c4o),e(R,Uv),e(Uv,nZ),e(nZ,g4o),e(Uv,h4o),e(Uv,iS),e(iS,u4o),e(Uv,p4o),e(R,_4o),e(R,Jv),e(Jv,sZ),e(sZ,v4o),e(Jv,b4o),e(Jv,dS),e(dS,T4o),e(Jv,F4o),e(R,M4o),e(R,Kv),e(Kv,lZ),e(lZ,E4o),e(Kv,C4o),e(Kv,mS),e(mS,y4o),e(Kv,w4o),e(R,A4o),e(R,Yv),e(Yv,iZ),e(iZ,x4o),e(Yv,L4o),e(Yv,fS),e(fS,B4o),e(Yv,k4o),e(R,R4o),e(R,Zv),e(Zv,dZ),e(dZ,S4o),e(Zv,P4o),e(Zv,cS),e(cS,$4o),e(Zv,I4o),e(R,j4o),e(R,e1),e(e1,mZ),e(mZ,N4o),e(e1,D4o),e(e1,gS),e(gS,G4o),e(e1,O4o),e(R,q4o),e(R,o1),e(o1,fZ),e(fZ,z4o),e(o1,X4o),e(o1,hS),e(hS,W4o),e(o1,V4o),e(R,Q4o),e(R,t1),e(t1,cZ),e(cZ,H4o),e(t1,U4o),e(t1,uS),e(uS,J4o),e(t1,K4o),e(R,Y4o),e(R,r1),e(r1,gZ),e(gZ,Z4o),e(r1,e5o),e(r1,pS),e(pS,o5o),e(r1,t5o),e(R,r5o),e(R,a1),e(a1,hZ),e(hZ,a5o),e(a1,n5o),e(a1,_S),e(_S,s5o),e(a1,l5o),e(R,i5o),e(R,n1),e(n1,uZ),e(uZ,d5o),e(n1,m5o),e(n1,vS),e(vS,f5o),e(n1,c5o),e(R,g5o),e(R,s1),e(s1,pZ),e(pZ,h5o),e(s1,u5o),e(s1,bS),e(bS,p5o),e(s1,_5o),e(R,v5o),e(R,l1),e(l1,_Z),e(_Z,b5o),e(l1,T5o),e(l1,TS),e(TS,F5o),e(l1,M5o),e(R,E5o),e(R,i1),e(i1,vZ),e(vZ,C5o),e(i1,y5o),e(i1,FS),e(FS,w5o),e(i1,A5o),e(R,x5o),e(R,d1),e(d1,bZ),e(bZ,L5o),e(d1,B5o),e(d1,MS),e(MS,k5o),e(d1,R5o),e(R,S5o),e(R,m1),e(m1,TZ),e(TZ,P5o),e(m1,$5o),e(m1,ES),e(ES,I5o),e(m1,j5o),e(R,N5o),e(R,f1),e(f1,FZ),e(FZ,D5o),e(f1,G5o),e(f1,CS),e(CS,O5o),e(f1,q5o),e(R,z5o),e(R,c1),e(c1,MZ),e(MZ,X5o),e(c1,W5o),e(c1,yS),e(yS,V5o),e(c1,Q5o),e(R,H5o),e(R,g1),e(g1,EZ),e(EZ,U5o),e(g1,J5o),e(g1,wS),e(wS,K5o),e(g1,Y5o),e(R,Z5o),e(R,h1),e(h1,CZ),e(CZ,e0o),e(h1,o0o),e(h1,AS),e(AS,t0o),e(h1,r0o),e(R,a0o),e(R,u1),e(u1,yZ),e(yZ,n0o),e(u1,s0o),e(u1,xS),e(xS,l0o),e(u1,i0o),e(R,d0o),e(R,p1),e(p1,wZ),e(wZ,m0o),e(p1,f0o),e(p1,LS),e(LS,c0o),e(p1,g0o),e(R,h0o),e(R,_1),e(_1,AZ),e(AZ,u0o),e(_1,p0o),e(_1,BS),e(BS,_0o),e(_1,v0o),e(R,b0o),e(R,v1),e(v1,xZ),e(xZ,T0o),e(v1,F0o),e(v1,kS),e(kS,M0o),e(v1,E0o),e(R,C0o),e(R,b1),e(b1,LZ),e(LZ,y0o),e(b1,w0o),e(b1,RS),e(RS,A0o),e(b1,x0o),e(R,L0o),e(R,T1),e(T1,BZ),e(BZ,B0o),e(T1,k0o),e(T1,SS),e(SS,R0o),e(T1,S0o),e(je,P0o),e(je,F1),e(F1,$0o),e(F1,kZ),e(kZ,I0o),e(F1,j0o),e(F1,RZ),e(RZ,N0o),e(je,D0o),e(je,SZ),e(SZ,G0o),e(je,O0o),g(yE,je,null),v(d,YEe,_),v(d,Ii,_),e(Ii,M1),e(M1,PZ),g(wE,PZ,null),e(Ii,q0o),e(Ii,$Z),e($Z,z0o),v(d,ZEe,_),v(d,Xo,_),g(AE,Xo,null),e(Xo,X0o),e(Xo,ji),e(ji,W0o),e(ji,IZ),e(IZ,V0o),e(ji,Q0o),e(ji,jZ),e(jZ,H0o),e(ji,U0o),e(Xo,J0o),e(Xo,xE),e(xE,K0o),e(xE,NZ),e(NZ,Y0o),e(xE,Z0o),e(Xo,eTo),e(Xo,It),g(LE,It,null),e(It,oTo),e(It,DZ),e(DZ,tTo),e(It,rTo),e(It,Ni),e(Ni,aTo),e(Ni,GZ),e(GZ,nTo),e(Ni,sTo),e(Ni,OZ),e(OZ,lTo),e(Ni,iTo),e(It,dTo),e(It,qZ),e(qZ,mTo),e(It,fTo),g(BE,It,null),e(Xo,cTo),e(Xo,Ne),g(kE,Ne,null),e(Ne,gTo),e(Ne,zZ),e(zZ,hTo),e(Ne,uTo),e(Ne,Sa),e(Sa,pTo),e(Sa,XZ),e(XZ,_To),e(Sa,vTo),e(Sa,WZ),e(WZ,bTo),e(Sa,TTo),e(Sa,VZ),e(VZ,FTo),e(Sa,MTo),e(Ne,ETo),e(Ne,QZ),e(QZ,E1),e(E1,HZ),e(HZ,CTo),e(E1,yTo),e(E1,PS),e(PS,wTo),e(E1,ATo),e(Ne,xTo),e(Ne,C1),e(C1,LTo),e(C1,UZ),e(UZ,BTo),e(C1,kTo),e(C1,JZ),e(JZ,RTo),e(Ne,STo),e(Ne,KZ),e(KZ,PTo),e(Ne,$To),g(RE,Ne,null),v(d,eCe,_),v(d,Di,_),e(Di,y1),e(y1,YZ),g(SE,YZ,null),e(Di,ITo),e(Di,ZZ),e(ZZ,jTo),v(d,oCe,_),v(d,Wo,_),g(PE,Wo,null),e(Wo,NTo),e(Wo,Gi),e(Gi,DTo),e(Gi,eee),e(eee,GTo),e(Gi,OTo),e(Gi,oee),e(oee,qTo),e(Gi,zTo),e(Wo,XTo),e(Wo,$E),e($E,WTo),e($E,tee),e(tee,VTo),e($E,QTo),e(Wo,HTo),e(Wo,jt),g(IE,jt,null),e(jt,UTo),e(jt,ree),e(ree,JTo),e(jt,KTo),e(jt,Oi),e(Oi,YTo),e(Oi,aee),e(aee,ZTo),e(Oi,eFo),e(Oi,nee),e(nee,oFo),e(Oi,tFo),e(jt,rFo),e(jt,see),e(see,aFo),e(jt,nFo),g(jE,jt,null),e(Wo,sFo),e(Wo,De),g(NE,De,null),e(De,lFo),e(De,lee),e(lee,iFo),e(De,dFo),e(De,Pa),e(Pa,mFo),e(Pa,iee),e(iee,fFo),e(Pa,cFo),e(Pa,dee),e(dee,gFo),e(Pa,hFo),e(Pa,mee),e(mee,uFo),e(Pa,pFo),e(De,_Fo),e(De,Vo),e(Vo,w1),e(w1,fee),e(fee,vFo),e(w1,bFo),e(w1,$S),e($S,TFo),e(w1,FFo),e(Vo,MFo),e(Vo,is),e(is,cee),e(cee,EFo),e(is,CFo),e(is,IS),e(IS,yFo),e(is,wFo),e(is,jS),e(jS,AFo),e(is,xFo),e(Vo,LFo),e(Vo,A1),e(A1,gee),e(gee,BFo),e(A1,kFo),e(A1,NS),e(NS,RFo),e(A1,SFo),e(Vo,PFo),e(Vo,Xr),e(Xr,hee),e(hee,$Fo),e(Xr,IFo),e(Xr,DS),e(DS,jFo),e(Xr,NFo),e(Xr,GS),e(GS,DFo),e(Xr,GFo),e(Xr,OS),e(OS,OFo),e(Xr,qFo),e(Vo,zFo),e(Vo,x1),e(x1,uee),e(uee,XFo),e(x1,WFo),e(x1,qS),e(qS,VFo),e(x1,QFo),e(Vo,HFo),e(Vo,L1),e(L1,pee),e(pee,UFo),e(L1,JFo),e(L1,zS),e(zS,KFo),e(L1,YFo),e(De,ZFo),e(De,B1),e(B1,eMo),e(B1,_ee),e(_ee,oMo),e(B1,tMo),e(B1,vee),e(vee,rMo),e(De,aMo),e(De,bee),e(bee,nMo),e(De,sMo),g(DE,De,null),v(d,tCe,_),v(d,qi,_),e(qi,k1),e(k1,Tee),g(GE,Tee,null),e(qi,lMo),e(qi,Fee),e(Fee,iMo),v(d,rCe,_),v(d,Qo,_),g(OE,Qo,null),e(Qo,dMo),e(Qo,zi),e(zi,mMo),e(zi,Mee),e(Mee,fMo),e(zi,cMo),e(zi,Eee),e(Eee,gMo),e(zi,hMo),e(Qo,uMo),e(Qo,qE),e(qE,pMo),e(qE,Cee),e(Cee,_Mo),e(qE,vMo),e(Qo,bMo),e(Qo,Nt),g(zE,Nt,null),e(Nt,TMo),e(Nt,yee),e(yee,FMo),e(Nt,MMo),e(Nt,Xi),e(Xi,EMo),e(Xi,wee),e(wee,CMo),e(Xi,yMo),e(Xi,Aee),e(Aee,wMo),e(Xi,AMo),e(Nt,xMo),e(Nt,xee),e(xee,LMo),e(Nt,BMo),g(XE,Nt,null),e(Qo,kMo),e(Qo,Ge),g(WE,Ge,null),e(Ge,RMo),e(Ge,Lee),e(Lee,SMo),e(Ge,PMo),e(Ge,$a),e($a,$Mo),e($a,Bee),e(Bee,IMo),e($a,jMo),e($a,kee),e(kee,NMo),e($a,DMo),e($a,Ree),e(Ree,GMo),e($a,OMo),e(Ge,qMo),e(Ge,See),e(See,R1),e(R1,Pee),e(Pee,zMo),e(R1,XMo),e(R1,XS),e(XS,WMo),e(R1,VMo),e(Ge,QMo),e(Ge,S1),e(S1,HMo),e(S1,$ee),e($ee,UMo),e(S1,JMo),e(S1,Iee),e(Iee,KMo),e(Ge,YMo),e(Ge,jee),e(jee,ZMo),e(Ge,eEo),g(VE,Ge,null),v(d,aCe,_),v(d,Wi,_),e(Wi,P1),e(P1,Nee),g(QE,Nee,null),e(Wi,oEo),e(Wi,Dee),e(Dee,tEo),v(d,nCe,_),v(d,Ho,_),g(HE,Ho,null),e(Ho,rEo),e(Ho,Vi),e(Vi,aEo),e(Vi,Gee),e(Gee,nEo),e(Vi,sEo),e(Vi,Oee),e(Oee,lEo),e(Vi,iEo),e(Ho,dEo),e(Ho,UE),e(UE,mEo),e(UE,qee),e(qee,fEo),e(UE,cEo),e(Ho,gEo),e(Ho,Dt),g(JE,Dt,null),e(Dt,hEo),e(Dt,zee),e(zee,uEo),e(Dt,pEo),e(Dt,Qi),e(Qi,_Eo),e(Qi,Xee),e(Xee,vEo),e(Qi,bEo),e(Qi,Wee),e(Wee,TEo),e(Qi,FEo),e(Dt,MEo),e(Dt,Vee),e(Vee,EEo),e(Dt,CEo),g(KE,Dt,null),e(Ho,yEo),e(Ho,Oe),g(YE,Oe,null),e(Oe,wEo),e(Oe,Qee),e(Qee,AEo),e(Oe,xEo),e(Oe,Ia),e(Ia,LEo),e(Ia,Hee),e(Hee,BEo),e(Ia,kEo),e(Ia,Uee),e(Uee,REo),e(Ia,SEo),e(Ia,Jee),e(Jee,PEo),e(Ia,$Eo),e(Oe,IEo),e(Oe,Ke),e(Ke,$1),e($1,Kee),e(Kee,jEo),e($1,NEo),e($1,WS),e(WS,DEo),e($1,GEo),e(Ke,OEo),e(Ke,I1),e(I1,Yee),e(Yee,qEo),e(I1,zEo),e(I1,VS),e(VS,XEo),e(I1,WEo),e(Ke,VEo),e(Ke,j1),e(j1,Zee),e(Zee,QEo),e(j1,HEo),e(j1,QS),e(QS,UEo),e(j1,JEo),e(Ke,KEo),e(Ke,N1),e(N1,eoe),e(eoe,YEo),e(N1,ZEo),e(N1,HS),e(HS,eCo),e(N1,oCo),e(Ke,tCo),e(Ke,D1),e(D1,ooe),e(ooe,rCo),e(D1,aCo),e(D1,US),e(US,nCo),e(D1,sCo),e(Ke,lCo),e(Ke,G1),e(G1,toe),e(toe,iCo),e(G1,dCo),e(G1,JS),e(JS,mCo),e(G1,fCo),e(Ke,cCo),e(Ke,O1),e(O1,roe),e(roe,gCo),e(O1,hCo),e(O1,KS),e(KS,uCo),e(O1,pCo),e(Oe,_Co),e(Oe,q1),e(q1,vCo),e(q1,aoe),e(aoe,bCo),e(q1,TCo),e(q1,noe),e(noe,FCo),e(Oe,MCo),e(Oe,soe),e(soe,ECo),e(Oe,CCo),g(ZE,Oe,null),v(d,sCe,_),v(d,Hi,_),e(Hi,z1),e(z1,loe),g(eC,loe,null),e(Hi,yCo),e(Hi,ioe),e(ioe,wCo),v(d,lCe,_),v(d,Uo,_),g(oC,Uo,null),e(Uo,ACo),e(Uo,Ui),e(Ui,xCo),e(Ui,doe),e(doe,LCo),e(Ui,BCo),e(Ui,moe),e(moe,kCo),e(Ui,RCo),e(Uo,SCo),e(Uo,tC),e(tC,PCo),e(tC,foe),e(foe,$Co),e(tC,ICo),e(Uo,jCo),e(Uo,Gt),g(rC,Gt,null),e(Gt,NCo),e(Gt,coe),e(coe,DCo),e(Gt,GCo),e(Gt,Ji),e(Ji,OCo),e(Ji,goe),e(goe,qCo),e(Ji,zCo),e(Ji,hoe),e(hoe,XCo),e(Ji,WCo),e(Gt,VCo),e(Gt,uoe),e(uoe,QCo),e(Gt,HCo),g(aC,Gt,null),e(Uo,UCo),e(Uo,qe),g(nC,qe,null),e(qe,JCo),e(qe,poe),e(poe,KCo),e(qe,YCo),e(qe,ja),e(ja,ZCo),e(ja,_oe),e(_oe,e3o),e(ja,o3o),e(ja,voe),e(voe,t3o),e(ja,r3o),e(ja,boe),e(boe,a3o),e(ja,n3o),e(qe,s3o),e(qe,Ki),e(Ki,X1),e(X1,Toe),e(Toe,l3o),e(X1,i3o),e(X1,YS),e(YS,d3o),e(X1,m3o),e(Ki,f3o),e(Ki,W1),e(W1,Foe),e(Foe,c3o),e(W1,g3o),e(W1,ZS),e(ZS,h3o),e(W1,u3o),e(Ki,p3o),e(Ki,V1),e(V1,Moe),e(Moe,_3o),e(V1,v3o),e(V1,eP),e(eP,b3o),e(V1,T3o),e(qe,F3o),e(qe,Q1),e(Q1,M3o),e(Q1,Eoe),e(Eoe,E3o),e(Q1,C3o),e(Q1,Coe),e(Coe,y3o),e(qe,w3o),e(qe,yoe),e(yoe,A3o),e(qe,x3o),g(sC,qe,null),v(d,iCe,_),v(d,Yi,_),e(Yi,H1),e(H1,woe),g(lC,woe,null),e(Yi,L3o),e(Yi,Aoe),e(Aoe,B3o),v(d,dCe,_),v(d,Jo,_),g(iC,Jo,null),e(Jo,k3o),e(Jo,Zi),e(Zi,R3o),e(Zi,xoe),e(xoe,S3o),e(Zi,P3o),e(Zi,Loe),e(Loe,$3o),e(Zi,I3o),e(Jo,j3o),e(Jo,dC),e(dC,N3o),e(dC,Boe),e(Boe,D3o),e(dC,G3o),e(Jo,O3o),e(Jo,Ot),g(mC,Ot,null),e(Ot,q3o),e(Ot,koe),e(koe,z3o),e(Ot,X3o),e(Ot,ed),e(ed,W3o),e(ed,Roe),e(Roe,V3o),e(ed,Q3o),e(ed,Soe),e(Soe,H3o),e(ed,U3o),e(Ot,J3o),e(Ot,Poe),e(Poe,K3o),e(Ot,Y3o),g(fC,Ot,null),e(Jo,Z3o),e(Jo,ze),g(cC,ze,null),e(ze,eyo),e(ze,$oe),e($oe,oyo),e(ze,tyo),e(ze,Na),e(Na,ryo),e(Na,Ioe),e(Ioe,ayo),e(Na,nyo),e(Na,joe),e(joe,syo),e(Na,lyo),e(Na,Noe),e(Noe,iyo),e(Na,dyo),e(ze,myo),e(ze,Ye),e(Ye,U1),e(U1,Doe),e(Doe,fyo),e(U1,cyo),e(U1,oP),e(oP,gyo),e(U1,hyo),e(Ye,uyo),e(Ye,J1),e(J1,Goe),e(Goe,pyo),e(J1,_yo),e(J1,tP),e(tP,vyo),e(J1,byo),e(Ye,Tyo),e(Ye,K1),e(K1,Ooe),e(Ooe,Fyo),e(K1,Myo),e(K1,rP),e(rP,Eyo),e(K1,Cyo),e(Ye,yyo),e(Ye,Y1),e(Y1,qoe),e(qoe,wyo),e(Y1,Ayo),e(Y1,aP),e(aP,xyo),e(Y1,Lyo),e(Ye,Byo),e(Ye,Z1),e(Z1,zoe),e(zoe,kyo),e(Z1,Ryo),e(Z1,nP),e(nP,Syo),e(Z1,Pyo),e(Ye,$yo),e(Ye,e2),e(e2,Xoe),e(Xoe,Iyo),e(e2,jyo),e(e2,sP),e(sP,Nyo),e(e2,Dyo),e(Ye,Gyo),e(Ye,o2),e(o2,Woe),e(Woe,Oyo),e(o2,qyo),e(o2,lP),e(lP,zyo),e(o2,Xyo),e(ze,Wyo),e(ze,t2),e(t2,Vyo),e(t2,Voe),e(Voe,Qyo),e(t2,Hyo),e(t2,Qoe),e(Qoe,Uyo),e(ze,Jyo),e(ze,Hoe),e(Hoe,Kyo),e(ze,Yyo),g(gC,ze,null),v(d,mCe,_),v(d,od,_),e(od,r2),e(r2,Uoe),g(hC,Uoe,null),e(od,Zyo),e(od,Joe),e(Joe,ewo),v(d,fCe,_),v(d,Ko,_),g(uC,Ko,null),e(Ko,owo),e(Ko,td),e(td,two),e(td,Koe),e(Koe,rwo),e(td,awo),e(td,Yoe),e(Yoe,nwo),e(td,swo),e(Ko,lwo),e(Ko,pC),e(pC,iwo),e(pC,Zoe),e(Zoe,dwo),e(pC,mwo),e(Ko,fwo),e(Ko,qt),g(_C,qt,null),e(qt,cwo),e(qt,ete),e(ete,gwo),e(qt,hwo),e(qt,rd),e(rd,uwo),e(rd,ote),e(ote,pwo),e(rd,_wo),e(rd,tte),e(tte,vwo),e(rd,bwo),e(qt,Two),e(qt,rte),e(rte,Fwo),e(qt,Mwo),g(vC,qt,null),e(Ko,Ewo),e(Ko,Xe),g(bC,Xe,null),e(Xe,Cwo),e(Xe,ate),e(ate,ywo),e(Xe,wwo),e(Xe,Da),e(Da,Awo),e(Da,nte),e(nte,xwo),e(Da,Lwo),e(Da,ste),e(ste,Bwo),e(Da,kwo),e(Da,lte),e(lte,Rwo),e(Da,Swo),e(Xe,Pwo),e(Xe,TC),e(TC,a2),e(a2,ite),e(ite,$wo),e(a2,Iwo),e(a2,iP),e(iP,jwo),e(a2,Nwo),e(TC,Dwo),e(TC,n2),e(n2,dte),e(dte,Gwo),e(n2,Owo),e(n2,dP),e(dP,qwo),e(n2,zwo),e(Xe,Xwo),e(Xe,s2),e(s2,Wwo),e(s2,mte),e(mte,Vwo),e(s2,Qwo),e(s2,fte),e(fte,Hwo),e(Xe,Uwo),e(Xe,cte),e(cte,Jwo),e(Xe,Kwo),g(FC,Xe,null),v(d,cCe,_),v(d,ad,_),e(ad,l2),e(l2,gte),g(MC,gte,null),e(ad,Ywo),e(ad,hte),e(hte,Zwo),v(d,gCe,_),v(d,Yo,_),g(EC,Yo,null),e(Yo,eAo),e(Yo,nd),e(nd,oAo),e(nd,ute),e(ute,tAo),e(nd,rAo),e(nd,pte),e(pte,aAo),e(nd,nAo),e(Yo,sAo),e(Yo,CC),e(CC,lAo),e(CC,_te),e(_te,iAo),e(CC,dAo),e(Yo,mAo),e(Yo,zt),g(yC,zt,null),e(zt,fAo),e(zt,vte),e(vte,cAo),e(zt,gAo),e(zt,sd),e(sd,hAo),e(sd,bte),e(bte,uAo),e(sd,pAo),e(sd,Tte),e(Tte,_Ao),e(sd,vAo),e(zt,bAo),e(zt,Fte),e(Fte,TAo),e(zt,FAo),g(wC,zt,null),e(Yo,MAo),e(Yo,We),g(AC,We,null),e(We,EAo),e(We,Mte),e(Mte,CAo),e(We,yAo),e(We,Ga),e(Ga,wAo),e(Ga,Ete),e(Ete,AAo),e(Ga,xAo),e(Ga,Cte),e(Cte,LAo),e(Ga,BAo),e(Ga,yte),e(yte,kAo),e(Ga,RAo),e(We,SAo),e(We,ld),e(ld,i2),e(i2,wte),e(wte,PAo),e(i2,$Ao),e(i2,mP),e(mP,IAo),e(i2,jAo),e(ld,NAo),e(ld,d2),e(d2,Ate),e(Ate,DAo),e(d2,GAo),e(d2,fP),e(fP,OAo),e(d2,qAo),e(ld,zAo),e(ld,m2),e(m2,xte),e(xte,XAo),e(m2,WAo),e(m2,cP),e(cP,VAo),e(m2,QAo),e(We,HAo),e(We,f2),e(f2,UAo),e(f2,Lte),e(Lte,JAo),e(f2,KAo),e(f2,Bte),e(Bte,YAo),e(We,ZAo),e(We,kte),e(kte,e7o),e(We,o7o),g(xC,We,null),v(d,hCe,_),v(d,id,_),e(id,c2),e(c2,Rte),g(LC,Rte,null),e(id,t7o),e(id,Ste),e(Ste,r7o),v(d,uCe,_),v(d,Zo,_),g(BC,Zo,null),e(Zo,a7o),e(Zo,dd),e(dd,n7o),e(dd,Pte),e(Pte,s7o),e(dd,l7o),e(dd,$te),e($te,i7o),e(dd,d7o),e(Zo,m7o),e(Zo,kC),e(kC,f7o),e(kC,Ite),e(Ite,c7o),e(kC,g7o),e(Zo,h7o),e(Zo,Xt),g(RC,Xt,null),e(Xt,u7o),e(Xt,jte),e(jte,p7o),e(Xt,_7o),e(Xt,md),e(md,v7o),e(md,Nte),e(Nte,b7o),e(md,T7o),e(md,Dte),e(Dte,F7o),e(md,M7o),e(Xt,E7o),e(Xt,Gte),e(Gte,C7o),e(Xt,y7o),g(SC,Xt,null),e(Zo,w7o),e(Zo,Ve),g(PC,Ve,null),e(Ve,A7o),e(Ve,Ote),e(Ote,x7o),e(Ve,L7o),e(Ve,Oa),e(Oa,B7o),e(Oa,qte),e(qte,k7o),e(Oa,R7o),e(Oa,zte),e(zte,S7o),e(Oa,P7o),e(Oa,Xte),e(Xte,$7o),e(Oa,I7o),e(Ve,j7o),e(Ve,Wte),e(Wte,g2),e(g2,Vte),e(Vte,N7o),e(g2,D7o),e(g2,gP),e(gP,G7o),e(g2,O7o),e(Ve,q7o),e(Ve,h2),e(h2,z7o),e(h2,Qte),e(Qte,X7o),e(h2,W7o),e(h2,Hte),e(Hte,V7o),e(Ve,Q7o),e(Ve,Ute),e(Ute,H7o),e(Ve,U7o),g($C,Ve,null),v(d,pCe,_),v(d,fd,_),e(fd,u2),e(u2,Jte),g(IC,Jte,null),e(fd,J7o),e(fd,Kte),e(Kte,K7o),v(d,_Ce,_),v(d,et,_),g(jC,et,null),e(et,Y7o),e(et,cd),e(cd,Z7o),e(cd,Yte),e(Yte,exo),e(cd,oxo),e(cd,Zte),e(Zte,txo),e(cd,rxo),e(et,axo),e(et,NC),e(NC,nxo),e(NC,ere),e(ere,sxo),e(NC,lxo),e(et,ixo),e(et,Wt),g(DC,Wt,null),e(Wt,dxo),e(Wt,ore),e(ore,mxo),e(Wt,fxo),e(Wt,gd),e(gd,cxo),e(gd,tre),e(tre,gxo),e(gd,hxo),e(gd,rre),e(rre,uxo),e(gd,pxo),e(Wt,_xo),e(Wt,are),e(are,vxo),e(Wt,bxo),g(GC,Wt,null),e(et,Txo),e(et,Qe),g(OC,Qe,null),e(Qe,Fxo),e(Qe,nre),e(nre,Mxo),e(Qe,Exo),e(Qe,qa),e(qa,Cxo),e(qa,sre),e(sre,yxo),e(qa,wxo),e(qa,lre),e(lre,Axo),e(qa,xxo),e(qa,ire),e(ire,Lxo),e(qa,Bxo),e(Qe,kxo),e(Qe,dre),e(dre,p2),e(p2,mre),e(mre,Rxo),e(p2,Sxo),e(p2,hP),e(hP,Pxo),e(p2,$xo),e(Qe,Ixo),e(Qe,_2),e(_2,jxo),e(_2,fre),e(fre,Nxo),e(_2,Dxo),e(_2,cre),e(cre,Gxo),e(Qe,Oxo),e(Qe,gre),e(gre,qxo),e(Qe,zxo),g(qC,Qe,null),v(d,vCe,_),v(d,hd,_),e(hd,v2),e(v2,hre),g(zC,hre,null),e(hd,Xxo),e(hd,ure),e(ure,Wxo),v(d,bCe,_),v(d,ot,_),g(XC,ot,null),e(ot,Vxo),e(ot,ud),e(ud,Qxo),e(ud,pre),e(pre,Hxo),e(ud,Uxo),e(ud,_re),e(_re,Jxo),e(ud,Kxo),e(ot,Yxo),e(ot,WC),e(WC,Zxo),e(WC,vre),e(vre,e6o),e(WC,o6o),e(ot,t6o),e(ot,Vt),g(VC,Vt,null),e(Vt,r6o),e(Vt,bre),e(bre,a6o),e(Vt,n6o),e(Vt,pd),e(pd,s6o),e(pd,Tre),e(Tre,l6o),e(pd,i6o),e(pd,Fre),e(Fre,d6o),e(pd,m6o),e(Vt,f6o),e(Vt,Mre),e(Mre,c6o),e(Vt,g6o),g(QC,Vt,null),e(ot,h6o),e(ot,ro),g(HC,ro,null),e(ro,u6o),e(ro,Ere),e(Ere,p6o),e(ro,_6o),e(ro,za),e(za,v6o),e(za,Cre),e(Cre,b6o),e(za,T6o),e(za,yre),e(yre,F6o),e(za,M6o),e(za,wre),e(wre,E6o),e(za,C6o),e(ro,y6o),e(ro,L),e(L,b2),e(b2,Are),e(Are,w6o),e(b2,A6o),e(b2,uP),e(uP,x6o),e(b2,L6o),e(L,B6o),e(L,T2),e(T2,xre),e(xre,k6o),e(T2,R6o),e(T2,pP),e(pP,S6o),e(T2,P6o),e(L,$6o),e(L,F2),e(F2,Lre),e(Lre,I6o),e(F2,j6o),e(F2,_P),e(_P,N6o),e(F2,D6o),e(L,G6o),e(L,M2),e(M2,Bre),e(Bre,O6o),e(M2,q6o),e(M2,vP),e(vP,z6o),e(M2,X6o),e(L,W6o),e(L,E2),e(E2,kre),e(kre,V6o),e(E2,Q6o),e(E2,bP),e(bP,H6o),e(E2,U6o),e(L,J6o),e(L,C2),e(C2,Rre),e(Rre,K6o),e(C2,Y6o),e(C2,TP),e(TP,Z6o),e(C2,e8o),e(L,o8o),e(L,y2),e(y2,Sre),e(Sre,t8o),e(y2,r8o),e(y2,FP),e(FP,a8o),e(y2,n8o),e(L,s8o),e(L,w2),e(w2,Pre),e(Pre,l8o),e(w2,i8o),e(w2,MP),e(MP,d8o),e(w2,m8o),e(L,f8o),e(L,A2),e(A2,$re),e($re,c8o),e(A2,g8o),e(A2,EP),e(EP,h8o),e(A2,u8o),e(L,p8o),e(L,x2),e(x2,Ire),e(Ire,_8o),e(x2,v8o),e(x2,CP),e(CP,b8o),e(x2,T8o),e(L,F8o),e(L,L2),e(L2,jre),e(jre,M8o),e(L2,E8o),e(L2,yP),e(yP,C8o),e(L2,y8o),e(L,w8o),e(L,B2),e(B2,Nre),e(Nre,A8o),e(B2,x8o),e(B2,wP),e(wP,L8o),e(B2,B8o),e(L,k8o),e(L,k2),e(k2,Dre),e(Dre,R8o),e(k2,S8o),e(k2,AP),e(AP,P8o),e(k2,$8o),e(L,I8o),e(L,R2),e(R2,Gre),e(Gre,j8o),e(R2,N8o),e(R2,xP),e(xP,D8o),e(R2,G8o),e(L,O8o),e(L,ds),e(ds,Ore),e(Ore,q8o),e(ds,z8o),e(ds,LP),e(LP,X8o),e(ds,W8o),e(ds,BP),e(BP,V8o),e(ds,Q8o),e(L,H8o),e(L,S2),e(S2,qre),e(qre,U8o),e(S2,J8o),e(S2,kP),e(kP,K8o),e(S2,Y8o),e(L,Z8o),e(L,P2),e(P2,zre),e(zre,eLo),e(P2,oLo),e(P2,RP),e(RP,tLo),e(P2,rLo),e(L,aLo),e(L,$2),e($2,Xre),e(Xre,nLo),e($2,sLo),e($2,SP),e(SP,lLo),e($2,iLo),e(L,dLo),e(L,I2),e(I2,Wre),e(Wre,mLo),e(I2,fLo),e(I2,PP),e(PP,cLo),e(I2,gLo),e(L,hLo),e(L,j2),e(j2,Vre),e(Vre,uLo),e(j2,pLo),e(j2,$P),e($P,_Lo),e(j2,vLo),e(L,bLo),e(L,N2),e(N2,Qre),e(Qre,TLo),e(N2,FLo),e(N2,IP),e(IP,MLo),e(N2,ELo),e(L,CLo),e(L,D2),e(D2,Hre),e(Hre,yLo),e(D2,wLo),e(D2,jP),e(jP,ALo),e(D2,xLo),e(L,LLo),e(L,G2),e(G2,Ure),e(Ure,BLo),e(G2,kLo),e(G2,NP),e(NP,RLo),e(G2,SLo),e(L,PLo),e(L,O2),e(O2,Jre),e(Jre,$Lo),e(O2,ILo),e(O2,DP),e(DP,jLo),e(O2,NLo),e(L,DLo),e(L,q2),e(q2,Kre),e(Kre,GLo),e(q2,OLo),e(q2,GP),e(GP,qLo),e(q2,zLo),e(L,XLo),e(L,z2),e(z2,Yre),e(Yre,WLo),e(z2,VLo),e(z2,OP),e(OP,QLo),e(z2,HLo),e(L,ULo),e(L,X2),e(X2,Zre),e(Zre,JLo),e(X2,KLo),e(X2,qP),e(qP,YLo),e(X2,ZLo),e(L,eBo),e(L,W2),e(W2,eae),e(eae,oBo),e(W2,tBo),e(W2,zP),e(zP,rBo),e(W2,aBo),e(L,nBo),e(L,V2),e(V2,oae),e(oae,sBo),e(V2,lBo),e(V2,XP),e(XP,iBo),e(V2,dBo),e(L,mBo),e(L,Q2),e(Q2,tae),e(tae,fBo),e(Q2,cBo),e(Q2,WP),e(WP,gBo),e(Q2,hBo),e(L,uBo),e(L,H2),e(H2,rae),e(rae,pBo),e(H2,_Bo),e(H2,VP),e(VP,vBo),e(H2,bBo),e(L,TBo),e(L,U2),e(U2,aae),e(aae,FBo),e(U2,MBo),e(U2,QP),e(QP,EBo),e(U2,CBo),e(L,yBo),e(L,J2),e(J2,nae),e(nae,wBo),e(J2,ABo),e(J2,HP),e(HP,xBo),e(J2,LBo),e(L,BBo),e(L,K2),e(K2,sae),e(sae,kBo),e(K2,RBo),e(K2,UP),e(UP,SBo),e(K2,PBo),e(L,$Bo),e(L,Y2),e(Y2,lae),e(lae,IBo),e(Y2,jBo),e(Y2,JP),e(JP,NBo),e(Y2,DBo),e(L,GBo),e(L,Z2),e(Z2,iae),e(iae,OBo),e(Z2,qBo),e(Z2,KP),e(KP,zBo),e(Z2,XBo),e(L,WBo),e(L,eb),e(eb,dae),e(dae,VBo),e(eb,QBo),e(eb,YP),e(YP,HBo),e(eb,UBo),e(L,JBo),e(L,ob),e(ob,mae),e(mae,KBo),e(ob,YBo),e(ob,ZP),e(ZP,ZBo),e(ob,e9o),e(L,o9o),e(L,tb),e(tb,fae),e(fae,t9o),e(tb,r9o),e(tb,e$),e(e$,a9o),e(tb,n9o),e(ro,s9o),e(ro,cae),e(cae,l9o),e(ro,i9o),g(UC,ro,null),v(d,TCe,_),v(d,_d,_),e(_d,rb),e(rb,gae),g(JC,gae,null),e(_d,d9o),e(_d,hae),e(hae,m9o),v(d,FCe,_),v(d,tt,_),g(KC,tt,null),e(tt,f9o),e(tt,vd),e(vd,c9o),e(vd,uae),e(uae,g9o),e(vd,h9o),e(vd,pae),e(pae,u9o),e(vd,p9o),e(tt,_9o),e(tt,YC),e(YC,v9o),e(YC,_ae),e(_ae,b9o),e(YC,T9o),e(tt,F9o),e(tt,Qt),g(ZC,Qt,null),e(Qt,M9o),e(Qt,vae),e(vae,E9o),e(Qt,C9o),e(Qt,bd),e(bd,y9o),e(bd,bae),e(bae,w9o),e(bd,A9o),e(bd,Tae),e(Tae,x9o),e(bd,L9o),e(Qt,B9o),e(Qt,Fae),e(Fae,k9o),e(Qt,R9o),g(e3,Qt,null),e(tt,S9o),e(tt,ao),g(o3,ao,null),e(ao,P9o),e(ao,Mae),e(Mae,$9o),e(ao,I9o),e(ao,Xa),e(Xa,j9o),e(Xa,Eae),e(Eae,N9o),e(Xa,D9o),e(Xa,Cae),e(Cae,G9o),e(Xa,O9o),e(Xa,yae),e(yae,q9o),e(Xa,z9o),e(ao,X9o),e(ao,V),e(V,ab),e(ab,wae),e(wae,W9o),e(ab,V9o),e(ab,o$),e(o$,Q9o),e(ab,H9o),e(V,U9o),e(V,nb),e(nb,Aae),e(Aae,J9o),e(nb,K9o),e(nb,t$),e(t$,Y9o),e(nb,Z9o),e(V,eko),e(V,sb),e(sb,xae),e(xae,oko),e(sb,tko),e(sb,r$),e(r$,rko),e(sb,ako),e(V,nko),e(V,lb),e(lb,Lae),e(Lae,sko),e(lb,lko),e(lb,a$),e(a$,iko),e(lb,dko),e(V,mko),e(V,ib),e(ib,Bae),e(Bae,fko),e(ib,cko),e(ib,n$),e(n$,gko),e(ib,hko),e(V,uko),e(V,db),e(db,kae),e(kae,pko),e(db,_ko),e(db,s$),e(s$,vko),e(db,bko),e(V,Tko),e(V,mb),e(mb,Rae),e(Rae,Fko),e(mb,Mko),e(mb,l$),e(l$,Eko),e(mb,Cko),e(V,yko),e(V,fb),e(fb,Sae),e(Sae,wko),e(fb,Ako),e(fb,i$),e(i$,xko),e(fb,Lko),e(V,Bko),e(V,cb),e(cb,Pae),e(Pae,kko),e(cb,Rko),e(cb,d$),e(d$,Sko),e(cb,Pko),e(V,$ko),e(V,gb),e(gb,$ae),e($ae,Iko),e(gb,jko),e(gb,m$),e(m$,Nko),e(gb,Dko),e(V,Gko),e(V,hb),e(hb,Iae),e(Iae,Oko),e(hb,qko),e(hb,f$),e(f$,zko),e(hb,Xko),e(V,Wko),e(V,ub),e(ub,jae),e(jae,Vko),e(ub,Qko),e(ub,c$),e(c$,Hko),e(ub,Uko),e(V,Jko),e(V,pb),e(pb,Nae),e(Nae,Kko),e(pb,Yko),e(pb,g$),e(g$,Zko),e(pb,eRo),e(V,oRo),e(V,_b),e(_b,Dae),e(Dae,tRo),e(_b,rRo),e(_b,h$),e(h$,aRo),e(_b,nRo),e(V,sRo),e(V,vb),e(vb,Gae),e(Gae,lRo),e(vb,iRo),e(vb,u$),e(u$,dRo),e(vb,mRo),e(V,fRo),e(V,bb),e(bb,Oae),e(Oae,cRo),e(bb,gRo),e(bb,p$),e(p$,hRo),e(bb,uRo),e(V,pRo),e(V,Tb),e(Tb,qae),e(qae,_Ro),e(Tb,vRo),e(Tb,_$),e(_$,bRo),e(Tb,TRo),e(V,FRo),e(V,Fb),e(Fb,zae),e(zae,MRo),e(Fb,ERo),e(Fb,v$),e(v$,CRo),e(Fb,yRo),e(V,wRo),e(V,Mb),e(Mb,Xae),e(Xae,ARo),e(Mb,xRo),e(Mb,b$),e(b$,LRo),e(Mb,BRo),e(V,kRo),e(V,Eb),e(Eb,Wae),e(Wae,RRo),e(Eb,SRo),e(Eb,T$),e(T$,PRo),e(Eb,$Ro),e(V,IRo),e(V,Cb),e(Cb,Vae),e(Vae,jRo),e(Cb,NRo),e(Cb,F$),e(F$,DRo),e(Cb,GRo),e(V,ORo),e(V,yb),e(yb,Qae),e(Qae,qRo),e(yb,zRo),e(yb,M$),e(M$,XRo),e(yb,WRo),e(ao,VRo),e(ao,Hae),e(Hae,QRo),e(ao,HRo),g(t3,ao,null),v(d,MCe,_),v(d,Td,_),e(Td,wb),e(wb,Uae),g(r3,Uae,null),e(Td,URo),e(Td,Jae),e(Jae,JRo),v(d,ECe,_),v(d,rt,_),g(a3,rt,null),e(rt,KRo),e(rt,Fd),e(Fd,YRo),e(Fd,Kae),e(Kae,ZRo),e(Fd,eSo),e(Fd,Yae),e(Yae,oSo),e(Fd,tSo),e(rt,rSo),e(rt,n3),e(n3,aSo),e(n3,Zae),e(Zae,nSo),e(n3,sSo),e(rt,lSo),e(rt,Ht),g(s3,Ht,null),e(Ht,iSo),e(Ht,ene),e(ene,dSo),e(Ht,mSo),e(Ht,Md),e(Md,fSo),e(Md,one),e(one,cSo),e(Md,gSo),e(Md,tne),e(tne,hSo),e(Md,uSo),e(Ht,pSo),e(Ht,rne),e(rne,_So),e(Ht,vSo),g(l3,Ht,null),e(rt,bSo),e(rt,no),g(i3,no,null),e(no,TSo),e(no,ane),e(ane,FSo),e(no,MSo),e(no,Wa),e(Wa,ESo),e(Wa,nne),e(nne,CSo),e(Wa,ySo),e(Wa,sne),e(sne,wSo),e(Wa,ASo),e(Wa,lne),e(lne,xSo),e(Wa,LSo),e(no,BSo),e(no,ce),e(ce,Ab),e(Ab,ine),e(ine,kSo),e(Ab,RSo),e(Ab,E$),e(E$,SSo),e(Ab,PSo),e(ce,$So),e(ce,xb),e(xb,dne),e(dne,ISo),e(xb,jSo),e(xb,C$),e(C$,NSo),e(xb,DSo),e(ce,GSo),e(ce,Lb),e(Lb,mne),e(mne,OSo),e(Lb,qSo),e(Lb,y$),e(y$,zSo),e(Lb,XSo),e(ce,WSo),e(ce,Bb),e(Bb,fne),e(fne,VSo),e(Bb,QSo),e(Bb,w$),e(w$,HSo),e(Bb,USo),e(ce,JSo),e(ce,kb),e(kb,cne),e(cne,KSo),e(kb,YSo),e(kb,A$),e(A$,ZSo),e(kb,ePo),e(ce,oPo),e(ce,Rb),e(Rb,gne),e(gne,tPo),e(Rb,rPo),e(Rb,x$),e(x$,aPo),e(Rb,nPo),e(ce,sPo),e(ce,Sb),e(Sb,hne),e(hne,lPo),e(Sb,iPo),e(Sb,L$),e(L$,dPo),e(Sb,mPo),e(ce,fPo),e(ce,Pb),e(Pb,une),e(une,cPo),e(Pb,gPo),e(Pb,B$),e(B$,hPo),e(Pb,uPo),e(ce,pPo),e(ce,$b),e($b,pne),e(pne,_Po),e($b,vPo),e($b,k$),e(k$,bPo),e($b,TPo),e(ce,FPo),e(ce,Ib),e(Ib,_ne),e(_ne,MPo),e(Ib,EPo),e(Ib,R$),e(R$,CPo),e(Ib,yPo),e(no,wPo),e(no,vne),e(vne,APo),e(no,xPo),g(d3,no,null),v(d,CCe,_),v(d,Ed,_),e(Ed,jb),e(jb,bne),g(m3,bne,null),e(Ed,LPo),e(Ed,Tne),e(Tne,BPo),v(d,yCe,_),v(d,at,_),g(f3,at,null),e(at,kPo),e(at,Cd),e(Cd,RPo),e(Cd,Fne),e(Fne,SPo),e(Cd,PPo),e(Cd,Mne),e(Mne,$Po),e(Cd,IPo),e(at,jPo),e(at,c3),e(c3,NPo),e(c3,Ene),e(Ene,DPo),e(c3,GPo),e(at,OPo),e(at,Ut),g(g3,Ut,null),e(Ut,qPo),e(Ut,Cne),e(Cne,zPo),e(Ut,XPo),e(Ut,yd),e(yd,WPo),e(yd,yne),e(yne,VPo),e(yd,QPo),e(yd,wne),e(wne,HPo),e(yd,UPo),e(Ut,JPo),e(Ut,Ane),e(Ane,KPo),e(Ut,YPo),g(h3,Ut,null),e(at,ZPo),e(at,so),g(u3,so,null),e(so,e$o),e(so,xne),e(xne,o$o),e(so,t$o),e(so,Va),e(Va,r$o),e(Va,Lne),e(Lne,a$o),e(Va,n$o),e(Va,Bne),e(Bne,s$o),e(Va,l$o),e(Va,kne),e(kne,i$o),e(Va,d$o),e(so,m$o),e(so,Rne),e(Rne,Nb),e(Nb,Sne),e(Sne,f$o),e(Nb,c$o),e(Nb,S$),e(S$,g$o),e(Nb,h$o),e(so,u$o),e(so,Pne),e(Pne,p$o),e(so,_$o),g(p3,so,null),v(d,wCe,_),v(d,wd,_),e(wd,Db),e(Db,$ne),g(_3,$ne,null),e(wd,v$o),e(wd,Ine),e(Ine,b$o),v(d,ACe,_),v(d,nt,_),g(v3,nt,null),e(nt,T$o),e(nt,Ad),e(Ad,F$o),e(Ad,jne),e(jne,M$o),e(Ad,E$o),e(Ad,Nne),e(Nne,C$o),e(Ad,y$o),e(nt,w$o),e(nt,b3),e(b3,A$o),e(b3,Dne),e(Dne,x$o),e(b3,L$o),e(nt,B$o),e(nt,Jt),g(T3,Jt,null),e(Jt,k$o),e(Jt,Gne),e(Gne,R$o),e(Jt,S$o),e(Jt,xd),e(xd,P$o),e(xd,One),e(One,$$o),e(xd,I$o),e(xd,qne),e(qne,j$o),e(xd,N$o),e(Jt,D$o),e(Jt,zne),e(zne,G$o),e(Jt,O$o),g(F3,Jt,null),e(nt,q$o),e(nt,lo),g(M3,lo,null),e(lo,z$o),e(lo,Xne),e(Xne,X$o),e(lo,W$o),e(lo,Qa),e(Qa,V$o),e(Qa,Wne),e(Wne,Q$o),e(Qa,H$o),e(Qa,Vne),e(Vne,U$o),e(Qa,J$o),e(Qa,Qne),e(Qne,K$o),e(Qa,Y$o),e(lo,Z$o),e(lo,K),e(K,Gb),e(Gb,Hne),e(Hne,eIo),e(Gb,oIo),e(Gb,P$),e(P$,tIo),e(Gb,rIo),e(K,aIo),e(K,Ob),e(Ob,Une),e(Une,nIo),e(Ob,sIo),e(Ob,$$),e($$,lIo),e(Ob,iIo),e(K,dIo),e(K,qb),e(qb,Jne),e(Jne,mIo),e(qb,fIo),e(qb,I$),e(I$,cIo),e(qb,gIo),e(K,hIo),e(K,zb),e(zb,Kne),e(Kne,uIo),e(zb,pIo),e(zb,j$),e(j$,_Io),e(zb,vIo),e(K,bIo),e(K,Xb),e(Xb,Yne),e(Yne,TIo),e(Xb,FIo),e(Xb,N$),e(N$,MIo),e(Xb,EIo),e(K,CIo),e(K,Wb),e(Wb,Zne),e(Zne,yIo),e(Wb,wIo),e(Wb,D$),e(D$,AIo),e(Wb,xIo),e(K,LIo),e(K,Vb),e(Vb,ese),e(ese,BIo),e(Vb,kIo),e(Vb,G$),e(G$,RIo),e(Vb,SIo),e(K,PIo),e(K,Qb),e(Qb,ose),e(ose,$Io),e(Qb,IIo),e(Qb,O$),e(O$,jIo),e(Qb,NIo),e(K,DIo),e(K,Hb),e(Hb,tse),e(tse,GIo),e(Hb,OIo),e(Hb,q$),e(q$,qIo),e(Hb,zIo),e(K,XIo),e(K,Ub),e(Ub,rse),e(rse,WIo),e(Ub,VIo),e(Ub,z$),e(z$,QIo),e(Ub,HIo),e(K,UIo),e(K,Jb),e(Jb,ase),e(ase,JIo),e(Jb,KIo),e(Jb,X$),e(X$,YIo),e(Jb,ZIo),e(K,ejo),e(K,Kb),e(Kb,nse),e(nse,ojo),e(Kb,tjo),e(Kb,W$),e(W$,rjo),e(Kb,ajo),e(K,njo),e(K,Yb),e(Yb,sse),e(sse,sjo),e(Yb,ljo),e(Yb,V$),e(V$,ijo),e(Yb,djo),e(K,mjo),e(K,Zb),e(Zb,lse),e(lse,fjo),e(Zb,cjo),e(Zb,Q$),e(Q$,gjo),e(Zb,hjo),e(K,ujo),e(K,e4),e(e4,ise),e(ise,pjo),e(e4,_jo),e(e4,H$),e(H$,vjo),e(e4,bjo),e(K,Tjo),e(K,o4),e(o4,dse),e(dse,Fjo),e(o4,Mjo),e(o4,U$),e(U$,Ejo),e(o4,Cjo),e(K,yjo),e(K,t4),e(t4,mse),e(mse,wjo),e(t4,Ajo),e(t4,J$),e(J$,xjo),e(t4,Ljo),e(K,Bjo),e(K,r4),e(r4,fse),e(fse,kjo),e(r4,Rjo),e(r4,K$),e(K$,Sjo),e(r4,Pjo),e(K,$jo),e(K,a4),e(a4,cse),e(cse,Ijo),e(a4,jjo),e(a4,Y$),e(Y$,Njo),e(a4,Djo),e(K,Gjo),e(K,n4),e(n4,gse),e(gse,Ojo),e(n4,qjo),e(n4,Z$),e(Z$,zjo),e(n4,Xjo),e(lo,Wjo),e(lo,hse),e(hse,Vjo),e(lo,Qjo),g(E3,lo,null),v(d,xCe,_),v(d,Ld,_),e(Ld,s4),e(s4,use),g(C3,use,null),e(Ld,Hjo),e(Ld,pse),e(pse,Ujo),v(d,LCe,_),v(d,st,_),g(y3,st,null),e(st,Jjo),e(st,Bd),e(Bd,Kjo),e(Bd,_se),e(_se,Yjo),e(Bd,Zjo),e(Bd,vse),e(vse,eNo),e(Bd,oNo),e(st,tNo),e(st,w3),e(w3,rNo),e(w3,bse),e(bse,aNo),e(w3,nNo),e(st,sNo),e(st,Kt),g(A3,Kt,null),e(Kt,lNo),e(Kt,Tse),e(Tse,iNo),e(Kt,dNo),e(Kt,kd),e(kd,mNo),e(kd,Fse),e(Fse,fNo),e(kd,cNo),e(kd,Mse),e(Mse,gNo),e(kd,hNo),e(Kt,uNo),e(Kt,Ese),e(Ese,pNo),e(Kt,_No),g(x3,Kt,null),e(st,vNo),e(st,io),g(L3,io,null),e(io,bNo),e(io,Cse),e(Cse,TNo),e(io,FNo),e(io,Ha),e(Ha,MNo),e(Ha,yse),e(yse,ENo),e(Ha,CNo),e(Ha,wse),e(wse,yNo),e(Ha,wNo),e(Ha,Ase),e(Ase,ANo),e(Ha,xNo),e(io,LNo),e(io,ge),e(ge,l4),e(l4,xse),e(xse,BNo),e(l4,kNo),e(l4,eI),e(eI,RNo),e(l4,SNo),e(ge,PNo),e(ge,i4),e(i4,Lse),e(Lse,$No),e(i4,INo),e(i4,oI),e(oI,jNo),e(i4,NNo),e(ge,DNo),e(ge,d4),e(d4,Bse),e(Bse,GNo),e(d4,ONo),e(d4,tI),e(tI,qNo),e(d4,zNo),e(ge,XNo),e(ge,m4),e(m4,kse),e(kse,WNo),e(m4,VNo),e(m4,rI),e(rI,QNo),e(m4,HNo),e(ge,UNo),e(ge,f4),e(f4,Rse),e(Rse,JNo),e(f4,KNo),e(f4,aI),e(aI,YNo),e(f4,ZNo),e(ge,eDo),e(ge,c4),e(c4,Sse),e(Sse,oDo),e(c4,tDo),e(c4,nI),e(nI,rDo),e(c4,aDo),e(ge,nDo),e(ge,g4),e(g4,Pse),e(Pse,sDo),e(g4,lDo),e(g4,sI),e(sI,iDo),e(g4,dDo),e(ge,mDo),e(ge,h4),e(h4,$se),e($se,fDo),e(h4,cDo),e(h4,lI),e(lI,gDo),e(h4,hDo),e(ge,uDo),e(ge,u4),e(u4,Ise),e(Ise,pDo),e(u4,_Do),e(u4,iI),e(iI,vDo),e(u4,bDo),e(ge,TDo),e(ge,p4),e(p4,jse),e(jse,FDo),e(p4,MDo),e(p4,dI),e(dI,EDo),e(p4,CDo),e(io,yDo),e(io,Nse),e(Nse,wDo),e(io,ADo),g(B3,io,null),v(d,BCe,_),v(d,Rd,_),e(Rd,_4),e(_4,Dse),g(k3,Dse,null),e(Rd,xDo),e(Rd,Gse),e(Gse,LDo),v(d,kCe,_),v(d,lt,_),g(R3,lt,null),e(lt,BDo),e(lt,Sd),e(Sd,kDo),e(Sd,Ose),e(Ose,RDo),e(Sd,SDo),e(Sd,qse),e(qse,PDo),e(Sd,$Do),e(lt,IDo),e(lt,S3),e(S3,jDo),e(S3,zse),e(zse,NDo),e(S3,DDo),e(lt,GDo),e(lt,Yt),g(P3,Yt,null),e(Yt,ODo),e(Yt,Xse),e(Xse,qDo),e(Yt,zDo),e(Yt,Pd),e(Pd,XDo),e(Pd,Wse),e(Wse,WDo),e(Pd,VDo),e(Pd,Vse),e(Vse,QDo),e(Pd,HDo),e(Yt,UDo),e(Yt,Qse),e(Qse,JDo),e(Yt,KDo),g($3,Yt,null),e(lt,YDo),e(lt,mo),g(I3,mo,null),e(mo,ZDo),e(mo,Hse),e(Hse,eGo),e(mo,oGo),e(mo,Ua),e(Ua,tGo),e(Ua,Use),e(Use,rGo),e(Ua,aGo),e(Ua,Jse),e(Jse,nGo),e(Ua,sGo),e(Ua,Kse),e(Kse,lGo),e(Ua,iGo),e(mo,dGo),e(mo,O),e(O,v4),e(v4,Yse),e(Yse,mGo),e(v4,fGo),e(v4,mI),e(mI,cGo),e(v4,gGo),e(O,hGo),e(O,b4),e(b4,Zse),e(Zse,uGo),e(b4,pGo),e(b4,fI),e(fI,_Go),e(b4,vGo),e(O,bGo),e(O,T4),e(T4,ele),e(ele,TGo),e(T4,FGo),e(T4,cI),e(cI,MGo),e(T4,EGo),e(O,CGo),e(O,F4),e(F4,ole),e(ole,yGo),e(F4,wGo),e(F4,gI),e(gI,AGo),e(F4,xGo),e(O,LGo),e(O,M4),e(M4,tle),e(tle,BGo),e(M4,kGo),e(M4,hI),e(hI,RGo),e(M4,SGo),e(O,PGo),e(O,E4),e(E4,rle),e(rle,$Go),e(E4,IGo),e(E4,uI),e(uI,jGo),e(E4,NGo),e(O,DGo),e(O,C4),e(C4,ale),e(ale,GGo),e(C4,OGo),e(C4,pI),e(pI,qGo),e(C4,zGo),e(O,XGo),e(O,y4),e(y4,nle),e(nle,WGo),e(y4,VGo),e(y4,_I),e(_I,QGo),e(y4,HGo),e(O,UGo),e(O,w4),e(w4,sle),e(sle,JGo),e(w4,KGo),e(w4,vI),e(vI,YGo),e(w4,ZGo),e(O,eOo),e(O,A4),e(A4,lle),e(lle,oOo),e(A4,tOo),e(A4,bI),e(bI,rOo),e(A4,aOo),e(O,nOo),e(O,x4),e(x4,ile),e(ile,sOo),e(x4,lOo),e(x4,TI),e(TI,iOo),e(x4,dOo),e(O,mOo),e(O,L4),e(L4,dle),e(dle,fOo),e(L4,cOo),e(L4,FI),e(FI,gOo),e(L4,hOo),e(O,uOo),e(O,B4),e(B4,mle),e(mle,pOo),e(B4,_Oo),e(B4,MI),e(MI,vOo),e(B4,bOo),e(O,TOo),e(O,k4),e(k4,fle),e(fle,FOo),e(k4,MOo),e(k4,EI),e(EI,EOo),e(k4,COo),e(O,yOo),e(O,R4),e(R4,cle),e(cle,wOo),e(R4,AOo),e(R4,CI),e(CI,xOo),e(R4,LOo),e(O,BOo),e(O,S4),e(S4,gle),e(gle,kOo),e(S4,ROo),e(S4,yI),e(yI,SOo),e(S4,POo),e(O,$Oo),e(O,P4),e(P4,hle),e(hle,IOo),e(P4,jOo),e(P4,wI),e(wI,NOo),e(P4,DOo),e(O,GOo),e(O,$4),e($4,ule),e(ule,OOo),e($4,qOo),e($4,AI),e(AI,zOo),e($4,XOo),e(O,WOo),e(O,I4),e(I4,ple),e(ple,VOo),e(I4,QOo),e(I4,xI),e(xI,HOo),e(I4,UOo),e(O,JOo),e(O,j4),e(j4,_le),e(_le,KOo),e(j4,YOo),e(j4,LI),e(LI,ZOo),e(j4,eqo),e(O,oqo),e(O,N4),e(N4,vle),e(vle,tqo),e(N4,rqo),e(N4,BI),e(BI,aqo),e(N4,nqo),e(O,sqo),e(O,D4),e(D4,ble),e(ble,lqo),e(D4,iqo),e(D4,kI),e(kI,dqo),e(D4,mqo),e(O,fqo),e(O,G4),e(G4,Tle),e(Tle,cqo),e(G4,gqo),e(G4,RI),e(RI,hqo),e(G4,uqo),e(O,pqo),e(O,O4),e(O4,Fle),e(Fle,_qo),e(O4,vqo),e(O4,SI),e(SI,bqo),e(O4,Tqo),e(O,Fqo),e(O,q4),e(q4,Mle),e(Mle,Mqo),e(q4,Eqo),e(q4,PI),e(PI,Cqo),e(q4,yqo),e(mo,wqo),e(mo,Ele),e(Ele,Aqo),e(mo,xqo),g(j3,mo,null),v(d,RCe,_),v(d,$d,_),e($d,z4),e(z4,Cle),g(N3,Cle,null),e($d,Lqo),e($d,yle),e(yle,Bqo),v(d,SCe,_),v(d,it,_),g(D3,it,null),e(it,kqo),e(it,Id),e(Id,Rqo),e(Id,wle),e(wle,Sqo),e(Id,Pqo),e(Id,Ale),e(Ale,$qo),e(Id,Iqo),e(it,jqo),e(it,G3),e(G3,Nqo),e(G3,xle),e(xle,Dqo),e(G3,Gqo),e(it,Oqo),e(it,Zt),g(O3,Zt,null),e(Zt,qqo),e(Zt,Lle),e(Lle,zqo),e(Zt,Xqo),e(Zt,jd),e(jd,Wqo),e(jd,Ble),e(Ble,Vqo),e(jd,Qqo),e(jd,kle),e(kle,Hqo),e(jd,Uqo),e(Zt,Jqo),e(Zt,Rle),e(Rle,Kqo),e(Zt,Yqo),g(q3,Zt,null),e(it,Zqo),e(it,fo),g(z3,fo,null),e(fo,ezo),e(fo,Sle),e(Sle,ozo),e(fo,tzo),e(fo,Ja),e(Ja,rzo),e(Ja,Ple),e(Ple,azo),e(Ja,nzo),e(Ja,$le),e($le,szo),e(Ja,lzo),e(Ja,Ile),e(Ile,izo),e(Ja,dzo),e(fo,mzo),e(fo,re),e(re,X4),e(X4,jle),e(jle,fzo),e(X4,czo),e(X4,$I),e($I,gzo),e(X4,hzo),e(re,uzo),e(re,W4),e(W4,Nle),e(Nle,pzo),e(W4,_zo),e(W4,II),e(II,vzo),e(W4,bzo),e(re,Tzo),e(re,V4),e(V4,Dle),e(Dle,Fzo),e(V4,Mzo),e(V4,jI),e(jI,Ezo),e(V4,Czo),e(re,yzo),e(re,Q4),e(Q4,Gle),e(Gle,wzo),e(Q4,Azo),e(Q4,NI),e(NI,xzo),e(Q4,Lzo),e(re,Bzo),e(re,H4),e(H4,Ole),e(Ole,kzo),e(H4,Rzo),e(H4,DI),e(DI,Szo),e(H4,Pzo),e(re,$zo),e(re,U4),e(U4,qle),e(qle,Izo),e(U4,jzo),e(U4,GI),e(GI,Nzo),e(U4,Dzo),e(re,Gzo),e(re,J4),e(J4,zle),e(zle,Ozo),e(J4,qzo),e(J4,OI),e(OI,zzo),e(J4,Xzo),e(re,Wzo),e(re,K4),e(K4,Xle),e(Xle,Vzo),e(K4,Qzo),e(K4,qI),e(qI,Hzo),e(K4,Uzo),e(re,Jzo),e(re,Y4),e(Y4,Wle),e(Wle,Kzo),e(Y4,Yzo),e(Y4,zI),e(zI,Zzo),e(Y4,eXo),e(re,oXo),e(re,Z4),e(Z4,Vle),e(Vle,tXo),e(Z4,rXo),e(Z4,XI),e(XI,aXo),e(Z4,nXo),e(re,sXo),e(re,e5),e(e5,Qle),e(Qle,lXo),e(e5,iXo),e(e5,WI),e(WI,dXo),e(e5,mXo),e(re,fXo),e(re,o5),e(o5,Hle),e(Hle,cXo),e(o5,gXo),e(o5,VI),e(VI,hXo),e(o5,uXo),e(re,pXo),e(re,t5),e(t5,Ule),e(Ule,_Xo),e(t5,vXo),e(t5,QI),e(QI,bXo),e(t5,TXo),e(re,FXo),e(re,r5),e(r5,Jle),e(Jle,MXo),e(r5,EXo),e(r5,HI),e(HI,CXo),e(r5,yXo),e(re,wXo),e(re,a5),e(a5,Kle),e(Kle,AXo),e(a5,xXo),e(a5,UI),e(UI,LXo),e(a5,BXo),e(re,kXo),e(re,n5),e(n5,Yle),e(Yle,RXo),e(n5,SXo),e(n5,JI),e(JI,PXo),e(n5,$Xo),e(re,IXo),e(re,s5),e(s5,Zle),e(Zle,jXo),e(s5,NXo),e(s5,KI),e(KI,DXo),e(s5,GXo),e(fo,OXo),e(fo,eie),e(eie,qXo),e(fo,zXo),g(X3,fo,null),v(d,PCe,_),v(d,Nd,_),e(Nd,l5),e(l5,oie),g(W3,oie,null),e(Nd,XXo),e(Nd,tie),e(tie,WXo),v(d,$Ce,_),v(d,dt,_),g(V3,dt,null),e(dt,VXo),e(dt,Dd),e(Dd,QXo),e(Dd,rie),e(rie,HXo),e(Dd,UXo),e(Dd,aie),e(aie,JXo),e(Dd,KXo),e(dt,YXo),e(dt,Q3),e(Q3,ZXo),e(Q3,nie),e(nie,eWo),e(Q3,oWo),e(dt,tWo),e(dt,er),g(H3,er,null),e(er,rWo),e(er,sie),e(sie,aWo),e(er,nWo),e(er,Gd),e(Gd,sWo),e(Gd,lie),e(lie,lWo),e(Gd,iWo),e(Gd,iie),e(iie,dWo),e(Gd,mWo),e(er,fWo),e(er,die),e(die,cWo),e(er,gWo),g(U3,er,null),e(dt,hWo),e(dt,co),g(J3,co,null),e(co,uWo),e(co,mie),e(mie,pWo),e(co,_Wo),e(co,Ka),e(Ka,vWo),e(Ka,fie),e(fie,bWo),e(Ka,TWo),e(Ka,cie),e(cie,FWo),e(Ka,MWo),e(Ka,gie),e(gie,EWo),e(Ka,CWo),e(co,yWo),e(co,hie),e(hie,i5),e(i5,uie),e(uie,wWo),e(i5,AWo),e(i5,YI),e(YI,xWo),e(i5,LWo),e(co,BWo),e(co,pie),e(pie,kWo),e(co,RWo),g(K3,co,null),v(d,ICe,_),v(d,Od,_),e(Od,d5),e(d5,_ie),g(Y3,_ie,null),e(Od,SWo),e(Od,vie),e(vie,PWo),v(d,jCe,_),v(d,mt,_),g(Z3,mt,null),e(mt,$Wo),e(mt,qd),e(qd,IWo),e(qd,bie),e(bie,jWo),e(qd,NWo),e(qd,Tie),e(Tie,DWo),e(qd,GWo),e(mt,OWo),e(mt,ey),e(ey,qWo),e(ey,Fie),e(Fie,zWo),e(ey,XWo),e(mt,WWo),e(mt,or),g(oy,or,null),e(or,VWo),e(or,Mie),e(Mie,QWo),e(or,HWo),e(or,zd),e(zd,UWo),e(zd,Eie),e(Eie,JWo),e(zd,KWo),e(zd,Cie),e(Cie,YWo),e(zd,ZWo),e(or,eVo),e(or,yie),e(yie,oVo),e(or,tVo),g(ty,or,null),e(mt,rVo),e(mt,go),g(ry,go,null),e(go,aVo),e(go,wie),e(wie,nVo),e(go,sVo),e(go,Ya),e(Ya,lVo),e(Ya,Aie),e(Aie,iVo),e(Ya,dVo),e(Ya,xie),e(xie,mVo),e(Ya,fVo),e(Ya,Lie),e(Lie,cVo),e(Ya,gVo),e(go,hVo),e(go,Y),e(Y,m5),e(m5,Bie),e(Bie,uVo),e(m5,pVo),e(m5,ZI),e(ZI,_Vo),e(m5,vVo),e(Y,bVo),e(Y,f5),e(f5,kie),e(kie,TVo),e(f5,FVo),e(f5,ej),e(ej,MVo),e(f5,EVo),e(Y,CVo),e(Y,c5),e(c5,Rie),e(Rie,yVo),e(c5,wVo),e(c5,oj),e(oj,AVo),e(c5,xVo),e(Y,LVo),e(Y,g5),e(g5,Sie),e(Sie,BVo),e(g5,kVo),e(g5,tj),e(tj,RVo),e(g5,SVo),e(Y,PVo),e(Y,h5),e(h5,Pie),e(Pie,$Vo),e(h5,IVo),e(h5,rj),e(rj,jVo),e(h5,NVo),e(Y,DVo),e(Y,u5),e(u5,$ie),e($ie,GVo),e(u5,OVo),e(u5,aj),e(aj,qVo),e(u5,zVo),e(Y,XVo),e(Y,p5),e(p5,Iie),e(Iie,WVo),e(p5,VVo),e(p5,nj),e(nj,QVo),e(p5,HVo),e(Y,UVo),e(Y,_5),e(_5,jie),e(jie,JVo),e(_5,KVo),e(_5,sj),e(sj,YVo),e(_5,ZVo),e(Y,eQo),e(Y,v5),e(v5,Nie),e(Nie,oQo),e(v5,tQo),e(v5,lj),e(lj,rQo),e(v5,aQo),e(Y,nQo),e(Y,b5),e(b5,Die),e(Die,sQo),e(b5,lQo),e(b5,ij),e(ij,iQo),e(b5,dQo),e(Y,mQo),e(Y,T5),e(T5,Gie),e(Gie,fQo),e(T5,cQo),e(T5,dj),e(dj,gQo),e(T5,hQo),e(Y,uQo),e(Y,F5),e(F5,Oie),e(Oie,pQo),e(F5,_Qo),e(F5,mj),e(mj,vQo),e(F5,bQo),e(Y,TQo),e(Y,M5),e(M5,qie),e(qie,FQo),e(M5,MQo),e(M5,fj),e(fj,EQo),e(M5,CQo),e(Y,yQo),e(Y,E5),e(E5,zie),e(zie,wQo),e(E5,AQo),e(E5,cj),e(cj,xQo),e(E5,LQo),e(Y,BQo),e(Y,C5),e(C5,Xie),e(Xie,kQo),e(C5,RQo),e(C5,gj),e(gj,SQo),e(C5,PQo),e(Y,$Qo),e(Y,y5),e(y5,Wie),e(Wie,IQo),e(y5,jQo),e(y5,hj),e(hj,NQo),e(y5,DQo),e(Y,GQo),e(Y,w5),e(w5,Vie),e(Vie,OQo),e(w5,qQo),e(w5,uj),e(uj,zQo),e(w5,XQo),e(Y,WQo),e(Y,A5),e(A5,Qie),e(Qie,VQo),e(A5,QQo),e(A5,pj),e(pj,HQo),e(A5,UQo),e(Y,JQo),e(Y,x5),e(x5,Hie),e(Hie,KQo),e(x5,YQo),e(x5,_j),e(_j,ZQo),e(x5,eHo),e(Y,oHo),e(Y,L5),e(L5,Uie),e(Uie,tHo),e(L5,rHo),e(L5,vj),e(vj,aHo),e(L5,nHo),e(go,sHo),e(go,Jie),e(Jie,lHo),e(go,iHo),g(ay,go,null),v(d,NCe,_),v(d,Xd,_),e(Xd,B5),e(B5,Kie),g(ny,Kie,null),e(Xd,dHo),e(Xd,Yie),e(Yie,mHo),v(d,DCe,_),v(d,ft,_),g(sy,ft,null),e(ft,fHo),e(ft,Wd),e(Wd,cHo),e(Wd,Zie),e(Zie,gHo),e(Wd,hHo),e(Wd,ede),e(ede,uHo),e(Wd,pHo),e(ft,_Ho),e(ft,ly),e(ly,vHo),e(ly,ode),e(ode,bHo),e(ly,THo),e(ft,FHo),e(ft,tr),g(iy,tr,null),e(tr,MHo),e(tr,tde),e(tde,EHo),e(tr,CHo),e(tr,Vd),e(Vd,yHo),e(Vd,rde),e(rde,wHo),e(Vd,AHo),e(Vd,ade),e(ade,xHo),e(Vd,LHo),e(tr,BHo),e(tr,nde),e(nde,kHo),e(tr,RHo),g(dy,tr,null),e(ft,SHo),e(ft,ho),g(my,ho,null),e(ho,PHo),e(ho,sde),e(sde,$Ho),e(ho,IHo),e(ho,Za),e(Za,jHo),e(Za,lde),e(lde,NHo),e(Za,DHo),e(Za,ide),e(ide,GHo),e(Za,OHo),e(Za,dde),e(dde,qHo),e(Za,zHo),e(ho,XHo),e(ho,Z),e(Z,k5),e(k5,mde),e(mde,WHo),e(k5,VHo),e(k5,bj),e(bj,QHo),e(k5,HHo),e(Z,UHo),e(Z,R5),e(R5,fde),e(fde,JHo),e(R5,KHo),e(R5,Tj),e(Tj,YHo),e(R5,ZHo),e(Z,eUo),e(Z,S5),e(S5,cde),e(cde,oUo),e(S5,tUo),e(S5,Fj),e(Fj,rUo),e(S5,aUo),e(Z,nUo),e(Z,P5),e(P5,gde),e(gde,sUo),e(P5,lUo),e(P5,Mj),e(Mj,iUo),e(P5,dUo),e(Z,mUo),e(Z,$5),e($5,hde),e(hde,fUo),e($5,cUo),e($5,Ej),e(Ej,gUo),e($5,hUo),e(Z,uUo),e(Z,I5),e(I5,ude),e(ude,pUo),e(I5,_Uo),e(I5,Cj),e(Cj,vUo),e(I5,bUo),e(Z,TUo),e(Z,j5),e(j5,pde),e(pde,FUo),e(j5,MUo),e(j5,yj),e(yj,EUo),e(j5,CUo),e(Z,yUo),e(Z,N5),e(N5,_de),e(_de,wUo),e(N5,AUo),e(N5,wj),e(wj,xUo),e(N5,LUo),e(Z,BUo),e(Z,D5),e(D5,vde),e(vde,kUo),e(D5,RUo),e(D5,Aj),e(Aj,SUo),e(D5,PUo),e(Z,$Uo),e(Z,G5),e(G5,bde),e(bde,IUo),e(G5,jUo),e(G5,xj),e(xj,NUo),e(G5,DUo),e(Z,GUo),e(Z,O5),e(O5,Tde),e(Tde,OUo),e(O5,qUo),e(O5,Lj),e(Lj,zUo),e(O5,XUo),e(Z,WUo),e(Z,q5),e(q5,Fde),e(Fde,VUo),e(q5,QUo),e(q5,Bj),e(Bj,HUo),e(q5,UUo),e(Z,JUo),e(Z,z5),e(z5,Mde),e(Mde,KUo),e(z5,YUo),e(z5,kj),e(kj,ZUo),e(z5,eJo),e(Z,oJo),e(Z,X5),e(X5,Ede),e(Ede,tJo),e(X5,rJo),e(X5,Rj),e(Rj,aJo),e(X5,nJo),e(Z,sJo),e(Z,W5),e(W5,Cde),e(Cde,lJo),e(W5,iJo),e(W5,Sj),e(Sj,dJo),e(W5,mJo),e(Z,fJo),e(Z,V5),e(V5,yde),e(yde,cJo),e(V5,gJo),e(V5,Pj),e(Pj,hJo),e(V5,uJo),e(Z,pJo),e(Z,Q5),e(Q5,wde),e(wde,_Jo),e(Q5,vJo),e(Q5,$j),e($j,bJo),e(Q5,TJo),e(Z,FJo),e(Z,H5),e(H5,Ade),e(Ade,MJo),e(H5,EJo),e(H5,Ij),e(Ij,CJo),e(H5,yJo),e(Z,wJo),e(Z,U5),e(U5,xde),e(xde,AJo),e(U5,xJo),e(U5,jj),e(jj,LJo),e(U5,BJo),e(ho,kJo),e(ho,Lde),e(Lde,RJo),e(ho,SJo),g(fy,ho,null),v(d,GCe,_),v(d,Qd,_),e(Qd,J5),e(J5,Bde),g(cy,Bde,null),e(Qd,PJo),e(Qd,kde),e(kde,$Jo),v(d,OCe,_),v(d,ct,_),g(gy,ct,null),e(ct,IJo),e(ct,Hd),e(Hd,jJo),e(Hd,Rde),e(Rde,NJo),e(Hd,DJo),e(Hd,Sde),e(Sde,GJo),e(Hd,OJo),e(ct,qJo),e(ct,hy),e(hy,zJo),e(hy,Pde),e(Pde,XJo),e(hy,WJo),e(ct,VJo),e(ct,rr),g(uy,rr,null),e(rr,QJo),e(rr,$de),e($de,HJo),e(rr,UJo),e(rr,Ud),e(Ud,JJo),e(Ud,Ide),e(Ide,KJo),e(Ud,YJo),e(Ud,jde),e(jde,ZJo),e(Ud,eKo),e(rr,oKo),e(rr,Nde),e(Nde,tKo),e(rr,rKo),g(py,rr,null),e(ct,aKo),e(ct,uo),g(_y,uo,null),e(uo,nKo),e(uo,Dde),e(Dde,sKo),e(uo,lKo),e(uo,en),e(en,iKo),e(en,Gde),e(Gde,dKo),e(en,mKo),e(en,Ode),e(Ode,fKo),e(en,cKo),e(en,qde),e(qde,gKo),e(en,hKo),e(uo,uKo),e(uo,Q),e(Q,K5),e(K5,zde),e(zde,pKo),e(K5,_Ko),e(K5,Nj),e(Nj,vKo),e(K5,bKo),e(Q,TKo),e(Q,Y5),e(Y5,Xde),e(Xde,FKo),e(Y5,MKo),e(Y5,Dj),e(Dj,EKo),e(Y5,CKo),e(Q,yKo),e(Q,Z5),e(Z5,Wde),e(Wde,wKo),e(Z5,AKo),e(Z5,Gj),e(Gj,xKo),e(Z5,LKo),e(Q,BKo),e(Q,e0),e(e0,Vde),e(Vde,kKo),e(e0,RKo),e(e0,Oj),e(Oj,SKo),e(e0,PKo),e(Q,$Ko),e(Q,o0),e(o0,Qde),e(Qde,IKo),e(o0,jKo),e(o0,qj),e(qj,NKo),e(o0,DKo),e(Q,GKo),e(Q,t0),e(t0,Hde),e(Hde,OKo),e(t0,qKo),e(t0,zj),e(zj,zKo),e(t0,XKo),e(Q,WKo),e(Q,r0),e(r0,Ude),e(Ude,VKo),e(r0,QKo),e(r0,Xj),e(Xj,HKo),e(r0,UKo),e(Q,JKo),e(Q,a0),e(a0,Jde),e(Jde,KKo),e(a0,YKo),e(a0,Wj),e(Wj,ZKo),e(a0,eYo),e(Q,oYo),e(Q,n0),e(n0,Kde),e(Kde,tYo),e(n0,rYo),e(n0,Vj),e(Vj,aYo),e(n0,nYo),e(Q,sYo),e(Q,s0),e(s0,Yde),e(Yde,lYo),e(s0,iYo),e(s0,Qj),e(Qj,dYo),e(s0,mYo),e(Q,fYo),e(Q,l0),e(l0,Zde),e(Zde,cYo),e(l0,gYo),e(l0,Hj),e(Hj,hYo),e(l0,uYo),e(Q,pYo),e(Q,i0),e(i0,eme),e(eme,_Yo),e(i0,vYo),e(i0,Uj),e(Uj,bYo),e(i0,TYo),e(Q,FYo),e(Q,d0),e(d0,ome),e(ome,MYo),e(d0,EYo),e(d0,Jj),e(Jj,CYo),e(d0,yYo),e(Q,wYo),e(Q,m0),e(m0,tme),e(tme,AYo),e(m0,xYo),e(m0,Kj),e(Kj,LYo),e(m0,BYo),e(Q,kYo),e(Q,f0),e(f0,rme),e(rme,RYo),e(f0,SYo),e(f0,Yj),e(Yj,PYo),e(f0,$Yo),e(Q,IYo),e(Q,c0),e(c0,ame),e(ame,jYo),e(c0,NYo),e(c0,Zj),e(Zj,DYo),e(c0,GYo),e(Q,OYo),e(Q,g0),e(g0,nme),e(nme,qYo),e(g0,zYo),e(g0,eN),e(eN,XYo),e(g0,WYo),e(Q,VYo),e(Q,h0),e(h0,sme),e(sme,QYo),e(h0,HYo),e(h0,oN),e(oN,UYo),e(h0,JYo),e(Q,KYo),e(Q,u0),e(u0,lme),e(lme,YYo),e(u0,ZYo),e(u0,tN),e(tN,eZo),e(u0,oZo),e(Q,tZo),e(Q,p0),e(p0,ime),e(ime,rZo),e(p0,aZo),e(p0,rN),e(rN,nZo),e(p0,sZo),e(Q,lZo),e(Q,_0),e(_0,dme),e(dme,iZo),e(_0,dZo),e(_0,aN),e(aN,mZo),e(_0,fZo),e(Q,cZo),e(Q,v0),e(v0,mme),e(mme,gZo),e(v0,hZo),e(v0,nN),e(nN,uZo),e(v0,pZo),e(uo,_Zo),e(uo,fme),e(fme,vZo),e(uo,bZo),g(vy,uo,null),v(d,qCe,_),v(d,Jd,_),e(Jd,b0),e(b0,cme),g(by,cme,null),e(Jd,TZo),e(Jd,gme),e(gme,FZo),v(d,zCe,_),v(d,gt,_),g(Ty,gt,null),e(gt,MZo),e(gt,Kd),e(Kd,EZo),e(Kd,hme),e(hme,CZo),e(Kd,yZo),e(Kd,ume),e(ume,wZo),e(Kd,AZo),e(gt,xZo),e(gt,Fy),e(Fy,LZo),e(Fy,pme),e(pme,BZo),e(Fy,kZo),e(gt,RZo),e(gt,ar),g(My,ar,null),e(ar,SZo),e(ar,_me),e(_me,PZo),e(ar,$Zo),e(ar,Yd),e(Yd,IZo),e(Yd,vme),e(vme,jZo),e(Yd,NZo),e(Yd,bme),e(bme,DZo),e(Yd,GZo),e(ar,OZo),e(ar,Tme),e(Tme,qZo),e(ar,zZo),g(Ey,ar,null),e(gt,XZo),e(gt,po),g(Cy,po,null),e(po,WZo),e(po,Fme),e(Fme,VZo),e(po,QZo),e(po,on),e(on,HZo),e(on,Mme),e(Mme,UZo),e(on,JZo),e(on,Eme),e(Eme,KZo),e(on,YZo),e(on,Cme),e(Cme,ZZo),e(on,eet),e(po,oet),e(po,Zd),e(Zd,T0),e(T0,yme),e(yme,tet),e(T0,ret),e(T0,sN),e(sN,aet),e(T0,net),e(Zd,set),e(Zd,F0),e(F0,wme),e(wme,iet),e(F0,det),e(F0,lN),e(lN,met),e(F0,fet),e(Zd,cet),e(Zd,M0),e(M0,Ame),e(Ame,get),e(M0,het),e(M0,iN),e(iN,uet),e(M0,pet),e(po,_et),e(po,xme),e(xme,vet),e(po,bet),g(yy,po,null),v(d,XCe,_),v(d,em,_),e(em,E0),e(E0,Lme),g(wy,Lme,null),e(em,Tet),e(em,Bme),e(Bme,Fet),v(d,WCe,_),v(d,ht,_),g(Ay,ht,null),e(ht,Met),e(ht,om),e(om,Eet),e(om,kme),e(kme,Cet),e(om,yet),e(om,Rme),e(Rme,wet),e(om,Aet),e(ht,xet),e(ht,xy),e(xy,Let),e(xy,Sme),e(Sme,Bet),e(xy,ket),e(ht,Ret),e(ht,nr),g(Ly,nr,null),e(nr,Set),e(nr,Pme),e(Pme,Pet),e(nr,$et),e(nr,tm),e(tm,Iet),e(tm,$me),e($me,jet),e(tm,Net),e(tm,Ime),e(Ime,Det),e(tm,Get),e(nr,Oet),e(nr,jme),e(jme,qet),e(nr,zet),g(By,nr,null),e(ht,Xet),e(ht,_o),g(ky,_o,null),e(_o,Wet),e(_o,Nme),e(Nme,Vet),e(_o,Qet),e(_o,tn),e(tn,Het),e(tn,Dme),e(Dme,Uet),e(tn,Jet),e(tn,Gme),e(Gme,Ket),e(tn,Yet),e(tn,Ome),e(Ome,Zet),e(tn,eot),e(_o,oot),e(_o,he),e(he,C0),e(C0,qme),e(qme,tot),e(C0,rot),e(C0,dN),e(dN,aot),e(C0,not),e(he,sot),e(he,y0),e(y0,zme),e(zme,lot),e(y0,iot),e(y0,mN),e(mN,dot),e(y0,mot),e(he,fot),e(he,w0),e(w0,Xme),e(Xme,cot),e(w0,got),e(w0,fN),e(fN,hot),e(w0,uot),e(he,pot),e(he,A0),e(A0,Wme),e(Wme,_ot),e(A0,vot),e(A0,cN),e(cN,bot),e(A0,Tot),e(he,Fot),e(he,x0),e(x0,Vme),e(Vme,Mot),e(x0,Eot),e(x0,gN),e(gN,Cot),e(x0,yot),e(he,wot),e(he,L0),e(L0,Qme),e(Qme,Aot),e(L0,xot),e(L0,hN),e(hN,Lot),e(L0,Bot),e(he,kot),e(he,B0),e(B0,Hme),e(Hme,Rot),e(B0,Sot),e(B0,uN),e(uN,Pot),e(B0,$ot),e(he,Iot),e(he,k0),e(k0,Ume),e(Ume,jot),e(k0,Not),e(k0,pN),e(pN,Dot),e(k0,Got),e(he,Oot),e(he,R0),e(R0,Jme),e(Jme,qot),e(R0,zot),e(R0,_N),e(_N,Xot),e(R0,Wot),e(he,Vot),e(he,S0),e(S0,Kme),e(Kme,Qot),e(S0,Hot),e(S0,vN),e(vN,Uot),e(S0,Jot),e(_o,Kot),e(_o,Yme),e(Yme,Yot),e(_o,Zot),g(Ry,_o,null),v(d,VCe,_),v(d,rm,_),e(rm,P0),e(P0,Zme),g(Sy,Zme,null),e(rm,ett),e(rm,efe),e(efe,ott),v(d,QCe,_),v(d,ut,_),g(Py,ut,null),e(ut,ttt),e(ut,am),e(am,rtt),e(am,ofe),e(ofe,att),e(am,ntt),e(am,tfe),e(tfe,stt),e(am,ltt),e(ut,itt),e(ut,$y),e($y,dtt),e($y,rfe),e(rfe,mtt),e($y,ftt),e(ut,ctt),e(ut,sr),g(Iy,sr,null),e(sr,gtt),e(sr,afe),e(afe,htt),e(sr,utt),e(sr,nm),e(nm,ptt),e(nm,nfe),e(nfe,_tt),e(nm,vtt),e(nm,sfe),e(sfe,btt),e(nm,Ttt),e(sr,Ftt),e(sr,lfe),e(lfe,Mtt),e(sr,Ett),g(jy,sr,null),e(ut,Ctt),e(ut,vo),g(Ny,vo,null),e(vo,ytt),e(vo,ife),e(ife,wtt),e(vo,Att),e(vo,rn),e(rn,xtt),e(rn,dfe),e(dfe,Ltt),e(rn,Btt),e(rn,mfe),e(mfe,ktt),e(rn,Rtt),e(rn,ffe),e(ffe,Stt),e(rn,Ptt),e(vo,$tt),e(vo,Me),e(Me,$0),e($0,cfe),e(cfe,Itt),e($0,jtt),e($0,bN),e(bN,Ntt),e($0,Dtt),e(Me,Gtt),e(Me,I0),e(I0,gfe),e(gfe,Ott),e(I0,qtt),e(I0,TN),e(TN,ztt),e(I0,Xtt),e(Me,Wtt),e(Me,j0),e(j0,hfe),e(hfe,Vtt),e(j0,Qtt),e(j0,FN),e(FN,Htt),e(j0,Utt),e(Me,Jtt),e(Me,N0),e(N0,ufe),e(ufe,Ktt),e(N0,Ytt),e(N0,MN),e(MN,Ztt),e(N0,ert),e(Me,ort),e(Me,D0),e(D0,pfe),e(pfe,trt),e(D0,rrt),e(D0,EN),e(EN,art),e(D0,nrt),e(Me,srt),e(Me,G0),e(G0,_fe),e(_fe,lrt),e(G0,irt),e(G0,CN),e(CN,drt),e(G0,mrt),e(Me,frt),e(Me,O0),e(O0,vfe),e(vfe,crt),e(O0,grt),e(O0,yN),e(yN,hrt),e(O0,urt),e(Me,prt),e(Me,q0),e(q0,bfe),e(bfe,_rt),e(q0,vrt),e(q0,wN),e(wN,brt),e(q0,Trt),e(vo,Frt),e(vo,Tfe),e(Tfe,Mrt),e(vo,Ert),g(Dy,vo,null),v(d,HCe,_),v(d,sm,_),e(sm,z0),e(z0,Ffe),g(Gy,Ffe,null),e(sm,Crt),e(sm,Mfe),e(Mfe,yrt),v(d,UCe,_),v(d,pt,_),g(Oy,pt,null),e(pt,wrt),e(pt,lm),e(lm,Art),e(lm,Efe),e(Efe,xrt),e(lm,Lrt),e(lm,Cfe),e(Cfe,Brt),e(lm,krt),e(pt,Rrt),e(pt,qy),e(qy,Srt),e(qy,yfe),e(yfe,Prt),e(qy,$rt),e(pt,Irt),e(pt,lr),g(zy,lr,null),e(lr,jrt),e(lr,wfe),e(wfe,Nrt),e(lr,Drt),e(lr,im),e(im,Grt),e(im,Afe),e(Afe,Ort),e(im,qrt),e(im,xfe),e(xfe,zrt),e(im,Xrt),e(lr,Wrt),e(lr,Lfe),e(Lfe,Vrt),e(lr,Qrt),g(Xy,lr,null),e(pt,Hrt),e(pt,bo),g(Wy,bo,null),e(bo,Urt),e(bo,Bfe),e(Bfe,Jrt),e(bo,Krt),e(bo,an),e(an,Yrt),e(an,kfe),e(kfe,Zrt),e(an,eat),e(an,Rfe),e(Rfe,oat),e(an,tat),e(an,Sfe),e(Sfe,rat),e(an,aat),e(bo,nat),e(bo,pe),e(pe,X0),e(X0,Pfe),e(Pfe,sat),e(X0,lat),e(X0,AN),e(AN,iat),e(X0,dat),e(pe,mat),e(pe,W0),e(W0,$fe),e($fe,fat),e(W0,cat),e(W0,xN),e(xN,gat),e(W0,hat),e(pe,uat),e(pe,V0),e(V0,Ife),e(Ife,pat),e(V0,_at),e(V0,LN),e(LN,vat),e(V0,bat),e(pe,Tat),e(pe,Q0),e(Q0,jfe),e(jfe,Fat),e(Q0,Mat),e(Q0,BN),e(BN,Eat),e(Q0,Cat),e(pe,yat),e(pe,H0),e(H0,Nfe),e(Nfe,wat),e(H0,Aat),e(H0,kN),e(kN,xat),e(H0,Lat),e(pe,Bat),e(pe,U0),e(U0,Dfe),e(Dfe,kat),e(U0,Rat),e(U0,RN),e(RN,Sat),e(U0,Pat),e(pe,$at),e(pe,J0),e(J0,Gfe),e(Gfe,Iat),e(J0,jat),e(J0,SN),e(SN,Nat),e(J0,Dat),e(pe,Gat),e(pe,K0),e(K0,Ofe),e(Ofe,Oat),e(K0,qat),e(K0,PN),e(PN,zat),e(K0,Xat),e(pe,Wat),e(pe,Y0),e(Y0,qfe),e(qfe,Vat),e(Y0,Qat),e(Y0,$N),e($N,Hat),e(Y0,Uat),e(bo,Jat),e(bo,zfe),e(zfe,Kat),e(bo,Yat),g(Vy,bo,null),v(d,JCe,_),v(d,dm,_),e(dm,Z0),e(Z0,Xfe),g(Qy,Xfe,null),e(dm,Zat),e(dm,Wfe),e(Wfe,ent),v(d,KCe,_),v(d,_t,_),g(Hy,_t,null),e(_t,ont),e(_t,mm),e(mm,tnt),e(mm,Vfe),e(Vfe,rnt),e(mm,ant),e(mm,Qfe),e(Qfe,nnt),e(mm,snt),e(_t,lnt),e(_t,Uy),e(Uy,int),e(Uy,Hfe),e(Hfe,dnt),e(Uy,mnt),e(_t,fnt),e(_t,ir),g(Jy,ir,null),e(ir,cnt),e(ir,Ufe),e(Ufe,gnt),e(ir,hnt),e(ir,fm),e(fm,unt),e(fm,Jfe),e(Jfe,pnt),e(fm,_nt),e(fm,Kfe),e(Kfe,vnt),e(fm,bnt),e(ir,Tnt),e(ir,Yfe),e(Yfe,Fnt),e(ir,Mnt),g(Ky,ir,null),e(_t,Ent),e(_t,To),g(Yy,To,null),e(To,Cnt),e(To,Zfe),e(Zfe,ynt),e(To,wnt),e(To,nn),e(nn,Ant),e(nn,ece),e(ece,xnt),e(nn,Lnt),e(nn,oce),e(oce,Bnt),e(nn,knt),e(nn,tce),e(tce,Rnt),e(nn,Snt),e(To,Pnt),e(To,Ee),e(Ee,eT),e(eT,rce),e(rce,$nt),e(eT,Int),e(eT,IN),e(IN,jnt),e(eT,Nnt),e(Ee,Dnt),e(Ee,oT),e(oT,ace),e(ace,Gnt),e(oT,Ont),e(oT,jN),e(jN,qnt),e(oT,znt),e(Ee,Xnt),e(Ee,tT),e(tT,nce),e(nce,Wnt),e(tT,Vnt),e(tT,NN),e(NN,Qnt),e(tT,Hnt),e(Ee,Unt),e(Ee,rT),e(rT,sce),e(sce,Jnt),e(rT,Knt),e(rT,DN),e(DN,Ynt),e(rT,Znt),e(Ee,est),e(Ee,aT),e(aT,lce),e(lce,ost),e(aT,tst),e(aT,GN),e(GN,rst),e(aT,ast),e(Ee,nst),e(Ee,nT),e(nT,ice),e(ice,sst),e(nT,lst),e(nT,ON),e(ON,ist),e(nT,dst),e(Ee,mst),e(Ee,sT),e(sT,dce),e(dce,fst),e(sT,cst),e(sT,qN),e(qN,gst),e(sT,hst),e(Ee,ust),e(Ee,lT),e(lT,mce),e(mce,pst),e(lT,_st),e(lT,zN),e(zN,vst),e(lT,bst),e(To,Tst),e(To,fce),e(fce,Fst),e(To,Mst),g(Zy,To,null),v(d,YCe,_),v(d,cm,_),e(cm,iT),e(iT,cce),g(ew,cce,null),e(cm,Est),e(cm,gce),e(gce,Cst),v(d,ZCe,_),v(d,vt,_),g(ow,vt,null),e(vt,yst),e(vt,gm),e(gm,wst),e(gm,hce),e(hce,Ast),e(gm,xst),e(gm,uce),e(uce,Lst),e(gm,Bst),e(vt,kst),e(vt,tw),e(tw,Rst),e(tw,pce),e(pce,Sst),e(tw,Pst),e(vt,$st),e(vt,dr),g(rw,dr,null),e(dr,Ist),e(dr,_ce),e(_ce,jst),e(dr,Nst),e(dr,hm),e(hm,Dst),e(hm,vce),e(vce,Gst),e(hm,Ost),e(hm,bce),e(bce,qst),e(hm,zst),e(dr,Xst),e(dr,Tce),e(Tce,Wst),e(dr,Vst),g(aw,dr,null),e(vt,Qst),e(vt,Fo),g(nw,Fo,null),e(Fo,Hst),e(Fo,Fce),e(Fce,Ust),e(Fo,Jst),e(Fo,sn),e(sn,Kst),e(sn,Mce),e(Mce,Yst),e(sn,Zst),e(sn,Ece),e(Ece,elt),e(sn,olt),e(sn,Cce),e(Cce,tlt),e(sn,rlt),e(Fo,alt),e(Fo,Ce),e(Ce,dT),e(dT,yce),e(yce,nlt),e(dT,slt),e(dT,XN),e(XN,llt),e(dT,ilt),e(Ce,dlt),e(Ce,mT),e(mT,wce),e(wce,mlt),e(mT,flt),e(mT,WN),e(WN,clt),e(mT,glt),e(Ce,hlt),e(Ce,fT),e(fT,Ace),e(Ace,ult),e(fT,plt),e(fT,VN),e(VN,_lt),e(fT,vlt),e(Ce,blt),e(Ce,cT),e(cT,xce),e(xce,Tlt),e(cT,Flt),e(cT,QN),e(QN,Mlt),e(cT,Elt),e(Ce,Clt),e(Ce,gT),e(gT,Lce),e(Lce,ylt),e(gT,wlt),e(gT,HN),e(HN,Alt),e(gT,xlt),e(Ce,Llt),e(Ce,hT),e(hT,Bce),e(Bce,Blt),e(hT,klt),e(hT,UN),e(UN,Rlt),e(hT,Slt),e(Ce,Plt),e(Ce,uT),e(uT,kce),e(kce,$lt),e(uT,Ilt),e(uT,JN),e(JN,jlt),e(uT,Nlt),e(Ce,Dlt),e(Ce,pT),e(pT,Rce),e(Rce,Glt),e(pT,Olt),e(pT,KN),e(KN,qlt),e(pT,zlt),e(Fo,Xlt),e(Fo,Sce),e(Sce,Wlt),e(Fo,Vlt),g(sw,Fo,null),v(d,e3e,_),v(d,um,_),e(um,_T),e(_T,Pce),g(lw,Pce,null),e(um,Qlt),e(um,$ce),e($ce,Hlt),v(d,o3e,_),v(d,bt,_),g(iw,bt,null),e(bt,Ult),e(bt,pm),e(pm,Jlt),e(pm,Ice),e(Ice,Klt),e(pm,Ylt),e(pm,jce),e(jce,Zlt),e(pm,eit),e(bt,oit),e(bt,dw),e(dw,tit),e(dw,Nce),e(Nce,rit),e(dw,ait),e(bt,nit),e(bt,mr),g(mw,mr,null),e(mr,sit),e(mr,Dce),e(Dce,lit),e(mr,iit),e(mr,_m),e(_m,dit),e(_m,Gce),e(Gce,mit),e(_m,fit),e(_m,Oce),e(Oce,cit),e(_m,git),e(mr,hit),e(mr,qce),e(qce,uit),e(mr,pit),g(fw,mr,null),e(bt,_it),e(bt,Mo),g(cw,Mo,null),e(Mo,vit),e(Mo,zce),e(zce,bit),e(Mo,Tit),e(Mo,ln),e(ln,Fit),e(ln,Xce),e(Xce,Mit),e(ln,Eit),e(ln,Wce),e(Wce,Cit),e(ln,yit),e(ln,Vce),e(Vce,wit),e(ln,Ait),e(Mo,xit),e(Mo,Tt),e(Tt,vT),e(vT,Qce),e(Qce,Lit),e(vT,Bit),e(vT,YN),e(YN,kit),e(vT,Rit),e(Tt,Sit),e(Tt,bT),e(bT,Hce),e(Hce,Pit),e(bT,$it),e(bT,ZN),e(ZN,Iit),e(bT,jit),e(Tt,Nit),e(Tt,TT),e(TT,Uce),e(Uce,Dit),e(TT,Git),e(TT,eD),e(eD,Oit),e(TT,qit),e(Tt,zit),e(Tt,FT),e(FT,Jce),e(Jce,Xit),e(FT,Wit),e(FT,oD),e(oD,Vit),e(FT,Qit),e(Tt,Hit),e(Tt,MT),e(MT,Kce),e(Kce,Uit),e(MT,Jit),e(MT,tD),e(tD,Kit),e(MT,Yit),e(Tt,Zit),e(Tt,ET),e(ET,Yce),e(Yce,edt),e(ET,odt),e(ET,rD),e(rD,tdt),e(ET,rdt),e(Mo,adt),e(Mo,Zce),e(Zce,ndt),e(Mo,sdt),g(gw,Mo,null),v(d,t3e,_),v(d,vm,_),e(vm,CT),e(CT,ege),g(hw,ege,null),e(vm,ldt),e(vm,oge),e(oge,idt),v(d,r3e,_),v(d,Ft,_),g(uw,Ft,null),e(Ft,ddt),e(Ft,bm),e(bm,mdt),e(bm,tge),e(tge,fdt),e(bm,cdt),e(bm,rge),e(rge,gdt),e(bm,hdt),e(Ft,udt),e(Ft,pw),e(pw,pdt),e(pw,age),e(age,_dt),e(pw,vdt),e(Ft,bdt),e(Ft,fr),g(_w,fr,null),e(fr,Tdt),e(fr,nge),e(nge,Fdt),e(fr,Mdt),e(fr,Tm),e(Tm,Edt),e(Tm,sge),e(sge,Cdt),e(Tm,ydt),e(Tm,lge),e(lge,wdt),e(Tm,Adt),e(fr,xdt),e(fr,ige),e(ige,Ldt),e(fr,Bdt),g(vw,fr,null),e(Ft,kdt),e(Ft,Eo),g(bw,Eo,null),e(Eo,Rdt),e(Eo,dge),e(dge,Sdt),e(Eo,Pdt),e(Eo,dn),e(dn,$dt),e(dn,mge),e(mge,Idt),e(dn,jdt),e(dn,fge),e(fge,Ndt),e(dn,Ddt),e(dn,cge),e(cge,Gdt),e(dn,Odt),e(Eo,qdt),e(Eo,Mt),e(Mt,yT),e(yT,gge),e(gge,zdt),e(yT,Xdt),e(yT,aD),e(aD,Wdt),e(yT,Vdt),e(Mt,Qdt),e(Mt,wT),e(wT,hge),e(hge,Hdt),e(wT,Udt),e(wT,nD),e(nD,Jdt),e(wT,Kdt),e(Mt,Ydt),e(Mt,AT),e(AT,uge),e(uge,Zdt),e(AT,emt),e(AT,sD),e(sD,omt),e(AT,tmt),e(Mt,rmt),e(Mt,xT),e(xT,pge),e(pge,amt),e(xT,nmt),e(xT,lD),e(lD,smt),e(xT,lmt),e(Mt,imt),e(Mt,LT),e(LT,_ge),e(_ge,dmt),e(LT,mmt),e(LT,iD),e(iD,fmt),e(LT,cmt),e(Mt,gmt),e(Mt,BT),e(BT,vge),e(vge,hmt),e(BT,umt),e(BT,dD),e(dD,pmt),e(BT,_mt),e(Eo,vmt),e(Eo,bge),e(bge,bmt),e(Eo,Tmt),g(Tw,Eo,null),v(d,a3e,_),v(d,Fm,_),e(Fm,kT),e(kT,Tge),g(Fw,Tge,null),e(Fm,Fmt),e(Fm,Fge),e(Fge,Mmt),v(d,n3e,_),v(d,Et,_),g(Mw,Et,null),e(Et,Emt),e(Et,Mm),e(Mm,Cmt),e(Mm,Mge),e(Mge,ymt),e(Mm,wmt),e(Mm,Ege),e(Ege,Amt),e(Mm,xmt),e(Et,Lmt),e(Et,Ew),e(Ew,Bmt),e(Ew,Cge),e(Cge,kmt),e(Ew,Rmt),e(Et,Smt),e(Et,cr),g(Cw,cr,null),e(cr,Pmt),e(cr,yge),e(yge,$mt),e(cr,Imt),e(cr,Em),e(Em,jmt),e(Em,wge),e(wge,Nmt),e(Em,Dmt),e(Em,Age),e(Age,Gmt),e(Em,Omt),e(cr,qmt),e(cr,xge),e(xge,zmt),e(cr,Xmt),g(yw,cr,null),e(Et,Wmt),e(Et,Co),g(ww,Co,null),e(Co,Vmt),e(Co,Lge),e(Lge,Qmt),e(Co,Hmt),e(Co,mn),e(mn,Umt),e(mn,Bge),e(Bge,Jmt),e(mn,Kmt),e(mn,kge),e(kge,Ymt),e(mn,Zmt),e(mn,Rge),e(Rge,eft),e(mn,oft),e(Co,tft),e(Co,Sge),e(Sge,RT),e(RT,Pge),e(Pge,rft),e(RT,aft),e(RT,mD),e(mD,nft),e(RT,sft),e(Co,lft),e(Co,$ge),e($ge,ift),e(Co,dft),g(Aw,Co,null),v(d,s3e,_),v(d,Cm,_),e(Cm,ST),e(ST,Ige),g(xw,Ige,null),e(Cm,mft),e(Cm,jge),e(jge,fft),v(d,l3e,_),v(d,Ct,_),g(Lw,Ct,null),e(Ct,cft),e(Ct,ym),e(ym,gft),e(ym,Nge),e(Nge,hft),e(ym,uft),e(ym,Dge),e(Dge,pft),e(ym,_ft),e(Ct,vft),e(Ct,Bw),e(Bw,bft),e(Bw,Gge),e(Gge,Tft),e(Bw,Fft),e(Ct,Mft),e(Ct,gr),g(kw,gr,null),e(gr,Eft),e(gr,Oge),e(Oge,Cft),e(gr,yft),e(gr,wm),e(wm,wft),e(wm,qge),e(qge,Aft),e(wm,xft),e(wm,zge),e(zge,Lft),e(wm,Bft),e(gr,kft),e(gr,Xge),e(Xge,Rft),e(gr,Sft),g(Rw,gr,null),e(Ct,Pft),e(Ct,yo),g(Sw,yo,null),e(yo,$ft),e(yo,Wge),e(Wge,Ift),e(yo,jft),e(yo,fn),e(fn,Nft),e(fn,Vge),e(Vge,Dft),e(fn,Gft),e(fn,Qge),e(Qge,Oft),e(fn,qft),e(fn,Hge),e(Hge,zft),e(fn,Xft),e(yo,Wft),e(yo,Pw),e(Pw,PT),e(PT,Uge),e(Uge,Vft),e(PT,Qft),e(PT,fD),e(fD,Hft),e(PT,Uft),e(Pw,Jft),e(Pw,$T),e($T,Jge),e(Jge,Kft),e($T,Yft),e($T,cD),e(cD,Zft),e($T,ect),e(yo,oct),e(yo,Kge),e(Kge,tct),e(yo,rct),g($w,yo,null),v(d,i3e,_),v(d,Am,_),e(Am,IT),e(IT,Yge),g(Iw,Yge,null),e(Am,act),e(Am,Zge),e(Zge,nct),v(d,d3e,_),v(d,yt,_),g(jw,yt,null),e(yt,sct),e(yt,xm),e(xm,lct),e(xm,ehe),e(ehe,ict),e(xm,dct),e(xm,ohe),e(ohe,mct),e(xm,fct),e(yt,cct),e(yt,Nw),e(Nw,gct),e(Nw,the),e(the,hct),e(Nw,uct),e(yt,pct),e(yt,hr),g(Dw,hr,null),e(hr,_ct),e(hr,rhe),e(rhe,vct),e(hr,bct),e(hr,Lm),e(Lm,Tct),e(Lm,ahe),e(ahe,Fct),e(Lm,Mct),e(Lm,nhe),e(nhe,Ect),e(Lm,Cct),e(hr,yct),e(hr,she),e(she,wct),e(hr,Act),g(Gw,hr,null),e(yt,xct),e(yt,wo),g(Ow,wo,null),e(wo,Lct),e(wo,lhe),e(lhe,Bct),e(wo,kct),e(wo,cn),e(cn,Rct),e(cn,ihe),e(ihe,Sct),e(cn,Pct),e(cn,dhe),e(dhe,$ct),e(cn,Ict),e(cn,mhe),e(mhe,jct),e(cn,Nct),e(wo,Dct),e(wo,fhe),e(fhe,jT),e(jT,che),e(che,Gct),e(jT,Oct),e(jT,gD),e(gD,qct),e(jT,zct),e(wo,Xct),e(wo,ghe),e(ghe,Wct),e(wo,Vct),g(qw,wo,null),m3e=!0},p(d,[_]){const zw={};_&2&&(zw.$$scope={dirty:_,ctx:d}),Im.$set(zw);const hhe={};_&2&&(hhe.$$scope={dirty:_,ctx:d}),Kc.$set(hhe);const uhe={};_&2&&(uhe.$$scope={dirty:_,ctx:d}),sg.$set(uhe)},i(d){m3e||(h(ie.$$.fragment,d),h(ba.$$.fragment,d),h(IF.$$.fragment,d),h(jF.$$.fragment,d),h(Im.$$.fragment,d),h(NF.$$.fragment,d),h(DF.$$.fragment,d),h(qF.$$.fragment,d),h(zF.$$.fragment,d),h(XF.$$.fragment,d),h(WF.$$.fragment,d),h(VF.$$.fragment,d),h(UF.$$.fragment,d),h(JF.$$.fragment,d),h(KF.$$.fragment,d),h(YF.$$.fragment,d),h(ZF.$$.fragment,d),h(tM.$$.fragment,d),h(Kc.$$.fragment,d),h(rM.$$.fragment,d),h(aM.$$.fragment,d),h(nM.$$.fragment,d),h(iM.$$.fragment,d),h(sg.$$.fragment,d),h(dM.$$.fragment,d),h(mM.$$.fragment,d),h(fM.$$.fragment,d),h(gM.$$.fragment,d),h(hM.$$.fragment,d),h(uM.$$.fragment,d),h(pM.$$.fragment,d),h(_M.$$.fragment,d),h(vM.$$.fragment,d),h(TM.$$.fragment,d),h(FM.$$.fragment,d),h(MM.$$.fragment,d),h(EM.$$.fragment,d),h(CM.$$.fragment,d),h(yM.$$.fragment,d),h(AM.$$.fragment,d),h(xM.$$.fragment,d),h(LM.$$.fragment,d),h(BM.$$.fragment,d),h(kM.$$.fragment,d),h(RM.$$.fragment,d),h(PM.$$.fragment,d),h($M.$$.fragment,d),h(IM.$$.fragment,d),h(jM.$$.fragment,d),h(NM.$$.fragment,d),h(DM.$$.fragment,d),h(OM.$$.fragment,d),h(qM.$$.fragment,d),h(zM.$$.fragment,d),h(XM.$$.fragment,d),h(WM.$$.fragment,d),h(VM.$$.fragment,d),h(HM.$$.fragment,d),h(UM.$$.fragment,d),h(JM.$$.fragment,d),h(KM.$$.fragment,d),h(YM.$$.fragment,d),h(ZM.$$.fragment,d),h(oE.$$.fragment,d),h(tE.$$.fragment,d),h(rE.$$.fragment,d),h(aE.$$.fragment,d),h(nE.$$.fragment,d),h(sE.$$.fragment,d),h(iE.$$.fragment,d),h(dE.$$.fragment,d),h(mE.$$.fragment,d),h(fE.$$.fragment,d),h(cE.$$.fragment,d),h(gE.$$.fragment,d),h(uE.$$.fragment,d),h(pE.$$.fragment,d),h(_E.$$.fragment,d),h(vE.$$.fragment,d),h(bE.$$.fragment,d),h(TE.$$.fragment,d),h(ME.$$.fragment,d),h(EE.$$.fragment,d),h(CE.$$.fragment,d),h(yE.$$.fragment,d),h(wE.$$.fragment,d),h(AE.$$.fragment,d),h(LE.$$.fragment,d),h(BE.$$.fragment,d),h(kE.$$.fragment,d),h(RE.$$.fragment,d),h(SE.$$.fragment,d),h(PE.$$.fragment,d),h(IE.$$.fragment,d),h(jE.$$.fragment,d),h(NE.$$.fragment,d),h(DE.$$.fragment,d),h(GE.$$.fragment,d),h(OE.$$.fragment,d),h(zE.$$.fragment,d),h(XE.$$.fragment,d),h(WE.$$.fragment,d),h(VE.$$.fragment,d),h(QE.$$.fragment,d),h(HE.$$.fragment,d),h(JE.$$.fragment,d),h(KE.$$.fragment,d),h(YE.$$.fragment,d),h(ZE.$$.fragment,d),h(eC.$$.fragment,d),h(oC.$$.fragment,d),h(rC.$$.fragment,d),h(aC.$$.fragment,d),h(nC.$$.fragment,d),h(sC.$$.fragment,d),h(lC.$$.fragment,d),h(iC.$$.fragment,d),h(mC.$$.fragment,d),h(fC.$$.fragment,d),h(cC.$$.fragment,d),h(gC.$$.fragment,d),h(hC.$$.fragment,d),h(uC.$$.fragment,d),h(_C.$$.fragment,d),h(vC.$$.fragment,d),h(bC.$$.fragment,d),h(FC.$$.fragment,d),h(MC.$$.fragment,d),h(EC.$$.fragment,d),h(yC.$$.fragment,d),h(wC.$$.fragment,d),h(AC.$$.fragment,d),h(xC.$$.fragment,d),h(LC.$$.fragment,d),h(BC.$$.fragment,d),h(RC.$$.fragment,d),h(SC.$$.fragment,d),h(PC.$$.fragment,d),h($C.$$.fragment,d),h(IC.$$.fragment,d),h(jC.$$.fragment,d),h(DC.$$.fragment,d),h(GC.$$.fragment,d),h(OC.$$.fragment,d),h(qC.$$.fragment,d),h(zC.$$.fragment,d),h(XC.$$.fragment,d),h(VC.$$.fragment,d),h(QC.$$.fragment,d),h(HC.$$.fragment,d),h(UC.$$.fragment,d),h(JC.$$.fragment,d),h(KC.$$.fragment,d),h(ZC.$$.fragment,d),h(e3.$$.fragment,d),h(o3.$$.fragment,d),h(t3.$$.fragment,d),h(r3.$$.fragment,d),h(a3.$$.fragment,d),h(s3.$$.fragment,d),h(l3.$$.fragment,d),h(i3.$$.fragment,d),h(d3.$$.fragment,d),h(m3.$$.fragment,d),h(f3.$$.fragment,d),h(g3.$$.fragment,d),h(h3.$$.fragment,d),h(u3.$$.fragment,d),h(p3.$$.fragment,d),h(_3.$$.fragment,d),h(v3.$$.fragment,d),h(T3.$$.fragment,d),h(F3.$$.fragment,d),h(M3.$$.fragment,d),h(E3.$$.fragment,d),h(C3.$$.fragment,d),h(y3.$$.fragment,d),h(A3.$$.fragment,d),h(x3.$$.fragment,d),h(L3.$$.fragment,d),h(B3.$$.fragment,d),h(k3.$$.fragment,d),h(R3.$$.fragment,d),h(P3.$$.fragment,d),h($3.$$.fragment,d),h(I3.$$.fragment,d),h(j3.$$.fragment,d),h(N3.$$.fragment,d),h(D3.$$.fragment,d),h(O3.$$.fragment,d),h(q3.$$.fragment,d),h(z3.$$.fragment,d),h(X3.$$.fragment,d),h(W3.$$.fragment,d),h(V3.$$.fragment,d),h(H3.$$.fragment,d),h(U3.$$.fragment,d),h(J3.$$.fragment,d),h(K3.$$.fragment,d),h(Y3.$$.fragment,d),h(Z3.$$.fragment,d),h(oy.$$.fragment,d),h(ty.$$.fragment,d),h(ry.$$.fragment,d),h(ay.$$.fragment,d),h(ny.$$.fragment,d),h(sy.$$.fragment,d),h(iy.$$.fragment,d),h(dy.$$.fragment,d),h(my.$$.fragment,d),h(fy.$$.fragment,d),h(cy.$$.fragment,d),h(gy.$$.fragment,d),h(uy.$$.fragment,d),h(py.$$.fragment,d),h(_y.$$.fragment,d),h(vy.$$.fragment,d),h(by.$$.fragment,d),h(Ty.$$.fragment,d),h(My.$$.fragment,d),h(Ey.$$.fragment,d),h(Cy.$$.fragment,d),h(yy.$$.fragment,d),h(wy.$$.fragment,d),h(Ay.$$.fragment,d),h(Ly.$$.fragment,d),h(By.$$.fragment,d),h(ky.$$.fragment,d),h(Ry.$$.fragment,d),h(Sy.$$.fragment,d),h(Py.$$.fragment,d),h(Iy.$$.fragment,d),h(jy.$$.fragment,d),h(Ny.$$.fragment,d),h(Dy.$$.fragment,d),h(Gy.$$.fragment,d),h(Oy.$$.fragment,d),h(zy.$$.fragment,d),h(Xy.$$.fragment,d),h(Wy.$$.fragment,d),h(Vy.$$.fragment,d),h(Qy.$$.fragment,d),h(Hy.$$.fragment,d),h(Jy.$$.fragment,d),h(Ky.$$.fragment,d),h(Yy.$$.fragment,d),h(Zy.$$.fragment,d),h(ew.$$.fragment,d),h(ow.$$.fragment,d),h(rw.$$.fragment,d),h(aw.$$.fragment,d),h(nw.$$.fragment,d),h(sw.$$.fragment,d),h(lw.$$.fragment,d),h(iw.$$.fragment,d),h(mw.$$.fragment,d),h(fw.$$.fragment,d),h(cw.$$.fragment,d),h(gw.$$.fragment,d),h(hw.$$.fragment,d),h(uw.$$.fragment,d),h(_w.$$.fragment,d),h(vw.$$.fragment,d),h(bw.$$.fragment,d),h(Tw.$$.fragment,d),h(Fw.$$.fragment,d),h(Mw.$$.fragment,d),h(Cw.$$.fragment,d),h(yw.$$.fragment,d),h(ww.$$.fragment,d),h(Aw.$$.fragment,d),h(xw.$$.fragment,d),h(Lw.$$.fragment,d),h(kw.$$.fragment,d),h(Rw.$$.fragment,d),h(Sw.$$.fragment,d),h($w.$$.fragment,d),h(Iw.$$.fragment,d),h(jw.$$.fragment,d),h(Dw.$$.fragment,d),h(Gw.$$.fragment,d),h(Ow.$$.fragment,d),h(qw.$$.fragment,d),m3e=!0)},o(d){u(ie.$$.fragment,d),u(ba.$$.fragment,d),u(IF.$$.fragment,d),u(jF.$$.fragment,d),u(Im.$$.fragment,d),u(NF.$$.fragment,d),u(DF.$$.fragment,d),u(qF.$$.fragment,d),u(zF.$$.fragment,d),u(XF.$$.fragment,d),u(WF.$$.fragment,d),u(VF.$$.fragment,d),u(UF.$$.fragment,d),u(JF.$$.fragment,d),u(KF.$$.fragment,d),u(YF.$$.fragment,d),u(ZF.$$.fragment,d),u(tM.$$.fragment,d),u(Kc.$$.fragment,d),u(rM.$$.fragment,d),u(aM.$$.fragment,d),u(nM.$$.fragment,d),u(iM.$$.fragment,d),u(sg.$$.fragment,d),u(dM.$$.fragment,d),u(mM.$$.fragment,d),u(fM.$$.fragment,d),u(gM.$$.fragment,d),u(hM.$$.fragment,d),u(uM.$$.fragment,d),u(pM.$$.fragment,d),u(_M.$$.fragment,d),u(vM.$$.fragment,d),u(TM.$$.fragment,d),u(FM.$$.fragment,d),u(MM.$$.fragment,d),u(EM.$$.fragment,d),u(CM.$$.fragment,d),u(yM.$$.fragment,d),u(AM.$$.fragment,d),u(xM.$$.fragment,d),u(LM.$$.fragment,d),u(BM.$$.fragment,d),u(kM.$$.fragment,d),u(RM.$$.fragment,d),u(PM.$$.fragment,d),u($M.$$.fragment,d),u(IM.$$.fragment,d),u(jM.$$.fragment,d),u(NM.$$.fragment,d),u(DM.$$.fragment,d),u(OM.$$.fragment,d),u(qM.$$.fragment,d),u(zM.$$.fragment,d),u(XM.$$.fragment,d),u(WM.$$.fragment,d),u(VM.$$.fragment,d),u(HM.$$.fragment,d),u(UM.$$.fragment,d),u(JM.$$.fragment,d),u(KM.$$.fragment,d),u(YM.$$.fragment,d),u(ZM.$$.fragment,d),u(oE.$$.fragment,d),u(tE.$$.fragment,d),u(rE.$$.fragment,d),u(aE.$$.fragment,d),u(nE.$$.fragment,d),u(sE.$$.fragment,d),u(iE.$$.fragment,d),u(dE.$$.fragment,d),u(mE.$$.fragment,d),u(fE.$$.fragment,d),u(cE.$$.fragment,d),u(gE.$$.fragment,d),u(uE.$$.fragment,d),u(pE.$$.fragment,d),u(_E.$$.fragment,d),u(vE.$$.fragment,d),u(bE.$$.fragment,d),u(TE.$$.fragment,d),u(ME.$$.fragment,d),u(EE.$$.fragment,d),u(CE.$$.fragment,d),u(yE.$$.fragment,d),u(wE.$$.fragment,d),u(AE.$$.fragment,d),u(LE.$$.fragment,d),u(BE.$$.fragment,d),u(kE.$$.fragment,d),u(RE.$$.fragment,d),u(SE.$$.fragment,d),u(PE.$$.fragment,d),u(IE.$$.fragment,d),u(jE.$$.fragment,d),u(NE.$$.fragment,d),u(DE.$$.fragment,d),u(GE.$$.fragment,d),u(OE.$$.fragment,d),u(zE.$$.fragment,d),u(XE.$$.fragment,d),u(WE.$$.fragment,d),u(VE.$$.fragment,d),u(QE.$$.fragment,d),u(HE.$$.fragment,d),u(JE.$$.fragment,d),u(KE.$$.fragment,d),u(YE.$$.fragment,d),u(ZE.$$.fragment,d),u(eC.$$.fragment,d),u(oC.$$.fragment,d),u(rC.$$.fragment,d),u(aC.$$.fragment,d),u(nC.$$.fragment,d),u(sC.$$.fragment,d),u(lC.$$.fragment,d),u(iC.$$.fragment,d),u(mC.$$.fragment,d),u(fC.$$.fragment,d),u(cC.$$.fragment,d),u(gC.$$.fragment,d),u(hC.$$.fragment,d),u(uC.$$.fragment,d),u(_C.$$.fragment,d),u(vC.$$.fragment,d),u(bC.$$.fragment,d),u(FC.$$.fragment,d),u(MC.$$.fragment,d),u(EC.$$.fragment,d),u(yC.$$.fragment,d),u(wC.$$.fragment,d),u(AC.$$.fragment,d),u(xC.$$.fragment,d),u(LC.$$.fragment,d),u(BC.$$.fragment,d),u(RC.$$.fragment,d),u(SC.$$.fragment,d),u(PC.$$.fragment,d),u($C.$$.fragment,d),u(IC.$$.fragment,d),u(jC.$$.fragment,d),u(DC.$$.fragment,d),u(GC.$$.fragment,d),u(OC.$$.fragment,d),u(qC.$$.fragment,d),u(zC.$$.fragment,d),u(XC.$$.fragment,d),u(VC.$$.fragment,d),u(QC.$$.fragment,d),u(HC.$$.fragment,d),u(UC.$$.fragment,d),u(JC.$$.fragment,d),u(KC.$$.fragment,d),u(ZC.$$.fragment,d),u(e3.$$.fragment,d),u(o3.$$.fragment,d),u(t3.$$.fragment,d),u(r3.$$.fragment,d),u(a3.$$.fragment,d),u(s3.$$.fragment,d),u(l3.$$.fragment,d),u(i3.$$.fragment,d),u(d3.$$.fragment,d),u(m3.$$.fragment,d),u(f3.$$.fragment,d),u(g3.$$.fragment,d),u(h3.$$.fragment,d),u(u3.$$.fragment,d),u(p3.$$.fragment,d),u(_3.$$.fragment,d),u(v3.$$.fragment,d),u(T3.$$.fragment,d),u(F3.$$.fragment,d),u(M3.$$.fragment,d),u(E3.$$.fragment,d),u(C3.$$.fragment,d),u(y3.$$.fragment,d),u(A3.$$.fragment,d),u(x3.$$.fragment,d),u(L3.$$.fragment,d),u(B3.$$.fragment,d),u(k3.$$.fragment,d),u(R3.$$.fragment,d),u(P3.$$.fragment,d),u($3.$$.fragment,d),u(I3.$$.fragment,d),u(j3.$$.fragment,d),u(N3.$$.fragment,d),u(D3.$$.fragment,d),u(O3.$$.fragment,d),u(q3.$$.fragment,d),u(z3.$$.fragment,d),u(X3.$$.fragment,d),u(W3.$$.fragment,d),u(V3.$$.fragment,d),u(H3.$$.fragment,d),u(U3.$$.fragment,d),u(J3.$$.fragment,d),u(K3.$$.fragment,d),u(Y3.$$.fragment,d),u(Z3.$$.fragment,d),u(oy.$$.fragment,d),u(ty.$$.fragment,d),u(ry.$$.fragment,d),u(ay.$$.fragment,d),u(ny.$$.fragment,d),u(sy.$$.fragment,d),u(iy.$$.fragment,d),u(dy.$$.fragment,d),u(my.$$.fragment,d),u(fy.$$.fragment,d),u(cy.$$.fragment,d),u(gy.$$.fragment,d),u(uy.$$.fragment,d),u(py.$$.fragment,d),u(_y.$$.fragment,d),u(vy.$$.fragment,d),u(by.$$.fragment,d),u(Ty.$$.fragment,d),u(My.$$.fragment,d),u(Ey.$$.fragment,d),u(Cy.$$.fragment,d),u(yy.$$.fragment,d),u(wy.$$.fragment,d),u(Ay.$$.fragment,d),u(Ly.$$.fragment,d),u(By.$$.fragment,d),u(ky.$$.fragment,d),u(Ry.$$.fragment,d),u(Sy.$$.fragment,d),u(Py.$$.fragment,d),u(Iy.$$.fragment,d),u(jy.$$.fragment,d),u(Ny.$$.fragment,d),u(Dy.$$.fragment,d),u(Gy.$$.fragment,d),u(Oy.$$.fragment,d),u(zy.$$.fragment,d),u(Xy.$$.fragment,d),u(Wy.$$.fragment,d),u(Vy.$$.fragment,d),u(Qy.$$.fragment,d),u(Hy.$$.fragment,d),u(Jy.$$.fragment,d),u(Ky.$$.fragment,d),u(Yy.$$.fragment,d),u(Zy.$$.fragment,d),u(ew.$$.fragment,d),u(ow.$$.fragment,d),u(rw.$$.fragment,d),u(aw.$$.fragment,d),u(nw.$$.fragment,d),u(sw.$$.fragment,d),u(lw.$$.fragment,d),u(iw.$$.fragment,d),u(mw.$$.fragment,d),u(fw.$$.fragment,d),u(cw.$$.fragment,d),u(gw.$$.fragment,d),u(hw.$$.fragment,d),u(uw.$$.fragment,d),u(_w.$$.fragment,d),u(vw.$$.fragment,d),u(bw.$$.fragment,d),u(Tw.$$.fragment,d),u(Fw.$$.fragment,d),u(Mw.$$.fragment,d),u(Cw.$$.fragment,d),u(yw.$$.fragment,d),u(ww.$$.fragment,d),u(Aw.$$.fragment,d),u(xw.$$.fragment,d),u(Lw.$$.fragment,d),u(kw.$$.fragment,d),u(Rw.$$.fragment,d),u(Sw.$$.fragment,d),u($w.$$.fragment,d),u(Iw.$$.fragment,d),u(jw.$$.fragment,d),u(Dw.$$.fragment,d),u(Gw.$$.fragment,d),u(Ow.$$.fragment,d),u(qw.$$.fragment,d),m3e=!1},d(d){r(J),d&&r(ye),d&&r(se),p(ie),d&&r(km),d&&r(zr),d&&r(Fe),d&&r(Ze),d&&r(Sm),p(ba,d),d&&r(eo),d&&r(me),d&&r(ko),d&&r(Ta),d&&r(bEe),d&&r(Zl),p(IF),d&&r(TEe),d&&r(_n),d&&r(FEe),p(jF,d),d&&r(MEe),d&&r(OA),d&&r(EEe),p(Im,d),d&&r(CEe),d&&r(ei),p(NF),d&&r(yEe),d&&r(Ro),p(DF),p(qF),p(zF),p(XF),d&&r(wEe),d&&r(ti),p(WF),d&&r(AEe),d&&r(So),p(VF),p(UF),p(JF),p(KF),d&&r(xEe),d&&r(ri),p(YF),d&&r(LEe),d&&r(Gr),p(ZF),p(tM),p(Kc),p(rM),d&&r(BEe),d&&r(ai),p(aM),d&&r(kEe),d&&r(Or),p(nM),p(iM),p(sg),p(dM),d&&r(REe),d&&r(si),p(mM),d&&r(SEe),d&&r(Po),p(fM),p(gM),p(hM),p(uM),p(pM),d&&r(PEe),d&&r(di),p(_M),d&&r($Ee),d&&r($o),p(vM),p(TM),p(FM),p(MM),p(EM),d&&r(IEe),d&&r(ci),p(CM),d&&r(jEe),d&&r(Io),p(yM),p(AM),p(xM),p(LM),p(BM),d&&r(NEe),d&&r(ui),p(kM),d&&r(DEe),d&&r(jo),p(RM),p(PM),p($M),p(IM),p(jM),d&&r(GEe),d&&r(vi),p(NM),d&&r(OEe),d&&r(No),p(DM),p(OM),p(qM),p(zM),p(XM),d&&r(qEe),d&&r(Fi),p(WM),d&&r(zEe),d&&r(Do),p(VM),p(HM),p(UM),p(JM),p(KM),d&&r(XEe),d&&r(Ci),p(YM),d&&r(WEe),d&&r(Go),p(ZM),p(oE),p(tE),p(rE),p(aE),d&&r(VEe),d&&r(Ai),p(nE),d&&r(QEe),d&&r(Oo),p(sE),p(iE),p(dE),p(mE),p(fE),d&&r(HEe),d&&r(Bi),p(cE),d&&r(UEe),d&&r(qo),p(gE),p(uE),p(pE),p(_E),p(vE),d&&r(JEe),d&&r(Si),p(bE),d&&r(KEe),d&&r(zo),p(TE),p(ME),p(EE),p(CE),p(yE),d&&r(YEe),d&&r(Ii),p(wE),d&&r(ZEe),d&&r(Xo),p(AE),p(LE),p(BE),p(kE),p(RE),d&&r(eCe),d&&r(Di),p(SE),d&&r(oCe),d&&r(Wo),p(PE),p(IE),p(jE),p(NE),p(DE),d&&r(tCe),d&&r(qi),p(GE),d&&r(rCe),d&&r(Qo),p(OE),p(zE),p(XE),p(WE),p(VE),d&&r(aCe),d&&r(Wi),p(QE),d&&r(nCe),d&&r(Ho),p(HE),p(JE),p(KE),p(YE),p(ZE),d&&r(sCe),d&&r(Hi),p(eC),d&&r(lCe),d&&r(Uo),p(oC),p(rC),p(aC),p(nC),p(sC),d&&r(iCe),d&&r(Yi),p(lC),d&&r(dCe),d&&r(Jo),p(iC),p(mC),p(fC),p(cC),p(gC),d&&r(mCe),d&&r(od),p(hC),d&&r(fCe),d&&r(Ko),p(uC),p(_C),p(vC),p(bC),p(FC),d&&r(cCe),d&&r(ad),p(MC),d&&r(gCe),d&&r(Yo),p(EC),p(yC),p(wC),p(AC),p(xC),d&&r(hCe),d&&r(id),p(LC),d&&r(uCe),d&&r(Zo),p(BC),p(RC),p(SC),p(PC),p($C),d&&r(pCe),d&&r(fd),p(IC),d&&r(_Ce),d&&r(et),p(jC),p(DC),p(GC),p(OC),p(qC),d&&r(vCe),d&&r(hd),p(zC),d&&r(bCe),d&&r(ot),p(XC),p(VC),p(QC),p(HC),p(UC),d&&r(TCe),d&&r(_d),p(JC),d&&r(FCe),d&&r(tt),p(KC),p(ZC),p(e3),p(o3),p(t3),d&&r(MCe),d&&r(Td),p(r3),d&&r(ECe),d&&r(rt),p(a3),p(s3),p(l3),p(i3),p(d3),d&&r(CCe),d&&r(Ed),p(m3),d&&r(yCe),d&&r(at),p(f3),p(g3),p(h3),p(u3),p(p3),d&&r(wCe),d&&r(wd),p(_3),d&&r(ACe),d&&r(nt),p(v3),p(T3),p(F3),p(M3),p(E3),d&&r(xCe),d&&r(Ld),p(C3),d&&r(LCe),d&&r(st),p(y3),p(A3),p(x3),p(L3),p(B3),d&&r(BCe),d&&r(Rd),p(k3),d&&r(kCe),d&&r(lt),p(R3),p(P3),p($3),p(I3),p(j3),d&&r(RCe),d&&r($d),p(N3),d&&r(SCe),d&&r(it),p(D3),p(O3),p(q3),p(z3),p(X3),d&&r(PCe),d&&r(Nd),p(W3),d&&r($Ce),d&&r(dt),p(V3),p(H3),p(U3),p(J3),p(K3),d&&r(ICe),d&&r(Od),p(Y3),d&&r(jCe),d&&r(mt),p(Z3),p(oy),p(ty),p(ry),p(ay),d&&r(NCe),d&&r(Xd),p(ny),d&&r(DCe),d&&r(ft),p(sy),p(iy),p(dy),p(my),p(fy),d&&r(GCe),d&&r(Qd),p(cy),d&&r(OCe),d&&r(ct),p(gy),p(uy),p(py),p(_y),p(vy),d&&r(qCe),d&&r(Jd),p(by),d&&r(zCe),d&&r(gt),p(Ty),p(My),p(Ey),p(Cy),p(yy),d&&r(XCe),d&&r(em),p(wy),d&&r(WCe),d&&r(ht),p(Ay),p(Ly),p(By),p(ky),p(Ry),d&&r(VCe),d&&r(rm),p(Sy),d&&r(QCe),d&&r(ut),p(Py),p(Iy),p(jy),p(Ny),p(Dy),d&&r(HCe),d&&r(sm),p(Gy),d&&r(UCe),d&&r(pt),p(Oy),p(zy),p(Xy),p(Wy),p(Vy),d&&r(JCe),d&&r(dm),p(Qy),d&&r(KCe),d&&r(_t),p(Hy),p(Jy),p(Ky),p(Yy),p(Zy),d&&r(YCe),d&&r(cm),p(ew),d&&r(ZCe),d&&r(vt),p(ow),p(rw),p(aw),p(nw),p(sw),d&&r(e3e),d&&r(um),p(lw),d&&r(o3e),d&&r(bt),p(iw),p(mw),p(fw),p(cw),p(gw),d&&r(t3e),d&&r(vm),p(hw),d&&r(r3e),d&&r(Ft),p(uw),p(_w),p(vw),p(bw),p(Tw),d&&r(a3e),d&&r(Fm),p(Fw),d&&r(n3e),d&&r(Et),p(Mw),p(Cw),p(yw),p(ww),p(Aw),d&&r(s3e),d&&r(Cm),p(xw),d&&r(l3e),d&&r(Ct),p(Lw),p(kw),p(Rw),p(Sw),p($w),d&&r(i3e),d&&r(Am),p(Iw),d&&r(d3e),d&&r(yt),p(jw),p(Dw),p(Gw),p(Ow),p(qw)}}}const VVt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function QVt(Wl,J,ye){let{fw:se}=J;return Wl.$$set=de=>{"fw"in de&&ye(0,se=de.fw)},[se]}class eQt extends NVt{constructor(J){super();DVt(this,J,QVt,WVt,GVt,{fw:0})}}export{eQt as default,VVt as metadata};
