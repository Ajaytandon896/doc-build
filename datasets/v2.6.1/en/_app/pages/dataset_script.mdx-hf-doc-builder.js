import{S as oi,i as li,s as ri,e as s,k as d,w as g,t as n,M as ni,c as o,d as a,m as u,a as l,x as _,h as i,b as f,G as e,g as p,y as w,q as v,o as q,B as y,v as ii}from"../chunks/vendor-hf-doc-builder.js";import{T as Ks}from"../chunks/Tip-hf-doc-builder.js";import{I as mt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as S}from"../chunks/CodeBlock-hf-doc-builder.js";function pi(I){let h,$,c,m,k;return{c(){h=s("p"),$=n(`The dataset script is optional if your dataset is in one of the following formats: CSV, JSON, JSON lines, text or Parquet.
With those formats, you should be able to load your dataset automatically with `),c=s("a"),m=n("load_dataset()"),k=n("."),this.h()},l(E){h=o(E,"P",{});var b=l(h);$=i(b,`The dataset script is optional if your dataset is in one of the following formats: CSV, JSON, JSON lines, text or Parquet.
With those formats, you should be able to load your dataset automatically with `),c=o(b,"A",{href:!0});var D=l(c);m=i(D,"load_dataset()"),D.forEach(a),k=i(b,"."),b.forEach(a),this.h()},h(){f(c,"href","/docs/datasets/v2.6.1/en/package_reference/loading_methods#datasets.load_dataset")},m(E,b){p(E,h,b),e(h,$),e(h,c),e(c,m),e(h,k)},d(E){E&&a(h)}}}function di(I){let h,$,c,m,k;return{c(){h=s("p"),$=n("To help you get started, try beginning with the dataset loading script "),c=s("a"),m=n("template"),k=n("!"),this.h()},l(E){h=o(E,"P",{});var b=l(h);$=i(b,"To help you get started, try beginning with the dataset loading script "),c=o(b,"A",{href:!0,rel:!0});var D=l(c);m=i(D,"template"),D.forEach(a),k=i(b,"!"),b.forEach(a),this.h()},h(){f(c,"href","https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py"),f(c,"rel","nofollow")},m(E,b){p(E,h,b),e(h,$),e(h,c),e(c,m),e(h,k)},d(E){E&&a(h)}}}function ui(I){let h,$;return{c(){h=s("p"),$=n("Only use a default configuration when it makes sense. Don\u2019t set one because it may be more convenient for the user to not specify a configuration when they load your dataset. For example, multi-lingual datasets often have a separate configuration for each language. An appropriate default may be an aggregated configuration that loads all the languages of the dataset if the user doesn\u2019t request a particular one.")},l(c){h=o(c,"P",{});var m=l(h);$=i(m,"Only use a default configuration when it makes sense. Don\u2019t set one because it may be more convenient for the user to not specify a configuration when they load your dataset. For example, multi-lingual datasets often have a separate configuration for each language. An appropriate default may be an aggregated configuration that loads all the languages of the dataset if the user doesn\u2019t request a particular one."),m.forEach(a)},m(c,m){p(c,h,m),e(h,$)},d(c){c&&a(h)}}}function fi(I){let h,$;return{c(){h=s("p"),$=n("If the data files live in the same folder or repository of the dataset script, you can just pass the relative paths to the files instead of URLs.")},l(c){h=o(c,"P",{});var m=l(h);$=i(m,"If the data files live in the same folder or repository of the dataset script, you can just pass the relative paths to the files instead of URLs."),m.forEach(a)},m(c,m){p(c,h,m),e(h,$)},d(c){c&&a(h)}}}function hi(I){let h,$,c,m,k,E,b,D,Zs,Oa,Y,xa,Xt,to,Ca,Jt,eo,La,O,ao,Ee,so,oo,be,lo,ro,Ta,gt,Na,_t,Pa,Wt,no,Ga,j,je,io,po,ke,uo,fo,Ae,ho,co,Se,mo,go,De,_o,Ra,X,wo,wt,vo,qo,Ua,J,Ba,U,W,Ie,vt,yo,Oe,$o,Va,K,Eo,xe,bo,jo,Fa,Z,Ce,Kt,Le,ko,Ao,So,Te,tt,Ne,Do,Io,Zt,Oo,xo,Ma,qt,za,B,Pe,te,Ge,Co,Lo,To,Re,ee,Ue,No,Po,Ha,ae,Go,Qa,yt,Ya,V,et,Be,$t,Ro,Ve,Uo,Xa,x,Bo,Et,Vo,Fo,se,Mo,zo,Ja,at,Ho,bt,Qo,Yo,Wa,oe,jt,Xo,le,Jo,Wo,Ka,kt,Za,At,St,Ko,Fe,Zo,tl,ts,Dt,es,It,Ot,el,Me,al,sl,as,xt,ss,F,st,ze,Ct,ol,He,ll,os,C,rl,Qe,nl,il,Ye,pl,dl,ls,Lt,rs,ot,ns,M,lt,Xe,Tt,ul,Je,fl,is,re,hl,ps,ne,We,cl,ds,Nt,us,rt,fs,Pt,Gt,nt,ie,ml,gl,pe,_l,wl,vl,Rt,Ke,A,ql,Ze,yl,$l,ta,El,bl,ea,jl,kl,aa,Al,Sl,Dl,sa,de,oa,Il,Ol,hs,it,xl,la,Cl,Ll,cs,Ut,ms,z,pt,ra,Bt,Tl,na,Nl,gs,ue,Pl,_s,L,ia,Gl,Rl,pa,Ul,Bl,da,Vl,ws,fe,Fl,vs,dt,ua,ut,fa,Ml,zl,ha,Hl,Ql,Yl,ca,Vt,Xl,ma,Jl,Wl,qs,Ft,ys,H,ft,ga,Mt,Kl,_a,Zl,$s,T,tr,wa,er,ar,va,sr,or,Es,ht,lr,qa,rr,nr,bs,zt,js,N,ir,ya,pr,dr,$a,ur,fr,ks,Q,ct,Ea,Ht,hr,ba,cr,As,P,mr,he,gr,_r,ce,wr,vr,Ss,me,qr,Ds,Qt,Is;return E=new mt({}),Y=new Ks({props:{$$slots:{default:[pi]},$$scope:{ctx:I}}}),gt=new S({props:{code:`my_dataset/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 my_dataset.py`,highlighted:`my<span class="hljs-emphasis">_dataset/
\u251C\u2500\u2500 README.md
\u2514\u2500\u2500 my_</span>dataset.py`}}),_t=new S({props:{code:`from datasets import load_dataset
load_dataset("path/to/my_dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>load_dataset(<span class="hljs-string">&quot;path/to/my_dataset&quot;</span>)`}}),J=new Ks({props:{$$slots:{default:[di]},$$scope:{ctx:I}}}),vt=new mt({}),qt=new S({props:{code:`datasets.Features(
    {
        "id": datasets.Value("string"),
        "title": datasets.Value("string"),
        "context": datasets.Value("string"),
        "question": datasets.Value("string"),
        "answers": datasets.Sequence(
            {
                "text": datasets.Value("string"),
                "answer_start": datasets.Value("int32"),
            }
        ),
    }
)`,highlighted:`datasets.Features(
    {
        <span class="hljs-string">&quot;id&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
        <span class="hljs-string">&quot;title&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
        <span class="hljs-string">&quot;context&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
        <span class="hljs-string">&quot;question&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
        <span class="hljs-string">&quot;answers&quot;</span>: datasets.<span class="hljs-type">Sequence</span>(
            {
                <span class="hljs-string">&quot;text&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;answer_start&quot;</span>: datasets.Value(<span class="hljs-string">&quot;int32&quot;</span>),
            }
        ),
    }
)`}}),yt=new S({props:{code:`def _info(self):
    return datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                "id": datasets.Value("string"),
                "title": datasets.Value("string"),
                "context": datasets.Value("string"),
                "question": datasets.Value("string"),
                "answers": datasets.features.Sequence(
                    {"text": datasets.Value("string"), "answer_start": datasets.Value("int32"),}
                ),
            }
        ),
        # No default supervised_keys (as we have to pass both question
        # and context as input).
        supervised_keys=None,
        homepage="https://rajpurkar.github.io/SQuAD-explorer/",
        citation=_CITATION,
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_info</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">return</span> datasets.DatasetInfo(
        description=_DESCRIPTION,
        features=datasets.Features(
            {
                <span class="hljs-string">&quot;id&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;title&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;context&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;question&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),
                <span class="hljs-string">&quot;answers&quot;</span>: datasets.features.<span class="hljs-type">Sequence</span>(
                    {<span class="hljs-string">&quot;text&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>), <span class="hljs-string">&quot;answer_start&quot;</span>: datasets.Value(<span class="hljs-string">&quot;int32&quot;</span>),}
                ),
            }
        ),
        <span class="hljs-comment"># No default supervised_keys (as we have to pass both question</span>
        <span class="hljs-comment"># and context as input).</span>
        supervised_keys=<span class="hljs-literal">None</span>,
        homepage=<span class="hljs-string">&quot;https://rajpurkar.github.io/SQuAD-explorer/&quot;</span>,
        citation=_CITATION,
    )`}}),$t=new mt({}),kt=new S({props:{code:`class SuperGlueConfig(datasets.BuilderConfig):
    """BuilderConfig for SuperGLUE."""

    def __init__(self, features, data_url, citation, url, label_classes=("False", "True"), **kwargs):
        """BuilderConfig for SuperGLUE.

        Args:
        features: *list[string]*, list of the features that will appear in the
            feature dict. Should not include "label".
        data_url: *string*, url to download the zip file from.
        citation: *string*, citation for the data set.
        url: *string*, url for information about the data set.
        label_classes: *list[string]*, the list of classes for the label if the
            label is present as a string. Non-string labels will be cast to either
            'False' or 'True'.
        **kwargs: keyword arguments forwarded to super.
        """
        # Version history:
        # 1.0.2: Fixed non-nondeterminism in ReCoRD.
        # 1.0.1: Change from the pre-release trial version of SuperGLUE (v1.9) to
        #        the full release (v2.0).
        # 1.0.0: S3 (new shuffling, sharding and slicing mechanism).
        # 0.0.2: Initial version.
        super().__init__(version=datasets.Version("1.0.2"), **kwargs)
        self.features = features
        self.label_classes = label_classes
        self.data_url = data_url
        self.citation = citation
        self.url = url`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">SuperGlueConfig</span>(datasets.BuilderConfig):
    <span class="hljs-string">&quot;&quot;&quot;BuilderConfig for SuperGLUE.&quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, features, data_url, citation, url, label_classes=(<span class="hljs-params"><span class="hljs-string">&quot;False&quot;</span>, <span class="hljs-string">&quot;True&quot;</span></span>), **kwargs</span>):
        <span class="hljs-string">&quot;&quot;&quot;BuilderConfig for SuperGLUE.

        Args:
        features: *list[string]*, list of the features that will appear in the
            feature dict. Should not include &quot;label&quot;.
        data_url: *string*, url to download the zip file from.
        citation: *string*, citation for the data set.
        url: *string*, url for information about the data set.
        label_classes: *list[string]*, the list of classes for the label if the
            label is present as a string. Non-string labels will be cast to either
            &#x27;False&#x27; or &#x27;True&#x27;.
        **kwargs: keyword arguments forwarded to super.
        &quot;&quot;&quot;</span>
        <span class="hljs-comment"># Version history:</span>
        <span class="hljs-comment"># 1.0.2: Fixed non-nondeterminism in ReCoRD.</span>
        <span class="hljs-comment"># 1.0.1: Change from the pre-release trial version of SuperGLUE (v1.9) to</span>
        <span class="hljs-comment">#        the full release (v2.0).</span>
        <span class="hljs-comment"># 1.0.0: S3 (new shuffling, sharding and slicing mechanism).</span>
        <span class="hljs-comment"># 0.0.2: Initial version.</span>
        <span class="hljs-built_in">super</span>().__init__(version=datasets.Version(<span class="hljs-string">&quot;1.0.2&quot;</span>), **kwargs)
        self.features = features
        self.label_classes = label_classes
        self.data_url = data_url
        self.citation = citation
        self.url = url`}}),Dt=new S({props:{code:`class SuperGlue(datasets.GeneratorBasedBuilder):
    """The SuperGLUE benchmark."""

    BUILDER_CONFIGS = [
        SuperGlueConfig(
            name="boolq",
            description=_BOOLQ_DESCRIPTION,
            features=["question", "passage"],
            data_url="https://dl.fbaipublicfiles.com/glue/superglue/data/v2/BoolQ.zip",
            citation=_BOOLQ_CITATION,
            url="https://github.com/google-research-datasets/boolean-questions",
        ),
        ...
        ...
        SuperGlueConfig(
            name="axg",
            description=_AXG_DESCRIPTION,
            features=["premise", "hypothesis"],
            label_classes=["entailment", "not_entailment"],
            data_url="https://dl.fbaipublicfiles.com/glue/superglue/data/v2/AX-g.zip",
            citation=_AXG_CITATION,
            url="https://github.com/rudinger/winogender-schemas",
        ),`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">SuperGlue</span>(datasets.GeneratorBasedBuilder):
    <span class="hljs-string">&quot;&quot;&quot;The SuperGLUE benchmark.&quot;&quot;&quot;</span>

    BUILDER_CONFIGS = [
        SuperGlueConfig(
            name=<span class="hljs-string">&quot;boolq&quot;</span>,
            description=_BOOLQ_DESCRIPTION,
            features=[<span class="hljs-string">&quot;question&quot;</span>, <span class="hljs-string">&quot;passage&quot;</span>],
            data_url=<span class="hljs-string">&quot;https://dl.fbaipublicfiles.com/glue/superglue/data/v2/BoolQ.zip&quot;</span>,
            citation=_BOOLQ_CITATION,
            url=<span class="hljs-string">&quot;https://github.com/google-research-datasets/boolean-questions&quot;</span>,
        ),
        ...
        ...
        SuperGlueConfig(
            name=<span class="hljs-string">&quot;axg&quot;</span>,
            description=_AXG_DESCRIPTION,
            features=[<span class="hljs-string">&quot;premise&quot;</span>, <span class="hljs-string">&quot;hypothesis&quot;</span>],
            label_classes=[<span class="hljs-string">&quot;entailment&quot;</span>, <span class="hljs-string">&quot;not_entailment&quot;</span>],
            data_url=<span class="hljs-string">&quot;https://dl.fbaipublicfiles.com/glue/superglue/data/v2/AX-g.zip&quot;</span>,
            citation=_AXG_CITATION,
            url=<span class="hljs-string">&quot;https://github.com/rudinger/winogender-schemas&quot;</span>,
        ),`}}),xt=new S({props:{code:`from datasets import load_dataset
dataset = load_dataset('super_glue', 'boolq')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;super_glue&#x27;</span>, <span class="hljs-string">&#x27;boolq&#x27;</span>)`}}),Ct=new mt({}),Lt=new S({props:{code:`class NewDataset(datasets.GeneratorBasedBuilder):

VERSION = datasets.Version("1.1.0")

BUILDER_CONFIGS = [
    datasets.BuilderConfig(name="first_domain", version=VERSION, description="This part of my dataset covers a first domain"),
    datasets.BuilderConfig(name="second_domain", version=VERSION, description="This part of my dataset covers a second domain"),
]

DEFAULT_CONFIG_NAME = "first_domain"`,highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">NewDataset</span>(datasets.GeneratorBasedBuilder):

VERSION = datasets.Version(<span class="hljs-string">&quot;1.1.0&quot;</span>)

BUILDER_CONFIGS = [
    datasets.BuilderConfig(name=<span class="hljs-string">&quot;first_domain&quot;</span>, version=VERSION, description=<span class="hljs-string">&quot;This part of my dataset covers a first domain&quot;</span>),
    datasets.BuilderConfig(name=<span class="hljs-string">&quot;second_domain&quot;</span>, version=VERSION, description=<span class="hljs-string">&quot;This part of my dataset covers a second domain&quot;</span>),
]

DEFAULT_CONFIG_NAME = <span class="hljs-string">&quot;first_domain&quot;</span>`}}),ot=new Ks({props:{warning:!0,$$slots:{default:[ui]},$$scope:{ctx:I}}}),Tt=new mt({}),Nt=new S({props:{code:`_URL = "https://rajpurkar.github.io/SQuAD-explorer/dataset/"
_URLS = {
    "train": _URL + "train-v1.1.json",
    "dev": _URL + "dev-v1.1.json",
}`,highlighted:`_URL = <span class="hljs-string">&quot;https://rajpurkar.github.io/SQuAD-explorer/dataset/&quot;</span>
_URLS = {
    <span class="hljs-string">&quot;train&quot;</span>: _URL + <span class="hljs-string">&quot;train-v1.1.json&quot;</span>,
    <span class="hljs-string">&quot;dev&quot;</span>: _URL + <span class="hljs-string">&quot;dev-v1.1.json&quot;</span>,
}`}}),rt=new Ks({props:{$$slots:{default:[fi]},$$scope:{ctx:I}}}),Ut=new S({props:{code:`def _split_generators(self, dl_manager: datasets.DownloadManager) -> List[datasets.SplitGenerator]:
    urls_to_download = self._URLS
    downloaded_files = dl_manager.download_and_extract(urls_to_download)

    return [
        datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={"filepath": downloaded_files["train"]}),
        datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={"filepath": downloaded_files["dev"]}),
    ]`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager: datasets.DownloadManager</span>) -&gt; <span class="hljs-type">List</span>[datasets.SplitGenerator]:
    urls_to_download = self._URLS
    downloaded_files = dl_manager.download_and_extract(urls_to_download)

    <span class="hljs-keyword">return</span> [
        datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={<span class="hljs-string">&quot;filepath&quot;</span>: downloaded_files[<span class="hljs-string">&quot;train&quot;</span>]}),
        datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={<span class="hljs-string">&quot;filepath&quot;</span>: downloaded_files[<span class="hljs-string">&quot;dev&quot;</span>]}),
    ]`}}),Bt=new mt({}),Ft=new S({props:{code:`def _generate_examples(self, filepath):
    """This function returns the examples in the raw (text) form."""
    logger.info("generating examples from = %s", filepath)
    with open(filepath) as f:
        squad = json.load(f)
        for article in squad["data"]:
            title = article.get("title", "").strip()
            for paragraph in article["paragraphs"]:
                context = paragraph["context"].strip()
                for qa in paragraph["qas"]:
                    question = qa["question"].strip()
                    id_ = qa["id"]

                    answer_starts = [answer["answer_start"] for answer in qa["answers"]]
                    answers = [answer["text"].strip() for answer in qa["answers"]]

                    # Features currently used are "context", "question", and "answers".
                    # Others are extracted here for the ease of future expansions.
                    yield id_, {
                        "title": title,
                        "context": context,
                        "question": question,
                        "id": id_,
                        "answers": {"answer_start": answer_starts, "text": answers,},
                    }`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">self, filepath</span>):
    <span class="hljs-string">&quot;&quot;&quot;This function returns the examples in the raw (text) form.&quot;&quot;&quot;</span>
    logger.info(<span class="hljs-string">&quot;generating examples from = %s&quot;</span>, filepath)
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath) <span class="hljs-keyword">as</span> f:
        squad = json.load(f)
        <span class="hljs-keyword">for</span> article <span class="hljs-keyword">in</span> squad[<span class="hljs-string">&quot;data&quot;</span>]:
            title = article.get(<span class="hljs-string">&quot;title&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).strip()
            <span class="hljs-keyword">for</span> paragraph <span class="hljs-keyword">in</span> article[<span class="hljs-string">&quot;paragraphs&quot;</span>]:
                context = paragraph[<span class="hljs-string">&quot;context&quot;</span>].strip()
                <span class="hljs-keyword">for</span> qa <span class="hljs-keyword">in</span> paragraph[<span class="hljs-string">&quot;qas&quot;</span>]:
                    question = qa[<span class="hljs-string">&quot;question&quot;</span>].strip()
                    id_ = qa[<span class="hljs-string">&quot;id&quot;</span>]

                    answer_starts = [answer[<span class="hljs-string">&quot;answer_start&quot;</span>] <span class="hljs-keyword">for</span> answer <span class="hljs-keyword">in</span> qa[<span class="hljs-string">&quot;answers&quot;</span>]]
                    answers = [answer[<span class="hljs-string">&quot;text&quot;</span>].strip() <span class="hljs-keyword">for</span> answer <span class="hljs-keyword">in</span> qa[<span class="hljs-string">&quot;answers&quot;</span>]]

                    <span class="hljs-comment"># Features currently used are &quot;context&quot;, &quot;question&quot;, and &quot;answers&quot;.</span>
                    <span class="hljs-comment"># Others are extracted here for the ease of future expansions.</span>
                    <span class="hljs-keyword">yield</span> id_, {
                        <span class="hljs-string">&quot;title&quot;</span>: title,
                        <span class="hljs-string">&quot;context&quot;</span>: context,
                        <span class="hljs-string">&quot;question&quot;</span>: question,
                        <span class="hljs-string">&quot;id&quot;</span>: id_,
                        <span class="hljs-string">&quot;answers&quot;</span>: {<span class="hljs-string">&quot;answer_start&quot;</span>: answer_starts, <span class="hljs-string">&quot;text&quot;</span>: answers,},
                    }`}}),Mt=new mt({}),zt=new S({props:{code:"datasets-cli test path/to/<your-dataset-loading-script> --save_info --all_configs",highlighted:'datasets-cli test path/<span class="hljs-keyword">to</span>/&lt;your-dataset-loading-<span class="hljs-keyword">script</span>&gt; <span class="hljs-comment">--save_info --all_configs</span>'}}),Ht=new mt({}),Qt=new S({props:{code:`from datasets import load_dataset
load_dataset("<username>/my_dataset")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)`}}),{c(){h=s("meta"),$=d(),c=s("h1"),m=s("a"),k=s("span"),g(E.$$.fragment),b=d(),D=s("span"),Zs=n("Create a dataset loading script"),Oa=d(),g(Y.$$.fragment),xa=d(),Xt=s("p"),to=n("Write a dataset script to load and share your own datasets. It is a Python file that defines the different configurations and splits of your dataset, as well as how to download and process the data."),Ca=d(),Jt=s("p"),eo=n("The script can download data files from any website, or from the same dataset repository."),La=d(),O=s("p"),ao=n("Any dataset script, for example "),Ee=s("code"),so=n("my_dataset.py"),oo=n(", can be placed in a folder or a repository named "),be=s("code"),lo=n("my_dataset"),ro=n(" and be loaded with:"),Ta=d(),g(gt.$$.fragment),Na=d(),g(_t.$$.fragment),Pa=d(),Wt=s("p"),no=n("The following guide includes instructions for dataset scripts for how to:"),Ga=d(),j=s("ul"),je=s("li"),io=n("Add dataset metadata."),po=d(),ke=s("li"),uo=n("Download data files."),fo=d(),Ae=s("li"),ho=n("Generate samples."),co=d(),Se=s("li"),mo=n("Generate dataset metadata."),go=d(),De=s("li"),_o=n("Upload a dataset to the Hub."),Ra=d(),X=s("p"),wo=n("Open the "),wt=s("a"),vo=n("SQuAD dataset loading script"),qo=n(" template to follow along on how to share a dataset."),Ua=d(),g(J.$$.fragment),Ba=d(),U=s("h2"),W=s("a"),Ie=s("span"),g(vt.$$.fragment),yo=d(),Oe=s("span"),$o=n("Add dataset attributes"),Va=d(),K=s("p"),Eo=n("The first step is to add some information, or attributes, about your dataset in "),xe=s("code"),bo=n("DatasetBuilder._info()"),jo=n(". The most important attributes you should specify are:"),Fa=d(),Z=s("ol"),Ce=s("li"),Kt=s("p"),Le=s("code"),ko=n("DatasetInfo.description"),Ao=n(" provides a concise description of your dataset. The description informs the user what\u2019s in the dataset, how it was collected, and how it can be used for a NLP task."),So=d(),Te=s("li"),tt=s("p"),Ne=s("code"),Do=n("DatasetInfo.features"),Io=n(" defines the name and type of each column in your dataset. This will also provide the structure for each example, so it is possible to create nested subfields in a column if you want. Take a look at "),Zt=s("a"),Oo=n("Features"),xo=n(" for a full list of feature types you can use."),Ma=d(),g(qt.$$.fragment),za=d(),B=s("ol"),Pe=s("li"),te=s("p"),Ge=s("code"),Co=n("DatasetInfo.homepage"),Lo=n(" contains the URL to the dataset homepage so users can find more details about the dataset."),To=d(),Re=s("li"),ee=s("p"),Ue=s("code"),No=n("DatasetInfo.citation"),Po=n(" contains a BibTeX citation for the dataset."),Ha=d(),ae=s("p"),Go=n("After you\u2019ve filled out all these fields in the template, it should look like the following example from the SQuAD loading script:"),Qa=d(),g(yt.$$.fragment),Ya=d(),V=s("h3"),et=s("a"),Be=s("span"),g($t.$$.fragment),Ro=d(),Ve=s("span"),Uo=n("Multiple configurations"),Xa=d(),x=s("p"),Bo=n("In some cases, your dataset may have multiple configurations. For example, the "),Et=s("a"),Vo=n("SuperGLUE"),Fo=n(" dataset is a collection of 5 datasets designed to evaluate language understanding tasks. \u{1F917} Datasets provides "),se=s("a"),Mo=n("BuilderConfig"),zo=n(" which allows you to create different configurations for the user to select from."),Ja=d(),at=s("p"),Ho=n("Let\u2019s study the "),bt=s("a"),Qo=n("SuperGLUE loading script"),Yo=n(" to see how you can define several configurations."),Wa=d(),oe=s("ol"),jt=s("li"),Xo=n("Create a "),le=s("a"),Jo=n("BuilderConfig"),Wo=n(" subclass with attributes about your dataset. These attributes can be the features of your dataset, label classes, and a URL to the data files."),Ka=d(),g(kt.$$.fragment),Za=d(),At=s("ol"),St=s("li"),Ko=n("Create instances of your config to specify the values of the attributes of each configuration. This gives you the flexibility to specify all the name and description of each configuration. These sub-class instances should be listed under "),Fe=s("code"),Zo=n("DatasetBuilder.BUILDER_CONFIGS"),tl=n(":"),ts=d(),g(Dt.$$.fragment),es=d(),It=s("ol"),Ot=s("li"),el=n("Now, users can load a specific configuration of the dataset with the configuration "),Me=s("code"),al=n("name"),sl=n(":"),as=d(),g(xt.$$.fragment),ss=d(),F=s("h3"),st=s("a"),ze=s("span"),g(Ct.$$.fragment),ol=d(),He=s("span"),ll=n("Default configurations"),os=d(),C=s("p"),rl=n("Users must specify a configuration name when they load a dataset with multiple configurations. Otherwise, \u{1F917} Datasets will raise a "),Qe=s("code"),nl=n("ValueError"),il=n(", and prompt the user to select a configuration name. You can avoid this by setting a default dataset configuration with the "),Ye=s("code"),pl=n("DEFAULT_CONFIG_NAME"),dl=n(" attribute:"),ls=d(),g(Lt.$$.fragment),rs=d(),g(ot.$$.fragment),ns=d(),M=s("h2"),lt=s("a"),Xe=s("span"),g(Tt.$$.fragment),ul=d(),Je=s("span"),fl=n("Download data files and organize splits"),is=d(),re=s("p"),hl=n("After you\u2019ve defined the attributes of your dataset, the next step is to download the data files and organize them according to their splits."),ps=d(),ne=s("ol"),We=s("li"),cl=n("Create a dictionary of URLs in the loading script that point to the original SQuAD data files:"),ds=d(),g(Nt.$$.fragment),us=d(),g(rt.$$.fragment),fs=d(),Pt=s("ol"),Gt=s("li"),nt=s("p"),ie=s("a"),ml=n("DownloadManager.download_and_extract()"),gl=n(" takes this dictionary and downloads the data files. Once the files are downloaded, use "),pe=s("a"),_l=n("SplitGenerator"),wl=n(" to organize each split in the dataset. This is a simple class that contains:"),vl=d(),Rt=s("ul"),Ke=s("li"),A=s("p"),ql=n("The "),Ze=s("code"),yl=n("name"),$l=n(" of each split. You should use the standard split names: "),ta=s("code"),El=n("Split.TRAIN"),bl=n(", "),ea=s("code"),jl=n("Split.TEST"),kl=n(", and "),aa=s("code"),Al=n("Split.VALIDATION"),Sl=n("."),Dl=d(),sa=s("li"),de=s("p"),oa=s("code"),Il=n("gen_kwargs"),Ol=n(" provides the file paths to the data files to load for each split."),hs=d(),it=s("p"),xl=n("Your "),la=s("code"),Cl=n("DatasetBuilder._split_generator()"),Ll=n(" should look like this now:"),cs=d(),g(Ut.$$.fragment),ms=d(),z=s("h2"),pt=s("a"),ra=s("span"),g(Bt.$$.fragment),Tl=d(),na=s("span"),Nl=n("Generate samples"),gs=d(),ue=s("p"),Pl=n("At this point, you have:"),_s=d(),L=s("ul"),ia=s("li"),Gl=n("Added the dataset attributes."),Rl=d(),pa=s("li"),Ul=n("Provided instructions for how to download the data files."),Bl=d(),da=s("li"),Vl=n("Organized the splits."),ws=d(),fe=s("p"),Fl=n("The next step is to actually generate the samples in each split."),vs=d(),dt=s("ol"),ua=s("li"),ut=s("p"),fa=s("code"),Ml=n("DatasetBuilder._generate_examples"),zl=n(" takes the file path provided by "),ha=s("code"),Hl=n("gen_kwargs"),Ql=n(" to read and parse the data files. You need to write a function that loads the data files and extracts the columns."),Yl=d(),ca=s("li"),Vt=s("p"),Xl=n("Your function should yield a tuple of an "),ma=s("code"),Jl=n("id_"),Wl=n(", and an example from the dataset."),qs=d(),g(Ft.$$.fragment),ys=d(),H=s("h2"),ft=s("a"),ga=s("span"),g(Mt.$$.fragment),Kl=d(),_a=s("span"),Zl=n("(Optional) Generate dataset metadata"),$s=d(),T=s("p"),tr=n("Adding dataset metadata is a great way to include information about your dataset. The metadata is stored in the dataset card "),wa=s("code"),er=n("README.md"),ar=n(" in YAML. It includes information like the number of examples required to confirm the dataset was correctly generated, and information about the dataset like its "),va=s("code"),sr=n("features"),or=n("."),Es=d(),ht=s("p"),lr=n("Run the following command to generate your dataset metadata in "),qa=s("code"),rr=n("README.md"),nr=n(" and make sure your new dataset loading script works correctly:"),bs=d(),g(zt.$$.fragment),js=d(),N=s("p"),ir=n("If your dataset loading script passed the test, you should now have a "),ya=s("code"),pr=n("README.md"),dr=n(" file in your dataset folder containing a "),$a=s("code"),ur=n("dataset_info"),fr=n(" field with some metadata."),ks=d(),Q=s("h2"),ct=s("a"),Ea=s("span"),g(Ht.$$.fragment),hr=d(),ba=s("span"),cr=n("Upload to the Hub"),As=d(),P=s("p"),mr=n("Once your script is ready, "),he=s("a"),gr=n("create a dataset card"),_r=n(" and "),ce=s("a"),wr=n("upload it to the Hub"),vr=n("."),Ss=d(),me=s("p"),qr=n("Congratulations, you can now load your dataset from the Hub! \u{1F973}"),Ds=d(),g(Qt.$$.fragment),this.h()},l(t){const r=ni('[data-svelte="svelte-1phssyn"]',document.head);h=o(r,"META",{name:!0,content:!0}),r.forEach(a),$=u(t),c=o(t,"H1",{class:!0});var Yt=l(c);m=o(Yt,"A",{id:!0,class:!0,href:!0});var ja=l(m);k=o(ja,"SPAN",{});var ka=l(k);_(E.$$.fragment,ka),ka.forEach(a),ja.forEach(a),b=u(Yt),D=o(Yt,"SPAN",{});var Aa=l(D);Zs=i(Aa,"Create a dataset loading script"),Aa.forEach(a),Yt.forEach(a),Oa=u(t),_(Y.$$.fragment,t),xa=u(t),Xt=o(t,"P",{});var jr=l(Xt);to=i(jr,"Write a dataset script to load and share your own datasets. It is a Python file that defines the different configurations and splits of your dataset, as well as how to download and process the data."),jr.forEach(a),Ca=u(t),Jt=o(t,"P",{});var kr=l(Jt);eo=i(kr,"The script can download data files from any website, or from the same dataset repository."),kr.forEach(a),La=u(t),O=o(t,"P",{});var ge=l(O);ao=i(ge,"Any dataset script, for example "),Ee=o(ge,"CODE",{});var Ar=l(Ee);so=i(Ar,"my_dataset.py"),Ar.forEach(a),oo=i(ge,", can be placed in a folder or a repository named "),be=o(ge,"CODE",{});var Sr=l(be);lo=i(Sr,"my_dataset"),Sr.forEach(a),ro=i(ge," and be loaded with:"),ge.forEach(a),Ta=u(t),_(gt.$$.fragment,t),Na=u(t),_(_t.$$.fragment,t),Pa=u(t),Wt=o(t,"P",{});var Dr=l(Wt);no=i(Dr,"The following guide includes instructions for dataset scripts for how to:"),Dr.forEach(a),Ga=u(t),j=o(t,"UL",{});var G=l(j);je=o(G,"LI",{});var Ir=l(je);io=i(Ir,"Add dataset metadata."),Ir.forEach(a),po=u(G),ke=o(G,"LI",{});var Or=l(ke);uo=i(Or,"Download data files."),Or.forEach(a),fo=u(G),Ae=o(G,"LI",{});var xr=l(Ae);ho=i(xr,"Generate samples."),xr.forEach(a),co=u(G),Se=o(G,"LI",{});var Cr=l(Se);mo=i(Cr,"Generate dataset metadata."),Cr.forEach(a),go=u(G),De=o(G,"LI",{});var Lr=l(De);_o=i(Lr,"Upload a dataset to the Hub."),Lr.forEach(a),G.forEach(a),Ra=u(t),X=o(t,"P",{});var Os=l(X);wo=i(Os,"Open the "),wt=o(Os,"A",{href:!0,rel:!0});var Tr=l(wt);vo=i(Tr,"SQuAD dataset loading script"),Tr.forEach(a),qo=i(Os," template to follow along on how to share a dataset."),Os.forEach(a),Ua=u(t),_(J.$$.fragment,t),Ba=u(t),U=o(t,"H2",{class:!0});var xs=l(U);W=o(xs,"A",{id:!0,class:!0,href:!0});var Nr=l(W);Ie=o(Nr,"SPAN",{});var Pr=l(Ie);_(vt.$$.fragment,Pr),Pr.forEach(a),Nr.forEach(a),yo=u(xs),Oe=o(xs,"SPAN",{});var Gr=l(Oe);$o=i(Gr,"Add dataset attributes"),Gr.forEach(a),xs.forEach(a),Va=u(t),K=o(t,"P",{});var Cs=l(K);Eo=i(Cs,"The first step is to add some information, or attributes, about your dataset in "),xe=o(Cs,"CODE",{});var Rr=l(xe);bo=i(Rr,"DatasetBuilder._info()"),Rr.forEach(a),jo=i(Cs,". The most important attributes you should specify are:"),Cs.forEach(a),Fa=u(t),Z=o(t,"OL",{});var Ls=l(Z);Ce=o(Ls,"LI",{});var Ur=l(Ce);Kt=o(Ur,"P",{});var yr=l(Kt);Le=o(yr,"CODE",{});var Br=l(Le);ko=i(Br,"DatasetInfo.description"),Br.forEach(a),Ao=i(yr," provides a concise description of your dataset. The description informs the user what\u2019s in the dataset, how it was collected, and how it can be used for a NLP task."),yr.forEach(a),Ur.forEach(a),So=u(Ls),Te=o(Ls,"LI",{});var Vr=l(Te);tt=o(Vr,"P",{});var Sa=l(tt);Ne=o(Sa,"CODE",{});var Fr=l(Ne);Do=i(Fr,"DatasetInfo.features"),Fr.forEach(a),Io=i(Sa," defines the name and type of each column in your dataset. This will also provide the structure for each example, so it is possible to create nested subfields in a column if you want. Take a look at "),Zt=o(Sa,"A",{href:!0});var Mr=l(Zt);Oo=i(Mr,"Features"),Mr.forEach(a),xo=i(Sa," for a full list of feature types you can use."),Sa.forEach(a),Vr.forEach(a),Ls.forEach(a),Ma=u(t),_(qt.$$.fragment,t),za=u(t),B=o(t,"OL",{start:!0});var Ts=l(B);Pe=o(Ts,"LI",{});var zr=l(Pe);te=o(zr,"P",{});var $r=l(te);Ge=o($r,"CODE",{});var Hr=l(Ge);Co=i(Hr,"DatasetInfo.homepage"),Hr.forEach(a),Lo=i($r," contains the URL to the dataset homepage so users can find more details about the dataset."),$r.forEach(a),zr.forEach(a),To=u(Ts),Re=o(Ts,"LI",{});var Qr=l(Re);ee=o(Qr,"P",{});var Er=l(ee);Ue=o(Er,"CODE",{});var Yr=l(Ue);No=i(Yr,"DatasetInfo.citation"),Yr.forEach(a),Po=i(Er," contains a BibTeX citation for the dataset."),Er.forEach(a),Qr.forEach(a),Ts.forEach(a),Ha=u(t),ae=o(t,"P",{});var Xr=l(ae);Go=i(Xr,"After you\u2019ve filled out all these fields in the template, it should look like the following example from the SQuAD loading script:"),Xr.forEach(a),Qa=u(t),_(yt.$$.fragment,t),Ya=u(t),V=o(t,"H3",{class:!0});var Ns=l(V);et=o(Ns,"A",{id:!0,class:!0,href:!0});var Jr=l(et);Be=o(Jr,"SPAN",{});var Wr=l(Be);_($t.$$.fragment,Wr),Wr.forEach(a),Jr.forEach(a),Ro=u(Ns),Ve=o(Ns,"SPAN",{});var Kr=l(Ve);Uo=i(Kr,"Multiple configurations"),Kr.forEach(a),Ns.forEach(a),Xa=u(t),x=o(t,"P",{});var _e=l(x);Bo=i(_e,"In some cases, your dataset may have multiple configurations. For example, the "),Et=o(_e,"A",{href:!0,rel:!0});var Zr=l(Et);Vo=i(Zr,"SuperGLUE"),Zr.forEach(a),Fo=i(_e," dataset is a collection of 5 datasets designed to evaluate language understanding tasks. \u{1F917} Datasets provides "),se=o(_e,"A",{href:!0});var tn=l(se);Mo=i(tn,"BuilderConfig"),tn.forEach(a),zo=i(_e," which allows you to create different configurations for the user to select from."),_e.forEach(a),Ja=u(t),at=o(t,"P",{});var Ps=l(at);Ho=i(Ps,"Let\u2019s study the "),bt=o(Ps,"A",{href:!0,rel:!0});var en=l(bt);Qo=i(en,"SuperGLUE loading script"),en.forEach(a),Yo=i(Ps," to see how you can define several configurations."),Ps.forEach(a),Wa=u(t),oe=o(t,"OL",{});var an=l(oe);jt=o(an,"LI",{});var Gs=l(jt);Xo=i(Gs,"Create a "),le=o(Gs,"A",{href:!0});var sn=l(le);Jo=i(sn,"BuilderConfig"),sn.forEach(a),Wo=i(Gs," subclass with attributes about your dataset. These attributes can be the features of your dataset, label classes, and a URL to the data files."),Gs.forEach(a),an.forEach(a),Ka=u(t),_(kt.$$.fragment,t),Za=u(t),At=o(t,"OL",{start:!0});var on=l(At);St=o(on,"LI",{});var Rs=l(St);Ko=i(Rs,"Create instances of your config to specify the values of the attributes of each configuration. This gives you the flexibility to specify all the name and description of each configuration. These sub-class instances should be listed under "),Fe=o(Rs,"CODE",{});var ln=l(Fe);Zo=i(ln,"DatasetBuilder.BUILDER_CONFIGS"),ln.forEach(a),tl=i(Rs,":"),Rs.forEach(a),on.forEach(a),ts=u(t),_(Dt.$$.fragment,t),es=u(t),It=o(t,"OL",{start:!0});var rn=l(It);Ot=o(rn,"LI",{});var Us=l(Ot);el=i(Us,"Now, users can load a specific configuration of the dataset with the configuration "),Me=o(Us,"CODE",{});var nn=l(Me);al=i(nn,"name"),nn.forEach(a),sl=i(Us,":"),Us.forEach(a),rn.forEach(a),as=u(t),_(xt.$$.fragment,t),ss=u(t),F=o(t,"H3",{class:!0});var Bs=l(F);st=o(Bs,"A",{id:!0,class:!0,href:!0});var pn=l(st);ze=o(pn,"SPAN",{});var dn=l(ze);_(Ct.$$.fragment,dn),dn.forEach(a),pn.forEach(a),ol=u(Bs),He=o(Bs,"SPAN",{});var un=l(He);ll=i(un,"Default configurations"),un.forEach(a),Bs.forEach(a),os=u(t),C=o(t,"P",{});var we=l(C);rl=i(we,"Users must specify a configuration name when they load a dataset with multiple configurations. Otherwise, \u{1F917} Datasets will raise a "),Qe=o(we,"CODE",{});var fn=l(Qe);nl=i(fn,"ValueError"),fn.forEach(a),il=i(we,", and prompt the user to select a configuration name. You can avoid this by setting a default dataset configuration with the "),Ye=o(we,"CODE",{});var hn=l(Ye);pl=i(hn,"DEFAULT_CONFIG_NAME"),hn.forEach(a),dl=i(we," attribute:"),we.forEach(a),ls=u(t),_(Lt.$$.fragment,t),rs=u(t),_(ot.$$.fragment,t),ns=u(t),M=o(t,"H2",{class:!0});var Vs=l(M);lt=o(Vs,"A",{id:!0,class:!0,href:!0});var cn=l(lt);Xe=o(cn,"SPAN",{});var mn=l(Xe);_(Tt.$$.fragment,mn),mn.forEach(a),cn.forEach(a),ul=u(Vs),Je=o(Vs,"SPAN",{});var gn=l(Je);fl=i(gn,"Download data files and organize splits"),gn.forEach(a),Vs.forEach(a),is=u(t),re=o(t,"P",{});var _n=l(re);hl=i(_n,"After you\u2019ve defined the attributes of your dataset, the next step is to download the data files and organize them according to their splits."),_n.forEach(a),ps=u(t),ne=o(t,"OL",{});var wn=l(ne);We=o(wn,"LI",{});var vn=l(We);cl=i(vn,"Create a dictionary of URLs in the loading script that point to the original SQuAD data files:"),vn.forEach(a),wn.forEach(a),ds=u(t),_(Nt.$$.fragment,t),us=u(t),_(rt.$$.fragment,t),fs=u(t),Pt=o(t,"OL",{start:!0});var qn=l(Pt);Gt=o(qn,"LI",{});var Fs=l(Gt);nt=o(Fs,"P",{});var Da=l(nt);ie=o(Da,"A",{href:!0});var yn=l(ie);ml=i(yn,"DownloadManager.download_and_extract()"),yn.forEach(a),gl=i(Da," takes this dictionary and downloads the data files. Once the files are downloaded, use "),pe=o(Da,"A",{href:!0});var $n=l(pe);_l=i($n,"SplitGenerator"),$n.forEach(a),wl=i(Da," to organize each split in the dataset. This is a simple class that contains:"),Da.forEach(a),vl=u(Fs),Rt=o(Fs,"UL",{});var Ms=l(Rt);Ke=o(Ms,"LI",{});var En=l(Ke);A=o(En,"P",{});var R=l(A);ql=i(R,"The "),Ze=o(R,"CODE",{});var bn=l(Ze);yl=i(bn,"name"),bn.forEach(a),$l=i(R," of each split. You should use the standard split names: "),ta=o(R,"CODE",{});var jn=l(ta);El=i(jn,"Split.TRAIN"),jn.forEach(a),bl=i(R,", "),ea=o(R,"CODE",{});var kn=l(ea);jl=i(kn,"Split.TEST"),kn.forEach(a),kl=i(R,", and "),aa=o(R,"CODE",{});var An=l(aa);Al=i(An,"Split.VALIDATION"),An.forEach(a),Sl=i(R,"."),R.forEach(a),En.forEach(a),Dl=u(Ms),sa=o(Ms,"LI",{});var Sn=l(sa);de=o(Sn,"P",{});var br=l(de);oa=o(br,"CODE",{});var Dn=l(oa);Il=i(Dn,"gen_kwargs"),Dn.forEach(a),Ol=i(br," provides the file paths to the data files to load for each split."),br.forEach(a),Sn.forEach(a),Ms.forEach(a),Fs.forEach(a),qn.forEach(a),hs=u(t),it=o(t,"P",{});var zs=l(it);xl=i(zs,"Your "),la=o(zs,"CODE",{});var In=l(la);Cl=i(In,"DatasetBuilder._split_generator()"),In.forEach(a),Ll=i(zs," should look like this now:"),zs.forEach(a),cs=u(t),_(Ut.$$.fragment,t),ms=u(t),z=o(t,"H2",{class:!0});var Hs=l(z);pt=o(Hs,"A",{id:!0,class:!0,href:!0});var On=l(pt);ra=o(On,"SPAN",{});var xn=l(ra);_(Bt.$$.fragment,xn),xn.forEach(a),On.forEach(a),Tl=u(Hs),na=o(Hs,"SPAN",{});var Cn=l(na);Nl=i(Cn,"Generate samples"),Cn.forEach(a),Hs.forEach(a),gs=u(t),ue=o(t,"P",{});var Ln=l(ue);Pl=i(Ln,"At this point, you have:"),Ln.forEach(a),_s=u(t),L=o(t,"UL",{});var ve=l(L);ia=o(ve,"LI",{});var Tn=l(ia);Gl=i(Tn,"Added the dataset attributes."),Tn.forEach(a),Rl=u(ve),pa=o(ve,"LI",{});var Nn=l(pa);Ul=i(Nn,"Provided instructions for how to download the data files."),Nn.forEach(a),Bl=u(ve),da=o(ve,"LI",{});var Pn=l(da);Vl=i(Pn,"Organized the splits."),Pn.forEach(a),ve.forEach(a),ws=u(t),fe=o(t,"P",{});var Gn=l(fe);Fl=i(Gn,"The next step is to actually generate the samples in each split."),Gn.forEach(a),vs=u(t),dt=o(t,"OL",{});var Qs=l(dt);ua=o(Qs,"LI",{});var Rn=l(ua);ut=o(Rn,"P",{});var Ia=l(ut);fa=o(Ia,"CODE",{});var Un=l(fa);Ml=i(Un,"DatasetBuilder._generate_examples"),Un.forEach(a),zl=i(Ia," takes the file path provided by "),ha=o(Ia,"CODE",{});var Bn=l(ha);Hl=i(Bn,"gen_kwargs"),Bn.forEach(a),Ql=i(Ia," to read and parse the data files. You need to write a function that loads the data files and extracts the columns."),Ia.forEach(a),Rn.forEach(a),Yl=u(Qs),ca=o(Qs,"LI",{});var Vn=l(ca);Vt=o(Vn,"P",{});var Ys=l(Vt);Xl=i(Ys,"Your function should yield a tuple of an "),ma=o(Ys,"CODE",{});var Fn=l(ma);Jl=i(Fn,"id_"),Fn.forEach(a),Wl=i(Ys,", and an example from the dataset."),Ys.forEach(a),Vn.forEach(a),Qs.forEach(a),qs=u(t),_(Ft.$$.fragment,t),ys=u(t),H=o(t,"H2",{class:!0});var Xs=l(H);ft=o(Xs,"A",{id:!0,class:!0,href:!0});var Mn=l(ft);ga=o(Mn,"SPAN",{});var zn=l(ga);_(Mt.$$.fragment,zn),zn.forEach(a),Mn.forEach(a),Kl=u(Xs),_a=o(Xs,"SPAN",{});var Hn=l(_a);Zl=i(Hn,"(Optional) Generate dataset metadata"),Hn.forEach(a),Xs.forEach(a),$s=u(t),T=o(t,"P",{});var qe=l(T);tr=i(qe,"Adding dataset metadata is a great way to include information about your dataset. The metadata is stored in the dataset card "),wa=o(qe,"CODE",{});var Qn=l(wa);er=i(Qn,"README.md"),Qn.forEach(a),ar=i(qe," in YAML. It includes information like the number of examples required to confirm the dataset was correctly generated, and information about the dataset like its "),va=o(qe,"CODE",{});var Yn=l(va);sr=i(Yn,"features"),Yn.forEach(a),or=i(qe,"."),qe.forEach(a),Es=u(t),ht=o(t,"P",{});var Js=l(ht);lr=i(Js,"Run the following command to generate your dataset metadata in "),qa=o(Js,"CODE",{});var Xn=l(qa);rr=i(Xn,"README.md"),Xn.forEach(a),nr=i(Js," and make sure your new dataset loading script works correctly:"),Js.forEach(a),bs=u(t),_(zt.$$.fragment,t),js=u(t),N=o(t,"P",{});var ye=l(N);ir=i(ye,"If your dataset loading script passed the test, you should now have a "),ya=o(ye,"CODE",{});var Jn=l(ya);pr=i(Jn,"README.md"),Jn.forEach(a),dr=i(ye," file in your dataset folder containing a "),$a=o(ye,"CODE",{});var Wn=l($a);ur=i(Wn,"dataset_info"),Wn.forEach(a),fr=i(ye," field with some metadata."),ye.forEach(a),ks=u(t),Q=o(t,"H2",{class:!0});var Ws=l(Q);ct=o(Ws,"A",{id:!0,class:!0,href:!0});var Kn=l(ct);Ea=o(Kn,"SPAN",{});var Zn=l(Ea);_(Ht.$$.fragment,Zn),Zn.forEach(a),Kn.forEach(a),hr=u(Ws),ba=o(Ws,"SPAN",{});var ti=l(ba);cr=i(ti,"Upload to the Hub"),ti.forEach(a),Ws.forEach(a),As=u(t),P=o(t,"P",{});var $e=l(P);mr=i($e,"Once your script is ready, "),he=o($e,"A",{href:!0});var ei=l(he);gr=i(ei,"create a dataset card"),ei.forEach(a),_r=i($e," and "),ce=o($e,"A",{href:!0});var ai=l(ce);wr=i(ai,"upload it to the Hub"),ai.forEach(a),vr=i($e,"."),$e.forEach(a),Ss=u(t),me=o(t,"P",{});var si=l(me);qr=i(si,"Congratulations, you can now load your dataset from the Hub! \u{1F973}"),si.forEach(a),Ds=u(t),_(Qt.$$.fragment,t),this.h()},h(){f(h,"name","hf:doc:metadata"),f(h,"content",JSON.stringify(ci)),f(m,"id","create-a-dataset-loading-script"),f(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(m,"href","#create-a-dataset-loading-script"),f(c,"class","relative group"),f(wt,"href","https://huggingface.co/datasets/squad/blob/main/squad.py"),f(wt,"rel","nofollow"),f(W,"id","add-dataset-attributes"),f(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(W,"href","#add-dataset-attributes"),f(U,"class","relative group"),f(Zt,"href","/docs/datasets/v2.6.1/en/package_reference/main_classes#datasets.Features"),f(B,"start","3"),f(et,"id","multiple-configurations"),f(et,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(et,"href","#multiple-configurations"),f(V,"class","relative group"),f(Et,"href","https://huggingface.co/datasets/super_glue"),f(Et,"rel","nofollow"),f(se,"href","/docs/datasets/v2.6.1/en/package_reference/builder_classes#datasets.BuilderConfig"),f(bt,"href","https://github.com/huggingface/datasets/blob/main/datasets/super_glue/super_glue.py"),f(bt,"rel","nofollow"),f(le,"href","/docs/datasets/v2.6.1/en/package_reference/builder_classes#datasets.BuilderConfig"),f(At,"start","2"),f(It,"start","3"),f(st,"id","default-configurations"),f(st,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(st,"href","#default-configurations"),f(F,"class","relative group"),f(lt,"id","download-data-files-and-organize-splits"),f(lt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(lt,"href","#download-data-files-and-organize-splits"),f(M,"class","relative group"),f(ie,"href","/docs/datasets/v2.6.1/en/package_reference/builder_classes#datasets.DownloadManager.download_and_extract"),f(pe,"href","/docs/datasets/v2.6.1/en/package_reference/builder_classes#datasets.SplitGenerator"),f(Pt,"start","2"),f(pt,"id","generate-samples"),f(pt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(pt,"href","#generate-samples"),f(z,"class","relative group"),f(ft,"id","optional-generate-dataset-metadata"),f(ft,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ft,"href","#optional-generate-dataset-metadata"),f(H,"class","relative group"),f(ct,"id","upload-to-the-hub"),f(ct,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ct,"href","#upload-to-the-hub"),f(Q,"class","relative group"),f(he,"href","dataset_card"),f(ce,"href","share")},m(t,r){e(document.head,h),p(t,$,r),p(t,c,r),e(c,m),e(m,k),w(E,k,null),e(c,b),e(c,D),e(D,Zs),p(t,Oa,r),w(Y,t,r),p(t,xa,r),p(t,Xt,r),e(Xt,to),p(t,Ca,r),p(t,Jt,r),e(Jt,eo),p(t,La,r),p(t,O,r),e(O,ao),e(O,Ee),e(Ee,so),e(O,oo),e(O,be),e(be,lo),e(O,ro),p(t,Ta,r),w(gt,t,r),p(t,Na,r),w(_t,t,r),p(t,Pa,r),p(t,Wt,r),e(Wt,no),p(t,Ga,r),p(t,j,r),e(j,je),e(je,io),e(j,po),e(j,ke),e(ke,uo),e(j,fo),e(j,Ae),e(Ae,ho),e(j,co),e(j,Se),e(Se,mo),e(j,go),e(j,De),e(De,_o),p(t,Ra,r),p(t,X,r),e(X,wo),e(X,wt),e(wt,vo),e(X,qo),p(t,Ua,r),w(J,t,r),p(t,Ba,r),p(t,U,r),e(U,W),e(W,Ie),w(vt,Ie,null),e(U,yo),e(U,Oe),e(Oe,$o),p(t,Va,r),p(t,K,r),e(K,Eo),e(K,xe),e(xe,bo),e(K,jo),p(t,Fa,r),p(t,Z,r),e(Z,Ce),e(Ce,Kt),e(Kt,Le),e(Le,ko),e(Kt,Ao),e(Z,So),e(Z,Te),e(Te,tt),e(tt,Ne),e(Ne,Do),e(tt,Io),e(tt,Zt),e(Zt,Oo),e(tt,xo),p(t,Ma,r),w(qt,t,r),p(t,za,r),p(t,B,r),e(B,Pe),e(Pe,te),e(te,Ge),e(Ge,Co),e(te,Lo),e(B,To),e(B,Re),e(Re,ee),e(ee,Ue),e(Ue,No),e(ee,Po),p(t,Ha,r),p(t,ae,r),e(ae,Go),p(t,Qa,r),w(yt,t,r),p(t,Ya,r),p(t,V,r),e(V,et),e(et,Be),w($t,Be,null),e(V,Ro),e(V,Ve),e(Ve,Uo),p(t,Xa,r),p(t,x,r),e(x,Bo),e(x,Et),e(Et,Vo),e(x,Fo),e(x,se),e(se,Mo),e(x,zo),p(t,Ja,r),p(t,at,r),e(at,Ho),e(at,bt),e(bt,Qo),e(at,Yo),p(t,Wa,r),p(t,oe,r),e(oe,jt),e(jt,Xo),e(jt,le),e(le,Jo),e(jt,Wo),p(t,Ka,r),w(kt,t,r),p(t,Za,r),p(t,At,r),e(At,St),e(St,Ko),e(St,Fe),e(Fe,Zo),e(St,tl),p(t,ts,r),w(Dt,t,r),p(t,es,r),p(t,It,r),e(It,Ot),e(Ot,el),e(Ot,Me),e(Me,al),e(Ot,sl),p(t,as,r),w(xt,t,r),p(t,ss,r),p(t,F,r),e(F,st),e(st,ze),w(Ct,ze,null),e(F,ol),e(F,He),e(He,ll),p(t,os,r),p(t,C,r),e(C,rl),e(C,Qe),e(Qe,nl),e(C,il),e(C,Ye),e(Ye,pl),e(C,dl),p(t,ls,r),w(Lt,t,r),p(t,rs,r),w(ot,t,r),p(t,ns,r),p(t,M,r),e(M,lt),e(lt,Xe),w(Tt,Xe,null),e(M,ul),e(M,Je),e(Je,fl),p(t,is,r),p(t,re,r),e(re,hl),p(t,ps,r),p(t,ne,r),e(ne,We),e(We,cl),p(t,ds,r),w(Nt,t,r),p(t,us,r),w(rt,t,r),p(t,fs,r),p(t,Pt,r),e(Pt,Gt),e(Gt,nt),e(nt,ie),e(ie,ml),e(nt,gl),e(nt,pe),e(pe,_l),e(nt,wl),e(Gt,vl),e(Gt,Rt),e(Rt,Ke),e(Ke,A),e(A,ql),e(A,Ze),e(Ze,yl),e(A,$l),e(A,ta),e(ta,El),e(A,bl),e(A,ea),e(ea,jl),e(A,kl),e(A,aa),e(aa,Al),e(A,Sl),e(Rt,Dl),e(Rt,sa),e(sa,de),e(de,oa),e(oa,Il),e(de,Ol),p(t,hs,r),p(t,it,r),e(it,xl),e(it,la),e(la,Cl),e(it,Ll),p(t,cs,r),w(Ut,t,r),p(t,ms,r),p(t,z,r),e(z,pt),e(pt,ra),w(Bt,ra,null),e(z,Tl),e(z,na),e(na,Nl),p(t,gs,r),p(t,ue,r),e(ue,Pl),p(t,_s,r),p(t,L,r),e(L,ia),e(ia,Gl),e(L,Rl),e(L,pa),e(pa,Ul),e(L,Bl),e(L,da),e(da,Vl),p(t,ws,r),p(t,fe,r),e(fe,Fl),p(t,vs,r),p(t,dt,r),e(dt,ua),e(ua,ut),e(ut,fa),e(fa,Ml),e(ut,zl),e(ut,ha),e(ha,Hl),e(ut,Ql),e(dt,Yl),e(dt,ca),e(ca,Vt),e(Vt,Xl),e(Vt,ma),e(ma,Jl),e(Vt,Wl),p(t,qs,r),w(Ft,t,r),p(t,ys,r),p(t,H,r),e(H,ft),e(ft,ga),w(Mt,ga,null),e(H,Kl),e(H,_a),e(_a,Zl),p(t,$s,r),p(t,T,r),e(T,tr),e(T,wa),e(wa,er),e(T,ar),e(T,va),e(va,sr),e(T,or),p(t,Es,r),p(t,ht,r),e(ht,lr),e(ht,qa),e(qa,rr),e(ht,nr),p(t,bs,r),w(zt,t,r),p(t,js,r),p(t,N,r),e(N,ir),e(N,ya),e(ya,pr),e(N,dr),e(N,$a),e($a,ur),e(N,fr),p(t,ks,r),p(t,Q,r),e(Q,ct),e(ct,Ea),w(Ht,Ea,null),e(Q,hr),e(Q,ba),e(ba,cr),p(t,As,r),p(t,P,r),e(P,mr),e(P,he),e(he,gr),e(P,_r),e(P,ce),e(ce,wr),e(P,vr),p(t,Ss,r),p(t,me,r),e(me,qr),p(t,Ds,r),w(Qt,t,r),Is=!0},p(t,[r]){const Yt={};r&2&&(Yt.$$scope={dirty:r,ctx:t}),Y.$set(Yt);const ja={};r&2&&(ja.$$scope={dirty:r,ctx:t}),J.$set(ja);const ka={};r&2&&(ka.$$scope={dirty:r,ctx:t}),ot.$set(ka);const Aa={};r&2&&(Aa.$$scope={dirty:r,ctx:t}),rt.$set(Aa)},i(t){Is||(v(E.$$.fragment,t),v(Y.$$.fragment,t),v(gt.$$.fragment,t),v(_t.$$.fragment,t),v(J.$$.fragment,t),v(vt.$$.fragment,t),v(qt.$$.fragment,t),v(yt.$$.fragment,t),v($t.$$.fragment,t),v(kt.$$.fragment,t),v(Dt.$$.fragment,t),v(xt.$$.fragment,t),v(Ct.$$.fragment,t),v(Lt.$$.fragment,t),v(ot.$$.fragment,t),v(Tt.$$.fragment,t),v(Nt.$$.fragment,t),v(rt.$$.fragment,t),v(Ut.$$.fragment,t),v(Bt.$$.fragment,t),v(Ft.$$.fragment,t),v(Mt.$$.fragment,t),v(zt.$$.fragment,t),v(Ht.$$.fragment,t),v(Qt.$$.fragment,t),Is=!0)},o(t){q(E.$$.fragment,t),q(Y.$$.fragment,t),q(gt.$$.fragment,t),q(_t.$$.fragment,t),q(J.$$.fragment,t),q(vt.$$.fragment,t),q(qt.$$.fragment,t),q(yt.$$.fragment,t),q($t.$$.fragment,t),q(kt.$$.fragment,t),q(Dt.$$.fragment,t),q(xt.$$.fragment,t),q(Ct.$$.fragment,t),q(Lt.$$.fragment,t),q(ot.$$.fragment,t),q(Tt.$$.fragment,t),q(Nt.$$.fragment,t),q(rt.$$.fragment,t),q(Ut.$$.fragment,t),q(Bt.$$.fragment,t),q(Ft.$$.fragment,t),q(Mt.$$.fragment,t),q(zt.$$.fragment,t),q(Ht.$$.fragment,t),q(Qt.$$.fragment,t),Is=!1},d(t){a(h),t&&a($),t&&a(c),y(E),t&&a(Oa),y(Y,t),t&&a(xa),t&&a(Xt),t&&a(Ca),t&&a(Jt),t&&a(La),t&&a(O),t&&a(Ta),y(gt,t),t&&a(Na),y(_t,t),t&&a(Pa),t&&a(Wt),t&&a(Ga),t&&a(j),t&&a(Ra),t&&a(X),t&&a(Ua),y(J,t),t&&a(Ba),t&&a(U),y(vt),t&&a(Va),t&&a(K),t&&a(Fa),t&&a(Z),t&&a(Ma),y(qt,t),t&&a(za),t&&a(B),t&&a(Ha),t&&a(ae),t&&a(Qa),y(yt,t),t&&a(Ya),t&&a(V),y($t),t&&a(Xa),t&&a(x),t&&a(Ja),t&&a(at),t&&a(Wa),t&&a(oe),t&&a(Ka),y(kt,t),t&&a(Za),t&&a(At),t&&a(ts),y(Dt,t),t&&a(es),t&&a(It),t&&a(as),y(xt,t),t&&a(ss),t&&a(F),y(Ct),t&&a(os),t&&a(C),t&&a(ls),y(Lt,t),t&&a(rs),y(ot,t),t&&a(ns),t&&a(M),y(Tt),t&&a(is),t&&a(re),t&&a(ps),t&&a(ne),t&&a(ds),y(Nt,t),t&&a(us),y(rt,t),t&&a(fs),t&&a(Pt),t&&a(hs),t&&a(it),t&&a(cs),y(Ut,t),t&&a(ms),t&&a(z),y(Bt),t&&a(gs),t&&a(ue),t&&a(_s),t&&a(L),t&&a(ws),t&&a(fe),t&&a(vs),t&&a(dt),t&&a(qs),y(Ft,t),t&&a(ys),t&&a(H),y(Mt),t&&a($s),t&&a(T),t&&a(Es),t&&a(ht),t&&a(bs),y(zt,t),t&&a(js),t&&a(N),t&&a(ks),t&&a(Q),y(Ht),t&&a(As),t&&a(P),t&&a(Ss),t&&a(me),t&&a(Ds),y(Qt,t)}}}const ci={local:"create-a-dataset-loading-script",sections:[{local:"add-dataset-attributes",sections:[{local:"multiple-configurations",title:"Multiple configurations"},{local:"default-configurations",title:"Default configurations"}],title:"Add dataset attributes"},{local:"download-data-files-and-organize-splits",title:"Download data files and organize splits"},{local:"generate-samples",title:"Generate samples"},{local:"optional-generate-dataset-metadata",title:"(Optional) Generate dataset metadata"},{local:"upload-to-the-hub",title:"Upload to the Hub"}],title:"Create a dataset loading script"};function mi(I){return ii(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class qi extends oi{constructor(h){super();li(this,h,mi,hi,ri,{})}}export{qi as default,ci as metadata};
