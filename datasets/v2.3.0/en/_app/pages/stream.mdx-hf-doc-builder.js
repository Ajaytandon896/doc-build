import{S as Di,i as Ai,s as Ii,e as t,k as c,w as _,t as n,M as Ti,c as l,d as s,m as f,a as o,x as v,h as r,b as h,N as Ei,G as a,g as i,y as j,q as b,o as $,B as x,v as Pi,L as qi}from"../chunks/vendor-hf-doc-builder.js";import{T as ut}from"../chunks/Tip-hf-doc-builder.js";import{I as C}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as I}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as Si,M as zi}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function Ci(q){let d,w,m,y,k,g,E,u;return{c(){d=t("p"),w=n("An "),m=t("a"),y=n("IterableDataset"),k=n(" is useful for iterative jobs like training a model. You shouldn\u2019t use a "),g=t("a"),E=n("IterableDataset"),u=n(" for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),this.h()},l(D){d=l(D,"P",{});var A=o(d);w=r(A,"An "),m=l(A,"A",{href:!0});var T=o(m);y=r(T,"IterableDataset"),T.forEach(s),k=r(A," is useful for iterative jobs like training a model. You shouldn\u2019t use a "),g=l(A,"A",{href:!0});var N=o(g);E=r(N,"IterableDataset"),N.forEach(s),u=r(A," for jobs that require random access to examples because you have to iterate all over it using a for loop. Getting the last example in an iterable dataset would require you to iterate over all the previous examples."),A.forEach(s),this.h()},h(){h(m,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset"),h(g,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset")},m(D,A){i(D,d,A),a(d,w),a(d,m),a(m,y),a(d,k),a(d,g),a(g,E),a(d,u)},d(D){D&&s(d)}}}function Ni(q){let d,w,m,y;return{c(){d=t("p"),w=t("a"),m=n("IterableDataset.shuffle()"),y=n(" will also shuffle the order of the shards if the dataset is sharded into multiple sets."),this.h()},l(k){d=l(k,"P",{});var g=o(d);w=l(g,"A",{href:!0});var E=o(w);m=r(E,"IterableDataset.shuffle()"),E.forEach(s),y=r(g," will also shuffle the order of the shards if the dataset is sharded into multiple sets."),g.forEach(s),this.h()},h(){h(w,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle")},m(k,g){i(k,d,g),a(d,w),a(w,m),a(d,y)},d(k){k&&s(d)}}}function Mi(q){let d,w,m,y,k,g,E,u,D,A,T,N,he;return{c(){d=t("p"),w=t("code"),m=n("take"),y=n(" and "),k=t("code"),g=n("skip"),E=n(" prevent future calls to "),u=t("code"),D=n("shuffle"),A=n(" because they lock in the order of the shards. You should "),T=t("code"),N=n("shuffle"),he=n(" your dataset before splitting it.")},l(z){d=l(z,"P",{});var P=o(d);w=l(P,"CODE",{});var Ds=o(w);m=r(Ds,"take"),Ds.forEach(s),y=r(P," and "),k=l(P,"CODE",{});var As=o(k);g=r(As,"skip"),As.forEach(s),E=r(P," prevent future calls to "),u=l(P,"CODE",{});var ce=o(u);D=r(ce,"shuffle"),ce.forEach(s),A=r(P," because they lock in the order of the shards. You should "),T=l(P,"CODE",{});var Is=o(T);N=r(Is,"shuffle"),Is.forEach(s),he=r(P," your dataset before splitting it."),P.forEach(s)},m(z,P){i(z,d,P),a(d,w),a(w,m),a(d,y),a(d,k),a(k,g),a(d,E),a(d,u),a(u,D),a(d,A),a(d,T),a(T,N),a(d,he)},d(z){z&&s(d)}}}function Li(q){let d,w,m,y,k,g,E,u;return{c(){d=t("p"),w=n("Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=t("code"),y=n("Value('int32')"),k=n(" to "),g=t("code"),E=n("Value('bool')"),u=n(" if the original column only contains ones and zeros.")},l(D){d=l(D,"P",{});var A=o(d);w=r(A,"Casting only works if the original feature type and new feature type are compatible. For example, you can cast a column with the feature type "),m=l(A,"CODE",{});var T=o(m);y=r(T,"Value('int32')"),T.forEach(s),k=r(A," to "),g=l(A,"CODE",{});var N=o(g);E=r(N,"Value('bool')"),N.forEach(s),u=r(A," if the original column only contains ones and zeros."),A.forEach(s)},m(D,A){i(D,d,A),a(d,w),a(d,m),a(m,y),a(d,k),a(d,g),a(g,E),a(d,u)},d(D){D&&s(d)}}}function Oi(q){let d,w,m,y,k;return{c(){d=t("p"),w=n("See other examples of batch processing in the "),m=t("a"),y=n("batched map processing"),k=n(" documentation. They work the same for iterable datasets."),this.h()},l(g){d=l(g,"P",{});var E=o(d);w=r(E,"See other examples of batch processing in the "),m=l(E,"A",{href:!0});var u=o(m);y=r(u,"batched map processing"),u.forEach(s),k=r(E," documentation. They work the same for iterable datasets."),E.forEach(s),this.h()},h(){h(m,"href","./process#batch-processing")},m(g,E){i(g,d,E),a(d,w),a(d,m),a(m,y),a(d,k)},d(g){g&&s(d)}}}function Vi(q){let d,w,m,y,k,g,E;return d=new I({props:{code:`seed, buffer_size = 42, 10_000
dataset = dataset.shuffle(seed, buffer_size=buffer_size)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>seed, buffer_size = <span class="hljs-number">42</span>, <span class="hljs-number">10_000</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.shuffle(seed, buffer_size=buffer_size)`}}),g=new I({props:{code:`import torch
from torch.utils.data import DataLoader
from transformers import AutoModelForMaskedLM, DataCollatorForLanguageModeling
from tqdm import tqdm
dataset = dataset.with_format("torch")
dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
device = 'cuda' if torch.cuda.is_available() else 'cpu' 
model = AutoModelForMaskedLM.from_pretrained("distilbert-base-uncased")
model.train().to(device)
optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)
for epoch in range(3):
    dataset.set_epoch(epoch)
    for i, batch in enumerate(tqdm(dataloader, total=5)):
        if i == 5:
            break
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs[0]
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        if i % 10 == 0:
            print(f"loss: {loss}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, DataCollatorForLanguageModeling
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
<span class="hljs-meta">&gt;&gt;&gt; </span>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span> 
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.train().to(device)
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = torch.optim.AdamW(params=model.parameters(), lr=<span class="hljs-number">1e-5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):
<span class="hljs-meta">... </span>    dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(dataloader, total=<span class="hljs-number">5</span>)):
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">5</span>:
<span class="hljs-meta">... </span>            <span class="hljs-keyword">break</span>
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>        loss.backward()
<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
<span class="hljs-meta">... </span>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss: <span class="hljs-subst">{loss}</span>&quot;</span>)`}}),{c(){_(d.$$.fragment),w=c(),m=t("p"),y=n("Lastly, create a simple training loop and start training:"),k=c(),_(g.$$.fragment)},l(u){v(d.$$.fragment,u),w=f(u),m=l(u,"P",{});var D=o(m);y=r(D,"Lastly, create a simple training loop and start training:"),D.forEach(s),k=f(u),v(g.$$.fragment,u)},m(u,D){j(d,u,D),i(u,w,D),i(u,m,D),a(m,y),i(u,k,D),j(g,u,D),E=!0},p:qi,i(u){E||(b(d.$$.fragment,u),b(g.$$.fragment,u),E=!0)},o(u){$(d.$$.fragment,u),$(g.$$.fragment,u),E=!1},d(u){x(d,u),u&&s(w),u&&s(m),u&&s(k),x(g,u)}}}function Fi(q){let d,w;return d=new zi({props:{$$slots:{default:[Vi]},$$scope:{ctx:q}}}),{c(){_(d.$$.fragment)},l(m){v(d.$$.fragment,m)},m(m,y){j(d,m,y),w=!0},p(m,y){const k={};y&2&&(k.$$scope={dirty:y,ctx:m}),d.$set(k)},i(m){w||(b(d.$$.fragment,m),w=!0)},o(m){$(d.$$.fragment,m),w=!1},d(m){x(d,m)}}}function Ri(q){let d,w,m,y,k,g,E,u,D,A,T,N,he,z,P,Ds,As,ce,Is,gt,J,Ts,Lo,Zl,Ps,Oo,_t,L,en,Be,sn,an,_a,tn,ln,qs,nn,rn,vt,Je,jt,H,on,Ss,pn,hn,zs,cn,fn,bt,fe,$t,W,de,va,We,dn,ja,mn,xt,O,un,Cs,gn,_n,Ns,vn,jn,Ms,bn,$n,wt,V,xn,ba,wn,yn,$a,kn,En,Ls,Dn,An,yt,Ge,kt,me,Et,G,ue,xa,Ke,In,wa,Tn,Dt,ge,Pn,ya,qn,Sn,At,_e,zn,ka,Cn,Nn,It,Qe,Tt,K,ve,Ea,Xe,Mn,Da,Ln,Pt,Os,On,qt,Vs,je,Fs,Vn,Fn,Aa,Rn,Hn,St,Ze,zt,Rs,be,Hs,Yn,Un,Ia,Bn,Jn,Ct,es,Nt,$e,Mt,Ys,Lt,Q,xe,Ta,ss,Wn,Pa,Gn,Ot,X,Us,Kn,Qn,Bs,Xn,Zn,Vt,as,Ft,we,er,qa,sr,ar,Rt,ts,Ht,Y,tr,Sa,lr,nr,za,rr,or,Yt,Z,ye,Ca,ls,pr,Na,ir,Ut,Js,hr,Bt,ee,ke,Ma,ns,cr,La,fr,Jt,Ee,dr,Ws,mr,ur,Wt,De,gr,Gs,_r,vr,Gt,rs,Kt,se,Ae,Oa,os,jr,Va,br,Qt,Ie,$r,Ks,xr,wr,Xt,ps,Zt,ae,Te,Fa,is,yr,Ra,kr,el,M,Qs,Er,Dr,Ha,Ar,Ir,Ya,Tr,Pr,Ua,qr,Sr,sl,hs,al,Pe,tl,qe,zr,Xs,Cr,Nr,ll,cs,nl,te,Se,Ba,fs,Mr,Ja,Lr,rl,S,Or,Zs,Vr,Fr,ea,Rr,Hr,sa,Yr,Ur,aa,Br,Jr,ta,Wr,Gr,ol,la,Kr,pl,U,Qr,na,Xr,Zr,Wa,eo,so,il,ds,hl,ze,ao,ra,to,lo,cl,ms,fl,Ce,no,oa,ro,oo,dl,B,po,Ga,io,ho,pa,co,fo,ml,us,ul,le,Ne,Ka,gs,mo,Qa,uo,gl,R,ia,go,_o,Xa,vo,jo,Za,bo,$o,_l,ne,Me,et,_s,xo,st,wo,vl,vs,jl,Le,bl,re,Oe,at,js,yo,tt,ko,$l,Ve,Eo,ha,Do,Ao,xl,bs,wl,oe,ca,Io,To,lt,Po,qo,yl,$s,kl,pe,Fe,nt,xs,So,rt,zo,El,ws,fa,Co,No,Dl,Re,Al;return g=new C({}),Je=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
print(next(iter(dataset)))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset)))
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, which he shared with John Blanchard during his first visit to Malawi. Chief Napoleon conveyed the desperate need for a program to intervene and care for the orphans and vulnerable children (OVC) in Malawi, and John committed to help...</span>`}}),fe=new ut({props:{$$slots:{default:[Ci]},$$scope:{ctx:q}}}),We=new C({}),Ge=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
shuffled_dataset = dataset.shuffle(seed=42, buffer_size=10_000)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>shuffled_dataset = dataset.shuffle(seed=<span class="hljs-number">42</span>, buffer_size=<span class="hljs-number">10_000</span>)`}}),me=new ut({props:{$$slots:{default:[Ni]},$$scope:{ctx:q}}}),Ke=new C({}),Qe=new I({props:{code:`for epoch in range(epochs):
    shuffled_dataset.set_epoch(epoch)
    for example in shuffled_dataset:
        ...`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):
<span class="hljs-meta">... </span>    shuffled_dataset.set_epoch(epoch)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> shuffled_dataset:
<span class="hljs-meta">... </span>        ...`}}),Xe=new C({}),Ze=new I({props:{code:`dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
dataset_head = dataset.take(2)
list(dataset_head)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset_head = dataset.take(<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(dataset_head)
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was...&#x27;</span>}, {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),es=new I({props:{code:"train_dataset = shuffled_dataset.skip(1000)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataset = shuffled_dataset.skip(<span class="hljs-number">1000</span>)'}}),$e=new ut({props:{warning:!0,$$slots:{default:[Mi]},$$scope:{ctx:q}}}),ss=new C({}),as=new I({props:{code:`from datasets import interleave_datasets
en_dataset = load_dataset('oscar', "unshuffled_deduplicated_en", split='train', streaming=True)
fr_dataset = load_dataset('oscar', "unshuffled_deduplicated_fr", split='train', streaming=True)

multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
list(multilingual_dataset.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> interleave_datasets
<span class="hljs-meta">&gt;&gt;&gt; </span>en_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_en&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>fr_dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&quot;unshuffled_deduplicated_fr&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>, streaming=<span class="hljs-literal">True</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset = interleave_datasets([en_dataset, fr_dataset])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&quot;M\xE9dia de d\xE9bat d&#x27;id\xE9es, de culture et de litt\xE9rature...&quot;</span>}]`}}),ts=new I({props:{code:`multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[0.8, 0.2], seed=42)
list(multilingual_dataset_with_oversampling.take(2))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>multilingual_dataset_with_oversampling = interleave_datasets([en_dataset, fr_dataset], probabilities=[<span class="hljs-number">0.8</span>, <span class="hljs-number">0.2</span>], seed=<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(multilingual_dataset_with_oversampling.take(<span class="hljs-number">2</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision...&#x27;</span>}, {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Lily James cannot fight the music...&#x27;</span>}]`}}),ls=new C({}),ns=new C({}),rs=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.rename_column("text", "content")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.rename_column(<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>)`}}),os=new C({}),ps=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('mc4', 'en', streaming=True, split='train')
dataset = dataset.remove_columns('timestamp')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;mc4&#x27;</span>, <span class="hljs-string">&#x27;en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.remove_columns(<span class="hljs-string">&#x27;timestamp&#x27;</span>)`}}),is=new C({}),hs=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('glue', 'mrpc', split='train')features

from datasets import ClassLabel, Value
new_features = dataset.features.copy()
new_features["label"] = ClassLabel(names=['negative', 'positive'])
new_features["idx"] = Value('int64')
dataset = dataset.cast(new_features)
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;glue&#x27;</span>, <span class="hljs-string">&#x27;mrpc&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;not_equivalent&#x27;</span>, <span class="hljs-string">&#x27;equivalent&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> ClassLabel, Value
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features = dataset.features.copy()
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;label&quot;</span>] = ClassLabel(names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>new_features[<span class="hljs-string">&quot;idx&quot;</span>] = Value(<span class="hljs-string">&#x27;int64&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast(new_features)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;negative&#x27;</span>, <span class="hljs-string">&#x27;positive&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
<span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int64&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),Pe=new ut({props:{$$slots:{default:[Li]},$$scope:{ctx:q}}}),cs=new I({props:{code:`dataset.features

dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
dataset.features`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">44100</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.features
{<span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">16000</span>, mono=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),fs=new C({}),ds=new I({props:{code:`def add_prefix(example):
    example['text'] = 'My text: ' + example['text']
    return example`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_prefix</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    example[<span class="hljs-string">&#x27;text&#x27;</span>] = <span class="hljs-string">&#x27;My text: &#x27;</span> + example[<span class="hljs-string">&#x27;text&#x27;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`}}),ms=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
updated_dataset = dataset.map(add_prefix)
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),us=new I({props:{code:`updated_dataset = dataset.map(add_prefix, remove_columns=["id"])
list(updated_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>updated_dataset = dataset.<span class="hljs-built_in">map</span>(add_prefix, remove_columns=[<span class="hljs-string">&quot;id&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(updated_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Mtendere Village was inspired by...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: Lily James cannot fight the music...&#x27;</span>},
 {<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My text: &quot;I\\&#x27;d love to help kickstart...&#x27;</span>}]`}}),gs=new C({}),_s=new C({}),vs=new I({props:{code:`from datasets import load_dataset
from transformers import AutoTokenizer
dataset = load_dataset("mc4", "en", streaming=True, split="train")
tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
def encode(examples):
    return tokenizer(examples['text'], truncation=True, padding='max_length')
dataset = dataset.map(encode, batched=True, remove_columns=["text", "timestamp", "url"])
next(iter(dataset))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;mc4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&#x27;text&#x27;</span>], truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-string">&#x27;max_length&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(encode, batched=<span class="hljs-literal">True</span>, remove_columns=[<span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;timestamp&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: <span class="hljs-number">101</span>, <span class="hljs-number">8466</span>, <span class="hljs-number">1018</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">4029</span>, <span class="hljs-number">2475</span>, <span class="hljs-number">2062</span>, <span class="hljs-number">18558</span>, <span class="hljs-number">3100</span>, <span class="hljs-number">2061</span>, ...,<span class="hljs-number">1106</span>, <span class="hljs-number">3739</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, ..., <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Le=new ut({props:{$$slots:{default:[Oi]},$$scope:{ctx:q}}}),js=new C({}),bs=new I({props:{code:`from datasets import load_dataset
dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train')
start_with_ar = dataset.filter(lambda example: example['text'].startswith('Ar'))
next(iter(start_with_ar))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&#x27;oscar&#x27;</span>, <span class="hljs-string">&#x27;unshuffled_deduplicated_en&#x27;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>start_with_ar = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example: example[<span class="hljs-string">&#x27;text&#x27;</span>].startswith(<span class="hljs-string">&#x27;Ar&#x27;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(start_with_ar))
{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Are you looking for Number the Stars (Essential Modern Classics)?...&#x27;</span>}`}}),$s=new I({props:{code:`even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True)
list(even_dataset.take(3))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>even_dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example, idx: idx % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>, with_indices=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(even_dataset.take(<span class="hljs-number">3</span>))
[{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, ...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;&quot;I\\&#x27;d love to help kickstart continued development! And 0 EUR/month...&#x27;</span>},
 {<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Are you looking for Number the Stars (Essential Modern Classics)? Normally, ...&#x27;</span>}]`}}),xs=new C({}),Re=new Si({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[Fi]},$$scope:{ctx:q}}}),{c(){d=t("meta"),w=c(),m=t("h1"),y=t("a"),k=t("span"),_(g.$$.fragment),E=c(),u=t("span"),D=n("Stream"),A=c(),T=t("p"),N=n("Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),he=c(),z=t("ul"),P=t("li"),Ds=n("You don\u2019t want to wait for an extremely large dataset to download."),As=c(),ce=t("li"),Is=n("The dataset size exceeds the amount of disk space on your computer."),gt=c(),J=t("div"),Ts=t("img"),Zl=c(),Ps=t("img"),_t=c(),L=t("p"),en=n("For example, the English split of the "),Be=t("a"),sn=n("OSCAR"),an=n(" dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),_a=t("code"),tn=n("streaming=True"),ln=n(" in "),qs=t("a"),nn=n("load_dataset()"),rn=n(" as shown below:"),vt=c(),_(Je.$$.fragment),jt=c(),H=t("p"),on=n("Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Ss=t("a"),pn=n("Dataset"),hn=n(" object), known as an "),zs=t("a"),cn=n("IterableDataset"),fn=n(". This special type of dataset has its own set of processing methods shown below."),bt=c(),_(fe.$$.fragment),$t=c(),W=t("h2"),de=t("a"),va=t("span"),_(We.$$.fragment),dn=c(),ja=t("span"),mn=n("Shuffle"),xt=c(),O=t("p"),un=n("Like a regular "),Cs=t("a"),gn=n("Dataset"),_n=n(" object, you can also shuffle a "),Ns=t("a"),vn=n("IterableDataset"),jn=n(" with "),Ms=t("a"),bn=n("IterableDataset.shuffle()"),$n=n("."),wt=c(),V=t("p"),xn=n("The "),ba=t("code"),wn=n("buffer_size"),yn=n(" argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),$a=t("code"),kn=n("buffer_size"),En=n(" to ten thousand. "),Ls=t("a"),Dn=n("IterableDataset.shuffle()"),An=n(" will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),yt=c(),_(Ge.$$.fragment),kt=c(),_(me.$$.fragment),Et=c(),G=t("h2"),ue=t("a"),xa=t("span"),_(Ke.$$.fragment),In=c(),wa=t("span"),Tn=n("Reshuffle"),Dt=c(),ge=t("p"),Pn=n("Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),ya=t("code"),qn=n("IterableDataset.set_epoch()"),Sn=n(" in between epochs to tell the dataset what epoch you\u2019re on."),At=c(),_e=t("p"),zn=n("Your seed effectively becomes: "),ka=t("code"),Cn=n("initial seed + current epoch"),Nn=n("."),It=c(),_(Qe.$$.fragment),Tt=c(),K=t("h2"),ve=t("a"),Ea=t("span"),_(Xe.$$.fragment),Mn=c(),Da=t("span"),Ln=n("Split dataset"),Pt=c(),Os=t("p"),On=n("You can split your dataset one of two ways:"),qt=c(),Vs=t("ul"),je=t("li"),Fs=t("a"),Vn=n("IterableDataset.take()"),Fn=n(" returns the first "),Aa=t("code"),Rn=n("n"),Hn=n(" examples in a dataset:"),St=c(),_(Ze.$$.fragment),zt=c(),Rs=t("ul"),be=t("li"),Hs=t("a"),Yn=n("IterableDataset.skip()"),Un=n(" omits the first "),Ia=t("code"),Bn=n("n"),Jn=n(" examples in a dataset and returns the remaining examples:"),Ct=c(),_(es.$$.fragment),Nt=c(),_($e.$$.fragment),Mt=c(),Ys=t("a"),Lt=c(),Q=t("h2"),xe=t("a"),Ta=t("span"),_(ss.$$.fragment),Wn=c(),Pa=t("span"),Gn=n("Interleave"),Ot=c(),X=t("p"),Us=t("a"),Kn=n("interleave_datasets()"),Qn=n(" can combine an "),Bs=t("a"),Xn=n("IterableDataset"),Zn=n(" with other datasets. The combined dataset returns alternating examples from each of the original datasets."),Vt=c(),_(as.$$.fragment),Ft=c(),we=t("p"),er=n("Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),qa=t("code"),sr=n("probabilities"),ar=n(" argument with your desired sampling probabilities:"),Rt=c(),_(ts.$$.fragment),Ht=c(),Y=t("p"),tr=n("Around 80% of the final dataset is made of the "),Sa=t("code"),lr=n("en_dataset"),nr=n(", and 20% of the "),za=t("code"),rr=n("fr_dataset"),or=n("."),Yt=c(),Z=t("h2"),ye=t("a"),Ca=t("span"),_(ls.$$.fragment),pr=c(),Na=t("span"),ir=n("Rename, remove, and cast"),Ut=c(),Js=t("p"),hr=n("The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),Bt=c(),ee=t("h3"),ke=t("a"),Ma=t("span"),_(ns.$$.fragment),cr=c(),La=t("span"),fr=n("Rename"),Jt=c(),Ee=t("p"),dr=n("Use "),Ws=t("a"),mr=n("IterableDataset.rename_column()"),ur=n(" when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Wt=c(),De=t("p"),gr=n("Provide "),Gs=t("a"),_r=n("IterableDataset.rename_column()"),vr=n(" with the name of the original column, and the new column name:"),Gt=c(),_(rs.$$.fragment),Kt=c(),se=t("h3"),Ae=t("a"),Oa=t("span"),_(os.$$.fragment),jr=c(),Va=t("span"),br=n("Remove"),Qt=c(),Ie=t("p"),$r=n("When you need to remove one or more columns, give "),Ks=t("a"),xr=n("IterableDataset.remove_columns()"),wr=n(" the name of the column to remove. Remove more than one column by providing a list of column names:"),Xt=c(),_(ps.$$.fragment),Zt=c(),ae=t("h3"),Te=t("a"),Fa=t("span"),_(is.$$.fragment),yr=c(),Ra=t("span"),kr=n("Cast"),el=c(),M=t("p"),Qs=t("a"),Er=n("IterableDataset.cast()"),Dr=n(" changes the feature type of one or more columns. This method takes your new "),Ha=t("code"),Ar=n("Features"),Ir=n(" as its argument. The following sample code shows how to change the feature types of "),Ya=t("code"),Tr=n("ClassLabel"),Pr=n(" and "),Ua=t("code"),qr=n("Value"),Sr=n(":"),sl=c(),_(hs.$$.fragment),al=c(),_(Pe.$$.fragment),tl=c(),qe=t("p"),zr=n("Use "),Xs=t("a"),Cr=n("IterableDataset.cast_column()"),Nr=n(" to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),ll=c(),_(cs.$$.fragment),nl=c(),te=t("h2"),Se=t("a"),Ba=t("span"),_(fs.$$.fragment),Mr=c(),Ja=t("span"),Lr=n("Map"),rl=c(),S=t("p"),Or=n("Similar to the "),Zs=t("a"),Vr=n("Dataset.map()"),Fr=n(" function for a regular "),ea=t("a"),Rr=n("Dataset"),Hr=n(", \u{1F917}  Datasets features "),sa=t("a"),Yr=n("IterableDataset.map()"),Ur=n(" for processing an "),aa=t("a"),Br=n("IterableDataset"),Jr=n(`.
`),ta=t("a"),Wr=n("IterableDataset.map()"),Gr=n(" applies processing on-the-fly when examples are streamed."),ol=c(),la=t("p"),Kr=n("It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),pl=c(),U=t("p"),Qr=n("The following example demonstrates how to tokenize a "),na=t("a"),Xr=n("IterableDataset"),Zr=n(". The function needs to accept and output a "),Wa=t("code"),eo=n("dict"),so=n(":"),il=c(),_(ds.$$.fragment),hl=c(),ze=t("p"),ao=n("Next, apply this function to the dataset with "),ra=t("a"),to=n("IterableDataset.map()"),lo=n(":"),cl=c(),_(ms.$$.fragment),fl=c(),Ce=t("p"),no=n("Let\u2019s take a look at another example, except this time, you will remove a column with "),oa=t("a"),ro=n("IterableDataset.map()"),oo=n(". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),dl=c(),B=t("p"),po=n("Specify the column to remove with the "),Ga=t("code"),io=n("remove_columns"),ho=n(" argument in "),pa=t("a"),co=n("IterableDataset.map()"),fo=n(":"),ml=c(),_(us.$$.fragment),ul=c(),le=t("h3"),Ne=t("a"),Ka=t("span"),_(gs.$$.fragment),mo=c(),Qa=t("span"),uo=n("Batch processing"),gl=c(),R=t("p"),ia=t("a"),go=n("IterableDataset.map()"),_o=n(" also supports working with batches of examples. Operate on batches by setting "),Xa=t("code"),vo=n("batched=True"),jo=n(". The default batch size is 1000, but you can adjust it with the "),Za=t("code"),bo=n("batch_size"),$o=n(" argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),_l=c(),ne=t("h4"),Me=t("a"),et=t("span"),_(_s.$$.fragment),xo=c(),st=t("span"),wo=n("Tokenization"),vl=c(),_(vs.$$.fragment),jl=c(),_(Le.$$.fragment),bl=c(),re=t("h3"),Oe=t("a"),at=t("span"),_(js.$$.fragment),yo=c(),tt=t("span"),ko=n("Filter"),$l=c(),Ve=t("p"),Eo=n("You can filter rows in the dataset based on a predicate function using "),ha=t("a"),Do=n("Dataset.filter()"),Ao=n(". It returns rows that match a specified condition:"),xl=c(),_(bs.$$.fragment),wl=c(),oe=t("p"),ca=t("a"),Io=n("Dataset.filter()"),To=n(" can also filter by indices if you set "),lt=t("code"),Po=n("with_indices=True"),qo=n(":"),yl=c(),_($s.$$.fragment),kl=c(),pe=t("h2"),Fe=t("a"),nt=t("span"),_(xs.$$.fragment),So=c(),rt=t("span"),zo=n("Stream in a training loop"),El=c(),ws=t("p"),fa=t("a"),Co=n("IterableDataset"),No=n(" can be integrated into a training loop. First, shuffle the dataset:"),Dl=c(),_(Re.$$.fragment),this.h()},l(e){const p=Ti('[data-svelte="svelte-1phssyn"]',document.head);d=l(p,"META",{name:!0,content:!0}),p.forEach(s),w=f(e),m=l(e,"H1",{class:!0});var ys=o(m);y=l(ys,"A",{id:!0,class:!0,href:!0});var ot=o(y);k=l(ot,"SPAN",{});var pt=o(k);v(g.$$.fragment,pt),pt.forEach(s),ot.forEach(s),E=f(ys),u=l(ys,"SPAN",{});var it=o(u);D=r(it,"Stream"),it.forEach(s),ys.forEach(s),A=f(e),T=l(e,"P",{});var ht=o(T);N=r(ht,"Dataset streaming lets you get started with a dataset without waiting for the entire dataset to download. The data is downloaded progressively as you iterate over the dataset. This is especially helpful when:"),ht.forEach(s),he=f(e),z=l(e,"UL",{});var ks=o(z);P=l(ks,"LI",{});var Vo=o(P);Ds=r(Vo,"You don\u2019t want to wait for an extremely large dataset to download."),Vo.forEach(s),As=f(ks),ce=l(ks,"LI",{});var Fo=o(ce);Is=r(Fo,"The dataset size exceeds the amount of disk space on your computer."),Fo.forEach(s),ks.forEach(s),gt=f(e),J=l(e,"DIV",{class:!0});var Il=o(J);Ts=l(Il,"IMG",{class:!0,src:!0}),Zl=f(Il),Ps=l(Il,"IMG",{class:!0,src:!0}),Il.forEach(s),_t=f(e),L=l(e,"P",{});var He=o(L);en=r(He,"For example, the English split of the "),Be=l(He,"A",{href:!0,rel:!0});var Ro=o(Be);sn=r(Ro,"OSCAR"),Ro.forEach(s),an=r(He," dataset is 1.2 terabytes, but you can use it instantly with streaming. Stream a dataset by setting "),_a=l(He,"CODE",{});var Ho=o(_a);tn=r(Ho,"streaming=True"),Ho.forEach(s),ln=r(He," in "),qs=l(He,"A",{href:!0});var Yo=o(qs);nn=r(Yo,"load_dataset()"),Yo.forEach(s),rn=r(He," as shown below:"),He.forEach(s),vt=f(e),v(Je.$$.fragment,e),jt=f(e),H=l(e,"P",{});var da=o(H);on=r(da,"Loading a dataset in streaming mode creates a new dataset type instance (instead of the classic "),Ss=l(da,"A",{href:!0});var Uo=o(Ss);pn=r(Uo,"Dataset"),Uo.forEach(s),hn=r(da," object), known as an "),zs=l(da,"A",{href:!0});var Bo=o(zs);cn=r(Bo,"IterableDataset"),Bo.forEach(s),fn=r(da,". This special type of dataset has its own set of processing methods shown below."),da.forEach(s),bt=f(e),v(fe.$$.fragment,e),$t=f(e),W=l(e,"H2",{class:!0});var Tl=o(W);de=l(Tl,"A",{id:!0,class:!0,href:!0});var Jo=o(de);va=l(Jo,"SPAN",{});var Wo=o(va);v(We.$$.fragment,Wo),Wo.forEach(s),Jo.forEach(s),dn=f(Tl),ja=l(Tl,"SPAN",{});var Go=o(ja);mn=r(Go,"Shuffle"),Go.forEach(s),Tl.forEach(s),xt=f(e),O=l(e,"P",{});var Ye=o(O);un=r(Ye,"Like a regular "),Cs=l(Ye,"A",{href:!0});var Ko=o(Cs);gn=r(Ko,"Dataset"),Ko.forEach(s),_n=r(Ye," object, you can also shuffle a "),Ns=l(Ye,"A",{href:!0});var Qo=o(Ns);vn=r(Qo,"IterableDataset"),Qo.forEach(s),jn=r(Ye," with "),Ms=l(Ye,"A",{href:!0});var Xo=o(Ms);bn=r(Xo,"IterableDataset.shuffle()"),Xo.forEach(s),$n=r(Ye,"."),Ye.forEach(s),wt=f(e),V=l(e,"P",{});var Ue=o(V);xn=r(Ue,"The "),ba=l(Ue,"CODE",{});var Zo=o(ba);wn=r(Zo,"buffer_size"),Zo.forEach(s),yn=r(Ue," argument controls the size of the buffer to randomly sample examples from. Let\u2019s say your dataset has one million examples, and you set the "),$a=l(Ue,"CODE",{});var ep=o($a);kn=r(ep,"buffer_size"),ep.forEach(s),En=r(Ue," to ten thousand. "),Ls=l(Ue,"A",{href:!0});var sp=o(Ls);Dn=r(sp,"IterableDataset.shuffle()"),sp.forEach(s),An=r(Ue," will randomly select examples from the first ten thousand examples in the buffer. Selected examples in the buffer are replaced with new examples. By default, the buffer size is 1,000."),Ue.forEach(s),yt=f(e),v(Ge.$$.fragment,e),kt=f(e),v(me.$$.fragment,e),Et=f(e),G=l(e,"H2",{class:!0});var Pl=o(G);ue=l(Pl,"A",{id:!0,class:!0,href:!0});var ap=o(ue);xa=l(ap,"SPAN",{});var tp=o(xa);v(Ke.$$.fragment,tp),tp.forEach(s),ap.forEach(s),In=f(Pl),wa=l(Pl,"SPAN",{});var lp=o(wa);Tn=r(lp,"Reshuffle"),lp.forEach(s),Pl.forEach(s),Dt=f(e),ge=l(e,"P",{});var ql=o(ge);Pn=r(ql,"Sometimes you may want to reshuffle the dataset after each epoch. This will require you to set a different seed for each epoch. Use "),ya=l(ql,"CODE",{});var np=o(ya);qn=r(np,"IterableDataset.set_epoch()"),np.forEach(s),Sn=r(ql," in between epochs to tell the dataset what epoch you\u2019re on."),ql.forEach(s),At=f(e),_e=l(e,"P",{});var Sl=o(_e);zn=r(Sl,"Your seed effectively becomes: "),ka=l(Sl,"CODE",{});var rp=o(ka);Cn=r(rp,"initial seed + current epoch"),rp.forEach(s),Nn=r(Sl,"."),Sl.forEach(s),It=f(e),v(Qe.$$.fragment,e),Tt=f(e),K=l(e,"H2",{class:!0});var zl=o(K);ve=l(zl,"A",{id:!0,class:!0,href:!0});var op=o(ve);Ea=l(op,"SPAN",{});var pp=o(Ea);v(Xe.$$.fragment,pp),pp.forEach(s),op.forEach(s),Mn=f(zl),Da=l(zl,"SPAN",{});var ip=o(Da);Ln=r(ip,"Split dataset"),ip.forEach(s),zl.forEach(s),Pt=f(e),Os=l(e,"P",{});var hp=o(Os);On=r(hp,"You can split your dataset one of two ways:"),hp.forEach(s),qt=f(e),Vs=l(e,"UL",{});var cp=o(Vs);je=l(cp,"LI",{});var ct=o(je);Fs=l(ct,"A",{href:!0});var fp=o(Fs);Vn=r(fp,"IterableDataset.take()"),fp.forEach(s),Fn=r(ct," returns the first "),Aa=l(ct,"CODE",{});var dp=o(Aa);Rn=r(dp,"n"),dp.forEach(s),Hn=r(ct," examples in a dataset:"),ct.forEach(s),cp.forEach(s),St=f(e),v(Ze.$$.fragment,e),zt=f(e),Rs=l(e,"UL",{});var mp=o(Rs);be=l(mp,"LI",{});var ft=o(be);Hs=l(ft,"A",{href:!0});var up=o(Hs);Yn=r(up,"IterableDataset.skip()"),up.forEach(s),Un=r(ft," omits the first "),Ia=l(ft,"CODE",{});var gp=o(Ia);Bn=r(gp,"n"),gp.forEach(s),Jn=r(ft," examples in a dataset and returns the remaining examples:"),ft.forEach(s),mp.forEach(s),Ct=f(e),v(es.$$.fragment,e),Nt=f(e),v($e.$$.fragment,e),Mt=f(e),Ys=l(e,"A",{id:!0}),o(Ys).forEach(s),Lt=f(e),Q=l(e,"H2",{class:!0});var Cl=o(Q);xe=l(Cl,"A",{id:!0,class:!0,href:!0});var _p=o(xe);Ta=l(_p,"SPAN",{});var vp=o(Ta);v(ss.$$.fragment,vp),vp.forEach(s),_p.forEach(s),Wn=f(Cl),Pa=l(Cl,"SPAN",{});var jp=o(Pa);Gn=r(jp,"Interleave"),jp.forEach(s),Cl.forEach(s),Ot=f(e),X=l(e,"P",{});var dt=o(X);Us=l(dt,"A",{href:!0});var bp=o(Us);Kn=r(bp,"interleave_datasets()"),bp.forEach(s),Qn=r(dt," can combine an "),Bs=l(dt,"A",{href:!0});var $p=o(Bs);Xn=r($p,"IterableDataset"),$p.forEach(s),Zn=r(dt," with other datasets. The combined dataset returns alternating examples from each of the original datasets."),dt.forEach(s),Vt=f(e),v(as.$$.fragment,e),Ft=f(e),we=l(e,"P",{});var Nl=o(we);er=r(Nl,"Define sampling probabilities from each of the original datasets for more control over how each of them are sampled and combined. Set the "),qa=l(Nl,"CODE",{});var xp=o(qa);sr=r(xp,"probabilities"),xp.forEach(s),ar=r(Nl," argument with your desired sampling probabilities:"),Nl.forEach(s),Rt=f(e),v(ts.$$.fragment,e),Ht=f(e),Y=l(e,"P",{});var ma=o(Y);tr=r(ma,"Around 80% of the final dataset is made of the "),Sa=l(ma,"CODE",{});var wp=o(Sa);lr=r(wp,"en_dataset"),wp.forEach(s),nr=r(ma,", and 20% of the "),za=l(ma,"CODE",{});var yp=o(za);rr=r(yp,"fr_dataset"),yp.forEach(s),or=r(ma,"."),ma.forEach(s),Yt=f(e),Z=l(e,"H2",{class:!0});var Ml=o(Z);ye=l(Ml,"A",{id:!0,class:!0,href:!0});var kp=o(ye);Ca=l(kp,"SPAN",{});var Ep=o(Ca);v(ls.$$.fragment,Ep),Ep.forEach(s),kp.forEach(s),pr=f(Ml),Na=l(Ml,"SPAN",{});var Dp=o(Na);ir=r(Dp,"Rename, remove, and cast"),Dp.forEach(s),Ml.forEach(s),Ut=f(e),Js=l(e,"P",{});var Ap=o(Js);hr=r(Ap,"The following methods allow you to modify the columns of a dataset. These methods are useful for renaming or removing columns and changing columns to a new set of features."),Ap.forEach(s),Bt=f(e),ee=l(e,"H3",{class:!0});var Ll=o(ee);ke=l(Ll,"A",{id:!0,class:!0,href:!0});var Ip=o(ke);Ma=l(Ip,"SPAN",{});var Tp=o(Ma);v(ns.$$.fragment,Tp),Tp.forEach(s),Ip.forEach(s),cr=f(Ll),La=l(Ll,"SPAN",{});var Pp=o(La);fr=r(Pp,"Rename"),Pp.forEach(s),Ll.forEach(s),Jt=f(e),Ee=l(e,"P",{});var Ol=o(Ee);dr=r(Ol,"Use "),Ws=l(Ol,"A",{href:!0});var qp=o(Ws);mr=r(qp,"IterableDataset.rename_column()"),qp.forEach(s),ur=r(Ol," when you need to rename a column in your dataset. Features associated with the original column are actually moved under the new column name, instead of just replacing the original column in-place."),Ol.forEach(s),Wt=f(e),De=l(e,"P",{});var Vl=o(De);gr=r(Vl,"Provide "),Gs=l(Vl,"A",{href:!0});var Sp=o(Gs);_r=r(Sp,"IterableDataset.rename_column()"),Sp.forEach(s),vr=r(Vl," with the name of the original column, and the new column name:"),Vl.forEach(s),Gt=f(e),v(rs.$$.fragment,e),Kt=f(e),se=l(e,"H3",{class:!0});var Fl=o(se);Ae=l(Fl,"A",{id:!0,class:!0,href:!0});var zp=o(Ae);Oa=l(zp,"SPAN",{});var Cp=o(Oa);v(os.$$.fragment,Cp),Cp.forEach(s),zp.forEach(s),jr=f(Fl),Va=l(Fl,"SPAN",{});var Np=o(Va);br=r(Np,"Remove"),Np.forEach(s),Fl.forEach(s),Qt=f(e),Ie=l(e,"P",{});var Rl=o(Ie);$r=r(Rl,"When you need to remove one or more columns, give "),Ks=l(Rl,"A",{href:!0});var Mp=o(Ks);xr=r(Mp,"IterableDataset.remove_columns()"),Mp.forEach(s),wr=r(Rl," the name of the column to remove. Remove more than one column by providing a list of column names:"),Rl.forEach(s),Xt=f(e),v(ps.$$.fragment,e),Zt=f(e),ae=l(e,"H3",{class:!0});var Hl=o(ae);Te=l(Hl,"A",{id:!0,class:!0,href:!0});var Lp=o(Te);Fa=l(Lp,"SPAN",{});var Op=o(Fa);v(is.$$.fragment,Op),Op.forEach(s),Lp.forEach(s),yr=f(Hl),Ra=l(Hl,"SPAN",{});var Vp=o(Ra);kr=r(Vp,"Cast"),Vp.forEach(s),Hl.forEach(s),el=f(e),M=l(e,"P",{});var ie=o(M);Qs=l(ie,"A",{href:!0});var Fp=o(Qs);Er=r(Fp,"IterableDataset.cast()"),Fp.forEach(s),Dr=r(ie," changes the feature type of one or more columns. This method takes your new "),Ha=l(ie,"CODE",{});var Rp=o(Ha);Ar=r(Rp,"Features"),Rp.forEach(s),Ir=r(ie," as its argument. The following sample code shows how to change the feature types of "),Ya=l(ie,"CODE",{});var Hp=o(Ya);Tr=r(Hp,"ClassLabel"),Hp.forEach(s),Pr=r(ie," and "),Ua=l(ie,"CODE",{});var Yp=o(Ua);qr=r(Yp,"Value"),Yp.forEach(s),Sr=r(ie,":"),ie.forEach(s),sl=f(e),v(hs.$$.fragment,e),al=f(e),v(Pe.$$.fragment,e),tl=f(e),qe=l(e,"P",{});var Yl=o(qe);zr=r(Yl,"Use "),Xs=l(Yl,"A",{href:!0});var Up=o(Xs);Cr=r(Up,"IterableDataset.cast_column()"),Up.forEach(s),Nr=r(Yl," to change the feature type of just one column. Pass the column name and its new feature type as arguments:"),Yl.forEach(s),ll=f(e),v(cs.$$.fragment,e),nl=f(e),te=l(e,"H2",{class:!0});var Ul=o(te);Se=l(Ul,"A",{id:!0,class:!0,href:!0});var Bp=o(Se);Ba=l(Bp,"SPAN",{});var Jp=o(Ba);v(fs.$$.fragment,Jp),Jp.forEach(s),Bp.forEach(s),Mr=f(Ul),Ja=l(Ul,"SPAN",{});var Wp=o(Ja);Lr=r(Wp,"Map"),Wp.forEach(s),Ul.forEach(s),rl=f(e),S=l(e,"P",{});var F=o(S);Or=r(F,"Similar to the "),Zs=l(F,"A",{href:!0});var Gp=o(Zs);Vr=r(Gp,"Dataset.map()"),Gp.forEach(s),Fr=r(F," function for a regular "),ea=l(F,"A",{href:!0});var Kp=o(ea);Rr=r(Kp,"Dataset"),Kp.forEach(s),Hr=r(F,", \u{1F917}  Datasets features "),sa=l(F,"A",{href:!0});var Qp=o(sa);Yr=r(Qp,"IterableDataset.map()"),Qp.forEach(s),Ur=r(F," for processing an "),aa=l(F,"A",{href:!0});var Xp=o(aa);Br=r(Xp,"IterableDataset"),Xp.forEach(s),Jr=r(F,`.
`),ta=l(F,"A",{href:!0});var Zp=o(ta);Wr=r(Zp,"IterableDataset.map()"),Zp.forEach(s),Gr=r(F," applies processing on-the-fly when examples are streamed."),F.forEach(s),ol=f(e),la=l(e,"P",{});var ei=o(la);Kr=r(ei,"It allows you to apply a processing function to each example in a dataset, independently or in batches. This function can even create new rows and columns."),ei.forEach(s),pl=f(e),U=l(e,"P",{});var ua=o(U);Qr=r(ua,"The following example demonstrates how to tokenize a "),na=l(ua,"A",{href:!0});var si=o(na);Xr=r(si,"IterableDataset"),si.forEach(s),Zr=r(ua,". The function needs to accept and output a "),Wa=l(ua,"CODE",{});var ai=o(Wa);eo=r(ai,"dict"),ai.forEach(s),so=r(ua,":"),ua.forEach(s),il=f(e),v(ds.$$.fragment,e),hl=f(e),ze=l(e,"P",{});var Bl=o(ze);ao=r(Bl,"Next, apply this function to the dataset with "),ra=l(Bl,"A",{href:!0});var ti=o(ra);to=r(ti,"IterableDataset.map()"),ti.forEach(s),lo=r(Bl,":"),Bl.forEach(s),cl=f(e),v(ms.$$.fragment,e),fl=f(e),Ce=l(e,"P",{});var Jl=o(Ce);no=r(Jl,"Let\u2019s take a look at another example, except this time, you will remove a column with "),oa=l(Jl,"A",{href:!0});var li=o(oa);ro=r(li,"IterableDataset.map()"),li.forEach(s),oo=r(Jl,". When you remove a column, it is only removed after the example has been provided to the mapped function. This allows the mapped function to use the content of the columns before they are removed."),Jl.forEach(s),dl=f(e),B=l(e,"P",{});var ga=o(B);po=r(ga,"Specify the column to remove with the "),Ga=l(ga,"CODE",{});var ni=o(Ga);io=r(ni,"remove_columns"),ni.forEach(s),ho=r(ga," argument in "),pa=l(ga,"A",{href:!0});var ri=o(pa);co=r(ri,"IterableDataset.map()"),ri.forEach(s),fo=r(ga,":"),ga.forEach(s),ml=f(e),v(us.$$.fragment,e),ul=f(e),le=l(e,"H3",{class:!0});var Wl=o(le);Ne=l(Wl,"A",{id:!0,class:!0,href:!0});var oi=o(Ne);Ka=l(oi,"SPAN",{});var pi=o(Ka);v(gs.$$.fragment,pi),pi.forEach(s),oi.forEach(s),mo=f(Wl),Qa=l(Wl,"SPAN",{});var ii=o(Qa);uo=r(ii,"Batch processing"),ii.forEach(s),Wl.forEach(s),gl=f(e),R=l(e,"P",{});var Es=o(R);ia=l(Es,"A",{href:!0});var hi=o(ia);go=r(hi,"IterableDataset.map()"),hi.forEach(s),_o=r(Es," also supports working with batches of examples. Operate on batches by setting "),Xa=l(Es,"CODE",{});var ci=o(Xa);vo=r(ci,"batched=True"),ci.forEach(s),jo=r(Es,". The default batch size is 1000, but you can adjust it with the "),Za=l(Es,"CODE",{});var fi=o(Za);bo=r(fi,"batch_size"),fi.forEach(s),$o=r(Es," argument. This opens the door to many interesting applications such as tokenization, splitting long sentences into shorter chunks, and data augmentation."),Es.forEach(s),_l=f(e),ne=l(e,"H4",{class:!0});var Gl=o(ne);Me=l(Gl,"A",{id:!0,class:!0,href:!0});var di=o(Me);et=l(di,"SPAN",{});var mi=o(et);v(_s.$$.fragment,mi),mi.forEach(s),di.forEach(s),xo=f(Gl),st=l(Gl,"SPAN",{});var ui=o(st);wo=r(ui,"Tokenization"),ui.forEach(s),Gl.forEach(s),vl=f(e),v(vs.$$.fragment,e),jl=f(e),v(Le.$$.fragment,e),bl=f(e),re=l(e,"H3",{class:!0});var Kl=o(re);Oe=l(Kl,"A",{id:!0,class:!0,href:!0});var gi=o(Oe);at=l(gi,"SPAN",{});var _i=o(at);v(js.$$.fragment,_i),_i.forEach(s),gi.forEach(s),yo=f(Kl),tt=l(Kl,"SPAN",{});var vi=o(tt);ko=r(vi,"Filter"),vi.forEach(s),Kl.forEach(s),$l=f(e),Ve=l(e,"P",{});var Ql=o(Ve);Eo=r(Ql,"You can filter rows in the dataset based on a predicate function using "),ha=l(Ql,"A",{href:!0});var ji=o(ha);Do=r(ji,"Dataset.filter()"),ji.forEach(s),Ao=r(Ql,". It returns rows that match a specified condition:"),Ql.forEach(s),xl=f(e),v(bs.$$.fragment,e),wl=f(e),oe=l(e,"P",{});var mt=o(oe);ca=l(mt,"A",{href:!0});var bi=o(ca);Io=r(bi,"Dataset.filter()"),bi.forEach(s),To=r(mt," can also filter by indices if you set "),lt=l(mt,"CODE",{});var $i=o(lt);Po=r($i,"with_indices=True"),$i.forEach(s),qo=r(mt,":"),mt.forEach(s),yl=f(e),v($s.$$.fragment,e),kl=f(e),pe=l(e,"H2",{class:!0});var Xl=o(pe);Fe=l(Xl,"A",{id:!0,class:!0,href:!0});var xi=o(Fe);nt=l(xi,"SPAN",{});var wi=o(nt);v(xs.$$.fragment,wi),wi.forEach(s),xi.forEach(s),So=f(Xl),rt=l(Xl,"SPAN",{});var yi=o(rt);zo=r(yi,"Stream in a training loop"),yi.forEach(s),Xl.forEach(s),El=f(e),ws=l(e,"P",{});var Mo=o(ws);fa=l(Mo,"A",{href:!0});var ki=o(fa);Co=r(ki,"IterableDataset"),ki.forEach(s),No=r(Mo," can be integrated into a training loop. First, shuffle the dataset:"),Mo.forEach(s),Dl=f(e),v(Re.$$.fragment,e),this.h()},h(){h(d,"name","hf:doc:metadata"),h(d,"content",JSON.stringify(Hi)),h(y,"id","stream"),h(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(y,"href","#stream"),h(m,"class","relative group"),h(Ts,"class","block dark:hidden"),Ei(Ts.src,Lo="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming.gif")||h(Ts,"src",Lo),h(Ps,"class","hidden dark:block"),Ei(Ps.src,Oo="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming-dark.gif")||h(Ps,"src",Oo),h(J,"class","flex justify-center"),h(Be,"href","https://huggingface.co/datasets/oscar"),h(Be,"rel","nofollow"),h(qs,"href","/docs/datasets/v2.3.0/en/package_reference/loading_methods#datasets.load_dataset"),h(Ss,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.Dataset"),h(zs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset"),h(de,"id","shuffle"),h(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(de,"href","#shuffle"),h(W,"class","relative group"),h(Cs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.Dataset"),h(Ns,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset"),h(Ms,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(Ls,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle"),h(ue,"id","reshuffle"),h(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ue,"href","#reshuffle"),h(G,"class","relative group"),h(ve,"id","split-dataset"),h(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ve,"href","#split-dataset"),h(K,"class","relative group"),h(Fs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.take"),h(Hs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.skip"),h(Ys,"id","interleave_datasets"),h(xe,"id","interleave"),h(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(xe,"href","#interleave"),h(Q,"class","relative group"),h(Us,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.interleave_datasets"),h(Bs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset"),h(ye,"id","rename-remove-and-cast"),h(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ye,"href","#rename-remove-and-cast"),h(Z,"class","relative group"),h(ke,"id","rename"),h(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ke,"href","#rename"),h(ee,"class","relative group"),h(Ws,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.rename_column"),h(Gs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.rename_column"),h(Ae,"id","remove"),h(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ae,"href","#remove"),h(se,"class","relative group"),h(Ks,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.remove_columns"),h(Te,"id","cast"),h(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Te,"href","#cast"),h(ae,"class","relative group"),h(Qs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.cast"),h(Xs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.cast_column"),h(Se,"id","map"),h(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Se,"href","#map"),h(te,"class","relative group"),h(Zs,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.Dataset.map"),h(ea,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.Dataset"),h(sa,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.map"),h(aa,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset"),h(ta,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.map"),h(na,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset"),h(ra,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.map"),h(oa,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.map"),h(pa,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Ne,"id","batch-processing"),h(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ne,"href","#batch-processing"),h(le,"class","relative group"),h(ia,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset.map"),h(Me,"id","tokenization"),h(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Me,"href","#tokenization"),h(ne,"class","relative group"),h(Oe,"id","filter"),h(Oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Oe,"href","#filter"),h(re,"class","relative group"),h(ha,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.Dataset.filter"),h(ca,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.Dataset.filter"),h(Fe,"id","stream-in-a-training-loop"),h(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Fe,"href","#stream-in-a-training-loop"),h(pe,"class","relative group"),h(fa,"href","/docs/datasets/v2.3.0/en/package_reference/main_classes#datasets.IterableDataset")},m(e,p){a(document.head,d),i(e,w,p),i(e,m,p),a(m,y),a(y,k),j(g,k,null),a(m,E),a(m,u),a(u,D),i(e,A,p),i(e,T,p),a(T,N),i(e,he,p),i(e,z,p),a(z,P),a(P,Ds),a(z,As),a(z,ce),a(ce,Is),i(e,gt,p),i(e,J,p),a(J,Ts),a(J,Zl),a(J,Ps),i(e,_t,p),i(e,L,p),a(L,en),a(L,Be),a(Be,sn),a(L,an),a(L,_a),a(_a,tn),a(L,ln),a(L,qs),a(qs,nn),a(L,rn),i(e,vt,p),j(Je,e,p),i(e,jt,p),i(e,H,p),a(H,on),a(H,Ss),a(Ss,pn),a(H,hn),a(H,zs),a(zs,cn),a(H,fn),i(e,bt,p),j(fe,e,p),i(e,$t,p),i(e,W,p),a(W,de),a(de,va),j(We,va,null),a(W,dn),a(W,ja),a(ja,mn),i(e,xt,p),i(e,O,p),a(O,un),a(O,Cs),a(Cs,gn),a(O,_n),a(O,Ns),a(Ns,vn),a(O,jn),a(O,Ms),a(Ms,bn),a(O,$n),i(e,wt,p),i(e,V,p),a(V,xn),a(V,ba),a(ba,wn),a(V,yn),a(V,$a),a($a,kn),a(V,En),a(V,Ls),a(Ls,Dn),a(V,An),i(e,yt,p),j(Ge,e,p),i(e,kt,p),j(me,e,p),i(e,Et,p),i(e,G,p),a(G,ue),a(ue,xa),j(Ke,xa,null),a(G,In),a(G,wa),a(wa,Tn),i(e,Dt,p),i(e,ge,p),a(ge,Pn),a(ge,ya),a(ya,qn),a(ge,Sn),i(e,At,p),i(e,_e,p),a(_e,zn),a(_e,ka),a(ka,Cn),a(_e,Nn),i(e,It,p),j(Qe,e,p),i(e,Tt,p),i(e,K,p),a(K,ve),a(ve,Ea),j(Xe,Ea,null),a(K,Mn),a(K,Da),a(Da,Ln),i(e,Pt,p),i(e,Os,p),a(Os,On),i(e,qt,p),i(e,Vs,p),a(Vs,je),a(je,Fs),a(Fs,Vn),a(je,Fn),a(je,Aa),a(Aa,Rn),a(je,Hn),i(e,St,p),j(Ze,e,p),i(e,zt,p),i(e,Rs,p),a(Rs,be),a(be,Hs),a(Hs,Yn),a(be,Un),a(be,Ia),a(Ia,Bn),a(be,Jn),i(e,Ct,p),j(es,e,p),i(e,Nt,p),j($e,e,p),i(e,Mt,p),i(e,Ys,p),i(e,Lt,p),i(e,Q,p),a(Q,xe),a(xe,Ta),j(ss,Ta,null),a(Q,Wn),a(Q,Pa),a(Pa,Gn),i(e,Ot,p),i(e,X,p),a(X,Us),a(Us,Kn),a(X,Qn),a(X,Bs),a(Bs,Xn),a(X,Zn),i(e,Vt,p),j(as,e,p),i(e,Ft,p),i(e,we,p),a(we,er),a(we,qa),a(qa,sr),a(we,ar),i(e,Rt,p),j(ts,e,p),i(e,Ht,p),i(e,Y,p),a(Y,tr),a(Y,Sa),a(Sa,lr),a(Y,nr),a(Y,za),a(za,rr),a(Y,or),i(e,Yt,p),i(e,Z,p),a(Z,ye),a(ye,Ca),j(ls,Ca,null),a(Z,pr),a(Z,Na),a(Na,ir),i(e,Ut,p),i(e,Js,p),a(Js,hr),i(e,Bt,p),i(e,ee,p),a(ee,ke),a(ke,Ma),j(ns,Ma,null),a(ee,cr),a(ee,La),a(La,fr),i(e,Jt,p),i(e,Ee,p),a(Ee,dr),a(Ee,Ws),a(Ws,mr),a(Ee,ur),i(e,Wt,p),i(e,De,p),a(De,gr),a(De,Gs),a(Gs,_r),a(De,vr),i(e,Gt,p),j(rs,e,p),i(e,Kt,p),i(e,se,p),a(se,Ae),a(Ae,Oa),j(os,Oa,null),a(se,jr),a(se,Va),a(Va,br),i(e,Qt,p),i(e,Ie,p),a(Ie,$r),a(Ie,Ks),a(Ks,xr),a(Ie,wr),i(e,Xt,p),j(ps,e,p),i(e,Zt,p),i(e,ae,p),a(ae,Te),a(Te,Fa),j(is,Fa,null),a(ae,yr),a(ae,Ra),a(Ra,kr),i(e,el,p),i(e,M,p),a(M,Qs),a(Qs,Er),a(M,Dr),a(M,Ha),a(Ha,Ar),a(M,Ir),a(M,Ya),a(Ya,Tr),a(M,Pr),a(M,Ua),a(Ua,qr),a(M,Sr),i(e,sl,p),j(hs,e,p),i(e,al,p),j(Pe,e,p),i(e,tl,p),i(e,qe,p),a(qe,zr),a(qe,Xs),a(Xs,Cr),a(qe,Nr),i(e,ll,p),j(cs,e,p),i(e,nl,p),i(e,te,p),a(te,Se),a(Se,Ba),j(fs,Ba,null),a(te,Mr),a(te,Ja),a(Ja,Lr),i(e,rl,p),i(e,S,p),a(S,Or),a(S,Zs),a(Zs,Vr),a(S,Fr),a(S,ea),a(ea,Rr),a(S,Hr),a(S,sa),a(sa,Yr),a(S,Ur),a(S,aa),a(aa,Br),a(S,Jr),a(S,ta),a(ta,Wr),a(S,Gr),i(e,ol,p),i(e,la,p),a(la,Kr),i(e,pl,p),i(e,U,p),a(U,Qr),a(U,na),a(na,Xr),a(U,Zr),a(U,Wa),a(Wa,eo),a(U,so),i(e,il,p),j(ds,e,p),i(e,hl,p),i(e,ze,p),a(ze,ao),a(ze,ra),a(ra,to),a(ze,lo),i(e,cl,p),j(ms,e,p),i(e,fl,p),i(e,Ce,p),a(Ce,no),a(Ce,oa),a(oa,ro),a(Ce,oo),i(e,dl,p),i(e,B,p),a(B,po),a(B,Ga),a(Ga,io),a(B,ho),a(B,pa),a(pa,co),a(B,fo),i(e,ml,p),j(us,e,p),i(e,ul,p),i(e,le,p),a(le,Ne),a(Ne,Ka),j(gs,Ka,null),a(le,mo),a(le,Qa),a(Qa,uo),i(e,gl,p),i(e,R,p),a(R,ia),a(ia,go),a(R,_o),a(R,Xa),a(Xa,vo),a(R,jo),a(R,Za),a(Za,bo),a(R,$o),i(e,_l,p),i(e,ne,p),a(ne,Me),a(Me,et),j(_s,et,null),a(ne,xo),a(ne,st),a(st,wo),i(e,vl,p),j(vs,e,p),i(e,jl,p),j(Le,e,p),i(e,bl,p),i(e,re,p),a(re,Oe),a(Oe,at),j(js,at,null),a(re,yo),a(re,tt),a(tt,ko),i(e,$l,p),i(e,Ve,p),a(Ve,Eo),a(Ve,ha),a(ha,Do),a(Ve,Ao),i(e,xl,p),j(bs,e,p),i(e,wl,p),i(e,oe,p),a(oe,ca),a(ca,Io),a(oe,To),a(oe,lt),a(lt,Po),a(oe,qo),i(e,yl,p),j($s,e,p),i(e,kl,p),i(e,pe,p),a(pe,Fe),a(Fe,nt),j(xs,nt,null),a(pe,So),a(pe,rt),a(rt,zo),i(e,El,p),i(e,ws,p),a(ws,fa),a(fa,Co),a(ws,No),i(e,Dl,p),j(Re,e,p),Al=!0},p(e,[p]){const ys={};p&2&&(ys.$$scope={dirty:p,ctx:e}),fe.$set(ys);const ot={};p&2&&(ot.$$scope={dirty:p,ctx:e}),me.$set(ot);const pt={};p&2&&(pt.$$scope={dirty:p,ctx:e}),$e.$set(pt);const it={};p&2&&(it.$$scope={dirty:p,ctx:e}),Pe.$set(it);const ht={};p&2&&(ht.$$scope={dirty:p,ctx:e}),Le.$set(ht);const ks={};p&2&&(ks.$$scope={dirty:p,ctx:e}),Re.$set(ks)},i(e){Al||(b(g.$$.fragment,e),b(Je.$$.fragment,e),b(fe.$$.fragment,e),b(We.$$.fragment,e),b(Ge.$$.fragment,e),b(me.$$.fragment,e),b(Ke.$$.fragment,e),b(Qe.$$.fragment,e),b(Xe.$$.fragment,e),b(Ze.$$.fragment,e),b(es.$$.fragment,e),b($e.$$.fragment,e),b(ss.$$.fragment,e),b(as.$$.fragment,e),b(ts.$$.fragment,e),b(ls.$$.fragment,e),b(ns.$$.fragment,e),b(rs.$$.fragment,e),b(os.$$.fragment,e),b(ps.$$.fragment,e),b(is.$$.fragment,e),b(hs.$$.fragment,e),b(Pe.$$.fragment,e),b(cs.$$.fragment,e),b(fs.$$.fragment,e),b(ds.$$.fragment,e),b(ms.$$.fragment,e),b(us.$$.fragment,e),b(gs.$$.fragment,e),b(_s.$$.fragment,e),b(vs.$$.fragment,e),b(Le.$$.fragment,e),b(js.$$.fragment,e),b(bs.$$.fragment,e),b($s.$$.fragment,e),b(xs.$$.fragment,e),b(Re.$$.fragment,e),Al=!0)},o(e){$(g.$$.fragment,e),$(Je.$$.fragment,e),$(fe.$$.fragment,e),$(We.$$.fragment,e),$(Ge.$$.fragment,e),$(me.$$.fragment,e),$(Ke.$$.fragment,e),$(Qe.$$.fragment,e),$(Xe.$$.fragment,e),$(Ze.$$.fragment,e),$(es.$$.fragment,e),$($e.$$.fragment,e),$(ss.$$.fragment,e),$(as.$$.fragment,e),$(ts.$$.fragment,e),$(ls.$$.fragment,e),$(ns.$$.fragment,e),$(rs.$$.fragment,e),$(os.$$.fragment,e),$(ps.$$.fragment,e),$(is.$$.fragment,e),$(hs.$$.fragment,e),$(Pe.$$.fragment,e),$(cs.$$.fragment,e),$(fs.$$.fragment,e),$(ds.$$.fragment,e),$(ms.$$.fragment,e),$(us.$$.fragment,e),$(gs.$$.fragment,e),$(_s.$$.fragment,e),$(vs.$$.fragment,e),$(Le.$$.fragment,e),$(js.$$.fragment,e),$(bs.$$.fragment,e),$($s.$$.fragment,e),$(xs.$$.fragment,e),$(Re.$$.fragment,e),Al=!1},d(e){s(d),e&&s(w),e&&s(m),x(g),e&&s(A),e&&s(T),e&&s(he),e&&s(z),e&&s(gt),e&&s(J),e&&s(_t),e&&s(L),e&&s(vt),x(Je,e),e&&s(jt),e&&s(H),e&&s(bt),x(fe,e),e&&s($t),e&&s(W),x(We),e&&s(xt),e&&s(O),e&&s(wt),e&&s(V),e&&s(yt),x(Ge,e),e&&s(kt),x(me,e),e&&s(Et),e&&s(G),x(Ke),e&&s(Dt),e&&s(ge),e&&s(At),e&&s(_e),e&&s(It),x(Qe,e),e&&s(Tt),e&&s(K),x(Xe),e&&s(Pt),e&&s(Os),e&&s(qt),e&&s(Vs),e&&s(St),x(Ze,e),e&&s(zt),e&&s(Rs),e&&s(Ct),x(es,e),e&&s(Nt),x($e,e),e&&s(Mt),e&&s(Ys),e&&s(Lt),e&&s(Q),x(ss),e&&s(Ot),e&&s(X),e&&s(Vt),x(as,e),e&&s(Ft),e&&s(we),e&&s(Rt),x(ts,e),e&&s(Ht),e&&s(Y),e&&s(Yt),e&&s(Z),x(ls),e&&s(Ut),e&&s(Js),e&&s(Bt),e&&s(ee),x(ns),e&&s(Jt),e&&s(Ee),e&&s(Wt),e&&s(De),e&&s(Gt),x(rs,e),e&&s(Kt),e&&s(se),x(os),e&&s(Qt),e&&s(Ie),e&&s(Xt),x(ps,e),e&&s(Zt),e&&s(ae),x(is),e&&s(el),e&&s(M),e&&s(sl),x(hs,e),e&&s(al),x(Pe,e),e&&s(tl),e&&s(qe),e&&s(ll),x(cs,e),e&&s(nl),e&&s(te),x(fs),e&&s(rl),e&&s(S),e&&s(ol),e&&s(la),e&&s(pl),e&&s(U),e&&s(il),x(ds,e),e&&s(hl),e&&s(ze),e&&s(cl),x(ms,e),e&&s(fl),e&&s(Ce),e&&s(dl),e&&s(B),e&&s(ml),x(us,e),e&&s(ul),e&&s(le),x(gs),e&&s(gl),e&&s(R),e&&s(_l),e&&s(ne),x(_s),e&&s(vl),x(vs,e),e&&s(jl),x(Le,e),e&&s(bl),e&&s(re),x(js),e&&s($l),e&&s(Ve),e&&s(xl),x(bs,e),e&&s(wl),e&&s(oe),e&&s(yl),x($s,e),e&&s(kl),e&&s(pe),x(xs),e&&s(El),e&&s(ws),e&&s(Dl),x(Re,e)}}}const Hi={local:"stream",sections:[{local:"shuffle",title:"Shuffle"},{local:"reshuffle",title:"Reshuffle"},{local:"split-dataset",title:"Split dataset"},{local:"interleave",title:"Interleave"},{local:"rename-remove-and-cast",sections:[{local:"rename",title:"Rename"},{local:"remove",title:"Remove"},{local:"cast",title:"Cast"}],title:"Rename, remove, and cast"},{local:"map",sections:[{local:"batch-processing",sections:[{local:"tokenization",title:"Tokenization"}],title:"Batch processing"},{local:"filter",title:"Filter"}],title:"Map"},{local:"stream-in-a-training-loop",title:"Stream in a training loop"}],title:"Stream"};function Yi(q){return Pi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Qi extends Di{constructor(d){super();Ai(this,d,Yi,Ri,Ii,{})}}export{Qi as default,Hi as metadata};
