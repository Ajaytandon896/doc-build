import{S as zl,i as Nl,s as Il,e as r,k as i,w as m,t as n,M as Ul,c as o,d as a,m as d,a as p,x as u,h as l,b as c,G as t,g as h,y as f,q as g,o as j,B as y,v as Fl}from"../chunks/vendor-hf-doc-builder.js";import{T as Bl}from"../chunks/Tip-hf-doc-builder.js";import{I as M}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../chunks/CodeBlock-hf-doc-builder.js";function Hl(Oa){let _,Y,b,k,O;return{c(){_=r("p"),Y=n("A "),b=r("a"),k=n("Dataset"),O=n(" object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),this.h()},l(w){_=o(w,"P",{});var P=p(_);Y=l(P,"A "),b=o(P,"A",{href:!0});var G=p(b);k=l(G,"Dataset"),G.forEach(a),O=l(P," object is a wrapper of an Arrow table, which allows fast zero-copy reads from arrays in the dataset to PyTorch tensors."),P.forEach(a),this.h()},h(){c(b,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset")},m(w,P){h(w,_,P),t(_,Y),t(_,b),t(b,k),t(_,O)},d(w){w&&a(_)}}}function Rl(Oa){let _,Y,b,k,O,w,P,G,It,za,v,Ut,Js,Ft,Bt,Ks,Ht,Rt,Qs,Mt,Yt,Vs,Gt,Wt,Na,z,W,Xs,ds,Jt,Zs,Kt,Ia,Cs,Qt,Ua,T,Vt,sa,Xt,Zt,Os,se,ae,Fa,cs,Ba,J,Ha,K,te,aa,ee,ne,Ra,ms,Ma,N,Q,ta,us,le,ea,re,Ya,zs,oe,Ga,fs,Wa,V,pe,na,he,ie,Ja,gs,Ka,I,X,la,js,de,ra,ce,Qa,ys,Ns,me,ue,Va,_s,Xa,Z,fe,oa,ge,je,Za,bs,st,A,ye,Is,_e,be,Us,ve,we,at,U,ss,pa,vs,$e,ha,ke,tt,E,Ee,ia,De,qe,Fs,xe,Pe,da,Te,Ae,et,ws,nt,F,as,ca,$s,Le,ma,Se,lt,Bs,Ce,rt,B,ts,ua,ks,Oe,fa,ze,ot,L,Ne,ga,Ie,Ue,ja,Fe,Be,pt,D,He,ya,Re,Me,_a,Ye,Ge,ba,We,Je,ht,Es,it,H,es,va,Ds,Ke,wa,Qe,dt,ns,Ve,$a,Xe,Ze,ct,qs,mt,Hs,sn,ut,xs,ft,S,an,ka,tn,en,Ea,nn,ln,gt,Ps,jt,q,rn,Da,on,pn,qa,hn,dn,xa,cn,mn,yt,R,ls,Pa,Ts,un,Ta,fn,_t,x,gn,Aa,jn,yn,La,_n,bn,Sa,vn,wn,bt,As,vt,rs,$n,Ca,kn,En,wt,Ls,$t,Rs,Dn,kt;return w=new M({}),ds=new M({}),cs=new $({props:{code:`from datasets import Dataset
data = [[1, 2],[3, 4]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("torch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}`}}),J=new Bl({props:{$$slots:{default:[Hl]},$$scope:{ctx:Oa}}}),ms=new $({props:{code:`import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ds = ds.with_format("torch", device=device)
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>, device=device)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)}`}}),us=new M({}),fs=new $({props:{code:`from datasets import Dataset
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
ds = Dataset.from_dict({"data": data})
ds = ds.with_format("torch")
ds[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: [tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]), tensor([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]}`}}),gs=new $({props:{code:`from datasets import Dataset, Features, Array2D
data = [[[1, 2],[3, 4]],[[5, 6],[7, 8]]]
features = Features({"data": Array2D(shape=(2, 2), dtype='int32')})
ds = Dataset.from_dict({"data": data}, features=features)
ds = ds.with_format("torch")
ds[0]
ds[:2]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, Array2D
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],[[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: Array2D(shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=<span class="hljs-string">&#x27;int32&#x27;</span>)})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
         [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])}
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],
          [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],
 
         [[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],
          [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]])}`}}),js=new M({}),_s=new $({props:{code:`from datasets import Dataset, Features, ClassLabel
data = [0, 0, 1]
features = Features({"data": ClassLabel(names=["negative", "positive"])})
ds = Dataset.from_dict({"data": data}, features=features) 
ds = ds.with_format("torch")  
ds[:3]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features, ClassLabel
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>features = Features({<span class="hljs-string">&quot;data&quot;</span>: ClassLabel(names=[<span class="hljs-string">&quot;negative&quot;</span>, <span class="hljs-string">&quot;positive&quot;</span>])})
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}, features=features) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>)  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">3</span>]
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}`}}),bs=new $({props:{code:`from datasets import Dataset, Features 
text = ["foo", "bar"]
data = [0, 1] 
ds = Dataset.from_dict({"text": text, "data": data})  
ds = ds.with_format("torch", columns=["data"], output_all_columns=True) 
ds[:2]                                                                                                                                                     `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, Features 
<span class="hljs-meta">&gt;&gt;&gt; </span>text = [<span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot;bar&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>data = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;text&quot;</span>: text, <span class="hljs-string">&quot;data&quot;</span>: data})  
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.with_format(<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;data&quot;</span>], output_all_columns=<span class="hljs-literal">True</span>) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ds[:<span class="hljs-number">2</span>]                                                                                                                                                     
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]), <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;foo&#x27;</span>, <span class="hljs-string">&#x27;bar&#x27;</span>]}`}}),vs=new M({}),ws=new $({props:{code:`import numpy as np
from datasets import Dataset 
from torch.utils.data import DataLoader
data = np.random.rand(16)
label = np.random.randint(0, 2, size=16)
ds = Dataset.from_dict({"data": data, "label": label}).with_format("torch")
dataloader = DataLoader(ds, batch_size=4)
for batch in dataloader:
    print(batch)                                                                                            `,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset 
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>label = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=<span class="hljs-number">16</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data, <span class="hljs-string">&quot;label&quot;</span>: label}).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(batch)                                                                                            
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.0047</span>, <span class="hljs-number">0.4979</span>, <span class="hljs-number">0.6726</span>, <span class="hljs-number">0.8105</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.4832</span>, <span class="hljs-number">0.2723</span>, <span class="hljs-number">0.4259</span>, <span class="hljs-number">0.2224</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.5837</span>, <span class="hljs-number">0.3444</span>, <span class="hljs-number">0.4658</span>, <span class="hljs-number">0.6417</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])}
{<span class="hljs-string">&#x27;data&#x27;</span>: tensor([<span class="hljs-number">0.7022</span>, <span class="hljs-number">0.1225</span>, <span class="hljs-number">0.7228</span>, <span class="hljs-number">0.8259</span>]), <span class="hljs-string">&#x27;label&#x27;</span>: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`}}),$s=new M({}),ks=new M({}),Es=new $({props:{code:`import numpy as np
from datasets import Dataset, load_from_disk
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).save_to_disk("my_dataset")
ds = load_from_disk("my_dataset").with_format("torch")
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_from_disk
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).save_to_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_from_disk(<span class="hljs-string">&quot;my_dataset&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),Ds=new M({}),qs=new $({props:{code:"batch = [dataset[idx] for idx in range(start, end)]",highlighted:'batch = [dataset[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end)]'}}),xs=new $({props:{code:`batch = dataset[start:end]
# or
batch = dataset[list_of_indices]`,highlighted:`batch = dataset[start:end]
<span class="hljs-comment"># or</span>
batch = dataset[list_of_indices]`}}),Ps=new $({props:{code:`from torch.utils.data.sampler import BatchSampler, RandomSampler
sampler = BatchSampler(RandomSampler(ds), batch_size=32, drop_last=False)
dataloader = DataLoader(ds, sampler=sampler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data.sampler <span class="hljs-keyword">import</span> BatchSampler, RandomSampler
<span class="hljs-meta">&gt;&gt;&gt; </span>sampler = BatchSampler(RandomSampler(ds), batch_size=<span class="hljs-number">32</span>, drop_last=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, sampler=sampler)`}}),Ts=new M({}),As=new $({props:{code:`import numpy as np
from datasets import Dataset, load_dataset
from torch.utils.data import DataLoader
data = np.random.rand(10_000)
Dataset.from_dict({"data": data}).push_to_hub("<username>/my_dataset")  # Upload to the Hugging Face Hub
ds = load_dataset("<username>/my_dataset", streaming=True, split="train").with_format("torch")
dataloader = DataLoader(ds, batch_size=32)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset, load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-meta">&gt;&gt;&gt; </span>data = np.random.rand(<span class="hljs-number">10_000</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Dataset.from_dict({<span class="hljs-string">&quot;data&quot;</span>: data}).push_to_hub(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>)  <span class="hljs-comment"># Upload to the Hugging Face Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;&lt;username&gt;/my_dataset&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>)`}}),Ls=new $({props:{code:`ds = load_dataset("c4", "en", streaming=True, split="train").with_format("torch")
ds.n_shards
dataloader = DataLoader(ds, batch_size=32, num_workers=4)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;c4&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>, streaming=<span class="hljs-literal">True</span>, split=<span class="hljs-string">&quot;train&quot;</span>).with_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds.n_shards
<span class="hljs-number">1024</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(ds, batch_size=<span class="hljs-number">32</span>, num_workers=<span class="hljs-number">4</span>)`}}),{c(){_=r("meta"),Y=i(),b=r("h1"),k=r("a"),O=r("span"),m(w.$$.fragment),P=i(),G=r("span"),It=n("Use with PyTorch"),za=i(),v=r("p"),Ut=n("This document is a quick introduction to using "),Js=r("code"),Ft=n("datasets"),Bt=n(` with PyTorch, with a particular focus on how to get
`),Ks=r("code"),Ht=n("torch.Tensor"),Rt=n(" objects out of our datasets, and how to use a PyTorch "),Qs=r("code"),Mt=n("DataLoader"),Yt=n(" and a Hugging Face "),Vs=r("code"),Gt=n("Dataset"),Wt=n(`
with the best performance.`),Na=i(),z=r("h2"),W=r("a"),Xs=r("span"),m(ds.$$.fragment),Jt=i(),Zs=r("span"),Kt=n("Dataset format"),Ia=i(),Cs=r("p"),Qt=n("By default, datasets return regular python objects: integers, floats, strings, lists, etc."),Ua=i(),T=r("p"),Vt=n("To get PyTorch tensors instead, you can set the format of the dataset to "),sa=r("code"),Xt=n("pytorch"),Zt=n(" using "),Os=r("a"),se=n("Dataset.with_format()"),ae=n(":"),Fa=i(),m(cs.$$.fragment),Ba=i(),m(J.$$.fragment),Ha=i(),K=r("p"),te=n("To load the data as tensors on a GPU, specify the "),aa=r("code"),ee=n("device"),ne=n(" argument:"),Ra=i(),m(ms.$$.fragment),Ma=i(),N=r("h2"),Q=r("a"),ta=r("span"),m(us.$$.fragment),le=i(),ea=r("span"),re=n("N-dimensional arrays"),Ya=i(),zs=r("p"),oe=n(`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of a single tensor:`),Ga=i(),m(fs.$$.fragment),Wa=i(),V=r("p"),pe=n("To get a single tensor, you must explicitly use the "),na=r("code"),he=n("Array"),ie=n(" feature type and specify the shape of your tensors:"),Ja=i(),m(gs.$$.fragment),Ka=i(),I=r("h2"),X=r("a"),la=r("span"),m(js.$$.fragment),de=i(),ra=r("span"),ce=n("Other feature types"),Qa=i(),ys=r("p"),Ns=r("a"),me=n("ClassLabel"),ue=n(" data are properly converted to tensors:"),Va=i(),m(_s.$$.fragment),Xa=i(),Z=r("p"),fe=n("However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),oa=r("code"),ge=n("string"),je=n(` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Za=i(),m(bs.$$.fragment),st=i(),A=r("p"),ye=n("The "),Is=r("a"),_e=n("Image"),be=n(" and "),Us=r("a"),ve=n("Audio"),we=n(" feature types are not supported yet."),at=i(),U=r("h2"),ss=r("a"),pa=r("span"),m(vs.$$.fragment),$e=i(),ha=r("span"),ke=n("Data loading"),tt=i(),E=r("p"),Ee=n("Like "),ia=r("code"),De=n("torch.utils.data.Dataset"),qe=n(" objects, a "),Fs=r("a"),xe=n("Dataset"),Pe=n(" can be passed directly to a PyTorch "),da=r("code"),Te=n("DataLoader"),Ae=n(":"),et=i(),m(ws.$$.fragment),nt=i(),F=r("h3"),as=r("a"),ca=r("span"),m($s.$$.fragment),Le=i(),ma=r("span"),Se=n("Optimize data loading"),lt=i(),Bs=r("p"),Ce=n(`There are several ways you can increase the speed your data is loaded which can save you time, especially if you are working with large datasets.
PyTorch offers parallelized data loading, retrieving batches of indices instead of individually, and streaming to progressively download datasets.`),rt=i(),B=r("h4"),ts=r("a"),ua=r("span"),m(ks.$$.fragment),Oe=i(),fa=r("span"),ze=n("Use multiple Workers"),ot=i(),L=r("p"),Ne=n("You can parallelize data loading with the "),ga=r("code"),Ie=n("num_workers"),Ue=n(" argument of a PyTorch "),ja=r("code"),Fe=n("DataLoader"),Be=n(" and get a higher throughput."),pt=i(),D=r("p"),He=n("Under the hood, the "),ya=r("code"),Re=n("DataLoader"),Me=n(" starts "),_a=r("code"),Ye=n("num_workers"),Ge=n(` processes.
Each process reloads the dataset passed to the `),ba=r("code"),We=n("DataLoader"),Je=n(` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-maps the dataset again from your disk.`),ht=i(),m(Es.$$.fragment),it=i(),H=r("h4"),es=r("a"),va=r("span"),m(Ds.$$.fragment),Ke=i(),wa=r("span"),Qe=n("Use a BatchSampler"),dt=i(),ns=r("p"),Ve=n("By default, the PyTorch "),$a=r("code"),Xe=n("DataLoader"),Ze=n(" load batches of data from a dataset one by one like this:"),ct=i(),m(qs.$$.fragment),mt=i(),Hs=r("p"),sn=n(`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),ut=i(),m(xs.$$.fragment),ft=i(),S=r("p"),an=n("For the PyTorch "),ka=r("code"),tn=n("DataLoader"),en=n(" to query batches using a list, you can use a "),Ea=r("code"),nn=n("BatchSampler"),ln=n(":"),gt=i(),m(Ps.$$.fragment),jt=i(),q=r("p"),rn=n("Moreover, this is particularly useful if you used "),Da=r("code"),on=n("set_transform"),pn=n(` to apply a transform on-the-fly when examples are accessed.
You must use a `),qa=r("code"),hn=n("BatchSampler"),dn=n(" if you want the transform to be given full batches instead of receiving "),xa=r("code"),cn=n("batch_size"),mn=n(" times one single element."),yt=i(),R=r("h3"),ls=r("a"),Pa=r("span"),m(Ts.$$.fragment),un=i(),Ta=r("span"),fn=n("Stream data"),_t=i(),x=r("p"),gn=n(`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to `),Aa=r("code"),jn=n("torch"),yn=n(", and it inherits from "),La=r("code"),_n=n("torch.utils.data.IterableDataset"),bn=n(" so you can pass it to a "),Sa=r("code"),vn=n("DataLoader"),wn=n(":"),bt=i(),m(As.$$.fragment),vt=i(),rs=r("p"),$n=n("If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),Ca=r("code"),kn=n("num_workers"),En=n(":"),wt=i(),m(Ls.$$.fragment),$t=i(),Rs=r("p"),Dn=n("In this case each worker will be given a subset of the list of shards to stream from."),this.h()},l(s){const e=Ul('[data-svelte="svelte-1phssyn"]',document.head);_=o(e,"META",{name:!0,content:!0}),e.forEach(a),Y=d(s),b=o(s,"H1",{class:!0});var Ss=p(b);k=o(Ss,"A",{id:!0,class:!0,href:!0});var xn=p(k);O=o(xn,"SPAN",{});var Pn=p(O);u(w.$$.fragment,Pn),Pn.forEach(a),xn.forEach(a),P=d(Ss),G=o(Ss,"SPAN",{});var Tn=p(G);It=l(Tn,"Use with PyTorch"),Tn.forEach(a),Ss.forEach(a),za=d(s),v=o(s,"P",{});var C=p(v);Ut=l(C,"This document is a quick introduction to using "),Js=o(C,"CODE",{});var An=p(Js);Ft=l(An,"datasets"),An.forEach(a),Bt=l(C,` with PyTorch, with a particular focus on how to get
`),Ks=o(C,"CODE",{});var Ln=p(Ks);Ht=l(Ln,"torch.Tensor"),Ln.forEach(a),Rt=l(C," objects out of our datasets, and how to use a PyTorch "),Qs=o(C,"CODE",{});var Sn=p(Qs);Mt=l(Sn,"DataLoader"),Sn.forEach(a),Yt=l(C," and a Hugging Face "),Vs=o(C,"CODE",{});var Cn=p(Vs);Gt=l(Cn,"Dataset"),Cn.forEach(a),Wt=l(C,`
with the best performance.`),C.forEach(a),Na=d(s),z=o(s,"H2",{class:!0});var Et=p(z);W=o(Et,"A",{id:!0,class:!0,href:!0});var On=p(W);Xs=o(On,"SPAN",{});var zn=p(Xs);u(ds.$$.fragment,zn),zn.forEach(a),On.forEach(a),Jt=d(Et),Zs=o(Et,"SPAN",{});var Nn=p(Zs);Kt=l(Nn,"Dataset format"),Nn.forEach(a),Et.forEach(a),Ia=d(s),Cs=o(s,"P",{});var In=p(Cs);Qt=l(In,"By default, datasets return regular python objects: integers, floats, strings, lists, etc."),In.forEach(a),Ua=d(s),T=o(s,"P",{});var Ms=p(T);Vt=l(Ms,"To get PyTorch tensors instead, you can set the format of the dataset to "),sa=o(Ms,"CODE",{});var Un=p(sa);Xt=l(Un,"pytorch"),Un.forEach(a),Zt=l(Ms," using "),Os=o(Ms,"A",{href:!0});var Fn=p(Os);se=l(Fn,"Dataset.with_format()"),Fn.forEach(a),ae=l(Ms,":"),Ms.forEach(a),Fa=d(s),u(cs.$$.fragment,s),Ba=d(s),u(J.$$.fragment,s),Ha=d(s),K=o(s,"P",{});var Dt=p(K);te=l(Dt,"To load the data as tensors on a GPU, specify the "),aa=o(Dt,"CODE",{});var Bn=p(aa);ee=l(Bn,"device"),Bn.forEach(a),ne=l(Dt," argument:"),Dt.forEach(a),Ra=d(s),u(ms.$$.fragment,s),Ma=d(s),N=o(s,"H2",{class:!0});var qt=p(N);Q=o(qt,"A",{id:!0,class:!0,href:!0});var Hn=p(Q);ta=o(Hn,"SPAN",{});var Rn=p(ta);u(us.$$.fragment,Rn),Rn.forEach(a),Hn.forEach(a),le=d(qt),ea=o(qt,"SPAN",{});var Mn=p(ea);re=l(Mn,"N-dimensional arrays"),Mn.forEach(a),qt.forEach(a),Ya=d(s),zs=o(s,"P",{});var Yn=p(zs);oe=l(Yn,`If your dataset consists of N-dimensional arrays, you will see that by default they are considered as nested lists.
In particular, a PyTorch formatted dataset outputs nested lists instead of a single tensor:`),Yn.forEach(a),Ga=d(s),u(fs.$$.fragment,s),Wa=d(s),V=o(s,"P",{});var xt=p(V);pe=l(xt,"To get a single tensor, you must explicitly use the "),na=o(xt,"CODE",{});var Gn=p(na);he=l(Gn,"Array"),Gn.forEach(a),ie=l(xt," feature type and specify the shape of your tensors:"),xt.forEach(a),Ja=d(s),u(gs.$$.fragment,s),Ka=d(s),I=o(s,"H2",{class:!0});var Pt=p(I);X=o(Pt,"A",{id:!0,class:!0,href:!0});var Wn=p(X);la=o(Wn,"SPAN",{});var Jn=p(la);u(js.$$.fragment,Jn),Jn.forEach(a),Wn.forEach(a),de=d(Pt),ra=o(Pt,"SPAN",{});var Kn=p(ra);ce=l(Kn,"Other feature types"),Kn.forEach(a),Pt.forEach(a),Qa=d(s),ys=o(s,"P",{});var qn=p(ys);Ns=o(qn,"A",{href:!0});var Qn=p(Ns);me=l(Qn,"ClassLabel"),Qn.forEach(a),ue=l(qn," data are properly converted to tensors:"),qn.forEach(a),Va=d(s),u(_s.$$.fragment,s),Xa=d(s),Z=o(s,"P",{});var Tt=p(Z);fe=l(Tt,"However, since it\u2019s not possible to convert text data to PyTorch tensors, you can\u2019t format a "),oa=o(Tt,"CODE",{});var Vn=p(oa);ge=l(Vn,"string"),Vn.forEach(a),je=l(Tt,` column to PyTorch.
Instead, you can explicitly format certain columns and leave the other columns unformatted:`),Tt.forEach(a),Za=d(s),u(bs.$$.fragment,s),st=d(s),A=o(s,"P",{});var Ys=p(A);ye=l(Ys,"The "),Is=o(Ys,"A",{href:!0});var Xn=p(Is);_e=l(Xn,"Image"),Xn.forEach(a),be=l(Ys," and "),Us=o(Ys,"A",{href:!0});var Zn=p(Us);ve=l(Zn,"Audio"),Zn.forEach(a),we=l(Ys," feature types are not supported yet."),Ys.forEach(a),at=d(s),U=o(s,"H2",{class:!0});var At=p(U);ss=o(At,"A",{id:!0,class:!0,href:!0});var sl=p(ss);pa=o(sl,"SPAN",{});var al=p(pa);u(vs.$$.fragment,al),al.forEach(a),sl.forEach(a),$e=d(At),ha=o(At,"SPAN",{});var tl=p(ha);ke=l(tl,"Data loading"),tl.forEach(a),At.forEach(a),tt=d(s),E=o(s,"P",{});var os=p(E);Ee=l(os,"Like "),ia=o(os,"CODE",{});var el=p(ia);De=l(el,"torch.utils.data.Dataset"),el.forEach(a),qe=l(os," objects, a "),Fs=o(os,"A",{href:!0});var nl=p(Fs);xe=l(nl,"Dataset"),nl.forEach(a),Pe=l(os," can be passed directly to a PyTorch "),da=o(os,"CODE",{});var ll=p(da);Te=l(ll,"DataLoader"),ll.forEach(a),Ae=l(os,":"),os.forEach(a),et=d(s),u(ws.$$.fragment,s),nt=d(s),F=o(s,"H3",{class:!0});var Lt=p(F);as=o(Lt,"A",{id:!0,class:!0,href:!0});var rl=p(as);ca=o(rl,"SPAN",{});var ol=p(ca);u($s.$$.fragment,ol),ol.forEach(a),rl.forEach(a),Le=d(Lt),ma=o(Lt,"SPAN",{});var pl=p(ma);Se=l(pl,"Optimize data loading"),pl.forEach(a),Lt.forEach(a),lt=d(s),Bs=o(s,"P",{});var hl=p(Bs);Ce=l(hl,`There are several ways you can increase the speed your data is loaded which can save you time, especially if you are working with large datasets.
PyTorch offers parallelized data loading, retrieving batches of indices instead of individually, and streaming to progressively download datasets.`),hl.forEach(a),rt=d(s),B=o(s,"H4",{class:!0});var St=p(B);ts=o(St,"A",{id:!0,class:!0,href:!0});var il=p(ts);ua=o(il,"SPAN",{});var dl=p(ua);u(ks.$$.fragment,dl),dl.forEach(a),il.forEach(a),Oe=d(St),fa=o(St,"SPAN",{});var cl=p(fa);ze=l(cl,"Use multiple Workers"),cl.forEach(a),St.forEach(a),ot=d(s),L=o(s,"P",{});var Gs=p(L);Ne=l(Gs,"You can parallelize data loading with the "),ga=o(Gs,"CODE",{});var ml=p(ga);Ie=l(ml,"num_workers"),ml.forEach(a),Ue=l(Gs," argument of a PyTorch "),ja=o(Gs,"CODE",{});var ul=p(ja);Fe=l(ul,"DataLoader"),ul.forEach(a),Be=l(Gs," and get a higher throughput."),Gs.forEach(a),pt=d(s),D=o(s,"P",{});var ps=p(D);He=l(ps,"Under the hood, the "),ya=o(ps,"CODE",{});var fl=p(ya);Re=l(fl,"DataLoader"),fl.forEach(a),Me=l(ps," starts "),_a=o(ps,"CODE",{});var gl=p(_a);Ye=l(gl,"num_workers"),gl.forEach(a),Ge=l(ps,` processes.
Each process reloads the dataset passed to the `),ba=o(ps,"CODE",{});var jl=p(ba);We=l(jl,"DataLoader"),jl.forEach(a),Je=l(ps,` and is used to query examples.
Reloading the dataset inside a worker doesn\u2019t fill up your RAM, since it simply memory-maps the dataset again from your disk.`),ps.forEach(a),ht=d(s),u(Es.$$.fragment,s),it=d(s),H=o(s,"H4",{class:!0});var Ct=p(H);es=o(Ct,"A",{id:!0,class:!0,href:!0});var yl=p(es);va=o(yl,"SPAN",{});var _l=p(va);u(Ds.$$.fragment,_l),_l.forEach(a),yl.forEach(a),Ke=d(Ct),wa=o(Ct,"SPAN",{});var bl=p(wa);Qe=l(bl,"Use a BatchSampler"),bl.forEach(a),Ct.forEach(a),dt=d(s),ns=o(s,"P",{});var Ot=p(ns);Ve=l(Ot,"By default, the PyTorch "),$a=o(Ot,"CODE",{});var vl=p($a);Xe=l(vl,"DataLoader"),vl.forEach(a),Ze=l(Ot," load batches of data from a dataset one by one like this:"),Ot.forEach(a),ct=d(s),u(qs.$$.fragment,s),mt=d(s),Hs=o(s,"P",{});var wl=p(Hs);sn=l(wl,`Unfortunately, this does numerous read operations on the dataset.
It is more efficient to query batches of examples using a list:`),wl.forEach(a),ut=d(s),u(xs.$$.fragment,s),ft=d(s),S=o(s,"P",{});var Ws=p(S);an=l(Ws,"For the PyTorch "),ka=o(Ws,"CODE",{});var $l=p(ka);tn=l($l,"DataLoader"),$l.forEach(a),en=l(Ws," to query batches using a list, you can use a "),Ea=o(Ws,"CODE",{});var kl=p(Ea);nn=l(kl,"BatchSampler"),kl.forEach(a),ln=l(Ws,":"),Ws.forEach(a),gt=d(s),u(Ps.$$.fragment,s),jt=d(s),q=o(s,"P",{});var hs=p(q);rn=l(hs,"Moreover, this is particularly useful if you used "),Da=o(hs,"CODE",{});var El=p(Da);on=l(El,"set_transform"),El.forEach(a),pn=l(hs,` to apply a transform on-the-fly when examples are accessed.
You must use a `),qa=o(hs,"CODE",{});var Dl=p(qa);hn=l(Dl,"BatchSampler"),Dl.forEach(a),dn=l(hs," if you want the transform to be given full batches instead of receiving "),xa=o(hs,"CODE",{});var ql=p(xa);cn=l(ql,"batch_size"),ql.forEach(a),mn=l(hs," times one single element."),hs.forEach(a),yt=d(s),R=o(s,"H3",{class:!0});var zt=p(R);ls=o(zt,"A",{id:!0,class:!0,href:!0});var xl=p(ls);Pa=o(xl,"SPAN",{});var Pl=p(Pa);u(Ts.$$.fragment,Pl),Pl.forEach(a),xl.forEach(a),un=d(zt),Ta=o(zt,"SPAN",{});var Tl=p(Ta);fn=l(Tl,"Stream data"),Tl.forEach(a),zt.forEach(a),_t=d(s),x=o(s,"P",{});var is=p(x);gn=l(is,`Loading a dataset in streaming mode is useful to progressively download the data you need while iterating over the dataset.
Set the format of a streaming dataset to `),Aa=o(is,"CODE",{});var Al=p(Aa);jn=l(Al,"torch"),Al.forEach(a),yn=l(is,", and it inherits from "),La=o(is,"CODE",{});var Ll=p(La);_n=l(Ll,"torch.utils.data.IterableDataset"),Ll.forEach(a),bn=l(is," so you can pass it to a "),Sa=o(is,"CODE",{});var Sl=p(Sa);vn=l(Sl,"DataLoader"),Sl.forEach(a),wn=l(is,":"),is.forEach(a),bt=d(s),u(As.$$.fragment,s),vt=d(s),rs=o(s,"P",{});var Nt=p(rs);$n=l(Nt,"If the dataset is split in several shards (i.e. if the dataset consists of multiple data files), then you can stream in parallel using "),Ca=o(Nt,"CODE",{});var Cl=p(Ca);kn=l(Cl,"num_workers"),Cl.forEach(a),En=l(Nt,":"),Nt.forEach(a),wt=d(s),u(Ls.$$.fragment,s),$t=d(s),Rs=o(s,"P",{});var Ol=p(Rs);Dn=l(Ol,"In this case each worker will be given a subset of the list of shards to stream from."),Ol.forEach(a),this.h()},h(){c(_,"name","hf:doc:metadata"),c(_,"content",JSON.stringify(Ml)),c(k,"id","use-with-pytorch"),c(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k,"href","#use-with-pytorch"),c(b,"class","relative group"),c(W,"id","dataset-format"),c(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W,"href","#dataset-format"),c(z,"class","relative group"),c(Os,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.with_format"),c(Q,"id","ndimensional-arrays"),c(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q,"href","#ndimensional-arrays"),c(N,"class","relative group"),c(X,"id","other-feature-types"),c(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X,"href","#other-feature-types"),c(I,"class","relative group"),c(Ns,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.ClassLabel"),c(Is,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Image"),c(Us,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Audio"),c(ss,"id","data-loading"),c(ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ss,"href","#data-loading"),c(U,"class","relative group"),c(Fs,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset"),c(as,"id","optimize-data-loading"),c(as,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(as,"href","#optimize-data-loading"),c(F,"class","relative group"),c(ts,"id","use-multiple-workers"),c(ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ts,"href","#use-multiple-workers"),c(B,"class","relative group"),c(es,"id","use-a-batchsampler"),c(es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(es,"href","#use-a-batchsampler"),c(H,"class","relative group"),c(ls,"id","stream-data"),c(ls,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ls,"href","#stream-data"),c(R,"class","relative group")},m(s,e){t(document.head,_),h(s,Y,e),h(s,b,e),t(b,k),t(k,O),f(w,O,null),t(b,P),t(b,G),t(G,It),h(s,za,e),h(s,v,e),t(v,Ut),t(v,Js),t(Js,Ft),t(v,Bt),t(v,Ks),t(Ks,Ht),t(v,Rt),t(v,Qs),t(Qs,Mt),t(v,Yt),t(v,Vs),t(Vs,Gt),t(v,Wt),h(s,Na,e),h(s,z,e),t(z,W),t(W,Xs),f(ds,Xs,null),t(z,Jt),t(z,Zs),t(Zs,Kt),h(s,Ia,e),h(s,Cs,e),t(Cs,Qt),h(s,Ua,e),h(s,T,e),t(T,Vt),t(T,sa),t(sa,Xt),t(T,Zt),t(T,Os),t(Os,se),t(T,ae),h(s,Fa,e),f(cs,s,e),h(s,Ba,e),f(J,s,e),h(s,Ha,e),h(s,K,e),t(K,te),t(K,aa),t(aa,ee),t(K,ne),h(s,Ra,e),f(ms,s,e),h(s,Ma,e),h(s,N,e),t(N,Q),t(Q,ta),f(us,ta,null),t(N,le),t(N,ea),t(ea,re),h(s,Ya,e),h(s,zs,e),t(zs,oe),h(s,Ga,e),f(fs,s,e),h(s,Wa,e),h(s,V,e),t(V,pe),t(V,na),t(na,he),t(V,ie),h(s,Ja,e),f(gs,s,e),h(s,Ka,e),h(s,I,e),t(I,X),t(X,la),f(js,la,null),t(I,de),t(I,ra),t(ra,ce),h(s,Qa,e),h(s,ys,e),t(ys,Ns),t(Ns,me),t(ys,ue),h(s,Va,e),f(_s,s,e),h(s,Xa,e),h(s,Z,e),t(Z,fe),t(Z,oa),t(oa,ge),t(Z,je),h(s,Za,e),f(bs,s,e),h(s,st,e),h(s,A,e),t(A,ye),t(A,Is),t(Is,_e),t(A,be),t(A,Us),t(Us,ve),t(A,we),h(s,at,e),h(s,U,e),t(U,ss),t(ss,pa),f(vs,pa,null),t(U,$e),t(U,ha),t(ha,ke),h(s,tt,e),h(s,E,e),t(E,Ee),t(E,ia),t(ia,De),t(E,qe),t(E,Fs),t(Fs,xe),t(E,Pe),t(E,da),t(da,Te),t(E,Ae),h(s,et,e),f(ws,s,e),h(s,nt,e),h(s,F,e),t(F,as),t(as,ca),f($s,ca,null),t(F,Le),t(F,ma),t(ma,Se),h(s,lt,e),h(s,Bs,e),t(Bs,Ce),h(s,rt,e),h(s,B,e),t(B,ts),t(ts,ua),f(ks,ua,null),t(B,Oe),t(B,fa),t(fa,ze),h(s,ot,e),h(s,L,e),t(L,Ne),t(L,ga),t(ga,Ie),t(L,Ue),t(L,ja),t(ja,Fe),t(L,Be),h(s,pt,e),h(s,D,e),t(D,He),t(D,ya),t(ya,Re),t(D,Me),t(D,_a),t(_a,Ye),t(D,Ge),t(D,ba),t(ba,We),t(D,Je),h(s,ht,e),f(Es,s,e),h(s,it,e),h(s,H,e),t(H,es),t(es,va),f(Ds,va,null),t(H,Ke),t(H,wa),t(wa,Qe),h(s,dt,e),h(s,ns,e),t(ns,Ve),t(ns,$a),t($a,Xe),t(ns,Ze),h(s,ct,e),f(qs,s,e),h(s,mt,e),h(s,Hs,e),t(Hs,sn),h(s,ut,e),f(xs,s,e),h(s,ft,e),h(s,S,e),t(S,an),t(S,ka),t(ka,tn),t(S,en),t(S,Ea),t(Ea,nn),t(S,ln),h(s,gt,e),f(Ps,s,e),h(s,jt,e),h(s,q,e),t(q,rn),t(q,Da),t(Da,on),t(q,pn),t(q,qa),t(qa,hn),t(q,dn),t(q,xa),t(xa,cn),t(q,mn),h(s,yt,e),h(s,R,e),t(R,ls),t(ls,Pa),f(Ts,Pa,null),t(R,un),t(R,Ta),t(Ta,fn),h(s,_t,e),h(s,x,e),t(x,gn),t(x,Aa),t(Aa,jn),t(x,yn),t(x,La),t(La,_n),t(x,bn),t(x,Sa),t(Sa,vn),t(x,wn),h(s,bt,e),f(As,s,e),h(s,vt,e),h(s,rs,e),t(rs,$n),t(rs,Ca),t(Ca,kn),t(rs,En),h(s,wt,e),f(Ls,s,e),h(s,$t,e),h(s,Rs,e),t(Rs,Dn),kt=!0},p(s,[e]){const Ss={};e&2&&(Ss.$$scope={dirty:e,ctx:s}),J.$set(Ss)},i(s){kt||(g(w.$$.fragment,s),g(ds.$$.fragment,s),g(cs.$$.fragment,s),g(J.$$.fragment,s),g(ms.$$.fragment,s),g(us.$$.fragment,s),g(fs.$$.fragment,s),g(gs.$$.fragment,s),g(js.$$.fragment,s),g(_s.$$.fragment,s),g(bs.$$.fragment,s),g(vs.$$.fragment,s),g(ws.$$.fragment,s),g($s.$$.fragment,s),g(ks.$$.fragment,s),g(Es.$$.fragment,s),g(Ds.$$.fragment,s),g(qs.$$.fragment,s),g(xs.$$.fragment,s),g(Ps.$$.fragment,s),g(Ts.$$.fragment,s),g(As.$$.fragment,s),g(Ls.$$.fragment,s),kt=!0)},o(s){j(w.$$.fragment,s),j(ds.$$.fragment,s),j(cs.$$.fragment,s),j(J.$$.fragment,s),j(ms.$$.fragment,s),j(us.$$.fragment,s),j(fs.$$.fragment,s),j(gs.$$.fragment,s),j(js.$$.fragment,s),j(_s.$$.fragment,s),j(bs.$$.fragment,s),j(vs.$$.fragment,s),j(ws.$$.fragment,s),j($s.$$.fragment,s),j(ks.$$.fragment,s),j(Es.$$.fragment,s),j(Ds.$$.fragment,s),j(qs.$$.fragment,s),j(xs.$$.fragment,s),j(Ps.$$.fragment,s),j(Ts.$$.fragment,s),j(As.$$.fragment,s),j(Ls.$$.fragment,s),kt=!1},d(s){a(_),s&&a(Y),s&&a(b),y(w),s&&a(za),s&&a(v),s&&a(Na),s&&a(z),y(ds),s&&a(Ia),s&&a(Cs),s&&a(Ua),s&&a(T),s&&a(Fa),y(cs,s),s&&a(Ba),y(J,s),s&&a(Ha),s&&a(K),s&&a(Ra),y(ms,s),s&&a(Ma),s&&a(N),y(us),s&&a(Ya),s&&a(zs),s&&a(Ga),y(fs,s),s&&a(Wa),s&&a(V),s&&a(Ja),y(gs,s),s&&a(Ka),s&&a(I),y(js),s&&a(Qa),s&&a(ys),s&&a(Va),y(_s,s),s&&a(Xa),s&&a(Z),s&&a(Za),y(bs,s),s&&a(st),s&&a(A),s&&a(at),s&&a(U),y(vs),s&&a(tt),s&&a(E),s&&a(et),y(ws,s),s&&a(nt),s&&a(F),y($s),s&&a(lt),s&&a(Bs),s&&a(rt),s&&a(B),y(ks),s&&a(ot),s&&a(L),s&&a(pt),s&&a(D),s&&a(ht),y(Es,s),s&&a(it),s&&a(H),y(Ds),s&&a(dt),s&&a(ns),s&&a(ct),y(qs,s),s&&a(mt),s&&a(Hs),s&&a(ut),y(xs,s),s&&a(ft),s&&a(S),s&&a(gt),y(Ps,s),s&&a(jt),s&&a(q),s&&a(yt),s&&a(R),y(Ts),s&&a(_t),s&&a(x),s&&a(bt),y(As,s),s&&a(vt),s&&a(rs),s&&a(wt),y(Ls,s),s&&a($t),s&&a(Rs)}}}const Ml={local:"use-with-pytorch",sections:[{local:"dataset-format",title:"Dataset format"},{local:"ndimensional-arrays",title:"N-dimensional arrays"},{local:"other-feature-types",title:"Other feature types"},{local:"data-loading",sections:[{local:"optimize-data-loading",sections:[{local:"use-multiple-workers",title:"Use multiple Workers"},{local:"use-a-batchsampler",title:"Use a BatchSampler"}],title:"Optimize data loading"},{local:"stream-data",title:"Stream data"}],title:"Data loading"}],title:"Use with PyTorch"};function Yl(Oa){return Fl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ql extends zl{constructor(_){super();Nl(this,_,Yl,Rl,Il,{})}}export{Ql as default,Ml as metadata};
