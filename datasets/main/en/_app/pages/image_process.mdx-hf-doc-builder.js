import{S as $s,i as ws,s as bs,e as s,k as f,w as k,t as o,M as js,c as r,d as t,m as c,a as n,x as E,h as l,b as m,N as ys,G as a,g as p,y as x,q as A,o as P,B as T,v as ks}from"../chunks/vendor-hf-doc-builder.js";import{T as Es}from"../chunks/Tip-hf-doc-builder.js";import{I as Bt}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Te}from"../chunks/CodeBlock-hf-doc-builder.js";function xs(Ge){let h,N,u,v,C,d,Y,D,y,B,w;return{c(){h=s("p"),N=o("Feel free to use other data augmentation libraries like "),u=s("a"),v=o("Albumentations"),C=o(", "),d=s("a"),Y=o("Kornia"),D=o(", and "),y=s("a"),B=o("imgaug"),w=o("."),this.h()},l(q){h=r(q,"P",{});var g=n(h);N=l(g,"Feel free to use other data augmentation libraries like "),u=r(g,"A",{href:!0,rel:!0});var $=n(u);v=l($,"Albumentations"),$.forEach(t),C=l(g,", "),d=r(g,"A",{href:!0,rel:!0});var b=n(d);Y=l(b,"Kornia"),b.forEach(t),D=l(g,", and "),y=r(g,"A",{href:!0,rel:!0});var ue=n(y);B=l(ue,"imgaug"),ue.forEach(t),w=l(g,"."),g.forEach(t),this.h()},h(){m(u,"href","https://albumentations.ai/docs/"),m(u,"rel","nofollow"),m(d,"href","https://kornia.readthedocs.io/en/latest/"),m(d,"rel","nofollow"),m(y,"href","https://imgaug.readthedocs.io/en/latest/"),m(y,"rel","nofollow")},m(q,g){p(q,h,g),a(h,N),a(h,u),a(u,v),a(h,C),a(h,d),a(d,Y),a(h,D),a(h,y),a(y,B),a(h,w)},d(q){q&&t(h)}}}function As(Ge){let h,N,u,v,C,d,Y,D,y,B,w,q,g,$,b,ue,de,Da,qa,Ia,Z,za,ge,La,Na,Me,J,Ba,ee,Ja,Oa,Ue,I,O,Ce,ae,Sa,De,Ra,He,S,Fa,_e,Ga,Ma,Ke,R,Ua,te,qe,Ha,Ka,Ve,se,Qe,_,Va,ve,Qa,Wa,Ie,Xa,Ya,ze,Za,et,Le,at,tt,We,re,Xe,F,st,ye,rt,ot,Ye,oe,$e,lt,nt,Ze,G,we,be,Ne,it,pt,mt,je,ke,Be,ft,ct,ea,M,ht,Ee,ut,dt,aa,z,U,Je,le,gt,Oe,_t,ta,H,vt,ne,yt,$t,sa,K,ra,V,wt,ie,Se,bt,jt,oa,pe,la,Q,kt,Re,Et,xt,na,me,ia,W,At,xe,Pt,Tt,pa,fe,ma,X,Ct,Fe,Dt,qt,fa,ce,ca,L,Ae,Jt,It,Pe,Ot,ha;return d=new Bt({}),ae=new Bt({}),se=new Te({props:{code:`def transforms(examples):
    examples["pixel_values"] = [image.convert("RGB").resize((100,100)) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [image.convert(<span class="hljs-string">&quot;RGB&quot;</span>).resize((<span class="hljs-number">100</span>,<span class="hljs-number">100</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),re=new Te({props:{code:`dataset = dataset.map(transforms, remove_columns=["image"], batched=True)
dataset[0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(transforms, remove_columns=[<span class="hljs-string">&quot;image&quot;</span>], batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">6</span>,
 <span class="hljs-string">&#x27;pixel_values&#x27;</span>: &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=100x100 at <span class="hljs-number">0x7F058237BB10</span>&gt;}`}}),le=new Bt({}),K=new Es({props:{$$slots:{default:[xs]},$$scope:{ctx:Ge}}}),pe=new Te({props:{code:`from torchvision.transforms import Compose, ColorJitter, ToTensor

jitter = Compose(
    [
         ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.7),
         ToTensor(),
    ]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>         ColorJitter(brightness=<span class="hljs-number">0.25</span>, contrast=<span class="hljs-number">0.25</span>, saturation=<span class="hljs-number">0.25</span>, hue=<span class="hljs-number">0.7</span>),
<span class="hljs-meta">... </span>         ToTensor(),
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)`}}),me=new Te({props:{code:`def transforms(examples):
    examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),fe=new Te({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),ce=new Te({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset[0]["pixel_values"]
plt.imshow(img.permute(1, 2, 0))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`}}),{c(){h=s("meta"),N=f(),u=s("h1"),v=s("a"),C=s("span"),k(d.$$.fragment),Y=f(),D=s("span"),y=o("Process image data"),B=f(),w=s("p"),q=o("This guide shows specific methods for processing image datasets. Learn how to:"),g=f(),$=s("ul"),b=s("li"),ue=o("Use "),de=s("a"),Da=o("map()"),qa=o(" with image dataset."),Ia=f(),Z=s("li"),za=o("Apply data augmentations to your dataset with "),ge=s("a"),La=o("set_transform()"),Na=o("."),Me=f(),J=s("p"),Ba=o("For a guide on how to process any type of dataset, take a look at the "),ee=s("a"),Ja=o("general process guide"),Oa=o("."),Ue=f(),I=s("h2"),O=s("a"),Ce=s("span"),k(ae.$$.fragment),Sa=f(),De=s("span"),Ra=o("Map"),He=f(),S=s("p"),Fa=o("The "),_e=s("a"),Ga=o("map()"),Ma=o(" function can apply transforms over an entire dataset."),Ke=f(),R=s("p"),Ua=o("For example, create a basic "),te=s("a"),qe=s("code"),Ha=o("Resize"),Ka=o(" function:"),Ve=f(),k(se.$$.fragment),Qe=f(),_=s("p"),Va=o("Now use the "),ve=s("a"),Qa=o("map()"),Wa=o(" function to resize the entire dataset, and set "),Ie=s("code"),Xa=o("batched=True"),Ya=o(" to speed up the process by accepting batches of examples. The transform returns "),ze=s("code"),Za=o("pixel_values"),et=o(" as a cacheable "),Le=s("code"),at=o("PIL.Image"),tt=o(" object:"),We=f(),k(re.$$.fragment),Xe=f(),F=s("p"),st=o("The cache file saves time because you don\u2019t have to execute the same transform twice. The "),ye=s("a"),rt=o("map()"),ot=o(" function is best for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),Ye=f(),oe=s("p"),$e=s("a"),lt=o("map()"),nt=o(" takes up some memory, but you can reduce its memory requirements with the following parameters:"),Ze=f(),G=s("ul"),we=s("li"),be=s("a"),Ne=s("code"),it=o("batch_size"),pt=o(" determines the number of examples that are processed in one call to the transform function."),mt=f(),je=s("li"),ke=s("a"),Be=s("code"),ft=o("writer_batch_size"),ct=o(" determines the number of processed examples that are kept in memory before they are stored away."),ea=f(),M=s("p"),ht=o("Both parameter values default to 1000, which can be expensive if you are storing images. Lower these values to use less memory when you use "),Ee=s("a"),ut=o("map()"),dt=o("."),aa=f(),z=s("h2"),U=s("a"),Je=s("span"),k(le.$$.fragment),gt=f(),Oe=s("span"),_t=o("Data augmentation"),ta=f(),H=s("p"),vt=o("\u{1F917} Datasets can apply data augmentations from any library or package to your dataset. This guide will use the transforms from "),ne=s("a"),yt=o("torchvision"),$t=o("."),sa=f(),k(K.$$.fragment),ra=f(),V=s("p"),wt=o("As an example, try to apply a "),ie=s("a"),Se=s("code"),bt=o("ColorJitter"),jt=o(" transform to change the color properties of the image randomly:"),oa=f(),k(pe.$$.fragment),la=f(),Q=s("p"),kt=o("Create a function to apply the "),Re=s("code"),Et=o("ColorJitter"),xt=o(" transform to an image:"),na=f(),k(me.$$.fragment),ia=f(),W=s("p"),At=o("Use the "),xe=s("a"),Pt=o("set_transform()"),Tt=o(" function to apply the transform on-the-fly which consumes less disk space. This function is useful if you only need to access the examples once:"),pa=f(),k(fe.$$.fragment),ma=f(),X=s("p"),Ct=o("Now you can take a look at the augmented image by indexing into the "),Fe=s("code"),Dt=o("pixel_values"),qt=o(":"),fa=f(),k(ce.$$.fragment),ca=f(),L=s("div"),Ae=s("img"),It=f(),Pe=s("img"),this.h()},l(e){const i=js('[data-svelte="svelte-1phssyn"]',document.head);h=r(i,"META",{name:!0,content:!0}),i.forEach(t),N=c(e),u=r(e,"H1",{class:!0});var he=n(u);v=r(he,"A",{id:!0,class:!0,href:!0});var St=n(v);C=r(St,"SPAN",{});var Rt=n(C);E(d.$$.fragment,Rt),Rt.forEach(t),St.forEach(t),Y=c(he),D=r(he,"SPAN",{});var Ft=n(D);y=l(Ft,"Process image data"),Ft.forEach(t),he.forEach(t),B=c(e),w=r(e,"P",{});var Gt=n(w);q=l(Gt,"This guide shows specific methods for processing image datasets. Learn how to:"),Gt.forEach(t),g=c(e),$=r(e,"UL",{});var ua=n($);b=r(ua,"LI",{});var da=n(b);ue=l(da,"Use "),de=r(da,"A",{href:!0});var Mt=n(de);Da=l(Mt,"map()"),Mt.forEach(t),qa=l(da," with image dataset."),da.forEach(t),Ia=c(ua),Z=r(ua,"LI",{});var ga=n(Z);za=l(ga,"Apply data augmentations to your dataset with "),ge=r(ga,"A",{href:!0});var Ut=n(ge);La=l(Ut,"set_transform()"),Ut.forEach(t),Na=l(ga,"."),ga.forEach(t),ua.forEach(t),Me=c(e),J=r(e,"P",{});var _a=n(J);Ba=l(_a,"For a guide on how to process any type of dataset, take a look at the "),ee=r(_a,"A",{class:!0,href:!0});var Ht=n(ee);Ja=l(Ht,"general process guide"),Ht.forEach(t),Oa=l(_a,"."),_a.forEach(t),Ue=c(e),I=r(e,"H2",{class:!0});var va=n(I);O=r(va,"A",{id:!0,class:!0,href:!0});var Kt=n(O);Ce=r(Kt,"SPAN",{});var Vt=n(Ce);E(ae.$$.fragment,Vt),Vt.forEach(t),Kt.forEach(t),Sa=c(va),De=r(va,"SPAN",{});var Qt=n(De);Ra=l(Qt,"Map"),Qt.forEach(t),va.forEach(t),He=c(e),S=r(e,"P",{});var ya=n(S);Fa=l(ya,"The "),_e=r(ya,"A",{href:!0});var Wt=n(_e);Ga=l(Wt,"map()"),Wt.forEach(t),Ma=l(ya," function can apply transforms over an entire dataset."),ya.forEach(t),Ke=c(e),R=r(e,"P",{});var $a=n(R);Ua=l($a,"For example, create a basic "),te=r($a,"A",{href:!0,rel:!0});var Xt=n(te);qe=r(Xt,"CODE",{});var Yt=n(qe);Ha=l(Yt,"Resize"),Yt.forEach(t),Xt.forEach(t),Ka=l($a," function:"),$a.forEach(t),Ve=c(e),E(se.$$.fragment,e),Qe=c(e),_=r(e,"P",{});var j=n(_);Va=l(j,"Now use the "),ve=r(j,"A",{href:!0});var Zt=n(ve);Qa=l(Zt,"map()"),Zt.forEach(t),Wa=l(j," function to resize the entire dataset, and set "),Ie=r(j,"CODE",{});var es=n(Ie);Xa=l(es,"batched=True"),es.forEach(t),Ya=l(j," to speed up the process by accepting batches of examples. The transform returns "),ze=r(j,"CODE",{});var as=n(ze);Za=l(as,"pixel_values"),as.forEach(t),et=l(j," as a cacheable "),Le=r(j,"CODE",{});var ts=n(Le);at=l(ts,"PIL.Image"),ts.forEach(t),tt=l(j," object:"),j.forEach(t),We=c(e),E(re.$$.fragment,e),Xe=c(e),F=r(e,"P",{});var wa=n(F);st=l(wa,"The cache file saves time because you don\u2019t have to execute the same transform twice. The "),ye=r(wa,"A",{href:!0});var ss=n(ye);rt=l(ss,"map()"),ss.forEach(t),ot=l(wa," function is best for operations you only run once per training - like resizing an image - instead of using it for operations executed for each epoch, like data augmentations."),wa.forEach(t),Ye=c(e),oe=r(e,"P",{});var zt=n(oe);$e=r(zt,"A",{href:!0});var rs=n($e);lt=l(rs,"map()"),rs.forEach(t),nt=l(zt," takes up some memory, but you can reduce its memory requirements with the following parameters:"),zt.forEach(t),Ze=c(e),G=r(e,"UL",{});var ba=n(G);we=r(ba,"LI",{});var Lt=n(we);be=r(Lt,"A",{href:!0});var os=n(be);Ne=r(os,"CODE",{});var ls=n(Ne);it=l(ls,"batch_size"),ls.forEach(t),os.forEach(t),pt=l(Lt," determines the number of examples that are processed in one call to the transform function."),Lt.forEach(t),mt=c(ba),je=r(ba,"LI",{});var Nt=n(je);ke=r(Nt,"A",{href:!0});var ns=n(ke);Be=r(ns,"CODE",{});var is=n(Be);ft=l(is,"writer_batch_size"),is.forEach(t),ns.forEach(t),ct=l(Nt," determines the number of processed examples that are kept in memory before they are stored away."),Nt.forEach(t),ba.forEach(t),ea=c(e),M=r(e,"P",{});var ja=n(M);ht=l(ja,"Both parameter values default to 1000, which can be expensive if you are storing images. Lower these values to use less memory when you use "),Ee=r(ja,"A",{href:!0});var ps=n(Ee);ut=l(ps,"map()"),ps.forEach(t),dt=l(ja,"."),ja.forEach(t),aa=c(e),z=r(e,"H2",{class:!0});var ka=n(z);U=r(ka,"A",{id:!0,class:!0,href:!0});var ms=n(U);Je=r(ms,"SPAN",{});var fs=n(Je);E(le.$$.fragment,fs),fs.forEach(t),ms.forEach(t),gt=c(ka),Oe=r(ka,"SPAN",{});var cs=n(Oe);_t=l(cs,"Data augmentation"),cs.forEach(t),ka.forEach(t),ta=c(e),H=r(e,"P",{});var Ea=n(H);vt=l(Ea,"\u{1F917} Datasets can apply data augmentations from any library or package to your dataset. This guide will use the transforms from "),ne=r(Ea,"A",{href:!0,rel:!0});var hs=n(ne);yt=l(hs,"torchvision"),hs.forEach(t),$t=l(Ea,"."),Ea.forEach(t),sa=c(e),E(K.$$.fragment,e),ra=c(e),V=r(e,"P",{});var xa=n(V);wt=l(xa,"As an example, try to apply a "),ie=r(xa,"A",{href:!0,rel:!0});var us=n(ie);Se=r(us,"CODE",{});var ds=n(Se);bt=l(ds,"ColorJitter"),ds.forEach(t),us.forEach(t),jt=l(xa," transform to change the color properties of the image randomly:"),xa.forEach(t),oa=c(e),E(pe.$$.fragment,e),la=c(e),Q=r(e,"P",{});var Aa=n(Q);kt=l(Aa,"Create a function to apply the "),Re=r(Aa,"CODE",{});var gs=n(Re);Et=l(gs,"ColorJitter"),gs.forEach(t),xt=l(Aa," transform to an image:"),Aa.forEach(t),na=c(e),E(me.$$.fragment,e),ia=c(e),W=r(e,"P",{});var Pa=n(W);At=l(Pa,"Use the "),xe=r(Pa,"A",{href:!0});var _s=n(xe);Pt=l(_s,"set_transform()"),_s.forEach(t),Tt=l(Pa," function to apply the transform on-the-fly which consumes less disk space. This function is useful if you only need to access the examples once:"),Pa.forEach(t),pa=c(e),E(fe.$$.fragment,e),ma=c(e),X=r(e,"P",{});var Ta=n(X);Ct=l(Ta,"Now you can take a look at the augmented image by indexing into the "),Fe=r(Ta,"CODE",{});var vs=n(Fe);Dt=l(vs,"pixel_values"),vs.forEach(t),qt=l(Ta,":"),Ta.forEach(t),fa=c(e),E(ce.$$.fragment,e),ca=c(e),L=r(e,"DIV",{class:!0});var Ca=n(L);Ae=r(Ca,"IMG",{class:!0,src:!0}),It=c(Ca),Pe=r(Ca,"IMG",{class:!0,src:!0}),Ca.forEach(t),this.h()},h(){m(h,"name","hf:doc:metadata"),m(h,"content",JSON.stringify(Ps)),m(v,"id","process-image-data"),m(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(v,"href","#process-image-data"),m(u,"class","relative group"),m(de,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),m(ge,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.set_transform"),m(ee,"class","underline decoration-sky-400 decoration-2 font-semibold"),m(ee,"href","./process"),m(O,"id","map"),m(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(O,"href","#map"),m(I,"class","relative group"),m(_e,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),m(te,"href","https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html"),m(te,"rel","nofollow"),m(ve,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),m(ye,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),m($e,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),m(be,"href","./package_reference/main_classes#datasets.DatasetDict.map.batch_size"),m(ke,"href","./package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size"),m(Ee,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),m(U,"id","data-augmentation"),m(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(U,"href","#data-augmentation"),m(z,"class","relative group"),m(ne,"href","https://pytorch.org/vision/stable/transforms.html"),m(ne,"rel","nofollow"),m(ie,"href","https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ColorJitter"),m(ie,"rel","nofollow"),m(xe,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.set_transform"),m(Ae,"class","block dark:hidden"),ys(Ae.src,Jt="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_jitter.png")||m(Ae,"src",Jt),m(Pe,"class","hidden dark:block"),ys(Pe.src,Ot="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_process_jitter.png")||m(Pe,"src",Ot),m(L,"class","flex justify-center")},m(e,i){a(document.head,h),p(e,N,i),p(e,u,i),a(u,v),a(v,C),x(d,C,null),a(u,Y),a(u,D),a(D,y),p(e,B,i),p(e,w,i),a(w,q),p(e,g,i),p(e,$,i),a($,b),a(b,ue),a(b,de),a(de,Da),a(b,qa),a($,Ia),a($,Z),a(Z,za),a(Z,ge),a(ge,La),a(Z,Na),p(e,Me,i),p(e,J,i),a(J,Ba),a(J,ee),a(ee,Ja),a(J,Oa),p(e,Ue,i),p(e,I,i),a(I,O),a(O,Ce),x(ae,Ce,null),a(I,Sa),a(I,De),a(De,Ra),p(e,He,i),p(e,S,i),a(S,Fa),a(S,_e),a(_e,Ga),a(S,Ma),p(e,Ke,i),p(e,R,i),a(R,Ua),a(R,te),a(te,qe),a(qe,Ha),a(R,Ka),p(e,Ve,i),x(se,e,i),p(e,Qe,i),p(e,_,i),a(_,Va),a(_,ve),a(ve,Qa),a(_,Wa),a(_,Ie),a(Ie,Xa),a(_,Ya),a(_,ze),a(ze,Za),a(_,et),a(_,Le),a(Le,at),a(_,tt),p(e,We,i),x(re,e,i),p(e,Xe,i),p(e,F,i),a(F,st),a(F,ye),a(ye,rt),a(F,ot),p(e,Ye,i),p(e,oe,i),a(oe,$e),a($e,lt),a(oe,nt),p(e,Ze,i),p(e,G,i),a(G,we),a(we,be),a(be,Ne),a(Ne,it),a(we,pt),a(G,mt),a(G,je),a(je,ke),a(ke,Be),a(Be,ft),a(je,ct),p(e,ea,i),p(e,M,i),a(M,ht),a(M,Ee),a(Ee,ut),a(M,dt),p(e,aa,i),p(e,z,i),a(z,U),a(U,Je),x(le,Je,null),a(z,gt),a(z,Oe),a(Oe,_t),p(e,ta,i),p(e,H,i),a(H,vt),a(H,ne),a(ne,yt),a(H,$t),p(e,sa,i),x(K,e,i),p(e,ra,i),p(e,V,i),a(V,wt),a(V,ie),a(ie,Se),a(Se,bt),a(V,jt),p(e,oa,i),x(pe,e,i),p(e,la,i),p(e,Q,i),a(Q,kt),a(Q,Re),a(Re,Et),a(Q,xt),p(e,na,i),x(me,e,i),p(e,ia,i),p(e,W,i),a(W,At),a(W,xe),a(xe,Pt),a(W,Tt),p(e,pa,i),x(fe,e,i),p(e,ma,i),p(e,X,i),a(X,Ct),a(X,Fe),a(Fe,Dt),a(X,qt),p(e,fa,i),x(ce,e,i),p(e,ca,i),p(e,L,i),a(L,Ae),a(L,It),a(L,Pe),ha=!0},p(e,[i]){const he={};i&2&&(he.$$scope={dirty:i,ctx:e}),K.$set(he)},i(e){ha||(A(d.$$.fragment,e),A(ae.$$.fragment,e),A(se.$$.fragment,e),A(re.$$.fragment,e),A(le.$$.fragment,e),A(K.$$.fragment,e),A(pe.$$.fragment,e),A(me.$$.fragment,e),A(fe.$$.fragment,e),A(ce.$$.fragment,e),ha=!0)},o(e){P(d.$$.fragment,e),P(ae.$$.fragment,e),P(se.$$.fragment,e),P(re.$$.fragment,e),P(le.$$.fragment,e),P(K.$$.fragment,e),P(pe.$$.fragment,e),P(me.$$.fragment,e),P(fe.$$.fragment,e),P(ce.$$.fragment,e),ha=!1},d(e){t(h),e&&t(N),e&&t(u),T(d),e&&t(B),e&&t(w),e&&t(g),e&&t($),e&&t(Me),e&&t(J),e&&t(Ue),e&&t(I),T(ae),e&&t(He),e&&t(S),e&&t(Ke),e&&t(R),e&&t(Ve),T(se,e),e&&t(Qe),e&&t(_),e&&t(We),T(re,e),e&&t(Xe),e&&t(F),e&&t(Ye),e&&t(oe),e&&t(Ze),e&&t(G),e&&t(ea),e&&t(M),e&&t(aa),e&&t(z),T(le),e&&t(ta),e&&t(H),e&&t(sa),T(K,e),e&&t(ra),e&&t(V),e&&t(oa),T(pe,e),e&&t(la),e&&t(Q),e&&t(na),T(me,e),e&&t(ia),e&&t(W),e&&t(pa),T(fe,e),e&&t(ma),e&&t(X),e&&t(fa),T(ce,e),e&&t(ca),e&&t(L)}}}const Ps={local:"process-image-data",sections:[{local:"map",title:"Map"},{local:"data-augmentation",title:"Data augmentation"}],title:"Process image data"};function Ts(Ge){return ks(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class zs extends $s{constructor(h){super();ws(this,h,Ts,As,bs,{})}}export{zs as default,Ps as metadata};
