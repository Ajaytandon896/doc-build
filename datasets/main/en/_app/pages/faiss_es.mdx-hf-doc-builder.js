import{S as St,i as Pt,s as Lt,e as n,k as c,w as m,t as i,M as At,c as l,d as e,m as h,a as r,x as u,h as p,b as d,G as a,g as o,y as _,L as It,q as f,o as g,B as x,v as Rt}from"../chunks/vendor-hf-doc-builder.js";import{I as Ta}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as q}from"../chunks/CodeBlock-hf-doc-builder.js";function zt(Fa){let j,Us,w,D,Ls,I,Oe,As,Te,Ws,v,R,Fe,Qe,z,Ne,Be,Ys,_s,Me,Gs,y,S,Is,C,He,Rs,Ue,Js,P,We,O,Ye,Ge,Ks,fs,zs,Je,Vs,T,Xs,F,Cs,Ke,Zs,Q,se,N,B,Ve,gs,Xe,Ze,ee,M,ae,H,$,sa,Os,ea,aa,xs,ta,na,te,U,ne,W,E,la,qs,ra,oa,Ts,ia,pa,le,Y,re,G,J,da,js,ca,ha,oe,K,ie,V,X,ma,ws,ua,_a,pe,Z,de,b,L,Fs,ss,fa,Qs,ga,ce,vs,xa,he,A,qa,es,ja,wa,me,ys,Ns,va,ue,as,_e,ts,ns,ya,$s,$a,Ea,fe,ls,ge,rs,k,ba,Bs,ka,Da,Es,Sa,Pa,xe,os,qe,is,ps,La,Ms,Aa,Ia,je,ds,we,cs,hs,Ra,bs,za,Ca,ve,ms,ye,ks,Oa,$e,us,Ee;return I=new Ta({}),C=new Ta({}),T=new q({props:{code:`from transformers import DPRContextEncoder, DPRContextEncoderTokenizer
import torch
torch.set_grad_enabled(False)
ctx_encoder = DPRContextEncoder.from_pretrained("facebook/dpr-ctx_encoder-single-nq-base")
ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained("facebook/dpr-ctx_encoder-single-nq-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DPRContextEncoder, DPRContextEncoderTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>torch.set_grad_enabled(<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ctx_encoder = DPRContextEncoder.from_pretrained(<span class="hljs-string">&quot;facebook/dpr-ctx_encoder-single-nq-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/dpr-ctx_encoder-single-nq-base&quot;</span>)`}}),Q=new q({props:{code:`from datasets import load_dataset
ds = load_dataset('crime_and_punish', split='train[:100]')
ds_with_embeddings = ds.map(lambda example: {'embeddings': ctx_encoder(**ctx_tokenizer(example["line"], return_tensors="pt"))[0][0].numpy()})`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&#x27;crime_and_punish&#x27;</span>, split=<span class="hljs-string">&#x27;train[:100]&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_with_embeddings = ds.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> example: {<span class="hljs-string">&#x27;embeddings&#x27;</span>: ctx_encoder(**ctx_tokenizer(example[<span class="hljs-string">&quot;line&quot;</span>], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>))[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].numpy()})`}}),M=new q({props:{code:"ds_with_embeddings.add_faiss_index(column='embeddings')",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>ds_with_embeddings.add_faiss_index(column=<span class="hljs-string">&#x27;embeddings&#x27;</span>)'}}),U=new q({props:{code:`from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer
q_encoder = DPRQuestionEncoder.from_pretrained("facebook/dpr-question_encoder-single-nq-base")
q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained("facebook/dpr-question_encoder-single-nq-base")

question = "Is it serious ?"
question_embedding = q_encoder(**q_tokenizer(question, return_tensors="pt"))[0][0].numpy()
scores, retrieved_examples = ds_with_embeddings.get_nearest_examples('embeddings', question_embedding, k=10)
retrieved_examples["line"][0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DPRQuestionEncoder, DPRQuestionEncoderTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span>q_encoder = DPRQuestionEncoder.from_pretrained(<span class="hljs-string">&quot;facebook/dpr-question_encoder-single-nq-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/dpr-question_encoder-single-nq-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>question = <span class="hljs-string">&quot;Is it serious ?&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>question_embedding = q_encoder(**q_tokenizer(question, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>))[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].numpy()
<span class="hljs-meta">&gt;&gt;&gt; </span>scores, retrieved_examples = ds_with_embeddings.get_nearest_examples(<span class="hljs-string">&#x27;embeddings&#x27;</span>, question_embedding, k=<span class="hljs-number">10</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>retrieved_examples[<span class="hljs-string">&quot;line&quot;</span>][<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;_that_ serious? It is not serious at all. It\u2019s simply a fantasy to amuse\\r\\n&#x27;</span>`}}),Y=new q({props:{code:`faiss_index = ds_with_embeddings.get_index('embeddings').faiss_index
limits, distances, indices = faiss_index.range_search(x=question_embedding.reshape(1, -1), thresh=0.95)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>faiss_index = ds_with_embeddings.get_index(<span class="hljs-string">&#x27;embeddings&#x27;</span>).faiss_index
<span class="hljs-meta">&gt;&gt;&gt; </span>limits, distances, indices = faiss_index.range_search(x=question_embedding.reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>), thresh=<span class="hljs-number">0.95</span>)`}}),K=new q({props:{code:"ds_with_embeddings.save_faiss_index('embeddings', 'my_index.faiss')",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>ds_with_embeddings.save_faiss_index(<span class="hljs-string">&#x27;embeddings&#x27;</span>, <span class="hljs-string">&#x27;my_index.faiss&#x27;</span>)'}}),Z=new q({props:{code:`ds = load_dataset('crime_and_punish', split='train[:100]')
ds.load_faiss_index('embeddings', 'my_index.faiss')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&#x27;crime_and_punish&#x27;</span>, split=<span class="hljs-string">&#x27;train[:100]&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds.load_faiss_index(<span class="hljs-string">&#x27;embeddings&#x27;</span>, <span class="hljs-string">&#x27;my_index.faiss&#x27;</span>)`}}),ss=new Ta({}),as=new q({props:{code:`from datasets import load_dataset
squad = load_dataset('squad', split='validation')`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>, split=<span class="hljs-string">&#x27;validation&#x27;</span>)`}}),ls=new q({props:{code:'squad.add_elasticsearch_index("context", host="localhost", port="9200")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>squad.add_elasticsearch_index(<span class="hljs-string">&quot;context&quot;</span>, host=<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-string">&quot;9200&quot;</span>)'}}),os=new q({props:{code:`query = "machine"
scores, retrieved_examples = squad.get_nearest_examples("context", query, k=10)
retrieved_examples["title"][0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>query = <span class="hljs-string">&quot;machine&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>scores, retrieved_examples = squad.get_nearest_examples(<span class="hljs-string">&quot;context&quot;</span>, query, k=<span class="hljs-number">10</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>retrieved_examples[<span class="hljs-string">&quot;title&quot;</span>][<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;Computational_complexity_theory&#x27;</span>`}}),ds=new q({props:{code:`from datasets import load_dataset
squad = load_dataset('squad', split='validation')
squad.add_elasticsearch_index("context", host="localhost", port="9200", es_index_name="hf_squad_val_context")
squad.get_index("context").es_index_name`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>, split=<span class="hljs-string">&#x27;validation&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>squad.add_elasticsearch_index(<span class="hljs-string">&quot;context&quot;</span>, host=<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-string">&quot;9200&quot;</span>, es_index_name=<span class="hljs-string">&quot;hf_squad_val_context&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>squad.get_index(<span class="hljs-string">&quot;context&quot;</span>).es_index_name
hf_squad_val_context`}}),ms=new q({props:{code:`from datasets import load_dataset
squad = load_dataset('squad', split='validation')
squad.load_elasticsearch_index("context", host="localhost", port="9200", es_index_name="hf_squad_val_context")
query = "machine"
scores, retrieved_examples = squad.get_nearest_examples("context", query, k=10)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>squad = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>, split=<span class="hljs-string">&#x27;validation&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>squad.load_elasticsearch_index(<span class="hljs-string">&quot;context&quot;</span>, host=<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-string">&quot;9200&quot;</span>, es_index_name=<span class="hljs-string">&quot;hf_squad_val_context&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>query = <span class="hljs-string">&quot;machine&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>scores, retrieved_examples = squad.get_nearest_examples(<span class="hljs-string">&quot;context&quot;</span>, query, k=<span class="hljs-number">10</span>)`}}),us=new q({props:{code:`import elasticsearch as es
import elasticsearch.helpers
from elasticsearch import Elasticsearch
es_client = Elasticsearch([{"host": "localhost", "port": "9200"}])  # default client
es_config = {
    "settings": {
        "number_of_shards": 1,
        "analysis": {"analyzer": {"stop_standard": {"type": "standard", " stopwords": "_english_"}}},
    },
    "mappings": {"properties": {"text": {"type": "text", "analyzer": "standard", "similarity": "BM25"}}},
}  # default config
es_index_name = "hf_squad_context"  # name of the index in ElasticSearch
squad.add_elasticsearch_index("context", es_client=es_client, es_config=es_config, es_index_name=es_index_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> elasticsearch <span class="hljs-keyword">as</span> es
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> elasticsearch.helpers
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> elasticsearch <span class="hljs-keyword">import</span> Elasticsearch
<span class="hljs-meta">&gt;&gt;&gt; </span>es_client = Elasticsearch([{<span class="hljs-string">&quot;host&quot;</span>: <span class="hljs-string">&quot;localhost&quot;</span>, <span class="hljs-string">&quot;port&quot;</span>: <span class="hljs-string">&quot;9200&quot;</span>}])  <span class="hljs-comment"># default client</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>es_config = {
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;settings&quot;</span>: {
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;number_of_shards&quot;</span>: <span class="hljs-number">1</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;analysis&quot;</span>: {<span class="hljs-string">&quot;analyzer&quot;</span>: {<span class="hljs-string">&quot;stop_standard&quot;</span>: {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;standard&quot;</span>, <span class="hljs-string">&quot; stopwords&quot;</span>: <span class="hljs-string">&quot;_english_&quot;</span>}}},
<span class="hljs-meta">... </span>    },
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;mappings&quot;</span>: {<span class="hljs-string">&quot;properties&quot;</span>: {<span class="hljs-string">&quot;text&quot;</span>: {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;analyzer&quot;</span>: <span class="hljs-string">&quot;standard&quot;</span>, <span class="hljs-string">&quot;similarity&quot;</span>: <span class="hljs-string">&quot;BM25&quot;</span>}}},
<span class="hljs-meta">... </span>}  <span class="hljs-comment"># default config</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>es_index_name = <span class="hljs-string">&quot;hf_squad_context&quot;</span>  <span class="hljs-comment"># name of the index in ElasticSearch</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>squad.add_elasticsearch_index(<span class="hljs-string">&quot;context&quot;</span>, es_client=es_client, es_config=es_config, es_index_name=es_index_name)`}}),{c(){j=n("meta"),Us=c(),w=n("h1"),D=n("a"),Ls=n("span"),m(I.$$.fragment),Oe=c(),As=n("span"),Te=i("Search index"),Ws=c(),v=n("p"),R=n("a"),Fe=i("FAISS"),Qe=i(" and "),z=n("a"),Ne=i("ElasticSearch"),Be=i(" enables searching for examples in a dataset. This can be useful when you want to retrieve specific examples from a dataset that are relevant to your NLP task. For example, if you are working on a Open Domain Question Answering task, you may want to only return examples that are relevant to answering your question."),Ys=c(),_s=n("p"),Me=i("This guide will show you how to build an index for your dataset that will allow you to search it."),Gs=c(),y=n("h2"),S=n("a"),Is=n("span"),m(C.$$.fragment),He=c(),Rs=n("span"),Ue=i("FAISS"),Js=c(),P=n("p"),We=i("FAISS retrieves documents based on the similarity of their vector representations. In this example, you will generate the vector representations with the "),O=n("a"),Ye=i("DPR"),Ge=i(" model."),Ks=c(),fs=n("ol"),zs=n("li"),Je=i("Download the DPR model from \u{1F917} Transformers:"),Vs=c(),m(T.$$.fragment),Xs=c(),F=n("ol"),Cs=n("li"),Ke=i("Load your dataset and compute the vector representations:"),Zs=c(),m(Q.$$.fragment),se=c(),N=n("ol"),B=n("li"),Ve=i("Create the index with "),gs=n("a"),Xe=i("Dataset.add_faiss_index()"),Ze=i(":"),ee=c(),m(M.$$.fragment),ae=c(),H=n("ol"),$=n("li"),sa=i("Now you can query your dataset with the "),Os=n("code"),ea=i("embeddings"),aa=i(" index. Load the DPR Question Encoder, and search for a question with "),xs=n("a"),ta=i("Dataset.get_nearest_examples()"),na=i(":"),te=c(),m(U.$$.fragment),ne=c(),W=n("ol"),E=n("li"),la=i("You can access the index with "),qs=n("a"),ra=i("Dataset.get_index()"),oa=i(" and use it for special operations, e.g. query it using "),Ts=n("code"),ia=i("range_search"),pa=i(":"),le=c(),m(Y.$$.fragment),re=c(),G=n("ol"),J=n("li"),da=i("When you are done querying, save the index on disk with "),js=n("a"),ca=i("Dataset.save_faiss_index()"),ha=i(":"),oe=c(),m(K.$$.fragment),ie=c(),V=n("ol"),X=n("li"),ma=i("Reload it at a later time with "),ws=n("a"),ua=i("Dataset.load_faiss_index()"),_a=i(":"),pe=c(),m(Z.$$.fragment),de=c(),b=n("h2"),L=n("a"),Fs=n("span"),m(ss.$$.fragment),fa=c(),Qs=n("span"),ga=i("ElasticSearch"),ce=c(),vs=n("p"),xa=i("Unlike FAISS, ElasticSearch retrieves documents based on exact matches."),he=c(),A=n("p"),qa=i("Start ElasticSearch on your machine, or see the "),es=n("a"),ja=i("ElasticSearch installation guide"),wa=i(" if you don\u2019t already have it installed."),me=c(),ys=n("ol"),Ns=n("li"),va=i("Load the dataset you want to index:"),ue=c(),m(as.$$.fragment),_e=c(),ts=n("ol"),ns=n("li"),ya=i("Build the index with "),$s=n("a"),$a=i("Dataset.add_elasticsearch_index()"),Ea=i(":"),fe=c(),m(ls.$$.fragment),ge=c(),rs=n("ol"),k=n("li"),ba=i("Then you can query the "),Bs=n("code"),ka=i("context"),Da=i(" index with "),Es=n("a"),Sa=i("Dataset.get_nearest_examples()"),Pa=i(":"),xe=c(),m(os.$$.fragment),qe=c(),is=n("ol"),ps=n("li"),La=i("If you want to reuse the index, define the "),Ms=n("code"),Aa=i("es_index_name"),Ia=i(" parameter when you build the index:"),je=c(),m(ds.$$.fragment),we=c(),cs=n("ol"),hs=n("li"),Ra=i("Reload it later with the index name when you call "),bs=n("a"),za=i("Dataset.load_elasticsearch_index()"),Ca=i(":"),ve=c(),m(ms.$$.fragment),ye=c(),ks=n("p"),Oa=i("For more advanced ElasticSearch usage, you can specify your own configuration with custom settings:"),$e=c(),m(us.$$.fragment),this.h()},l(s){const t=At('[data-svelte="svelte-1phssyn"]',document.head);j=l(t,"META",{name:!0,content:!0}),t.forEach(e),Us=h(s),w=l(s,"H1",{class:!0});var be=r(w);D=l(be,"A",{id:!0,class:!0,href:!0});var Qa=r(D);Ls=l(Qa,"SPAN",{});var Na=r(Ls);u(I.$$.fragment,Na),Na.forEach(e),Qa.forEach(e),Oe=h(be),As=l(be,"SPAN",{});var Ba=r(As);Te=p(Ba,"Search index"),Ba.forEach(e),be.forEach(e),Ws=h(s),v=l(s,"P",{});var Hs=r(v);R=l(Hs,"A",{href:!0,rel:!0});var Ma=r(R);Fe=p(Ma,"FAISS"),Ma.forEach(e),Qe=p(Hs," and "),z=l(Hs,"A",{href:!0,rel:!0});var Ha=r(z);Ne=p(Ha,"ElasticSearch"),Ha.forEach(e),Be=p(Hs," enables searching for examples in a dataset. This can be useful when you want to retrieve specific examples from a dataset that are relevant to your NLP task. For example, if you are working on a Open Domain Question Answering task, you may want to only return examples that are relevant to answering your question."),Hs.forEach(e),Ys=h(s),_s=l(s,"P",{});var Ua=r(_s);Me=p(Ua,"This guide will show you how to build an index for your dataset that will allow you to search it."),Ua.forEach(e),Gs=h(s),y=l(s,"H2",{class:!0});var ke=r(y);S=l(ke,"A",{id:!0,class:!0,href:!0});var Wa=r(S);Is=l(Wa,"SPAN",{});var Ya=r(Is);u(C.$$.fragment,Ya),Ya.forEach(e),Wa.forEach(e),He=h(ke),Rs=l(ke,"SPAN",{});var Ga=r(Rs);Ue=p(Ga,"FAISS"),Ga.forEach(e),ke.forEach(e),Js=h(s),P=l(s,"P",{});var De=r(P);We=p(De,"FAISS retrieves documents based on the similarity of their vector representations. In this example, you will generate the vector representations with the "),O=l(De,"A",{href:!0,rel:!0});var Ja=r(O);Ye=p(Ja,"DPR"),Ja.forEach(e),Ge=p(De," model."),De.forEach(e),Ks=h(s),fs=l(s,"OL",{});var Ka=r(fs);zs=l(Ka,"LI",{});var Va=r(zs);Je=p(Va,"Download the DPR model from \u{1F917} Transformers:"),Va.forEach(e),Ka.forEach(e),Vs=h(s),u(T.$$.fragment,s),Xs=h(s),F=l(s,"OL",{start:!0});var Xa=r(F);Cs=l(Xa,"LI",{});var Za=r(Cs);Ke=p(Za,"Load your dataset and compute the vector representations:"),Za.forEach(e),Xa.forEach(e),Zs=h(s),u(Q.$$.fragment,s),se=h(s),N=l(s,"OL",{start:!0});var st=r(N);B=l(st,"LI",{});var Se=r(B);Ve=p(Se,"Create the index with "),gs=l(Se,"A",{href:!0});var et=r(gs);Xe=p(et,"Dataset.add_faiss_index()"),et.forEach(e),Ze=p(Se,":"),Se.forEach(e),st.forEach(e),ee=h(s),u(M.$$.fragment,s),ae=h(s),H=l(s,"OL",{start:!0});var at=r(H);$=l(at,"LI",{});var Ds=r($);sa=p(Ds,"Now you can query your dataset with the "),Os=l(Ds,"CODE",{});var tt=r(Os);ea=p(tt,"embeddings"),tt.forEach(e),aa=p(Ds," index. Load the DPR Question Encoder, and search for a question with "),xs=l(Ds,"A",{href:!0});var nt=r(xs);ta=p(nt,"Dataset.get_nearest_examples()"),nt.forEach(e),na=p(Ds,":"),Ds.forEach(e),at.forEach(e),te=h(s),u(U.$$.fragment,s),ne=h(s),W=l(s,"OL",{start:!0});var lt=r(W);E=l(lt,"LI",{});var Ss=r(E);la=p(Ss,"You can access the index with "),qs=l(Ss,"A",{href:!0});var rt=r(qs);ra=p(rt,"Dataset.get_index()"),rt.forEach(e),oa=p(Ss," and use it for special operations, e.g. query it using "),Ts=l(Ss,"CODE",{});var ot=r(Ts);ia=p(ot,"range_search"),ot.forEach(e),pa=p(Ss,":"),Ss.forEach(e),lt.forEach(e),le=h(s),u(Y.$$.fragment,s),re=h(s),G=l(s,"OL",{start:!0});var it=r(G);J=l(it,"LI",{});var Pe=r(J);da=p(Pe,"When you are done querying, save the index on disk with "),js=l(Pe,"A",{href:!0});var pt=r(js);ca=p(pt,"Dataset.save_faiss_index()"),pt.forEach(e),ha=p(Pe,":"),Pe.forEach(e),it.forEach(e),oe=h(s),u(K.$$.fragment,s),ie=h(s),V=l(s,"OL",{start:!0});var dt=r(V);X=l(dt,"LI",{});var Le=r(X);ma=p(Le,"Reload it at a later time with "),ws=l(Le,"A",{href:!0});var ct=r(ws);ua=p(ct,"Dataset.load_faiss_index()"),ct.forEach(e),_a=p(Le,":"),Le.forEach(e),dt.forEach(e),pe=h(s),u(Z.$$.fragment,s),de=h(s),b=l(s,"H2",{class:!0});var Ae=r(b);L=l(Ae,"A",{id:!0,class:!0,href:!0});var ht=r(L);Fs=l(ht,"SPAN",{});var mt=r(Fs);u(ss.$$.fragment,mt),mt.forEach(e),ht.forEach(e),fa=h(Ae),Qs=l(Ae,"SPAN",{});var ut=r(Qs);ga=p(ut,"ElasticSearch"),ut.forEach(e),Ae.forEach(e),ce=h(s),vs=l(s,"P",{});var _t=r(vs);xa=p(_t,"Unlike FAISS, ElasticSearch retrieves documents based on exact matches."),_t.forEach(e),he=h(s),A=l(s,"P",{});var Ie=r(A);qa=p(Ie,"Start ElasticSearch on your machine, or see the "),es=l(Ie,"A",{href:!0,rel:!0});var ft=r(es);ja=p(ft,"ElasticSearch installation guide"),ft.forEach(e),wa=p(Ie," if you don\u2019t already have it installed."),Ie.forEach(e),me=h(s),ys=l(s,"OL",{});var gt=r(ys);Ns=l(gt,"LI",{});var xt=r(Ns);va=p(xt,"Load the dataset you want to index:"),xt.forEach(e),gt.forEach(e),ue=h(s),u(as.$$.fragment,s),_e=h(s),ts=l(s,"OL",{start:!0});var qt=r(ts);ns=l(qt,"LI",{});var Re=r(ns);ya=p(Re,"Build the index with "),$s=l(Re,"A",{href:!0});var jt=r($s);$a=p(jt,"Dataset.add_elasticsearch_index()"),jt.forEach(e),Ea=p(Re,":"),Re.forEach(e),qt.forEach(e),fe=h(s),u(ls.$$.fragment,s),ge=h(s),rs=l(s,"OL",{start:!0});var wt=r(rs);k=l(wt,"LI",{});var Ps=r(k);ba=p(Ps,"Then you can query the "),Bs=l(Ps,"CODE",{});var vt=r(Bs);ka=p(vt,"context"),vt.forEach(e),Da=p(Ps," index with "),Es=l(Ps,"A",{href:!0});var yt=r(Es);Sa=p(yt,"Dataset.get_nearest_examples()"),yt.forEach(e),Pa=p(Ps,":"),Ps.forEach(e),wt.forEach(e),xe=h(s),u(os.$$.fragment,s),qe=h(s),is=l(s,"OL",{start:!0});var $t=r(is);ps=l($t,"LI",{});var ze=r(ps);La=p(ze,"If you want to reuse the index, define the "),Ms=l(ze,"CODE",{});var Et=r(Ms);Aa=p(Et,"es_index_name"),Et.forEach(e),Ia=p(ze," parameter when you build the index:"),ze.forEach(e),$t.forEach(e),je=h(s),u(ds.$$.fragment,s),we=h(s),cs=l(s,"OL",{start:!0});var bt=r(cs);hs=l(bt,"LI",{});var Ce=r(hs);Ra=p(Ce,"Reload it later with the index name when you call "),bs=l(Ce,"A",{href:!0});var kt=r(bs);za=p(kt,"Dataset.load_elasticsearch_index()"),kt.forEach(e),Ca=p(Ce,":"),Ce.forEach(e),bt.forEach(e),ve=h(s),u(ms.$$.fragment,s),ye=h(s),ks=l(s,"P",{});var Dt=r(ks);Oa=p(Dt,"For more advanced ElasticSearch usage, you can specify your own configuration with custom settings:"),Dt.forEach(e),$e=h(s),u(us.$$.fragment,s),this.h()},h(){d(j,"name","hf:doc:metadata"),d(j,"content",JSON.stringify(Ct)),d(D,"id","search-index"),d(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D,"href","#search-index"),d(w,"class","relative group"),d(R,"href","https://github.com/facebookresearch/faiss"),d(R,"rel","nofollow"),d(z,"href","https://www.elastic.co/elasticsearch/"),d(z,"rel","nofollow"),d(S,"id","faiss"),d(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S,"href","#faiss"),d(y,"class","relative group"),d(O,"href","https://huggingface.co/transformers/model_doc/dpr.html"),d(O,"rel","nofollow"),d(F,"start","2"),d(gs,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.add_faiss_index"),d(N,"start","3"),d(xs,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.get_nearest_examples"),d(H,"start","4"),d(qs,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.get_index"),d(W,"start","5"),d(js,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.save_faiss_index"),d(G,"start","6"),d(ws,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.load_faiss_index"),d(V,"start","7"),d(L,"id","elasticsearch"),d(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L,"href","#elasticsearch"),d(b,"class","relative group"),d(es,"href","https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html"),d(es,"rel","nofollow"),d($s,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.add_elasticsearch_index"),d(ts,"start","2"),d(Es,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.get_nearest_examples"),d(rs,"start","3"),d(is,"start","4"),d(bs,"href","/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.load_elasticsearch_index"),d(cs,"start","5")},m(s,t){a(document.head,j),o(s,Us,t),o(s,w,t),a(w,D),a(D,Ls),_(I,Ls,null),a(w,Oe),a(w,As),a(As,Te),o(s,Ws,t),o(s,v,t),a(v,R),a(R,Fe),a(v,Qe),a(v,z),a(z,Ne),a(v,Be),o(s,Ys,t),o(s,_s,t),a(_s,Me),o(s,Gs,t),o(s,y,t),a(y,S),a(S,Is),_(C,Is,null),a(y,He),a(y,Rs),a(Rs,Ue),o(s,Js,t),o(s,P,t),a(P,We),a(P,O),a(O,Ye),a(P,Ge),o(s,Ks,t),o(s,fs,t),a(fs,zs),a(zs,Je),o(s,Vs,t),_(T,s,t),o(s,Xs,t),o(s,F,t),a(F,Cs),a(Cs,Ke),o(s,Zs,t),_(Q,s,t),o(s,se,t),o(s,N,t),a(N,B),a(B,Ve),a(B,gs),a(gs,Xe),a(B,Ze),o(s,ee,t),_(M,s,t),o(s,ae,t),o(s,H,t),a(H,$),a($,sa),a($,Os),a(Os,ea),a($,aa),a($,xs),a(xs,ta),a($,na),o(s,te,t),_(U,s,t),o(s,ne,t),o(s,W,t),a(W,E),a(E,la),a(E,qs),a(qs,ra),a(E,oa),a(E,Ts),a(Ts,ia),a(E,pa),o(s,le,t),_(Y,s,t),o(s,re,t),o(s,G,t),a(G,J),a(J,da),a(J,js),a(js,ca),a(J,ha),o(s,oe,t),_(K,s,t),o(s,ie,t),o(s,V,t),a(V,X),a(X,ma),a(X,ws),a(ws,ua),a(X,_a),o(s,pe,t),_(Z,s,t),o(s,de,t),o(s,b,t),a(b,L),a(L,Fs),_(ss,Fs,null),a(b,fa),a(b,Qs),a(Qs,ga),o(s,ce,t),o(s,vs,t),a(vs,xa),o(s,he,t),o(s,A,t),a(A,qa),a(A,es),a(es,ja),a(A,wa),o(s,me,t),o(s,ys,t),a(ys,Ns),a(Ns,va),o(s,ue,t),_(as,s,t),o(s,_e,t),o(s,ts,t),a(ts,ns),a(ns,ya),a(ns,$s),a($s,$a),a(ns,Ea),o(s,fe,t),_(ls,s,t),o(s,ge,t),o(s,rs,t),a(rs,k),a(k,ba),a(k,Bs),a(Bs,ka),a(k,Da),a(k,Es),a(Es,Sa),a(k,Pa),o(s,xe,t),_(os,s,t),o(s,qe,t),o(s,is,t),a(is,ps),a(ps,La),a(ps,Ms),a(Ms,Aa),a(ps,Ia),o(s,je,t),_(ds,s,t),o(s,we,t),o(s,cs,t),a(cs,hs),a(hs,Ra),a(hs,bs),a(bs,za),a(hs,Ca),o(s,ve,t),_(ms,s,t),o(s,ye,t),o(s,ks,t),a(ks,Oa),o(s,$e,t),_(us,s,t),Ee=!0},p:It,i(s){Ee||(f(I.$$.fragment,s),f(C.$$.fragment,s),f(T.$$.fragment,s),f(Q.$$.fragment,s),f(M.$$.fragment,s),f(U.$$.fragment,s),f(Y.$$.fragment,s),f(K.$$.fragment,s),f(Z.$$.fragment,s),f(ss.$$.fragment,s),f(as.$$.fragment,s),f(ls.$$.fragment,s),f(os.$$.fragment,s),f(ds.$$.fragment,s),f(ms.$$.fragment,s),f(us.$$.fragment,s),Ee=!0)},o(s){g(I.$$.fragment,s),g(C.$$.fragment,s),g(T.$$.fragment,s),g(Q.$$.fragment,s),g(M.$$.fragment,s),g(U.$$.fragment,s),g(Y.$$.fragment,s),g(K.$$.fragment,s),g(Z.$$.fragment,s),g(ss.$$.fragment,s),g(as.$$.fragment,s),g(ls.$$.fragment,s),g(os.$$.fragment,s),g(ds.$$.fragment,s),g(ms.$$.fragment,s),g(us.$$.fragment,s),Ee=!1},d(s){e(j),s&&e(Us),s&&e(w),x(I),s&&e(Ws),s&&e(v),s&&e(Ys),s&&e(_s),s&&e(Gs),s&&e(y),x(C),s&&e(Js),s&&e(P),s&&e(Ks),s&&e(fs),s&&e(Vs),x(T,s),s&&e(Xs),s&&e(F),s&&e(Zs),x(Q,s),s&&e(se),s&&e(N),s&&e(ee),x(M,s),s&&e(ae),s&&e(H),s&&e(te),x(U,s),s&&e(ne),s&&e(W),s&&e(le),x(Y,s),s&&e(re),s&&e(G),s&&e(oe),x(K,s),s&&e(ie),s&&e(V),s&&e(pe),x(Z,s),s&&e(de),s&&e(b),x(ss),s&&e(ce),s&&e(vs),s&&e(he),s&&e(A),s&&e(me),s&&e(ys),s&&e(ue),x(as,s),s&&e(_e),s&&e(ts),s&&e(fe),x(ls,s),s&&e(ge),s&&e(rs),s&&e(xe),x(os,s),s&&e(qe),s&&e(is),s&&e(je),x(ds,s),s&&e(we),s&&e(cs),s&&e(ve),x(ms,s),s&&e(ye),s&&e(ks),s&&e($e),x(us,s)}}}const Ct={local:"search-index",sections:[{local:"faiss",title:"FAISS"},{local:"elasticsearch",title:"ElasticSearch"}],title:"Search index"};function Ot(Fa){return Rt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Nt extends St{constructor(j){super();Pt(this,j,Ot,zt,Lt,{})}}export{Nt as default,Ct as metadata};
