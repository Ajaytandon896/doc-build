import{S as Zu,i as Vu,s as Xu,e as r,k as d,w as u,t as a,M as em,c as l,d as o,m as c,a as n,x as m,h as s,b as f,N as ic,G as t,g as p,y as h,L as tm,q as g,o as _,B as v,v as om}from"../chunks/vendor-hf-doc-builder.js";import{I as ne}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as w}from"../chunks/CodeBlock-hf-doc-builder.js";function am(pc){let J,gs,Q,ie,Eo,ze,hl,bo,gl,_s,At,_l,vs,Ne,ys,P,vl,Re,yl,wl,pe,ko,El,bl,kl,ws,k,Pt,Ft,$l,jl,Sl,Lt,zt,Dl,ql,xl,Nt,Rt,Ml,Cl,Tl,Ut,Yt,Hl,Ol,Il,Bt,Wt,Al,Pl,Es,Z,de,$o,Ue,Fl,jo,Ll,bs,ce,zl,Ye,Nl,Rl,ks,Kt,Ul,$s,F,So,Be,Yl,Bl,Do,We,Wl,Kl,qo,Gl,js,fe,Jl,Ke,Ql,Zl,Ss,ue,Vl,xo,Xl,en,Ds,Ge,qs,Gt,Mo,tn,xs,Jt,on,Ms,Je,Cs,Qt,V,an,Co,sn,rn,To,ln,nn,Ts,Zt,Ho,pn,Hs,Vt,dn,Os,Qe,Is,X,me,Oo,Ze,cn,Io,fn,As,q,dc,Ps,Xt,un,Fs,he,Ao,mn,hn,Ve,gn,Po,_n,vn,Ls,ge,yn,Xe,wn,En,zs,ee,_e,Fo,et,bn,Lo,kn,Ns,eo,$n,Rs,T,jn,zo,Sn,Dn,No,qn,xn,Ro,Mn,Cn,Us,tt,Ys,to,Tn,Bs,ot,Ws,te,ve,Uo,at,Hn,oo,On,Yo,In,Ks,ye,An,Bo,Pn,Fn,Gs,st,Js,ao,Ln,Qs,rt,Zs,oe,we,Wo,lt,zn,Ko,Nn,Vs,Ee,Rn,Go,Un,Yn,Xs,H,Jo,Qo,Bn,Wn,Zo,Vo,Kn,Gn,Xo,ea,Jn,Qn,ta,oa,Zn,er,so,Vn,tr,nt,or,be,Xn,aa,ei,ti,ar,ro,sa,oi,sr,it,rr,pt,dt,ai,ra,si,ri,lr,ct,nr,ft,ut,li,la,ni,ii,ir,mt,pr,ke,pi,na,di,ci,dr,ae,$e,ia,ht,fi,pa,ui,cr,x,cc,fr,je,mi,da,hi,gi,ur,Se,De,ca,_i,vi,gt,yi,wi,Ei,L,fa,bi,ki,ua,$i,ji,_t,Si,Di,mr,vt,hr,lo,qi,gr,yt,_r,qe,xi,wt,Mi,Ci,vr,se,xe,ma,Et,Ti,ha,Hi,yr,M,fc,wr,z,Oi,bt,Ii,Ai,kt,Pi,Fi,Er,Me,Li,ga,zi,Ni,br,no,re,Ri,_a,Ui,Yi,va,Bi,Wi,kr,N,Ki,ya,Gi,Ji,$t,Qi,Zi,$r,jt,jr,R,Vi,wa,Xi,ep,Ea,tp,op,Sr,St,Dr,Ce,ap,ba,sp,rp,qr,Dt,xr,Te,lp,qt,np,ip,Mr,le,He,ka,xt,pp,$a,dp,Cr,$,cp,ja,fp,up,Sa,mp,hp,Da,gp,_p,io,vp,yp,Tr,Mt,Hr,U,wp,qa,Ep,bp,xa,kp,$p,Or,j,b,Ma,jp,Sp,Ca,Dp,qp,Ta,xp,Mp,Ha,Cp,Tp,Oa,Hp,Op,Ia,Ip,Ap,Pp,y,Aa,Fp,Lp,Pa,zp,Np,Fa,Rp,Up,La,Yp,Bp,za,Wp,Kp,Na,Gp,Jp,Ra,Qp,Zp,Ua,Vp,Xp,ed,O,Ya,td,od,Ba,ad,sd,Wa,rd,ld,Ct,po,Ka,nd,id,pd,co,Ga,dd,cd,fd,S,Ja,ud,md,Qa,hd,gd,Za,_d,vd,Va,yd,wd,Xa,Ed,bd,kd,I,es,$d,jd,ts,Sd,Dd,os,qd,xd,Tt,Oe,as,Md,Cd,ss,Td,Hd,Od,Ie,rs,Id,Ad,ls,Pd,Fd,Ir,D,Ld,ns,zd,Nd,is,Rd,Ud,ps,Yd,Bd,ds,Wd,Kd,Ar,Ht,Pr,Y,Gd,cs,Jd,Qd,fs,Zd,Vd,Fr,Ot,Lr;return ze=new ne({}),Ne=new w({props:{code:`from sagemaker.huggingface import HuggingFaceModel

# create Hugging Face Model Class and deploy it as SageMaker endpoint
huggingface_model = HuggingFaceModel(...).deploy()`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># create Hugging Face Model Class and deploy it as SageMaker endpoint</span>
huggingface_model = HuggingFaceModel(...).deploy()`}}),Ue=new ne({}),Ge=new w({props:{code:"pip install sagemaker --upgrade",highlighted:"pip install sagemaker --upgrade"}}),Je=new w({props:{code:`import sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()`,highlighted:`<span class="hljs-keyword">import</span> sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()`}}),Qe=new w({props:{code:`import sagemaker
import boto3

iam_client = boto3.client('iam')
role = iam_client.get_role(RoleName='role-name-of-your-iam-role-with-right-permissions')['Role']['Arn']
sess = sagemaker.Session()`,highlighted:`<span class="hljs-keyword">import</span> sagemaker
<span class="hljs-keyword">import</span> boto3

iam_client = boto3.client(<span class="hljs-string">&#x27;iam&#x27;</span>)
role = iam_client.get_role(RoleName=<span class="hljs-string">&#x27;role-name-of-your-iam-role-with-right-permissions&#x27;</span>)[<span class="hljs-string">&#x27;Role&#x27;</span>][<span class="hljs-string">&#x27;Arn&#x27;</span>]
sess = sagemaker.Session()`}}),Ze=new ne({}),et=new ne({}),tt=new w({props:{code:`from sagemaker.huggingface import HuggingFace

############ pseudo code start ############

# create Hugging Face Estimator for training
huggingface_estimator = HuggingFace(....)

# start the train job with our uploaded datasets as input
huggingface_estimator.fit(...)

############ pseudo code end ############

# deploy model to SageMaker Inference
predictor = hf_estimator.deploy(initial_instance_count=1, instance_type="ml.m5.xlarge")

# example request: you always need to define "inputs"
data = {
   "inputs": "Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days."
}

# request
predictor.predict(data)`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface <span class="hljs-keyword">import</span> HuggingFace

<span class="hljs-comment">############ pseudo code start ############</span>

<span class="hljs-comment"># create Hugging Face Estimator for training</span>
huggingface_estimator = HuggingFace(....)

<span class="hljs-comment"># start the train job with our uploaded datasets as input</span>
huggingface_estimator.fit(...)

<span class="hljs-comment">############ pseudo code end ############</span>

<span class="hljs-comment"># deploy model to SageMaker Inference</span>
predictor = hf_estimator.deploy(initial_instance_count=<span class="hljs-number">1</span>, instance_type=<span class="hljs-string">&quot;ml.m5.xlarge&quot;</span>)

<span class="hljs-comment"># example request: you always need to define &quot;inputs&quot;</span>
data = {
   <span class="hljs-string">&quot;inputs&quot;</span>: <span class="hljs-string">&quot;Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.&quot;</span>
}

<span class="hljs-comment"># request</span>
predictor.predict(data)`}}),ot=new w({props:{code:`# delete endpoint
predictor.delete_endpoint()`,highlighted:`<span class="hljs-comment"># delete endpoint</span>
predictor.delete_endpoint()`}}),at=new ne({}),st=new w({props:{code:`from sagemaker.huggingface.model import HuggingFaceModel

# create Hugging Face Model Class
huggingface_model = HuggingFaceModel(
   model_data="s3://models/my-bert-model/model.tar.gz",  # path to your trained SageMaker model
   role=role,                                            # IAM role with permissions to create an endpoint
   transformers_version="4.6",                           # Transformers version used
   pytorch_version="1.7",                                # PyTorch version used
   py_version='py36',                                    # Python version used
)

# deploy model to SageMaker Inference
predictor = huggingface_model.deploy(
   initial_instance_count=1,
   instance_type="ml.m5.xlarge"
)

# example request: you always need to define "inputs"
data = {
   "inputs": "Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days."
}

# request
predictor.predict(data)`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface.model <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># create Hugging Face Model Class</span>
huggingface_model = HuggingFaceModel(
   model_data=<span class="hljs-string">&quot;s3://models/my-bert-model/model.tar.gz&quot;</span>,  <span class="hljs-comment"># path to your trained SageMaker model</span>
   role=role,                                            <span class="hljs-comment"># IAM role with permissions to create an endpoint</span>
   transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,                           <span class="hljs-comment"># Transformers version used</span>
   pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                                <span class="hljs-comment"># PyTorch version used</span>
   py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,                                    <span class="hljs-comment"># Python version used</span>
)

<span class="hljs-comment"># deploy model to SageMaker Inference</span>
predictor = huggingface_model.deploy(
   initial_instance_count=<span class="hljs-number">1</span>,
   instance_type=<span class="hljs-string">&quot;ml.m5.xlarge&quot;</span>
)

<span class="hljs-comment"># example request: you always need to define &quot;inputs&quot;</span>
data = {
   <span class="hljs-string">&quot;inputs&quot;</span>: <span class="hljs-string">&quot;Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.&quot;</span>
}

<span class="hljs-comment"># request</span>
predictor.predict(data)`}}),rt=new w({props:{code:`# delete endpoint
predictor.delete_endpoint()`,highlighted:`<span class="hljs-comment"># delete endpoint</span>
predictor.delete_endpoint()`}}),lt=new ne({}),nt=new w({props:{code:`model.tar.gz/
|- pytorch_model.bin
|- vocab.txt
|- tokenizer_config.json
|- config.json
|- special_tokens_map.json`,highlighted:`model.tar.gz/
|- pytorch_model.bin
|- vocab.txt
|- tokenizer_config.json
|- config.json
|- special_tokens_map.json`}}),it=new w({props:{code:`git lfs install
git clone https://huggingface.co/{repository}`,highlighted:`git lfs install
git <span class="hljs-built_in">clone</span> https://huggingface.co/{repository}`}}),ct=new w({props:{code:`cd {repository}
tar zcvf model.tar.gz *`,highlighted:`<span class="hljs-built_in">cd</span> {repository}
tar zcvf model.tar.gz *`}}),mt=new w({props:{code:"aws s3 cp model.tar.gz <s3://{my-s3-path}>",highlighted:'aws s3 <span class="hljs-built_in">cp</span> model.tar.gz &lt;s3://{my-s3-path}&gt;'}}),ht=new ne({}),vt=new w({props:{code:`from sagemaker.huggingface.model import HuggingFaceModel

# Hub model configuration <https://huggingface.co/models>
hub = {
  'HF_MODEL_ID':'distilbert-base-uncased-distilled-squad', # model_id from hf.co/models
  'HF_TASK':'question-answering'                           # NLP task you want to use for predictions
}

# create Hugging Face Model Class
huggingface_model = HuggingFaceModel(
   env=hub,                                                # configuration for loading model from Hub
   role=role,                                              # IAM role with permissions to create an endpoint
   transformers_version="4.6",                             # Transformers version used
   pytorch_version="1.7",                                  # PyTorch version used
   py_version='py36',                                      # Python version used
)

# deploy model to SageMaker Inference
predictor = huggingface_model.deploy(
   initial_instance_count=1,
   instance_type="ml.m5.xlarge"
)

# example request: you always need to define "inputs"
data = {
"inputs": {
	"question": "What is used for inference?",
	"context": "My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference."
	}
}

# request
predictor.predict(data)`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface.model <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># Hub model configuration &lt;https://huggingface.co/models&gt;</span>
hub = {
  <span class="hljs-string">&#x27;HF_MODEL_ID&#x27;</span>:<span class="hljs-string">&#x27;distilbert-base-uncased-distilled-squad&#x27;</span>, <span class="hljs-comment"># model_id from hf.co/models</span>
  <span class="hljs-string">&#x27;HF_TASK&#x27;</span>:<span class="hljs-string">&#x27;question-answering&#x27;</span>                           <span class="hljs-comment"># NLP task you want to use for predictions</span>
}

<span class="hljs-comment"># create Hugging Face Model Class</span>
huggingface_model = HuggingFaceModel(
   env=hub,                                                <span class="hljs-comment"># configuration for loading model from Hub</span>
   role=role,                                              <span class="hljs-comment"># IAM role with permissions to create an endpoint</span>
   transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,                             <span class="hljs-comment"># Transformers version used</span>
   pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                                  <span class="hljs-comment"># PyTorch version used</span>
   py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,                                      <span class="hljs-comment"># Python version used</span>
)

<span class="hljs-comment"># deploy model to SageMaker Inference</span>
predictor = huggingface_model.deploy(
   initial_instance_count=<span class="hljs-number">1</span>,
   instance_type=<span class="hljs-string">&quot;ml.m5.xlarge&quot;</span>
)

<span class="hljs-comment"># example request: you always need to define &quot;inputs&quot;</span>
data = {
<span class="hljs-string">&quot;inputs&quot;</span>: {
	<span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;What is used for inference?&quot;</span>,
	<span class="hljs-string">&quot;context&quot;</span>: <span class="hljs-string">&quot;My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.&quot;</span>
	}
}

<span class="hljs-comment"># request</span>
predictor.predict(data)`}}),yt=new w({props:{code:`# delete endpoint
predictor.delete_endpoint()`,highlighted:`<span class="hljs-comment"># delete endpoint</span>
predictor.delete_endpoint()`}}),Et=new ne({}),jt=new w({props:{code:`batch_job = huggingface_estimator.transformer(
    instance_count=1,
    instance_type='ml.p3.2xlarge',
    strategy='SingleRecord')


batch_job.transform(
    data='s3://s3-uri-to-batch-data',
    content_type='application/json',    
    split_type='Line')`,highlighted:`batch_job = huggingface_estimator.transformer(
    instance_count=<span class="hljs-number">1</span>,
    instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
    strategy=<span class="hljs-string">&#x27;SingleRecord&#x27;</span>)


batch_job.transform(
    data=<span class="hljs-string">&#x27;s3://s3-uri-to-batch-data&#x27;</span>,
    content_type=<span class="hljs-string">&#x27;application/json&#x27;</span>,    
    split_type=<span class="hljs-string">&#x27;Line&#x27;</span>)`}}),St=new w({props:{code:`from sagemaker.huggingface.model import HuggingFaceModel

# Hub model configuration <https://huggingface.co/models>
hub = {
	'HF_MODEL_ID':'distilbert-base-uncased-finetuned-sst-2-english',
	'HF_TASK':'text-classification'
}

# create Hugging Face Model Class
huggingface_model = HuggingFaceModel(
   env=hub,                                                # configuration for loading model from Hub
   role=role,                                              # IAM role with permissions to create an endpoint
   transformers_version="4.6",                             # Transformers version used
   pytorch_version="1.7",                                  # PyTorch version used
   py_version='py36',                                      # Python version used
)

# create transformer to run a batch job
batch_job = huggingface_model.transformer(
    instance_count=1,
    instance_type='ml.p3.2xlarge',
    strategy='SingleRecord'
)

# starts batch transform job and uses S3 data as input
batch_job.transform(
    data='s3://sagemaker-s3-demo-test/samples/input.jsonl',
    content_type='application/json',    
    split_type='Line'
)`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface.model <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># Hub model configuration &lt;https://huggingface.co/models&gt;</span>
hub = {
	<span class="hljs-string">&#x27;HF_MODEL_ID&#x27;</span>:<span class="hljs-string">&#x27;distilbert-base-uncased-finetuned-sst-2-english&#x27;</span>,
	<span class="hljs-string">&#x27;HF_TASK&#x27;</span>:<span class="hljs-string">&#x27;text-classification&#x27;</span>
}

<span class="hljs-comment"># create Hugging Face Model Class</span>
huggingface_model = HuggingFaceModel(
   env=hub,                                                <span class="hljs-comment"># configuration for loading model from Hub</span>
   role=role,                                              <span class="hljs-comment"># IAM role with permissions to create an endpoint</span>
   transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,                             <span class="hljs-comment"># Transformers version used</span>
   pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                                  <span class="hljs-comment"># PyTorch version used</span>
   py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,                                      <span class="hljs-comment"># Python version used</span>
)

<span class="hljs-comment"># create transformer to run a batch job</span>
batch_job = huggingface_model.transformer(
    instance_count=<span class="hljs-number">1</span>,
    instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
    strategy=<span class="hljs-string">&#x27;SingleRecord&#x27;</span>
)

<span class="hljs-comment"># starts batch transform job and uses S3 data as input</span>
batch_job.transform(
    data=<span class="hljs-string">&#x27;s3://sagemaker-s3-demo-test/samples/input.jsonl&#x27;</span>,
    content_type=<span class="hljs-string">&#x27;application/json&#x27;</span>,    
    split_type=<span class="hljs-string">&#x27;Line&#x27;</span>
)`}}),Dt=new w({props:{code:`{"inputs":"this movie is terrible"}
{"inputs":"this movie is amazing"}
{"inputs":"SageMaker is pretty cool"}
{"inputs":"SageMaker is pretty cool"}
{"inputs":"this movie is terrible"}
{"inputs":"this movie is amazing"}`,highlighted:`<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is terrible&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is amazing&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;SageMaker is pretty cool&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;SageMaker is pretty cool&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is terrible&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is amazing&quot;</span><span class="hljs-punctuation">}</span>`}}),xt=new ne({}),Mt=new w({props:{code:`model.tar.gz/
|- pytorch_model.bin
|- ....
|- code/
  |- inference.py
  |- requirements.txt `,highlighted:`model.tar.gz/
|- pytorch_model.bin
|- ....
|- code/
  |- inference.py
  |- requirements.txt `}}),Ht=new w({props:{code:`def model_fn(model_dir):
    return "model"

def input_fn(data, content_type):
    return "data"

def predict_fn(data, model):
    return "output"

def output_fn(prediction, accept):
    return prediction`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">model_fn</span>(<span class="hljs-params">model_dir</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;model&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">input_fn</span>(<span class="hljs-params">data, content_type</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;data&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_fn</span>(<span class="hljs-params">data, model</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;output&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">output_fn</span>(<span class="hljs-params">prediction, accept</span>):
    <span class="hljs-keyword">return</span> prediction`}}),Ot=new w({props:{code:`def model_fn(model_dir):
    return "loading model"

def transform_fn(model, input_data, content_type, accept):
    return f"output"`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">model_fn</span>(<span class="hljs-params">model_dir</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;loading model&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">transform_fn</span>(<span class="hljs-params">model, input_data, content_type, accept</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;output&quot;</span>`}}),{c(){J=r("meta"),gs=d(),Q=r("h1"),ie=r("a"),Eo=r("span"),u(ze.$$.fragment),hl=d(),bo=r("span"),gl=a("Deploy models to Amazon SageMaker"),_s=d(),At=r("p"),_l=a("Deploying a \u{1F917} Transformers models in SageMaker for inference is as easy as:"),vs=d(),u(Ne.$$.fragment),ys=d(),P=r("p"),vl=a("This guide will show you how to deploy models with zero-code using the "),Re=r("a"),yl=a("Inference Toolkit"),wl=a(". The Inference Toolkit builds on top of the "),pe=r("a"),ko=r("code"),El=a("pipeline"),bl=a(" feature"),kl=a(" from \u{1F917} Transformers. Learn how to:"),ws=d(),k=r("ul"),Pt=r("li"),Ft=r("a"),$l=a("Install and setup the Inference Toolkit"),jl=a("."),Sl=d(),Lt=r("li"),zt=r("a"),Dl=a("Deploy a \u{1F917} Transformers model trained in SageMaker"),ql=a("."),xl=d(),Nt=r("li"),Rt=r("a"),Ml=a("Deploy a \u{1F917} Transformers model from the Hugging Face [model Hub](https://huggingface.co/models)"),Cl=a("."),Tl=d(),Ut=r("li"),Yt=r("a"),Hl=a("Run a Batch Transform Job using \u{1F917} Transformers and Amazon SageMaker"),Ol=a("."),Il=d(),Bt=r("li"),Wt=r("a"),Al=a("Create a custom inference module"),Pl=a("."),Es=d(),Z=r("h2"),de=r("a"),$o=r("span"),u(Ue.$$.fragment),Fl=d(),jo=r("span"),Ll=a("Installation and setup"),bs=d(),ce=r("p"),zl=a("Before deploying a \u{1F917} Transformers model to SageMaker, you need to sign up for an AWS account. If you don\u2019t have an AWS account yet, learn more "),Ye=r("a"),Nl=a("here"),Rl=a("."),ks=d(),Kt=r("p"),Ul=a("Once you have an AWS account, get started using one of the following:"),$s=d(),F=r("ul"),So=r("li"),Be=r("a"),Yl=a("SageMaker Studio"),Bl=d(),Do=r("li"),We=r("a"),Wl=a("SageMaker notebook instance"),Kl=d(),qo=r("li"),Gl=a("Local environment"),js=d(),fe=r("p"),Jl=a("To start training locally, you need to setup an appropriate "),Ke=r("a"),Ql=a("IAM role"),Zl=a("."),Ss=d(),ue=r("p"),Vl=a("Upgrade to the latest "),xo=r("code"),Xl=a("sagemaker"),en=a(" version."),Ds=d(),u(Ge.$$.fragment),qs=d(),Gt=r("p"),Mo=r("strong"),tn=a("SageMaker environment"),xs=d(),Jt=r("p"),on=a("Setup your SageMaker environment as shown below:"),Ms=d(),u(Je.$$.fragment),Cs=d(),Qt=r("p"),V=r("em"),an=a("Note: The execution role is only available when running a notebook within SageMaker. If you run "),Co=r("code"),sn=a("get_execution_role"),rn=a(" in a notebook not on SageMaker, expect a "),To=r("code"),ln=a("region"),nn=a(" error."),Ts=d(),Zt=r("p"),Ho=r("strong"),pn=a("Local environment"),Hs=d(),Vt=r("p"),dn=a("Setup your local environment as shown below:"),Os=d(),u(Qe.$$.fragment),Is=d(),X=r("h2"),me=r("a"),Oo=r("span"),u(Ze.$$.fragment),cn=d(),Io=r("span"),fn=a("Deploy a \u{1F917} Transformers model trained in SageMaker"),As=d(),q=r("iframe"),Ps=d(),Xt=r("p"),un=a("There are two ways to deploy your Hugging Face model trained in SageMaker:"),Fs=d(),he=r("ul"),Ao=r("li"),mn=a("Deploy it after your training has finished."),hn=d(),Ve=r("li"),gn=a("Deploy your saved model at a later time from S3 with the "),Po=r("code"),_n=a("model_data"),vn=a("."),Ls=d(),ge=r("p"),yn=a("\u{1F4D3} Open the "),Xe=r("a"),wn=a("notebook"),En=a(" for an example of how to deploy a model from S3 to SageMaker for inference."),zs=d(),ee=r("h3"),_e=r("a"),Fo=r("span"),u(et.$$.fragment),bn=d(),Lo=r("span"),kn=a("Deploy after training"),Ns=d(),eo=r("p"),$n=a("To deploy your model directly after training, ensure all required files are saved in your training script, including the tokenizer and the model."),Rs=d(),T=r("p"),jn=a("If you use the Hugging Face "),zo=r("code"),Sn=a("Trainer"),Dn=a(", you can pass your tokenizer as an argument to the "),No=r("code"),qn=a("Trainer"),xn=a(". It will be automatically saved when you call "),Ro=r("code"),Mn=a("trainer.save_model()"),Cn=a("."),Us=d(),u(tt.$$.fragment),Ys=d(),to=r("p"),Tn=a("After you run your request you can delete the endpoint as shown:"),Bs=d(),u(ot.$$.fragment),Ws=d(),te=r("h3"),ve=r("a"),Uo=r("span"),u(at.$$.fragment),Hn=d(),oo=r("span"),On=a("Deploy with "),Yo=r("code"),In=a("model_data"),Ks=d(),ye=r("p"),An=a("If you\u2019ve already trained your model and want to deploy it at a later time, use the "),Bo=r("code"),Pn=a("model_data"),Fn=a(" argument to specify the location of your tokenizer and model weights."),Gs=d(),u(st.$$.fragment),Js=d(),ao=r("p"),Ln=a("After you run our request, you can delete the endpoint again with:"),Qs=d(),u(rt.$$.fragment),Zs=d(),oe=r("h3"),we=r("a"),Wo=r("span"),u(lt.$$.fragment),zn=d(),Ko=r("span"),Nn=a("Create a model artifact for deployment"),Vs=d(),Ee=r("p"),Rn=a("For later deployment, you can create a "),Go=r("code"),Un=a("model.tar.gz"),Yn=a(" file that contains all the required files, such as:"),Xs=d(),H=r("ul"),Jo=r("li"),Qo=r("code"),Bn=a("pytorch_model.bin"),Wn=d(),Zo=r("li"),Vo=r("code"),Kn=a("tf_model.h5"),Gn=d(),Xo=r("li"),ea=r("code"),Jn=a("tokenizer.json"),Qn=d(),ta=r("li"),oa=r("code"),Zn=a("tokenizer_config.json"),er=d(),so=r("p"),Vn=a("For example, your file should look like this:"),tr=d(),u(nt.$$.fragment),or=d(),be=r("p"),Xn=a("Create your own "),aa=r("code"),ei=a("model.tar.gz"),ti=a(" from a model from the \u{1F917} Hub:"),ar=d(),ro=r("ol"),sa=r("li"),oi=a("Download a model:"),sr=d(),u(it.$$.fragment),rr=d(),pt=r("ol"),dt=r("li"),ai=a("Create a "),ra=r("code"),si=a("tar"),ri=a(" file:"),lr=d(),u(ct.$$.fragment),nr=d(),ft=r("ol"),ut=r("li"),li=a("Upload "),la=r("code"),ni=a("model.tar.gz"),ii=a(" to S3:"),ir=d(),u(mt.$$.fragment),pr=d(),ke=r("p"),pi=a("Now you can provide the S3 URI to the "),na=r("code"),di=a("model_data"),ci=a(" argument to deploy your model later."),dr=d(),ae=r("h2"),$e=r("a"),ia=r("span"),u(ht.$$.fragment),fi=d(),pa=r("span"),ui=a("Deploy a model from the \u{1F917} Hub"),cr=d(),x=r("iframe"),fr=d(),je=r("p"),mi=a("To deploy a model directly from the \u{1F917} Hub to SageMaker, define two environment variables when you create a "),da=r("code"),hi=a("HuggingFaceModel"),gi=a(":"),ur=d(),Se=r("ul"),De=r("li"),ca=r("code"),_i=a("HF_MODEL_ID"),vi=a(" defines the model ID which is automatically loaded from "),gt=r("a"),yi=a("huggingface.co/models"),wi=a(" when you create a SageMaker endpoint. Access 10,000+ models on he \u{1F917} Hub through this environment variable."),Ei=d(),L=r("li"),fa=r("code"),bi=a("HF_TASK"),ki=a(" defines the task for the \u{1F917} Transformers "),ua=r("code"),$i=a("pipeline"),ji=a(". A complete list of tasks can be found "),_t=r("a"),Si=a("here"),Di=a("."),mr=d(),u(vt.$$.fragment),hr=d(),lo=r("p"),qi=a("After you run our request, you can delete the endpoint again with:"),gr=d(),u(yt.$$.fragment),_r=d(),qe=r("p"),xi=a("\u{1F4D3} Open the "),wt=r("a"),Mi=a("notebook"),Ci=a(" for an example of how to deploy a model from the \u{1F917} Hub to SageMaker for inference."),vr=d(),se=r("h2"),xe=r("a"),ma=r("span"),u(Et.$$.fragment),Ti=d(),ha=r("span"),Hi=a("Run batch transform with \u{1F917} Transformers and SageMaker"),yr=d(),M=r("iframe"),wr=d(),z=r("p"),Oi=a("After training a model, you can use "),bt=r("a"),Ii=a("SageMaker batch transform"),Ai=a(" to perform inference with the model. Batch transform accepts your inference data as an S3 URI  and then SageMaker will take care of downloading the data, running the prediction, and uploading the results to S3. For more details about batch transform, take a look "),kt=r("a"),Pi=a("here"),Fi=a("."),Er=d(),Me=r("p"),Li=a("\u26A0\uFE0F The Hugging Face Inference DLC currently only supports "),ga=r("code"),zi=a(".jsonl"),Ni=a(" for batch transform due to the complex structure of textual data."),br=d(),no=r("p"),re=r("em"),Ri=a("Note: Make sure your "),_a=r("code"),Ui=a("inputs"),Yi=a(" fit the "),va=r("code"),Bi=a("max_length"),Wi=a(" of the model during preprocessing."),kr=d(),N=r("p"),Ki=a("If you trained a model using the Hugging Face Estimator, call the "),ya=r("code"),Gi=a("transformer()"),Ji=a(" method to create a transform job for a model based on the training job (see "),$t=r("a"),Qi=a("here"),Zi=a(" for more details):"),$r=d(),u(jt.$$.fragment),jr=d(),R=r("p"),Vi=a("If you want to run your batch transform job later or with a model from the \u{1F917} Hub, create a "),wa=r("code"),Xi=a("HuggingFaceModel"),ep=a(" instance and then call the "),Ea=r("code"),tp=a("transformer()"),op=a(" method:"),Sr=d(),u(St.$$.fragment),Dr=d(),Ce=r("p"),ap=a("The "),ba=r("code"),sp=a("input.jsonl"),rp=a(" looks like this:"),qr=d(),u(Dt.$$.fragment),xr=d(),Te=r("p"),lp=a("\u{1F4D3} Open the "),qt=r("a"),np=a("notebook"),ip=a(" for an example of how to run a batch transform job for inference."),Mr=d(),le=r("h2"),He=r("a"),ka=r("span"),u(xt.$$.fragment),pp=d(),$a=r("span"),dp=a("User defined code and modules"),Cr=d(),$=r("p"),cp=a("The Hugging Face Inference Toolkit allows the user to override the default methods of the "),ja=r("code"),fp=a("HuggingFaceHandlerService"),up=a(". You will need to create a folder named "),Sa=r("code"),mp=a("code/"),hp=a(" with an "),Da=r("code"),gp=a("inference.py"),_p=a(" file in it. See "),io=r("a"),vp=a("here"),yp=a(" for more details on how to archive your model artifacts. For example:"),Tr=d(),u(Mt.$$.fragment),Hr=d(),U=r("p"),wp=a("The "),qa=r("code"),Ep=a("inference.py"),bp=a(" file contains your custom inference module, and the "),xa=r("code"),kp=a("requirements.txt"),$p=a(" file contains additional dependencies that should be added. The custom module can override the following methods:"),Or=d(),j=r("ul"),b=r("li"),Ma=r("code"),jp=a("model_fn(model_dir)"),Sp=a(" overrides the default method for loading a model. The return value "),Ca=r("code"),Dp=a("model"),qp=a(" will be used in "),Ta=r("code"),xp=a("predict"),Mp=a(" for predictions. "),Ha=r("code"),Cp=a("predict"),Tp=a(" receives argument the "),Oa=r("code"),Hp=a("model_dir"),Op=a(", the path to your unzipped "),Ia=r("code"),Ip=a("model.tar.gz"),Ap=a("."),Pp=d(),y=r("li"),Aa=r("code"),Fp=a("transform_fn(model, data, content_type, accept_type)"),Lp=a(" overrides the default transform function with your custom implementation. You will need to implement your own "),Pa=r("code"),zp=a("preprocess"),Np=a(", "),Fa=r("code"),Rp=a("predict"),Up=a(" and "),La=r("code"),Yp=a("postprocess"),Bp=a(" steps in the "),za=r("code"),Wp=a("transform_fn"),Kp=a(". This method can\u2019t be combined with "),Na=r("code"),Gp=a("input_fn"),Jp=a(", "),Ra=r("code"),Qp=a("predict_fn"),Zp=a(" or "),Ua=r("code"),Vp=a("output_fn"),Xp=a(" mentioned below."),ed=d(),O=r("li"),Ya=r("code"),td=a("input_fn(input_data, content_type)"),od=a(" overrides the default method for preprocessing. The return value "),Ba=r("code"),ad=a("data"),sd=a(" will be used in "),Wa=r("code"),rd=a("predict"),ld=a(" for predicitions. The inputs are:"),Ct=r("ul"),po=r("li"),Ka=r("code"),nd=a("input_data"),id=a(" is the raw body of your request."),pd=d(),co=r("li"),Ga=r("code"),dd=a("content_type"),cd=a(" is the content type from the request header."),fd=d(),S=r("li"),Ja=r("code"),ud=a("predict_fn(processed_data, model)"),md=a(" overrides the default method for predictions. The return value "),Qa=r("code"),hd=a("predictions"),gd=a(" will be used in "),Za=r("code"),_d=a("postprocess"),vd=a(". The input is "),Va=r("code"),yd=a("processed_data"),wd=a(", the result from "),Xa=r("code"),Ed=a("preprocess"),bd=a("."),kd=d(),I=r("li"),es=r("code"),$d=a("output_fn(prediction, accept)"),jd=a(" overrides the default method for postprocessing. The return value "),ts=r("code"),Sd=a("result"),Dd=a(" will be the response of your request (e.g."),os=r("code"),qd=a("JSON"),xd=a("). The inputs are:"),Tt=r("ul"),Oe=r("li"),as=r("code"),Md=a("predictions"),Cd=a(" is the result from "),ss=r("code"),Td=a("predict"),Hd=a("."),Od=d(),Ie=r("li"),rs=r("code"),Id=a("accept"),Ad=a(" is the return accept type from the HTTP Request, e.g. "),ls=r("code"),Pd=a("application/json"),Fd=a("."),Ir=d(),D=r("p"),Ld=a("Here is an example of a custom inference module with "),ns=r("code"),zd=a("model_fn"),Nd=a(", "),is=r("code"),Rd=a("input_fn"),Ud=a(", "),ps=r("code"),Yd=a("predict_fn"),Bd=a(", and "),ds=r("code"),Wd=a("output_fn"),Kd=a(":"),Ar=d(),u(Ht.$$.fragment),Pr=d(),Y=r("p"),Gd=a("Customize your inference module with only "),cs=r("code"),Jd=a("model_fn"),Qd=a(" and "),fs=r("code"),Zd=a("transform_fn"),Vd=a(":"),Fr=d(),u(Ot.$$.fragment),this.h()},l(e){const i=em('[data-svelte="svelte-1phssyn"]',document.head);J=l(i,"META",{name:!0,content:!0}),i.forEach(o),gs=c(e),Q=l(e,"H1",{class:!0});var zr=n(Q);ie=l(zr,"A",{id:!0,class:!0,href:!0});var uc=n(ie);Eo=l(uc,"SPAN",{});var mc=n(Eo);m(ze.$$.fragment,mc),mc.forEach(o),uc.forEach(o),hl=c(zr),bo=l(zr,"SPAN",{});var hc=n(bo);gl=s(hc,"Deploy models to Amazon SageMaker"),hc.forEach(o),zr.forEach(o),_s=c(e),At=l(e,"P",{});var gc=n(At);_l=s(gc,"Deploying a \u{1F917} Transformers models in SageMaker for inference is as easy as:"),gc.forEach(o),vs=c(e),m(Ne.$$.fragment,e),ys=c(e),P=l(e,"P",{});var fo=n(P);vl=s(fo,"This guide will show you how to deploy models with zero-code using the "),Re=l(fo,"A",{href:!0,rel:!0});var _c=n(Re);yl=s(_c,"Inference Toolkit"),_c.forEach(o),wl=s(fo,". The Inference Toolkit builds on top of the "),pe=l(fo,"A",{href:!0,rel:!0});var Xd=n(pe);ko=l(Xd,"CODE",{});var vc=n(ko);El=s(vc,"pipeline"),vc.forEach(o),bl=s(Xd," feature"),Xd.forEach(o),kl=s(fo," from \u{1F917} Transformers. Learn how to:"),fo.forEach(o),ws=c(e),k=l(e,"UL",{});var B=n(k);Pt=l(B,"LI",{});var ec=n(Pt);Ft=l(ec,"A",{href:!0});var yc=n(Ft);$l=s(yc,"Install and setup the Inference Toolkit"),yc.forEach(o),jl=s(ec,"."),ec.forEach(o),Sl=c(B),Lt=l(B,"LI",{});var tc=n(Lt);zt=l(tc,"A",{href:!0});var wc=n(zt);Dl=s(wc,"Deploy a \u{1F917} Transformers model trained in SageMaker"),wc.forEach(o),ql=s(tc,"."),tc.forEach(o),xl=c(B),Nt=l(B,"LI",{});var oc=n(Nt);Rt=l(oc,"A",{href:!0});var Ec=n(Rt);Ml=s(Ec,"Deploy a \u{1F917} Transformers model from the Hugging Face [model Hub](https://huggingface.co/models)"),Ec.forEach(o),Cl=s(oc,"."),oc.forEach(o),Tl=c(B),Ut=l(B,"LI",{});var ac=n(Ut);Yt=l(ac,"A",{href:!0});var bc=n(Yt);Hl=s(bc,"Run a Batch Transform Job using \u{1F917} Transformers and Amazon SageMaker"),bc.forEach(o),Ol=s(ac,"."),ac.forEach(o),Il=c(B),Bt=l(B,"LI",{});var sc=n(Bt);Wt=l(sc,"A",{href:!0});var kc=n(Wt);Al=s(kc,"Create a custom inference module"),kc.forEach(o),Pl=s(sc,"."),sc.forEach(o),B.forEach(o),Es=c(e),Z=l(e,"H2",{class:!0});var Nr=n(Z);de=l(Nr,"A",{id:!0,class:!0,href:!0});var $c=n(de);$o=l($c,"SPAN",{});var jc=n($o);m(Ue.$$.fragment,jc),jc.forEach(o),$c.forEach(o),Fl=c(Nr),jo=l(Nr,"SPAN",{});var Sc=n(jo);Ll=s(Sc,"Installation and setup"),Sc.forEach(o),Nr.forEach(o),bs=c(e),ce=l(e,"P",{});var Rr=n(ce);zl=s(Rr,"Before deploying a \u{1F917} Transformers model to SageMaker, you need to sign up for an AWS account. If you don\u2019t have an AWS account yet, learn more "),Ye=l(Rr,"A",{href:!0,rel:!0});var Dc=n(Ye);Nl=s(Dc,"here"),Dc.forEach(o),Rl=s(Rr,"."),Rr.forEach(o),ks=c(e),Kt=l(e,"P",{});var qc=n(Kt);Ul=s(qc,"Once you have an AWS account, get started using one of the following:"),qc.forEach(o),$s=c(e),F=l(e,"UL",{});var uo=n(F);So=l(uo,"LI",{});var xc=n(So);Be=l(xc,"A",{href:!0,rel:!0});var Mc=n(Be);Yl=s(Mc,"SageMaker Studio"),Mc.forEach(o),xc.forEach(o),Bl=c(uo),Do=l(uo,"LI",{});var Cc=n(Do);We=l(Cc,"A",{href:!0,rel:!0});var Tc=n(We);Wl=s(Tc,"SageMaker notebook instance"),Tc.forEach(o),Cc.forEach(o),Kl=c(uo),qo=l(uo,"LI",{});var Hc=n(qo);Gl=s(Hc,"Local environment"),Hc.forEach(o),uo.forEach(o),js=c(e),fe=l(e,"P",{});var Ur=n(fe);Jl=s(Ur,"To start training locally, you need to setup an appropriate "),Ke=l(Ur,"A",{href:!0,rel:!0});var Oc=n(Ke);Ql=s(Oc,"IAM role"),Oc.forEach(o),Zl=s(Ur,"."),Ur.forEach(o),Ss=c(e),ue=l(e,"P",{});var Yr=n(ue);Vl=s(Yr,"Upgrade to the latest "),xo=l(Yr,"CODE",{});var Ic=n(xo);Xl=s(Ic,"sagemaker"),Ic.forEach(o),en=s(Yr," version."),Yr.forEach(o),Ds=c(e),m(Ge.$$.fragment,e),qs=c(e),Gt=l(e,"P",{});var Ac=n(Gt);Mo=l(Ac,"STRONG",{});var Pc=n(Mo);tn=s(Pc,"SageMaker environment"),Pc.forEach(o),Ac.forEach(o),xs=c(e),Jt=l(e,"P",{});var Fc=n(Jt);on=s(Fc,"Setup your SageMaker environment as shown below:"),Fc.forEach(o),Ms=c(e),m(Je.$$.fragment,e),Cs=c(e),Qt=l(e,"P",{});var Lc=n(Qt);V=l(Lc,"EM",{});var mo=n(V);an=s(mo,"Note: The execution role is only available when running a notebook within SageMaker. If you run "),Co=l(mo,"CODE",{});var zc=n(Co);sn=s(zc,"get_execution_role"),zc.forEach(o),rn=s(mo," in a notebook not on SageMaker, expect a "),To=l(mo,"CODE",{});var Nc=n(To);ln=s(Nc,"region"),Nc.forEach(o),nn=s(mo," error."),mo.forEach(o),Lc.forEach(o),Ts=c(e),Zt=l(e,"P",{});var Rc=n(Zt);Ho=l(Rc,"STRONG",{});var Uc=n(Ho);pn=s(Uc,"Local environment"),Uc.forEach(o),Rc.forEach(o),Hs=c(e),Vt=l(e,"P",{});var Yc=n(Vt);dn=s(Yc,"Setup your local environment as shown below:"),Yc.forEach(o),Os=c(e),m(Qe.$$.fragment,e),Is=c(e),X=l(e,"H2",{class:!0});var Br=n(X);me=l(Br,"A",{id:!0,class:!0,href:!0});var Bc=n(me);Oo=l(Bc,"SPAN",{});var Wc=n(Oo);m(Ze.$$.fragment,Wc),Wc.forEach(o),Bc.forEach(o),cn=c(Br),Io=l(Br,"SPAN",{});var Kc=n(Io);fn=s(Kc,"Deploy a \u{1F917} Transformers model trained in SageMaker"),Kc.forEach(o),Br.forEach(o),As=c(e),q=l(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(q).forEach(o),Ps=c(e),Xt=l(e,"P",{});var Gc=n(Xt);un=s(Gc,"There are two ways to deploy your Hugging Face model trained in SageMaker:"),Gc.forEach(o),Fs=c(e),he=l(e,"UL",{});var Wr=n(he);Ao=l(Wr,"LI",{});var Jc=n(Ao);mn=s(Jc,"Deploy it after your training has finished."),Jc.forEach(o),hn=c(Wr),Ve=l(Wr,"LI",{});var Kr=n(Ve);gn=s(Kr,"Deploy your saved model at a later time from S3 with the "),Po=l(Kr,"CODE",{});var Qc=n(Po);_n=s(Qc,"model_data"),Qc.forEach(o),vn=s(Kr,"."),Kr.forEach(o),Wr.forEach(o),Ls=c(e),ge=l(e,"P",{});var Gr=n(ge);yn=s(Gr,"\u{1F4D3} Open the "),Xe=l(Gr,"A",{href:!0,rel:!0});var Zc=n(Xe);wn=s(Zc,"notebook"),Zc.forEach(o),En=s(Gr," for an example of how to deploy a model from S3 to SageMaker for inference."),Gr.forEach(o),zs=c(e),ee=l(e,"H3",{class:!0});var Jr=n(ee);_e=l(Jr,"A",{id:!0,class:!0,href:!0});var Vc=n(_e);Fo=l(Vc,"SPAN",{});var Xc=n(Fo);m(et.$$.fragment,Xc),Xc.forEach(o),Vc.forEach(o),bn=c(Jr),Lo=l(Jr,"SPAN",{});var ef=n(Lo);kn=s(ef,"Deploy after training"),ef.forEach(o),Jr.forEach(o),Ns=c(e),eo=l(e,"P",{});var tf=n(eo);$n=s(tf,"To deploy your model directly after training, ensure all required files are saved in your training script, including the tokenizer and the model."),tf.forEach(o),Rs=c(e),T=l(e,"P",{});var Ae=n(T);jn=s(Ae,"If you use the Hugging Face "),zo=l(Ae,"CODE",{});var of=n(zo);Sn=s(of,"Trainer"),of.forEach(o),Dn=s(Ae,", you can pass your tokenizer as an argument to the "),No=l(Ae,"CODE",{});var af=n(No);qn=s(af,"Trainer"),af.forEach(o),xn=s(Ae,". It will be automatically saved when you call "),Ro=l(Ae,"CODE",{});var sf=n(Ro);Mn=s(sf,"trainer.save_model()"),sf.forEach(o),Cn=s(Ae,"."),Ae.forEach(o),Us=c(e),m(tt.$$.fragment,e),Ys=c(e),to=l(e,"P",{});var rf=n(to);Tn=s(rf,"After you run your request you can delete the endpoint as shown:"),rf.forEach(o),Bs=c(e),m(ot.$$.fragment,e),Ws=c(e),te=l(e,"H3",{class:!0});var Qr=n(te);ve=l(Qr,"A",{id:!0,class:!0,href:!0});var lf=n(ve);Uo=l(lf,"SPAN",{});var nf=n(Uo);m(at.$$.fragment,nf),nf.forEach(o),lf.forEach(o),Hn=c(Qr),oo=l(Qr,"SPAN",{});var rc=n(oo);On=s(rc,"Deploy with "),Yo=l(rc,"CODE",{});var pf=n(Yo);In=s(pf,"model_data"),pf.forEach(o),rc.forEach(o),Qr.forEach(o),Ks=c(e),ye=l(e,"P",{});var Zr=n(ye);An=s(Zr,"If you\u2019ve already trained your model and want to deploy it at a later time, use the "),Bo=l(Zr,"CODE",{});var df=n(Bo);Pn=s(df,"model_data"),df.forEach(o),Fn=s(Zr," argument to specify the location of your tokenizer and model weights."),Zr.forEach(o),Gs=c(e),m(st.$$.fragment,e),Js=c(e),ao=l(e,"P",{});var cf=n(ao);Ln=s(cf,"After you run our request, you can delete the endpoint again with:"),cf.forEach(o),Qs=c(e),m(rt.$$.fragment,e),Zs=c(e),oe=l(e,"H3",{class:!0});var Vr=n(oe);we=l(Vr,"A",{id:!0,class:!0,href:!0});var ff=n(we);Wo=l(ff,"SPAN",{});var uf=n(Wo);m(lt.$$.fragment,uf),uf.forEach(o),ff.forEach(o),zn=c(Vr),Ko=l(Vr,"SPAN",{});var mf=n(Ko);Nn=s(mf,"Create a model artifact for deployment"),mf.forEach(o),Vr.forEach(o),Vs=c(e),Ee=l(e,"P",{});var Xr=n(Ee);Rn=s(Xr,"For later deployment, you can create a "),Go=l(Xr,"CODE",{});var hf=n(Go);Un=s(hf,"model.tar.gz"),hf.forEach(o),Yn=s(Xr," file that contains all the required files, such as:"),Xr.forEach(o),Xs=c(e),H=l(e,"UL",{});var Pe=n(H);Jo=l(Pe,"LI",{});var gf=n(Jo);Qo=l(gf,"CODE",{});var _f=n(Qo);Bn=s(_f,"pytorch_model.bin"),_f.forEach(o),gf.forEach(o),Wn=c(Pe),Zo=l(Pe,"LI",{});var vf=n(Zo);Vo=l(vf,"CODE",{});var yf=n(Vo);Kn=s(yf,"tf_model.h5"),yf.forEach(o),vf.forEach(o),Gn=c(Pe),Xo=l(Pe,"LI",{});var wf=n(Xo);ea=l(wf,"CODE",{});var Ef=n(ea);Jn=s(Ef,"tokenizer.json"),Ef.forEach(o),wf.forEach(o),Qn=c(Pe),ta=l(Pe,"LI",{});var bf=n(ta);oa=l(bf,"CODE",{});var kf=n(oa);Zn=s(kf,"tokenizer_config.json"),kf.forEach(o),bf.forEach(o),Pe.forEach(o),er=c(e),so=l(e,"P",{});var $f=n(so);Vn=s($f,"For example, your file should look like this:"),$f.forEach(o),tr=c(e),m(nt.$$.fragment,e),or=c(e),be=l(e,"P",{});var el=n(be);Xn=s(el,"Create your own "),aa=l(el,"CODE",{});var jf=n(aa);ei=s(jf,"model.tar.gz"),jf.forEach(o),ti=s(el," from a model from the \u{1F917} Hub:"),el.forEach(o),ar=c(e),ro=l(e,"OL",{});var Sf=n(ro);sa=l(Sf,"LI",{});var Df=n(sa);oi=s(Df,"Download a model:"),Df.forEach(o),Sf.forEach(o),sr=c(e),m(it.$$.fragment,e),rr=c(e),pt=l(e,"OL",{start:!0});var qf=n(pt);dt=l(qf,"LI",{});var tl=n(dt);ai=s(tl,"Create a "),ra=l(tl,"CODE",{});var xf=n(ra);si=s(xf,"tar"),xf.forEach(o),ri=s(tl," file:"),tl.forEach(o),qf.forEach(o),lr=c(e),m(ct.$$.fragment,e),nr=c(e),ft=l(e,"OL",{start:!0});var Mf=n(ft);ut=l(Mf,"LI",{});var ol=n(ut);li=s(ol,"Upload "),la=l(ol,"CODE",{});var Cf=n(la);ni=s(Cf,"model.tar.gz"),Cf.forEach(o),ii=s(ol," to S3:"),ol.forEach(o),Mf.forEach(o),ir=c(e),m(mt.$$.fragment,e),pr=c(e),ke=l(e,"P",{});var al=n(ke);pi=s(al,"Now you can provide the S3 URI to the "),na=l(al,"CODE",{});var Tf=n(na);di=s(Tf,"model_data"),Tf.forEach(o),ci=s(al," argument to deploy your model later."),al.forEach(o),dr=c(e),ae=l(e,"H2",{class:!0});var sl=n(ae);$e=l(sl,"A",{id:!0,class:!0,href:!0});var Hf=n($e);ia=l(Hf,"SPAN",{});var Of=n(ia);m(ht.$$.fragment,Of),Of.forEach(o),Hf.forEach(o),fi=c(sl),pa=l(sl,"SPAN",{});var If=n(pa);ui=s(If,"Deploy a model from the \u{1F917} Hub"),If.forEach(o),sl.forEach(o),cr=c(e),x=l(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(x).forEach(o),fr=c(e),je=l(e,"P",{});var rl=n(je);mi=s(rl,"To deploy a model directly from the \u{1F917} Hub to SageMaker, define two environment variables when you create a "),da=l(rl,"CODE",{});var Af=n(da);hi=s(Af,"HuggingFaceModel"),Af.forEach(o),gi=s(rl,":"),rl.forEach(o),ur=c(e),Se=l(e,"UL",{});var ll=n(Se);De=l(ll,"LI",{});var us=n(De);ca=l(us,"CODE",{});var Pf=n(ca);_i=s(Pf,"HF_MODEL_ID"),Pf.forEach(o),vi=s(us," defines the model ID which is automatically loaded from "),gt=l(us,"A",{href:!0,rel:!0});var Ff=n(gt);yi=s(Ff,"huggingface.co/models"),Ff.forEach(o),wi=s(us," when you create a SageMaker endpoint. Access 10,000+ models on he \u{1F917} Hub through this environment variable."),us.forEach(o),Ei=c(ll),L=l(ll,"LI",{});var It=n(L);fa=l(It,"CODE",{});var Lf=n(fa);bi=s(Lf,"HF_TASK"),Lf.forEach(o),ki=s(It," defines the task for the \u{1F917} Transformers "),ua=l(It,"CODE",{});var zf=n(ua);$i=s(zf,"pipeline"),zf.forEach(o),ji=s(It,". A complete list of tasks can be found "),_t=l(It,"A",{href:!0,rel:!0});var Nf=n(_t);Si=s(Nf,"here"),Nf.forEach(o),Di=s(It,"."),It.forEach(o),ll.forEach(o),mr=c(e),m(vt.$$.fragment,e),hr=c(e),lo=l(e,"P",{});var Rf=n(lo);qi=s(Rf,"After you run our request, you can delete the endpoint again with:"),Rf.forEach(o),gr=c(e),m(yt.$$.fragment,e),_r=c(e),qe=l(e,"P",{});var nl=n(qe);xi=s(nl,"\u{1F4D3} Open the "),wt=l(nl,"A",{href:!0,rel:!0});var Uf=n(wt);Mi=s(Uf,"notebook"),Uf.forEach(o),Ci=s(nl," for an example of how to deploy a model from the \u{1F917} Hub to SageMaker for inference."),nl.forEach(o),vr=c(e),se=l(e,"H2",{class:!0});var il=n(se);xe=l(il,"A",{id:!0,class:!0,href:!0});var Yf=n(xe);ma=l(Yf,"SPAN",{});var Bf=n(ma);m(Et.$$.fragment,Bf),Bf.forEach(o),Yf.forEach(o),Ti=c(il),ha=l(il,"SPAN",{});var Wf=n(ha);Hi=s(Wf,"Run batch transform with \u{1F917} Transformers and SageMaker"),Wf.forEach(o),il.forEach(o),yr=c(e),M=l(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(M).forEach(o),wr=c(e),z=l(e,"P",{});var ho=n(z);Oi=s(ho,"After training a model, you can use "),bt=l(ho,"A",{href:!0,rel:!0});var Kf=n(bt);Ii=s(Kf,"SageMaker batch transform"),Kf.forEach(o),Ai=s(ho," to perform inference with the model. Batch transform accepts your inference data as an S3 URI  and then SageMaker will take care of downloading the data, running the prediction, and uploading the results to S3. For more details about batch transform, take a look "),kt=l(ho,"A",{href:!0,rel:!0});var Gf=n(kt);Pi=s(Gf,"here"),Gf.forEach(o),Fi=s(ho,"."),ho.forEach(o),Er=c(e),Me=l(e,"P",{});var pl=n(Me);Li=s(pl,"\u26A0\uFE0F The Hugging Face Inference DLC currently only supports "),ga=l(pl,"CODE",{});var Jf=n(ga);zi=s(Jf,".jsonl"),Jf.forEach(o),Ni=s(pl," for batch transform due to the complex structure of textual data."),pl.forEach(o),br=c(e),no=l(e,"P",{});var Qf=n(no);re=l(Qf,"EM",{});var go=n(re);Ri=s(go,"Note: Make sure your "),_a=l(go,"CODE",{});var Zf=n(_a);Ui=s(Zf,"inputs"),Zf.forEach(o),Yi=s(go," fit the "),va=l(go,"CODE",{});var Vf=n(va);Bi=s(Vf,"max_length"),Vf.forEach(o),Wi=s(go," of the model during preprocessing."),go.forEach(o),Qf.forEach(o),kr=c(e),N=l(e,"P",{});var _o=n(N);Ki=s(_o,"If you trained a model using the Hugging Face Estimator, call the "),ya=l(_o,"CODE",{});var Xf=n(ya);Gi=s(Xf,"transformer()"),Xf.forEach(o),Ji=s(_o," method to create a transform job for a model based on the training job (see "),$t=l(_o,"A",{href:!0,rel:!0});var eu=n($t);Qi=s(eu,"here"),eu.forEach(o),Zi=s(_o," for more details):"),_o.forEach(o),$r=c(e),m(jt.$$.fragment,e),jr=c(e),R=l(e,"P",{});var vo=n(R);Vi=s(vo,"If you want to run your batch transform job later or with a model from the \u{1F917} Hub, create a "),wa=l(vo,"CODE",{});var tu=n(wa);Xi=s(tu,"HuggingFaceModel"),tu.forEach(o),ep=s(vo," instance and then call the "),Ea=l(vo,"CODE",{});var ou=n(Ea);tp=s(ou,"transformer()"),ou.forEach(o),op=s(vo," method:"),vo.forEach(o),Sr=c(e),m(St.$$.fragment,e),Dr=c(e),Ce=l(e,"P",{});var dl=n(Ce);ap=s(dl,"The "),ba=l(dl,"CODE",{});var au=n(ba);sp=s(au,"input.jsonl"),au.forEach(o),rp=s(dl," looks like this:"),dl.forEach(o),qr=c(e),m(Dt.$$.fragment,e),xr=c(e),Te=l(e,"P",{});var cl=n(Te);lp=s(cl,"\u{1F4D3} Open the "),qt=l(cl,"A",{href:!0,rel:!0});var su=n(qt);np=s(su,"notebook"),su.forEach(o),ip=s(cl," for an example of how to run a batch transform job for inference."),cl.forEach(o),Mr=c(e),le=l(e,"H2",{class:!0});var fl=n(le);He=l(fl,"A",{id:!0,class:!0,href:!0});var ru=n(He);ka=l(ru,"SPAN",{});var lu=n(ka);m(xt.$$.fragment,lu),lu.forEach(o),ru.forEach(o),pp=c(fl),$a=l(fl,"SPAN",{});var nu=n($a);dp=s(nu,"User defined code and modules"),nu.forEach(o),fl.forEach(o),Cr=c(e),$=l(e,"P",{});var W=n($);cp=s(W,"The Hugging Face Inference Toolkit allows the user to override the default methods of the "),ja=l(W,"CODE",{});var iu=n(ja);fp=s(iu,"HuggingFaceHandlerService"),iu.forEach(o),up=s(W,". You will need to create a folder named "),Sa=l(W,"CODE",{});var pu=n(Sa);mp=s(pu,"code/"),pu.forEach(o),hp=s(W," with an "),Da=l(W,"CODE",{});var du=n(Da);gp=s(du,"inference.py"),du.forEach(o),_p=s(W," file in it. See "),io=l(W,"A",{href:!0});var cu=n(io);vp=s(cu,"here"),cu.forEach(o),yp=s(W," for more details on how to archive your model artifacts. For example:"),W.forEach(o),Tr=c(e),m(Mt.$$.fragment,e),Hr=c(e),U=l(e,"P",{});var yo=n(U);wp=s(yo,"The "),qa=l(yo,"CODE",{});var fu=n(qa);Ep=s(fu,"inference.py"),fu.forEach(o),bp=s(yo," file contains your custom inference module, and the "),xa=l(yo,"CODE",{});var uu=n(xa);kp=s(uu,"requirements.txt"),uu.forEach(o),$p=s(yo," file contains additional dependencies that should be added. The custom module can override the following methods:"),yo.forEach(o),Or=c(e),j=l(e,"UL",{});var K=n(j);b=l(K,"LI",{});var C=n(b);Ma=l(C,"CODE",{});var mu=n(Ma);jp=s(mu,"model_fn(model_dir)"),mu.forEach(o),Sp=s(C," overrides the default method for loading a model. The return value "),Ca=l(C,"CODE",{});var hu=n(Ca);Dp=s(hu,"model"),hu.forEach(o),qp=s(C," will be used in "),Ta=l(C,"CODE",{});var gu=n(Ta);xp=s(gu,"predict"),gu.forEach(o),Mp=s(C," for predictions. "),Ha=l(C,"CODE",{});var _u=n(Ha);Cp=s(_u,"predict"),_u.forEach(o),Tp=s(C," receives argument the "),Oa=l(C,"CODE",{});var vu=n(Oa);Hp=s(vu,"model_dir"),vu.forEach(o),Op=s(C,", the path to your unzipped "),Ia=l(C,"CODE",{});var yu=n(Ia);Ip=s(yu,"model.tar.gz"),yu.forEach(o),Ap=s(C,"."),C.forEach(o),Pp=c(K),y=l(K,"LI",{});var E=n(y);Aa=l(E,"CODE",{});var wu=n(Aa);Fp=s(wu,"transform_fn(model, data, content_type, accept_type)"),wu.forEach(o),Lp=s(E," overrides the default transform function with your custom implementation. You will need to implement your own "),Pa=l(E,"CODE",{});var Eu=n(Pa);zp=s(Eu,"preprocess"),Eu.forEach(o),Np=s(E,", "),Fa=l(E,"CODE",{});var bu=n(Fa);Rp=s(bu,"predict"),bu.forEach(o),Up=s(E," and "),La=l(E,"CODE",{});var ku=n(La);Yp=s(ku,"postprocess"),ku.forEach(o),Bp=s(E," steps in the "),za=l(E,"CODE",{});var $u=n(za);Wp=s($u,"transform_fn"),$u.forEach(o),Kp=s(E,". This method can\u2019t be combined with "),Na=l(E,"CODE",{});var ju=n(Na);Gp=s(ju,"input_fn"),ju.forEach(o),Jp=s(E,", "),Ra=l(E,"CODE",{});var Su=n(Ra);Qp=s(Su,"predict_fn"),Su.forEach(o),Zp=s(E," or "),Ua=l(E,"CODE",{});var Du=n(Ua);Vp=s(Du,"output_fn"),Du.forEach(o),Xp=s(E," mentioned below."),E.forEach(o),ed=c(K),O=l(K,"LI",{});var Fe=n(O);Ya=l(Fe,"CODE",{});var qu=n(Ya);td=s(qu,"input_fn(input_data, content_type)"),qu.forEach(o),od=s(Fe," overrides the default method for preprocessing. The return value "),Ba=l(Fe,"CODE",{});var xu=n(Ba);ad=s(xu,"data"),xu.forEach(o),sd=s(Fe," will be used in "),Wa=l(Fe,"CODE",{});var Mu=n(Wa);rd=s(Mu,"predict"),Mu.forEach(o),ld=s(Fe," for predicitions. The inputs are:"),Ct=l(Fe,"UL",{});var ul=n(Ct);po=l(ul,"LI",{});var lc=n(po);Ka=l(lc,"CODE",{});var Cu=n(Ka);nd=s(Cu,"input_data"),Cu.forEach(o),id=s(lc," is the raw body of your request."),lc.forEach(o),pd=c(ul),co=l(ul,"LI",{});var nc=n(co);Ga=l(nc,"CODE",{});var Tu=n(Ga);dd=s(Tu,"content_type"),Tu.forEach(o),cd=s(nc," is the content type from the request header."),nc.forEach(o),ul.forEach(o),Fe.forEach(o),fd=c(K),S=l(K,"LI",{});var A=n(S);Ja=l(A,"CODE",{});var Hu=n(Ja);ud=s(Hu,"predict_fn(processed_data, model)"),Hu.forEach(o),md=s(A," overrides the default method for predictions. The return value "),Qa=l(A,"CODE",{});var Ou=n(Qa);hd=s(Ou,"predictions"),Ou.forEach(o),gd=s(A," will be used in "),Za=l(A,"CODE",{});var Iu=n(Za);_d=s(Iu,"postprocess"),Iu.forEach(o),vd=s(A,". The input is "),Va=l(A,"CODE",{});var Au=n(Va);yd=s(Au,"processed_data"),Au.forEach(o),wd=s(A,", the result from "),Xa=l(A,"CODE",{});var Pu=n(Xa);Ed=s(Pu,"preprocess"),Pu.forEach(o),bd=s(A,"."),A.forEach(o),kd=c(K),I=l(K,"LI",{});var Le=n(I);es=l(Le,"CODE",{});var Fu=n(es);$d=s(Fu,"output_fn(prediction, accept)"),Fu.forEach(o),jd=s(Le," overrides the default method for postprocessing. The return value "),ts=l(Le,"CODE",{});var Lu=n(ts);Sd=s(Lu,"result"),Lu.forEach(o),Dd=s(Le," will be the response of your request (e.g."),os=l(Le,"CODE",{});var zu=n(os);qd=s(zu,"JSON"),zu.forEach(o),xd=s(Le,"). The inputs are:"),Tt=l(Le,"UL",{});var ml=n(Tt);Oe=l(ml,"LI",{});var ms=n(Oe);as=l(ms,"CODE",{});var Nu=n(as);Md=s(Nu,"predictions"),Nu.forEach(o),Cd=s(ms," is the result from "),ss=l(ms,"CODE",{});var Ru=n(ss);Td=s(Ru,"predict"),Ru.forEach(o),Hd=s(ms,"."),ms.forEach(o),Od=c(ml),Ie=l(ml,"LI",{});var hs=n(Ie);rs=l(hs,"CODE",{});var Uu=n(rs);Id=s(Uu,"accept"),Uu.forEach(o),Ad=s(hs," is the return accept type from the HTTP Request, e.g. "),ls=l(hs,"CODE",{});var Yu=n(ls);Pd=s(Yu,"application/json"),Yu.forEach(o),Fd=s(hs,"."),hs.forEach(o),ml.forEach(o),Le.forEach(o),K.forEach(o),Ir=c(e),D=l(e,"P",{});var G=n(D);Ld=s(G,"Here is an example of a custom inference module with "),ns=l(G,"CODE",{});var Bu=n(ns);zd=s(Bu,"model_fn"),Bu.forEach(o),Nd=s(G,", "),is=l(G,"CODE",{});var Wu=n(is);Rd=s(Wu,"input_fn"),Wu.forEach(o),Ud=s(G,", "),ps=l(G,"CODE",{});var Ku=n(ps);Yd=s(Ku,"predict_fn"),Ku.forEach(o),Bd=s(G,", and "),ds=l(G,"CODE",{});var Gu=n(ds);Wd=s(Gu,"output_fn"),Gu.forEach(o),Kd=s(G,":"),G.forEach(o),Ar=c(e),m(Ht.$$.fragment,e),Pr=c(e),Y=l(e,"P",{});var wo=n(Y);Gd=s(wo,"Customize your inference module with only "),cs=l(wo,"CODE",{});var Ju=n(cs);Jd=s(Ju,"model_fn"),Ju.forEach(o),Qd=s(wo," and "),fs=l(wo,"CODE",{});var Qu=n(fs);Zd=s(Qu,"transform_fn"),Qu.forEach(o),Vd=s(wo,":"),wo.forEach(o),Fr=c(e),m(Ot.$$.fragment,e),this.h()},h(){f(J,"name","hf:doc:metadata"),f(J,"content",JSON.stringify(sm)),f(ie,"id","deploy-models-to-amazon-sagemaker"),f(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ie,"href","#deploy-models-to-amazon-sagemaker"),f(Q,"class","relative group"),f(Re,"href","https://github.com/aws/sagemaker-huggingface-inference-toolkit"),f(Re,"rel","nofollow"),f(pe,"href","https://huggingface.co/transformers/main_classes/pipelines.html"),f(pe,"rel","nofollow"),f(Ft,"href","#installation-and-setup"),f(zt,"href","#deploy-a-transformer-model-trained-in-sagemaker"),f(Rt,"href","#deploy-a-model-from-the-hub"),f(Yt,"href","#run-batch-transform-with-transformers-and-sagemaker"),f(Wt,"href","#user-defined-code-and-modules"),f(de,"id","installation-and-setup"),f(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(de,"href","#installation-and-setup"),f(Z,"class","relative group"),f(Ye,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html"),f(Ye,"rel","nofollow"),f(Be,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html"),f(Be,"rel","nofollow"),f(We,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html"),f(We,"rel","nofollow"),f(Ke,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html"),f(Ke,"rel","nofollow"),f(me,"id","deploy-a-transformers-model-trained-in-sagemaker"),f(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(me,"href","#deploy-a-transformers-model-trained-in-sagemaker"),f(X,"class","relative group"),f(q,"width","700"),f(q,"height","394"),ic(q.src,dc="https://www.youtube.com/embed/pfBGgSGnYLs")||f(q,"src",dc),f(q,"title","YouTube video player"),f(q,"frameborder","0"),f(q,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),q.allowFullscreen=!0,f(Xe,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb"),f(Xe,"rel","nofollow"),f(_e,"id","deploy-after-training"),f(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(_e,"href","#deploy-after-training"),f(ee,"class","relative group"),f(ve,"id","deploy-with-modeldata"),f(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ve,"href","#deploy-with-modeldata"),f(te,"class","relative group"),f(we,"id","create-a-model-artifact-for-deployment"),f(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(we,"href","#create-a-model-artifact-for-deployment"),f(oe,"class","relative group"),f(pt,"start","2"),f(ft,"start","3"),f($e,"id","deploy-a-model-from-the-hub"),f($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f($e,"href","#deploy-a-model-from-the-hub"),f(ae,"class","relative group"),f(x,"width","700"),f(x,"height","394"),ic(x.src,cc="https://www.youtube.com/embed/l9QZuazbzWM")||f(x,"src",cc),f(x,"title","YouTube video player"),f(x,"frameborder","0"),f(x,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),x.allowFullscreen=!0,f(gt,"href","http://huggingface.co/models"),f(gt,"rel","nofollow"),f(_t,"href","https://huggingface.co/transformers/main_classes/pipelines.html"),f(_t,"rel","nofollow"),f(wt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb"),f(wt,"rel","nofollow"),f(xe,"id","run-batch-transform-with-transformers-and-sagemaker"),f(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(xe,"href","#run-batch-transform-with-transformers-and-sagemaker"),f(se,"class","relative group"),f(M,"width","700"),f(M,"height","394"),ic(M.src,fc="https://www.youtube.com/embed/lnTixz0tUBg")||f(M,"src",fc),f(M,"title","YouTube video player"),f(M,"frameborder","0"),f(M,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),M.allowFullscreen=!0,f(bt,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html"),f(bt,"rel","nofollow"),f(kt,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html"),f(kt,"rel","nofollow"),f($t,"href","https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform"),f($t,"rel","nofollow"),f(qt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb"),f(qt,"rel","nofollow"),f(He,"id","user-defined-code-and-modules"),f(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(He,"href","#user-defined-code-and-modules"),f(le,"class","relative group"),f(io,"href","#create-a-model-artifact-for-deployment")},m(e,i){t(document.head,J),p(e,gs,i),p(e,Q,i),t(Q,ie),t(ie,Eo),h(ze,Eo,null),t(Q,hl),t(Q,bo),t(bo,gl),p(e,_s,i),p(e,At,i),t(At,_l),p(e,vs,i),h(Ne,e,i),p(e,ys,i),p(e,P,i),t(P,vl),t(P,Re),t(Re,yl),t(P,wl),t(P,pe),t(pe,ko),t(ko,El),t(pe,bl),t(P,kl),p(e,ws,i),p(e,k,i),t(k,Pt),t(Pt,Ft),t(Ft,$l),t(Pt,jl),t(k,Sl),t(k,Lt),t(Lt,zt),t(zt,Dl),t(Lt,ql),t(k,xl),t(k,Nt),t(Nt,Rt),t(Rt,Ml),t(Nt,Cl),t(k,Tl),t(k,Ut),t(Ut,Yt),t(Yt,Hl),t(Ut,Ol),t(k,Il),t(k,Bt),t(Bt,Wt),t(Wt,Al),t(Bt,Pl),p(e,Es,i),p(e,Z,i),t(Z,de),t(de,$o),h(Ue,$o,null),t(Z,Fl),t(Z,jo),t(jo,Ll),p(e,bs,i),p(e,ce,i),t(ce,zl),t(ce,Ye),t(Ye,Nl),t(ce,Rl),p(e,ks,i),p(e,Kt,i),t(Kt,Ul),p(e,$s,i),p(e,F,i),t(F,So),t(So,Be),t(Be,Yl),t(F,Bl),t(F,Do),t(Do,We),t(We,Wl),t(F,Kl),t(F,qo),t(qo,Gl),p(e,js,i),p(e,fe,i),t(fe,Jl),t(fe,Ke),t(Ke,Ql),t(fe,Zl),p(e,Ss,i),p(e,ue,i),t(ue,Vl),t(ue,xo),t(xo,Xl),t(ue,en),p(e,Ds,i),h(Ge,e,i),p(e,qs,i),p(e,Gt,i),t(Gt,Mo),t(Mo,tn),p(e,xs,i),p(e,Jt,i),t(Jt,on),p(e,Ms,i),h(Je,e,i),p(e,Cs,i),p(e,Qt,i),t(Qt,V),t(V,an),t(V,Co),t(Co,sn),t(V,rn),t(V,To),t(To,ln),t(V,nn),p(e,Ts,i),p(e,Zt,i),t(Zt,Ho),t(Ho,pn),p(e,Hs,i),p(e,Vt,i),t(Vt,dn),p(e,Os,i),h(Qe,e,i),p(e,Is,i),p(e,X,i),t(X,me),t(me,Oo),h(Ze,Oo,null),t(X,cn),t(X,Io),t(Io,fn),p(e,As,i),p(e,q,i),p(e,Ps,i),p(e,Xt,i),t(Xt,un),p(e,Fs,i),p(e,he,i),t(he,Ao),t(Ao,mn),t(he,hn),t(he,Ve),t(Ve,gn),t(Ve,Po),t(Po,_n),t(Ve,vn),p(e,Ls,i),p(e,ge,i),t(ge,yn),t(ge,Xe),t(Xe,wn),t(ge,En),p(e,zs,i),p(e,ee,i),t(ee,_e),t(_e,Fo),h(et,Fo,null),t(ee,bn),t(ee,Lo),t(Lo,kn),p(e,Ns,i),p(e,eo,i),t(eo,$n),p(e,Rs,i),p(e,T,i),t(T,jn),t(T,zo),t(zo,Sn),t(T,Dn),t(T,No),t(No,qn),t(T,xn),t(T,Ro),t(Ro,Mn),t(T,Cn),p(e,Us,i),h(tt,e,i),p(e,Ys,i),p(e,to,i),t(to,Tn),p(e,Bs,i),h(ot,e,i),p(e,Ws,i),p(e,te,i),t(te,ve),t(ve,Uo),h(at,Uo,null),t(te,Hn),t(te,oo),t(oo,On),t(oo,Yo),t(Yo,In),p(e,Ks,i),p(e,ye,i),t(ye,An),t(ye,Bo),t(Bo,Pn),t(ye,Fn),p(e,Gs,i),h(st,e,i),p(e,Js,i),p(e,ao,i),t(ao,Ln),p(e,Qs,i),h(rt,e,i),p(e,Zs,i),p(e,oe,i),t(oe,we),t(we,Wo),h(lt,Wo,null),t(oe,zn),t(oe,Ko),t(Ko,Nn),p(e,Vs,i),p(e,Ee,i),t(Ee,Rn),t(Ee,Go),t(Go,Un),t(Ee,Yn),p(e,Xs,i),p(e,H,i),t(H,Jo),t(Jo,Qo),t(Qo,Bn),t(H,Wn),t(H,Zo),t(Zo,Vo),t(Vo,Kn),t(H,Gn),t(H,Xo),t(Xo,ea),t(ea,Jn),t(H,Qn),t(H,ta),t(ta,oa),t(oa,Zn),p(e,er,i),p(e,so,i),t(so,Vn),p(e,tr,i),h(nt,e,i),p(e,or,i),p(e,be,i),t(be,Xn),t(be,aa),t(aa,ei),t(be,ti),p(e,ar,i),p(e,ro,i),t(ro,sa),t(sa,oi),p(e,sr,i),h(it,e,i),p(e,rr,i),p(e,pt,i),t(pt,dt),t(dt,ai),t(dt,ra),t(ra,si),t(dt,ri),p(e,lr,i),h(ct,e,i),p(e,nr,i),p(e,ft,i),t(ft,ut),t(ut,li),t(ut,la),t(la,ni),t(ut,ii),p(e,ir,i),h(mt,e,i),p(e,pr,i),p(e,ke,i),t(ke,pi),t(ke,na),t(na,di),t(ke,ci),p(e,dr,i),p(e,ae,i),t(ae,$e),t($e,ia),h(ht,ia,null),t(ae,fi),t(ae,pa),t(pa,ui),p(e,cr,i),p(e,x,i),p(e,fr,i),p(e,je,i),t(je,mi),t(je,da),t(da,hi),t(je,gi),p(e,ur,i),p(e,Se,i),t(Se,De),t(De,ca),t(ca,_i),t(De,vi),t(De,gt),t(gt,yi),t(De,wi),t(Se,Ei),t(Se,L),t(L,fa),t(fa,bi),t(L,ki),t(L,ua),t(ua,$i),t(L,ji),t(L,_t),t(_t,Si),t(L,Di),p(e,mr,i),h(vt,e,i),p(e,hr,i),p(e,lo,i),t(lo,qi),p(e,gr,i),h(yt,e,i),p(e,_r,i),p(e,qe,i),t(qe,xi),t(qe,wt),t(wt,Mi),t(qe,Ci),p(e,vr,i),p(e,se,i),t(se,xe),t(xe,ma),h(Et,ma,null),t(se,Ti),t(se,ha),t(ha,Hi),p(e,yr,i),p(e,M,i),p(e,wr,i),p(e,z,i),t(z,Oi),t(z,bt),t(bt,Ii),t(z,Ai),t(z,kt),t(kt,Pi),t(z,Fi),p(e,Er,i),p(e,Me,i),t(Me,Li),t(Me,ga),t(ga,zi),t(Me,Ni),p(e,br,i),p(e,no,i),t(no,re),t(re,Ri),t(re,_a),t(_a,Ui),t(re,Yi),t(re,va),t(va,Bi),t(re,Wi),p(e,kr,i),p(e,N,i),t(N,Ki),t(N,ya),t(ya,Gi),t(N,Ji),t(N,$t),t($t,Qi),t(N,Zi),p(e,$r,i),h(jt,e,i),p(e,jr,i),p(e,R,i),t(R,Vi),t(R,wa),t(wa,Xi),t(R,ep),t(R,Ea),t(Ea,tp),t(R,op),p(e,Sr,i),h(St,e,i),p(e,Dr,i),p(e,Ce,i),t(Ce,ap),t(Ce,ba),t(ba,sp),t(Ce,rp),p(e,qr,i),h(Dt,e,i),p(e,xr,i),p(e,Te,i),t(Te,lp),t(Te,qt),t(qt,np),t(Te,ip),p(e,Mr,i),p(e,le,i),t(le,He),t(He,ka),h(xt,ka,null),t(le,pp),t(le,$a),t($a,dp),p(e,Cr,i),p(e,$,i),t($,cp),t($,ja),t(ja,fp),t($,up),t($,Sa),t(Sa,mp),t($,hp),t($,Da),t(Da,gp),t($,_p),t($,io),t(io,vp),t($,yp),p(e,Tr,i),h(Mt,e,i),p(e,Hr,i),p(e,U,i),t(U,wp),t(U,qa),t(qa,Ep),t(U,bp),t(U,xa),t(xa,kp),t(U,$p),p(e,Or,i),p(e,j,i),t(j,b),t(b,Ma),t(Ma,jp),t(b,Sp),t(b,Ca),t(Ca,Dp),t(b,qp),t(b,Ta),t(Ta,xp),t(b,Mp),t(b,Ha),t(Ha,Cp),t(b,Tp),t(b,Oa),t(Oa,Hp),t(b,Op),t(b,Ia),t(Ia,Ip),t(b,Ap),t(j,Pp),t(j,y),t(y,Aa),t(Aa,Fp),t(y,Lp),t(y,Pa),t(Pa,zp),t(y,Np),t(y,Fa),t(Fa,Rp),t(y,Up),t(y,La),t(La,Yp),t(y,Bp),t(y,za),t(za,Wp),t(y,Kp),t(y,Na),t(Na,Gp),t(y,Jp),t(y,Ra),t(Ra,Qp),t(y,Zp),t(y,Ua),t(Ua,Vp),t(y,Xp),t(j,ed),t(j,O),t(O,Ya),t(Ya,td),t(O,od),t(O,Ba),t(Ba,ad),t(O,sd),t(O,Wa),t(Wa,rd),t(O,ld),t(O,Ct),t(Ct,po),t(po,Ka),t(Ka,nd),t(po,id),t(Ct,pd),t(Ct,co),t(co,Ga),t(Ga,dd),t(co,cd),t(j,fd),t(j,S),t(S,Ja),t(Ja,ud),t(S,md),t(S,Qa),t(Qa,hd),t(S,gd),t(S,Za),t(Za,_d),t(S,vd),t(S,Va),t(Va,yd),t(S,wd),t(S,Xa),t(Xa,Ed),t(S,bd),t(j,kd),t(j,I),t(I,es),t(es,$d),t(I,jd),t(I,ts),t(ts,Sd),t(I,Dd),t(I,os),t(os,qd),t(I,xd),t(I,Tt),t(Tt,Oe),t(Oe,as),t(as,Md),t(Oe,Cd),t(Oe,ss),t(ss,Td),t(Oe,Hd),t(Tt,Od),t(Tt,Ie),t(Ie,rs),t(rs,Id),t(Ie,Ad),t(Ie,ls),t(ls,Pd),t(Ie,Fd),p(e,Ir,i),p(e,D,i),t(D,Ld),t(D,ns),t(ns,zd),t(D,Nd),t(D,is),t(is,Rd),t(D,Ud),t(D,ps),t(ps,Yd),t(D,Bd),t(D,ds),t(ds,Wd),t(D,Kd),p(e,Ar,i),h(Ht,e,i),p(e,Pr,i),p(e,Y,i),t(Y,Gd),t(Y,cs),t(cs,Jd),t(Y,Qd),t(Y,fs),t(fs,Zd),t(Y,Vd),p(e,Fr,i),h(Ot,e,i),Lr=!0},p:tm,i(e){Lr||(g(ze.$$.fragment,e),g(Ne.$$.fragment,e),g(Ue.$$.fragment,e),g(Ge.$$.fragment,e),g(Je.$$.fragment,e),g(Qe.$$.fragment,e),g(Ze.$$.fragment,e),g(et.$$.fragment,e),g(tt.$$.fragment,e),g(ot.$$.fragment,e),g(at.$$.fragment,e),g(st.$$.fragment,e),g(rt.$$.fragment,e),g(lt.$$.fragment,e),g(nt.$$.fragment,e),g(it.$$.fragment,e),g(ct.$$.fragment,e),g(mt.$$.fragment,e),g(ht.$$.fragment,e),g(vt.$$.fragment,e),g(yt.$$.fragment,e),g(Et.$$.fragment,e),g(jt.$$.fragment,e),g(St.$$.fragment,e),g(Dt.$$.fragment,e),g(xt.$$.fragment,e),g(Mt.$$.fragment,e),g(Ht.$$.fragment,e),g(Ot.$$.fragment,e),Lr=!0)},o(e){_(ze.$$.fragment,e),_(Ne.$$.fragment,e),_(Ue.$$.fragment,e),_(Ge.$$.fragment,e),_(Je.$$.fragment,e),_(Qe.$$.fragment,e),_(Ze.$$.fragment,e),_(et.$$.fragment,e),_(tt.$$.fragment,e),_(ot.$$.fragment,e),_(at.$$.fragment,e),_(st.$$.fragment,e),_(rt.$$.fragment,e),_(lt.$$.fragment,e),_(nt.$$.fragment,e),_(it.$$.fragment,e),_(ct.$$.fragment,e),_(mt.$$.fragment,e),_(ht.$$.fragment,e),_(vt.$$.fragment,e),_(yt.$$.fragment,e),_(Et.$$.fragment,e),_(jt.$$.fragment,e),_(St.$$.fragment,e),_(Dt.$$.fragment,e),_(xt.$$.fragment,e),_(Mt.$$.fragment,e),_(Ht.$$.fragment,e),_(Ot.$$.fragment,e),Lr=!1},d(e){o(J),e&&o(gs),e&&o(Q),v(ze),e&&o(_s),e&&o(At),e&&o(vs),v(Ne,e),e&&o(ys),e&&o(P),e&&o(ws),e&&o(k),e&&o(Es),e&&o(Z),v(Ue),e&&o(bs),e&&o(ce),e&&o(ks),e&&o(Kt),e&&o($s),e&&o(F),e&&o(js),e&&o(fe),e&&o(Ss),e&&o(ue),e&&o(Ds),v(Ge,e),e&&o(qs),e&&o(Gt),e&&o(xs),e&&o(Jt),e&&o(Ms),v(Je,e),e&&o(Cs),e&&o(Qt),e&&o(Ts),e&&o(Zt),e&&o(Hs),e&&o(Vt),e&&o(Os),v(Qe,e),e&&o(Is),e&&o(X),v(Ze),e&&o(As),e&&o(q),e&&o(Ps),e&&o(Xt),e&&o(Fs),e&&o(he),e&&o(Ls),e&&o(ge),e&&o(zs),e&&o(ee),v(et),e&&o(Ns),e&&o(eo),e&&o(Rs),e&&o(T),e&&o(Us),v(tt,e),e&&o(Ys),e&&o(to),e&&o(Bs),v(ot,e),e&&o(Ws),e&&o(te),v(at),e&&o(Ks),e&&o(ye),e&&o(Gs),v(st,e),e&&o(Js),e&&o(ao),e&&o(Qs),v(rt,e),e&&o(Zs),e&&o(oe),v(lt),e&&o(Vs),e&&o(Ee),e&&o(Xs),e&&o(H),e&&o(er),e&&o(so),e&&o(tr),v(nt,e),e&&o(or),e&&o(be),e&&o(ar),e&&o(ro),e&&o(sr),v(it,e),e&&o(rr),e&&o(pt),e&&o(lr),v(ct,e),e&&o(nr),e&&o(ft),e&&o(ir),v(mt,e),e&&o(pr),e&&o(ke),e&&o(dr),e&&o(ae),v(ht),e&&o(cr),e&&o(x),e&&o(fr),e&&o(je),e&&o(ur),e&&o(Se),e&&o(mr),v(vt,e),e&&o(hr),e&&o(lo),e&&o(gr),v(yt,e),e&&o(_r),e&&o(qe),e&&o(vr),e&&o(se),v(Et),e&&o(yr),e&&o(M),e&&o(wr),e&&o(z),e&&o(Er),e&&o(Me),e&&o(br),e&&o(no),e&&o(kr),e&&o(N),e&&o($r),v(jt,e),e&&o(jr),e&&o(R),e&&o(Sr),v(St,e),e&&o(Dr),e&&o(Ce),e&&o(qr),v(Dt,e),e&&o(xr),e&&o(Te),e&&o(Mr),e&&o(le),v(xt),e&&o(Cr),e&&o($),e&&o(Tr),v(Mt,e),e&&o(Hr),e&&o(U),e&&o(Or),e&&o(j),e&&o(Ir),e&&o(D),e&&o(Ar),v(Ht,e),e&&o(Pr),e&&o(Y),e&&o(Fr),v(Ot,e)}}}const sm={local:"deploy-models-to-amazon-sagemaker",sections:[{local:"installation-and-setup",title:"Installation and setup"},{local:"deploy-a-transformers-model-trained-in-sagemaker",sections:[{local:"deploy-after-training",title:"Deploy after training"},{local:"deploy-with-modeldata",title:"Deploy with `model_data`"},{local:"create-a-model-artifact-for-deployment",title:"Create a model artifact for deployment"}],title:"Deploy a \u{1F917} Transformers model trained in SageMaker"},{local:"deploy-a-model-from-the-hub",title:"Deploy a model from the \u{1F917} Hub"},{local:"run-batch-transform-with-transformers-and-sagemaker",title:"Run batch transform with \u{1F917} Transformers and SageMaker"},{local:"user-defined-code-and-modules",title:"User defined code and modules"}],title:"Deploy models to Amazon SageMaker"};function rm(pc){return om(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pm extends Zu{constructor(J){super();Vu(this,J,rm,am,Xu,{})}}export{pm as default,sm as metadata};
