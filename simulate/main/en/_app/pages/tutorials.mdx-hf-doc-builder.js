import{S as Ye,i as Be,s as Ge,e as r,k as c,w as oe,t as h,M as je,c as n,d as t,m as p,a as s,x as re,h as u,b as l,G as a,g as i,y as ne,q as se,o as le,B as ie,v as Fe}from"../chunks/vendor-hf-doc-builder.js";import{T as We}from"../chunks/Tip-hf-doc-builder.js";import{I as Ae}from"../chunks/IconCopyLink-hf-doc-builder.js";function Je(U){let f;return{c(){f=h("The examples only cover the basic skills you need to use \u{1F917} Simulate. There are many other useful functionalities and applications that aren't discussed here. You can find more here TODO")},l(d){f=u(d,"The examples only cover the basic skills you need to use \u{1F917} Simulate. There are many other useful functionalities and applications that aren't discussed here. You can find more here TODO")},m(d,m){i(d,f,m)},d(d){d&&t(f)}}}function ze(U){let f,d,m,g,I,E,he,O,ue,Y,y,fe,A,ce,pe,B,v,$,N,x,me,H,de,G,_,j,k,ve,P,we,ge,F,w,b,M,L,ye,C,$e,W,D,_e,J,S,ke,R,be,Se,z,K,Q,q,Ee,V;return E=new Ae({}),x=new Ae({}),_=new We({props:{$$slots:{default:[Je]},$$scope:{ctx:U}}}),L=new Ae({}),{c(){f=r("meta"),d=c(),m=r("h1"),g=r("a"),I=r("span"),oe(E.$$.fragment),he=c(),O=r("span"),ue=h("Overview"),Y=c(),y=r("p"),fe=h("Welcome to the \u{1F917} Simulate tutorials! These beginner-friendly tutorials will guide you through the fundamentals of working with \u{1F917} Simulate. You\u2019ll load and prepare an environment for training with your Deep RL framework of choice. Along the way, you\u2019ll learn how to define and load different Assets, Sensors and Actuators, watch an RL Agent interact with and see what\u2019s inside your environment and share a dataset to the "),A=r("a"),ce=h("Hub"),pe=h("."),B=c(),v=r("h2"),$=r("a"),N=r("span"),oe(x.$$.fragment),me=c(),H=r("span"),de=h("Examples"),G=h(`

The examples assume some basic knowledge of Python, Deep Reinforcement Learning and a Deep RL framework like [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).
If you're already familiar with these, feel free to check out the [quickstart](./quickstart) to see what you can do with \u{1F917} Simulate. If you want to learn more about Deep Reinforcement Learning, check of the \u{1F917} [Deep RL course](https://github.com/huggingface/deep-rl-class#the-hugging-face-deep-reinforcement-learning-class-).
`),oe(_.$$.fragment),j=c(),k=r("p"),ve=h("If you have any questions about \u{1F917} Simulate, feel free to join and ask the community on our "),P=r("a"),we=h("forum"),ge=h("."),F=c(),w=r("h2"),b=r("a"),M=r("span"),oe(L.$$.fragment),ye=c(),C=r("span"),$e=h("Advanced Usage"),W=c(),D=r("p"),_e=h("This section is for users looking to gain speed, run more advanced simulations, or use tools that are recently added."),J=c(),S=r("p"),ke=h("For example, these include how to achieve high throughput training with Map Pools, the "),R=r("a"),be=h("sample-factory"),Se=h(" RL framework and running Simulate on a GCP instance"),z=c(),K=r("hr"),Q=c(),q=r("p"),Ee=h("Let\u2019s get started! \u{1F3C1}"),this.h()},l(e){const o=je('[data-svelte="svelte-1phssyn"]',document.head);f=n(o,"META",{name:!0,content:!0}),o.forEach(t),d=p(e),m=n(e,"H1",{class:!0});var T=s(m);g=n(T,"A",{id:!0,class:!0,href:!0});var xe=s(g);I=n(xe,"SPAN",{});var Pe=s(I);re(E.$$.fragment,Pe),Pe.forEach(t),xe.forEach(t),he=p(T),O=n(T,"SPAN",{});var Le=s(O);ue=u(Le,"Overview"),Le.forEach(t),T.forEach(t),Y=p(e),y=n(e,"P",{});var X=s(y);fe=u(X,"Welcome to the \u{1F917} Simulate tutorials! These beginner-friendly tutorials will guide you through the fundamentals of working with \u{1F917} Simulate. You\u2019ll load and prepare an environment for training with your Deep RL framework of choice. Along the way, you\u2019ll learn how to define and load different Assets, Sensors and Actuators, watch an RL Agent interact with and see what\u2019s inside your environment and share a dataset to the "),A=n(X,"A",{href:!0,rel:!0});var Re=s(A);ce=u(Re,"Hub"),Re.forEach(t),pe=u(X,"."),X.forEach(t),B=p(e),v=n(e,"H2",{class:!0});var Z=s(v);$=n(Z,"A",{id:!0,class:!0,href:!0});var Te=s($);N=n(Te,"SPAN",{});var De=s(N);re(x.$$.fragment,De),De.forEach(t),Te.forEach(t),me=p(Z),H=n(Z,"SPAN",{});var qe=s(H);de=u(qe,"Examples"),qe.forEach(t),Z.forEach(t),G=u(e,`

The examples assume some basic knowledge of Python, Deep Reinforcement Learning and a Deep RL framework like [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).
If you're already familiar with these, feel free to check out the [quickstart](./quickstart) to see what you can do with \u{1F917} Simulate. If you want to learn more about Deep Reinforcement Learning, check of the \u{1F917} [Deep RL course](https://github.com/huggingface/deep-rl-class#the-hugging-face-deep-reinforcement-learning-class-).
`),re(_.$$.fragment,e),j=p(e),k=n(e,"P",{});var ee=s(k);ve=u(ee,"If you have any questions about \u{1F917} Simulate, feel free to join and ask the community on our "),P=n(ee,"A",{href:!0,rel:!0});var Ie=s(P);we=u(Ie,"forum"),Ie.forEach(t),ge=u(ee,"."),ee.forEach(t),F=p(e),w=n(e,"H2",{class:!0});var te=s(w);b=n(te,"A",{id:!0,class:!0,href:!0});var Oe=s(b);M=n(Oe,"SPAN",{});var Ne=s(M);re(L.$$.fragment,Ne),Ne.forEach(t),Oe.forEach(t),ye=p(te),C=n(te,"SPAN",{});var He=s(C);$e=u(He,"Advanced Usage"),He.forEach(t),te.forEach(t),W=p(e),D=n(e,"P",{});var Me=s(D);_e=u(Me,"This section is for users looking to gain speed, run more advanced simulations, or use tools that are recently added."),Me.forEach(t),J=p(e),S=n(e,"P",{});var ae=s(S);ke=u(ae,"For example, these include how to achieve high throughput training with Map Pools, the "),R=n(ae,"A",{href:!0,rel:!0});var Ce=s(R);be=u(Ce,"sample-factory"),Ce.forEach(t),Se=u(ae," RL framework and running Simulate on a GCP instance"),ae.forEach(t),z=p(e),K=n(e,"HR",{}),Q=p(e),q=n(e,"P",{});var Ue=s(q);Ee=u(Ue,"Let\u2019s get started! \u{1F3C1}"),Ue.forEach(t),this.h()},h(){l(f,"name","hf:doc:metadata"),l(f,"content",JSON.stringify(Ke)),l(g,"id","overview"),l(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(g,"href","#overview"),l(m,"class","relative group"),l(A,"href","https://huggingface.co/Spaces"),l(A,"rel","nofollow"),l($,"id","examples"),l($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l($,"href","#examples"),l(v,"class","relative group"),l(P,"href","https://discuss.huggingface.co/c/simulate/10"),l(P,"rel","nofollow"),l(b,"id","advanced-usage"),l(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(b,"href","#advanced-usage"),l(w,"class","relative group"),l(R,"href","https://alex-petrenko.github.io/sample-factory/"),l(R,"rel","nofollow")},m(e,o){a(document.head,f),i(e,d,o),i(e,m,o),a(m,g),a(g,I),ne(E,I,null),a(m,he),a(m,O),a(O,ue),i(e,Y,o),i(e,y,o),a(y,fe),a(y,A),a(A,ce),a(y,pe),i(e,B,o),i(e,v,o),a(v,$),a($,N),ne(x,N,null),a(v,me),a(v,H),a(H,de),i(e,G,o),ne(_,e,o),i(e,j,o),i(e,k,o),a(k,ve),a(k,P),a(P,we),a(k,ge),i(e,F,o),i(e,w,o),a(w,b),a(b,M),ne(L,M,null),a(w,ye),a(w,C),a(C,$e),i(e,W,o),i(e,D,o),a(D,_e),i(e,J,o),i(e,S,o),a(S,ke),a(S,R),a(R,be),a(S,Se),i(e,z,o),i(e,K,o),i(e,Q,o),i(e,q,o),a(q,Ee),V=!0},p(e,[o]){const T={};o&2&&(T.$$scope={dirty:o,ctx:e}),_.$set(T)},i(e){V||(se(E.$$.fragment,e),se(x.$$.fragment,e),se(_.$$.fragment,e),se(L.$$.fragment,e),V=!0)},o(e){le(E.$$.fragment,e),le(x.$$.fragment,e),le(_.$$.fragment,e),le(L.$$.fragment,e),V=!1},d(e){t(f),e&&t(d),e&&t(m),ie(E),e&&t(Y),e&&t(y),e&&t(B),e&&t(v),ie(x),e&&t(G),ie(_,e),e&&t(j),e&&t(k),e&&t(F),e&&t(w),ie(L),e&&t(W),e&&t(D),e&&t(J),e&&t(S),e&&t(z),e&&t(K),e&&t(Q),e&&t(q)}}}const Ke={local:"overview",sections:[{local:"examples",title:"Examples"},{local:"advanced-usage",title:"Advanced Usage"}],title:"Overview"};function Qe(U){return Fe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class et extends Ye{constructor(f){super();Be(this,f,Qe,ze,Ge,{})}}export{et as default,Ke as metadata};
