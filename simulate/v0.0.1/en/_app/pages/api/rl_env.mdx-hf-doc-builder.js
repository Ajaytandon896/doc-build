import{S as gt,i as bt,s as _t,e as r,k as s,w as h,t as m,M as $t,c as a,d as n,m as i,a as o,x as v,h as d,b as l,G as t,g as w,y as g,L as yt,q as b,o as _,B as $,v as Et}from"../../chunks/vendor-hf-doc-builder.js";import{D as L}from"../../chunks/Docstring-hf-doc-builder.js";import{I as wt}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Lt(nt){let D,le,O,T,Y,k,Ee,Z,we,ce,c,M,Le,ee,De,Oe,R,U,Te,te,Re,Pe,P,G,xe,ne,Ie,Ae,x,C,Se,re,Ve,pe,p,N,ke,z,Me,F,Ue,Ge,I,q,Ce,ae,Ne,Fe,A,W,qe,oe,We,Be,S,B,He,se,Je,me,f,H,je,K,ze,J,Ke,Qe,V,j,Xe,ie,Ye,de,Q,Ze,ue;return k=new wt({}),M=new L({props:{name:"class simulate.RLEnv",anchor:"simulate.RLEnv",parameters:[{name:"scene",val:": Scene"},{name:"time_step",val:": typing.Optional[float] = 0.03333333333333333"},{name:"frame_skip",val:": typing.Optional[int] = 4"}],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/rl_env.py#L23"}}),U=new L({props:{name:"reset",anchor:"simulate.RLEnv.reset",parameters:[],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/rl_env.py#L170",returnDescription:`
<p>the observation of the environment after reset.</p>
`,returnType:`
<p>obs (<code>Dict</code>)</p>
`}}),G=new L({props:{name:"sample_action",anchor:"simulate.RLEnv.sample_action",parameters:[],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/rl_env.py#L205",returnDescription:`
<p>TODO</p>
`,returnType:`
<p>action</p>
`}}),C=new L({props:{name:"step",anchor:"simulate.RLEnv.step",parameters:[{name:"action",val:": typing.Union[typing.Dict, typing.List, numpy.ndarray]"}],parametersDescription:[{anchor:"simulate.RLEnv.step.action",description:"<strong>action</strong> (<code>Dict</code> or <code>List</code>) &#x2014; TODO verify, a dict with actuator tags as keys and as values a Tensor of shape (n_show, n_actors, n_actions)",name:"action"}],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/rl_env.py#L79",returnDescription:`
<p>TODO
reward (<code>float</code>): TODO
done (<code>bool</code>): TODO
info: TODO</p>
`,returnType:`
<p>observation (<code>Dict</code>)</p>
`}}),N=new L({props:{name:"class simulate.ParallelRLEnv",anchor:"simulate.ParallelRLEnv",parameters:[{name:"scene_or_map_fn",val:": typing.Union[typing.Callable, simulate.scene.Scene]"},{name:"n_maps",val:": typing.Optional[int] = 1"},{name:"n_show",val:": typing.Optional[int] = 1"},{name:"time_step",val:": typing.Optional[float] = 0.03333333333333333"},{name:"frame_skip",val:": typing.Optional[int] = 4"},{name:"**engine_kwargs",val:""}],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/parallel_rl_env.py#L40"}}),q=new L({props:{name:"reset",anchor:"simulate.ParallelRLEnv.reset",parameters:[],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/parallel_rl_env.py#L188",returnDescription:`
<p>the observation of the environment after reset.</p>
`,returnType:`
<p>obs (<code>Dict</code>)</p>
`}}),W=new L({props:{name:"sample_action",anchor:"simulate.ParallelRLEnv.sample_action",parameters:[],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/parallel_rl_env.py#L223",returnDescription:`
<p>TODO</p>
`,returnType:`
<p>action</p>
`}}),B=new L({props:{name:"step",anchor:"simulate.ParallelRLEnv.step",parameters:[{name:"action",val:": typing.Union[typing.Dict, typing.List, numpy.ndarray]"}],parametersDescription:[{anchor:"simulate.ParallelRLEnv.step.action",description:"<strong>action</strong> (<code>Dict</code> or <code>List</code>) &#x2014; TODO verify, a dict with actuator tags as keys and as values a Tensor of shape (n_show, n_actors, n_actions)",name:"action"}],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/parallel_rl_env.py#L113",returnDescription:`
<p>TODO
reward (<code>float</code>): TODO
done (<code>bool</code>): TODO
info: TODO</p>
`,returnType:`
<p>observation (<code>Dict</code>)</p>
`}}),H=new L({props:{name:"class simulate.MultiProcessRLEnv",anchor:"simulate.MultiProcessRLEnv",parameters:[{name:"env_fn",val:": typing.Callable"},{name:"n_parallel",val:": int"},{name:"starting_port",val:": int = 55001"}],parametersDescription:[{anchor:"simulate.MultiProcessRLEnv.env_fn",description:`<strong>env_fn</strong> (<code>Callable</code>) &#x2014; a generator function that returns a RLEnv / ParallelRLEnv for generating instances
of the desired environment.`,name:"env_fn"},{anchor:"simulate.MultiProcessRLEnv.n_parallel",description:"<strong>n_parallel</strong> (<code>int</code>) &#x2014; the number of executable instances to create.",name:"n_parallel"},{anchor:"simulate.MultiProcessRLEnv.starting_port",description:"<strong>starting_port</strong> (<code>int</code>) &#x2014; initial communication port for spawned executables.",name:"starting_port"}],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/multi_proc_rl_env.py#L33"}}),j=new L({props:{name:"step",anchor:"simulate.MultiProcessRLEnv.step",parameters:[{name:"actions",val:": typing.Union[<built-in function array>, NoneType] = None"}],parametersDescription:[{anchor:"simulate.MultiProcessRLEnv.step.actions",description:"<strong>actions</strong> (<code>Dict</code> or <code>List</code>) &#x2014; TODO verify, a dict with actuator tags as keys and as values a Tensor of shape (n_show, n_actors, n_actions)",name:"actions"}],source:"https://github.com/huggingface/simulate/blob/v0.0.1/src/simulate/rl/multi_proc_rl_env.py#L64",returnDescription:`
<p>TODO
all_reward (<code>float</code>): TODO
all_done (<code>bool</code>): TODO
all_info: TODO</p>
`,returnType:`
<p>all_observation (<code>Dict</code>)</p>
`}}),{c(){D=r("meta"),le=s(),O=r("h1"),T=r("a"),Y=r("span"),h(k.$$.fragment),Ee=s(),Z=r("span"),we=m("RL Environment Wrappers"),ce=s(),c=r("div"),h(M.$$.fragment),Le=s(),ee=r("p"),De=m("The basic RL environment wrapper for Simulate scene following the Gym API."),Oe=s(),R=r("div"),h(U.$$.fragment),Te=s(),te=r("p"),Re=m("Resets the actors and the scene of the environment."),Pe=s(),P=r("div"),h(G.$$.fragment),xe=s(),ne=r("p"),Ie=m("Samples an action from the actors in the environment. This function loads the configuration of maps and actors to return the correct shape across multiple configurations."),Ae=s(),x=r("div"),h(C.$$.fragment),Se=s(),re=r("p"),Ve=m("The step function for the environment, follows the API from OpenAI Gym."),pe=s(),p=r("div"),h(N.$$.fragment),ke=s(),z=r("p"),Me=m(`RL environment wrapper for Simulate scene. Uses functionality from the VecEnv in stable baselines 3
For more information on VecEnv, see the source
`),F=r("a"),Ue=m("https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html"),Ge=s(),I=r("div"),h(q.$$.fragment),Ce=s(),ae=r("p"),Ne=m("Resets the actors and the scene of the environment."),Fe=s(),A=r("div"),h(W.$$.fragment),qe=s(),oe=r("p"),We=m("Samples an action from the actors in the environment. This function loads the configuration of maps and actors to return the correct shape across multiple configurations."),Be=s(),S=r("div"),h(B.$$.fragment),He=s(),se=r("p"),Je=m("The step function for the environment, follows the API from OpenAI Gym."),me=s(),f=r("div"),h(H.$$.fragment),je=s(),K=r("p"),ze=m(`Multi-process RL environment wrapper for Simulate scene. Spawns multiple backend executables to run in parallel,
in addition to the optionality of multiple maps.
Uses functionality from the VecEnv in stable baselines 3. For more information on VecEnv, see the source
`),J=r("a"),Ke=m("https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html"),Qe=s(),V=r("div"),h(j.$$.fragment),Xe=s(),ie=r("p"),Ye=m("The step function for the environment, follows the API from OpenAI Gym."),de=s(),Q=r("p"),Ze=m("Under construction \u{1F6A7}."),this.h()},l(e){const u=$t('[data-svelte="svelte-1phssyn"]',document.head);D=a(u,"META",{name:!0,content:!0}),u.forEach(n),le=i(e),O=a(e,"H1",{class:!0});var fe=o(O);T=a(fe,"A",{id:!0,class:!0,href:!0});var rt=o(T);Y=a(rt,"SPAN",{});var at=o(Y);v(k.$$.fragment,at),at.forEach(n),rt.forEach(n),Ee=i(fe),Z=a(fe,"SPAN",{});var ot=o(Z);we=d(ot,"RL Environment Wrappers"),ot.forEach(n),fe.forEach(n),ce=i(e),c=a(e,"DIV",{class:!0});var y=o(c);v(M.$$.fragment,y),Le=i(y),ee=a(y,"P",{});var st=o(ee);De=d(st,"The basic RL environment wrapper for Simulate scene following the Gym API."),st.forEach(n),Oe=i(y),R=a(y,"DIV",{class:!0});var he=o(R);v(U.$$.fragment,he),Te=i(he),te=a(he,"P",{});var it=o(te);Re=d(it,"Resets the actors and the scene of the environment."),it.forEach(n),he.forEach(n),Pe=i(y),P=a(y,"DIV",{class:!0});var ve=o(P);v(G.$$.fragment,ve),xe=i(ve),ne=a(ve,"P",{});var lt=o(ne);Ie=d(lt,"Samples an action from the actors in the environment. This function loads the configuration of maps and actors to return the correct shape across multiple configurations."),lt.forEach(n),ve.forEach(n),Ae=i(y),x=a(y,"DIV",{class:!0});var ge=o(x);v(C.$$.fragment,ge),Se=i(ge),re=a(ge,"P",{});var ct=o(re);Ve=d(ct,"The step function for the environment, follows the API from OpenAI Gym."),ct.forEach(n),ge.forEach(n),y.forEach(n),pe=i(e),p=a(e,"DIV",{class:!0});var E=o(p);v(N.$$.fragment,E),ke=i(E),z=a(E,"P",{});var et=o(z);Me=d(et,`RL environment wrapper for Simulate scene. Uses functionality from the VecEnv in stable baselines 3
For more information on VecEnv, see the source
`),F=a(et,"A",{href:!0,rel:!0});var pt=o(F);Ue=d(pt,"https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html"),pt.forEach(n),et.forEach(n),Ge=i(E),I=a(E,"DIV",{class:!0});var be=o(I);v(q.$$.fragment,be),Ce=i(be),ae=a(be,"P",{});var mt=o(ae);Ne=d(mt,"Resets the actors and the scene of the environment."),mt.forEach(n),be.forEach(n),Fe=i(E),A=a(E,"DIV",{class:!0});var _e=o(A);v(W.$$.fragment,_e),qe=i(_e),oe=a(_e,"P",{});var dt=o(oe);We=d(dt,"Samples an action from the actors in the environment. This function loads the configuration of maps and actors to return the correct shape across multiple configurations."),dt.forEach(n),_e.forEach(n),Be=i(E),S=a(E,"DIV",{class:!0});var $e=o(S);v(B.$$.fragment,$e),He=i($e),se=a($e,"P",{});var ut=o(se);Je=d(ut,"The step function for the environment, follows the API from OpenAI Gym."),ut.forEach(n),$e.forEach(n),E.forEach(n),me=i(e),f=a(e,"DIV",{class:!0});var X=o(f);v(H.$$.fragment,X),je=i(X),K=a(X,"P",{});var tt=o(K);ze=d(tt,`Multi-process RL environment wrapper for Simulate scene. Spawns multiple backend executables to run in parallel,
in addition to the optionality of multiple maps.
Uses functionality from the VecEnv in stable baselines 3. For more information on VecEnv, see the source
`),J=a(tt,"A",{href:!0,rel:!0});var ft=o(J);Ke=d(ft,"https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html"),ft.forEach(n),tt.forEach(n),Qe=i(X),V=a(X,"DIV",{class:!0});var ye=o(V);v(j.$$.fragment,ye),Xe=i(ye),ie=a(ye,"P",{});var ht=o(ie);Ye=d(ht,"The step function for the environment, follows the API from OpenAI Gym."),ht.forEach(n),ye.forEach(n),X.forEach(n),de=i(e),Q=a(e,"P",{});var vt=o(Q);Ze=d(vt,"Under construction \u{1F6A7}."),vt.forEach(n),this.h()},h(){l(D,"name","hf:doc:metadata"),l(D,"content",JSON.stringify(Dt)),l(T,"id","simulate.RLEnv"),l(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(T,"href","#simulate.RLEnv"),l(O,"class","relative group"),l(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(c,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(F,"href","https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html"),l(F,"rel","nofollow"),l(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(p,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(J,"href","https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html"),l(J,"rel","nofollow"),l(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(f,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,u){t(document.head,D),w(e,le,u),w(e,O,u),t(O,T),t(T,Y),g(k,Y,null),t(O,Ee),t(O,Z),t(Z,we),w(e,ce,u),w(e,c,u),g(M,c,null),t(c,Le),t(c,ee),t(ee,De),t(c,Oe),t(c,R),g(U,R,null),t(R,Te),t(R,te),t(te,Re),t(c,Pe),t(c,P),g(G,P,null),t(P,xe),t(P,ne),t(ne,Ie),t(c,Ae),t(c,x),g(C,x,null),t(x,Se),t(x,re),t(re,Ve),w(e,pe,u),w(e,p,u),g(N,p,null),t(p,ke),t(p,z),t(z,Me),t(z,F),t(F,Ue),t(p,Ge),t(p,I),g(q,I,null),t(I,Ce),t(I,ae),t(ae,Ne),t(p,Fe),t(p,A),g(W,A,null),t(A,qe),t(A,oe),t(oe,We),t(p,Be),t(p,S),g(B,S,null),t(S,He),t(S,se),t(se,Je),w(e,me,u),w(e,f,u),g(H,f,null),t(f,je),t(f,K),t(K,ze),t(K,J),t(J,Ke),t(f,Qe),t(f,V),g(j,V,null),t(V,Xe),t(V,ie),t(ie,Ye),w(e,de,u),w(e,Q,u),t(Q,Ze),ue=!0},p:yt,i(e){ue||(b(k.$$.fragment,e),b(M.$$.fragment,e),b(U.$$.fragment,e),b(G.$$.fragment,e),b(C.$$.fragment,e),b(N.$$.fragment,e),b(q.$$.fragment,e),b(W.$$.fragment,e),b(B.$$.fragment,e),b(H.$$.fragment,e),b(j.$$.fragment,e),ue=!0)},o(e){_(k.$$.fragment,e),_(M.$$.fragment,e),_(U.$$.fragment,e),_(G.$$.fragment,e),_(C.$$.fragment,e),_(N.$$.fragment,e),_(q.$$.fragment,e),_(W.$$.fragment,e),_(B.$$.fragment,e),_(H.$$.fragment,e),_(j.$$.fragment,e),ue=!1},d(e){n(D),e&&n(le),e&&n(O),$(k),e&&n(ce),e&&n(c),$(M),$(U),$(G),$(C),e&&n(pe),e&&n(p),$(N),$(q),$(W),$(B),e&&n(me),e&&n(f),$(H),$(j),e&&n(de),e&&n(Q)}}}const Dt={local:"simulate.RLEnv",title:"RL Environment Wrappers"};function Ot(nt){return Et(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xt extends gt{constructor(D){super();bt(this,D,Ot,Lt,_t,{})}}export{xt as default,Dt as metadata};
