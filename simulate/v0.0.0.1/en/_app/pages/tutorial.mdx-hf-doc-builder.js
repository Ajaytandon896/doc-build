import{S as ye,i as _e,s as ge,e as i,k as L,w as ce,t as r,M as ke,c as u,d as t,m as E,a as f,x as me,h as n,b as s,G as a,g as c,y as pe,q as de,o as we,B as ve,v as $e}from"../chunks/vendor-hf-doc-builder.js";import{T as Se}from"../chunks/Tip-hf-doc-builder.js";import{I as be}from"../chunks/IconCopyLink-hf-doc-builder.js";function Ae(q){let l;return{c(){l=r("The tutorials only cover the basic skills you need to use \u{1F917} Simulate. There are many other useful functionalities and applications that aren't discussed here. You can find more here TODO")},l(p){l=n(p,"The tutorials only cover the basic skills you need to use \u{1F917} Simulate. There are many other useful functionalities and applications that aren't discussed here. You can find more here TODO")},m(p,m){c(p,l,m)},d(p){p&&t(l)}}}function Le(q){let l,p,m,d,D,g,j,P,C,I,w,W,k,G,J,O,h,U,$,z,F,T,K,Q,S,V,X,x,v,Y,y,Z,b,ee,te,B,R,ae,H;return g=new be({}),v=new Se({props:{$$slots:{default:[Ae]},$$scope:{ctx:q}}}),{c(){l=i("meta"),p=L(),m=i("h1"),d=i("a"),D=i("span"),ce(g.$$.fragment),j=L(),P=i("span"),C=r("Overview"),I=L(),w=i("p"),W=r("Welcome to the \u{1F917} Simulate tutorials! These beginner-friendly tutorials will guide you through the fundamentals of working with \u{1F917} Simulate. You\u2019ll load and prepare an environment for training with your Deep RL framework of choice. Along the way, you\u2019ll learn how to define and load different Assets, Sensors and Actuators, watch an RL Agent interact with and see what\u2019s inside your environment and share a dataset to the "),k=i("a"),G=r("Hub"),J=r("."),O=L(),h=i("p"),U=r("The tutorials assume some basic knowledge of Python, Deep Reinforcement Learning and a Deep RL framework like "),$=i("a"),z=r("Stable Baselines 3"),F=r(". If you\u2019re already familiar with these, feel free to check out the "),T=i("a"),K=r("quickstart"),Q=r(" to see what you can do with \u{1F917} Simulate. If you want to learn more about Deep Reinforcement Learning, check of the \u{1F917} "),S=i("a"),V=r("Deep RL course"),X=r("."),x=L(),ce(v.$$.fragment),Y=L(),y=i("p"),Z=r("If you have any questions about \u{1F917} Simulate, feel free to join and ask the community on our "),b=i("a"),ee=r("forum"),te=r("."),B=L(),R=i("p"),ae=r("Let\u2019s get started! \u{1F3C1}"),this.h()},l(e){const o=ke('[data-svelte="svelte-1phssyn"]',document.head);l=u(o,"META",{name:!0,content:!0}),o.forEach(t),p=E(e),m=u(e,"H1",{class:!0});var A=f(m);d=u(A,"A",{id:!0,class:!0,href:!0});var oe=f(d);D=u(oe,"SPAN",{});var re=f(D);me(g.$$.fragment,re),re.forEach(t),oe.forEach(t),j=E(A),P=u(A,"SPAN",{});var ne=f(P);C=n(ne,"Overview"),ne.forEach(t),A.forEach(t),I=E(e),w=u(e,"P",{});var M=f(w);W=n(M,"Welcome to the \u{1F917} Simulate tutorials! These beginner-friendly tutorials will guide you through the fundamentals of working with \u{1F917} Simulate. You\u2019ll load and prepare an environment for training with your Deep RL framework of choice. Along the way, you\u2019ll learn how to define and load different Assets, Sensors and Actuators, watch an RL Agent interact with and see what\u2019s inside your environment and share a dataset to the "),k=u(M,"A",{href:!0,rel:!0});var se=f(k);G=n(se,"Hub"),se.forEach(t),J=n(M,"."),M.forEach(t),O=E(e),h=u(e,"P",{});var _=f(h);U=n(_,"The tutorials assume some basic knowledge of Python, Deep Reinforcement Learning and a Deep RL framework like "),$=u(_,"A",{href:!0,rel:!0});var le=f($);z=n(le,"Stable Baselines 3"),le.forEach(t),F=n(_,". If you\u2019re already familiar with these, feel free to check out the "),T=u(_,"A",{href:!0});var ie=f(T);K=n(ie,"quickstart"),ie.forEach(t),Q=n(_," to see what you can do with \u{1F917} Simulate. If you want to learn more about Deep Reinforcement Learning, check of the \u{1F917} "),S=u(_,"A",{href:!0,rel:!0});var ue=f(S);V=n(ue,"Deep RL course"),ue.forEach(t),X=n(_,"."),_.forEach(t),x=E(e),me(v.$$.fragment,e),Y=E(e),y=u(e,"P",{});var N=f(y);Z=n(N,"If you have any questions about \u{1F917} Simulate, feel free to join and ask the community on our "),b=u(N,"A",{href:!0,rel:!0});var fe=f(b);ee=n(fe,"forum"),fe.forEach(t),te=n(N,"."),N.forEach(t),B=E(e),R=u(e,"P",{});var he=f(R);ae=n(he,"Let\u2019s get started! \u{1F3C1}"),he.forEach(t),this.h()},h(){s(l,"name","hf:doc:metadata"),s(l,"content",JSON.stringify(Ee)),s(d,"id","overview"),s(d,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(d,"href","#overview"),s(m,"class","relative group"),s(k,"href","https://huggingface.co/Spaces"),s(k,"rel","nofollow"),s($,"href","https://stable-baselines3.readthedocs.io/en/master/"),s($,"rel","nofollow"),s(T,"href","./quickstart"),s(S,"href","https://github.com/huggingface/deep-rl-class#the-hugging-face-deep-reinforcement-learning-class-"),s(S,"rel","nofollow"),s(b,"href","https://discuss.huggingface.co/c/simulate/10"),s(b,"rel","nofollow")},m(e,o){a(document.head,l),c(e,p,o),c(e,m,o),a(m,d),a(d,D),pe(g,D,null),a(m,j),a(m,P),a(P,C),c(e,I,o),c(e,w,o),a(w,W),a(w,k),a(k,G),a(w,J),c(e,O,o),c(e,h,o),a(h,U),a(h,$),a($,z),a(h,F),a(h,T),a(T,K),a(h,Q),a(h,S),a(S,V),a(h,X),c(e,x,o),pe(v,e,o),c(e,Y,o),c(e,y,o),a(y,Z),a(y,b),a(b,ee),a(y,te),c(e,B,o),c(e,R,o),a(R,ae),H=!0},p(e,[o]){const A={};o&2&&(A.$$scope={dirty:o,ctx:e}),v.$set(A)},i(e){H||(de(g.$$.fragment,e),de(v.$$.fragment,e),H=!0)},o(e){we(g.$$.fragment,e),we(v.$$.fragment,e),H=!1},d(e){t(l),e&&t(p),e&&t(m),ve(g),e&&t(I),e&&t(w),e&&t(O),e&&t(h),e&&t(x),ve(v,e),e&&t(Y),e&&t(y),e&&t(B),e&&t(R)}}}const Ee={local:"overview",title:"Overview"};function Te(q){return $e(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class qe extends ye{constructor(l){super();_e(this,l,Te,Le,ge,{})}}export{qe as default,Ee as metadata};
